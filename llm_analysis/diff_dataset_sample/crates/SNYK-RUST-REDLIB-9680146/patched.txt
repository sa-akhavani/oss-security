# ====================================================================
# FILE: scripts/update_oauth_resources.sh
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-59 ---
     1| ios_version_list=$(curl -s "https://ipaarchive.com/app/usa/1064216828" | rg "(20\d{2}\.\d+.\d+) / (\d+)" --only-matching -r "Version \$1/Build \$2" | sort | uniq)
     2| ios_app_count=$(echo "$ios_version_list" | wc -l)
     3| echo -e "Fetching \e[34m$ios_app_count iOS app versions...\e[0m"
     4| filename="src/oauth_resources.rs"
     5| echo "// This file was generated by scripts/update_oauth_resources.sh" > "$filename"
     6| echo "// Rerun scripts/update_oauth_resources.sh to update this file" >> "$filename"
     7| echo "// Please do not edit manually" >> "$filename"
     8| echo "// Filled in with real app versions" >> "$filename"
     9| echo "pub const _IOS_APP_VERSION_LIST: &[&str; $ios_app_count] = &[" >> "$filename"
    10| num=0
    11| echo "$ios_version_list" | while IFS= read -r line; do
    12|   num=$((num+1))
    13|   echo "	\"$line\"," >> "$filename"
    14|   echo -e "[$num/$ios_app_count] Fetched \e[34m$line\e[0m."
    15| done
    16| echo "];" >> "$filename"
    17| page_1=$(curl -s "https://apkcombo.com/reddit/com.reddit.frontpage/old-versions/" | rg "<a class=\"ver-item\" href=\"(/reddit/com\.reddit\.frontpage/download/phone-20\d{2}\.\d+\.\d+-apk)\" rel=\"nofollow\">" -r "https://apkcombo.com\$1" | sort | uniq | sed 's/      //g')
    18| page_2=$(curl -s "https://apkcombo.com/reddit/com.reddit.frontpage/old-versions?page=2" | rg "<a class=\"ver-item\" href=\"(/reddit/com\.reddit\.frontpage/download/phone-20\d{2}\.\d+\.\d+-apk)\" rel=\"nofollow\">" -r "https://apkcombo.com\$1" | sort | uniq | sed 's/      //g')
    19| page_3=$(curl -s "https://apkcombo.com/reddit/com.reddit.frontpage/old-versions?page=3" | rg "<a class=\"ver-item\" href=\"(/reddit/com\.reddit\.frontpage/download/phone-20\d{2}\.\d+\.\d+-apk)\" rel=\"nofollow\">" -r "https://apkcombo.com\$1" | sort | uniq | sed 's/      //g')
    20| page_4=$(curl -s "https://apkcombo.com/reddit/com.reddit.frontpage/old-versions?page=4" | rg "<a class=\"ver-item\" href=\"(/reddit/com\.reddit\.frontpage/download/phone-20\d{2}\.\d+\.\d+-apk)\" rel=\"nofollow\">" -r "https://apkcombo.com\$1" | sort | uniq | sed 's/      //g')
    21| page_5=$(curl -s "https://apkcombo.com/reddit/com.reddit.frontpage/old-versions?page=5" | rg "<a class=\"ver-item\" href=\"(/reddit/com\.reddit\.frontpage/download/phone-20\d{2}\.\d+\.\d+-apk)\" rel=\"nofollow\">" -r "https://apkcombo.com\$1" | sort | uniq | sed 's/      //g')
    22| versions="${page_1}"
    23| versions+=$'\n'
    24| versions+="${page_2}"
    25| versions+=$'\n'
    26| versions+="${page_3}"
    27| versions+=$'\n'
    28| versions+="${page_4}"
    29| versions+=$'\n'
    30| versions+="${page_5}"
    31| android_count=$(echo "$versions" | wc -l)
    32| echo -e "Fetching \e[32m$android_count Android app versions...\e[0m"
    33| echo "pub const ANDROID_APP_VERSION_LIST: &[&str; $android_count] = &[" >> "$filename"
    34| num=0
    35| echo "$versions" | while IFS= read -r line; do
    36|   num=$((num+1))
    37|   fetch_page=$(curl -s "$line")
    38|   build=$(echo "$fetch_page" | rg "<span class=\"vercode\">\((\d+)\)</span>" --only-matching -r "\$1" | head -n1)
    39|   version=$(echo "$fetch_page" | rg "<span class=\"vername\">Reddit (20\d{2}\.\d+\.\d+)</span>" --only-matching -r "\$1" | head -n1)
    40|   echo "	\"Version $version/Build $build\"," >> "$filename"
    41|   echo -e "[$num/$android_count] Fetched \e[32mVersion $version/Build $build\e[0m."
    42| done
    43| echo "];" >> "$filename"
    44| table=$(curl -s "https://en.wikipedia.org/w/api.php?action=parse&page=IOS_17&prop=wikitext&section=31&format=json" | jq ".parse.wikitext.\"*\"" | rg "(17\.[\d\.]*)\\\n\|(\w*)\\\n\|" --only-matching -r "Version \$1 (Build \$2)")
    45| ios_count=$(echo "$table" | wc -l)
    46| echo -e "Fetching \e[34m$ios_count iOS versions...\e[0m"
    47| echo "pub const _IOS_OS_VERSION_LIST: &[&str; $ios_count] = &[" >> "$filename"
    48| num=0
    49| echo "$table" | while IFS= read -r line; do
    50|   num=$((num+1))
    51|   echo "	\"$line\"," >> "$filename"
    52|   echo -e "\e[34m[$num/$ios_count] Fetched $line\e[0m."
    53| done
    54| echo "];" >> "$filename"
    55| echo -e "\e[34mRetrieved $ios_app_count iOS app versions.\e[0m"
    56| echo -e "\e[32mRetrieved $android_count Android app versions.\e[0m"
    57| echo -e "\e[34mRetrieved $ios_count iOS versions.\e[0m"
    58| echo -e "\e[34mTotal: $((ios_app_count + android_count + ios_count))\e[0m"
    59| echo -e "\e[32mSuccess!\e[0m"


# ====================================================================
# FILE: src/client.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-389 ---
     1| use arc_swap::ArcSwap;
     2| use cached::proc_macro::cached;
     3| use futures_lite::future::block_on;
     4| use futures_lite::{future::Boxed, FutureExt};
     5| use hyper::client::HttpConnector;
     6| use hyper::header::HeaderValue;
     7| use hyper::{body, body::Buf, header, Body, Client, Method, Request, Response, Uri};
     8| use hyper_rustls::HttpsConnector;
     9| use libflate::gzip;
    10| use log::{error, trace, warn};
    11| use once_cell::sync::Lazy;
    12| use percent_encoding::{percent_encode, CONTROLS};
    13| use serde_json::Value;
    14| use std::sync::atomic::Ordering;
    15| use std::sync::atomic::{AtomicBool, AtomicU16};
    16| use std::{io, result::Result};
    17| use crate::dbg_msg;
    18| use crate::oauth::{force_refresh_token, token_daemon, Oauth};
    19| use crate::server::RequestExt;
    20| use crate::utils::{format_url, Post};
    21| const REDDIT_URL_BASE: &str = "https://oauth.reddit.com";
    22| const REDDIT_URL_BASE_HOST: &str = "oauth.reddit.com";
    23| const REDDIT_SHORT_URL_BASE: &str = "https://redd.it";
    24| const REDDIT_SHORT_URL_BASE_HOST: &str = "redd.it";
    25| const ALTERNATIVE_REDDIT_URL_BASE: &str = "https://www.reddit.com";
    26| const ALTERNATIVE_REDDIT_URL_BASE_HOST: &str = "www.reddit.com";
    27| pub static HTTPS_CONNECTOR: Lazy<HttpsConnector<HttpConnector>> =
    28| 	Lazy::new(|| hyper_rustls::HttpsConnectorBuilder::new().with_native_roots().https_only().enable_http2().build());
    29| pub static CLIENT: Lazy<Client<HttpsConnector<HttpConnector>>> = Lazy::new(|| Client::builder().build::<_, Body>(HTTPS_CONNECTOR.clone()));
    30| pub static OAUTH_CLIENT: Lazy<ArcSwap<Oauth>> = Lazy::new(|| {
    31| 	let client = block_on(Oauth::new());
    32| 	tokio::spawn(token_daemon());
    33| 	ArcSwap::new(client.into())
    34| });
    35| pub static OAUTH_RATELIMIT_REMAINING: AtomicU16 = AtomicU16::new(99);
    36| pub static OAUTH_IS_ROLLING_OVER: AtomicBool = AtomicBool::new(false);
    37| const URL_PAIRS: [(&str, &str); 2] = [
    38| 	(ALTERNATIVE_REDDIT_URL_BASE, ALTERNATIVE_REDDIT_URL_BASE_HOST),
    39| 	(REDDIT_SHORT_URL_BASE, REDDIT_SHORT_URL_BASE_HOST),
    40| ];
    41| #[cached(size = 1024, time = 600, result = true)]
    42| #[async_recursion::async_recursion]
    43| pub async fn canonical_path(path: String, tries: i8) -> Result<Option<String>, String> {
    44| 	if tries == 0 {
    45| 		return Ok(None);
    46| 	}
    47| 	let res = {
    48| 		let mut res = None;
    49| 		for (url_base, url_base_host) in URL_PAIRS {
    50| 			res = reddit_short_head(path.clone(), true, url_base, url_base_host).await.ok();
    51| 			if let Some(res) = &res {
    52| 				if !res.status().is_client_error() {
    53| 					break;
    54| 				}
    55| 			}
    56| 		}
    57| 		res
    58| 	};
    59| 	let res = res.ok_or_else(|| "Unable to make HEAD request to Reddit.".to_string())?;
    60| 	let status = res.status().as_u16();
    61| 	let policy_error = res.headers().get(header::RETRY_AFTER).is_some();
    62| 	match status {
    63| 		200..=299 => Ok(Some(path)),
    64| 		301 => match res.headers().get(header::LOCATION) {
    65| 			Some(val) => {
    66| 				let Ok(original) = val.to_str() else {
    67| 					return Err("Unable to decode Location header.".to_string());
    68| 				};
    69| 				let stripped_uri = original.strip_suffix(".json").unwrap_or(original).split('?').next().unwrap_or_default();
    70| 				let uri = format_url(stripped_uri);
    71| 				canonical_path(uri, tries - 1).await
    72| 			}
    73| 			None => Ok(None),
    74| 		},
    75| 		300..=399 => Ok(None),
    76| 		429 => Err("Too many requests.".to_string()),
    77| 		403 if policy_error => Err("Too many requests.".to_string()),
    78| 		_ => Ok(
    79| 			res
    80| 				.headers()
    81| 				.get(header::LOCATION)
    82| 				.map(|val| percent_encode(val.as_bytes(), CONTROLS).to_string().trim_start_matches(REDDIT_URL_BASE).to_string()),
    83| 		),
    84| 	}
    85| }
    86| pub async fn proxy(req: Request<Body>, format: &str) -> Result<Response<Body>, String> {
    87| 	let mut url = format!("{format}?{}", req.uri().query().unwrap_or_default());
    88| 	for (name, value) in &req.params() {
    89| 		url = url.replace(&format!("{{{name}}}"), value);
    90| 	}
    91| 	stream(&url, &req).await
    92| }
    93| async fn stream(url: &str, req: &Request<Body>) -> Result<Response<Body>, String> {
    94| 	let parsed_uri = url.parse::<Uri>().map_err(|_| "Couldn't parse URL".to_string())?;
    95| 	let client: &Lazy<Client<_, Body>> = &CLIENT;
    96| 	let mut builder = Request::get(parsed_uri);
    97| 	for &key in &["Range", "If-Modified-Since", "Cache-Control"] {
    98| 		if let Some(value) = req.headers().get(key) {
    99| 			builder = builder.header(key, value);
   100| 		}
   101| 	}
   102| 	let stream_request = builder.body(Body::empty()).map_err(|_| "Couldn't build empty body in stream".to_string())?;
   103| 	client
   104| 		.request(stream_request)
   105| 		.await
   106| 		.map(|mut res| {
   107| 			let mut rm = |key: &str| res.headers_mut().remove(key);
   108| 			rm("access-control-expose-headers");
   109| 			rm("server");
   110| 			rm("vary");
   111| 			rm("etag");
   112| 			rm("x-cdn");
   113| 			rm("x-cdn-client-region");
   114| 			rm("x-cdn-name");
   115| 			rm("x-cdn-server-region");
   116| 			rm("x-reddit-cdn");
   117| 			rm("x-reddit-video-features");
   118| 			rm("Nel");
   119| 			rm("Report-To");
   120| 			res
   121| 		})
   122| 		.map_err(|e| e.to_string())
   123| }
   124| fn reddit_get(path: String, quarantine: bool) -> Boxed<Result<Response<Body>, String>> {
   125| 	request(&Method::GET, path, true, quarantine, REDDIT_URL_BASE, REDDIT_URL_BASE_HOST)
   126| }
   127| fn reddit_short_head(path: String, quarantine: bool, base_path: &'static str, host: &'static str) -> Boxed<Result<Response<Body>, String>> {
   128| 	request(&Method::HEAD, path, false, quarantine, base_path, host)
   129| }
   130| fn request(method: &'static Method, path: String, redirect: bool, quarantine: bool, base_path: &'static str, host: &'static str) -> Boxed<Result<Response<Body>, String>> {
   131| 	let url = format!("{base_path}{path}");
   132| 	let client: &Lazy<Client<_, Body>> = &CLIENT;
   133| 	let mut headers: Vec<(String, String)> = vec![
   134| 		("Host".into(), host.into()),
   135| 		("Accept-Encoding".into(), if method == Method::GET { "gzip".into() } else { "identity".into() }),
   136| 		(
   137| 			"Cookie".into(),
   138| 			if quarantine {
   139| 				"_options=%7B%22pref_quarantine_optin%22%3A%20true%2C%20%22pref_gated_sr_optin%22%3A%20true%7D".into()
   140| 			} else {
   141| 				"".into()
   142| 			},
   143| 		),
   144| 	];
   145| 	{
   146| 		let client = OAUTH_CLIENT.load_full();
   147| 		for (key, value) in client.headers_map.clone() {
   148| 			headers.push((key, value));
   149| 		}
   150| 	}
   151| 	fastrand::shuffle(&mut headers);
   152| 	let mut builder = Request::builder().method(method).uri(&url);
   153| 	for (key, value) in headers {
   154| 		builder = builder.header(key, value);
   155| 	}
   156| 	let builder = builder.body(Body::empty());
   157| 	async move {
   158| 		match builder {
   159| 			Ok(req) => match client.request(req).await {
   160| 				Ok(mut response) => {
   161| 					if response.status().is_redirection() {
   162| 						if !redirect {
   163| 							return Ok(response);
   164| 						};
   165| 						let location_header = response.headers().get(header::LOCATION);
   166| 						if location_header == Some(&HeaderValue::from_static(ALTERNATIVE_REDDIT_URL_BASE)) {
   167| 							return Err("Reddit response was invalid".to_string());
   168| 						}
   169| 						return request(
   170| 							method,
   171| 							location_header
   172| 								.map(|val| {
   173| 									let new_path = percent_encode(val.as_bytes(), CONTROLS)
   174| 										.to_string()
   175| 										.trim_start_matches(REDDIT_URL_BASE)
   176| 										.trim_start_matches(ALTERNATIVE_REDDIT_URL_BASE)
   177| 										.to_string();
   178| 									format!("{new_path}{}raw_json=1", if new_path.contains('?') { "&" } else { "?" })
   179| 								})
   180| 								.unwrap_or_default()
   181| 								.to_string(),
   182| 							true,
   183| 							quarantine,
   184| 							base_path,
   185| 							host,
   186| 						)
   187| 						.await;
   188| 					};
   189| 					match response.headers().get(header::CONTENT_ENCODING) {
   190| 						None => Ok(response),
   191| 						Some(hdr) => {
   192| 							match hdr.to_str() {
   193| 								Ok(val) => match val {
   194| 									"gzip" => {}
   195| 									"identity" => return Ok(response),
   196| 									_ => return Err("Reddit response was encoded with an unsupported compressor".to_string()),
   197| 								},
   198| 								Err(_) => return Err("Reddit response was invalid".to_string()),
   199| 							}
   200| 							let mut decompressed: Vec<u8>;
   201| 							{
   202| 								let mut aggregated_body = match body::aggregate(response.body_mut()).await {
   203| 									Ok(b) => b.reader(),
   204| 									Err(e) => return Err(e.to_string()),
   205| 								};
   206| 								let mut decoder = match gzip::Decoder::new(&mut aggregated_body) {
   207| 									Ok(decoder) => decoder,
   208| 									Err(e) => return Err(e.to_string()),
   209| 								};
   210| 								decompressed = Vec::<u8>::new();
   211| 								if let Err(e) = io::copy(&mut decoder, &mut decompressed) {
   212| 									return Err(e.to_string());
   213| 								};
   214| 							}
   215| 							response.headers_mut().remove(header::CONTENT_ENCODING);
   216| 							response.headers_mut().insert(header::CONTENT_LENGTH, decompressed.len().into());
   217| 							*(response.body_mut()) = Body::from(decompressed);
   218| 							Ok(response)
   219| 						}
   220| 					}
   221| 				}
   222| 				Err(e) => {
   223| 					dbg_msg!("{method} {REDDIT_URL_BASE}{path}: {}", e);
   224| 					Err(e.to_string())
   225| 				}
   226| 			},
   227| 			Err(_) => Err("Post url contains non-ASCII characters".to_string()),
   228| 		}
   229| 	}
   230| 	.boxed()
   231| }
   232| #[cached(size = 100, time = 30, result = true)]
   233| pub async fn json(path: String, quarantine: bool) -> Result<Value, String> {
   234| 	let err = |msg: &str, e: String, path: String| -> Result<Value, String> {
   235| 		Err(format!("{msg}: {e} | {path}"))
   236| 	};
   237| 	let current_rate_limit = OAUTH_RATELIMIT_REMAINING.load(Ordering::SeqCst);
   238| 	let is_rolling_over = OAUTH_IS_ROLLING_OVER.load(Ordering::SeqCst);
   239| 	if current_rate_limit < 10 && !is_rolling_over {
   240| 		warn!("Rate limit {current_rate_limit} is low. Spawning force_refresh_token()");
   241| 		tokio::spawn(force_refresh_token());
   242| 	}
   243| 	OAUTH_RATELIMIT_REMAINING.fetch_sub(1, Ordering::SeqCst);
   244| 	match reddit_get(path.clone(), quarantine).await {
   245| 		Ok(response) => {
   246| 			let status = response.status();
   247| 			let reset: Option<String> = if let (Some(remaining), Some(reset), Some(used)) = (
   248| 				response.headers().get("x-ratelimit-remaining").and_then(|val| val.to_str().ok().map(|s| s.to_string())),
   249| 				response.headers().get("x-ratelimit-reset").and_then(|val| val.to_str().ok().map(|s| s.to_string())),
   250| 				response.headers().get("x-ratelimit-used").and_then(|val| val.to_str().ok().map(|s| s.to_string())),
   251| 			) {
   252| 				trace!(
   253| 					"Ratelimit remaining: Header says {remaining}, we have {current_rate_limit}. Resets in {reset}. Rollover: {}. Ratelimit used: {used}",
   254| 					if is_rolling_over { "yes" } else { "no" },
   255| 				);
   256| 				if let Ok(val) = remaining.parse::<f32>() {
   257| 					OAUTH_RATELIMIT_REMAINING.store(val.round() as u16, Ordering::SeqCst);
   258| 				}
   259| 				Some(reset)
   260| 			} else {
   261| 				None
   262| 			};
   263| 			match hyper::body::aggregate(response).await {
   264| 				Ok(body) => {
   265| 					let has_remaining = body.has_remaining();
   266| 					if !has_remaining {
   267| 						tokio::spawn(force_refresh_token());
   268| 						return match reset {
   269| 							Some(val) => Err(format!(
   270| 								"Reddit rate limit exceeded. Try refreshing in a few seconds.\
   271| 								 Rate limit will reset in: {val}"
   272| 							)),
   273| 							None => Err("Reddit rate limit exceeded".to_string()),
   274| 						};
   275| 					}
   276| 					match serde_json::from_reader(body.reader()) {
   277| 						Ok(value) => {
   278| 							let json: Value = value;
   279| 							if let Some(data) = json.get("data") {
   280| 								if let Some(is_suspended) = data.get("is_suspended").and_then(Value::as_bool) {
   281| 									if is_suspended {
   282| 										return Err("suspended".into());
   283| 									}
   284| 								}
   285| 							}
   286| 							if json["error"].is_i64() {
   287| 								if json["message"] == "Unauthorized" {
   288| 									error!("Forcing a token refresh");
   289| 									let () = force_refresh_token().await;
   290| 									return Err("OAuth token has expired. Please refresh the page!".to_string());
   291| 								}
   292| 								if json["reason"] == "quarantined" {
   293| 									return Err("quarantined".into());
   294| 								}
   295| 								if json["reason"] == "gated" {
   296| 									return Err("gated".into());
   297| 								}
   298| 								if json["reason"] == "private" {
   299| 									return Err("private".into());
   300| 								}
   301| 								if json["reason"] == "banned" {
   302| 									return Err("banned".into());
   303| 								}
   304| 								Err(format!("Reddit error {} \"{}\": {} | {path}", json["error"], json["reason"], json["message"]))
   305| 							} else {
   306| 								Ok(json)
   307| 							}
   308| 						}
   309| 						Err(e) => {
   310| 							error!("Got an invalid response from reddit {e}. Status code: {status}");
   311| 							if status.is_server_error() {
   312| 								Err("Reddit is having issues, check if there's an outage".to_string())
   313| 							} else {
   314| 								err("Failed to parse page JSON data", e.to_string(), path)
   315| 							}
   316| 						}
   317| 					}
   318| 				}
   319| 				Err(e) => err("Failed receiving body from Reddit", e.to_string(), path),
   320| 			}
   321| 		}
   322| 		Err(e) => err("Couldn't send request to Reddit", e, path),
   323| 	}
   324| }
   325| async fn self_check(sub: &str) -> Result<(), String> {
   326| 	let query = format!("/r/{sub}/hot.json?&raw_json=1");
   327| 	match Post::fetch(&query, true).await {
   328| 		Ok(_) => Ok(()),
   329| 		Err(e) => Err(e),
   330| 	}
   331| }
   332| pub async fn rate_limit_check() -> Result<(), String> {
   333| 	self_check("reddit").await?;
   334| 	if OAUTH_RATELIMIT_REMAINING.load(Ordering::SeqCst) != 99 {
   335| 		return Err(format!("Rate limit check failed: expected 99, got {}", OAUTH_RATELIMIT_REMAINING.load(Ordering::SeqCst)));
   336| 	}
   337| 	force_refresh_token().await;
   338| 	self_check("rust").await?;
   339| 	if OAUTH_RATELIMIT_REMAINING.load(Ordering::SeqCst) != 99 {
   340| 		return Err(format!("Rate limit check failed: expected 99, got {}", OAUTH_RATELIMIT_REMAINING.load(Ordering::SeqCst)));
   341| 	}
   342| 	Ok(())
   343| }
   344| #[cfg(test)]
   345| use {crate::config::get_setting, sealed_test::prelude::*};
   346| #[tokio::test(flavor = "multi_thread")]
   347| async fn test_rate_limit_check() {
   348| 	rate_limit_check().await.unwrap();
   349| }
   350| #[test]
   351| #[sealed_test(env = [("REDLIB_DEFAULT_SUBSCRIPTIONS", "rust")])]
   352| fn test_default_subscriptions() {
   353| 	tokio::runtime::Builder::new_multi_thread().enable_all().build().unwrap().block_on(async {
   354| 		let subscriptions = get_setting("REDLIB_DEFAULT_SUBSCRIPTIONS");
   355| 		assert!(subscriptions.is_some());
   356| 		rate_limit_check().await.unwrap();
   357| 	});
   358| }
   359| #[cfg(test)]
   360| const POPULAR_URL: &str = "/r/popular/hot.json?&raw_json=1&geo_filter=GLOBAL";
   361| #[tokio::test(flavor = "multi_thread")]
   362| async fn test_localization_popular() {
   363| 	let val = json(POPULAR_URL.to_string(), false).await.unwrap();
   364| 	assert_eq!("GLOBAL", val["data"]["geo_filter"].as_str().unwrap());
   365| }
   366| #[tokio::test(flavor = "multi_thread")]
   367| async fn test_obfuscated_share_link() {
   368| 	let share_link = "/r/rust/s/kPgq8WNHRK".into();
   369| 	let canonical_link = "/r/rust/comments/18t5968/why_use_tuple_struct_over_standard_struct/kfbqlbc/".into();
   370| 	assert_eq!(canonical_path(share_link, 3).await, Ok(Some(canonical_link)));
   371| }
   372| #[tokio::test(flavor = "multi_thread")]
   373| async fn test_private_sub() {
   374| 	let link = json("/r/suicide/about.json?raw_json=1".into(), true).await;
   375| 	assert!(link.is_err());
   376| 	assert_eq!(link, Err("private".into()));
   377| }
   378| #[tokio::test(flavor = "multi_thread")]
   379| async fn test_banned_sub() {
   380| 	let link = json("/r/aaa/about.json?raw_json=1".into(), true).await;
   381| 	assert!(link.is_err());
   382| 	assert_eq!(link, Err("banned".into()));
   383| }
   384| #[tokio::test(flavor = "multi_thread")]
   385| async fn test_gated_sub() {
   386| 	let link = json("/r/drugs/about.json?raw_json=1".into(), false).await;
   387| 	assert!(link.is_err());
   388| 	assert_eq!(link, Err("gated".into()));
   389| }


# ====================================================================
# FILE: src/config.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-211 ---
     1| use once_cell::sync::Lazy;
     2| use serde::{Deserialize, Serialize};
     3| use std::{env::var, fs::read_to_string};
     4| pub static CONFIG: Lazy<Config> = Lazy::new(Config::load);
     5| pub const DEFAULT_PUSHSHIFT_FRONTEND: &str = "undelete.pullpush.io";
     6| #[derive(Default, Serialize, Deserialize, Clone, Debug)]
     7| pub struct Config {
     8| 	#[serde(rename = "REDLIB_SFW_ONLY")]
     9| 	#[serde(alias = "LIBREDDIT_SFW_ONLY")]
    10| 	pub(crate) sfw_only: Option<String>,
    11| 	#[serde(rename = "REDLIB_DEFAULT_THEME")]
    12| 	#[serde(alias = "LIBREDDIT_DEFAULT_THEME")]
    13| 	pub(crate) default_theme: Option<String>,
    14| 	#[serde(rename = "REDLIB_DEFAULT_FRONT_PAGE")]
    15| 	#[serde(alias = "LIBREDDIT_DEFAULT_FRONT_PAGE")]
    16| 	pub(crate) default_front_page: Option<String>,
    17| 	#[serde(rename = "REDLIB_DEFAULT_LAYOUT")]
    18| 	#[serde(alias = "LIBREDDIT_DEFAULT_LAYOUT")]
    19| 	pub(crate) default_layout: Option<String>,
    20| 	#[serde(rename = "REDLIB_DEFAULT_WIDE")]
    21| 	#[serde(alias = "LIBREDDIT_DEFAULT_WIDE")]
    22| 	pub(crate) default_wide: Option<String>,
    23| 	#[serde(rename = "REDLIB_DEFAULT_COMMENT_SORT")]
    24| 	#[serde(alias = "LIBREDDIT_DEFAULT_COMMENT_SORT")]
    25| 	pub(crate) default_comment_sort: Option<String>,
    26| 	#[serde(rename = "REDLIB_DEFAULT_POST_SORT")]
    27| 	#[serde(alias = "LIBREDDIT_DEFAULT_POST_SORT")]
    28| 	pub(crate) default_post_sort: Option<String>,
    29| 	#[serde(rename = "REDLIB_DEFAULT_BLUR_SPOILER")]
    30| 	#[serde(alias = "LIBREDDIT_DEFAULT_BLUR_SPOILER")]
    31| 	pub(crate) default_blur_spoiler: Option<String>,
    32| 	#[serde(rename = "REDLIB_DEFAULT_SHOW_NSFW")]
    33| 	#[serde(alias = "LIBREDDIT_DEFAULT_SHOW_NSFW")]
    34| 	pub(crate) default_show_nsfw: Option<String>,
    35| 	#[serde(rename = "REDLIB_DEFAULT_BLUR_NSFW")]
    36| 	#[serde(alias = "LIBREDDIT_DEFAULT_BLUR_NSFW")]
    37| 	pub(crate) default_blur_nsfw: Option<String>,
    38| 	#[serde(rename = "REDLIB_DEFAULT_USE_HLS")]
    39| 	#[serde(alias = "LIBREDDIT_DEFAULT_USE_HLS")]
    40| 	pub(crate) default_use_hls: Option<String>,
    41| 	#[serde(rename = "REDLIB_DEFAULT_HIDE_HLS_NOTIFICATION")]
    42| 	#[serde(alias = "LIBREDDIT_DEFAULT_HIDE_HLS_NOTIFICATION")]
    43| 	pub(crate) default_hide_hls_notification: Option<String>,
    44| 	#[serde(rename = "REDLIB_DEFAULT_HIDE_AWARDS")]
    45| 	#[serde(alias = "LIBREDDIT_DEFAULT_HIDE_AWARDS")]
    46| 	pub(crate) default_hide_awards: Option<String>,
    47| 	#[serde(rename = "REDLIB_DEFAULT_HIDE_SIDEBAR_AND_SUMMARY")]
    48| 	#[serde(alias = "LIBREDDIT_DEFAULT_HIDE_SIDEBAR_AND_SUMMARY")]
    49| 	pub(crate) default_hide_sidebar_and_summary: Option<String>,
    50| 	#[serde(rename = "REDLIB_DEFAULT_HIDE_SCORE")]
    51| 	#[serde(alias = "LIBREDDIT_DEFAULT_HIDE_SCORE")]
    52| 	pub(crate) default_hide_score: Option<String>,
    53| 	#[serde(rename = "REDLIB_DEFAULT_SUBSCRIPTIONS")]
    54| 	#[serde(alias = "LIBREDDIT_DEFAULT_SUBSCRIPTIONS")]
    55| 	pub(crate) default_subscriptions: Option<String>,
    56| 	#[serde(rename = "REDLIB_DEFAULT_FILTERS")]
    57| 	#[serde(alias = "LIBREDDIT_DEFAULT_FILTERS")]
    58| 	pub(crate) default_filters: Option<String>,
    59| 	#[serde(rename = "REDLIB_DEFAULT_DISABLE_VISIT_REDDIT_CONFIRMATION")]
    60| 	#[serde(alias = "LIBREDDIT_DEFAULT_DISABLE_VISIT_REDDIT_CONFIRMATION")]
    61| 	pub(crate) default_disable_visit_reddit_confirmation: Option<String>,
    62| 	#[serde(rename = "REDLIB_BANNER")]
    63| 	#[serde(alias = "LIBREDDIT_BANNER")]
    64| 	pub(crate) banner: Option<String>,
    65| 	#[serde(rename = "REDLIB_ROBOTS_DISABLE_INDEXING")]
    66| 	#[serde(alias = "LIBREDDIT_ROBOTS_DISABLE_INDEXING")]
    67| 	pub(crate) robots_disable_indexing: Option<String>,
    68| 	#[serde(rename = "REDLIB_PUSHSHIFT_FRONTEND")]
    69| 	#[serde(alias = "LIBREDDIT_PUSHSHIFT_FRONTEND")]
    70| 	pub(crate) pushshift: Option<String>,
    71| 	#[serde(rename = "REDLIB_ENABLE_RSS")]
    72| 	pub(crate) enable_rss: Option<String>,
    73| 	#[serde(rename = "REDLIB_FULL_URL")]
    74| 	pub(crate) full_url: Option<String>,
    75| 	#[serde(rename = "REDLIB_DEFAULT_REMOVE_DEFAULT_FEEDS")]
    76| 	pub(crate) default_remove_default_feeds: Option<String>,
    77| }
    78| impl Config {
    79| 	pub fn load() -> Self {
    80| 		let load_config = |name: &str| {
    81| 			let new_file = read_to_string(name);
    82| 			new_file.ok().and_then(|new_file| toml::from_str::<Self>(&new_file).ok())
    83| 		};
    84| 		let config = load_config("redlib.toml").or_else(|| load_config("libreddit.toml")).unwrap_or_default();
    85| 		let parse = |key: &str| -> Option<String> {
    86| 			let legacy_key = key.replace("REDLIB_", "LIBREDDIT_");
    87| 			var(key).ok().or_else(|| var(legacy_key).ok()).or_else(|| get_setting_from_config(key, &config))
    88| 		};
    89| 		Self {
    90| 			sfw_only: parse("REDLIB_SFW_ONLY"),
    91| 			default_theme: parse("REDLIB_DEFAULT_THEME"),
    92| 			default_front_page: parse("REDLIB_DEFAULT_FRONT_PAGE"),
    93| 			default_layout: parse("REDLIB_DEFAULT_LAYOUT"),
    94| 			default_post_sort: parse("REDLIB_DEFAULT_POST_SORT"),
    95| 			default_wide: parse("REDLIB_DEFAULT_WIDE"),
    96| 			default_comment_sort: parse("REDLIB_DEFAULT_COMMENT_SORT"),
    97| 			default_blur_spoiler: parse("REDLIB_DEFAULT_BLUR_SPOILER"),
    98| 			default_show_nsfw: parse("REDLIB_DEFAULT_SHOW_NSFW"),
    99| 			default_blur_nsfw: parse("REDLIB_DEFAULT_BLUR_NSFW"),
   100| 			default_use_hls: parse("REDLIB_DEFAULT_USE_HLS"),
   101| 			default_hide_hls_notification: parse("REDLIB_DEFAULT_HIDE_HLS_NOTIFICATION"),
   102| 			default_hide_awards: parse("REDLIB_DEFAULT_HIDE_AWARDS"),
   103| 			default_hide_sidebar_and_summary: parse("REDLIB_DEFAULT_HIDE_SIDEBAR_AND_SUMMARY"),
   104| 			default_hide_score: parse("REDLIB_DEFAULT_HIDE_SCORE"),
   105| 			default_subscriptions: parse("REDLIB_DEFAULT_SUBSCRIPTIONS"),
   106| 			default_filters: parse("REDLIB_DEFAULT_FILTERS"),
   107| 			default_disable_visit_reddit_confirmation: parse("REDLIB_DEFAULT_DISABLE_VISIT_REDDIT_CONFIRMATION"),
   108| 			banner: parse("REDLIB_BANNER"),
   109| 			robots_disable_indexing: parse("REDLIB_ROBOTS_DISABLE_INDEXING"),
   110| 			pushshift: parse("REDLIB_PUSHSHIFT_FRONTEND"),
   111| 			enable_rss: parse("REDLIB_ENABLE_RSS"),
   112| 			full_url: parse("REDLIB_FULL_URL"),
   113| 			default_remove_default_feeds: parse("REDLIB_DEFAULT_REMOVE_DEFAULT_FEEDS"),
   114| 		}
   115| 	}
   116| }
   117| fn get_setting_from_config(name: &str, config: &Config) -> Option<String> {
   118| 	match name {
   119| 		"REDLIB_SFW_ONLY" => config.sfw_only.clone(),
   120| 		"REDLIB_DEFAULT_THEME" => config.default_theme.clone(),
   121| 		"REDLIB_DEFAULT_FRONT_PAGE" => config.default_front_page.clone(),
   122| 		"REDLIB_DEFAULT_LAYOUT" => config.default_layout.clone(),
   123| 		"REDLIB_DEFAULT_COMMENT_SORT" => config.default_comment_sort.clone(),
   124| 		"REDLIB_DEFAULT_POST_SORT" => config.default_post_sort.clone(),
   125| 		"REDLIB_DEFAULT_BLUR_SPOILER" => config.default_blur_spoiler.clone(),
   126| 		"REDLIB_DEFAULT_SHOW_NSFW" => config.default_show_nsfw.clone(),
   127| 		"REDLIB_DEFAULT_BLUR_NSFW" => config.default_blur_nsfw.clone(),
   128| 		"REDLIB_DEFAULT_USE_HLS" => config.default_use_hls.clone(),
   129| 		"REDLIB_DEFAULT_HIDE_HLS_NOTIFICATION" => config.default_hide_hls_notification.clone(),
   130| 		"REDLIB_DEFAULT_WIDE" => config.default_wide.clone(),
   131| 		"REDLIB_DEFAULT_HIDE_AWARDS" => config.default_hide_awards.clone(),
   132| 		"REDLIB_DEFAULT_HIDE_SIDEBAR_AND_SUMMARY" => config.default_hide_sidebar_and_summary.clone(),
   133| 		"REDLIB_DEFAULT_HIDE_SCORE" => config.default_hide_score.clone(),
   134| 		"REDLIB_DEFAULT_SUBSCRIPTIONS" => config.default_subscriptions.clone(),
   135| 		"REDLIB_DEFAULT_FILTERS" => config.default_filters.clone(),
   136| 		"REDLIB_DEFAULT_DISABLE_VISIT_REDDIT_CONFIRMATION" => config.default_disable_visit_reddit_confirmation.clone(),
   137| 		"REDLIB_BANNER" => config.banner.clone(),
   138| 		"REDLIB_ROBOTS_DISABLE_INDEXING" => config.robots_disable_indexing.clone(),
   139| 		"REDLIB_PUSHSHIFT_FRONTEND" => config.pushshift.clone(),
   140| 		"REDLIB_ENABLE_RSS" => config.enable_rss.clone(),
   141| 		"REDLIB_FULL_URL" => config.full_url.clone(),
   142| 		"REDLIB_DEFAULT_REMOVE_DEFAULT_FEEDS" => config.default_remove_default_feeds.clone(),
   143| 		_ => None,
   144| 	}
   145| }
   146| pub fn get_setting(name: &str) -> Option<String> {
   147| 	get_setting_from_config(name, &CONFIG)
   148| }
   149| #[cfg(test)]
   150| use {sealed_test::prelude::*, std::fs::write};
   151| #[test]
   152| fn test_deserialize() {
   153| 	let result = toml::from_str::<Config>("");
   154| 	assert!(result.is_ok(), "Error: {}", result.unwrap_err());
   155| }
   156| #[test]
   157| #[sealed_test(env = [("REDLIB_SFW_ONLY", "on")])]
   158| fn test_env_var() {
   159| 	assert!(crate::utils::sfw_only())
   160| }
   161| #[test]
   162| #[sealed_test]
   163| fn test_config() {
   164| 	let config_to_write = r#"REDLIB_DEFAULT_COMMENT_SORT = "best""#;
   165| 	write("redlib.toml", config_to_write).unwrap();
   166| 	assert_eq!(get_setting("REDLIB_DEFAULT_COMMENT_SORT"), Some("best".into()));
   167| }
   168| #[test]
   169| #[sealed_test]
   170| fn test_config_legacy() {
   171| 	let config_to_write = r#"LIBREDDIT_DEFAULT_COMMENT_SORT = "best""#;
   172| 	write("libreddit.toml", config_to_write).unwrap();
   173| 	assert_eq!(get_setting("REDLIB_DEFAULT_COMMENT_SORT"), Some("best".into()));
   174| }
   175| #[test]
   176| #[sealed_test(env = [("LIBREDDIT_SFW_ONLY", "on")])]
   177| fn test_env_var_legacy() {
   178| 	assert!(crate::utils::sfw_only())
   179| }
   180| #[test]
   181| #[sealed_test(env = [("REDLIB_DEFAULT_COMMENT_SORT", "top")])]
   182| fn test_env_config_precedence() {
   183| 	let config_to_write = r#"REDLIB_DEFAULT_COMMENT_SORT = "best""#;
   184| 	write("redlib.toml", config_to_write).unwrap();
   185| 	assert_eq!(get_setting("REDLIB_DEFAULT_COMMENT_SORT"), Some("top".into()))
   186| }
   187| #[test]
   188| #[sealed_test(env = [("REDLIB_DEFAULT_COMMENT_SORT", "top")])]
   189| fn test_alt_env_config_precedence() {
   190| 	let config_to_write = r#"REDLIB_DEFAULT_COMMENT_SORT = "best""#;
   191| 	write("redlib.toml", config_to_write).unwrap();
   192| 	assert_eq!(get_setting("REDLIB_DEFAULT_COMMENT_SORT"), Some("top".into()))
   193| }
   194| #[test]
   195| #[sealed_test(env = [("REDLIB_DEFAULT_SUBSCRIPTIONS", "news+bestof")])]
   196| fn test_default_subscriptions() {
   197| 	assert_eq!(get_setting("REDLIB_DEFAULT_SUBSCRIPTIONS"), Some("news+bestof".into()));
   198| }
   199| #[test]
   200| #[sealed_test(env = [("REDLIB_DEFAULT_FILTERS", "news+bestof")])]
   201| fn test_default_filters() {
   202| 	assert_eq!(get_setting("REDLIB_DEFAULT_FILTERS"), Some("news+bestof".into()));
   203| }
   204| #[test]
   205| #[sealed_test]
   206| fn test_pushshift() {
   207| 	let config_to_write = r#"REDLIB_PUSHSHIFT_FRONTEND = "https://api.pushshift.io""#;
   208| 	write("redlib.toml", config_to_write).unwrap();
   209| 	assert!(get_setting("REDLIB_PUSHSHIFT_FRONTEND").is_some());
   210| 	assert_eq!(get_setting("REDLIB_PUSHSHIFT_FRONTEND"), Some("https://api.pushshift.io".into()));
   211| }


# ====================================================================
# FILE: src/duplicates.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-128 ---
     1| use crate::client::json;
     2| use crate::server::RequestExt;
     3| use crate::subreddit::{can_access_quarantine, quarantine};
     4| use crate::utils::{error, filter_posts, get_filters, nsfw_landing, parse_post, template, Post, Preferences};
     5| use hyper::{Body, Request, Response};
     6| use rinja::Template;
     7| use serde_json::Value;
     8| use std::borrow::ToOwned;
     9| use std::collections::HashSet;
    10| use std::vec::Vec;
    11| struct DuplicatesParams {
    12| 	before: String,
    13| 	after: String,
    14| 	sort: String,
    15| }
    16| #[derive(Template)]
    17| #[template(path = "duplicates.html")]
    18| struct DuplicatesTemplate {
    19| 	params: DuplicatesParams,
    20| 	post: Post,
    21| 	duplicates: Vec<Post>,
    22| 	prefs: Preferences,
    23| 	url: String,
    24| 	num_posts_filtered: u64,
    25| 	all_posts_filtered: bool,
    26| }
    27| pub async fn item(req: Request<Body>) -> Result<Response<Body>, String> {
    28| 	let path: String = format!("{}.json?{}&raw_json=1", req.uri().path(), req.uri().query().unwrap_or_default());
    29| 	let sub = req.param("sub").unwrap_or_default();
    30| 	let quarantined = can_access_quarantine(&req, &sub);
    31| 	#[cfg(debug_assertions)]
    32| 	req.param("id").unwrap_or_default();
    33| 	match json(path, quarantined).await {
    34| 		Ok(response) => {
    35| 			let post = parse_post(&response[0]["data"]["children"][0]).await;
    36| 			let req_url = req.uri().to_string();
    37| 			if post.nsfw && crate::utils::should_be_nsfw_gated(&req, &req_url) {
    38| 				return Ok(nsfw_landing(req, req_url).await.unwrap_or_default());
    39| 			}
    40| 			let filters = get_filters(&req);
    41| 			let (duplicates, num_posts_filtered, all_posts_filtered) = parse_duplicates(&response[1], &filters).await;
    42| 			let mut before: String = String::new();
    43| 			let mut after: String = String::new();
    44| 			let mut sort: String = String::new();
    45| 			let l = duplicates.len();
    46| 			if l > 0 {
    47| 				let mut have_before: bool = false;
    48| 				let mut have_after: bool = false;
    49| 				let query_str = req.uri().query().unwrap_or_default().to_string();
    50| 				if !query_str.is_empty() {
    51| 					for param in query_str.split('&') {
    52| 						let kv: Vec<&str> = param.split('=').collect();
    53| 						if kv.len() < 2 {
    54| 							continue;
    55| 						}
    56| 						let key: &str = kv[0];
    57| 						match key {
    58| 							"before" => have_before = true,
    59| 							"after" => have_after = true,
    60| 							"sort" => {
    61| 								let val: &str = kv[1];
    62| 								match val {
    63| 									"new" | "num_comments" => sort = val.to_string(),
    64| 									_ => {}
    65| 								}
    66| 							}
    67| 							_ => {}
    68| 						}
    69| 					}
    70| 				}
    71| 				if have_after {
    72| 					"t3_".clone_into(&mut before);
    73| 					before.push_str(&duplicates[0].id);
    74| 				}
    75| 				if have_before {
    76| 					"t3_".clone_into(&mut after);
    77| 					after.push_str(&duplicates[l - 1].id);
    78| 					let new_path: String = format!(
    79| 						"{}.json?before=t3_{}&sort={}&limit=1&raw_json=1",
    80| 						req.uri().path(),
    81| 						&duplicates[0].id,
    82| 						if sort.is_empty() { "num_comments".to_string() } else { sort.clone() }
    83| 					);
    84| 					match json(new_path, true).await {
    85| 						Ok(response) => {
    86| 							if !response[1]["data"]["children"].as_array().unwrap_or(&Vec::new()).is_empty() {
    87| 								"t3_".clone_into(&mut before);
    88| 								before.push_str(&duplicates[0].id);
    89| 							}
    90| 						}
    91| 						Err(msg) => {
    92| 							return error(req, &msg).await;
    93| 						}
    94| 					}
    95| 				} else {
    96| 					after = response[1]["data"]["after"].as_str().unwrap_or_default().to_string();
    97| 				}
    98| 			}
    99| 			Ok(template(&DuplicatesTemplate {
   100| 				params: DuplicatesParams { before, after, sort },
   101| 				post,
   102| 				duplicates,
   103| 				prefs: Preferences::new(&req),
   104| 				url: req_url,
   105| 				num_posts_filtered,
   106| 				all_posts_filtered,
   107| 			}))
   108| 		}
   109| 		Err(msg) => {
   110| 			if msg == "quarantined" || msg == "gated" {
   111| 				let sub = req.param("sub").unwrap_or_default();
   112| 				Ok(quarantine(&req, sub, &msg))
   113| 			} else {
   114| 				error(req, &msg).await
   115| 			}
   116| 		}
   117| 	}
   118| }
   119| async fn parse_duplicates(json: &Value, filters: &HashSet<String>) -> (Vec<Post>, u64, bool) {
   120| 	let post_duplicates: &Vec<Value> = &json["data"]["children"].as_array().map_or(Vec::new(), ToOwned::to_owned);
   121| 	let mut duplicates: Vec<Post> = Vec::new();
   122| 	for val in post_duplicates {
   123| 		let post: Post = parse_post(val).await;
   124| 		duplicates.push(post);
   125| 	}
   126| 	let (num_posts_filtered, all_posts_filtered) = filter_posts(&mut duplicates, filters);
   127| 	(duplicates, num_posts_filtered, all_posts_filtered)
   128| }


# ====================================================================
# FILE: src/instance_info.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-219 ---
     1| use crate::{
     2| 	config::{Config, CONFIG},
     3| 	server::RequestExt,
     4| 	utils::{ErrorTemplate, Preferences},
     5| };
     6| use build_html::{Container, Html, HtmlContainer, Table};
     7| use hyper::{http::Error, Body, Request, Response};
     8| use once_cell::sync::Lazy;
     9| use rinja::Template;
    10| use serde::{Deserialize, Serialize};
    11| use time::OffsetDateTime;
    12| pub static INSTANCE_INFO: Lazy<InstanceInfo> = Lazy::new(InstanceInfo::new);
    13| pub async fn instance_info(req: Request<Body>) -> Result<Response<Body>, String> {
    14| 	let extension = req.param("extension").unwrap_or_default();
    15| 	let response = match extension.as_str() {
    16| 		"yaml" | "yml" => info_yaml(),
    17| 		"txt" => info_txt(),
    18| 		"json" => info_json(),
    19| 		"html" | "" => info_html(&req),
    20| 		_ => {
    21| 			let error = ErrorTemplate {
    22| 				msg: "Error: Invalid info extension".into(),
    23| 				prefs: Preferences::new(&req),
    24| 				url: req.uri().to_string(),
    25| 			}
    26| 			.render()
    27| 			.unwrap();
    28| 			Response::builder().status(404).header("content-type", "text/html; charset=utf-8").body(error.into())
    29| 		}
    30| 	};
    31| 	response.map_err(|err| format!("{err}"))
    32| }
    33| fn info_json() -> Result<Response<Body>, Error> {
    34| 	if let Ok(body) = serde_json::to_string(&*INSTANCE_INFO) {
    35| 		Response::builder().status(200).header("content-type", "application/json").body(body.into())
    36| 	} else {
    37| 		Response::builder()
    38| 			.status(500)
    39| 			.header("content-type", "text/plain")
    40| 			.body(Body::from("Error serializing JSON"))
    41| 	}
    42| }
    43| fn info_yaml() -> Result<Response<Body>, Error> {
    44| 	if let Ok(body) = serde_yaml::to_string(&*INSTANCE_INFO) {
    45| 		Response::builder().status(200).header("content-type", "application/yaml").body(body.into())
    46| 	} else {
    47| 		Response::builder()
    48| 			.status(500)
    49| 			.header("content-type", "text/plain")
    50| 			.body(Body::from("Error serializing YAML."))
    51| 	}
    52| }
    53| fn info_txt() -> Result<Response<Body>, Error> {
    54| 	Response::builder()
    55| 		.status(200)
    56| 		.header("content-type", "text/plain")
    57| 		.body(Body::from(INSTANCE_INFO.to_string(&StringType::Raw)))
    58| }
    59| fn info_html(req: &Request<Body>) -> Result<Response<Body>, Error> {
    60| 	let message = MessageTemplate {
    61| 		title: String::from("Instance information"),
    62| 		body: INSTANCE_INFO.to_string(&StringType::Html),
    63| 		prefs: Preferences::new(req),
    64| 		url: req.uri().to_string(),
    65| 	}
    66| 	.render()
    67| 	.unwrap();
    68| 	Response::builder().status(200).header("content-type", "text/html; charset=utf8").body(Body::from(message))
    69| }
    70| #[derive(Serialize, Deserialize, Default)]
    71| pub struct InstanceInfo {
    72| 	package_name: String,
    73| 	crate_version: String,
    74| 	pub git_commit: String,
    75| 	deploy_date: String,
    76| 	compile_mode: String,
    77| 	deploy_unix_ts: i64,
    78| 	config: Config,
    79| }
    80| impl InstanceInfo {
    81| 	pub fn new() -> Self {
    82| 		Self {
    83| 			package_name: env!("CARGO_PKG_NAME").to_string(),
    84| 			crate_version: env!("CARGO_PKG_VERSION").to_string(),
    85| 			git_commit: env!("GIT_HASH").to_string(),
    86| 			deploy_date: OffsetDateTime::now_local().unwrap_or_else(|_| OffsetDateTime::now_utc()).to_string(),
    87| 			#[cfg(debug_assertions)]
    88| 			compile_mode: "Debug".into(),
    89| 			#[cfg(not(debug_assertions))]
    90| 			compile_mode: "Release".into(),
    91| 			deploy_unix_ts: OffsetDateTime::now_local().unwrap_or_else(|_| OffsetDateTime::now_utc()).unix_timestamp(),
    92| 			config: CONFIG.clone(),
    93| 		}
    94| 	}
    95| 	fn to_table(&self) -> String {
    96| 		let mut container = Container::default();
    97| 		let convert = |o: &Option<String>| -> String { o.clone().unwrap_or_else(|| "<span class=\"unset\"><i>Unset</i></span>".to_owned()) };
    98| 		if let Some(banner) = &self.config.banner {
    99| 			container.add_header(3, "Instance banner");
   100| 			container.add_raw("<br />");
   101| 			container.add_paragraph(banner);
   102| 			container.add_raw("<br />");
   103| 		}
   104| 		container.add_table(
   105| 			Table::from([
   106| 				["Package name", &self.package_name],
   107| 				["Crate version", &self.crate_version],
   108| 				["Git commit", &self.git_commit],
   109| 				["Deploy date", &self.deploy_date],
   110| 				["Deploy timestamp", &self.deploy_unix_ts.to_string()],
   111| 				["Compile mode", &self.compile_mode],
   112| 				["SFW only", &convert(&self.config.sfw_only)],
   113| 				["Pushshift frontend", &convert(&self.config.pushshift)],
   114| 				["RSS enabled", &convert(&self.config.enable_rss)],
   115| 				["Full URL", &convert(&self.config.full_url)],
   116| 				["Remove default feeds", &convert(&self.config.default_remove_default_feeds)],
   117| 			])
   118| 			.with_header_row(["Settings"]),
   119| 		);
   120| 		container.add_raw("<br />");
   121| 		container.add_table(
   122| 			Table::from([
   123| 				["Hide awards", &convert(&self.config.default_hide_awards)],
   124| 				["Hide score", &convert(&self.config.default_hide_score)],
   125| 				["Theme", &convert(&self.config.default_theme)],
   126| 				["Front page", &convert(&self.config.default_front_page)],
   127| 				["Layout", &convert(&self.config.default_layout)],
   128| 				["Wide", &convert(&self.config.default_wide)],
   129| 				["Comment sort", &convert(&self.config.default_comment_sort)],
   130| 				["Post sort", &convert(&self.config.default_post_sort)],
   131| 				["Blur Spoiler", &convert(&self.config.default_blur_spoiler)],
   132| 				["Show NSFW", &convert(&self.config.default_show_nsfw)],
   133| 				["Blur NSFW", &convert(&self.config.default_blur_nsfw)],
   134| 				["Use HLS", &convert(&self.config.default_use_hls)],
   135| 				["Hide HLS notification", &convert(&self.config.default_hide_hls_notification)],
   136| 				["Subscriptions", &convert(&self.config.default_subscriptions)],
   137| 				["Filters", &convert(&self.config.default_filters)],
   138| 			])
   139| 			.with_header_row(["Default preferences"]),
   140| 		);
   141| 		container.to_html_string().replace("<th>", "<th colspan=\"2\">")
   142| 	}
   143| 	fn to_string(&self, string_type: &StringType) -> String {
   144| 		match string_type {
   145| 			StringType::Raw => {
   146| 				format!(
   147| 					"Package name: {}\n
   148| 				Crate version: {}\n
   149|                 Git commit: {}\n
   150|                 Deploy date: {}\n
   151|                 Deploy timestamp: {}\n
   152|                 Compile mode: {}\n
   153| 				SFW only: {:?}\n
   154| 				Pushshift frontend: {:?}\n
   155| 				RSS enabled: {:?}\n
   156| 				Full URL: {:?}\n
   157| 				Remove default feeds: {:?}\n
   158|                 Config:\n
   159|                     Banner: {:?}\n
   160|                     Hide awards: {:?}\n
   161|                     Hide score: {:?}\n
   162|                     Default theme: {:?}\n
   163|                     Default front page: {:?}\n
   164|                     Default layout: {:?}\n
   165|                     Default wide: {:?}\n
   166|                     Default comment sort: {:?}\n
   167|                     Default post sort: {:?}\n
   168| 					Default blur Spoiler: {:?}\n
   169|                     Default show NSFW: {:?}\n
   170|                     Default blur NSFW: {:?}\n
   171|                     Default use HLS: {:?}\n
   172|                     Default hide HLS notification: {:?}\n
   173|                     Default subscriptions: {:?}\n
   174|                     Default filters: {:?}\n",
   175| 					self.package_name,
   176| 					self.crate_version,
   177| 					self.git_commit,
   178| 					self.deploy_date,
   179| 					self.deploy_unix_ts,
   180| 					self.compile_mode,
   181| 					self.config.sfw_only,
   182| 					self.config.enable_rss,
   183| 					self.config.full_url,
   184| 					self.config.default_remove_default_feeds,
   185| 					self.config.pushshift,
   186| 					self.config.banner,
   187| 					self.config.default_hide_awards,
   188| 					self.config.default_hide_score,
   189| 					self.config.default_theme,
   190| 					self.config.default_front_page,
   191| 					self.config.default_layout,
   192| 					self.config.default_wide,
   193| 					self.config.default_comment_sort,
   194| 					self.config.default_post_sort,
   195| 					self.config.default_blur_spoiler,
   196| 					self.config.default_show_nsfw,
   197| 					self.config.default_blur_nsfw,
   198| 					self.config.default_use_hls,
   199| 					self.config.default_hide_hls_notification,
   200| 					self.config.default_subscriptions,
   201| 					self.config.default_filters,
   202| 				)
   203| 			}
   204| 			StringType::Html => self.to_table(),
   205| 		}
   206| 	}
   207| }
   208| enum StringType {
   209| 	Raw,
   210| 	Html,
   211| }
   212| #[derive(Template)]
   213| #[template(path = "message.html")]
   214| struct MessageTemplate {
   215| 	title: String,
   216| 	body: String,
   217| 	prefs: Preferences,
   218| 	url: String,
   219| }


# ====================================================================
# FILE: src/lib.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-13 ---
     1| pub mod client;
     2| pub mod config;
     3| pub mod duplicates;
     4| pub mod instance_info;
     5| pub mod oauth;
     6| pub mod oauth_resources;
     7| pub mod post;
     8| pub mod search;
     9| pub mod server;
    10| pub mod settings;
    11| pub mod subreddit;
    12| pub mod user;
    13| pub mod utils;


# ====================================================================
# FILE: src/main.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-363 ---
     1| #![forbid(unsafe_code)]
     2| #![allow(clippy::cmp_owned)]
     3| use cached::proc_macro::cached;
     4| use clap::{Arg, ArgAction, Command};
     5| use std::str::FromStr;
     6| use futures_lite::FutureExt;
     7| use hyper::Uri;
     8| use hyper::{header::HeaderValue, Body, Request, Response};
     9| use log::{info, warn};
    10| use once_cell::sync::Lazy;
    11| use redlib::client::{canonical_path, proxy, rate_limit_check, CLIENT};
    12| use redlib::server::{self, RequestExt};
    13| use redlib::utils::{error, redirect, ThemeAssets};
    14| use redlib::{config, duplicates, headers, instance_info, post, search, settings, subreddit, user};
    15| use redlib::client::OAUTH_CLIENT;
    16| async fn pwa_logo() -> Result<Response<Body>, String> {
    17| 	Ok(
    18| 		Response::builder()
    19| 			.status(200)
    20| 			.header("content-type", "image/png")
    21| 			.body(include_bytes!("../static/logo.png").as_ref().into())
    22| 			.unwrap_or_default(),
    23| 	)
    24| }
    25| async fn iphone_logo() -> Result<Response<Body>, String> {
    26| 	Ok(
    27| 		Response::builder()
    28| 			.status(200)
    29| 			.header("content-type", "image/png")
    30| 			.body(include_bytes!("../static/apple-touch-icon.png").as_ref().into())
    31| 			.unwrap_or_default(),
    32| 	)
    33| }
    34| async fn favicon() -> Result<Response<Body>, String> {
    35| 	Ok(
    36| 		Response::builder()
    37| 			.status(200)
    38| 			.header("content-type", "image/vnd.microsoft.icon")
    39| 			.header("Cache-Control", "public, max-age=1209600, s-maxage=86400")
    40| 			.body(include_bytes!("../static/favicon.ico").as_ref().into())
    41| 			.unwrap_or_default(),
    42| 	)
    43| }
    44| async fn font() -> Result<Response<Body>, String> {
    45| 	Ok(
    46| 		Response::builder()
    47| 			.status(200)
    48| 			.header("content-type", "font/woff2")
    49| 			.header("Cache-Control", "public, max-age=1209600, s-maxage=86400")
    50| 			.body(include_bytes!("../static/Inter.var.woff2").as_ref().into())
    51| 			.unwrap_or_default(),
    52| 	)
    53| }
    54| async fn opensearch() -> Result<Response<Body>, String> {
    55| 	Ok(
    56| 		Response::builder()
    57| 			.status(200)
    58| 			.header("content-type", "application/opensearchdescription+xml")
    59| 			.header("Cache-Control", "public, max-age=1209600, s-maxage=86400")
    60| 			.body(include_bytes!("../static/opensearch.xml").as_ref().into())
    61| 			.unwrap_or_default(),
    62| 	)
    63| }
    64| async fn resource(body: &str, content_type: &str, cache: bool) -> Result<Response<Body>, String> {
    65| 	let mut res = Response::builder()
    66| 		.status(200)
    67| 		.header("content-type", content_type)
    68| 		.body(body.to_string().into())
    69| 		.unwrap_or_default();
    70| 	if cache {
    71| 		if let Ok(val) = HeaderValue::from_str("public, max-age=1209600, s-maxage=86400") {
    72| 			res.headers_mut().insert("Cache-Control", val);
    73| 		}
    74| 	}
    75| 	Ok(res)
    76| }
    77| async fn style() -> Result<Response<Body>, String> {
    78| 	let mut res = include_str!("../static/style.css").to_string();
    79| 	for file in ThemeAssets::iter() {
    80| 		res.push('\n');
    81| 		let theme = ThemeAssets::get(file.as_ref()).unwrap();
    82| 		res.push_str(std::str::from_utf8(theme.data.as_ref()).unwrap());
    83| 	}
    84| 	Ok(
    85| 		Response::builder()
    86| 			.status(200)
    87| 			.header("content-type", "text/css")
    88| 			.header("Cache-Control", "public, max-age=1209600, s-maxage=86400")
    89| 			.body(res.to_string().into())
    90| 			.unwrap_or_default(),
    91| 	)
    92| }
    93| #[tokio::main]
    94| async fn main() {
    95| 	_ = dotenvy::dotenv();
    96| 	pretty_env_logger::init();
    97| 	let matches = Command::new("Redlib")
    98| 		.version(env!("CARGO_PKG_VERSION"))
    99| 		.about("Private front-end for Reddit written in Rust ")
   100| 		.arg(Arg::new("ipv4-only").short('4').long("ipv4-only").help("Listen on IPv4 only").num_args(0))
   101| 		.arg(Arg::new("ipv6-only").short('6').long("ipv6-only").help("Listen on IPv6 only").num_args(0))
   102| 		.arg(
   103| 			Arg::new("redirect-https")
   104| 				.short('r')
   105| 				.long("redirect-https")
   106| 				.help("Redirect all HTTP requests to HTTPS (no longer functional)")
   107| 				.num_args(0),
   108| 		)
   109| 		.arg(
   110| 			Arg::new("address")
   111| 				.short('a')
   112| 				.long("address")
   113| 				.value_name("ADDRESS")
   114| 				.help("Sets address to listen on")
   115| 				.default_value("[::]")
   116| 				.num_args(1),
   117| 		)
   118| 		.arg(
   119| 			Arg::new("port")
   120| 				.short('p')
   121| 				.long("port")
   122| 				.value_name("PORT")
   123| 				.env("PORT")
   124| 				.help("Port to listen on")
   125| 				.default_value("8080")
   126| 				.action(ArgAction::Set)
   127| 				.num_args(1),
   128| 		)
   129| 		.arg(
   130| 			Arg::new("hsts")
   131| 				.short('H')
   132| 				.long("hsts")
   133| 				.value_name("EXPIRE_TIME")
   134| 				.help("HSTS header to tell browsers that this site should only be accessed over HTTPS")
   135| 				.default_value("604800")
   136| 				.num_args(1),
   137| 		)
   138| 		.get_matches();
   139| 	match rate_limit_check().await {
   140| 		Ok(()) => {
   141| 			info!("[] Rate limit check passed");
   142| 		}
   143| 		Err(e) => {
   144| 			let mut message = format!("Rate limit check failed: {}", e);
   145| 			message += "\nThis may cause issues with the rate limit.";
   146| 			message += "\nPlease report this error with the above information.";
   147| 			message += "\nhttps://github.com/redlib-org/redlib/issues/new?assignees=sigaloid&labels=bug&title=%F0%9F%90%9B+Bug+Report%3A+Rate+limit+mismatch";
   148| 			warn!("{}", message);
   149| 			eprintln!("{}", message);
   150| 		}
   151| 	}
   152| 	let address = matches.get_one::<String>("address").unwrap();
   153| 	let port = matches.get_one::<String>("port").unwrap();
   154| 	let hsts = matches.get_one("hsts").map(|m: &String| m.as_str());
   155| 	let ipv4_only = std::env::var("IPV4_ONLY").is_ok() || matches.get_flag("ipv4-only");
   156| 	let ipv6_only = std::env::var("IPV6_ONLY").is_ok() || matches.get_flag("ipv6-only");
   157| 	let listener = if ipv4_only {
   158| 		format!("0.0.0.0:{}", port)
   159| 	} else if ipv6_only {
   160| 		format!("[::]:{}", port)
   161| 	} else {
   162| 		[address, ":", port].concat()
   163| 	};
   164| 	println!("Starting Redlib...");
   165| 	let mut app = server::Server::new();
   166| 	info!("Evaluating config.");
   167| 	Lazy::force(&config::CONFIG);
   168| 	info!("Evaluating instance info.");
   169| 	Lazy::force(&instance_info::INSTANCE_INFO);
   170| 	info!("Creating OAUTH client.");
   171| 	Lazy::force(&OAUTH_CLIENT);
   172| 	app.default_headers = headers! {
   173| 		"Referrer-Policy" => "no-referrer",
   174| 		"X-Content-Type-Options" => "nosniff",
   175| 		"X-Frame-Options" => "DENY",
   176| 		"Content-Security-Policy" => "default-src 'none'; font-src 'self'; script-src 'self' blob:; manifest-src 'self'; media-src 'self' data: blob: about:; style-src 'self' 'unsafe-inline'; base-uri 'none'; img-src 'self' data:; form-action 'self'; frame-ancestors 'none'; connect-src 'self'; worker-src blob:;"
   177| 	};
   178| 	if let Some(expire_time) = hsts {
   179| 		if let Ok(val) = HeaderValue::from_str(&format!("max-age={expire_time}")) {
   180| 			app.default_headers.insert("Strict-Transport-Security", val);
   181| 		}
   182| 	}
   183| 	app.at("/style.css").get(|_| style().boxed());
   184| 	app
   185| 		.at("/manifest.json")
   186| 		.get(|_| resource(include_str!("../static/manifest.json"), "application/json", false).boxed());
   187| 	app.at("/robots.txt").get(|_| {
   188| 		resource(
   189| 			if match config::get_setting("REDLIB_ROBOTS_DISABLE_INDEXING") {
   190| 				Some(val) => val == "on",
   191| 				None => false,
   192| 			} {
   193| 				"User-agent: *\nDisallow: /"
   194| 			} else {
   195| 				"User-agent: *\nDisallow: /u/\nDisallow: /user/"
   196| 			},
   197| 			"text/plain",
   198| 			true,
   199| 		)
   200| 		.boxed()
   201| 	});
   202| 	app.at("/favicon.ico").get(|_| favicon().boxed());
   203| 	app.at("/logo.png").get(|_| pwa_logo().boxed());
   204| 	app.at("/Inter.var.woff2").get(|_| font().boxed());
   205| 	app.at("/touch-icon-iphone.png").get(|_| iphone_logo().boxed());
   206| 	app.at("/apple-touch-icon.png").get(|_| iphone_logo().boxed());
   207| 	app.at("/opensearch.xml").get(|_| opensearch().boxed());
   208| 	app
   209| 		.at("/playHLSVideo.js")
   210| 		.get(|_| resource(include_str!("../static/playHLSVideo.js"), "text/javascript", false).boxed());
   211| 	app
   212| 		.at("/hls.min.js")
   213| 		.get(|_| resource(include_str!("../static/hls.min.js"), "text/javascript", false).boxed());
   214| 	app
   215| 		.at("/highlighted.js")
   216| 		.get(|_| resource(include_str!("../static/highlighted.js"), "text/javascript", false).boxed());
   217| 	app
   218| 		.at("/check_update.js")
   219| 		.get(|_| resource(include_str!("../static/check_update.js"), "text/javascript", false).boxed());
   220| 	app.at("/copy.js").get(|_| resource(include_str!("../static/copy.js"), "text/javascript", false).boxed());
   221| 	app.at("/commits.atom").get(|_| async move { proxy_commit_info().await }.boxed());
   222| 	app.at("/instances.json").get(|_| async move { proxy_instances().await }.boxed());
   223| 	app.at("/vid/:id/:size").get(|r| proxy(r, "https://v.redd.it/{id}/DASH_{size}").boxed());
   224| 	app.at("/hls/:id/*path").get(|r| proxy(r, "https://v.redd.it/{id}/{path}").boxed());
   225| 	app.at("/img/*path").get(|r| proxy(r, "https://i.redd.it/{path}").boxed());
   226| 	app.at("/thumb/:point/:id").get(|r| proxy(r, "https://{point}.thumbs.redditmedia.com/{id}").boxed());
   227| 	app.at("/emoji/:id/:name").get(|r| proxy(r, "https://emoji.redditmedia.com/{id}/{name}").boxed());
   228| 	app
   229| 		.at("/emote/:subreddit_id/:filename")
   230| 		.get(|r| proxy(r, "https://reddit-econ-prod-assets-permanent.s3.amazonaws.com/asset-manager/{subreddit_id}/{filename}").boxed());
   231| 	app
   232| 		.at("/preview/:loc/award_images/:fullname/:id")
   233| 		.get(|r| proxy(r, "https://{loc}view.redd.it/award_images/{fullname}/{id}").boxed());
   234| 	app.at("/preview/:loc/:id").get(|r| proxy(r, "https://{loc}view.redd.it/{id}").boxed());
   235| 	app.at("/style/*path").get(|r| proxy(r, "https://styles.redditmedia.com/{path}").boxed());
   236| 	app.at("/static/*path").get(|r| proxy(r, "https://www.redditstatic.com/{path}").boxed());
   237| 	app
   238| 		.at("/u/:name")
   239| 		.get(|r| async move { Ok(redirect(&format!("/user/{}", r.param("name").unwrap_or_default()))) }.boxed());
   240| 	app.at("/u/:name/comments/:id/:title").get(|r| post::item(r).boxed());
   241| 	app.at("/u/:name/comments/:id/:title/:comment_id").get(|r| post::item(r).boxed());
   242| 	app.at("/user/[deleted]").get(|req| error(req, "User has deleted their account").boxed());
   243| 	app.at("/user/:name.rss").get(|r| user::rss(r).boxed());
   244| 	app.at("/user/:name").get(|r| user::profile(r).boxed());
   245| 	app.at("/user/:name/:listing").get(|r| user::profile(r).boxed());
   246| 	app.at("/user/:name/comments/:id").get(|r| post::item(r).boxed());
   247| 	app.at("/user/:name/comments/:id/:title").get(|r| post::item(r).boxed());
   248| 	app.at("/user/:name/comments/:id/:title/:comment_id").get(|r| post::item(r).boxed());
   249| 	app.at("/settings").get(|r| settings::get(r).boxed()).post(|r| settings::set(r).boxed());
   250| 	app.at("/settings/restore").get(|r| settings::restore(r).boxed());
   251| 	app.at("/settings/encoded-restore").post(|r| settings::encoded_restore(r).boxed());
   252| 	app.at("/settings/update").get(|r| settings::update(r).boxed());
   253| 	app.at("/r/:sub.rss").get(|r| subreddit::rss(r).boxed());
   254| 	app
   255| 		.at("/r/:sub")
   256| 		.get(|r| subreddit::community(r).boxed())
   257| 		.post(|r| subreddit::add_quarantine_exception(r).boxed());
   258| 	app
   259| 		.at("/r/u_:name")
   260| 		.get(|r| async move { Ok(redirect(&format!("/user/{}", r.param("name").unwrap_or_default()))) }.boxed());
   261| 	app.at("/r/:sub/subscribe").post(|r| subreddit::subscriptions_filters(r).boxed());
   262| 	app.at("/r/:sub/unsubscribe").post(|r| subreddit::subscriptions_filters(r).boxed());
   263| 	app.at("/r/:sub/filter").post(|r| subreddit::subscriptions_filters(r).boxed());
   264| 	app.at("/r/:sub/unfilter").post(|r| subreddit::subscriptions_filters(r).boxed());
   265| 	app.at("/r/:sub/comments/:id").get(|r| post::item(r).boxed());
   266| 	app.at("/r/:sub/comments/:id/:title").get(|r| post::item(r).boxed());
   267| 	app.at("/r/:sub/comments/:id/:title/:comment_id").get(|r| post::item(r).boxed());
   268| 	app.at("/comments/:id").get(|r| post::item(r).boxed());
   269| 	app.at("/comments/:id/comments").get(|r| post::item(r).boxed());
   270| 	app.at("/comments/:id/comments/:comment_id").get(|r| post::item(r).boxed());
   271| 	app.at("/comments/:id/:title").get(|r| post::item(r).boxed());
   272| 	app.at("/comments/:id/:title/:comment_id").get(|r| post::item(r).boxed());
   273| 	app.at("/r/:sub/duplicates/:id").get(|r| duplicates::item(r).boxed());
   274| 	app.at("/r/:sub/duplicates/:id/:title").get(|r| duplicates::item(r).boxed());
   275| 	app.at("/duplicates/:id").get(|r| duplicates::item(r).boxed());
   276| 	app.at("/duplicates/:id/:title").get(|r| duplicates::item(r).boxed());
   277| 	app.at("/r/:sub/search").get(|r| search::find(r).boxed());
   278| 	app
   279| 		.at("/r/:sub/w")
   280| 		.get(|r| async move { Ok(redirect(&format!("/r/{}/wiki", r.param("sub").unwrap_or_default()))) }.boxed());
   281| 	app
   282| 		.at("/r/:sub/w/*page")
   283| 		.get(|r| async move { Ok(redirect(&format!("/r/{}/wiki/{}", r.param("sub").unwrap_or_default(), r.param("wiki").unwrap_or_default()))) }.boxed());
   284| 	app.at("/r/:sub/wiki").get(|r| subreddit::wiki(r).boxed());
   285| 	app.at("/r/:sub/wiki/*page").get(|r| subreddit::wiki(r).boxed());
   286| 	app.at("/r/:sub/about/sidebar").get(|r| subreddit::sidebar(r).boxed());
   287| 	app.at("/r/:sub/:sort").get(|r| subreddit::community(r).boxed());
   288| 	app.at("/").get(|r| subreddit::community(r).boxed());
   289| 	app.at("/w").get(|_| async { Ok(redirect("/wiki")) }.boxed());
   290| 	app
   291| 		.at("/w/*page")
   292| 		.get(|r| async move { Ok(redirect(&format!("/wiki/{}", r.param("page").unwrap_or_default()))) }.boxed());
   293| 	app.at("/wiki").get(|r| subreddit::wiki(r).boxed());
   294| 	app.at("/wiki/*page").get(|r| subreddit::wiki(r).boxed());
   295| 	app.at("/search").get(|r| search::find(r).boxed());
   296| 	app.at("/about").get(|req| error(req, "About pages aren't added yet").boxed());
   297| 	app.at("/info").get(|r| instance_info::instance_info(r).boxed());
   298| 	app.at("/info.:extension").get(|r| instance_info::instance_info(r).boxed());
   299| 	app.at("/r/:sub/s/:id").get(|req: Request<Body>| {
   300| 		Box::pin(async move {
   301| 			let sub = req.param("sub").unwrap_or_default();
   302| 			match req.param("id").as_deref() {
   303| 				Some(id) if (8..12).contains(&id.len()) => match canonical_path(format!("/r/{sub}/s/{id}"), 3).await {
   304| 					Ok(Some(path)) => Ok(redirect(&path)),
   305| 					Ok(None) => error(req, "Post ID is invalid. It may point to a post on a community that has been banned.").await,
   306| 					Err(e) => error(req, &e).await,
   307| 				},
   308| 				_ => error(req, "Nothing here").await,
   309| 			}
   310| 		})
   311| 	});
   312| 	app.at("/:id").get(|req: Request<Body>| {
   313| 		Box::pin(async move {
   314| 			match req.param("id").as_deref() {
   315| 				Some("best" | "hot" | "new" | "top" | "rising" | "controversial") => subreddit::community(req).await,
   316| 				Some(id) if (5..8).contains(&id.len()) => match canonical_path(format!("/comments/{id}"), 3).await {
   317| 					Ok(path_opt) => match path_opt {
   318| 						Some(path) => Ok(redirect(&path)),
   319| 						None => error(req, "Post ID is invalid. It may point to a post on a community that has been banned.").await,
   320| 					},
   321| 					Err(e) => error(req, &e).await,
   322| 				},
   323| 				_ => error(req, "Nothing here").await,
   324| 			}
   325| 		})
   326| 	});
   327| 	app.at("/*").get(|req| error(req, "Nothing here").boxed());
   328| 	println!("Running Redlib v{} on {listener}!", env!("CARGO_PKG_VERSION"));
   329| 	let server = app.listen(&listener);
   330| 	if let Err(e) = server.await {
   331| 		eprintln!("Server error: {e}");
   332| 	}
   333| }
   334| pub async fn proxy_commit_info() -> Result<Response<Body>, String> {
   335| 	Ok(
   336| 		Response::builder()
   337| 			.status(200)
   338| 			.header("content-type", "application/atom+xml")
   339| 			.body(Body::from(fetch_commit_info().await))
   340| 			.unwrap_or_default(),
   341| 	)
   342| }
   343| #[cached(time = 600)]
   344| async fn fetch_commit_info() -> String {
   345| 	let uri = Uri::from_str("https://github.com/redlib-org/redlib/commits/main.atom").expect("Invalid URI");
   346| 	let resp: Body = CLIENT.get(uri).await.expect("Failed to request GitHub").into_body();
   347| 	hyper::body::to_bytes(resp).await.expect("Failed to read body").iter().copied().map(|x| x as char).collect()
   348| }
   349| pub async fn proxy_instances() -> Result<Response<Body>, String> {
   350| 	Ok(
   351| 		Response::builder()
   352| 			.status(200)
   353| 			.header("content-type", "application/json")
   354| 			.body(Body::from(fetch_instances().await))
   355| 			.unwrap_or_default(),
   356| 	)
   357| }
   358| #[cached(time = 600)]
   359| async fn fetch_instances() -> String {
   360| 	let uri = Uri::from_str("https://raw.githubusercontent.com/redlib-org/redlib-instances/refs/heads/main/instances.json").expect("Invalid URI");
   361| 	let resp: Body = CLIENT.get(uri).await.expect("Failed to request GitHub").into_body();
   362| 	hyper::body::to_bytes(resp).await.expect("Failed to read body").iter().copied().map(|x| x as char).collect()
   363| }


# ====================================================================
# FILE: src/oauth.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-174 ---
     1| use std::{collections::HashMap, sync::atomic::Ordering, time::Duration};
     2| use crate::{
     3| 	client::{CLIENT, OAUTH_CLIENT, OAUTH_IS_ROLLING_OVER, OAUTH_RATELIMIT_REMAINING},
     4| 	oauth_resources::ANDROID_APP_VERSION_LIST,
     5| };
     6| use base64::{engine::general_purpose, Engine as _};
     7| use hyper::{client, Body, Method, Request};
     8| use log::{error, info, trace};
     9| use serde_json::json;
    10| use tegen::tegen::TextGenerator;
    11| use tokio::time::{error::Elapsed, timeout};
    12| const REDDIT_ANDROID_OAUTH_CLIENT_ID: &str = "ohXpoqrZYub1kg";
    13| const AUTH_ENDPOINT: &str = "https://www.reddit.com";
    14| #[derive(Debug, Clone, Default)]
    15| pub struct Oauth {
    16| 	pub(crate) initial_headers: HashMap<String, String>,
    17| 	pub(crate) headers_map: HashMap<String, String>,
    18| 	pub(crate) token: String,
    19| 	expires_in: u64,
    20| 	device: Device,
    21| }
    22| impl Oauth {
    23| 	pub(crate) async fn new() -> Self {
    24| 		loop {
    25| 			let attempt = Self::new_with_timeout().await;
    26| 			match attempt {
    27| 				Ok(Some(oauth)) => {
    28| 					info!("[] Successfully created OAuth client");
    29| 					return oauth;
    30| 				}
    31| 				Ok(None) => {
    32| 					error!("Failed to create OAuth client. Retrying in 5 seconds...");
    33| 				}
    34| 				Err(duration) => {
    35| 					error!("Failed to create OAuth client in {duration:?}. Retrying in 5 seconds...");
    36| 				}
    37| 			}
    38| 			tokio::time::sleep(Duration::from_secs(5)).await;
    39| 		}
    40| 	}
    41| 	async fn new_with_timeout() -> Result<Option<Self>, Elapsed> {
    42| 		let mut oauth = Self::default();
    43| 		timeout(Duration::from_secs(5), oauth.login()).await.map(|result| result.map(|_| oauth))
    44| 	}
    45| 	pub(crate) fn default() -> Self {
    46| 		let device = Device::new();
    47| 		let headers_map = device.headers.clone();
    48| 		let initial_headers = device.initial_headers.clone();
    49| 		Self {
    50| 			headers_map,
    51| 			initial_headers,
    52| 			token: String::new(),
    53| 			expires_in: 0,
    54| 			device,
    55| 		}
    56| 	}
    57| 	async fn login(&mut self) -> Option<()> {
    58| 		let url = format!("{AUTH_ENDPOINT}/auth/v2/oauth/access-token/loid");
    59| 		let mut builder = Request::builder().method(Method::POST).uri(&url);
    60| 		for (key, value) in &self.initial_headers {
    61| 			builder = builder.header(key, value);
    62| 		}
    63| 		let auth = general_purpose::STANDARD.encode(format!("{}:", self.device.oauth_id));
    64| 		builder = builder.header("Authorization", format!("Basic {auth}"));
    65| 		let json = json!({
    66| 				"scopes": ["*","email", "pii"]
    67| 		});
    68| 		let body = Body::from(json.to_string());
    69| 		let request = builder.body(body).unwrap();
    70| 		trace!("Sending token request...\n\n{request:?}");
    71| 		let client: &once_cell::sync::Lazy<client::Client<_, Body>> = &CLIENT;
    72| 		let resp = client.request(request).await.ok()?;
    73| 		trace!("Received response with status {} and length {:?}", resp.status(), resp.headers().get("content-length"));
    74| 		trace!("OAuth headers: {:#?}", resp.headers());
    75| 		if let Some(header) = resp.headers().get("x-reddit-loid") {
    76| 			self.headers_map.insert("x-reddit-loid".to_owned(), header.to_str().ok()?.to_string());
    77| 		}
    78| 		if let Some(header) = resp.headers().get("x-reddit-session") {
    79| 			self.headers_map.insert("x-reddit-session".to_owned(), header.to_str().ok()?.to_string());
    80| 		}
    81| 		trace!("Serializing response...");
    82| 		let body_bytes = hyper::body::to_bytes(resp.into_body()).await.ok()?;
    83| 		let json: serde_json::Value = serde_json::from_slice(&body_bytes).ok()?;
    84| 		trace!("Accessing relevant fields...");
    85| 		self.token = json.get("access_token")?.as_str()?.to_string();
    86| 		self.expires_in = json.get("expires_in")?.as_u64()?;
    87| 		self.headers_map.insert("Authorization".to_owned(), format!("Bearer {}", self.token));
    88| 		info!("[] Success - Retrieved token \"{}...\", expires in {}", &self.token[..32], self.expires_in);
    89| 		Some(())
    90| 	}
    91| }
    92| pub async fn token_daemon() {
    93| 	loop {
    94| 		let expires_in = { OAUTH_CLIENT.load_full().expires_in };
    95| 		let duration = Duration::from_secs(expires_in - 120);
    96| 		info!("[] Waiting for {duration:?} seconds before refreshing OAuth token...");
    97| 		tokio::time::sleep(duration).await;
    98| 		info!("[] {duration:?} Elapsed! Refreshing OAuth token...");
    99| 		{
   100| 			force_refresh_token().await;
   101| 		}
   102| 	}
   103| }
   104| pub async fn force_refresh_token() {
   105| 	if OAUTH_IS_ROLLING_OVER.compare_exchange(false, true, Ordering::SeqCst, Ordering::SeqCst).is_err() {
   106| 		trace!("Skipping refresh token roll over, already in progress");
   107| 		return;
   108| 	}
   109| 	trace!("Rolling over refresh token. Current rate limit: {}", OAUTH_RATELIMIT_REMAINING.load(Ordering::SeqCst));
   110| 	let new_client = Oauth::new().await;
   111| 	OAUTH_CLIENT.swap(new_client.into());
   112| 	OAUTH_RATELIMIT_REMAINING.store(99, Ordering::SeqCst);
   113| 	OAUTH_IS_ROLLING_OVER.store(false, Ordering::SeqCst);
   114| }
   115| #[derive(Debug, Clone, Default)]
   116| struct Device {
   117| 	oauth_id: String,
   118| 	initial_headers: HashMap<String, String>,
   119| 	headers: HashMap<String, String>,
   120| }
   121| impl Device {
   122| 	fn android() -> Self {
   123| 		let uuid = uuid::Uuid::new_v4().to_string();
   124| 		let android_app_version = choose(ANDROID_APP_VERSION_LIST).to_string();
   125| 		let android_version = fastrand::u8(9..=14);
   126| 		let android_user_agent = format!("Reddit/{android_app_version}/Android {android_version}");
   127| 		let qos = fastrand::u32(1000..=100_000);
   128| 		let qos: f32 = qos as f32 / 1000.0;
   129| 		let qos = format!("{:.3}", qos);
   130| 		let codecs = TextGenerator::new().generate("available-codecs=video/avc, video/hevc{, video/x-vnd.on2.vp9|}");
   131| 		let headers: HashMap<String, String> = HashMap::from([
   132| 			("User-Agent".into(), android_user_agent),
   133| 			("x-reddit-retry".into(), "algo=no-retries".into()),
   134| 			("x-reddit-compression".into(), "1".into()),
   135| 			("x-reddit-qos".into(), qos),
   136| 			("x-reddit-media-codecs".into(), codecs),
   137| 			("Content-Type".into(), "application/json; charset=UTF-8".into()),
   138| 			("client-vendor-id".into(), uuid.clone()),
   139| 			("X-Reddit-Device-Id".into(), uuid.clone()),
   140| 		]);
   141| 		info!("[] Spoofing Android client with headers: {headers:?}, uuid: \"{uuid}\", and OAuth ID \"{REDDIT_ANDROID_OAUTH_CLIENT_ID}\"");
   142| 		Self {
   143| 			oauth_id: REDDIT_ANDROID_OAUTH_CLIENT_ID.to_string(),
   144| 			headers: headers.clone(),
   145| 			initial_headers: headers,
   146| 		}
   147| 	}
   148| 	fn new() -> Self {
   149| 		Self::android()
   150| 	}
   151| }
   152| fn choose<T: Copy>(list: &[T]) -> T {
   153| 	*fastrand::choose_multiple(list.iter(), 1)[0]
   154| }
   155| #[tokio::test(flavor = "multi_thread")]
   156| async fn test_oauth_client() {
   157| 	assert!(!OAUTH_CLIENT.load_full().token.is_empty());
   158| }
   159| #[tokio::test(flavor = "multi_thread")]
   160| async fn test_oauth_client_refresh() {
   161| 	force_refresh_token().await;
   162| }
   163| #[tokio::test(flavor = "multi_thread")]
   164| async fn test_oauth_token_exists() {
   165| 	assert!(!OAUTH_CLIENT.load_full().token.is_empty());
   166| }
   167| #[tokio::test(flavor = "multi_thread")]
   168| async fn test_oauth_headers_len() {
   169| 	assert!(OAUTH_CLIENT.load_full().headers_map.len() >= 3);
   170| }
   171| #[test]
   172| fn test_creating_device() {
   173| 	Device::new();
   174| }


# ====================================================================
# FILE: src/oauth_resources.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-154 ---
     1| pub const _IOS_APP_VERSION_LIST: &[&str; 1] = &[""];
     2| pub const ANDROID_APP_VERSION_LIST: &[&str; 150] = &[
     3| 	"Version 2024.22.1/Build 1652272",
     4| 	"Version 2024.23.1/Build 1665606",
     5| 	"Version 2024.24.1/Build 1682520",
     6| 	"Version 2024.25.0/Build 1693595",
     7| 	"Version 2024.25.2/Build 1700401",
     8| 	"Version 2024.25.3/Build 1703490",
     9| 	"Version 2024.26.0/Build 1710470",
    10| 	"Version 2024.26.1/Build 1717435",
    11| 	"Version 2024.28.0/Build 1737665",
    12| 	"Version 2024.28.1/Build 1741165",
    13| 	"Version 2024.30.0/Build 1770787",
    14| 	"Version 2024.31.0/Build 1786202",
    15| 	"Version 2024.32.0/Build 1809095",
    16| 	"Version 2024.32.1/Build 1813258",
    17| 	"Version 2024.33.0/Build 1819908",
    18| 	"Version 2024.34.0/Build 1837909",
    19| 	"Version 2024.35.0/Build 1861437",
    20| 	"Version 2024.36.0/Build 1875012",
    21| 	"Version 2024.37.0/Build 1888053",
    22| 	"Version 2024.38.0/Build 1902791",
    23| 	"Version 2024.39.0/Build 1916713",
    24| 	"Version 2024.40.0/Build 1928580",
    25| 	"Version 2024.41.0/Build 1941199",
    26| 	"Version 2024.41.1/Build 1947805",
    27| 	"Version 2024.42.0/Build 1952440",
    28| 	"Version 2024.43.0/Build 1972250",
    29| 	"Version 2024.44.0/Build 1988458",
    30| 	"Version 2024.45.0/Build 2001943",
    31| 	"Version 2024.46.0/Build 2012731",
    32| 	"Version 2024.47.0/Build 2029755",
    33| 	"Version 2023.48.0/Build 1319123",
    34| 	"Version 2023.49.0/Build 1321715",
    35| 	"Version 2023.49.1/Build 1322281",
    36| 	"Version 2023.50.0/Build 1332338",
    37| 	"Version 2023.50.1/Build 1345844",
    38| 	"Version 2024.02.0/Build 1368985",
    39| 	"Version 2024.03.0/Build 1379408",
    40| 	"Version 2024.04.0/Build 1391236",
    41| 	"Version 2024.05.0/Build 1403584",
    42| 	"Version 2024.06.0/Build 1418489",
    43| 	"Version 2024.07.0/Build 1429651",
    44| 	"Version 2024.08.0/Build 1439531",
    45| 	"Version 2024.10.0/Build 1470045",
    46| 	"Version 2024.10.1/Build 1478645",
    47| 	"Version 2024.11.0/Build 1480707",
    48| 	"Version 2024.12.0/Build 1494694",
    49| 	"Version 2024.13.0/Build 1505187",
    50| 	"Version 2024.14.0/Build 1520556",
    51| 	"Version 2024.15.0/Build 1536823",
    52| 	"Version 2024.16.0/Build 1551366",
    53| 	"Version 2024.17.0/Build 1568106",
    54| 	"Version 2024.18.0/Build 1577901",
    55| 	"Version 2024.18.1/Build 1585304",
    56| 	"Version 2024.19.0/Build 1593346",
    57| 	"Version 2024.20.0/Build 1612800",
    58| 	"Version 2024.20.1/Build 1615586",
    59| 	"Version 2024.20.2/Build 1624969",
    60| 	"Version 2024.20.3/Build 1624970",
    61| 	"Version 2024.21.0/Build 1631686",
    62| 	"Version 2024.22.0/Build 1645257",
    63| 	"Version 2023.21.0/Build 956283",
    64| 	"Version 2023.22.0/Build 968223",
    65| 	"Version 2023.23.0/Build 983896",
    66| 	"Version 2023.24.0/Build 998541",
    67| 	"Version 2023.25.0/Build 1014750",
    68| 	"Version 2023.25.1/Build 1018737",
    69| 	"Version 2023.26.0/Build 1019073",
    70| 	"Version 2023.27.0/Build 1031923",
    71| 	"Version 2023.28.0/Build 1046887",
    72| 	"Version 2023.29.0/Build 1059855",
    73| 	"Version 2023.30.0/Build 1078734",
    74| 	"Version 2023.31.0/Build 1091027",
    75| 	"Version 2023.32.0/Build 1109919",
    76| 	"Version 2023.32.1/Build 1114141",
    77| 	"Version 2023.33.1/Build 1129741",
    78| 	"Version 2023.34.0/Build 1144243",
    79| 	"Version 2023.35.0/Build 1157967",
    80| 	"Version 2023.36.0/Build 1168982",
    81| 	"Version 2023.37.0/Build 1182743",
    82| 	"Version 2023.38.0/Build 1198522",
    83| 	"Version 2023.39.0/Build 1211607",
    84| 	"Version 2023.39.1/Build 1221505",
    85| 	"Version 2023.40.0/Build 1221521",
    86| 	"Version 2023.41.0/Build 1233125",
    87| 	"Version 2023.41.1/Build 1239615",
    88| 	"Version 2023.42.0/Build 1245088",
    89| 	"Version 2023.43.0/Build 1257426",
    90| 	"Version 2023.44.0/Build 1268622",
    91| 	"Version 2023.45.0/Build 1281371",
    92| 	"Version 2023.47.0/Build 1303604",
    93| 	"Version 2022.42.0/Build 638508",
    94| 	"Version 2022.43.0/Build 648277",
    95| 	"Version 2022.44.0/Build 664348",
    96| 	"Version 2022.45.0/Build 677985",
    97| 	"Version 2023.01.0/Build 709875",
    98| 	"Version 2023.02.0/Build 717912",
    99| 	"Version 2023.03.0/Build 729220",
   100| 	"Version 2023.04.0/Build 744681",
   101| 	"Version 2023.05.0/Build 755453",
   102| 	"Version 2023.06.0/Build 775017",
   103| 	"Version 2023.07.0/Build 788827",
   104| 	"Version 2023.07.1/Build 790267",
   105| 	"Version 2023.08.0/Build 798718",
   106| 	"Version 2023.09.0/Build 812015",
   107| 	"Version 2023.09.1/Build 816833",
   108| 	"Version 2023.10.0/Build 821148",
   109| 	"Version 2023.11.0/Build 830610",
   110| 	"Version 2023.12.0/Build 841150",
   111| 	"Version 2023.13.0/Build 852246",
   112| 	"Version 2023.14.0/Build 861593",
   113| 	"Version 2023.14.1/Build 864826",
   114| 	"Version 2023.15.0/Build 870628",
   115| 	"Version 2023.16.0/Build 883294",
   116| 	"Version 2023.16.1/Build 886269",
   117| 	"Version 2023.17.0/Build 896030",
   118| 	"Version 2023.17.1/Build 900542",
   119| 	"Version 2023.18.0/Build 911877",
   120| 	"Version 2023.19.0/Build 927681",
   121| 	"Version 2023.20.0/Build 943980",
   122| 	"Version 2023.20.1/Build 946732",
   123| 	"Version 2022.20.0/Build 487703",
   124| 	"Version 2022.21.0/Build 492436",
   125| 	"Version 2022.22.0/Build 498700",
   126| 	"Version 2022.23.0/Build 502374",
   127| 	"Version 2022.23.1/Build 506606",
   128| 	"Version 2022.24.0/Build 510950",
   129| 	"Version 2022.24.1/Build 513462",
   130| 	"Version 2022.25.0/Build 515072",
   131| 	"Version 2022.25.1/Build 516394",
   132| 	"Version 2022.25.2/Build 519915",
   133| 	"Version 2022.26.0/Build 521193",
   134| 	"Version 2022.27.0/Build 527406",
   135| 	"Version 2022.27.1/Build 529687",
   136| 	"Version 2022.28.0/Build 533235",
   137| 	"Version 2022.30.0/Build 548620",
   138| 	"Version 2022.31.0/Build 556666",
   139| 	"Version 2022.31.1/Build 562612",
   140| 	"Version 2022.32.0/Build 567875",
   141| 	"Version 2022.33.0/Build 572600",
   142| 	"Version 2022.34.0/Build 579352",
   143| 	"Version 2022.35.0/Build 588016",
   144| 	"Version 2022.35.1/Build 589034",
   145| 	"Version 2022.36.0/Build 593102",
   146| 	"Version 2022.37.0/Build 601691",
   147| 	"Version 2022.38.0/Build 607460",
   148| 	"Version 2022.39.0/Build 615385",
   149| 	"Version 2022.39.1/Build 619019",
   150| 	"Version 2022.40.0/Build 624782",
   151| 	"Version 2022.41.0/Build 630468",
   152| 	"Version 2022.41.1/Build 634168",
   153| ];
   154| pub const _IOS_OS_VERSION_LIST: &[&str; 1] = &[""];


# ====================================================================
# FILE: src/post.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-195 ---
     1| #![allow(clippy::cmp_owned)]
     2| use crate::client::json;
     3| use crate::config::get_setting;
     4| use crate::server::RequestExt;
     5| use crate::subreddit::{can_access_quarantine, quarantine};
     6| use crate::utils::{
     7| 	error, format_num, get_filters, nsfw_landing, param, parse_post, rewrite_emotes, setting, template, time, val, Author, Awards, Comment, Flair, FlairPart, Post, Preferences,
     8| };
     9| use hyper::{Body, Request, Response};
    10| use once_cell::sync::Lazy;
    11| use regex::Regex;
    12| use rinja::Template;
    13| use std::collections::{HashMap, HashSet};
    14| #[derive(Template)]
    15| #[template(path = "post.html")]
    16| struct PostTemplate {
    17| 	comments: Vec<Comment>,
    18| 	post: Post,
    19| 	sort: String,
    20| 	prefs: Preferences,
    21| 	single_thread: bool,
    22| 	url: String,
    23| 	url_without_query: String,
    24| 	comment_query: String,
    25| }
    26| static COMMENT_SEARCH_CAPTURE: Lazy<Regex> = Lazy::new(|| Regex::new(r"\?q=(.*)&type=comment").unwrap());
    27| pub async fn item(req: Request<Body>) -> Result<Response<Body>, String> {
    28| 	let mut path: String = format!("{}.json?{}&raw_json=1", req.uri().path(), req.uri().query().unwrap_or_default());
    29| 	let sub = req.param("sub").unwrap_or_default();
    30| 	let quarantined = can_access_quarantine(&req, &sub);
    31| 	let url = req.uri().to_string();
    32| 	let sort = param(&path, "sort").unwrap_or_else(|| {
    33| 		let default_sort = setting(&req, "comment_sort");
    34| 		if default_sort.is_empty() {
    35| 			String::new()
    36| 		} else {
    37| 			path = format!("{}.json?{}&sort={}&raw_json=1", req.uri().path(), req.uri().query().unwrap_or_default(), default_sort);
    38| 			default_sort
    39| 		}
    40| 	});
    41| 	#[cfg(debug_assertions)]
    42| 	req.param("id").unwrap_or_default();
    43| 	let single_thread = req.param("comment_id").is_some();
    44| 	let highlighted_comment = &req.param("comment_id").unwrap_or_default();
    45| 	match json(path, quarantined).await {
    46| 		Ok(response) => {
    47| 			let post = parse_post(&response[0]["data"]["children"][0]).await;
    48| 			let req_url = req.uri().to_string();
    49| 			if post.nsfw && crate::utils::should_be_nsfw_gated(&req, &req_url) {
    50| 				return Ok(nsfw_landing(req, req_url).await.unwrap_or_default());
    51| 			}
    52| 			let query_body = match COMMENT_SEARCH_CAPTURE.captures(&url) {
    53| 				Some(captures) => captures.get(1).unwrap().as_str().replace("%20", " ").replace('+', " "),
    54| 				None => String::new(),
    55| 			};
    56| 			let query_string = format!("q={query_body}&type=comment");
    57| 			let form = url::form_urlencoded::parse(query_string.as_bytes()).collect::<HashMap<_, _>>();
    58| 			let query = form.get("q").unwrap().clone().to_string();
    59| 			let comments = match query.as_str() {
    60| 				"" => parse_comments(&response[1], &post.permalink, &post.author.name, highlighted_comment, &get_filters(&req), &req),
    61| 				_ => query_comments(&response[1], &post.permalink, &post.author.name, highlighted_comment, &get_filters(&req), &query, &req),
    62| 			};
    63| 			Ok(template(&PostTemplate {
    64| 				comments,
    65| 				post,
    66| 				url_without_query: url.clone().trim_end_matches(&format!("?q={query}&type=comment")).to_string(),
    67| 				sort,
    68| 				prefs: Preferences::new(&req),
    69| 				single_thread,
    70| 				url: req_url,
    71| 				comment_query: query,
    72| 			}))
    73| 		}
    74| 		Err(msg) => {
    75| 			if msg == "quarantined" || msg == "gated" {
    76| 				let sub = req.param("sub").unwrap_or_default();
    77| 				Ok(quarantine(&req, sub, &msg))
    78| 			} else {
    79| 				error(req, &msg).await
    80| 			}
    81| 		}
    82| 	}
    83| }
    84| fn parse_comments(json: &serde_json::Value, post_link: &str, post_author: &str, highlighted_comment: &str, filters: &HashSet<String>, req: &Request<Body>) -> Vec<Comment> {
    85| 	let comments = json["data"]["children"].as_array().map_or(Vec::new(), std::borrow::ToOwned::to_owned);
    86| 	comments
    87| 		.into_iter()
    88| 		.map(|comment| {
    89| 			let data = &comment["data"];
    90| 			let replies: Vec<Comment> = if data["replies"].is_object() {
    91| 				parse_comments(&data["replies"], post_link, post_author, highlighted_comment, filters, req)
    92| 			} else {
    93| 				Vec::new()
    94| 			};
    95| 			build_comment(&comment, data, replies, post_link, post_author, highlighted_comment, filters, req)
    96| 		})
    97| 		.collect()
    98| }
    99| fn query_comments(
   100| 	json: &serde_json::Value,
   101| 	post_link: &str,
   102| 	post_author: &str,
   103| 	highlighted_comment: &str,
   104| 	filters: &HashSet<String>,
   105| 	query: &str,
   106| 	req: &Request<Body>,
   107| ) -> Vec<Comment> {
   108| 	let comments = json["data"]["children"].as_array().map_or(Vec::new(), std::borrow::ToOwned::to_owned);
   109| 	let mut results = Vec::new();
   110| 	for comment in comments {
   111| 		let data = &comment["data"];
   112| 		if data["replies"].is_object() {
   113| 			results.append(&mut query_comments(&data["replies"], post_link, post_author, highlighted_comment, filters, query, req));
   114| 		}
   115| 		let c = build_comment(&comment, data, Vec::new(), post_link, post_author, highlighted_comment, filters, req);
   116| 		if c.body.to_lowercase().contains(&query.to_lowercase()) {
   117| 			results.push(c);
   118| 		}
   119| 	}
   120| 	results
   121| }
   122| #[allow(clippy::too_many_arguments)]
   123| fn build_comment(
   124| 	comment: &serde_json::Value,
   125| 	data: &serde_json::Value,
   126| 	replies: Vec<Comment>,
   127| 	post_link: &str,
   128| 	post_author: &str,
   129| 	highlighted_comment: &str,
   130| 	filters: &HashSet<String>,
   131| 	req: &Request<Body>,
   132| ) -> Comment {
   133| 	let id = val(comment, "id");
   134| 	let body = if (val(comment, "author") == "[deleted]" && val(comment, "body") == "[removed]") || val(comment, "body") == "[ Removed by Reddit ]" {
   135| 		format!(
   136| 			"<div class=\"md\"><p>[removed]  <a href=\"https://{}{post_link}{id}\">view removed comment</a></p></div>",
   137| 			get_setting("REDLIB_PUSHSHIFT_FRONTEND").unwrap_or_else(|| String::from(crate::config::DEFAULT_PUSHSHIFT_FRONTEND)),
   138| 		)
   139| 	} else {
   140| 		rewrite_emotes(&data["media_metadata"], val(comment, "body_html"))
   141| 	};
   142| 	let kind = comment["kind"].as_str().unwrap_or_default().to_string();
   143| 	let unix_time = data["created_utc"].as_f64().unwrap_or_default();
   144| 	let (rel_time, created) = time(unix_time);
   145| 	let edited = data["edited"].as_f64().map_or((String::new(), String::new()), time);
   146| 	let score = data["score"].as_i64().unwrap_or(0);
   147| 	let more_count = data["count"].as_i64().unwrap_or_default();
   148| 	let awards: Awards = Awards::parse(&data["all_awardings"]);
   149| 	let parent_kind_and_id = val(comment, "parent_id");
   150| 	let parent_info = parent_kind_and_id.split('_').collect::<Vec<&str>>();
   151| 	let highlighted = id == highlighted_comment;
   152| 	let author = Author {
   153| 		name: val(comment, "author"),
   154| 		flair: Flair {
   155| 			flair_parts: FlairPart::parse(
   156| 				data["author_flair_type"].as_str().unwrap_or_default(),
   157| 				data["author_flair_richtext"].as_array(),
   158| 				data["author_flair_text"].as_str(),
   159| 			),
   160| 			text: val(comment, "link_flair_text"),
   161| 			background_color: val(comment, "author_flair_background_color"),
   162| 			foreground_color: val(comment, "author_flair_text_color"),
   163| 		},
   164| 		distinguished: val(comment, "distinguished"),
   165| 	};
   166| 	let is_filtered = filters.contains(&["u_", author.name.as_str()].concat());
   167| 	let is_moderator_comment = data["distinguished"].as_str().unwrap_or_default() == "moderator";
   168| 	let is_stickied = data["stickied"].as_bool().unwrap_or_default();
   169| 	let collapsed = (is_moderator_comment && is_stickied) || is_filtered;
   170| 	Comment {
   171| 		id,
   172| 		kind,
   173| 		parent_id: parent_info[1].to_string(),
   174| 		parent_kind: parent_info[0].to_string(),
   175| 		post_link: post_link.to_string(),
   176| 		post_author: post_author.to_string(),
   177| 		body,
   178| 		author,
   179| 		score: if data["score_hidden"].as_bool().unwrap_or_default() {
   180| 			("\u{2022}".to_string(), "Hidden".to_string())
   181| 		} else {
   182| 			format_num(score)
   183| 		},
   184| 		rel_time,
   185| 		created,
   186| 		edited,
   187| 		replies,
   188| 		highlighted,
   189| 		awards,
   190| 		collapsed,
   191| 		is_filtered,
   192| 		more_count,
   193| 		prefs: Preferences::new(req),
   194| 	}
   195| }


# ====================================================================
# FILE: src/search.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-159 ---
     1| #![allow(clippy::cmp_owned)]
     2| use crate::utils::{self, catch_random, error, filter_posts, format_num, format_url, get_filters, param, redirect, setting, template, val, Post, Preferences};
     3| use crate::{
     4| 	client::json,
     5| 	server::RequestExt,
     6| 	subreddit::{can_access_quarantine, quarantine},
     7| };
     8| use hyper::{Body, Request, Response};
     9| use once_cell::sync::Lazy;
    10| use regex::Regex;
    11| use rinja::Template;
    12| struct SearchParams {
    13| 	q: String,
    14| 	sort: String,
    15| 	t: String,
    16| 	before: String,
    17| 	after: String,
    18| 	restrict_sr: String,
    19| 	typed: String,
    20| }
    21| struct Subreddit {
    22| 	name: String,
    23| 	url: String,
    24| 	icon: String,
    25| 	description: String,
    26| 	subscribers: (String, String),
    27| }
    28| #[derive(Template)]
    29| #[template(path = "search.html")]
    30| struct SearchTemplate {
    31| 	posts: Vec<Post>,
    32| 	subreddits: Vec<Subreddit>,
    33| 	sub: String,
    34| 	params: SearchParams,
    35| 	prefs: Preferences,
    36| 	url: String,
    37| 	is_filtered: bool,
    38| 	all_posts_filtered: bool,
    39| 	all_posts_hidden_nsfw: bool,
    40| 	no_posts: bool,
    41| }
    42| static REDDIT_URL_MATCH: Lazy<Regex> = Lazy::new(|| Regex::new(r"^https?://([^\./]+\.)*reddit.com/").unwrap());
    43| pub async fn find(req: Request<Body>) -> Result<Response<Body>, String> {
    44| 	let nsfw_results = if setting(&req, "show_nsfw") == "on" && !utils::sfw_only() {
    45| 		"&include_over_18=on"
    46| 	} else {
    47| 		""
    48| 	};
    49| 	let uri_path = req.uri().path().replace("+", "%2B");
    50| 	let path = format!("{}.json?{}{}&raw_json=1", uri_path, req.uri().query().unwrap_or_default(), nsfw_results);
    51| 	let mut query = param(&path, "q").unwrap_or_default();
    52| 	query = REDDIT_URL_MATCH.replace(&query, "").to_string();
    53| 	if query.is_empty() {
    54| 		return Ok(redirect("/"));
    55| 	}
    56| 	if query.starts_with("r/") || query.starts_with("user/") {
    57| 		return Ok(redirect(&format!("/{query}")));
    58| 	}
    59| 	if query.starts_with("R/") {
    60| 		return Ok(redirect(&format!("/r{}", &query[1..])));
    61| 	}
    62| 	if query.starts_with("u/") || query.starts_with("U/") {
    63| 		return Ok(redirect(&format!("/user{}", &query[1..])));
    64| 	}
    65| 	let sub = req.param("sub").unwrap_or_default();
    66| 	let quarantined = can_access_quarantine(&req, &sub);
    67| 	if let Ok(random) = catch_random(&sub, "/find").await {
    68| 		return Ok(random);
    69| 	}
    70| 	let typed = param(&path, "type").unwrap_or_default();
    71| 	let sort = param(&path, "sort").unwrap_or_else(|| "relevance".to_string());
    72| 	let filters = get_filters(&req);
    73| 	let subreddits = if param(&path, "restrict_sr").is_none() {
    74| 		let mut subreddits = search_subreddits(&query, &typed).await;
    75| 		subreddits.retain(|s| !filters.contains(s.name.as_str()));
    76| 		subreddits
    77| 	} else {
    78| 		Vec::new()
    79| 	};
    80| 	let url = String::from(req.uri().path_and_query().map_or("", |val| val.as_str()));
    81| 	if sub.split('+').all(|s| filters.contains(s)) {
    82| 		Ok(template(&SearchTemplate {
    83| 			posts: Vec::new(),
    84| 			subreddits,
    85| 			sub,
    86| 			params: SearchParams {
    87| 				q: query.replace('"', "&quot;"),
    88| 				sort,
    89| 				t: param(&path, "t").unwrap_or_default(),
    90| 				before: param(&path, "after").unwrap_or_default(),
    91| 				after: String::new(),
    92| 				restrict_sr: param(&path, "restrict_sr").unwrap_or_default(),
    93| 				typed,
    94| 			},
    95| 			prefs: Preferences::new(&req),
    96| 			url,
    97| 			is_filtered: true,
    98| 			all_posts_filtered: false,
    99| 			all_posts_hidden_nsfw: false,
   100| 			no_posts: false,
   101| 		}))
   102| 	} else {
   103| 		match Post::fetch(&path, quarantined).await {
   104| 			Ok((mut posts, after)) => {
   105| 				let (_, all_posts_filtered) = filter_posts(&mut posts, &filters);
   106| 				let no_posts = posts.is_empty();
   107| 				let all_posts_hidden_nsfw = !no_posts && (posts.iter().all(|p| p.flags.nsfw) && setting(&req, "show_nsfw") != "on");
   108| 				Ok(template(&SearchTemplate {
   109| 					posts,
   110| 					subreddits,
   111| 					sub,
   112| 					params: SearchParams {
   113| 						q: query.replace('"', "&quot;"),
   114| 						sort,
   115| 						t: param(&path, "t").unwrap_or_default(),
   116| 						before: param(&path, "after").unwrap_or_default(),
   117| 						after,
   118| 						restrict_sr: param(&path, "restrict_sr").unwrap_or_default(),
   119| 						typed,
   120| 					},
   121| 					prefs: Preferences::new(&req),
   122| 					url,
   123| 					is_filtered: false,
   124| 					all_posts_filtered,
   125| 					all_posts_hidden_nsfw,
   126| 					no_posts,
   127| 				}))
   128| 			}
   129| 			Err(msg) => {
   130| 				if msg == "quarantined" || msg == "gated" {
   131| 					let sub = req.param("sub").unwrap_or_default();
   132| 					Ok(quarantine(&req, sub, &msg))
   133| 				} else {
   134| 					error(req, &msg).await
   135| 				}
   136| 			}
   137| 		}
   138| 	}
   139| }
   140| async fn search_subreddits(q: &str, typed: &str) -> Vec<Subreddit> {
   141| 	let limit = if typed == "sr_user" { "50" } else { "3" };
   142| 	let subreddit_search_path = format!("/subreddits/search.json?q={}&limit={limit}", q.replace(' ', "+"));
   143| 	json(subreddit_search_path, false).await.unwrap_or_default()["data"]["children"]
   144| 		.as_array()
   145| 		.map(ToOwned::to_owned)
   146| 		.unwrap_or_default()
   147| 		.iter()
   148| 		.map(|subreddit| {
   149| 			let icon = subreddit["data"]["community_icon"].as_str().map_or_else(|| val(subreddit, "icon_img"), ToString::to_string);
   150| 			Subreddit {
   151| 				name: val(subreddit, "display_name"),
   152| 				url: val(subreddit, "url"),
   153| 				icon: format_url(&icon),
   154| 				description: val(subreddit, "public_description"),
   155| 				subscribers: format_num(subreddit["data"]["subscribers"].as_f64().unwrap_or_default() as i64),
   156| 			}
   157| 		})
   158| 		.collect::<Vec<Subreddit>>()
   159| }


# ====================================================================
# FILE: src/server.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-493 ---
     1| #![allow(dead_code)]
     2| #![allow(clippy::cmp_owned)]
     3| use brotli::enc::{BrotliCompress, BrotliEncoderParams};
     4| use cached::proc_macro::cached;
     5| use cookie::Cookie;
     6| use core::f64;
     7| use futures_lite::{future::Boxed, Future, FutureExt};
     8| use hyper::{
     9| 	body,
    10| 	body::HttpBody,
    11| 	header,
    12| 	service::{make_service_fn, service_fn},
    13| 	HeaderMap,
    14| };
    15| use hyper::{Body, Method, Request, Response, Server as HyperServer};
    16| use libflate::gzip;
    17| use route_recognizer::{Params, Router};
    18| use std::{
    19| 	cmp::Ordering,
    20| 	fmt::Display,
    21| 	io,
    22| 	pin::Pin,
    23| 	result::Result,
    24| 	str::{from_utf8, Split},
    25| 	string::ToString,
    26| };
    27| use time::OffsetDateTime;
    28| use crate::dbg_msg;
    29| type BoxResponse = Pin<Box<dyn Future<Output = Result<Response<Body>, String>> + Send>>;
    30| #[derive(Copy, Clone, Debug, Eq, Hash, Ord, PartialEq, PartialOrd)]
    31| enum CompressionType {
    32| 	Passthrough,
    33| 	Gzip,
    34| 	Brotli,
    35| }
    36| const DEFAULT_COMPRESSOR: CompressionType = CompressionType::Gzip;
    37| impl CompressionType {
    38| 	fn parse(s: &str) -> Option<Self> {
    39| 		let c = match s {
    40| 			"gzip" => Self::Gzip,
    41| 			"br" => Self::Brotli,
    42| 			"*" => DEFAULT_COMPRESSOR,
    43| 			_ => return None,
    44| 		};
    45| 		Some(c)
    46| 	}
    47| }
    48| impl Display for CompressionType {
    49| 	fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
    50| 		match self {
    51| 			Self::Gzip => write!(f, "gzip"),
    52| 			Self::Brotli => write!(f, "br"),
    53| 			Self::Passthrough => Ok(()),
    54| 		}
    55| 	}
    56| }
    57| pub struct Route<'a> {
    58| 	router: &'a mut Router<fn(Request<Body>) -> BoxResponse>,
    59| 	path: String,
    60| }
    61| pub struct Server {
    62| 	pub default_headers: HeaderMap,
    63| 	router: Router<fn(Request<Body>) -> BoxResponse>,
    64| }
    65| #[macro_export]
    66| macro_rules! headers(
    67| 	{ $($key:expr => $value:expr),+ } => {
    68| 		{
    69| 			let mut m = hyper::HeaderMap::new();
    70| 			$(
    71| 				if let Ok(val) = hyper::header::HeaderValue::from_str($value) {
    72| 					m.insert($key, val);
    73| 				}
    74| 			)+
    75| 			m
    76| 		}
    77| 	 };
    78| );
    79| pub trait RequestExt {
    80| 	fn params(&self) -> Params;
    81| 	fn param(&self, name: &str) -> Option<String>;
    82| 	fn set_params(&mut self, params: Params) -> Option<Params>;
    83| 	fn cookies(&self) -> Vec<Cookie<'_>>;
    84| 	fn cookie(&self, name: &str) -> Option<Cookie<'_>>;
    85| }
    86| pub trait ResponseExt {
    87| 	fn cookies(&self) -> Vec<Cookie<'_>>;
    88| 	fn insert_cookie(&mut self, cookie: Cookie<'_>);
    89| 	fn remove_cookie(&mut self, name: String);
    90| }
    91| impl RequestExt for Request<Body> {
    92| 	fn params(&self) -> Params {
    93| 		self.extensions().get::<Params>().unwrap_or(&Params::new()).clone()
    94| 	}
    95| 	fn param(&self, name: &str) -> Option<String> {
    96| 		self.params().find(name).map(std::borrow::ToOwned::to_owned)
    97| 	}
    98| 	fn set_params(&mut self, params: Params) -> Option<Params> {
    99| 		self.extensions_mut().insert(params)
   100| 	}
   101| 	fn cookies(&self) -> Vec<Cookie<'_>> {
   102| 		self.headers().get("Cookie").map_or(Vec::new(), |header| {
   103| 			header
   104| 				.to_str()
   105| 				.unwrap_or_default()
   106| 				.split("; ")
   107| 				.map(|cookie| Cookie::parse(cookie).unwrap_or_else(|_| Cookie::from("")))
   108| 				.collect()
   109| 		})
   110| 	}
   111| 	fn cookie(&self, name: &str) -> Option<Cookie<'_>> {
   112| 		self.cookies().into_iter().find(|c| c.name() == name)
   113| 	}
   114| }
   115| impl ResponseExt for Response<Body> {
   116| 	fn cookies(&self) -> Vec<Cookie<'_>> {
   117| 		self.headers().get("Cookie").map_or(Vec::new(), |header| {
   118| 			header
   119| 				.to_str()
   120| 				.unwrap_or_default()
   121| 				.split("; ")
   122| 				.map(|cookie| Cookie::parse(cookie).unwrap_or_else(|_| Cookie::from("")))
   123| 				.collect()
   124| 		})
   125| 	}
   126| 	fn insert_cookie(&mut self, cookie: Cookie<'_>) {
   127| 		if let Ok(val) = header::HeaderValue::from_str(&cookie.to_string()) {
   128| 			self.headers_mut().append("Set-Cookie", val);
   129| 		}
   130| 	}
   131| 	fn remove_cookie(&mut self, name: String) {
   132| 		let removal_cookie = Cookie::build(name).path("/").http_only(true).expires(OffsetDateTime::now_utc());
   133| 		if let Ok(val) = header::HeaderValue::from_str(&removal_cookie.to_string()) {
   134| 			self.headers_mut().append("Set-Cookie", val);
   135| 		}
   136| 	}
   137| }
   138| impl Route<'_> {
   139| 	fn method(&mut self, method: &Method, dest: fn(Request<Body>) -> BoxResponse) -> &mut Self {
   140| 		self.router.add(&format!("/{}{}", method.as_str(), self.path), dest);
   141| 		self
   142| 	}
   143| 	pub fn get(&mut self, dest: fn(Request<Body>) -> BoxResponse) -> &mut Self {
   144| 		self.method(&Method::GET, dest)
   145| 	}
   146| 	pub fn post(&mut self, dest: fn(Request<Body>) -> BoxResponse) -> &mut Self {
   147| 		self.method(&Method::POST, dest)
   148| 	}
   149| }
   150| impl Default for Server {
   151| 	fn default() -> Self {
   152| 		Self::new()
   153| 	}
   154| }
   155| impl Server {
   156| 	pub fn new() -> Self {
   157| 		Self {
   158| 			default_headers: HeaderMap::new(),
   159| 			router: Router::new(),
   160| 		}
   161| 	}
   162| 	pub fn at(&mut self, path: &str) -> Route<'_> {
   163| 		Route {
   164| 			path: path.to_owned(),
   165| 			router: &mut self.router,
   166| 		}
   167| 	}
   168| 	pub fn listen(self, addr: &str) -> Boxed<Result<(), hyper::Error>> {
   169| 		let make_svc = make_service_fn(move |_conn| {
   170| 			let router = self.router.clone();
   171| 			let default_headers = self.default_headers.clone();
   172| 			async move {
   173| 				Ok::<_, String>(service_fn(move |req: Request<Body>| {
   174| 					let req_headers = req.headers().clone();
   175| 					let def_headers = default_headers.clone();
   176| 					let mut path = req.uri().path().replace("//", "/").replace("%2F", "/");
   177| 					if path != "/" && path.ends_with('/') {
   178| 						path.pop();
   179| 					}
   180| 					let (method, is_head) = match req.method() {
   181| 						&Method::HEAD => (&Method::GET, true),
   182| 						method => (method, false),
   183| 					};
   184| 					match router.recognize(&format!("/{}{}", method.as_str(), path)) {
   185| 						Ok(found) => {
   186| 							let mut parammed = req;
   187| 							parammed.set_params(found.params().clone());
   188| 							let func = (found.handler().to_owned().to_owned())(parammed);
   189| 							async move {
   190| 								match func.await {
   191| 									Ok(mut res) => {
   192| 										res.headers_mut().extend(def_headers);
   193| 										if is_head {
   194| 											*res.body_mut() = Body::empty();
   195| 										} else {
   196| 											let _ = compress_response(&req_headers, &mut res).await;
   197| 										}
   198| 										Ok(res)
   199| 									}
   200| 									Err(msg) => new_boilerplate(def_headers, req_headers, 500, if is_head { Body::empty() } else { Body::from(msg) }).await,
   201| 								}
   202| 							}
   203| 							.boxed()
   204| 						}
   205| 						Err(e) => new_boilerplate(def_headers, req_headers, 404, if is_head { Body::empty() } else { e.into() }).boxed(),
   206| 					}
   207| 				}))
   208| 			}
   209| 		});
   210| 		let address = &addr.parse().unwrap_or_else(|_| panic!("Cannot parse {addr} as address (example format: 0.0.0.0:8080)"));
   211| 		let server = HyperServer::bind(address).serve(make_svc).with_graceful_shutdown(async {
   212| 			#[cfg(windows)]
   213| 			tokio::signal::ctrl_c().await.expect("Failed to install CTRL+C signal handler");
   214| 			#[cfg(unix)]
   215| 			{
   216| 				let mut signal_terminate = tokio::signal::unix::signal(tokio::signal::unix::SignalKind::terminate()).expect("Failed to install SIGTERM signal handler");
   217| 				tokio::select! {
   218| 					_ = tokio::signal::ctrl_c() => (),
   219| 					_ = signal_terminate.recv() => ()
   220| 				}
   221| 			}
   222| 		});
   223| 		server.boxed()
   224| 	}
   225| }
   226| async fn new_boilerplate(
   227| 	default_headers: HeaderMap<header::HeaderValue>,
   228| 	req_headers: HeaderMap<header::HeaderValue>,
   229| 	status: u16,
   230| 	body: Body,
   231| ) -> Result<Response<Body>, String> {
   232| 	match Response::builder().status(status).body(body) {
   233| 		Ok(mut res) => {
   234| 			let _ = compress_response(&req_headers, &mut res).await;
   235| 			res.headers_mut().extend(default_headers.clone());
   236| 			Ok(res)
   237| 		}
   238| 		Err(msg) => Err(msg.to_string()),
   239| 	}
   240| }
   241| #[cached]
   242| fn determine_compressor(accept_encoding: String) -> Option<CompressionType> {
   243| 	if accept_encoding.is_empty() {
   244| 		return None;
   245| 	};
   246| 	struct CompressorCandidate {
   247| 		alg: CompressionType,
   248| 		q: f64,
   249| 	}
   250| 	impl Ord for CompressorCandidate {
   251| 		fn cmp(&self, other: &Self) -> Ordering {
   252| 			match self.q.total_cmp(&other.q) {
   253| 				Ordering::Equal => self.alg.cmp(&other.alg),
   254| 				ord => ord,
   255| 			}
   256| 		}
   257| 	}
   258| 	impl PartialOrd for CompressorCandidate {
   259| 		fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
   260| 			Some(self.cmp(other))
   261| 		}
   262| 	}
   263| 	impl PartialEq for CompressorCandidate {
   264| 		fn eq(&self, other: &Self) -> bool {
   265| 			(self.q == other.q) && (self.alg == other.alg)
   266| 		}
   267| 	}
   268| 	impl Eq for CompressorCandidate {}
   269| 	let mut cur_candidate = CompressorCandidate {
   270| 		alg: CompressionType::Passthrough,
   271| 		q: f64::NEG_INFINITY,
   272| 	};
   273| 	for val in accept_encoding.split(',') {
   274| 		let mut q: f64 = 1.0;
   275| 		let mut spl: Split<'_, char> = val.split(';');
   276| 		let compressor: CompressionType = match spl.next() {
   277| 			Some(s) => match CompressionType::parse(s.trim()) {
   278| 				Some(candidate) => candidate,
   279| 				None => continue,
   280| 			},
   281| 			None => continue,
   282| 		};
   283| 		if let Some(s) = spl.next() {
   284| 			if !(s.len() > 2 && s.starts_with("q=")) {
   285| 				return None;
   286| 			}
   287| 			match s[2..].parse::<f64>() {
   288| 				Ok(val) => {
   289| 					if (0.0..=1.0).contains(&val) {
   290| 						q = val;
   291| 					} else {
   292| 						return None;
   293| 					};
   294| 				}
   295| 				Err(_) => {
   296| 					return None;
   297| 				}
   298| 			}
   299| 		};
   300| 		let new_candidate = CompressorCandidate { alg: compressor, q };
   301| 		if let Some(ord) = new_candidate.partial_cmp(&cur_candidate) {
   302| 			if ord == Ordering::Greater {
   303| 				cur_candidate = new_candidate;
   304| 			}
   305| 		};
   306| 	}
   307| 	if cur_candidate.q == f64::NEG_INFINITY {
   308| 		None
   309| 	} else {
   310| 		Some(cur_candidate.alg)
   311| 	}
   312| }
   313| async fn compress_response(req_headers: &HeaderMap<header::HeaderValue>, res: &mut Response<Body>) -> Result<(), String> {
   314| 	if let Some(hdr) = res.headers().get(header::CONTENT_TYPE) {
   315| 		match from_utf8(hdr.as_bytes()) {
   316| 			Ok(val) => {
   317| 				let s = val.to_string();
   318| 				if !(s.starts_with("text/") || s.starts_with("application/json")) {
   319| 					return Ok(());
   320| 				};
   321| 			}
   322| 			Err(e) => {
   323| 				dbg_msg!(e);
   324| 				return Err(e.to_string());
   325| 			}
   326| 		};
   327| 	} else {
   328| 		return Ok(());
   329| 	};
   330| 	if res.body().size_hint().lower() < 1452 {
   331| 		return Ok(());
   332| 	};
   333| 	let accept_encoding: String = match req_headers.get(header::ACCEPT_ENCODING) {
   334| 		None => return Ok(()), // Client requested no compression.
   335| 		Some(hdr) => match String::from_utf8(hdr.as_bytes().into()) {
   336| 			Ok(val) => val,
   337| 			#[cfg(debug_assertions)]
   338| 			Err(e) => {
   339| 				dbg_msg!(e);
   340| 				return Ok(());
   341| 			}
   342| 			#[cfg(not(debug_assertions))]
   343| 			Err(_) => return Ok(()),
   344| 		},
   345| 	};
   346| 	let compressor: CompressionType = match determine_compressor(accept_encoding) {
   347| 		Some(c) => c,
   348| 		None => return Ok(()),
   349| 	};
   350| 	let body_bytes: Vec<u8> = match body::to_bytes(res.body_mut()).await {
   351| 		Ok(b) => b.to_vec(),
   352| 		Err(e) => {
   353| 			dbg_msg!(e);
   354| 			return Err(e.to_string());
   355| 		}
   356| 	};
   357| 	match compress_body(compressor, body_bytes) {
   358| 		Ok(compressed) => {
   359| 			res.headers_mut().insert(header::CONTENT_ENCODING, compressor.to_string().parse().unwrap());
   360| 			*(res.body_mut()) = Body::from(compressed);
   361| 		}
   362| 		Err(e) => return Err(e),
   363| 	}
   364| 	Ok(())
   365| }
   366| #[cached(size = 100, time = 600, result = true)]
   367| fn compress_body(compressor: CompressionType, body_bytes: Vec<u8>) -> Result<Vec<u8>, String> {
   368| 	let mut reader = io::Cursor::new(body_bytes);
   369| 	let compressed: Vec<u8> = match compressor {
   370| 		CompressionType::Gzip => {
   371| 			let mut gz: gzip::Encoder<Vec<u8>> = match gzip::Encoder::new(Vec::new()) {
   372| 				Ok(gz) => gz,
   373| 				Err(e) => {
   374| 					dbg_msg!(e);
   375| 					return Err(e.to_string());
   376| 				}
   377| 			};
   378| 			match io::copy(&mut reader, &mut gz) {
   379| 				Ok(_) => match gz.finish().into_result() {
   380| 					Ok(compressed) => compressed,
   381| 					Err(e) => {
   382| 						dbg_msg!(e);
   383| 						return Err(e.to_string());
   384| 					}
   385| 				},
   386| 				Err(e) => {
   387| 					dbg_msg!(e);
   388| 					return Err(e.to_string());
   389| 				}
   390| 			}
   391| 		}
   392| 		CompressionType::Brotli => {
   393| 			let brotli_params = BrotliEncoderParams::default();
   394| 			let mut compressed = Vec::<u8>::new();
   395| 			match BrotliCompress(&mut reader, &mut compressed, &brotli_params) {
   396| 				Ok(_) => compressed,
   397| 				Err(e) => {
   398| 					dbg_msg!(e);
   399| 					return Err(e.to_string());
   400| 				}
   401| 			}
   402| 		}
   403| 		CompressionType::Passthrough => {
   404| 			let msg = "unsupported compressor".to_string();
   405| 			return Err(msg);
   406| 		}
   407| 	};
   408| 	Ok(compressed)
   409| }
   410| #[cfg(test)]
   411| mod tests {
   412| 	use super::*;
   413| 	use brotli::Decompressor as BrotliDecompressor;
   414| 	use futures_lite::future::block_on;
   415| 	use lipsum::lipsum;
   416| 	use std::{boxed::Box, io};
   417| 	#[test]
   418| 	fn test_determine_compressor() {
   419| 		assert_eq!(determine_compressor("unsupported".to_string()), None);
   420| 		assert_eq!(determine_compressor("gzip".to_string()), Some(CompressionType::Gzip));
   421| 		assert_eq!(determine_compressor("*".to_string()), Some(DEFAULT_COMPRESSOR));
   422| 		assert_eq!(determine_compressor("gzip, br".to_string()), Some(CompressionType::Brotli));
   423| 		assert_eq!(determine_compressor("gzip;q=0.8, br;q=0.3".to_string()), Some(CompressionType::Gzip));
   424| 		assert_eq!(determine_compressor("br, gzip".to_string()), Some(CompressionType::Brotli));
   425| 		assert_eq!(determine_compressor("br;q=0.3, gzip;q=0.4".to_string()), Some(CompressionType::Gzip));
   426| 		assert_eq!(determine_compressor("gzip;q=NAN".to_string()), None);
   427| 	}
   428| 	#[test]
   429| 	fn test_compress_response() {
   430| 		macro_rules! ae_gen {
   431| 			($x:expr) => {
   432| 				$x.to_string().as_str()
   433| 			};
   434| 			($x:expr, $($y:expr),+) => {
   435| 				format!("{}, {}", $x.to_string(), ae_gen!($($y),+)).as_str()
   436| 			};
   437| 		}
   438| 		for accept_encoding in [
   439| 			"*",
   440| 			ae_gen!(CompressionType::Gzip),
   441| 			ae_gen!(CompressionType::Brotli, CompressionType::Gzip),
   442| 			ae_gen!(CompressionType::Brotli),
   443| 		] {
   444| 			let expected_encoding: CompressionType = match determine_compressor(accept_encoding.to_string()) {
   445| 				Some(s) => s,
   446| 				None => panic!("determine_compressor(accept_encoding.to_string()) => None"),
   447| 			};
   448| 			let mut req_headers = HeaderMap::new();
   449| 			req_headers.insert(header::ACCEPT_ENCODING, header::HeaderValue::from_str(accept_encoding).unwrap());
   450| 			let lorem_ipsum: String = lipsum(10000);
   451| 			let expected_lorem_ipsum = Vec::<u8>::from(lorem_ipsum.as_str());
   452| 			let mut res = Response::builder()
   453| 				.status(200)
   454| 				.header(header::CONTENT_TYPE, "text/plain")
   455| 				.body(Body::from(lorem_ipsum))
   456| 				.unwrap();
   457| 			if let Err(e) = block_on(compress_response(&req_headers, &mut res)) {
   458| 				panic!("compress_response(&req_headers, &mut res) => Err(\"{e}\")");
   459| 			};
   460| 			assert_eq!(
   461| 				res
   462| 					.headers()
   463| 					.get(header::CONTENT_ENCODING)
   464| 					.unwrap_or_else(|| panic!("missing content-encoding header"))
   465| 					.to_str()
   466| 					.unwrap_or_else(|_| panic!("failed to convert Content-Encoding header::HeaderValue to String")),
   467| 				expected_encoding.to_string()
   468| 			);
   469| 			let body_vec = match block_on(body::to_bytes(res.body_mut())) {
   470| 				Ok(b) => b.to_vec(),
   471| 				Err(e) => panic!("{e}"),
   472| 			};
   473| 			if expected_encoding == CompressionType::Passthrough {
   474| 				assert!(body_vec.eq(&expected_lorem_ipsum));
   475| 				continue;
   476| 			}
   477| 			let mut body_cursor: io::Cursor<Vec<u8>> = io::Cursor::new(body_vec);
   478| 			let mut decoder: Box<dyn io::Read> = match expected_encoding {
   479| 				CompressionType::Gzip => match gzip::Decoder::new(&mut body_cursor) {
   480| 					Ok(dgz) => Box::new(dgz),
   481| 					Err(e) => panic!("{e}"),
   482| 				},
   483| 				CompressionType::Brotli => Box::new(BrotliDecompressor::new(body_cursor, expected_lorem_ipsum.len())),
   484| 				_ => panic!("no decompressor for {}", expected_encoding),
   485| 			};
   486| 			let mut decompressed = Vec::<u8>::new();
   487| 			if let Err(e) = io::copy(&mut decoder, &mut decompressed) {
   488| 				panic!("{e}");
   489| 			};
   490| 			assert!(decompressed.eq(&expected_lorem_ipsum));
   491| 		}
   492| 	}
   493| }


# ====================================================================
# FILE: src/settings.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-206 ---
     1| #![allow(clippy::cmp_owned)]
     2| use std::collections::HashMap;
     3| use crate::server::ResponseExt;
     4| use crate::subreddit::join_until_size_limit;
     5| use crate::utils::{deflate_decompress, redirect, template, Preferences};
     6| use cookie::Cookie;
     7| use futures_lite::StreamExt;
     8| use hyper::{Body, Request, Response};
     9| use rinja::Template;
    10| use time::{Duration, OffsetDateTime};
    11| use tokio::time::timeout;
    12| use url::form_urlencoded;
    13| #[derive(Template)]
    14| #[template(path = "settings.html")]
    15| struct SettingsTemplate {
    16| 	prefs: Preferences,
    17| 	url: String,
    18| }
    19| const PREFS: [&str; 19] = [
    20| 	"theme",
    21| 	"front_page",
    22| 	"layout",
    23| 	"wide",
    24| 	"comment_sort",
    25| 	"post_sort",
    26| 	"blur_spoiler",
    27| 	"show_nsfw",
    28| 	"blur_nsfw",
    29| 	"use_hls",
    30| 	"hide_hls_notification",
    31| 	"autoplay_videos",
    32| 	"hide_sidebar_and_summary",
    33| 	"fixed_navbar",
    34| 	"hide_awards",
    35| 	"hide_score",
    36| 	"disable_visit_reddit_confirmation",
    37| 	"video_quality",
    38| 	"remove_default_feeds",
    39| ];
    40| pub async fn get(req: Request<Body>) -> Result<Response<Body>, String> {
    41| 	let url = req.uri().to_string();
    42| 	Ok(template(&SettingsTemplate {
    43| 		prefs: Preferences::new(&req),
    44| 		url,
    45| 	}))
    46| }
    47| pub async fn set(req: Request<Body>) -> Result<Response<Body>, String> {
    48| 	let (parts, mut body) = req.into_parts();
    49| 	let _cookies: Vec<Cookie<'_>> = parts
    50| 		.headers
    51| 		.get_all("Cookie")
    52| 		.iter()
    53| 		.filter_map(|header| Cookie::parse(header.to_str().unwrap_or_default()).ok())
    54| 		.collect();
    55| 	let body_bytes = body
    56| 		.try_fold(Vec::new(), |mut data, chunk| {
    57| 			data.extend_from_slice(&chunk);
    58| 			Ok(data)
    59| 		})
    60| 		.await
    61| 		.map_err(|e| e.to_string())?;
    62| 	let form = url::form_urlencoded::parse(&body_bytes).collect::<HashMap<_, _>>();
    63| 	let mut response = redirect("/settings");
    64| 	for &name in &PREFS {
    65| 		match form.get(name) {
    66| 			Some(value) => response.insert_cookie(
    67| 				Cookie::build((name.to_owned(), value.clone()))
    68| 					.path("/")
    69| 					.http_only(true)
    70| 					.expires(OffsetDateTime::now_utc() + Duration::weeks(52))
    71| 					.into(),
    72| 			),
    73| 			None => response.remove_cookie(name.to_string()),
    74| 		};
    75| 	}
    76| 	Ok(response)
    77| }
    78| fn set_cookies_method(req: Request<Body>, remove_cookies: bool) -> Response<Body> {
    79| 	let (parts, _) = req.into_parts();
    80| 	let _cookies: Vec<Cookie<'_>> = parts
    81| 		.headers
    82| 		.get_all("Cookie")
    83| 		.iter()
    84| 		.filter_map(|header| Cookie::parse(header.to_str().unwrap_or_default()).ok())
    85| 		.collect();
    86| 	let query = parts.uri.query().unwrap_or_default().as_bytes();
    87| 	let form = url::form_urlencoded::parse(query).collect::<HashMap<_, _>>();
    88| 	let path = match form.get("redirect") {
    89| 		Some(value) => format!("/{}", value.replace("%26", "&").replace("%23", "#")),
    90| 		None => "/".to_string(),
    91| 	};
    92| 	let mut response = redirect(&path);
    93| 	for name in PREFS {
    94| 		match form.get(name) {
    95| 			Some(value) => response.insert_cookie(
    96| 				Cookie::build((name.to_owned(), value.clone()))
    97| 					.path("/")
    98| 					.http_only(true)
    99| 					.expires(OffsetDateTime::now_utc() + Duration::weeks(52))
   100| 					.into(),
   101| 			),
   102| 			None => {
   103| 				if remove_cookies {
   104| 					response.remove_cookie(name.to_string());
   105| 				}
   106| 			}
   107| 		};
   108| 	}
   109| 	let subscriptions = form.get("subscriptions");
   110| 	let filters = form.get("filters");
   111| 	let cookies_string = parts
   112| 		.headers
   113| 		.get("cookie")
   114| 		.map(|hv| hv.to_str().unwrap_or("").to_string()) // Return String
   115| 		.unwrap_or_else(String::new); // Return an empty string if None
   116| 	if subscriptions.is_some() {
   117| 		let sub_list: Vec<String> = subscriptions.expect("Subscriptions").split('+').map(str::to_string).collect();
   118| 		let mut subscriptions_number_to_delete_from = 0;
   119| 		for (subscriptions_number, list) in join_until_size_limit(&sub_list).into_iter().enumerate() {
   120| 			let subscriptions_cookie = if subscriptions_number == 0 {
   121| 				"subscriptions".to_string()
   122| 			} else {
   123| 				format!("subscriptions{}", subscriptions_number)
   124| 			};
   125| 			response.insert_cookie(
   126| 				Cookie::build((subscriptions_cookie, list))
   127| 					.path("/")
   128| 					.http_only(true)
   129| 					.expires(OffsetDateTime::now_utc() + Duration::weeks(52))
   130| 					.into(),
   131| 			);
   132| 			subscriptions_number_to_delete_from += 1;
   133| 		}
   134| 		while cookies_string.contains(&format!("subscriptions{subscriptions_number_to_delete_from}=")) {
   135| 			response.remove_cookie(format!("subscriptions{subscriptions_number_to_delete_from}"));
   136| 			subscriptions_number_to_delete_from += 1;
   137| 		}
   138| 	} else {
   139| 		response.remove_cookie("subscriptions".to_string());
   140| 		let mut subscriptions_number_to_delete_from = 1;
   141| 		while cookies_string.contains(&format!("subscriptions{subscriptions_number_to_delete_from}=")) {
   142| 			response.remove_cookie(format!("subscriptions{subscriptions_number_to_delete_from}"));
   143| 			subscriptions_number_to_delete_from += 1;
   144| 		}
   145| 	}
   146| 	if filters.is_some() {
   147| 		let filters_list: Vec<String> = filters.expect("Filters").split('+').map(str::to_string).collect();
   148| 		let mut filters_number_to_delete_from = 0;
   149| 		for (filters_number, list) in join_until_size_limit(&filters_list).into_iter().enumerate() {
   150| 			let filters_cookie = if filters_number == 0 {
   151| 				"filters".to_string()
   152| 			} else {
   153| 				format!("filters{}", filters_number)
   154| 			};
   155| 			response.insert_cookie(
   156| 				Cookie::build((filters_cookie, list))
   157| 					.path("/")
   158| 					.http_only(true)
   159| 					.expires(OffsetDateTime::now_utc() + Duration::weeks(52))
   160| 					.into(),
   161| 			);
   162| 			filters_number_to_delete_from += 1;
   163| 		}
   164| 		while cookies_string.contains(&format!("filters{filters_number_to_delete_from}=")) {
   165| 			response.remove_cookie(format!("filters{filters_number_to_delete_from}"));
   166| 			filters_number_to_delete_from += 1;
   167| 		}
   168| 	} else {
   169| 		response.remove_cookie("filters".to_string());
   170| 		let mut filters_number_to_delete_from = 1;
   171| 		while cookies_string.contains(&format!("filters{filters_number_to_delete_from}=")) {
   172| 			response.remove_cookie(format!("filters{filters_number_to_delete_from}"));
   173| 			filters_number_to_delete_from += 1;
   174| 		}
   175| 	}
   176| 	response
   177| }
   178| pub async fn restore(req: Request<Body>) -> Result<Response<Body>, String> {
   179| 	Ok(set_cookies_method(req, true))
   180| }
   181| pub async fn update(req: Request<Body>) -> Result<Response<Body>, String> {
   182| 	Ok(set_cookies_method(req, false))
   183| }
   184| pub async fn encoded_restore(req: Request<Body>) -> Result<Response<Body>, String> {
   185| 	let body = hyper::body::to_bytes(req.into_body())
   186| 		.await
   187| 		.map_err(|e| format!("Failed to get bytes from request body: {}", e))?;
   188| 	if body.len() > 1024 * 1024 {
   189| 		return Err("Request body too large".to_string());
   190| 	}
   191| 	let encoded_prefs = form_urlencoded::parse(&body)
   192| 		.find(|(key, _)| key == "encoded_prefs")
   193| 		.map(|(_, value)| value)
   194| 		.ok_or_else(|| "encoded_prefs parameter not found in request body".to_string())?;
   195| 	let bytes = base2048::decode(&encoded_prefs).ok_or_else(|| "Failed to decode base2048 encoded preferences".to_string())?;
   196| 	let out = timeout(std::time::Duration::from_secs(1), async { deflate_decompress(bytes) })
   197| 		.await
   198| 		.map_err(|e| format!("Failed to decompress bytes: {}", e))??;
   199| 	let mut prefs: Preferences = timeout(std::time::Duration::from_secs(1), async { bincode::deserialize(&out) })
   200| 		.await
   201| 		.map_err(|e| format!("Failed to deserialize preferences: {}", e))?
   202| 		.map_err(|e| format!("Failed to deserialize bytes into Preferences struct: {}", e))?;
   203| 	prefs.available_themes = vec![];
   204| 	let url = format!("/settings/restore/?{}", prefs.to_urlencoded()?);
   205| 	Ok(redirect(&url))
   206| }


# ====================================================================
# FILE: src/subreddit.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-458 ---
     1| #![allow(clippy::cmp_owned)]
     2| use crate::{config, utils};
     3| use crate::utils::{
     4| 	catch_random, error, filter_posts, format_num, format_url, get_filters, info, nsfw_landing, param, redirect, rewrite_urls, setting, template, val, Post, Preferences,
     5| 	Subreddit,
     6| };
     7| use crate::{client::json, server::RequestExt, server::ResponseExt};
     8| use cookie::Cookie;
     9| use htmlescape::decode_html;
    10| use hyper::{Body, Request, Response};
    11| use rinja::Template;
    12| use chrono::DateTime;
    13| use once_cell::sync::Lazy;
    14| use regex::Regex;
    15| use time::{Duration, OffsetDateTime};
    16| #[derive(Template)]
    17| #[template(path = "subreddit.html")]
    18| struct SubredditTemplate {
    19| 	sub: Subreddit,
    20| 	posts: Vec<Post>,
    21| 	sort: (String, String),
    22| 	ends: (String, String),
    23| 	prefs: Preferences,
    24| 	url: String,
    25| 	redirect_url: String,
    26| 	is_filtered: bool,
    27| 	all_posts_filtered: bool,
    28| 	all_posts_hidden_nsfw: bool,
    29| 	no_posts: bool,
    30| }
    31| #[derive(Template)]
    32| #[template(path = "wiki.html")]
    33| struct WikiTemplate {
    34| 	sub: String,
    35| 	wiki: String,
    36| 	page: String,
    37| 	prefs: Preferences,
    38| 	url: String,
    39| }
    40| #[derive(Template)]
    41| #[template(path = "wall.html")]
    42| struct WallTemplate {
    43| 	title: String,
    44| 	sub: String,
    45| 	msg: String,
    46| 	prefs: Preferences,
    47| 	url: String,
    48| }
    49| static GEO_FILTER_MATCH: Lazy<Regex> = Lazy::new(|| Regex::new(r"geo_filter=(?<region>\w+)").unwrap());
    50| pub async fn community(req: Request<Body>) -> Result<Response<Body>, String> {
    51| 	let root = req.uri().path() == "/";
    52| 	let query = req.uri().query().unwrap_or_default().to_string();
    53| 	let subscribed = setting(&req, "subscriptions");
    54| 	let front_page = setting(&req, "front_page");
    55| 	let remove_default_feeds = setting(&req, "remove_default_feeds") == "on";
    56| 	let post_sort = req.cookie("post_sort").map_or_else(|| "hot".to_string(), |c| c.value().to_string());
    57| 	let sort = req.param("sort").unwrap_or_else(|| req.param("id").unwrap_or(post_sort));
    58| 	let sub_name = req.param("sub").unwrap_or(if front_page == "default" || front_page.is_empty() {
    59| 		if subscribed.is_empty() {
    60| 			"popular".to_string()
    61| 		} else {
    62| 			subscribed.clone()
    63| 		}
    64| 	} else {
    65| 		front_page.clone()
    66| 	});
    67| 	if (sub_name == "popular" || sub_name == "all") && remove_default_feeds {
    68| 		if subscribed.is_empty() {
    69| 			return info(req, "Subscribe to some subreddits! (Default feeds disabled in settings)").await;
    70| 		} else {
    71| 			return info(
    72| 				req,
    73| 				"You have subscribed to some subreddits, but your front page is not set to default. Visit settings and change front page to default.",
    74| 			)
    75| 			.await;
    76| 		}
    77| 	}
    78| 	let quarantined = can_access_quarantine(&req, &sub_name) || root;
    79| 	if let Ok(random) = catch_random(&sub_name, "").await {
    80| 		return Ok(random);
    81| 	}
    82| 	if req.param("sub").is_some() && sub_name.starts_with("u_") {
    83| 		return Ok(redirect(&["/user/", &sub_name[2..]].concat()));
    84| 	}
    85| 	let sub = if !sub_name.contains('+') && sub_name != subscribed && sub_name != "popular" && sub_name != "all" {
    86| 		subreddit(&sub_name, quarantined).await.unwrap_or_default()
    87| 	} else if sub_name == subscribed {
    88| 		if req.uri().path().starts_with("/r/") {
    89| 			subreddit(&sub_name, quarantined).await.unwrap_or_default()
    90| 		} else {
    91| 			Subreddit::default()
    92| 		}
    93| 	} else {
    94| 		Subreddit {
    95| 			name: sub_name.clone(),
    96| 			..Subreddit::default()
    97| 		}
    98| 	};
    99| 	let req_url = req.uri().to_string();
   100| 	if sub.nsfw && crate::utils::should_be_nsfw_gated(&req, &req_url) {
   101| 		return Ok(nsfw_landing(req, req_url).await.unwrap_or_default());
   102| 	}
   103| 	let mut params = String::from("&raw_json=1");
   104| 	if sub_name == "popular" {
   105| 		let geo_filter = match GEO_FILTER_MATCH.captures(&query) {
   106| 			Some(geo_filter) => geo_filter["region"].to_string(),
   107| 			None => "GLOBAL".to_owned(),
   108| 		};
   109| 		params.push_str(&format!("&geo_filter={geo_filter}"));
   110| 	}
   111| 	let path = format!("/r/{}/{sort}.json?{}{params}", sub_name.replace('+', "%2B"), req.uri().query().unwrap_or_default());
   112| 	let url = String::from(req.uri().path_and_query().map_or("", |val| val.as_str()));
   113| 	let redirect_url = url[1..].replace('?', "%3F").replace('&', "%26").replace('+', "%2B");
   114| 	let filters = get_filters(&req);
   115| 	if sub_name.split('+').all(|s| filters.contains(s)) {
   116| 		Ok(template(&SubredditTemplate {
   117| 			sub,
   118| 			posts: Vec::new(),
   119| 			sort: (sort, param(&path, "t").unwrap_or_default()),
   120| 			ends: (param(&path, "after").unwrap_or_default(), String::new()),
   121| 			prefs: Preferences::new(&req),
   122| 			url,
   123| 			redirect_url,
   124| 			is_filtered: true,
   125| 			all_posts_filtered: false,
   126| 			all_posts_hidden_nsfw: false,
   127| 			no_posts: false,
   128| 		}))
   129| 	} else {
   130| 		match Post::fetch(&path, quarantined).await {
   131| 			Ok((mut posts, after)) => {
   132| 				let (_, all_posts_filtered) = filter_posts(&mut posts, &filters);
   133| 				let no_posts = posts.is_empty();
   134| 				let all_posts_hidden_nsfw = !no_posts && (posts.iter().all(|p| p.flags.nsfw) && setting(&req, "show_nsfw") != "on");
   135| 				if sort == "new" {
   136| 					posts.sort_by(|a, b| b.created_ts.cmp(&a.created_ts));
   137| 					posts.sort_by(|a, b| b.flags.stickied.cmp(&a.flags.stickied));
   138| 				}
   139| 				Ok(template(&SubredditTemplate {
   140| 					sub,
   141| 					posts,
   142| 					sort: (sort, param(&path, "t").unwrap_or_default()),
   143| 					ends: (param(&path, "after").unwrap_or_default(), after),
   144| 					prefs: Preferences::new(&req),
   145| 					url,
   146| 					redirect_url,
   147| 					is_filtered: false,
   148| 					all_posts_filtered,
   149| 					all_posts_hidden_nsfw,
   150| 					no_posts,
   151| 				}))
   152| 			}
   153| 			Err(msg) => match msg.as_str() {
   154| 				"quarantined" | "gated" => Ok(quarantine(&req, sub_name, &msg)),
   155| 				"private" => error(req, &format!("r/{sub_name} is a private community")).await,
   156| 				"banned" => error(req, &format!("r/{sub_name} has been banned from Reddit")).await,
   157| 				_ => error(req, &msg).await,
   158| 			},
   159| 		}
   160| 	}
   161| }
   162| pub fn quarantine(req: &Request<Body>, sub: String, restriction: &str) -> Response<Body> {
   163| 	let wall = WallTemplate {
   164| 		title: format!("r/{sub} is {restriction}"),
   165| 		msg: "Please click the button below to continue to this subreddit.".to_string(),
   166| 		url: req.uri().to_string(),
   167| 		sub,
   168| 		prefs: Preferences::new(req),
   169| 	};
   170| 	Response::builder()
   171| 		.status(403)
   172| 		.header("content-type", "text/html")
   173| 		.body(wall.render().unwrap_or_default().into())
   174| 		.unwrap_or_default()
   175| }
   176| pub async fn add_quarantine_exception(req: Request<Body>) -> Result<Response<Body>, String> {
   177| 	let subreddit = req.param("sub").ok_or("Invalid URL")?;
   178| 	let redir = param(&format!("?{}", req.uri().query().unwrap_or_default()), "redir").ok_or("Invalid URL")?;
   179| 	let mut response = redirect(&redir);
   180| 	response.insert_cookie(
   181| 		Cookie::build((&format!("allow_quaran_{}", subreddit.to_lowercase()), "true"))
   182| 			.path("/")
   183| 			.http_only(true)
   184| 			.expires(cookie::Expiration::Session)
   185| 			.into(),
   186| 	);
   187| 	Ok(response)
   188| }
   189| pub fn can_access_quarantine(req: &Request<Body>, sub: &str) -> bool {
   190| 	setting(req, &format!("allow_quaran_{}", sub.to_lowercase())).parse().unwrap_or_default()
   191| }
   192| pub fn join_until_size_limit<T: std::fmt::Display>(vec: &[T]) -> Vec<std::string::String> {
   193| 	let mut result = Vec::new();
   194| 	let mut list = String::new();
   195| 	let mut current_size = 0;
   196| 	for item in vec {
   197| 		let item_size = item.to_string().len();
   198| 		if current_size + item_size > 4000 {
   199| 			list.push('+');
   200| 			result.push(list);
   201| 			list = String::new();
   202| 		}
   203| 		if !list.is_empty() {
   204| 			list.push('+');
   205| 		}
   206| 		list.push_str(&item.to_string());
   207| 		current_size = list.len() + item_size;
   208| 	}
   209| 	result.push(list);
   210| 	result
   211| }
   212| pub async fn subscriptions_filters(req: Request<Body>) -> Result<Response<Body>, String> {
   213| 	let sub = req.param("sub").unwrap_or_default();
   214| 	let action: Vec<String> = req.uri().path().split('/').map(String::from).collect();
   215| 	if sub == "random" || sub == "randnsfw" {
   216| 		if action.contains(&"filter".to_string()) || action.contains(&"unfilter".to_string()) {
   217| 			return Err("Can't filter random subreddit!".to_string());
   218| 		}
   219| 		return Err("Can't subscribe to random subreddit!".to_string());
   220| 	}
   221| 	let query = req.uri().query().unwrap_or_default().to_string();
   222| 	let preferences = Preferences::new(&req);
   223| 	let mut sub_list = preferences.subscriptions;
   224| 	let mut filters = preferences.filters;
   225| 	let posts = json(format!("/r/{sub}/hot.json?raw_json=1"), true).await;
   226| 	let display_lookup: Vec<(String, &str)> = match &posts {
   227| 		Ok(posts) => posts["data"]["children"]
   228| 			.as_array()
   229| 			.map(|list| {
   230| 				list
   231| 					.iter()
   232| 					.map(|post| {
   233| 						let display_name = post["data"]["subreddit"].as_str().unwrap_or_default();
   234| 						(display_name.to_lowercase(), display_name)
   235| 					})
   236| 					.collect::<Vec<_>>()
   237| 			})
   238| 			.unwrap_or_default(),
   239| 		Err(_) => vec![],
   240| 	};
   241| 	for part in sub.split('+').filter(|x| x != &"") {
   242| 		let display;
   243| 		let part = if part.starts_with("u_") {
   244| 			part
   245| 		} else if let Some(&(_, display)) = display_lookup.iter().find(|x| x.0 == part.to_lowercase()) {
   246| 			display
   247| 		} else {
   248| 			let path: String = format!("/r/{part}/about.json?raw_json=1");
   249| 			display = json(path, true).await;
   250| 			match &display {
   251| 				Ok(display) => display["data"]["display_name"].as_str(),
   252| 				Err(_) => None,
   253| 			}
   254| 			.unwrap_or(part)
   255| 		};
   256| 		if action.contains(&"subscribe".to_string()) && !sub_list.contains(&part.to_owned()) {
   257| 			sub_list.push(part.to_owned());
   258| 			filters.retain(|s| s.to_lowercase() != part.to_lowercase());
   259| 			sub_list.sort_by_key(|a| a.to_lowercase());
   260| 			filters.sort_by_key(|a| a.to_lowercase());
   261| 		} else if action.contains(&"unsubscribe".to_string()) {
   262| 			sub_list.retain(|s| s.to_lowercase() != part.to_lowercase());
   263| 		} else if action.contains(&"filter".to_string()) && !filters.contains(&part.to_owned()) {
   264| 			filters.push(part.to_owned());
   265| 			sub_list.retain(|s| s.to_lowercase() != part.to_lowercase());
   266| 			filters.sort_by_key(|a| a.to_lowercase());
   267| 			sub_list.sort_by_key(|a| a.to_lowercase());
   268| 		} else if action.contains(&"unfilter".to_string()) {
   269| 			filters.retain(|s| s.to_lowercase() != part.to_lowercase());
   270| 		}
   271| 	}
   272| 	let path = if let Some(redirect_path) = param(&format!("?{query}"), "redirect") {
   273| 		format!("/{redirect_path}")
   274| 	} else {
   275| 		format!("/r/{sub}")
   276| 	};
   277| 	let mut response = redirect(&path);
   278| 	if sub_list.is_empty() {
   279| 		response.remove_cookie("subscriptions".to_string());
   280| 		let mut subscriptions_number = 1;
   281| 		while req.cookie(&format!("subscriptions{}", subscriptions_number)).is_some() {
   282| 			response.remove_cookie(format!("subscriptions{}", subscriptions_number));
   283| 			subscriptions_number += 1;
   284| 		}
   285| 	} else {
   286| 		let mut subscriptions_number_to_delete_from = 0;
   287| 		for (subscriptions_number, list) in join_until_size_limit(&sub_list).into_iter().enumerate() {
   288| 			let subscriptions_cookie = if subscriptions_number == 0 {
   289| 				"subscriptions".to_string()
   290| 			} else {
   291| 				format!("subscriptions{}", subscriptions_number)
   292| 			};
   293| 			response.insert_cookie(
   294| 				Cookie::build((subscriptions_cookie, list))
   295| 					.path("/")
   296| 					.http_only(true)
   297| 					.expires(OffsetDateTime::now_utc() + Duration::weeks(52))
   298| 					.into(),
   299| 			);
   300| 			subscriptions_number_to_delete_from += 1;
   301| 		}
   302| 		while req.cookie(&format!("subscriptions{}", subscriptions_number_to_delete_from)).is_some() {
   303| 			response.remove_cookie(format!("subscriptions{}", subscriptions_number_to_delete_from));
   304| 			subscriptions_number_to_delete_from += 1;
   305| 		}
   306| 	}
   307| 	if filters.is_empty() {
   308| 		response.remove_cookie("filters".to_string());
   309| 		let mut filters_number = 1;
   310| 		while req.cookie(&format!("filters{}", filters_number)).is_some() {
   311| 			response.remove_cookie(format!("filters{}", filters_number));
   312| 			filters_number += 1;
   313| 		}
   314| 	} else {
   315| 		let mut filters_number_to_delete_from = 0;
   316| 		for (filters_number, list) in join_until_size_limit(&filters).into_iter().enumerate() {
   317| 			let filters_cookie = if filters_number == 0 {
   318| 				"filters".to_string()
   319| 			} else {
   320| 				format!("filters{}", filters_number)
   321| 			};
   322| 			response.insert_cookie(
   323| 				Cookie::build((filters_cookie, list))
   324| 					.path("/")
   325| 					.http_only(true)
   326| 					.expires(OffsetDateTime::now_utc() + Duration::weeks(52))
   327| 					.into(),
   328| 			);
   329| 			filters_number_to_delete_from += 1;
   330| 		}
   331| 		while req.cookie(&format!("filters{}", filters_number_to_delete_from)).is_some() {
   332| 			response.remove_cookie(format!("filters{}", filters_number_to_delete_from));
   333| 			filters_number_to_delete_from += 1;
   334| 		}
   335| 	}
   336| 	Ok(response)
   337| }
   338| pub async fn wiki(req: Request<Body>) -> Result<Response<Body>, String> {
   339| 	let sub = req.param("sub").unwrap_or_else(|| "reddit.com".to_string());
   340| 	let quarantined = can_access_quarantine(&req, &sub);
   341| 	if let Ok(random) = catch_random(&sub, "/wiki").await {
   342| 		return Ok(random);
   343| 	}
   344| 	let page = req.param("page").unwrap_or_else(|| "index".to_string());
   345| 	let path: String = format!("/r/{sub}/wiki/{page}.json?raw_json=1");
   346| 	let url = req.uri().to_string();
   347| 	match json(path, quarantined).await {
   348| 		Ok(response) => Ok(template(&WikiTemplate {
   349| 			sub,
   350| 			wiki: rewrite_urls(response["data"]["content_html"].as_str().unwrap_or("<h3>Wiki not found</h3>")),
   351| 			page,
   352| 			prefs: Preferences::new(&req),
   353| 			url,
   354| 		})),
   355| 		Err(msg) => {
   356| 			if msg == "quarantined" || msg == "gated" {
   357| 				Ok(quarantine(&req, sub, &msg))
   358| 			} else {
   359| 				error(req, &msg).await
   360| 			}
   361| 		}
   362| 	}
   363| }
   364| pub async fn sidebar(req: Request<Body>) -> Result<Response<Body>, String> {
   365| 	let sub = req.param("sub").unwrap_or_else(|| "reddit.com".to_string());
   366| 	let quarantined = can_access_quarantine(&req, &sub);
   367| 	if let Ok(random) = catch_random(&sub, "/about/sidebar").await {
   368| 		return Ok(random);
   369| 	}
   370| 	let path: String = format!("/r/{sub}/about.json?raw_json=1");
   371| 	let url = req.uri().to_string();
   372| 	match json(path, quarantined).await {
   373| 		Ok(response) => Ok(template(&WikiTemplate {
   374| 			wiki: rewrite_urls(&val(&response, "description_html")),
   375| 			sub,
   376| 			page: "Sidebar".to_string(),
   377| 			prefs: Preferences::new(&req),
   378| 			url,
   379| 		})),
   380| 		Err(msg) => {
   381| 			if msg == "quarantined" || msg == "gated" {
   382| 				Ok(quarantine(&req, sub, &msg))
   383| 			} else {
   384| 				error(req, &msg).await
   385| 			}
   386| 		}
   387| 	}
   388| }
   389| async fn subreddit(sub: &str, quarantined: bool) -> Result<Subreddit, String> {
   390| 	let path: String = format!("/r/{sub}/about.json?raw_json=1");
   391| 	let res = json(path, quarantined).await?;
   392| 	let members: i64 = res["data"]["subscribers"].as_u64().unwrap_or_default() as i64;
   393| 	let active: i64 = res["data"]["accounts_active"].as_u64().unwrap_or_default() as i64;
   394| 	let community_icon: &str = res["data"]["community_icon"].as_str().unwrap_or_default();
   395| 	let icon = if community_icon.is_empty() { val(&res, "icon_img") } else { community_icon.to_string() };
   396| 	Ok(Subreddit {
   397| 		name: val(&res, "display_name"),
   398| 		title: val(&res, "title"),
   399| 		description: val(&res, "public_description"),
   400| 		info: rewrite_urls(&val(&res, "description_html")),
   401| 		icon: format_url(&icon),
   402| 		members: format_num(members),
   403| 		active: format_num(active),
   404| 		wiki: res["data"]["wiki_enabled"].as_bool().unwrap_or_default(),
   405| 		nsfw: res["data"]["over18"].as_bool().unwrap_or_default(),
   406| 	})
   407| }
   408| pub async fn rss(req: Request<Body>) -> Result<Response<Body>, String> {
   409| 	if config::get_setting("REDLIB_ENABLE_RSS").is_none() {
   410| 		return Ok(error(req, "RSS is disabled on this instance.").await.unwrap_or_default());
   411| 	}
   412| 	use hyper::header::CONTENT_TYPE;
   413| 	use rss::{ChannelBuilder, Item};
   414| 	let sub = req.param("sub").unwrap_or_default();
   415| 	let post_sort = req.cookie("post_sort").map_or_else(|| "hot".to_string(), |c| c.value().to_string());
   416| 	let sort = req.param("sort").unwrap_or_else(|| req.param("id").unwrap_or(post_sort));
   417| 	let path = format!("/r/{sub}/{sort}.json?{}", req.uri().query().unwrap_or_default());
   418| 	let subreddit = subreddit(&sub, false).await?;
   419| 	let (posts, _) = Post::fetch(&path, false).await?;
   420| 	let channel = ChannelBuilder::default()
   421| 		.title(&subreddit.title)
   422| 		.description(&subreddit.description)
   423| 		.items(
   424| 			posts
   425| 				.into_iter()
   426| 				.map(|post| Item {
   427| 					title: Some(post.title.to_string()),
   428| 					link: Some(format_url(&utils::get_post_url(&post))),
   429| 					author: Some(post.author.name),
   430| 					content: Some(rewrite_urls(&decode_html(&post.body).unwrap())),
   431| 					pub_date: Some(DateTime::from_timestamp(post.created_ts as i64, 0).unwrap_or_default().to_rfc2822()),
   432| 					description: Some(format!(
   433| 						"<a href='{}{}'>Comments</a>",
   434| 						config::get_setting("REDLIB_FULL_URL").unwrap_or_default(),
   435| 						post.permalink
   436| 					)),
   437| 					..Default::default()
   438| 				})
   439| 				.collect::<Vec<_>>(),
   440| 		)
   441| 		.build();
   442| 	let body = channel.to_string().into_bytes();
   443| 	let mut res = Response::new(Body::from(body));
   444| 	res.headers_mut().insert(CONTENT_TYPE, hyper::header::HeaderValue::from_static("application/rss+xml"));
   445| 	Ok(res)
   446| }
   447| #[tokio::test(flavor = "multi_thread")]
   448| async fn test_fetching_subreddit() {
   449| 	let subreddit = subreddit("rust", false).await;
   450| 	assert!(subreddit.is_ok());
   451| }
   452| #[tokio::test(flavor = "multi_thread")]
   453| async fn test_gated_and_quarantined() {
   454| 	let quarantined = subreddit("edgy", true).await;
   455| 	assert!(quarantined.is_ok());
   456| 	let gated = subreddit("drugs", true).await;
   457| 	assert!(gated.is_ok());
   458| }


# ====================================================================
# FILE: src/user.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-141 ---
     1| #![allow(clippy::cmp_owned)]
     2| use crate::client::json;
     3| use crate::server::RequestExt;
     4| use crate::utils::{error, filter_posts, format_url, get_filters, nsfw_landing, param, setting, template, Post, Preferences, User};
     5| use crate::{config, utils};
     6| use chrono::DateTime;
     7| use htmlescape::decode_html;
     8| use hyper::{Body, Request, Response};
     9| use rinja::Template;
    10| use time::{macros::format_description, OffsetDateTime};
    11| #[derive(Template)]
    12| #[template(path = "user.html")]
    13| struct UserTemplate {
    14| 	user: User,
    15| 	posts: Vec<Post>,
    16| 	sort: (String, String),
    17| 	ends: (String, String),
    18| 	listing: String,
    19| 	prefs: Preferences,
    20| 	url: String,
    21| 	redirect_url: String,
    22| 	is_filtered: bool,
    23| 	all_posts_filtered: bool,
    24| 	all_posts_hidden_nsfw: bool,
    25| 	no_posts: bool,
    26| }
    27| pub async fn profile(req: Request<Body>) -> Result<Response<Body>, String> {
    28| 	let listing = req.param("listing").unwrap_or_else(|| "overview".to_string());
    29| 	let path = format!(
    30| 		"/user/{}/{listing}.json?{}&raw_json=1",
    31| 		req.param("name").unwrap_or_else(|| "reddit".to_string()),
    32| 		req.uri().query().unwrap_or_default(),
    33| 	);
    34| 	let url = String::from(req.uri().path_and_query().map_or("", |val| val.as_str()));
    35| 	let redirect_url = url[1..].replace('?', "%3F").replace('&', "%26");
    36| 	let sort = param(&path, "sort").unwrap_or_default();
    37| 	let username = req.param("name").unwrap_or_default();
    38| 	let user = user(&username).await.unwrap_or_default();
    39| 	let req_url = req.uri().to_string();
    40| 	if user.nsfw && crate::utils::should_be_nsfw_gated(&req, &req_url) {
    41| 		return Ok(nsfw_landing(req, req_url).await.unwrap_or_default());
    42| 	}
    43| 	let filters = get_filters(&req);
    44| 	if filters.contains(&["u_", &username].concat()) {
    45| 		Ok(template(&UserTemplate {
    46| 			user,
    47| 			posts: Vec::new(),
    48| 			sort: (sort, param(&path, "t").unwrap_or_default()),
    49| 			ends: (param(&path, "after").unwrap_or_default(), String::new()),
    50| 			listing,
    51| 			prefs: Preferences::new(&req),
    52| 			url,
    53| 			redirect_url,
    54| 			is_filtered: true,
    55| 			all_posts_filtered: false,
    56| 			all_posts_hidden_nsfw: false,
    57| 			no_posts: false,
    58| 		}))
    59| 	} else {
    60| 		match Post::fetch(&path, false).await {
    61| 			Ok((mut posts, after)) => {
    62| 				let (_, all_posts_filtered) = filter_posts(&mut posts, &filters);
    63| 				let no_posts = posts.is_empty();
    64| 				let all_posts_hidden_nsfw = !no_posts && (posts.iter().all(|p| p.flags.nsfw) && setting(&req, "show_nsfw") != "on");
    65| 				Ok(template(&UserTemplate {
    66| 					user,
    67| 					posts,
    68| 					sort: (sort, param(&path, "t").unwrap_or_default()),
    69| 					ends: (param(&path, "after").unwrap_or_default(), after),
    70| 					listing,
    71| 					prefs: Preferences::new(&req),
    72| 					url,
    73| 					redirect_url,
    74| 					is_filtered: false,
    75| 					all_posts_filtered,
    76| 					all_posts_hidden_nsfw,
    77| 					no_posts,
    78| 				}))
    79| 			}
    80| 			Err(msg) => error(req, &msg).await,
    81| 		}
    82| 	}
    83| }
    84| async fn user(name: &str) -> Result<User, String> {
    85| 	let path: String = format!("/user/{name}/about.json?raw_json=1");
    86| 	json(path, false).await.map(|res| {
    87| 		let created_unix = res["data"]["created"].as_f64().unwrap_or(0.0).round() as i64;
    88| 		let created = OffsetDateTime::from_unix_timestamp(created_unix).unwrap_or(OffsetDateTime::UNIX_EPOCH);
    89| 		let about = |item| res["data"]["subreddit"][item].as_str().unwrap_or_default().to_string();
    90| 		User {
    91| 			name: res["data"]["name"].as_str().unwrap_or(name).to_owned(),
    92| 			title: about("title"),
    93| 			icon: format_url(&about("icon_img")),
    94| 			karma: res["data"]["total_karma"].as_i64().unwrap_or(0),
    95| 			created: created.format(format_description!("[month repr:short] [day] '[year repr:last_two]")).unwrap_or_default(),
    96| 			banner: about("banner_img"),
    97| 			description: about("public_description"),
    98| 			nsfw: res["data"]["subreddit"]["over_18"].as_bool().unwrap_or_default(),
    99| 		}
   100| 	})
   101| }
   102| pub async fn rss(req: Request<Body>) -> Result<Response<Body>, String> {
   103| 	if config::get_setting("REDLIB_ENABLE_RSS").is_none() {
   104| 		return Ok(error(req, "RSS is disabled on this instance.").await.unwrap_or_default());
   105| 	}
   106| 	use crate::utils::rewrite_urls;
   107| 	use hyper::header::CONTENT_TYPE;
   108| 	use rss::{ChannelBuilder, Item};
   109| 	let user_str = req.param("name").unwrap_or_default();
   110| 	let listing = req.param("listing").unwrap_or_else(|| "overview".to_string());
   111| 	let path = format!("/user/{user_str}/{listing}.json?{}&raw_json=1", req.uri().query().unwrap_or_default(),);
   112| 	let user_obj = user(&user_str).await.unwrap_or_default();
   113| 	let (posts, _) = Post::fetch(&path, false).await?;
   114| 	let channel = ChannelBuilder::default()
   115| 		.title(user_str)
   116| 		.description(user_obj.description)
   117| 		.items(
   118| 			posts
   119| 				.into_iter()
   120| 				.map(|post| Item {
   121| 					title: Some(post.title.to_string()),
   122| 					link: Some(format_url(&utils::get_post_url(&post))),
   123| 					author: Some(post.author.name),
   124| 					pub_date: Some(DateTime::from_timestamp(post.created_ts as i64, 0).unwrap_or_default().to_rfc2822()),
   125| 					content: Some(rewrite_urls(&decode_html(&post.body).unwrap())),
   126| 					..Default::default()
   127| 				})
   128| 				.collect::<Vec<_>>(),
   129| 		)
   130| 		.build();
   131| 	let body = channel.to_string().into_bytes();
   132| 	let mut res = Response::new(Body::from(body));
   133| 	res.headers_mut().insert(CONTENT_TYPE, hyper::header::HeaderValue::from_static("application/rss+xml"));
   134| 	Ok(res)
   135| }
   136| #[tokio::test(flavor = "multi_thread")]
   137| async fn test_fetching_user() {
   138| 	let user = user("spez").await;
   139| 	assert!(user.is_ok());
   140| 	assert!(user.unwrap().karma > 100);
   141| }


# ====================================================================
# FILE: src/utils.rs
# Total hunks: 19
# ====================================================================
# --- HUNK 1: Lines 1-167 ---
     1| #![allow(dead_code)]
     2| #![allow(clippy::cmp_owned)]
     3| use crate::config::{self, get_setting};
     4| use crate::{client::json, server::RequestExt};
     5| use cookie::Cookie;
     6| use hyper::{Body, Request, Response};
     7| use libflate::deflate::{Decoder, Encoder};
     8| use log::error;
     9| use once_cell::sync::Lazy;
    10| use regex::Regex;
    11| use revision::revisioned;
    12| use rinja::Template;
    13| use rust_embed::RustEmbed;
    14| use serde::{Deserialize, Deserializer, Serialize, Serializer};
    15| use serde_json::Value;
    16| use serde_json_path::{JsonPath, JsonPathExt};
    17| use std::collections::{HashMap, HashSet};
    18| use std::env;
    19| use std::io::{Read, Write};
    20| use std::str::FromStr;
    21| use std::string::ToString;
    22| use time::{macros::format_description, Duration, OffsetDateTime};
    23| use url::Url;
    24| #[macro_export]
    25| macro_rules! dbg_msg {
    26| 	($x:expr) => {
    27| 		#[cfg(debug_assertions)]
    28| 		eprintln!("{}:{}: {}", file!(), line!(), $x.to_string())
    29| 	};
    30| 	($($x:expr),+) => {
    31| 		#[cfg(debug_assertions)]
    32| 		dbg_msg!(format!($($x),+))
    33| 	};
    34| }
    35| #[derive(PartialEq, Eq)]
    36| pub enum ResourceType {
    37| 	Subreddit,
    38| 	User,
    39| 	Post,
    40| }
    41| #[derive(Serialize)]
    42| pub struct Flair {
    43| 	pub flair_parts: Vec<FlairPart>,
    44| 	pub text: String,
    45| 	pub background_color: String,
    46| 	pub foreground_color: String,
    47| }
    48| #[derive(Clone, Serialize)]
    49| pub struct FlairPart {
    50| 	pub flair_part_type: String,
    51| 	pub value: String,
    52| }
    53| impl FlairPart {
    54| 	pub fn parse(flair_type: &str, rich_flair: Option<&Vec<Value>>, text_flair: Option<&str>) -> Vec<Self> {
    55| 		match flair_type {
    56| 			"richtext" => match rich_flair {
    57| 				Some(rich) => rich
    58| 					.iter()
    59| 					.map(|part| {
    60| 						let value = |name: &str| part[name].as_str().unwrap_or_default();
    61| 						Self {
    62| 							flair_part_type: value("e").to_string(),
    63| 							value: match value("e") {
    64| 								"text" => value("t").to_string(),
    65| 								"emoji" => format_url(value("u")),
    66| 								_ => String::new(),
    67| 							},
    68| 						}
    69| 					})
    70| 					.collect::<Vec<Self>>(),
    71| 				None => Vec::new(),
    72| 			},
    73| 			"text" => match text_flair {
    74| 				Some(text) => vec![Self {
    75| 					flair_part_type: "text".to_string(),
    76| 					value: text.to_string(),
    77| 				}],
    78| 				None => Vec::new(),
    79| 			},
    80| 			_ => Vec::new(),
    81| 		}
    82| 	}
    83| }
    84| #[derive(Serialize)]
    85| pub struct Author {
    86| 	pub name: String,
    87| 	pub flair: Flair,
    88| 	pub distinguished: String,
    89| }
    90| #[derive(Serialize)]
    91| pub struct Poll {
    92| 	pub poll_options: Vec<PollOption>,
    93| 	pub voting_end_timestamp: (String, String),
    94| 	pub total_vote_count: u64,
    95| }
    96| impl Poll {
    97| 	pub fn parse(poll_data: &Value) -> Option<Self> {
    98| 		poll_data.as_object()?;
    99| 		let total_vote_count = poll_data["total_vote_count"].as_u64()?;
   100| 		let voting_end_timestamp = time(poll_data["voting_end_timestamp"].as_f64()? / 1000.0);
   101| 		let poll_options = PollOption::parse(&poll_data["options"])?;
   102| 		Some(Self {
   103| 			poll_options,
   104| 			voting_end_timestamp,
   105| 			total_vote_count,
   106| 		})
   107| 	}
   108| 	pub fn most_votes(&self) -> u64 {
   109| 		self.poll_options.iter().filter_map(|o| o.vote_count).max().unwrap_or(0)
   110| 	}
   111| }
   112| #[derive(Serialize)]
   113| pub struct PollOption {
   114| 	pub id: u64,
   115| 	pub text: String,
   116| 	pub vote_count: Option<u64>,
   117| }
   118| impl PollOption {
   119| 	pub fn parse(options: &Value) -> Option<Vec<Self>> {
   120| 		Some(
   121| 			options
   122| 				.as_array()?
   123| 				.iter()
   124| 				.filter_map(|option| {
   125| 					let id = option["id"].as_str()?.parse::<u64>().ok()?;
   126| 					let text = option["text"].as_str()?.to_owned();
   127| 					let vote_count = option["vote_count"].as_u64();
   128| 					Some(Self { id, text, vote_count })
   129| 				})
   130| 				.collect::<Vec<Self>>(),
   131| 		)
   132| 	}
   133| }
   134| #[derive(Serialize)]
   135| pub struct Flags {
   136| 	pub spoiler: bool,
   137| 	pub nsfw: bool,
   138| 	pub stickied: bool,
   139| }
   140| #[derive(Debug, Serialize)]
   141| pub struct Media {
   142| 	pub url: String,
   143| 	pub alt_url: String,
   144| 	pub width: i64,
   145| 	pub height: i64,
   146| 	pub poster: String,
   147| 	pub download_name: String,
   148| }
   149| impl Media {
   150| 	pub async fn parse(data: &Value) -> (String, Self, Vec<GalleryMedia>) {
   151| 		let mut gallery = Vec::new();
   152| 		let data_preview = &data["preview"]["reddit_video_preview"];
   153| 		let secure_media = &data["secure_media"]["reddit_video"];
   154| 		let crosspost_parent_media = &data["crosspost_parent_list"][0]["secure_media"]["reddit_video"];
   155| 		let (post_type, url_val, alt_url_val) = if data_preview["fallback_url"].is_string() {
   156| 			(
   157| 				if data_preview["is_gif"].as_bool().unwrap_or(false) { "gif" } else { "video" },
   158| 				&data_preview["fallback_url"],
   159| 				Some(&data_preview["hls_url"]),
   160| 			)
   161| 		} else if secure_media["fallback_url"].is_string() {
   162| 			(
   163| 				if secure_media["is_gif"].as_bool().unwrap_or(false) { "gif" } else { "video" },
   164| 				&secure_media["fallback_url"],
   165| 				Some(&secure_media["hls_url"]),
   166| 			)
   167| 		} else if crosspost_parent_media["fallback_url"].is_string() {

# --- HUNK 2: Lines 170-304 ---
   170| 				&crosspost_parent_media["fallback_url"],
   171| 				Some(&crosspost_parent_media["hls_url"]),
   172| 			)
   173| 		} else if data["post_hint"].as_str().unwrap_or("") == "image" {
   174| 			let preview = &data["preview"]["images"][0];
   175| 			let mp4 = &preview["variants"]["mp4"];
   176| 			if mp4.is_object() {
   177| 				("gif", &mp4["source"]["url"], None)
   178| 			} else {
   179| 				if data["domain"] == "i.redd.it" {
   180| 					("image", &data["url"], None)
   181| 				} else {
   182| 					("image", &preview["source"]["url"], None)
   183| 				}
   184| 			}
   185| 		} else if data["is_self"].as_bool().unwrap_or_default() {
   186| 			("self", &data["permalink"], None)
   187| 		} else if data["is_gallery"].as_bool().unwrap_or_default() {
   188| 			gallery = GalleryMedia::parse(&data["gallery_data"]["items"], &data["media_metadata"]);
   189| 			("gallery", &data["url"], None)
   190| 		} else if data["crosspost_parent_list"][0]["is_gallery"].as_bool().unwrap_or_default() {
   191| 			gallery = GalleryMedia::parse(
   192| 				&data["crosspost_parent_list"][0]["gallery_data"]["items"],
   193| 				&data["crosspost_parent_list"][0]["media_metadata"],
   194| 			);
   195| 			("gallery", &data["url"], None)
   196| 		} else if data["is_reddit_media_domain"].as_bool().unwrap_or_default() && data["domain"] == "i.redd.it" {
   197| 			("image", &data["url"], None)
   198| 		} else {
   199| 			("link", &data["url"], None)
   200| 		};
   201| 		let source = &data["preview"]["images"][0]["source"];
   202| 		let alt_url = alt_url_val.map_or(String::new(), |val| format_url(val.as_str().unwrap_or_default()));
   203| 		let download_name = if post_type == "image" || post_type == "gif" || post_type == "video" {
   204| 			let permalink_base = url_path_basename(data["permalink"].as_str().unwrap_or_default());
   205| 			let media_url_base = url_path_basename(url_val.as_str().unwrap_or_default());
   206| 			format!("redlib_{permalink_base}_{media_url_base}")
   207| 		} else {
   208| 			String::new()
   209| 		};
   210| 		(
   211| 			post_type.to_string(),
   212| 			Self {
   213| 				url: format_url(url_val.as_str().unwrap_or_default()),
   214| 				alt_url,
   215| 				width: source["width"].as_i64().unwrap_or_default(),
   216| 				height: source["height"].as_i64().unwrap_or_default(),
   217| 				poster: format_url(source["url"].as_str().unwrap_or_default()),
   218| 				download_name,
   219| 			},
   220| 			gallery,
   221| 		)
   222| 	}
   223| }
   224| #[derive(Serialize)]
   225| pub struct GalleryMedia {
   226| 	pub url: String,
   227| 	pub width: i64,
   228| 	pub height: i64,
   229| 	pub caption: String,
   230| 	pub outbound_url: String,
   231| }
   232| impl GalleryMedia {
   233| 	fn parse(items: &Value, metadata: &Value) -> Vec<Self> {
   234| 		items
   235| 			.as_array()
   236| 			.unwrap_or(&Vec::new())
   237| 			.iter()
   238| 			.map(|item| {
   239| 				let media_id = item["media_id"].as_str().unwrap_or_default();
   240| 				let image = &metadata[media_id]["s"];
   241| 				let image_type = &metadata[media_id]["m"];
   242| 				let url = if image_type == "image/gif" {
   243| 					image["gif"].as_str().unwrap_or_default()
   244| 				} else {
   245| 					image["u"].as_str().unwrap_or_default()
   246| 				};
   247| 				Self {
   248| 					url: format_url(url),
   249| 					width: image["x"].as_i64().unwrap_or_default(),
   250| 					height: image["y"].as_i64().unwrap_or_default(),
   251| 					caption: item["caption"].as_str().unwrap_or_default().to_string(),
   252| 					outbound_url: item["outbound_url"].as_str().unwrap_or_default().to_string(),
   253| 				}
   254| 			})
   255| 			.collect::<Vec<Self>>()
   256| 	}
   257| }
   258| #[derive(Serialize)]
   259| pub struct Post {
   260| 	pub id: String,
   261| 	pub title: String,
   262| 	pub community: String,
   263| 	pub body: String,
   264| 	pub author: Author,
   265| 	pub permalink: String,
   266| 	pub link_title: String,
   267| 	pub poll: Option<Poll>,
   268| 	pub score: (String, String),
   269| 	pub upvote_ratio: i64,
   270| 	pub post_type: String,
   271| 	pub flair: Flair,
   272| 	pub flags: Flags,
   273| 	pub thumbnail: Media,
   274| 	pub media: Media,
   275| 	pub domain: String,
   276| 	pub rel_time: String,
   277| 	pub created: String,
   278| 	pub created_ts: u64,
   279| 	pub num_duplicates: u64,
   280| 	pub comments: (String, String),
   281| 	pub gallery: Vec<GalleryMedia>,
   282| 	pub awards: Awards,
   283| 	pub nsfw: bool,
   284| 	pub out_url: Option<String>,
   285| 	pub ws_url: String,
   286| }
   287| impl Post {
   288| 	pub async fn fetch(path: &str, quarantine: bool) -> Result<(Vec<Self>, String), String> {
   289| 		let res = match json(path.to_string(), quarantine).await {
   290| 			Ok(response) => response,
   291| 			Err(msg) => return Err(msg),
   292| 		};
   293| 		let Some(post_list) = res["data"]["children"].as_array() else {
   294| 			return Err("No posts found".to_string());
   295| 		};
   296| 		let mut posts: Vec<Self> = Vec::new();
   297| 		for post in post_list {
   298| 			let data = &post["data"];
   299| 			let (rel_time, created) = time(data["created_utc"].as_f64().unwrap_or_default());
   300| 			let created_ts = data["created_utc"].as_f64().unwrap_or_default().round() as u64;
   301| 			let score = data["score"].as_i64().unwrap_or_default();
   302| 			let ratio: f64 = data["upvote_ratio"].as_f64().unwrap_or(1.0) * 100.0;
   303| 			let title = val(post, "title");
   304| 			let (post_type, media, gallery) = Media::parse(data).await;

# --- HUNK 3: Lines 322-818 ---
   322| 						),
   323| 						text: val(post, "link_flair_text"),
   324| 						background_color: val(post, "author_flair_background_color"),
   325| 						foreground_color: val(post, "author_flair_text_color"),
   326| 					},
   327| 					distinguished: val(post, "distinguished"),
   328| 				},
   329| 				score: if data["hide_score"].as_bool().unwrap_or_default() {
   330| 					("\u{2022}".to_string(), "Hidden".to_string())
   331| 				} else {
   332| 					format_num(score)
   333| 				},
   334| 				upvote_ratio: ratio as i64,
   335| 				post_type,
   336| 				thumbnail: Media {
   337| 					url: format_url(val(post, "thumbnail").as_str()),
   338| 					alt_url: String::new(),
   339| 					width: data["thumbnail_width"].as_i64().unwrap_or_default(),
   340| 					height: data["thumbnail_height"].as_i64().unwrap_or_default(),
   341| 					poster: String::new(),
   342| 					download_name: String::new(),
   343| 				},
   344| 				media,
   345| 				domain: val(post, "domain"),
   346| 				flair: Flair {
   347| 					flair_parts: FlairPart::parse(
   348| 						data["link_flair_type"].as_str().unwrap_or_default(),
   349| 						data["link_flair_richtext"].as_array(),
   350| 						data["link_flair_text"].as_str(),
   351| 					),
   352| 					text: val(post, "link_flair_text"),
   353| 					background_color: val(post, "link_flair_background_color"),
   354| 					foreground_color: if val(post, "link_flair_text_color") == "dark" {
   355| 						"black".to_string()
   356| 					} else {
   357| 						"white".to_string()
   358| 					},
   359| 				},
   360| 				flags: Flags {
   361| 					spoiler: data["spoiler"].as_bool().unwrap_or_default(),
   362| 					nsfw: data["over_18"].as_bool().unwrap_or_default(),
   363| 					stickied: data["stickied"].as_bool().unwrap_or_default() || data["pinned"].as_bool().unwrap_or_default(),
   364| 				},
   365| 				permalink: val(post, "permalink"),
   366| 				link_title: val(post, "link_title"),
   367| 				poll: Poll::parse(&data["poll_data"]),
   368| 				rel_time,
   369| 				created,
   370| 				created_ts,
   371| 				num_duplicates: post["data"]["num_duplicates"].as_u64().unwrap_or(0),
   372| 				comments: format_num(data["num_comments"].as_i64().unwrap_or_default()),
   373| 				gallery,
   374| 				awards,
   375| 				nsfw: post["data"]["over_18"].as_bool().unwrap_or_default(),
   376| 				ws_url: val(post, "websocket_url"),
   377| 				out_url: post["data"]["url_overridden_by_dest"].as_str().map(|a| a.to_string()),
   378| 			});
   379| 		}
   380| 		Ok((posts, res["data"]["after"].as_str().unwrap_or_default().to_string()))
   381| 	}
   382| }
   383| #[derive(Template)]
   384| #[template(path = "comment.html")]
   385| pub struct Comment {
   386| 	pub id: String,
   387| 	pub kind: String,
   388| 	pub parent_id: String,
   389| 	pub parent_kind: String,
   390| 	pub post_link: String,
   391| 	pub post_author: String,
   392| 	pub body: String,
   393| 	pub author: Author,
   394| 	pub score: (String, String),
   395| 	pub rel_time: String,
   396| 	pub created: String,
   397| 	pub edited: (String, String),
   398| 	pub replies: Vec<Comment>,
   399| 	pub highlighted: bool,
   400| 	pub awards: Awards,
   401| 	pub collapsed: bool,
   402| 	pub is_filtered: bool,
   403| 	pub more_count: i64,
   404| 	pub prefs: Preferences,
   405| }
   406| #[derive(Default, Clone, Serialize)]
   407| pub struct Award {
   408| 	pub name: String,
   409| 	pub icon_url: String,
   410| 	pub description: String,
   411| 	pub count: i64,
   412| }
   413| impl std::fmt::Display for Award {
   414| 	fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
   415| 		write!(f, "{} {} {}", self.name, self.icon_url, self.description)
   416| 	}
   417| }
   418| #[derive(Serialize)]
   419| pub struct Awards(pub Vec<Award>);
   420| impl std::ops::Deref for Awards {
   421| 	type Target = Vec<Award>;
   422| 	fn deref(&self) -> &Self::Target {
   423| 		&self.0
   424| 	}
   425| }
   426| impl std::fmt::Display for Awards {
   427| 	fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
   428| 		self.iter().try_fold((), |_, award| writeln!(f, "{award}"))
   429| 	}
   430| }
   431| impl Awards {
   432| 	pub fn parse(items: &Value) -> Self {
   433| 		let parsed = items.as_array().unwrap_or(&Vec::new()).iter().fold(Vec::new(), |mut awards, item| {
   434| 			let name = item["name"].as_str().unwrap_or_default().to_string();
   435| 			let icon_url = format_url(item["resized_icons"][0]["url"].as_str().unwrap_or_default());
   436| 			let description = item["description"].as_str().unwrap_or_default().to_string();
   437| 			let count: i64 = i64::from_str(&item["count"].to_string()).unwrap_or(1);
   438| 			awards.push(Award {
   439| 				name,
   440| 				icon_url,
   441| 				description,
   442| 				count,
   443| 			});
   444| 			awards
   445| 		});
   446| 		Self(parsed)
   447| 	}
   448| }
   449| #[derive(Template)]
   450| #[template(path = "error.html")]
   451| pub struct ErrorTemplate {
   452| 	pub msg: String,
   453| 	pub prefs: Preferences,
   454| 	pub url: String,
   455| }
   456| #[derive(Template)]
   457| #[template(path = "info.html")]
   458| pub struct InfoTemplate {
   459| 	pub msg: String,
   460| 	pub prefs: Preferences,
   461| 	pub url: String,
   462| }
   463| #[derive(Template)]
   464| #[template(path = "nsfwlanding.html")]
   465| pub struct NSFWLandingTemplate {
   466| 	pub res: String,
   467| 	pub res_type: ResourceType,
   468| 	pub prefs: Preferences,
   469| 	pub url: String,
   470| }
   471| #[derive(Default)]
   472| pub struct User {
   473| 	pub name: String,
   474| 	pub title: String,
   475| 	pub icon: String,
   476| 	pub karma: i64,
   477| 	pub created: String,
   478| 	pub banner: String,
   479| 	pub description: String,
   480| 	pub nsfw: bool,
   481| }
   482| #[derive(Default)]
   483| pub struct Subreddit {
   484| 	pub name: String,
   485| 	pub title: String,
   486| 	pub description: String,
   487| 	pub info: String,
   488| 	pub icon: String,
   489| 	pub members: (String, String),
   490| 	pub active: (String, String),
   491| 	pub wiki: bool,
   492| 	pub nsfw: bool,
   493| }
   494| #[derive(serde::Deserialize)]
   495| pub struct Params {
   496| 	pub t: Option<String>,
   497| 	pub q: Option<String>,
   498| 	pub sort: Option<String>,
   499| 	pub after: Option<String>,
   500| 	pub before: Option<String>,
   501| }
   502| #[derive(Default, Serialize, Deserialize, Debug, PartialEq, Eq)]
   503| #[revisioned(revision = 1)]
   504| pub struct Preferences {
   505| 	#[revision(start = 1)]
   506| 	#[serde(skip_serializing, skip_deserializing)]
   507| 	pub available_themes: Vec<String>,
   508| 	#[revision(start = 1)]
   509| 	pub theme: String,
   510| 	#[revision(start = 1)]
   511| 	pub front_page: String,
   512| 	#[revision(start = 1)]
   513| 	pub layout: String,
   514| 	#[revision(start = 1)]
   515| 	pub wide: String,
   516| 	#[revision(start = 1)]
   517| 	pub blur_spoiler: String,
   518| 	#[revision(start = 1)]
   519| 	pub show_nsfw: String,
   520| 	#[revision(start = 1)]
   521| 	pub blur_nsfw: String,
   522| 	#[revision(start = 1)]
   523| 	pub hide_hls_notification: String,
   524| 	#[revision(start = 1)]
   525| 	pub video_quality: String,
   526| 	#[revision(start = 1)]
   527| 	pub hide_sidebar_and_summary: String,
   528| 	#[revision(start = 1)]
   529| 	pub use_hls: String,
   530| 	#[revision(start = 1)]
   531| 	pub autoplay_videos: String,
   532| 	#[revision(start = 1)]
   533| 	pub fixed_navbar: String,
   534| 	#[revision(start = 1)]
   535| 	pub disable_visit_reddit_confirmation: String,
   536| 	#[revision(start = 1)]
   537| 	pub comment_sort: String,
   538| 	#[revision(start = 1)]
   539| 	pub post_sort: String,
   540| 	#[revision(start = 1)]
   541| 	#[serde(serialize_with = "serialize_vec_with_plus", deserialize_with = "deserialize_vec_with_plus")]
   542| 	pub subscriptions: Vec<String>,
   543| 	#[revision(start = 1)]
   544| 	#[serde(serialize_with = "serialize_vec_with_plus", deserialize_with = "deserialize_vec_with_plus")]
   545| 	pub filters: Vec<String>,
   546| 	#[revision(start = 1)]
   547| 	pub hide_awards: String,
   548| 	#[revision(start = 1)]
   549| 	pub hide_score: String,
   550| 	#[revision(start = 1)]
   551| 	pub remove_default_feeds: String,
   552| }
   553| fn serialize_vec_with_plus<S>(vec: &[String], serializer: S) -> Result<S::Ok, S::Error>
   554| where
   555| 	S: Serializer,
   556| {
   557| 	serializer.serialize_str(&vec.join("+"))
   558| }
   559| fn deserialize_vec_with_plus<'de, D>(deserializer: D) -> Result<Vec<String>, D::Error>
   560| where
   561| 	D: Deserializer<'de>,
   562| {
   563| 	let string = String::deserialize(deserializer)?;
   564| 	if string.is_empty() {
   565| 		return Ok(Vec::new());
   566| 	}
   567| 	Ok(string.split('+').map(|s| s.to_string()).collect())
   568| }
   569| #[derive(RustEmbed)]
   570| #[folder = "static/themes/"]
   571| #[include = "*.css"]
   572| pub struct ThemeAssets;
   573| impl Preferences {
   574| 	pub fn new(req: &Request<Body>) -> Self {
   575| 		let mut themes = vec!["system".to_string()];
   576| 		for file in ThemeAssets::iter() {
   577| 			let chunks: Vec<&str> = file.as_ref().split(".css").collect();
   578| 			themes.push(chunks[0].to_owned());
   579| 		}
   580| 		Self {
   581| 			available_themes: themes,
   582| 			theme: setting(req, "theme"),
   583| 			front_page: setting(req, "front_page"),
   584| 			layout: setting(req, "layout"),
   585| 			wide: setting(req, "wide"),
   586| 			blur_spoiler: setting(req, "blur_spoiler"),
   587| 			show_nsfw: setting(req, "show_nsfw"),
   588| 			hide_sidebar_and_summary: setting(req, "hide_sidebar_and_summary"),
   589| 			blur_nsfw: setting(req, "blur_nsfw"),
   590| 			use_hls: setting(req, "use_hls"),
   591| 			hide_hls_notification: setting(req, "hide_hls_notification"),
   592| 			video_quality: setting(req, "video_quality"),
   593| 			autoplay_videos: setting(req, "autoplay_videos"),
   594| 			fixed_navbar: setting_or_default(req, "fixed_navbar", "on".to_string()),
   595| 			disable_visit_reddit_confirmation: setting(req, "disable_visit_reddit_confirmation"),
   596| 			comment_sort: setting(req, "comment_sort"),
   597| 			post_sort: setting(req, "post_sort"),
   598| 			subscriptions: setting(req, "subscriptions").split('+').map(String::from).filter(|s| !s.is_empty()).collect(),
   599| 			filters: setting(req, "filters").split('+').map(String::from).filter(|s| !s.is_empty()).collect(),
   600| 			hide_awards: setting(req, "hide_awards"),
   601| 			hide_score: setting(req, "hide_score"),
   602| 			remove_default_feeds: setting(req, "remove_default_feeds"),
   603| 		}
   604| 	}
   605| 	pub fn to_urlencoded(&self) -> Result<String, String> {
   606| 		serde_urlencoded::to_string(self).map_err(|e| e.to_string())
   607| 	}
   608| 	pub fn to_bincode(&self) -> Result<Vec<u8>, String> {
   609| 		bincode::serialize(self).map_err(|e| e.to_string())
   610| 	}
   611| 	pub fn to_compressed_bincode(&self) -> Result<Vec<u8>, String> {
   612| 		deflate_compress(self.to_bincode()?)
   613| 	}
   614| 	pub fn to_bincode_str(&self) -> Result<String, String> {
   615| 		Ok(base2048::encode(&self.to_compressed_bincode()?))
   616| 	}
   617| }
   618| pub fn deflate_compress(i: Vec<u8>) -> Result<Vec<u8>, String> {
   619| 	let mut e = Encoder::new(Vec::new());
   620| 	e.write_all(&i).map_err(|e| e.to_string())?;
   621| 	e.finish().into_result().map_err(|e| e.to_string())
   622| }
   623| pub fn deflate_decompress(i: Vec<u8>) -> Result<Vec<u8>, String> {
   624| 	let mut decoder = Decoder::new(&i[..]);
   625| 	let mut out = Vec::new();
   626| 	decoder.read_to_end(&mut out).map_err(|e| format!("Failed to read from gzip decoder: {}", e))?;
   627| 	Ok(out)
   628| }
   629| pub fn get_filters(req: &Request<Body>) -> HashSet<String> {
   630| 	setting(req, "filters").split('+').map(String::from).filter(|s| !s.is_empty()).collect::<HashSet<String>>()
   631| }
   632| pub fn filter_posts(posts: &mut Vec<Post>, filters: &HashSet<String>) -> (u64, bool) {
   633| 	let lb: u64 = posts.len().try_into().unwrap_or(0);
   634| 	if posts.is_empty() {
   635| 		(0, false)
   636| 	} else {
   637| 		posts.retain(|p| !(filters.contains(&p.community) || filters.contains(&["u_", &p.author.name].concat())));
   638| 		let la: u64 = posts.len().try_into().unwrap_or(0);
   639| 		(lb - la, posts.is_empty())
   640| 	}
   641| }
   642| pub async fn parse_post(post: &Value) -> Post {
   643| 	let (rel_time, created) = time(post["data"]["created_utc"].as_f64().unwrap_or_default());
   644| 	let score = post["data"]["score"].as_i64().unwrap_or_default();
   645| 	let ratio: f64 = post["data"]["upvote_ratio"].as_f64().unwrap_or(1.0) * 100.0;
   646| 	let (post_type, media, gallery) = Media::parse(&post["data"]).await;
   647| 	let created_ts = post["data"]["created_utc"].as_f64().unwrap_or_default().round() as u64;
   648| 	let awards: Awards = Awards::parse(&post["data"]["all_awardings"]);
   649| 	let permalink = val(post, "permalink");
   650| 	let poll = Poll::parse(&post["data"]["poll_data"]);
   651| 	let body = if val(post, "removed_by_category") == "moderator" {
   652| 		format!(
   653| 			"<div class=\"md\"><p>[removed]  <a href=\"https://{}{permalink}\">view removed post</a></p></div>",
   654| 			get_setting("REDLIB_PUSHSHIFT_FRONTEND").unwrap_or_else(|| String::from(crate::config::DEFAULT_PUSHSHIFT_FRONTEND)),
   655| 		)
   656| 	} else {
   657| 		let selftext = val(post, "selftext");
   658| 		if selftext.contains("```") {
   659| 			let mut html_output = String::new();
   660| 			let parser = pulldown_cmark::Parser::new(&selftext);
   661| 			pulldown_cmark::html::push_html(&mut html_output, parser);
   662| 			rewrite_urls(&html_output)
   663| 		} else {
   664| 			rewrite_urls(&val(post, "selftext_html"))
   665| 		}
   666| 	};
   667| 	Post {
   668| 		id: val(post, "id"),
   669| 		title: val(post, "title"),
   670| 		community: val(post, "subreddit"),
   671| 		body,
   672| 		author: Author {
   673| 			name: val(post, "author"),
   674| 			flair: Flair {
   675| 				flair_parts: FlairPart::parse(
   676| 					post["data"]["author_flair_type"].as_str().unwrap_or_default(),
   677| 					post["data"]["author_flair_richtext"].as_array(),
   678| 					post["data"]["author_flair_text"].as_str(),
   679| 				),
   680| 				text: val(post, "link_flair_text"),
   681| 				background_color: val(post, "author_flair_background_color"),
   682| 				foreground_color: val(post, "author_flair_text_color"),
   683| 			},
   684| 			distinguished: val(post, "distinguished"),
   685| 		},
   686| 		permalink,
   687| 		link_title: val(post, "link_title"),
   688| 		poll,
   689| 		score: format_num(score),
   690| 		upvote_ratio: ratio as i64,
   691| 		post_type,
   692| 		media,
   693| 		thumbnail: Media {
   694| 			url: format_url(val(post, "thumbnail").as_str()),
   695| 			alt_url: String::new(),
   696| 			width: post["data"]["thumbnail_width"].as_i64().unwrap_or_default(),
   697| 			height: post["data"]["thumbnail_height"].as_i64().unwrap_or_default(),
   698| 			poster: String::new(),
   699| 			download_name: String::new(),
   700| 		},
   701| 		flair: Flair {
   702| 			flair_parts: FlairPart::parse(
   703| 				post["data"]["link_flair_type"].as_str().unwrap_or_default(),
   704| 				post["data"]["link_flair_richtext"].as_array(),
   705| 				post["data"]["link_flair_text"].as_str(),
   706| 			),
   707| 			text: val(post, "link_flair_text"),
   708| 			background_color: val(post, "link_flair_background_color"),
   709| 			foreground_color: if val(post, "link_flair_text_color") == "dark" {
   710| 				"black".to_string()
   711| 			} else {
   712| 				"white".to_string()
   713| 			},
   714| 		},
   715| 		flags: Flags {
   716| 			spoiler: post["data"]["spoiler"].as_bool().unwrap_or_default(),
   717| 			nsfw: post["data"]["over_18"].as_bool().unwrap_or_default(),
   718| 			stickied: post["data"]["stickied"].as_bool().unwrap_or_default() || post["data"]["pinned"].as_bool().unwrap_or(false),
   719| 		},
   720| 		domain: val(post, "domain"),
   721| 		rel_time,
   722| 		created,
   723| 		created_ts,
   724| 		num_duplicates: post["data"]["num_duplicates"].as_u64().unwrap_or(0),
   725| 		comments: format_num(post["data"]["num_comments"].as_i64().unwrap_or_default()),
   726| 		gallery,
   727| 		awards,
   728| 		nsfw: post["data"]["over_18"].as_bool().unwrap_or_default(),
   729| 		ws_url: val(post, "websocket_url"),
   730| 		out_url: post["data"]["url_overridden_by_dest"].as_str().map(|a| a.to_string()),
   731| 	}
   732| }
   733| pub fn param(path: &str, value: &str) -> Option<String> {
   734| 	Some(
   735| 		Url::parse(format!("https://libredd.it/{path}").as_str())
   736| 			.ok()?
   737| 			.query_pairs()
   738| 			.into_owned()
   739| 			.collect::<HashMap<_, _>>()
   740| 			.get(value)?
   741| 			.clone(),
   742| 	)
   743| }
   744| pub fn setting(req: &Request<Body>, name: &str) -> String {
   745| 	if name == "subscriptions" && req.cookie("subscriptions").is_some() {
   746| 		let mut subscriptions = String::new();
   747| 		if req.cookie("subscriptions").is_some() {
   748| 			subscriptions.push_str(req.cookie("subscriptions").unwrap().value());
   749| 		}
   750| 		let mut subscriptions_number = 1;
   751| 		while req.cookie(&format!("subscriptions{}", subscriptions_number)).is_some() {
   752| 			subscriptions.push_str(req.cookie(&format!("subscriptions{}", subscriptions_number)).unwrap().value());
   753| 			subscriptions_number += 1;
   754| 		}
   755| 		subscriptions
   756| 	}
   757| 	else if name == "filters" && req.cookie("filters").is_some() {
   758| 		let mut filters = String::new();
   759| 		if req.cookie("filters").is_some() {
   760| 			filters.push_str(req.cookie("filters").unwrap().value());
   761| 		}
   762| 		let mut filters_number = 1;
   763| 		while req.cookie(&format!("filters{}", filters_number)).is_some() {
   764| 			filters.push_str(req.cookie(&format!("filters{}", filters_number)).unwrap().value());
   765| 			filters_number += 1;
   766| 		}
   767| 		filters
   768| 	}
   769| 	else {
   770| 		req
   771| 			.cookie(name)
   772| 			.unwrap_or_else(|| {
   773| 				if let Some(default) = get_setting(&format!("REDLIB_DEFAULT_{}", name.to_uppercase())) {
   774| 					Cookie::new(name, default)
   775| 				} else {
   776| 					Cookie::from(name)
   777| 				}
   778| 			})
   779| 			.value()
   780| 			.to_string()
   781| 	}
   782| }
   783| pub fn setting_or_default(req: &Request<Body>, name: &str, default: String) -> String {
   784| 	let value = setting(req, name);
   785| 	if value.is_empty() {
   786| 		default
   787| 	} else {
   788| 		value
   789| 	}
   790| }
   791| pub async fn catch_random(sub: &str, additional: &str) -> Result<Response<Body>, String> {
   792| 	if sub == "random" || sub == "randnsfw" {
   793| 		Ok(redirect(&format!(
   794| 			"/r/{}{additional}",
   795| 			json(format!("/r/{sub}/about.json?raw_json=1"), false).await?["data"]["display_name"]
   796| 				.as_str()
   797| 				.unwrap_or_default()
   798| 		)))
   799| 	} else {
   800| 		Err("No redirect needed".to_string())
   801| 	}
   802| }
   803| static REGEX_URL_WWW: Lazy<Regex> = Lazy::new(|| Regex::new(r"https?://www\.reddit\.com/(.*)").unwrap());
   804| static REGEX_URL_OLD: Lazy<Regex> = Lazy::new(|| Regex::new(r"https?://old\.reddit\.com/(.*)").unwrap());
   805| static REGEX_URL_NP: Lazy<Regex> = Lazy::new(|| Regex::new(r"https?://np\.reddit\.com/(.*)").unwrap());
   806| static REGEX_URL_PLAIN: Lazy<Regex> = Lazy::new(|| Regex::new(r"https?://reddit\.com/(.*)").unwrap());
   807| static REGEX_URL_VIDEOS: Lazy<Regex> = Lazy::new(|| Regex::new(r"https?://v\.redd\.it/(.*)/DASH_([0-9]{2,4}(\.mp4|$|\?source=fallback))").unwrap());
   808| static REGEX_URL_VIDEOS_HLS: Lazy<Regex> = Lazy::new(|| Regex::new(r"https?://v\.redd\.it/(.+)/(HLSPlaylist\.m3u8.*)$").unwrap());
   809| static REGEX_URL_IMAGES: Lazy<Regex> = Lazy::new(|| Regex::new(r"https?://i\.redd\.it/(.*)").unwrap());
   810| static REGEX_URL_THUMBS_A: Lazy<Regex> = Lazy::new(|| Regex::new(r"https?://a\.thumbs\.redditmedia\.com/(.*)").unwrap());
   811| static REGEX_URL_THUMBS_B: Lazy<Regex> = Lazy::new(|| Regex::new(r"https?://b\.thumbs\.redditmedia\.com/(.*)").unwrap());
   812| static REGEX_URL_EMOJI: Lazy<Regex> = Lazy::new(|| Regex::new(r"https?://emoji\.redditmedia\.com/(.*)/(.*)").unwrap());
   813| static REGEX_URL_PREVIEW: Lazy<Regex> = Lazy::new(|| Regex::new(r"https?://preview\.redd\.it/(.*)").unwrap());
   814| static REGEX_URL_EXTERNAL_PREVIEW: Lazy<Regex> = Lazy::new(|| Regex::new(r"https?://external\-preview\.redd\.it/(.*)").unwrap());
   815| static REGEX_URL_STYLES: Lazy<Regex> = Lazy::new(|| Regex::new(r"https?://styles\.redditmedia\.com/(.*)").unwrap());
   816| static REGEX_URL_STATIC_MEDIA: Lazy<Regex> = Lazy::new(|| Regex::new(r"https?://www\.redditstatic\.com/(.*)").unwrap());
   817| pub fn format_url(url: &str) -> String {
   818| 	if url.is_empty() || url == "self" || url == "default" || url == "nsfw" || url == "spoiler" {

# --- HUNK 4: Lines 848-998 ---
   848| 			}
   849| 			match domain {
   850| 				"www.reddit.com" => capture(&REGEX_URL_WWW, "/", 1),
   851| 				"old.reddit.com" => capture(&REGEX_URL_OLD, "/", 1),
   852| 				"np.reddit.com" => capture(&REGEX_URL_NP, "/", 1),
   853| 				"reddit.com" => capture(&REGEX_URL_PLAIN, "/", 1),
   854| 				"v.redd.it" => chain!(capture(&REGEX_URL_VIDEOS, "/vid/", 2), capture(&REGEX_URL_VIDEOS_HLS, "/hls/", 2)),
   855| 				"i.redd.it" => capture(&REGEX_URL_IMAGES, "/img/", 1),
   856| 				"a.thumbs.redditmedia.com" => capture(&REGEX_URL_THUMBS_A, "/thumb/a/", 1),
   857| 				"b.thumbs.redditmedia.com" => capture(&REGEX_URL_THUMBS_B, "/thumb/b/", 1),
   858| 				"emoji.redditmedia.com" => capture(&REGEX_URL_EMOJI, "/emoji/", 2),
   859| 				"preview.redd.it" => capture(&REGEX_URL_PREVIEW, "/preview/pre/", 1),
   860| 				"external-preview.redd.it" => capture(&REGEX_URL_EXTERNAL_PREVIEW, "/preview/external-pre/", 1),
   861| 				"styles.redditmedia.com" => capture(&REGEX_URL_STYLES, "/style/", 1),
   862| 				"www.redditstatic.com" => capture(&REGEX_URL_STATIC_MEDIA, "/static/", 1),
   863| 				_ => url.to_string(),
   864| 			}
   865| 		})
   866| 	}
   867| }
   868| static REGEX_BULLET: Lazy<Regex> = Lazy::new(|| Regex::new(r"(?m)^- (.*)$").unwrap());
   869| static REGEX_BULLET_CONSECUTIVE_LINES: Lazy<Regex> = Lazy::new(|| Regex::new(r"</ul>\n<ul>").unwrap());
   870| pub fn render_bullet_lists(input_text: &str) -> String {
   871| 	let text1 = REGEX_BULLET.replace_all(input_text, "<ul><li>$1</li></ul>").to_string();
   872| 	REGEX_BULLET_CONSECUTIVE_LINES.replace_all(&text1, "").to_string()
   873| }
   874| static REDDIT_REGEX: Lazy<Regex> = Lazy::new(|| Regex::new(r#"href="(https|http|)://(www\.|old\.|np\.|amp\.|new\.|)(reddit\.com|redd\.it)/"#).unwrap());
   875| static REDDIT_PREVIEW_REGEX: Lazy<Regex> = Lazy::new(|| Regex::new(r"https?://(external-preview|preview|i)\.redd\.it(.*)").unwrap());
   876| static REDDIT_EMOJI_REGEX: Lazy<Regex> = Lazy::new(|| Regex::new(r"https?://(www|).redditstatic\.com/(.*)").unwrap());
   877| static REDLIB_PREVIEW_LINK_REGEX: Lazy<Regex> = Lazy::new(|| Regex::new(r#"/(img|preview/)(pre|external-pre)?/(.*?)>"#).unwrap());
   878| static REDLIB_PREVIEW_TEXT_REGEX: Lazy<Regex> = Lazy::new(|| Regex::new(r">(.*?)</a>").unwrap());
   879| pub fn rewrite_urls(input_text: &str) -> String {
   880| 	let mut text1 =
   881| 		REDDIT_REGEX.replace_all(input_text, r#"href="/"#).to_string();
   882| 	loop {
   883| 		if REDDIT_EMOJI_REGEX.find(&text1).is_none() {
   884| 			break;
   885| 		} else {
   886| 			text1 = REDDIT_EMOJI_REGEX
   887| 				.replace_all(&text1, format_url(REDDIT_EMOJI_REGEX.find(&text1).map(|x| x.as_str()).unwrap_or_default()))
   888| 				.to_string()
   889| 		}
   890| 	}
   891| 	text1 = text1.replace("%5C", "").replace("\\_", "_");
   892| 	loop {
   893| 		if REDDIT_PREVIEW_REGEX.find(&text1).is_none() {
   894| 			return text1;
   895| 		} else {
   896| 			let formatted_url = format_url(REDDIT_PREVIEW_REGEX.find(&text1).map(|x| x.as_str()).unwrap_or_default());
   897| 			let image_url = REDLIB_PREVIEW_LINK_REGEX.find(&formatted_url).map_or("", |m| m.as_str());
   898| 			let mut image_caption = REDLIB_PREVIEW_TEXT_REGEX.find(&formatted_url).map_or("", |m| m.as_str());
   899| 			/* As long as image_caption isn't empty remove first and last four characters of image_text to leave us with just the text in the caption without any HTML.
   900| 			This makes it possible to enclose it in a <figcaption> later on without having stray HTML breaking it */
   901| 			if !image_caption.is_empty() {
   902| 				image_caption = &image_caption[1..image_caption.len() - 4];
   903| 			}
   904| 			let image_to_replace = format!("<p><a href=\"{image_url}{image_caption}</a></p>");
   905| 			/* We don't want to show a caption that's just the image's link, so we check if we find a Reddit preview link within the image's caption.
   906| 			If we don't find one we must have actual text, so we include a <figcaption> block that contains it.
   907| 			Otherwise we don't include the <figcaption> block as we don't need it. */
   908| 			let _image_replacement = if REDDIT_PREVIEW_REGEX.find(image_caption).is_none() {
   909| 				format!(
   910| 					"<figure><a href=\"{image_url}<img loading=\"lazy\" src=\"{image_url}</a><figcaption>{}</figcaption></figure>",
   911| 					image_caption.replace("\\&quot;", "\"")
   912| 				)
   913| 			} else {
   914| 				format!("<figure><a href=\"{image_url}<img loading=\"lazy\" src=\"{image_url}</a></figure>")
   915| 			};
   916| 			/* In order to know if we're dealing with a normal or external preview we need to take a look at the first capture group of REDDIT_PREVIEW_REGEX
   917| 			if it's preview we're dealing with something that needs /preview/pre, external-preview is /preview/external-pre, and i is /img */
   918| 			let reddit_preview_regex_capture = REDDIT_PREVIEW_REGEX.captures(&text1).unwrap().get(1).map_or("", |m| m.as_str());
   919| 			let _preview_type = match reddit_preview_regex_capture {
   920| 				"preview" => "/preview/pre",
   921| 				"external-preview" => "/preview/external-pre",
   922| 				_ => "/img",
   923| 			};
   924| 			text1 = REDDIT_PREVIEW_REGEX
   925| 				.replace(&text1, format!("{_preview_type}$2"))
   926| 				.replace(&image_to_replace, &_image_replacement)
   927| 		}
   928| 	}
   929| }
   930| static REDDIT_EMOTE_LINK_REGEX: Lazy<Regex> = Lazy::new(|| Regex::new(r#"https://reddit-econ-prod-assets-permanent.s3.amazonaws.com/asset-manager/(.*)"#).unwrap());
   931| static REDDIT_EMOTE_ID_NUMBER_REGEX: Lazy<Regex> = Lazy::new(|| Regex::new(r#""emote\|.*\|(.*)""#).unwrap());
   932| pub fn rewrite_emotes(media_metadata: &Value, comment: String) -> String {
   933| 	/* Create the paths we'll use to look for our data inside the json.
   934| 	Because we don't know the name of any given emote we use a wildcard to parse them. */
   935| 	let link_path = JsonPath::parse("$[*].s.u").expect("valid JSON Path");
   936| 	let id_path = JsonPath::parse("$[*].id").expect("valid JSON Path");
   937| 	let size_path = JsonPath::parse("$[*].s.y").expect("valid JSON Path");
   938| 	let link_nodes = media_metadata.json_path(&link_path);
   939| 	let id_nodes = media_metadata.json_path(&id_path);
   940| 	let mut id_vec = Vec::new();
   941| 	let mut link_vec = Vec::new();
   942| 	for current_id in id_nodes {
   943| 		id_vec.push(current_id)
   944| 	}
   945| 	for current_link in link_nodes {
   946| 		link_vec.push(current_link)
   947| 	}
   948| 	/* Set index to the length of link_vec.
   949| 	This is one larger than we'll actually be looking at, but we correct that later */
   950| 	let mut index = link_vec.len();
   951| 	let mut comment = comment;
   952| 	/* Loop until index hits zero.
   953| 	This also prevents us from trying to do anything on an empty vector */
   954| 	while index != 0 {
   955| 		/* Subtract 1 from index to get the real index we should be looking at.
   956| 		Then continue on each subsequent loop to continue until we hit the last entry in the vector.
   957| 		This is how we get this to deal with multiple emotes in a single message and properly replace each ID with it's link */
   958| 		index -= 1;
   959| 		let current_id = id_vec[index].to_string();
   960| 		/* The ID number can be multiple lengths, so we capture it with regex.
   961| 		We also want to only attempt anything when we get matches to avoid panicking */
   962| 		if let Some(id_capture) = REDDIT_EMOTE_ID_NUMBER_REGEX.captures(&current_id) {
   963| 			let id = format!(":{}:", &id_capture[1]);
   964| 			let link = link_vec[index].to_string();
   965| 			if let Some(link_capture) = REDDIT_EMOTE_LINK_REGEX.captures(&link) {
   966| 				/* Reddit sends a size for the image based on whether it's alone or accompanied by text.
   967| 				It's a good idea and makes everything look nicer, so we'll do the same. */
   968| 				let size = media_metadata.json_path(&size_path).first().unwrap().to_string();
   969| 				let to_replace_with = format!(
   970| 					"<img loading=\"lazy\" src=\"/emote/{} width=\"{size}\" height=\"{size}\" style=\"vertical-align:text-bottom\">",
   971| 					&link_capture[1]
   972| 				);
   973| 				comment = comment.replace(&id, &to_replace_with);
   974| 			}
   975| 		}
   976| 	}
   977| 	comment = render_bullet_lists(&comment);
   978| 	rewrite_urls(&comment)
   979| }
   980| pub fn format_num(num: i64) -> (String, String) {
   981| 	let truncated = if num >= 1_000_000 || num <= -1_000_000 {
   982| 		format!("{:.1}m", num as f64 / 1_000_000.0)
   983| 	} else if num >= 1000 || num <= -1000 {
   984| 		format!("{:.1}k", num as f64 / 1_000.0)
   985| 	} else {
   986| 		num.to_string()
   987| 	};
   988| 	(truncated, num.to_string())
   989| }
   990| pub fn time(created: f64) -> (String, String) {
   991| 	let time = OffsetDateTime::from_unix_timestamp(created.round() as i64).unwrap_or(OffsetDateTime::UNIX_EPOCH);
   992| 	let now = OffsetDateTime::now_utc();
   993| 	let min = time.min(now);
   994| 	let max = time.max(now);
   995| 	let time_delta = max - min;
   996| 	let mut rel_time = if time_delta > Duration::days(30) {
   997| 		time.format(format_description!("[month repr:short] [day] '[year repr:last_two]")).unwrap_or_default()
   998| 	} else if time_delta.whole_days() > 0 {

# --- HUNK 5: Lines 1029-1149 ---
  1029| pub fn redirect(path: &str) -> Response<Body> {
  1030| 	Response::builder()
  1031| 		.status(302)
  1032| 		.header("content-type", "text/html")
  1033| 		.header("Location", path)
  1034| 		.body(format!("Redirecting to <a href=\"{path}\">{path}</a>...").into())
  1035| 		.unwrap_or_default()
  1036| }
  1037| pub async fn error(req: Request<Body>, msg: &str) -> Result<Response<Body>, String> {
  1038| 	error!("Error page rendered: {}", msg.split('|').next().unwrap_or_default());
  1039| 	let url = req.uri().to_string();
  1040| 	let body = ErrorTemplate {
  1041| 		msg: msg.to_string(),
  1042| 		prefs: Preferences::new(&req),
  1043| 		url,
  1044| 	}
  1045| 	.render()
  1046| 	.unwrap_or_default();
  1047| 	Ok(Response::builder().status(404).header("content-type", "text/html").body(body.into()).unwrap_or_default())
  1048| }
  1049| pub async fn info(req: Request<Body>, msg: &str) -> Result<Response<Body>, String> {
  1050| 	let url = req.uri().to_string();
  1051| 	let body = InfoTemplate {
  1052| 		msg: msg.to_string(),
  1053| 		prefs: Preferences::new(&req),
  1054| 		url,
  1055| 	}
  1056| 	.render()
  1057| 	.unwrap_or_default();
  1058| 	Ok(Response::builder().status(200).header("content-type", "text/html").body(body.into()).unwrap_or_default())
  1059| }
  1060| pub fn sfw_only() -> bool {
  1061| 	match get_setting("REDLIB_SFW_ONLY") {
  1062| 		Some(val) => val == "on",
  1063| 		None => false,
  1064| 	}
  1065| }
  1066| pub fn enable_rss() -> bool {
  1067| 	match get_setting("REDLIB_ENABLE_RSS") {
  1068| 		Some(val) => val == "on",
  1069| 		None => false,
  1070| 	}
  1071| }
  1072| pub fn disable_indexing() -> bool {
  1073| 	match get_setting("REDLIB_ROBOTS_DISABLE_INDEXING") {
  1074| 		Some(val) => val == "on",
  1075| 		None => false,
  1076| 	}
  1077| }
  1078| pub fn should_be_nsfw_gated(req: &Request<Body>, req_url: &str) -> bool {
  1079| 	let sfw_instance = sfw_only();
  1080| 	let gate_nsfw = (setting(req, "show_nsfw") != "on") || sfw_instance;
  1081| 	let bypass_gate = !sfw_instance && req_url.contains("&bypass_nsfw_landing");
  1082| 	gate_nsfw && !bypass_gate
  1083| }
  1084| pub async fn nsfw_landing(req: Request<Body>, req_url: String) -> Result<Response<Body>, String> {
  1085| 	let res_type: ResourceType;
  1086| 	let resource: String = if !req.param("name").unwrap_or_default().is_empty() {
  1087| 		res_type = ResourceType::User;
  1088| 		req.param("name").unwrap_or_default()
  1089| 	} else if !req.param("id").unwrap_or_default().is_empty() {
  1090| 		res_type = ResourceType::Post;
  1091| 		req.param("id").unwrap_or_default()
  1092| 	} else {
  1093| 		res_type = ResourceType::Subreddit;
  1094| 		req.param("sub").unwrap_or_default()
  1095| 	};
  1096| 	let body = NSFWLandingTemplate {
  1097| 		res: resource,
  1098| 		res_type,
  1099| 		prefs: Preferences::new(&req),
  1100| 		url: req_url,
  1101| 	}
  1102| 	.render()
  1103| 	.unwrap_or_default();
  1104| 	Ok(Response::builder().status(403).header("content-type", "text/html").body(body.into()).unwrap_or_default())
  1105| }
  1106| pub fn url_path_basename(path: &str) -> String {
  1107| 	let url_result = Url::parse(format!("https://libredd.it/{path}").as_str());
  1108| 	if url_result.is_err() {
  1109| 		path.to_string()
  1110| 	} else {
  1111| 		let mut url = url_result.unwrap();
  1112| 		url.path_segments_mut().unwrap().pop_if_empty();
  1113| 		url.path_segments().unwrap().next_back().unwrap().to_string()
  1114| 	}
  1115| }
  1116| pub fn get_post_url(post: &Post) -> String {
  1117| 	if let Some(out_url) = &post.out_url {
  1118| 		if out_url.starts_with("/r/") {
  1119| 			format!("{}{}", config::get_setting("REDLIB_FULL_URL").unwrap_or_default(), out_url)
  1120| 		} else {
  1121| 			out_url.to_string()
  1122| 		}
  1123| 	} else {
  1124| 		format!("{}{}", config::get_setting("REDLIB_FULL_URL").unwrap_or_default(), post.permalink)
  1125| 	}
  1126| }
  1127| #[cfg(test)]
  1128| mod tests {
  1129| 	use super::{format_num, format_url, rewrite_urls, Preferences};
  1130| 	#[test]
  1131| 	fn format_num_works() {
  1132| 		assert_eq!(format_num(567), ("567".to_string(), "567".to_string()));
  1133| 		assert_eq!(format_num(1234), ("1.2k".to_string(), "1234".to_string()));
  1134| 		assert_eq!(format_num(1999), ("2.0k".to_string(), "1999".to_string()));
  1135| 		assert_eq!(format_num(1001), ("1.0k".to_string(), "1001".to_string()));
  1136| 		assert_eq!(format_num(1_999_999), ("2.0m".to_string(), "1999999".to_string()));
  1137| 	}
  1138| 	#[test]
  1139| 	fn rewrite_urls_removes_backslashes_and_rewrites_url() {
  1140| 		assert_eq!(
  1141| 			rewrite_urls(
  1142| 				"<a href=\"https://new.reddit.com/r/linux%5C_gaming/comments/x/just%5C_a%5C_test%5C/\">https://new.reddit.com/r/linux\\_gaming/comments/x/just\\_a\\_test/</a>"
  1143| 			),
  1144| 			"<a href=\"/r/linux_gaming/comments/x/just_a_test/\">https://new.reddit.com/r/linux_gaming/comments/x/just_a_test/</a>"
  1145| 		);
  1146| 		assert_eq!(
  1147| 			rewrite_urls(
  1148| 				"e.g. &lt;a href=\"https://www.reddit.com/r/linux%5C_gaming/comments/ql9j15/anyone%5C_else%5C_confused%5C_with%5C_linus%5C_linux%5C_issues/\"&gt;https://www.reddit.com/r/linux\\_gaming/comments/ql9j15/anyone\\_else\\_confused\\_with\\_linus\\_linux\\_issues/&lt;/a&gt;"
  1149| 			),

# --- HUNK 6: Lines 1169-1333 ---
  1169| 		assert_eq!(
  1170| 			format_url("https://preview.redd.it/qwerty.jpg?auto=webp&s=asdf"),
  1171| 			"/preview/pre/qwerty.jpg?auto=webp&s=asdf"
  1172| 		);
  1173| 		assert_eq!(format_url("https://v.redd.it/foo/DASH_360.mp4?source=fallback"), "/vid/foo/360.mp4");
  1174| 		assert_eq!(
  1175| 			format_url("https://v.redd.it/foo/HLSPlaylist.m3u8?a=bar&v=1&f=sd"),
  1176| 			"/hls/foo/HLSPlaylist.m3u8?a=bar&v=1&f=sd"
  1177| 		);
  1178| 		assert_eq!(format_url("https://www.redditstatic.com/gold/awards/icon/icon.png"), "/static/gold/awards/icon/icon.png");
  1179| 		assert_eq!(
  1180| 			format_url("https://www.redditstatic.com/marketplace-assets/v1/core/emotes/snoomoji_emotes/free_emotes_pack/shrug.gif"),
  1181| 			"/static/marketplace-assets/v1/core/emotes/snoomoji_emotes/free_emotes_pack/shrug.gif"
  1182| 		);
  1183| 		assert_eq!(format_url(""), "");
  1184| 		assert_eq!(format_url("self"), "");
  1185| 		assert_eq!(format_url("default"), "");
  1186| 		assert_eq!(format_url("nsfw"), "");
  1187| 		assert_eq!(format_url("spoiler"), "");
  1188| 	}
  1189| 	#[test]
  1190| 	fn serialize_prefs() {
  1191| 		let prefs = Preferences {
  1192| 			available_themes: vec![],
  1193| 			theme: "laserwave".to_owned(),
  1194| 			front_page: "default".to_owned(),
  1195| 			layout: "compact".to_owned(),
  1196| 			wide: "on".to_owned(),
  1197| 			blur_spoiler: "on".to_owned(),
  1198| 			show_nsfw: "off".to_owned(),
  1199| 			blur_nsfw: "on".to_owned(),
  1200| 			hide_hls_notification: "off".to_owned(),
  1201| 			video_quality: "best".to_owned(),
  1202| 			hide_sidebar_and_summary: "off".to_owned(),
  1203| 			use_hls: "on".to_owned(),
  1204| 			autoplay_videos: "on".to_owned(),
  1205| 			fixed_navbar: "on".to_owned(),
  1206| 			disable_visit_reddit_confirmation: "on".to_owned(),
  1207| 			comment_sort: "confidence".to_owned(),
  1208| 			post_sort: "top".to_owned(),
  1209| 			subscriptions: vec!["memes".to_owned(), "mildlyinteresting".to_owned()],
  1210| 			filters: vec![],
  1211| 			hide_awards: "off".to_owned(),
  1212| 			hide_score: "off".to_owned(),
  1213| 			remove_default_feeds: "off".to_owned(),
  1214| 		};
  1215| 		let urlencoded = serde_urlencoded::to_string(prefs).expect("Failed to serialize Prefs");
  1216| 		assert_eq!(urlencoded, "theme=laserwave&front_page=default&layout=compact&wide=on&blur_spoiler=on&show_nsfw=off&blur_nsfw=on&hide_hls_notification=off&video_quality=best&hide_sidebar_and_summary=off&use_hls=on&autoplay_videos=on&fixed_navbar=on&disable_visit_reddit_confirmation=on&comment_sort=confidence&post_sort=top&subscriptions=memes%2Bmildlyinteresting&filters=&hide_awards=off&hide_score=off&remove_default_feeds=off");
  1217| 	}
  1218| }
  1219| #[test]
  1220| fn test_rewriting_emoji() {
  1221| 	let input = r#"<div class="md"><p>How can you have such hard feelings towards a license? <img src="https://www.redditstatic.com/marketplace-assets/v1/core/emotes/snoomoji_emotes/free_emotes_pack/shrug.gif" width="20" height="20" style="vertical-align:middle"> Let people use what license they want, and BSD is one of the least restrictive ones AFAIK.</p>"#;
  1222| 	let output = r#"<div class="md"><p>How can you have such hard feelings towards a license? <img src="/static/marketplace-assets/v1/core/emotes/snoomoji_emotes/free_emotes_pack/shrug.gif" width="20" height="20" style="vertical-align:middle"> Let people use what license they want, and BSD is one of the least restrictive ones AFAIK.</p>"#;
  1223| 	assert_eq!(rewrite_urls(input), output);
  1224| }
  1225| #[tokio::test(flavor = "multi_thread")]
  1226| async fn test_fetching_subreddit_quarantined() {
  1227| 	let subreddit = Post::fetch("/r/drugs", true).await;
  1228| 	assert!(subreddit.is_ok());
  1229| 	assert!(!subreddit.unwrap().0.is_empty());
  1230| }
  1231| #[tokio::test(flavor = "multi_thread")]
  1232| async fn test_fetching_nsfw_subreddit() {
  1233| 	let subreddit = Post::fetch("/r/gonwild", false).await;
  1234| 	assert!(subreddit.is_ok());
  1235| 	assert!(!subreddit.unwrap().0.is_empty());
  1236| }
  1237| #[tokio::test(flavor = "multi_thread")]
  1238| async fn test_fetching_ws() {
  1239| 	let subreddit = Post::fetch("/r/popular", false).await;
  1240| 	assert!(subreddit.is_ok());
  1241| 	for post in subreddit.unwrap().0 {
  1242| 		assert!(post.ws_url.starts_with("wss://k8s-lb.wss.redditmedia.com/link/"));
  1243| 	}
  1244| }
  1245| #[test]
  1246| fn test_rewriting_image_links() {
  1247| 	let input =
  1248| 		r#"<p><a href="https://preview.redd.it/6awags382xo31.png?width=2560&amp;format=png&amp;auto=webp&amp;s=9c563aed4f07a91bdd249b5a3cea43a79710dcfc">caption 1</a></p>"#;
  1249| 	let output = r#"<figure><a href="/preview/pre/6awags382xo31.png?width=2560&amp;format=png&amp;auto=webp&amp;s=9c563aed4f07a91bdd249b5a3cea43a79710dcfc"><img loading="lazy" src="/preview/pre/6awags382xo31.png?width=2560&amp;format=png&amp;auto=webp&amp;s=9c563aed4f07a91bdd249b5a3cea43a79710dcfc"></a><figcaption>caption 1</figcaption></figure>"#;
  1250| 	assert_eq!(rewrite_urls(input), output);
  1251| }
  1252| #[test]
  1253| fn test_url_path_basename() {
  1254| 	assert_eq!(url_path_basename("/first/last"), "last");
  1255| 	assert_eq!(url_path_basename("/first/last/"), "last");
  1256| 	assert_eq!(url_path_basename("/first/last/?some=query"), "last");
  1257| 	assert_eq!(url_path_basename("/cdn/image.jpg"), "image.jpg");
  1258| 	assert_eq!(url_path_basename("https://doma.in/first/last"), "last");
  1259| 	assert_eq!(url_path_basename("/"), "");
  1260| }
  1261| #[test]
  1262| fn test_rewriting_emotes() {
  1263| 	let json_input = serde_json::from_str(r#"{"emote|t5_31hpy|2028":{"e":"Image","id":"emote|t5_31hpy|2028","m":"image/png","s":{"u":"https://reddit-econ-prod-assets-permanent.s3.amazonaws.com/asset-manager/t5_31hpy/PW6WsOaLcd.png","x":60,"y":60},"status":"valid","t":"sticker"}}"#).expect("Valid JSON");
  1264| 	let comment_input = r#"<div class="comment_body "><div class="md"><p>:2028:</p></div></div>"#;
  1265| 	let output = r#"<div class="comment_body "><div class="md"><p><img loading="lazy" src="/emote/t5_31hpy/PW6WsOaLcd.png" width="60" height="60" style="vertical-align:text-bottom"></p></div></div>"#;
  1266| 	assert_eq!(rewrite_emotes(&json_input, comment_input.to_string()), output);
  1267| }
  1268| #[test]
  1269| fn test_rewriting_bullet_list() {
  1270| 	let input = r#"<div class="md"><p>Hi, I&#39;ve bought this very same monitor and found no calibration whatsoever. I have an ICC profile that has been set up since I&#39;ve installed its driver from the LG website and it works ok. I also used <a href="http://www.lagom.nl/lcd-test/">http://www.lagom.nl/lcd-test/</a> to calibrate it. After some good tinkering I&#39;ve found the following settings + the color profile from the driver gets me past all the tests perfectly:
  1271| - Brightness 50 (still have to settle on this one, it&#39;s personal preference, it controls the backlight, not the colors)
  1272| - Contrast 70 (which for me was the default one)
  1273| - Picture mode Custom
  1274| - Super resolution + Off (it looks horrible anyway)
  1275| - Sharpness 50 (default one I think)
  1276| - Black level High (low messes up gray colors)
  1277| - DFC Off 
  1278| - Response Time Middle (personal preference, <a href="https://www.blurbusters.com/">https://www.blurbusters.com/</a> show horrible overdrive with it on high)
  1279| - Freesync doesn&#39;t matter
  1280| - Black stabilizer 50
  1281| - Gamma setting on 0 
  1282| - Color Temp Medium
  1283| How`s your monitor by the way? Any IPS bleed whatsoever? I either got lucky or the panel is pretty good, 0 bleed for me, just the usual IPS glow. How about the pixels? I see the pixels even at one meter away, especially on Microsoft Edge&#39;s icon for example, the blue background is just blocky, don&#39;t know why.</p>
  1284| </div>"#;
  1285| 	let output = r#"<div class="md"><p>Hi, I&#39;ve bought this very same monitor and found no calibration whatsoever. I have an ICC profile that has been set up since I&#39;ve installed its driver from the LG website and it works ok. I also used <a href="http://www.lagom.nl/lcd-test/">http://www.lagom.nl/lcd-test/</a> to calibrate it. After some good tinkering I&#39;ve found the following settings + the color profile from the driver gets me past all the tests perfectly:
  1286| <ul><li>Brightness 50 (still have to settle on this one, it&#39;s personal preference, it controls the backlight, not the colors)</li><li>Contrast 70 (which for me was the default one)</li><li>Picture mode Custom</li><li>Super resolution + Off (it looks horrible anyway)</li><li>Sharpness 50 (default one I think)</li><li>Black level High (low messes up gray colors)</li><li>DFC Off </li><li>Response Time Middle (personal preference, <a href="https://www.blurbusters.com/">https://www.blurbusters.com/</a> show horrible overdrive with it on high)</li><li>Freesync doesn&#39;t matter</li><li>Black stabilizer 50</li><li>Gamma setting on 0 </li><li>Color Temp Medium</li></ul>
  1287| How`s your monitor by the way? Any IPS bleed whatsoever? I either got lucky or the panel is pretty good, 0 bleed for me, just the usual IPS glow. How about the pixels? I see the pixels even at one meter away, especially on Microsoft Edge&#39;s icon for example, the blue background is just blocky, don&#39;t know why.</p>
  1288| </div>"#;
  1289| 	assert_eq!(render_bullet_lists(input), output);
  1290| }
  1291| #[test]
  1292| fn test_default_prefs_serialization_loop_json() {
  1293| 	let prefs = Preferences::default();
  1294| 	let serialized = serde_json::to_string(&prefs).unwrap();
  1295| 	let deserialized: Preferences = serde_json::from_str(&serialized).unwrap();
  1296| 	assert_eq!(prefs, deserialized);
  1297| }
  1298| #[test]
  1299| fn test_default_prefs_serialization_loop_bincode() {
  1300| 	let prefs = Preferences::default();
  1301| 	test_round_trip(&prefs, false);
  1302| 	test_round_trip(&prefs, true);
  1303| }
  1304| static KNOWN_GOOD_CONFIGS: &[&str] = &[
  1305| 	"",
  1306| 	"",
  1307| 	"",
  1308| ];
  1309| #[test]
  1310| fn test_known_good_configs_deserialization() {
  1311| 	for config in KNOWN_GOOD_CONFIGS {
  1312| 		let bytes = base2048::decode(config).unwrap();
  1313| 		let decompressed = deflate_decompress(bytes).unwrap();
  1314| 		assert!(bincode::deserialize::<Preferences>(&decompressed).is_ok());
  1315| 	}
  1316| }
  1317| #[test]
  1318| fn test_known_good_configs_full_round_trip() {
  1319| 	for config in KNOWN_GOOD_CONFIGS {
  1320| 		let bytes = base2048::decode(config).unwrap();
  1321| 		let decompressed = deflate_decompress(bytes).unwrap();
  1322| 		let prefs: Preferences = bincode::deserialize(&decompressed).unwrap();
  1323| 		test_round_trip(&prefs, false);
  1324| 		test_round_trip(&prefs, true);
  1325| 	}
  1326| }
  1327| fn test_round_trip(input: &Preferences, compression: bool) {
  1328| 	let serialized = bincode::serialize(input).unwrap();
  1329| 	let compressed = if compression { deflate_compress(serialized).unwrap() } else { serialized };
  1330| 	let decompressed = if compression { deflate_decompress(compressed).unwrap() } else { compressed };
  1331| 	let deserialized: Preferences = bincode::deserialize(&decompressed).unwrap();
  1332| 	assert_eq!(*input, deserialized);
  1333| }


# ====================================================================
# FILE: static/check_update.js
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-48 ---
     1| async function checkInstanceUpdateStatus() {
     2|     try {
     3|         const response = await fetch('/commits.atom');
     4|         const text = await response.text();
     5|         const parser = new DOMParser();
     6|         const xmlDoc = parser.parseFromString(text, "application/xml");
     7|         const entries = xmlDoc.getElementsByTagName('entry');
     8|         const localCommit = document.getElementById('git_commit').dataset.value;
     9|         let statusMessage = '';
    10|         if (entries.length > 0) {
    11|             const commitHashes = Array.from(entries).map(entry => {
    12|                 const id = entry.getElementsByTagName('id')[0].textContent;
    13|                 return id.split('/').pop();
    14|             });
    15|             const commitIndex = commitHashes.indexOf(localCommit);
    16|             if (commitIndex === 0) {
    17|                 statusMessage = ' Instance is up to date.';
    18|             } else if (commitIndex > 0) {
    19|                 statusMessage = ` This instance is not up to date and is ${commitIndex} commits old. Test and confirm on an up-to-date instance before reporting.`;
    20|                 document.getElementById('error-318').remove();
    21|             } else {
    22|                 statusMessage = ` This instance is not up to date and is at least ${commitHashes.length} commits old. Test and confirm on an up-to-date instance before reporting.`;
    23|                 document.getElementById('error-318').remove();
    24|             }
    25|         } else {
    26|             statusMessage = ' Unable to fetch commit information.';
    27|         }
    28|         document.getElementById('update-status').innerText = statusMessage;
    29|     } catch (error) {
    30|         console.error('Error fetching commits:', error);
    31|         document.getElementById('update-status').innerText = ' Error checking update status: ' + error;
    32|     }
    33| }
    34| async function checkOtherInstances() {
    35|     try {
    36|         const response = await fetch('/instances.json');
    37|         const data = await response.json();
    38|         const randomInstance = data.instances[Math.floor(Math.random() * data.instances.length)];
    39|         const instanceUrl = randomInstance.url;
    40|         document.getElementById('random-instance').href = instanceUrl + window.location.pathname;
    41|         document.getElementById('random-instance').innerText = "Visit Random Instance";
    42|     } catch (error) {
    43|         console.error('Error fetching instances:', error);
    44|         document.getElementById('update-status').innerText = ' Error checking other instances: ' + error;
    45|     }
    46| }
    47| window.addEventListener('load', checkOtherInstances);
    48| checkInstanceUpdateStatus();


# ====================================================================
# FILE: static/copy.js
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-7 ---
     1| async function copy() {
     2|     await navigator.clipboard.writeText(document.getElementById('bincode_str').value);
     3| }
     4| async function set_listener() {
     5|     document.getElementById('copy').addEventListener('click', copy);
     6| }
     7| window.addEventListener('load', set_listener);


# ====================================================================
# FILE: static/playHLSVideo.js
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-105 ---
     1| (function () {
     2|     const configElement = document.getElementById('video_quality');
     3|     const qualitySetting = configElement.getAttribute('data-value');
     4|     if (Hls.isSupported()) {
     5|         var videoSources = document.querySelectorAll("video source[type='application/vnd.apple.mpegurl']");
     6|         videoSources.forEach(function (source) {
     7|             var playlist = source.src;
     8|             var oldVideo = source.parentNode;
     9|             var autoplay = oldVideo.classList.contains("hls_autoplay");
    10|             if (oldVideo.canPlayType(source.type) === "probably") {
    11|                 if (autoplay) {
    12|                     oldVideo.play();
    13|                 }
    14|                 return;
    15|             }
    16|             var newVideo = oldVideo.cloneNode(true);
    17|             var allSources = newVideo.querySelectorAll("source");
    18|             allSources.forEach(function (source) {
    19|                 source.remove();
    20|             });
    21|             newVideo.src = "about:blank";
    22|             oldVideo.parentNode.replaceChild(newVideo, oldVideo);
    23|             function getIndexOfDefault(length) {
    24|                 switch (qualitySetting) {
    25|                     case 'best':
    26|                         return length - 1;
    27|                     case 'medium':
    28|                         return Math.floor(length / 2);
    29|                     case 'worst':
    30|                         return 0;
    31|                     default:
    32|                         return length - 1;
    33|                 }
    34|             }
    35|             function initializeHls() {
    36|                 newVideo.removeEventListener('play', initializeHls);
    37|                 var hls = new Hls({ autoStartLoad: false });
    38|                 hls.loadSource(playlist);
    39|                 hls.attachMedia(newVideo);
    40|                 hls.on(Hls.Events.MANIFEST_PARSED, function () {
    41|                     hls.loadLevel = getIndexOfDefault(hls.levels.length);
    42|                     var availableLevels = hls.levels.map(function(level) {
    43|                         return {
    44|                             height: level.height,
    45|                             width: level.width,
    46|                             bitrate: level.bitrate,
    47|                         };
    48|                     });
    49|                     addQualitySelector(newVideo, hls, availableLevels);
    50|                     hls.startLoad();
    51|                     newVideo.play();
    52|                 });
    53|                 hls.on(Hls.Events.ERROR, function (event, data) {
    54|                     var errorType = data.type;
    55|                     var errorFatal = data.fatal;
    56|                     if (errorFatal) {
    57|                         switch (errorType) {
    58|                             case Hls.ErrorType.NETWORK_ERROR:
    59|                                 hls.startLoad();
    60|                                 break;
    61|                             case Hls.ErrorType.MEDIA_ERROR:
    62|                                 hls.recoverMediaError();
    63|                                 break;
    64|                             default:
    65|                                 hls.destroy();
    66|                                 break;
    67|                         }
    68|                     }
    69|                     console.error("HLS error", data);
    70|                 });
    71|             }
    72|             function addQualitySelector(videoElement, hlsInstance, availableLevels) {
    73|                 var qualitySelector = document.createElement('select');
    74|                 qualitySelector.classList.add('quality-selector');
    75|                 var defaultIndex = getIndexOfDefault(availableLevels.length);
    76|                 availableLevels.forEach(function (level, index) {
    77|                     var option = document.createElement('option');
    78|                     option.value = index.toString();
    79|                     var bitrate = (level.bitrate / 1_000).toFixed(0);
    80|                     option.text = level.height + 'p (' + bitrate + ' kbps)';
    81|                     if (index === defaultIndex) {
    82|                         option.selected = "selected";
    83|                     }
    84|                     qualitySelector.appendChild(option);
    85|                 });
    86|                 qualitySelector.selectedIndex = defaultIndex;
    87|                 qualitySelector.addEventListener('change', function () {
    88|                     var selectedIndex = qualitySelector.selectedIndex;
    89|                     hlsInstance.nextLevel = selectedIndex;
    90|                     hlsInstance.startLoad();
    91|                 });
    92|                 videoElement.parentNode.appendChild(qualitySelector);
    93|             }
    94|             newVideo.addEventListener('play', initializeHls);
    95|             if (autoplay) {
    96|                 newVideo.play();
    97|             }
    98|         });
    99|     } else {
   100|         var videos = document.querySelectorAll("video.hls_autoplay");
   101|         videos.forEach(function (video) {
   102|             video.setAttribute("autoplay", "");
   103|         });
   104|     }
   105| })();

