# ====================================================================
# FILE: arrow/src/array/array_binary.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 986-1033 ---
   986|     fn test_fixed_size_binary_array_from_iter() {
   987|         let input_arg = vec![vec![1, 2], vec![3, 4], vec![5, 6]];
   988|         let arr = FixedSizeBinaryArray::try_from_iter(input_arg.into_iter()).unwrap();
   989|         assert_eq!(2, arr.value_length());
   990|         assert_eq!(3, arr.len())
   991|     }
   992|     #[test]
   993|     fn test_fixed_size_binary_array_from_sparse_iter() {
   994|         let input_arg = vec![
   995|             None,
   996|             Some(vec![7, 8]),
   997|             Some(vec![9, 10]),
   998|             None,
   999|             Some(vec![13, 14]),
  1000|         ];
  1001|         let arr =
  1002|             FixedSizeBinaryArray::try_from_sparse_iter(input_arg.into_iter()).unwrap();
  1003|         assert_eq!(2, arr.value_length());
  1004|         assert_eq!(5, arr.len())
  1005|     }
  1006|     #[test]
  1007|     fn test_binary_array_all_null() {
  1008|         let data = vec![None];
  1009|         let array = BinaryArray::from(data);
  1010|         array
  1011|             .data()
  1012|             .validate_full()
  1013|             .expect("All null array has valid array data");
  1014|     }
  1015|     #[test]
  1016|     fn test_large_binary_array_all_null() {
  1017|         let data = vec![None];
  1018|         let array = LargeBinaryArray::from(data);
  1019|         array
  1020|             .data()
  1021|             .validate_full()
  1022|             .expect("All null array has valid array data");
  1023|     }
  1024|     #[test]
  1025|     fn fixed_size_binary_array_all_null() {
  1026|         let data = vec![None] as Vec<Option<String>>;
  1027|         let array = FixedSizeBinaryArray::try_from_sparse_iter(data.into_iter()).unwrap();
  1028|         array
  1029|             .data()
  1030|             .validate_full()
  1031|             .expect("All null array has valid array data");
  1032|     }
  1033| }


# ====================================================================
# FILE: arrow/src/array/array_dictionary.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 253-282 ---
   253|         assert_eq!(0, keys.null_count());
   254|         assert_eq!(&[0, 1, 2, 0], keys.values());
   255|     }
   256|     #[test]
   257|     fn test_dictionary_keys_as_primitive_array_with_null() {
   258|         let test = vec![Some("a"), None, Some("b"), None, None, Some("a")];
   259|         let array: DictionaryArray<Int32Type> = test.into_iter().collect();
   260|         let keys = array.keys();
   261|         assert_eq!(&DataType::Int32, keys.data_type());
   262|         assert_eq!(3, keys.null_count());
   263|         assert!(keys.is_valid(0));
   264|         assert!(!keys.is_valid(1));
   265|         assert!(keys.is_valid(2));
   266|         assert!(!keys.is_valid(3));
   267|         assert!(!keys.is_valid(4));
   268|         assert!(keys.is_valid(5));
   269|         assert_eq!(0, keys.value(0));
   270|         assert_eq!(1, keys.value(2));
   271|         assert_eq!(0, keys.value(5));
   272|     }
   273|     #[test]
   274|     fn test_dictionary_all_nulls() {
   275|         let test = vec![None, None, None];
   276|         let array: DictionaryArray<Int32Type> = test.into_iter().collect();
   277|         array
   278|             .data()
   279|             .validate_full()
   280|             .expect("All null array has valid array data");
   281|     }
   282| }


# ====================================================================
# FILE: arrow/src/array/array_string.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 386-423 ---
   386|         assert_eq!(array1.value(1), "hello2");
   387|     }
   388|     #[test]
   389|     fn test_string_array_from_unbound_iter() {
   390|         let string_iter = (0..)
   391|             .scan(0usize, |pos, i| {
   392|                 if *pos < 10 {
   393|                     *pos += 1;
   394|                     Some(Some(format!("value {}", i)))
   395|                 } else {
   396|                     None
   397|                 }
   398|             })
   399|             .take(100);
   400|         let (_, upper_size_bound) = string_iter.size_hint();
   401|         assert_eq!(upper_size_bound, Some(100));
   402|         let string_array: StringArray = string_iter.collect();
   403|         assert_eq!(string_array.len(), 10);
   404|     }
   405|     #[test]
   406|     fn test_string_array_all_null() {
   407|         let data = vec![None];
   408|         let array = StringArray::from(data);
   409|         array
   410|             .data()
   411|             .validate_full()
   412|             .expect("All null array has valid array data");
   413|     }
   414|     #[test]
   415|     fn test_large_string_array_all_null() {
   416|         let data = vec![None];
   417|         let array = LargeStringArray::from(data);
   418|         array
   419|             .data()
   420|             .validate_full()
   421|             .expect("All null array has valid array data");
   422|     }
   423| }


# ====================================================================
# FILE: arrow/src/array/data.rs
# Total hunks: 6
# ====================================================================
# --- HUNK 1: Lines 1-23 ---
     1| use std::convert::TryInto;
     2| use std::mem;
     3| use std::ops::Range;
     4| use std::sync::Arc;
     5| use crate::datatypes::{DataType, IntervalUnit};
     6| use crate::error::{ArrowError, Result};
     7| use crate::{bitmap::Bitmap, datatypes::ArrowNativeType};
     8| use crate::{
     9|     buffer::{Buffer, MutableBuffer},
    10|     util::bit_util,
    11| };
    12| use super::equal::equal;
    13| #[inline]
    14| pub(crate) fn count_nulls(
    15|     null_bit_buffer: Option<&Buffer>,
    16|     offset: usize,
    17|     len: usize,
    18| ) -> usize {
    19|     if let Some(buf) = null_bit_buffer {
    20|         len.checked_sub(buf.count_set_bits_offset(offset, len))
    21|             .unwrap()
    22|     } else {
    23|         0

# --- HUNK 2: Lines 230-270 ---
   230|     pub fn try_new(
   231|         data_type: DataType,
   232|         len: usize,
   233|         null_count: Option<usize>,
   234|         null_bit_buffer: Option<Buffer>,
   235|         offset: usize,
   236|         buffers: Vec<Buffer>,
   237|         child_data: Vec<ArrayData>,
   238|     ) -> Result<Self> {
   239|         let new_self = unsafe {
   240|             Self::new_unchecked(
   241|                 data_type,
   242|                 len,
   243|                 null_count,
   244|                 null_bit_buffer,
   245|                 offset,
   246|                 buffers,
   247|                 child_data,
   248|             )
   249|         };
   250|         new_self.validate_full()?;
   251|         Ok(new_self)
   252|     }
   253|     #[inline]
   254|     pub const fn builder(data_type: DataType) -> ArrayDataBuilder {
   255|         ArrayDataBuilder::new(data_type)
   256|     }
   257|     #[inline]
   258|     pub const fn data_type(&self) -> &DataType {
   259|         &self.data_type
   260|     }
   261|     pub fn buffers(&self) -> &[Buffer] {
   262|         &self.buffers[..]
   263|     }
   264|     pub fn child_data(&self) -> &[ArrayData] {
   265|         &self.child_data[..]
   266|     }
   267|     pub fn is_null(&self, i: usize) -> bool {
   268|         if let Some(ref b) = self.null_bitmap {
   269|             return !b.is_set(self.offset + i);
   270|         }

# --- HUNK 3: Lines 495-561 ---
   495|         self.validate_child_data()?;
   496|         match &self.data_type {
   497|             DataType::Utf8 | DataType::Binary => {
   498|                 self.validate_offsets::<i32>(&self.buffers[0], self.buffers[1].len())?;
   499|             }
   500|             DataType::LargeUtf8 | DataType::LargeBinary => {
   501|                 self.validate_offsets::<i64>(&self.buffers[0], self.buffers[1].len())?;
   502|             }
   503|             DataType::Dictionary(key_type, _value_type) => {
   504|                 if !DataType::is_dictionary_key_type(key_type) {
   505|                     return Err(ArrowError::InvalidArgumentError(format!(
   506|                         "Dictionary values must be integer, but was {}",
   507|                         key_type
   508|                     )));
   509|                 }
   510|             }
   511|             _ => {}
   512|         };
   513|         Ok(())
   514|     }
   515|     fn typed_offsets<'a, T: ArrowNativeType + num::Num + std::fmt::Display>(
   516|         &'a self,
   517|         buffer: &'a Buffer,
   518|     ) -> Result<&'a [T]> {
   519|         let required_offsets = self.len + self.offset + 1;
   520|         if buffer.is_empty() {
   521|             return Ok(&[]);
   522|         }
   523|         if (buffer.len() / std::mem::size_of::<T>()) < required_offsets {
   524|             return Err(ArrowError::InvalidArgumentError(format!(
   525|                 "Offsets buffer size (bytes): {} isn't large enough for {}. Length {} needs {}",
   526|                 buffer.len(), self.data_type, self.len, required_offsets
   527|             )));
   528|         }
   529|         Ok(unsafe {
   530|             &(buffer.typed_data::<T>()[self.offset..self.offset + self.len + 1])
   531|         })
   532|     }
   533|     fn validate_offsets<T: ArrowNativeType + num::Num + std::fmt::Display>(
   534|         &self,
   535|         buffer: &Buffer,
   536|         values_length: usize,
   537|     ) -> Result<()> {
   538|         let offsets = self.typed_offsets::<T>(buffer)?;
   539|         if offsets.is_empty() {
   540|             return Ok(());
   541|         }
   542|         let first_offset = offsets[0].to_usize().ok_or_else(|| {
   543|             ArrowError::InvalidArgumentError(format!(
   544|                 "Error converting offset[0] ({}) to usize for {}",
   545|                 offsets[0], self.data_type
   546|             ))
   547|         })?;
   548|         let last_offset = offsets[self.len].to_usize().ok_or_else(|| {
   549|             ArrowError::InvalidArgumentError(format!(
   550|                 "Error converting offset[{}] ({}) to usize for {}",
   551|                 self.len, offsets[self.len], self.data_type
   552|             ))
   553|         })?;
   554|         if first_offset > values_length {
   555|             return Err(ArrowError::InvalidArgumentError(format!(
   556|                 "First offset {} of {} is larger than values length {}",
   557|                 first_offset, self.data_type, values_length,
   558|             )));
   559|         }
   560|         if last_offset > values_length {
   561|             return Err(ArrowError::InvalidArgumentError(format!(

# --- HUNK 4: Lines 657-882 ---
   657|         &self,
   658|         i: usize,
   659|         expected_type: &DataType,
   660|     ) -> Result<&ArrayData> {
   661|         let values_data = self.child_data
   662|             .get(i)
   663|             .ok_or_else(|| {
   664|                 ArrowError::InvalidArgumentError(format!(
   665|                     "{} did not have enough child arrays. Expected at least {} but had only {}",
   666|                     self.data_type, i+1, self.child_data.len()
   667|                 ))
   668|             })?;
   669|         if expected_type != &values_data.data_type {
   670|             return Err(ArrowError::InvalidArgumentError(format!(
   671|                 "Child type mismatch for {}. Expected {} but child data had {}",
   672|                 self.data_type, expected_type, values_data.data_type
   673|             )));
   674|         }
   675|         values_data.validate()?;
   676|         Ok(values_data)
   677|     }
   678|     pub fn validate_full(&self) -> Result<()> {
   679|         self.validate()?;
   680|         let null_bitmap_buffer = self
   681|             .null_bitmap
   682|             .as_ref()
   683|             .map(|null_bitmap| null_bitmap.buffer_ref());
   684|         let actual_null_count = count_nulls(null_bitmap_buffer, self.offset, self.len);
   685|         if actual_null_count != self.null_count {
   686|             return Err(ArrowError::InvalidArgumentError(format!(
   687|                 "null_count value ({}) doesn't match actual number of nulls in array ({})",
   688|                 self.null_count, actual_null_count
   689|             )));
   690|         }
   691|         match &self.data_type {
   692|             DataType::Utf8 => {
   693|                 self.validate_utf8::<i32>()?;
   694|             }
   695|             DataType::LargeUtf8 => {
   696|                 self.validate_utf8::<i64>()?;
   697|             }
   698|             DataType::Binary => {
   699|                 self.validate_offsets_full::<i32>(self.buffers[1].len())?;
   700|             }
   701|             DataType::LargeBinary => {
   702|                 self.validate_offsets_full::<i64>(self.buffers[1].len())?;
   703|             }
   704|             DataType::List(_) | DataType::Map(_, _) => {
   705|                 let child = &self.child_data[0];
   706|                 self.validate_offsets_full::<i32>(child.len + child.offset)?;
   707|             }
   708|             DataType::LargeList(_) => {
   709|                 let child = &self.child_data[0];
   710|                 self.validate_offsets_full::<i64>(child.len + child.offset)?;
   711|             }
   712|             DataType::Union(_) => {
   713|             }
   714|             DataType::Dictionary(key_type, _value_type) => {
   715|                 let dictionary_length: i64 = self.child_data[0].len.try_into().unwrap();
   716|                 let max_value = dictionary_length - 1;
   717|                 match key_type.as_ref() {
   718|                     DataType::UInt8 => self.check_bounds::<u8>(max_value)?,
   719|                     DataType::UInt16 => self.check_bounds::<u16>(max_value)?,
   720|                     DataType::UInt32 => self.check_bounds::<u32>(max_value)?,
   721|                     DataType::UInt64 => self.check_bounds::<u64>(max_value)?,
   722|                     DataType::Int8 => self.check_bounds::<i8>(max_value)?,
   723|                     DataType::Int16 => self.check_bounds::<i16>(max_value)?,
   724|                     DataType::Int32 => self.check_bounds::<i32>(max_value)?,
   725|                     DataType::Int64 => self.check_bounds::<i64>(max_value)?,
   726|                     _ => unreachable!(),
   727|                 }
   728|             }
   729|             _ => {
   730|             }
   731|         };
   732|         self.child_data
   733|             .iter()
   734|             .enumerate()
   735|             .try_for_each(|(i, child_data)| {
   736|                 child_data.validate_full().map_err(|e| {
   737|                     ArrowError::InvalidArgumentError(format!(
   738|                         "{} child #{} invalid: {}",
   739|                         self.data_type, i, e
   740|                     ))
   741|                 })
   742|             })?;
   743|         Ok(())
   744|     }
   745|     fn validate_each_offset<T, V>(
   746|         &self,
   747|         offset_buffer: &Buffer,
   748|         offset_limit: usize,
   749|         validate: V,
   750|     ) -> Result<()>
   751|     where
   752|         T: ArrowNativeType + std::convert::TryInto<usize> + num::Num + std::fmt::Display,
   753|         V: Fn(usize, Range<usize>) -> Result<()>,
   754|     {
   755|         if self.len == 0 && offset_buffer.is_empty() {
   756|             return Ok(());
   757|         }
   758|         let offsets = self.typed_offsets::<T>(offset_buffer)?;
   759|         offsets
   760|             .iter()
   761|             .zip(offsets.iter().skip(1))
   762|             .enumerate()
   763|             .map(|(i, (&start_offset, &end_offset))| {
   764|                 let start_offset: usize = start_offset
   765|                     .try_into()
   766|                     .map_err(|_| {
   767|                         ArrowError::InvalidArgumentError(format!(
   768|                             "Offset invariant failure: could not convert start_offset {} to usize in slot {}",
   769|                             start_offset, i))
   770|                     })?;
   771|                 let end_offset: usize = end_offset
   772|                     .try_into()
   773|                     .map_err(|_| {
   774|                         ArrowError::InvalidArgumentError(format!(
   775|                             "Offset invariant failure: Could not convert end_offset {} to usize in slot {}",
   776|                             end_offset, i+1))
   777|                     })?;
   778|                 if start_offset > offset_limit {
   779|                     return Err(ArrowError::InvalidArgumentError(format!(
   780|                         "Offset invariant failure: offset for slot {} out of bounds: {} > {}",
   781|                         i, start_offset, offset_limit))
   782|                     );
   783|                 }
   784|                 if end_offset > offset_limit {
   785|                     return Err(ArrowError::InvalidArgumentError(format!(
   786|                         "Offset invariant failure: offset for slot {} out of bounds: {} > {}",
   787|                         i, end_offset, offset_limit))
   788|                     );
   789|                 }
   790|                 if start_offset > end_offset {
   791|                     return Err(ArrowError::InvalidArgumentError(format!(
   792|                         "Offset invariant failure: non-monotonic offset at slot {}: {} > {}",
   793|                         i, start_offset, end_offset))
   794|                     );
   795|                 }
   796|                 Ok((i, start_offset..end_offset))
   797|             })
   798|             .try_for_each(|res: Result<(usize, Range<usize>)>| {
   799|                 let (item_index, range) = res?;
   800|                 validate(item_index, range)
   801|             })
   802|     }
   803|     fn validate_utf8<T>(&self) -> Result<()>
   804|     where
   805|         T: ArrowNativeType + std::convert::TryInto<usize> + num::Num + std::fmt::Display,
   806|     {
   807|         let offset_buffer = &self.buffers[0];
   808|         let values_buffer = &self.buffers[1].as_slice();
   809|         self.validate_each_offset::<T, _>(
   810|             offset_buffer,
   811|             values_buffer.len(),
   812|             |string_index, range| {
   813|                 std::str::from_utf8(&values_buffer[range.clone()]).map_err(|e| {
   814|                     ArrowError::InvalidArgumentError(format!(
   815|                         "Invalid UTF8 sequence at string index {} ({:?}): {}",
   816|                         string_index, range, e
   817|                     ))
   818|                 })?;
   819|                 Ok(())
   820|             },
   821|         )
   822|     }
   823|     fn validate_offsets_full<T>(&self, offset_limit: usize) -> Result<()>
   824|     where
   825|         T: ArrowNativeType + std::convert::TryInto<usize> + num::Num + std::fmt::Display,
   826|     {
   827|         let offset_buffer = &self.buffers[0];
   828|         self.validate_each_offset::<T, _>(
   829|             offset_buffer,
   830|             offset_limit,
   831|             |_string_index, _range| {
   832|                 Ok(())
   833|             },
   834|         )
   835|     }
   836|     fn check_bounds<T>(&self, max_value: i64) -> Result<()>
   837|     where
   838|         T: ArrowNativeType + std::convert::TryInto<i64> + num::Num + std::fmt::Display,
   839|     {
   840|         let required_len = self.len + self.offset;
   841|         let buffer = &self.buffers[0];
   842|         assert!(buffer.len() / std::mem::size_of::<T>() >= required_len);
   843|         let indexes: &[T] =
   844|             unsafe { &(buffer.typed_data::<T>()[self.offset..self.offset + self.len]) };
   845|         indexes.iter().enumerate().try_for_each(|(i, &dict_index)| {
   846|             if self.is_null(i) {
   847|                 return Ok(());
   848|             }
   849|             let dict_index: i64 = dict_index.try_into().map_err(|_| {
   850|                 ArrowError::InvalidArgumentError(format!(
   851|                     "Value at position {} out of bounds: {} (can not convert to i64)",
   852|                     i, dict_index
   853|                 ))
   854|             })?;
   855|             if dict_index < 0 || dict_index > max_value {
   856|                 return Err(ArrowError::InvalidArgumentError(format!(
   857|                     "Value at position {} out of bounds: {} (should be in [0, {}])",
   858|                     i, dict_index, max_value
   859|                 )));
   860|             }
   861|             Ok(())
   862|         })
   863|     }
   864| }
   865| fn layout(data_type: &DataType) -> DataTypeLayout {
   866|     use std::mem::size_of;
   867|     match data_type {
   868|         DataType::Null => DataTypeLayout::new_empty(),
   869|         DataType::Boolean => DataTypeLayout {
   870|             buffers: vec![BufferSpec::BitMap],
   871|         },
   872|         DataType::Int8 => DataTypeLayout::new_fixed_width(size_of::<i8>()),
   873|         DataType::Int16 => DataTypeLayout::new_fixed_width(size_of::<i16>()),
   874|         DataType::Int32 => DataTypeLayout::new_fixed_width(size_of::<i32>()),
   875|         DataType::Int64 => DataTypeLayout::new_fixed_width(size_of::<i64>()),
   876|         DataType::UInt8 => DataTypeLayout::new_fixed_width(size_of::<u8>()),
   877|         DataType::UInt16 => DataTypeLayout::new_fixed_width(size_of::<u16>()),
   878|         DataType::UInt32 => DataTypeLayout::new_fixed_width(size_of::<u32>()),
   879|         DataType::UInt64 => DataTypeLayout::new_fixed_width(size_of::<u64>()),
   880|         DataType::Float16 => unimplemented!(),
   881|         DataType::Float32 => DataTypeLayout::new_fixed_width(size_of::<f32>()),
   882|         DataType::Float64 => DataTypeLayout::new_fixed_width(size_of::<f64>()),

# --- HUNK 5: Lines 1023-1063 ---
  1023|             self.child_data,
  1024|         )
  1025|     }
  1026|     pub fn build(self) -> Result<ArrayData> {
  1027|         ArrayData::try_new(
  1028|             self.data_type,
  1029|             self.len,
  1030|             self.null_count,
  1031|             self.null_bit_buffer,
  1032|             self.offset,
  1033|             self.buffers,
  1034|             self.child_data,
  1035|         )
  1036|     }
  1037| }
  1038| #[cfg(test)]
  1039| mod tests {
  1040|     use super::*;
  1041|     use crate::array::{
  1042|         Array, BooleanBuilder, Int32Array, Int32Builder, StringArray, StructBuilder,
  1043|         UInt64Array,
  1044|     };
  1045|     use crate::buffer::Buffer;
  1046|     use crate::datatypes::Field;
  1047|     use crate::util::bit_util;
  1048|     #[test]
  1049|     fn test_builder() {
  1050|         let v = (0..25).collect::<Vec<i32>>();
  1051|         let b1 = Buffer::from_slice_ref(&v);
  1052|         let arr_data = ArrayData::builder(DataType::Int32)
  1053|             .len(20)
  1054|             .offset(5)
  1055|             .add_buffer(b1)
  1056|             .null_bit_buffer(Buffer::from(vec![
  1057|                 0b01011111, 0b10110101, 0b01100011, 0b00011110,
  1058|             ]))
  1059|             .build()
  1060|             .unwrap();
  1061|         assert_eq!(20, arr_data.len());
  1062|         assert_eq!(10, arr_data.null_count());
  1063|         assert_eq!(5, arr_data.offset());

# --- HUNK 6: Lines 1483-1808 ---
  1483|         .unwrap();
  1484|     }
  1485|     #[test]
  1486|     #[should_panic(
  1487|         expected = "child array #0 for field field1 has length smaller than expected for struct array (4 < 6)"
  1488|     )]
  1489|     fn test_validate_struct_child_length() {
  1490|         let field1 = vec![Some(1), Some(2), Some(3), None]
  1491|             .into_iter()
  1492|             .collect::<Int32Array>();
  1493|         ArrayData::try_new(
  1494|             DataType::Struct(vec![Field::new("field1", DataType::Int32, true)]),
  1495|             6,
  1496|             None,
  1497|             None,
  1498|             0,
  1499|             vec![],
  1500|             vec![field1.data().clone()],
  1501|         )
  1502|         .unwrap();
  1503|     }
  1504|     fn check_utf8_validation<T: ArrowNativeType>(data_type: DataType) {
  1505|         let data_buffer = Buffer::from_slice_ref(&[b'a', b'a', 0x80, 0x00]);
  1506|         let offsets: Vec<T> = [0, 2, 3]
  1507|             .iter()
  1508|             .map(|&v| T::from_usize(v).unwrap())
  1509|             .collect();
  1510|         let offsets_buffer = Buffer::from_slice_ref(&offsets);
  1511|         ArrayData::try_new(
  1512|             data_type,
  1513|             2,
  1514|             None,
  1515|             None,
  1516|             0,
  1517|             vec![offsets_buffer, data_buffer],
  1518|             vec![],
  1519|         )
  1520|         .unwrap();
  1521|     }
  1522|     #[test]
  1523|     #[should_panic(expected = "Invalid UTF8 sequence at string index 1 (2..3)")]
  1524|     fn test_validate_utf8_content() {
  1525|         check_utf8_validation::<i32>(DataType::Utf8);
  1526|     }
  1527|     #[test]
  1528|     #[should_panic(expected = "Invalid UTF8 sequence at string index 1 (2..3)")]
  1529|     fn test_validate_large_utf8_content() {
  1530|         check_utf8_validation::<i64>(DataType::LargeUtf8);
  1531|     }
  1532|     fn check_index_out_of_bounds_validation<T: ArrowNativeType>(data_type: DataType) {
  1533|         let data_buffer = Buffer::from_slice_ref(&[b'a', b'b', b'c', b'd']);
  1534|         let offsets: Vec<T> = [0, 1, 2, 5, 2]
  1535|             .iter()
  1536|             .map(|&v| T::from_usize(v).unwrap())
  1537|             .collect();
  1538|         let offsets_buffer = Buffer::from_slice_ref(&offsets);
  1539|         ArrayData::try_new(
  1540|             data_type,
  1541|             4,
  1542|             None,
  1543|             None,
  1544|             0,
  1545|             vec![offsets_buffer, data_buffer],
  1546|             vec![],
  1547|         )
  1548|         .unwrap();
  1549|     }
  1550|     #[test]
  1551|     #[should_panic(
  1552|         expected = "Offset invariant failure: offset for slot 2 out of bounds: 5 > 4"
  1553|     )]
  1554|     fn test_validate_utf8_out_of_bounds() {
  1555|         check_index_out_of_bounds_validation::<i32>(DataType::Utf8);
  1556|     }
  1557|     #[test]
  1558|     #[should_panic(
  1559|         expected = "Offset invariant failure: offset for slot 2 out of bounds: 5 > 4"
  1560|     )]
  1561|     fn test_validate_large_utf8_out_of_bounds() {
  1562|         check_index_out_of_bounds_validation::<i64>(DataType::LargeUtf8);
  1563|     }
  1564|     #[test]
  1565|     #[should_panic(
  1566|         expected = "Offset invariant failure: offset for slot 2 out of bounds: 5 > 4"
  1567|     )]
  1568|     fn test_validate_binary_out_of_bounds() {
  1569|         check_index_out_of_bounds_validation::<i32>(DataType::Binary);
  1570|     }
  1571|     #[test]
  1572|     #[should_panic(
  1573|         expected = "Offset invariant failure: offset for slot 2 out of bounds: 5 > 4"
  1574|     )]
  1575|     fn test_validate_large_binary_out_of_bounds() {
  1576|         check_index_out_of_bounds_validation::<i64>(DataType::LargeBinary);
  1577|     }
  1578|     fn check_index_backwards_validation<T: ArrowNativeType>(data_type: DataType) {
  1579|         let data_buffer = Buffer::from_slice_ref(&[b'a', b'b', b'c', b'd']);
  1580|         let offsets: Vec<T> = [0, 1, 2, 2, 1]
  1581|             .iter()
  1582|             .map(|&v| T::from_usize(v).unwrap())
  1583|             .collect();
  1584|         let offsets_buffer = Buffer::from_slice_ref(&offsets);
  1585|         ArrayData::try_new(
  1586|             data_type,
  1587|             4,
  1588|             None,
  1589|             None,
  1590|             0,
  1591|             vec![offsets_buffer, data_buffer],
  1592|             vec![],
  1593|         )
  1594|         .unwrap();
  1595|     }
  1596|     #[test]
  1597|     #[should_panic(
  1598|         expected = "Offset invariant failure: non-monotonic offset at slot 3: 2 > 1"
  1599|     )]
  1600|     fn test_validate_utf8_index_backwards() {
  1601|         check_index_backwards_validation::<i32>(DataType::Utf8);
  1602|     }
  1603|     #[test]
  1604|     #[should_panic(
  1605|         expected = "Offset invariant failure: non-monotonic offset at slot 3: 2 > 1"
  1606|     )]
  1607|     fn test_validate_large_utf8_index_backwards() {
  1608|         check_index_backwards_validation::<i64>(DataType::LargeUtf8);
  1609|     }
  1610|     #[test]
  1611|     #[should_panic(
  1612|         expected = "Offset invariant failure: non-monotonic offset at slot 3: 2 > 1"
  1613|     )]
  1614|     fn test_validate_binary_index_backwards() {
  1615|         check_index_backwards_validation::<i32>(DataType::Binary);
  1616|     }
  1617|     #[test]
  1618|     #[should_panic(
  1619|         expected = "Offset invariant failure: non-monotonic offset at slot 3: 2 > 1"
  1620|     )]
  1621|     fn test_validate_large_binary_index_backwards() {
  1622|         check_index_backwards_validation::<i64>(DataType::LargeBinary);
  1623|     }
  1624|     #[test]
  1625|     #[should_panic(
  1626|         expected = "Value at position 1 out of bounds: 3 (should be in [0, 1])"
  1627|     )]
  1628|     fn test_validate_dictionary_index_too_large() {
  1629|         let values: StringArray = [Some("foo"), Some("bar")].iter().collect();
  1630|         let keys: Int32Array = [Some(1), Some(3)].iter().collect();
  1631|         let data_type = DataType::Dictionary(
  1632|             Box::new(keys.data_type().clone()),
  1633|             Box::new(values.data_type().clone()),
  1634|         );
  1635|         ArrayData::try_new(
  1636|             data_type,
  1637|             2,
  1638|             None,
  1639|             None,
  1640|             0,
  1641|             vec![keys.data().buffers[0].clone()],
  1642|             vec![values.data().clone()],
  1643|         )
  1644|         .unwrap();
  1645|     }
  1646|     #[test]
  1647|     #[should_panic(
  1648|         expected = "Value at position 1 out of bounds: -1 (should be in [0, 1]"
  1649|     )]
  1650|     fn test_validate_dictionary_index_negative() {
  1651|         let values: StringArray = [Some("foo"), Some("bar")].iter().collect();
  1652|         let keys: Int32Array = [Some(1), Some(-1)].iter().collect();
  1653|         let data_type = DataType::Dictionary(
  1654|             Box::new(keys.data_type().clone()),
  1655|             Box::new(values.data_type().clone()),
  1656|         );
  1657|         ArrayData::try_new(
  1658|             data_type,
  1659|             2,
  1660|             None,
  1661|             None,
  1662|             0,
  1663|             vec![keys.data().buffers[0].clone()],
  1664|             vec![values.data().clone()],
  1665|         )
  1666|         .unwrap();
  1667|     }
  1668|     #[test]
  1669|     fn test_validate_dictionary_index_negative_but_not_referenced() {
  1670|         let values: StringArray = [Some("foo"), Some("bar")].iter().collect();
  1671|         let keys: Int32Array = [Some(1), Some(-1)].iter().collect();
  1672|         let data_type = DataType::Dictionary(
  1673|             Box::new(keys.data_type().clone()),
  1674|             Box::new(values.data_type().clone()),
  1675|         );
  1676|         ArrayData::try_new(
  1677|             data_type,
  1678|             1,
  1679|             None,
  1680|             None,
  1681|             0,
  1682|             vec![keys.data().buffers[0].clone()],
  1683|             vec![values.data().clone()],
  1684|         )
  1685|         .unwrap();
  1686|     }
  1687|     #[test]
  1688|     #[should_panic(
  1689|         expected = "Value at position 0 out of bounds: 18446744073709551615 (can not convert to i64)"
  1690|     )]
  1691|     fn test_validate_dictionary_index_giant_negative() {
  1692|         let values: StringArray = [Some("foo"), Some("bar")].iter().collect();
  1693|         let keys: UInt64Array = [Some(u64::MAX), Some(1)].iter().collect();
  1694|         let data_type = DataType::Dictionary(
  1695|             Box::new(keys.data_type().clone()),
  1696|             Box::new(values.data_type().clone()),
  1697|         );
  1698|         ArrayData::try_new(
  1699|             data_type,
  1700|             2,
  1701|             None,
  1702|             None,
  1703|             0,
  1704|             vec![keys.data().buffers[0].clone()],
  1705|             vec![values.data().clone()],
  1706|         )
  1707|         .unwrap();
  1708|     }
  1709|     fn check_list_offsets<T: ArrowNativeType>(data_type: DataType) {
  1710|         let values: Int32Array = [Some(1), Some(2), Some(3), Some(4)].iter().collect();
  1711|         let offsets: Vec<T> = [0, 2, 5, 4]
  1712|             .iter()
  1713|             .map(|&v| T::from_usize(v).unwrap())
  1714|             .collect();
  1715|         let offsets_buffer = Buffer::from_slice_ref(&offsets);
  1716|         ArrayData::try_new(
  1717|             data_type,
  1718|             3,
  1719|             None,
  1720|             None,
  1721|             0,
  1722|             vec![offsets_buffer],
  1723|             vec![values.data().clone()],
  1724|         )
  1725|         .unwrap();
  1726|     }
  1727|     #[test]
  1728|     #[should_panic(
  1729|         expected = "Offset invariant failure: offset for slot 1 out of bounds: 5 > 4"
  1730|     )]
  1731|     fn test_validate_list_offsets() {
  1732|         let field_type = Field::new("f", DataType::Int32, true);
  1733|         check_list_offsets::<i32>(DataType::List(Box::new(field_type)));
  1734|     }
  1735|     #[test]
  1736|     #[should_panic(
  1737|         expected = "Offset invariant failure: offset for slot 1 out of bounds: 5 > 4"
  1738|     )]
  1739|     fn test_validate_large_list_offsets() {
  1740|         let field_type = Field::new("f", DataType::Int32, true);
  1741|         check_list_offsets::<i64>(DataType::LargeList(Box::new(field_type)));
  1742|     }
  1743|     #[test]
  1744|     #[should_panic(
  1745|         expected = "Offset invariant failure: Could not convert end_offset -1 to usize in slot 2"
  1746|     )]
  1747|     fn test_validate_list_negative_offsets() {
  1748|         let values: Int32Array = [Some(1), Some(2), Some(3), Some(4)].iter().collect();
  1749|         let field_type = Field::new("f", values.data_type().clone(), true);
  1750|         let data_type = DataType::List(Box::new(field_type));
  1751|         let offsets: Vec<i32> = vec![0, 2, -1, 4];
  1752|         let offsets_buffer = Buffer::from_slice_ref(&offsets);
  1753|         ArrayData::try_new(
  1754|             data_type,
  1755|             3,
  1756|             None,
  1757|             None,
  1758|             0,
  1759|             vec![offsets_buffer],
  1760|             vec![values.data().clone()],
  1761|         )
  1762|         .unwrap();
  1763|     }
  1764|     #[test]
  1765|     #[should_panic(
  1766|         expected = "child #0 invalid: Invalid argument error: Value at position 1 out of bounds: -1 (should be in [0, 1])"
  1767|     )]
  1768|     fn test_validate_recursive() {
  1769|         let values: StringArray = [Some("foo"), Some("bar")].iter().collect();
  1770|         let keys: Int32Array = [Some(1), Some(-1), Some(1)].iter().collect();
  1771|         let dict_data_type = DataType::Dictionary(
  1772|             Box::new(keys.data_type().clone()),
  1773|             Box::new(values.data_type().clone()),
  1774|         );
  1775|         let dict_data = unsafe {
  1776|             ArrayData::new_unchecked(
  1777|                 dict_data_type,
  1778|                 2,
  1779|                 None,
  1780|                 None,
  1781|                 0,
  1782|                 vec![keys.data().buffers[0].clone()],
  1783|                 vec![values.data().clone()],
  1784|             )
  1785|         };
  1786|         let data_type =
  1787|             DataType::Struct(vec![Field::new("d", dict_data.data_type().clone(), true)]);
  1788|         ArrayData::try_new(data_type, 1, None, None, 0, vec![], vec![dict_data]).unwrap();
  1789|     }
  1790|     fn make_i32_buffer(n: usize) -> Buffer {
  1791|         Buffer::from_slice_ref(&vec![42i32; n])
  1792|     }
  1793|     fn make_f32_buffer(n: usize) -> Buffer {
  1794|         Buffer::from_slice_ref(&vec![42f32; n])
  1795|     }
  1796|     #[test]
  1797|     fn test_try_new_sliced_struct() {
  1798|         let mut builder = StructBuilder::new(
  1799|             vec![
  1800|                 Field::new("a", DataType::Int32, true),
  1801|                 Field::new("b", DataType::Boolean, true),
  1802|             ],
  1803|             vec![
  1804|                 Box::new(Int32Builder::new(5)),
  1805|                 Box::new(BooleanBuilder::new(5)),
  1806|             ],
  1807|         );
  1808|         builder


# ====================================================================
# FILE: arrow/src/array/equal/utils.rs
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 72-172 ---
    72|     let self_null_bitmap = child_data.null_bitmap().clone().unwrap_or_else(|| {
    73|         let ceil = bit_util::ceil(child_data.len(), 8);
    74|         Bitmap::from(Buffer::from(vec![0b11111111; ceil]))
    75|     });
    76|     match parent_data.data_type() {
    77|         DataType::List(_) | DataType::Map(_, _) => Some(logical_list_bitmap::<i32>(
    78|             parent_data,
    79|             parent_bitmap,
    80|             self_null_bitmap,
    81|         )),
    82|         DataType::LargeList(_) => Some(logical_list_bitmap::<i64>(
    83|             parent_data,
    84|             parent_bitmap,
    85|             self_null_bitmap,
    86|         )),
    87|         DataType::FixedSizeList(_, len) => {
    88|             let len = *len as usize;
    89|             let array_offset = parent_data.offset();
    90|             let bitmap_len = bit_util::ceil(parent_len * len, 8);
    91|             let mut buffer = MutableBuffer::from_len_zeroed(bitmap_len);
    92|             let null_slice = buffer.as_slice_mut();
    93|             (array_offset..parent_len + array_offset).for_each(|index| {
    94|                 let start = index * len;
    95|                 let end = start + len;
    96|                 let mask = parent_bitmap.is_set(index);
    97|                 (start..end).for_each(|child_index| {
    98|                     if mask && self_null_bitmap.is_set(child_index) {
    99|                         bit_util::set_bit(null_slice, child_index);
   100|                     }
   101|                 });
   102|             });
   103|             Some(buffer.into())
   104|         }
   105|         DataType::Struct(_) => {
   106|             let result = &parent_bitmap & &self_null_bitmap;
   107|             if let Ok(bitmap) = result {
   108|                 return Some(bitmap.bits);
   109|             }
   110|             let array_offset = parent_data.offset();
   111|             let mut buffer = MutableBuffer::new_null(parent_len);
   112|             let null_slice = buffer.as_slice_mut();
   113|             (0..parent_len).for_each(|index| {
   114|                 if parent_bitmap.is_set(index + array_offset)
   115|                     && self_null_bitmap.is_set(index + array_offset)
   116|                 {
   117|                     bit_util::set_bit(null_slice, index);
   118|                 }
   119|             });
   120|             Some(buffer.into())
   121|         }
   122|         DataType::Union(_) => {
   123|             unimplemented!("Logical equality not yet implemented for union arrays")
   124|         }
   125|         DataType::Dictionary(_, _) => {
   126|             unimplemented!("Logical equality not yet implemented for nested dictionaries")
   127|         }
   128|         data_type => panic!("Data type {:?} is not a supported nested type", data_type),
   129|     }
   130| }
   131| #[inline]
   132| fn logical_list_bitmap<OffsetSize: OffsetSizeTrait>(
   133|     parent_data: &ArrayData,
   134|     parent_bitmap: Bitmap,
   135|     child_bitmap: Bitmap,
   136| ) -> Buffer {
   137|     let offsets = parent_data.buffer::<OffsetSize>(0);
   138|     let offset_start = offsets.first().unwrap().to_usize().unwrap();
   139|     let offset_len = offsets.get(parent_data.len()).unwrap().to_usize().unwrap();
   140|     let mut buffer = MutableBuffer::new_null(offset_len - offset_start);
   141|     let null_slice = buffer.as_slice_mut();
   142|     offsets
   143|         .windows(2)
   144|         .enumerate()
   145|         .take(parent_data.len())
   146|         .for_each(|(index, window)| {
   147|             let start = window[0].to_usize().unwrap();
   148|             let end = window[1].to_usize().unwrap();
   149|             let mask = parent_bitmap.is_set(index);
   150|             (start..end).for_each(|child_index| {
   151|                 if mask && child_bitmap.is_set(child_index) {
   152|                     bit_util::set_bit(null_slice, child_index - offset_start);
   153|                 }
   154|             });
   155|         });
   156|     buffer.into()
   157| }
   158| #[cfg(test)]
   159| mod tests {
   160|     use super::*;
   161|     use crate::datatypes::{Field, ToByteSlice};
   162|     #[test]
   163|     fn test_logical_null_buffer() {
   164|         let child_data = ArrayData::builder(DataType::Int32)
   165|             .len(11)
   166|             .add_buffer(Buffer::from(
   167|                 vec![1i32, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11].to_byte_slice(),
   168|             ))
   169|             .build()
   170|             .unwrap();
   171|         let data = ArrayData::builder(DataType::List(Box::new(Field::new(
   172|             "item",


# ====================================================================
# FILE: arrow/src/array/transform/boolean.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-25 ---
     1| use crate::array::ArrayData;
     2| use super::{
     3|     Extend, _MutableArrayData,
     4|     utils::{resize_for_bits, set_bits},
     5| };
     6| pub(super) fn build_extend(array: &ArrayData) -> Extend {
     7|     let values = array.buffers()[0].as_slice();
     8|     Box::new(
     9|         move |mutable: &mut _MutableArrayData, _, start: usize, len: usize| {
    10|             let buffer = &mut mutable.buffer1;
    11|             resize_for_bits(buffer, mutable.len + len);
    12|             set_bits(
    13|                 buffer.as_slice_mut(),
    14|                 values,
    15|                 mutable.len,
    16|                 array.offset() + start,
    17|                 len,
    18|             );
    19|         },
    20|     )
    21| }
    22| pub(super) fn extend_nulls(mutable: &mut _MutableArrayData, len: usize) {
    23|     let buffer = &mut mutable.buffer1;
    24|     resize_for_bits(buffer, mutable.len + len);
    25| }


# ====================================================================
# FILE: arrow/src/buffer/mutable.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-28 ---
     1| use super::Buffer;
     2| use crate::{
     3|     alloc,
     4|     bytes::{Bytes, Deallocation},
     5|     datatypes::{ArrowNativeType, ToByteSlice},
     6|     util::bit_util,
     7| };
     8| use std::ptr::NonNull;
     9| #[derive(Debug)]
    10| pub struct MutableBuffer {
    11|     data: NonNull<u8>,
    12|     len: usize,
    13|     capacity: usize,
    14| }
    15| impl MutableBuffer {
    16|     #[inline]
    17|     pub fn new(capacity: usize) -> Self {
    18|         Self::with_capacity(capacity)
    19|     }
    20|     #[inline]
    21|     pub fn with_capacity(capacity: usize) -> Self {
    22|         let capacity = bit_util::round_upto_multiple_of_64(capacity);
    23|         let ptr = alloc::allocate_aligned(capacity);
    24|         Self {
    25|             data: ptr,
    26|             len: 0,
    27|             capacity,
    28|         }


# ====================================================================
# FILE: arrow/src/compute/kernels/cast.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1282-1332 ---
  1282| }
  1283| fn unpack_dictionary<K>(
  1284|     array: &ArrayRef,
  1285|     to_type: &DataType,
  1286|     cast_options: &CastOptions,
  1287| ) -> Result<ArrayRef>
  1288| where
  1289|     K: ArrowDictionaryKeyType,
  1290| {
  1291|     let dict_array = array
  1292|         .as_any()
  1293|         .downcast_ref::<DictionaryArray<K>>()
  1294|         .ok_or_else(|| {
  1295|             ArrowError::ComputeError(
  1296|                 "Internal Error: Cannot cast dictionary to DictionaryArray of expected type".to_string(),
  1297|             )
  1298|         })?;
  1299|     let cast_dict_values = cast_with_options(dict_array.values(), to_type, cast_options)?;
  1300|     let keys_array: ArrayRef =
  1301|         Arc::new(PrimitiveArray::<K>::from(dict_array.keys().data().clone()));
  1302|     let indices = cast_with_options(&keys_array, &DataType::UInt32, cast_options)?;
  1303|     let u32_indices =
  1304|         indices
  1305|             .as_any()
  1306|             .downcast_ref::<UInt32Array>()
  1307|             .ok_or_else(|| {
  1308|                 ArrowError::ComputeError(
  1309|                     "Internal Error: Cannot cast dict indices to UInt32".to_string(),
  1310|                 )
  1311|             })?;
  1312|     take(cast_dict_values.as_ref(), u32_indices, None)
  1313| }
  1314| fn cast_to_dictionary<K: ArrowDictionaryKeyType>(
  1315|     array: &ArrayRef,
  1316|     dict_value_type: &DataType,
  1317|     cast_options: &CastOptions,
  1318| ) -> Result<ArrayRef> {
  1319|     use DataType::*;
  1320|     match *dict_value_type {
  1321|         Int8 => pack_numeric_to_dictionary::<K, Int8Type>(
  1322|             array,
  1323|             dict_value_type,
  1324|             cast_options,
  1325|         ),
  1326|         Int16 => pack_numeric_to_dictionary::<K, Int16Type>(
  1327|             array,
  1328|             dict_value_type,
  1329|             cast_options,
  1330|         ),
  1331|         Int32 => pack_numeric_to_dictionary::<K, Int32Type>(
  1332|             array,


# ====================================================================
# FILE: arrow/src/compute/kernels/comparison.rs
# Total hunks: 3
# ====================================================================
# --- HUNK 1: Lines 597-648 ---
   597|         left.values().bit_slice(left_offset, len)
   598|     } else {
   599|         buffer_unary_not(left.values(), left.offset(), left.len())
   600|     };
   601|     let data = unsafe {
   602|         ArrayData::new_unchecked(
   603|             DataType::Boolean,
   604|             len,
   605|             None,
   606|             left.data_ref()
   607|                 .null_bitmap()
   608|                 .as_ref()
   609|                 .map(|b| b.bits.bit_slice(left_offset, len)),
   610|             0,
   611|             vec![values],
   612|             vec![],
   613|         )
   614|     };
   615|     Ok(BooleanArray::from(data))
   616| }
   617| pub fn lt_bool_scalar(left: &BooleanArray, right: bool) -> Result<BooleanArray> {
   618|     compare_op_scalar!(left, right, |a: bool, b: bool| !a & b)
   619| }
   620| pub fn lt_eq_bool_scalar(left: &BooleanArray, right: bool) -> Result<BooleanArray> {
   621|     compare_op_scalar!(left, right, |a, b| a <= b)
   622| }
   623| pub fn gt_bool_scalar(left: &BooleanArray, right: bool) -> Result<BooleanArray> {
   624|     compare_op_scalar!(left, right, |a: bool, b: bool| a & !b)
   625| }
   626| pub fn gt_eq_bool_scalar(left: &BooleanArray, right: bool) -> Result<BooleanArray> {
   627|     compare_op_scalar!(left, right, |a, b| a >= b)
   628| }
   629| pub fn neq_bool_scalar(left: &BooleanArray, right: bool) -> Result<BooleanArray> {
   630|     eq_bool_scalar(left, !right)
   631| }
   632| pub fn neq_utf8<OffsetSize: StringOffsetSizeTrait>(
   633|     left: &GenericStringArray<OffsetSize>,
   634|     right: &GenericStringArray<OffsetSize>,
   635| ) -> Result<BooleanArray> {
   636|     compare_op!(left, right, |a, b| a != b)
   637| }
   638| pub fn neq_utf8_scalar<OffsetSize: StringOffsetSizeTrait>(
   639|     left: &GenericStringArray<OffsetSize>,
   640|     right: &str,
   641| ) -> Result<BooleanArray> {
   642|     compare_op_scalar!(left, right, |a, b| a != b)
   643| }
   644| pub fn lt_utf8<OffsetSize: StringOffsetSizeTrait>(
   645|     left: &GenericStringArray<OffsetSize>,
   646|     right: &GenericStringArray<OffsetSize>,
   647| ) -> Result<BooleanArray> {
   648|     compare_op!(left, right, |a, b| a < b)

# --- HUNK 2: Lines 696-736 ---
   696|     simd_op: SIMD_OP,
   697|     scalar_op: SCALAR_OP,
   698| ) -> Result<BooleanArray>
   699| where
   700|     T: ArrowNumericType,
   701|     SIMD_OP: Fn(T::Simd, T::Simd) -> T::SimdMask,
   702|     SCALAR_OP: Fn(T::Native, T::Native) -> bool,
   703| {
   704|     use std::borrow::BorrowMut;
   705|     let len = left.len();
   706|     if len != right.len() {
   707|         return Err(ArrowError::ComputeError(
   708|             "Cannot perform comparison operation on arrays of different length"
   709|                 .to_string(),
   710|         ));
   711|     }
   712|     let null_bit_buffer = combine_option_bitmap(left.data_ref(), right.data_ref(), len)?;
   713|     let lanes = T::lanes();
   714|     let buffer_size = bit_util::ceil(len, 8);
   715|     let mut result = MutableBuffer::new(buffer_size).with_bitset(buffer_size, false);
   716|     assert_eq!(lanes % 8, 0, "Number of vector lanes must be multiple of 8");
   717|     let mut left_chunks = left.values().chunks_exact(lanes);
   718|     let mut right_chunks = right.values().chunks_exact(lanes);
   719|     let result_remainder = left_chunks
   720|         .borrow_mut()
   721|         .zip(right_chunks.borrow_mut())
   722|         .fold(
   723|             result.typed_data_mut(),
   724|             |result_slice, (left_slice, right_slice)| {
   725|                 let simd_left = T::load(left_slice);
   726|                 let simd_right = T::load(right_slice);
   727|                 let simd_result = simd_op(simd_left, simd_right);
   728|                 let bitmask = T::mask_to_u64(&simd_result);
   729|                 let bytes = bitmask.to_le_bytes();
   730|                 result_slice[0..lanes / 8].copy_from_slice(&bytes[0..lanes / 8]);
   731|                 &mut result_slice[lanes / 8..]
   732|             },
   733|         );
   734|     let left_remainder = left_chunks.remainder();
   735|     let right_remainder = right_chunks.remainder();
   736|     assert_eq!(left_remainder.len(), right_remainder.len());

# --- HUNK 3: Lines 1327-1402 ---
  1327|         )
  1328|     }
  1329|     #[test]
  1330|     fn test_boolean_array_eq_scalar() {
  1331|         let a: BooleanArray = vec![Some(true), Some(false), None].into();
  1332|         let res1: Vec<Option<bool>> = eq_bool_scalar(&a, false).unwrap().iter().collect();
  1333|         assert_eq!(res1, vec![Some(false), Some(true), None]);
  1334|         let res2: Vec<Option<bool>> = eq_bool_scalar(&a, true).unwrap().iter().collect();
  1335|         assert_eq!(res2, vec![Some(true), Some(false), None]);
  1336|     }
  1337|     #[test]
  1338|     fn test_boolean_array_neq_scalar() {
  1339|         let a: BooleanArray = vec![Some(true), Some(false), None].into();
  1340|         let res1: Vec<Option<bool>> =
  1341|             neq_bool_scalar(&a, false).unwrap().iter().collect();
  1342|         assert_eq!(res1, vec![Some(true), Some(false), None]);
  1343|         let res2: Vec<Option<bool>> = neq_bool_scalar(&a, true).unwrap().iter().collect();
  1344|         assert_eq!(res2, vec![Some(false), Some(true), None]);
  1345|     }
  1346|     #[test]
  1347|     fn test_boolean_array_lt_scalar() {
  1348|         let a: BooleanArray = vec![Some(true), Some(false), None].into();
  1349|         let res1: Vec<Option<bool>> = lt_bool_scalar(&a, false).unwrap().iter().collect();
  1350|         assert_eq!(res1, vec![Some(false), Some(false), None]);
  1351|         let res2: Vec<Option<bool>> = lt_bool_scalar(&a, true).unwrap().iter().collect();
  1352|         assert_eq!(res2, vec![Some(false), Some(true), None]);
  1353|     }
  1354|     #[test]
  1355|     fn test_boolean_array_lt_eq_scalar() {
  1356|         let a: BooleanArray = vec![Some(true), Some(false), None].into();
  1357|         let res1: Vec<Option<bool>> =
  1358|             lt_eq_bool_scalar(&a, false).unwrap().iter().collect();
  1359|         assert_eq!(res1, vec![Some(false), Some(true), None]);
  1360|         let res2: Vec<Option<bool>> =
  1361|             lt_eq_bool_scalar(&a, true).unwrap().iter().collect();
  1362|         assert_eq!(res2, vec![Some(true), Some(true), None]);
  1363|     }
  1364|     #[test]
  1365|     fn test_boolean_array_gt_scalar() {
  1366|         let a: BooleanArray = vec![Some(true), Some(false), None].into();
  1367|         let res1: Vec<Option<bool>> = gt_bool_scalar(&a, false).unwrap().iter().collect();
  1368|         assert_eq!(res1, vec![Some(true), Some(false), None]);
  1369|         let res2: Vec<Option<bool>> = gt_bool_scalar(&a, true).unwrap().iter().collect();
  1370|         assert_eq!(res2, vec![Some(false), Some(false), None]);
  1371|     }
  1372|     #[test]
  1373|     fn test_boolean_array_gt_eq_scalar() {
  1374|         let a: BooleanArray = vec![Some(true), Some(false), None].into();
  1375|         let res1: Vec<Option<bool>> =
  1376|             gt_eq_bool_scalar(&a, false).unwrap().iter().collect();
  1377|         assert_eq!(res1, vec![Some(true), Some(true), None]);
  1378|         let res2: Vec<Option<bool>> =
  1379|             gt_eq_bool_scalar(&a, true).unwrap().iter().collect();
  1380|         assert_eq!(res2, vec![Some(true), Some(false), None]);
  1381|     }
  1382|     #[test]
  1383|     fn test_primitive_array_lt() {
  1384|         cmp_i64!(
  1385|             lt,
  1386|             lt_dyn,
  1387|             vec![8, 8, 8, 8, 8, 8, 8, 8, 8, 8],
  1388|             vec![6, 7, 8, 9, 10, 6, 7, 8, 9, 10],
  1389|             vec![false, false, false, true, true, false, false, false, true, true]
  1390|         );
  1391|     }
  1392|     #[test]
  1393|     fn test_primitive_array_lt_scalar() {
  1394|         cmp_i64_scalar!(
  1395|             lt_scalar,
  1396|             vec![6, 7, 8, 9, 10, 6, 7, 8, 9, 10],
  1397|             8,
  1398|             vec![true, true, false, false, false, true, true, false, false, false]
  1399|         );
  1400|     }
  1401|     #[test]
  1402|     fn test_primitive_array_lt_nulls() {


# ====================================================================
# FILE: arrow/src/compute/kernels/filter.rs
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 184-225 ---
   184|             let data = array.data().clone();
   185|             Ok(make_array(data))
   186|         }
   187|         _ => {
   188|             let mut mutable =
   189|                 MutableArrayData::new(vec![array.data_ref()], false, filter_count);
   190|             iter.for_each(|(start, end)| mutable.extend(0, start, end));
   191|             let data = mutable.freeze();
   192|             Ok(make_array(data))
   193|         }
   194|     }
   195| }
   196| pub fn filter_record_batch(
   197|     record_batch: &RecordBatch,
   198|     predicate: &BooleanArray,
   199| ) -> Result<RecordBatch> {
   200|     if predicate.null_count() > 0 {
   201|         let predicate = prep_null_mask_filter(predicate);
   202|         return filter_record_batch(record_batch, &predicate);
   203|     }
   204|     let num_columns = record_batch.columns().len();
   205|     let filtered_arrays = match num_columns {
   206|         1 => {
   207|             vec![filter(record_batch.columns()[0].as_ref(), predicate)?]
   208|         }
   209|         _ => {
   210|             let filter = build_filter(predicate)?;
   211|             record_batch
   212|                 .columns()
   213|                 .iter()
   214|                 .map(|a| make_array(filter(a.data())))
   215|                 .collect()
   216|         }
   217|     };
   218|     RecordBatch::try_new(record_batch.schema(), filtered_arrays)
   219| }
   220| #[cfg(test)]
   221| mod tests {
   222|     use super::*;
   223|     use crate::datatypes::Int64Type;
   224|     use crate::{
   225|         buffer::Buffer,

# --- HUNK 2: Lines 350-390 ---
   350|         let d = c.as_ref().as_any().downcast_ref::<Int32Array>().unwrap();
   351|         assert_eq!(67, d.len());
   352|         assert_eq!(3, d.null_count());
   353|         assert_eq!(1, d.value(0));
   354|         assert!(d.is_null(1));
   355|         assert_eq!(64, d.value(63));
   356|         assert!(d.is_null(64));
   357|         assert_eq!(67, d.value(65));
   358|     }
   359|     #[test]
   360|     fn test_filter_string_array_simple() {
   361|         let a = StringArray::from(vec!["hello", " ", "world", "!"]);
   362|         let b = BooleanArray::from(vec![true, false, true, false]);
   363|         let c = filter(&a, &b).unwrap();
   364|         let d = c.as_ref().as_any().downcast_ref::<StringArray>().unwrap();
   365|         assert_eq!(2, d.len());
   366|         assert_eq!("hello", d.value(0));
   367|         assert_eq!("world", d.value(1));
   368|     }
   369|     #[test]
   370|     fn test_filter_primitive_array_with_null() {
   371|         let a = Int32Array::from(vec![Some(5), None]);
   372|         let b = BooleanArray::from(vec![false, true]);
   373|         let c = filter(&a, &b).unwrap();
   374|         let d = c.as_ref().as_any().downcast_ref::<Int32Array>().unwrap();
   375|         assert_eq!(1, d.len());
   376|         assert!(d.is_null(0));
   377|     }
   378|     #[test]
   379|     fn test_filter_string_array_with_null() {
   380|         let a = StringArray::from(vec![Some("hello"), None, Some("world"), None]);
   381|         let b = BooleanArray::from(vec![true, false, false, true]);
   382|         let c = filter(&a, &b).unwrap();
   383|         let d = c.as_ref().as_any().downcast_ref::<StringArray>().unwrap();
   384|         assert_eq!(2, d.len());
   385|         assert_eq!("hello", d.value(0));
   386|         assert!(!d.is_null(0));
   387|         assert!(d.is_null(1));
   388|     }
   389|     #[test]
   390|     fn test_filter_binary_array_with_null() {


# ====================================================================
# FILE: arrow/src/compute/kernels/take.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 220-262 ---
   220|                 .unwrap();
   221|             Ok(Arc::new(take_binary(values, indices)?))
   222|         }
   223|         DataType::FixedSizeBinary(_) => {
   224|             let values = values
   225|                 .as_any()
   226|                 .downcast_ref::<FixedSizeBinaryArray>()
   227|                 .unwrap();
   228|             Ok(Arc::new(take_fixed_size_binary(values, indices)?))
   229|         }
   230|         DataType::Null => {
   231|             if values.len() >= indices.len() {
   232|                 Ok(values.slice(0, indices.len()))
   233|             } else {
   234|                 Ok(new_null_array(&DataType::Null, indices.len()))
   235|             }
   236|         }
   237|         t => unimplemented!("Take not supported for data type {:?}", t),
   238|     }
   239| }
   240| #[derive(Clone, Debug, Default)]
   241| pub struct TakeOptions {
   242|     pub check_bounds: bool,
   243| }
   244| #[inline(always)]
   245| fn maybe_usize<I: ArrowNativeType>(index: I) -> Result<usize> {
   246|     index
   247|         .to_usize()
   248|         .ok_or_else(|| ArrowError::ComputeError("Cast to usize failed".to_string()))
   249| }
   250| fn take_no_nulls<T, I>(values: &[T], indices: &[I]) -> Result<(Buffer, Option<Buffer>)>
   251| where
   252|     T: ArrowNativeType,
   253|     I: ArrowNativeType,
   254| {
   255|     let values = indices
   256|         .iter()
   257|         .map(|index| Result::Ok(values[maybe_usize::<I>(*index)?]));
   258|     let buffer = unsafe { Buffer::try_from_trusted_len_iter(values)? };
   259|     Ok((buffer, None))
   260| }
   261| fn take_values_nulls<T, I>(
   262|     values: &PrimitiveArray<T>,


# ====================================================================
# FILE: arrow/src/compute/util.rs
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 221-261 ---
   221|     pub(crate) fn build_generic_list_nullable<S, T>(
   222|         data: Vec<Option<Vec<Option<T::Native>>>>,
   223|     ) -> GenericListArray<S>
   224|     where
   225|         S: OffsetSizeTrait + 'static,
   226|         T: ArrowPrimitiveType,
   227|         PrimitiveArray<T>: From<Vec<Option<T::Native>>>,
   228|     {
   229|         use std::any::TypeId;
   230|         let mut offset = vec![0];
   231|         let mut values = vec![];
   232|         let list_len = data.len();
   233|         let num_bytes = bit_util::ceil(list_len, 8);
   234|         let mut list_null_count = 0;
   235|         let mut list_bitmap = MutableBuffer::new(num_bytes).with_bitset(num_bytes, true);
   236|         for (idx, array) in data.into_iter().enumerate() {
   237|             if let Some(mut array) = array {
   238|                 values.append(&mut array);
   239|             } else {
   240|                 list_null_count += 1;
   241|                 bit_util::unset_bit(list_bitmap.as_slice_mut(), idx);
   242|             }
   243|             offset.push(values.len() as i64);
   244|         }
   245|         let value_data = PrimitiveArray::<T>::from(values).data().clone();
   246|         let (list_data_type, value_offsets) = if TypeId::of::<S>() == TypeId::of::<i32>()
   247|         {
   248|             (
   249|                 DataType::List(Box::new(Field::new(
   250|                     "item",
   251|                     T::DATA_TYPE,
   252|                     list_null_count == 0,
   253|                 ))),
   254|                 Buffer::from_slice_ref(
   255|                     &offset.into_iter().map(|x| x as i32).collect::<Vec<i32>>(),
   256|                 ),
   257|             )
   258|         } else if TypeId::of::<S>() == TypeId::of::<i64>() {
   259|             (
   260|                 DataType::LargeList(Box::new(Field::new(
   261|                     "item",

# --- HUNK 2: Lines 298-338 ---
   298|     }
   299|     pub(crate) fn build_fixed_size_list_nullable<T>(
   300|         list_values: Vec<Option<Vec<Option<T::Native>>>>,
   301|         length: <Int32Type as ArrowPrimitiveType>::Native,
   302|     ) -> FixedSizeListArray
   303|     where
   304|         T: ArrowPrimitiveType,
   305|         PrimitiveArray<T>: From<Vec<Option<T::Native>>>,
   306|     {
   307|         let mut values = vec![];
   308|         let mut list_null_count = 0;
   309|         let list_len = list_values.len();
   310|         let num_bytes = bit_util::ceil(list_len, 8);
   311|         let mut list_bitmap = MutableBuffer::new(num_bytes).with_bitset(num_bytes, true);
   312|         for (idx, list_element) in list_values.into_iter().enumerate() {
   313|             if let Some(items) = list_element {
   314|                 debug_assert_eq!(length as usize, items.len());
   315|                 values.extend(items.into_iter());
   316|             } else {
   317|                 list_null_count += 1;
   318|                 bit_util::unset_bit(list_bitmap.as_slice_mut(), idx);
   319|                 values.extend(vec![None; length as usize].into_iter());
   320|             }
   321|         }
   322|         let list_data_type = DataType::FixedSizeList(
   323|             Box::new(Field::new("item", T::DATA_TYPE, list_null_count == 0)),
   324|             length,
   325|         );
   326|         let child_data = PrimitiveArray::<T>::from(values).data().clone();
   327|         let list_data = ArrayData::builder(list_data_type)
   328|             .len(list_len)
   329|             .null_bit_buffer(list_bitmap.into())
   330|             .add_child_data(child_data)
   331|             .build()
   332|             .unwrap();
   333|         FixedSizeListArray::from(list_data)
   334|     }
   335|     #[test]
   336|     fn test_take_value_index_from_list() {
   337|         let list = build_generic_list::<i32, Int32Type>(vec![
   338|             Some(vec![0, 1]),


# ====================================================================
# FILE: arrow/src/datatypes/field.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 210-250 ---
   210|                                     ),
   211|                                     _ => unreachable!(
   212|                                         "Data type should be a list, largelist or fixedsizelist"
   213|                                     ),
   214|                                 }
   215|                         }
   216|                         Some(_) => {
   217|                             return Err(ArrowError::ParseError(
   218|                                 "Field 'children' must be an array".to_string(),
   219|                             ))
   220|                         }
   221|                         None => {
   222|                             return Err(ArrowError::ParseError(
   223|                                 "Field missing 'children' attribute".to_string(),
   224|                             ));
   225|                         }
   226|                     },
   227|                     DataType::Struct(mut fields) => match map.get("children") {
   228|                         Some(Value::Array(values)) => {
   229|                             let struct_fields: Result<Vec<Field>> =
   230|                                 values.iter().map(Field::from).collect();
   231|                             fields.append(&mut struct_fields?);
   232|                             DataType::Struct(fields)
   233|                         }
   234|                         Some(_) => {
   235|                             return Err(ArrowError::ParseError(
   236|                                 "Field 'children' must be an array".to_string(),
   237|                             ))
   238|                         }
   239|                         None => {
   240|                             return Err(ArrowError::ParseError(
   241|                                 "Field missing 'children' attribute".to_string(),
   242|                             ));
   243|                         }
   244|                     },
   245|                     DataType::Map(_, keys_sorted) => {
   246|                         match map.get("children") {
   247|                             Some(Value::Array(values)) if values.len() == 1 => {
   248|                                 let child = Self::from(&values[0])?;
   249|                                 match child.data_type() {
   250|                                     DataType::Struct(map_fields) if map_fields.len() == 2 => {


# ====================================================================
# FILE: arrow/src/datatypes/schema.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 98-138 ---
    98|     #[inline]
    99|     pub const fn metadata(&self) -> &HashMap<String, String> {
   100|         &self.metadata
   101|     }
   102|     pub fn column_with_name(&self, name: &str) -> Option<(usize, &Field)> {
   103|         self.fields
   104|             .iter()
   105|             .enumerate()
   106|             .find(|&(_, c)| c.name() == name)
   107|     }
   108|     pub fn to_json(&self) -> Value {
   109|         json!({
   110|             "fields": self.fields.iter().map(|field| field.to_json()).collect::<Vec<Value>>(),
   111|             "metadata": serde_json::to_value(&self.metadata).unwrap()
   112|         })
   113|     }
   114|     pub fn from(json: &Value) -> Result<Self> {
   115|         match *json {
   116|             Value::Object(ref schema) => {
   117|                 let fields = if let Some(Value::Array(fields)) = schema.get("fields") {
   118|                     fields.iter().map(Field::from).collect::<Result<_>>()?
   119|                 } else {
   120|                     return Err(ArrowError::ParseError(
   121|                         "Schema fields should be an array".to_string(),
   122|                     ));
   123|                 };
   124|                 let metadata = if let Some(value) = schema.get("metadata") {
   125|                     Self::from_metadata(value)?
   126|                 } else {
   127|                     HashMap::default()
   128|                 };
   129|                 Ok(Self { fields, metadata })
   130|             }
   131|             _ => Err(ArrowError::ParseError(
   132|                 "Invalid json value type for schema".to_string(),
   133|             )),
   134|         }
   135|     }
   136|     fn from_metadata(json: &Value) -> Result<HashMap<String, String>> {
   137|         match json {
   138|             Value::Array(_) => {


# ====================================================================
# FILE: arrow/src/ffi.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 39-81 ---
    39| #[derive(Debug)]
    40| pub struct FFI_ArrowSchema {
    41|     format: *const c_char,
    42|     name: *const c_char,
    43|     metadata: *const c_char,
    44|     flags: i64,
    45|     n_children: i64,
    46|     children: *mut *mut FFI_ArrowSchema,
    47|     dictionary: *mut FFI_ArrowSchema,
    48|     release: Option<unsafe extern "C" fn(arg1: *mut FFI_ArrowSchema)>,
    49|     private_data: *mut c_void,
    50| }
    51| struct SchemaPrivateData {
    52|     children: Box<[*mut FFI_ArrowSchema]>,
    53| }
    54| unsafe extern "C" fn release_schema(schema: *mut FFI_ArrowSchema) {
    55|     if schema.is_null() {
    56|         return;
    57|     }
    58|     let schema = &mut *schema;
    59|     drop(CString::from_raw(schema.format as *mut c_char));
    60|     if !schema.name.is_null() {
    61|         drop(CString::from_raw(schema.name as *mut c_char));
    62|     }
    63|     if !schema.private_data.is_null() {
    64|         let private_data = Box::from_raw(schema.private_data as *mut SchemaPrivateData);
    65|         for child in private_data.children.iter() {
    66|             drop(Box::from_raw(*child))
    67|         }
    68|         drop(private_data);
    69|     }
    70|     schema.release = None;
    71| }
    72| impl FFI_ArrowSchema {
    73|     pub fn try_new(format: &str, children: Vec<FFI_ArrowSchema>) -> Result<Self> {
    74|         let mut this = Self::empty();
    75|         let children_ptr = children
    76|             .into_iter()
    77|             .map(Box::new)
    78|             .map(Box::into_raw)
    79|             .collect::<Box<_>>();
    80|         this.format = CString::new(format).unwrap().into_raw();
    81|         this.release = Some(release_schema);


# ====================================================================
# FILE: arrow/src/ipc/writer.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 520-590 ---
   520|             unreachable!("Options with the metadata version cannot be created")
   521|         }
   522|         ipc::MetadataVersion::V4 => {
   523|             if !write_options.write_legacy_ipc_format {
   524|                 writer.write_all(&CONTINUATION_MARKER)?;
   525|                 written = 4;
   526|             }
   527|             writer.write_all(&total_len.to_le_bytes()[..])?;
   528|         }
   529|         ipc::MetadataVersion::V5 => {
   530|             writer.write_all(&CONTINUATION_MARKER)?;
   531|             writer.write_all(&total_len.to_le_bytes()[..])?;
   532|         }
   533|         z => panic!("Unsupported ipc::MetadataVersion {:?}", z),
   534|     };
   535|     writer.flush()?;
   536|     Ok(written)
   537| }
   538| fn write_array_data(
   539|     array_data: &ArrayData,
   540|     buffers: &mut Vec<ipc::Buffer>,
   541|     arrow_data: &mut Vec<u8>,
   542|     nodes: &mut Vec<ipc::FieldNode>,
   543|     offset: i64,
   544|     num_rows: usize,
   545|     null_count: usize,
   546| ) -> i64 {
   547|     let mut offset = offset;
   548|     nodes.push(ipc::FieldNode::new(num_rows as i64, null_count as i64));
   549|     if array_data.data_type() != &DataType::Null {
   550|         let null_buffer = match array_data.null_buffer() {
   551|             None => {
   552|                 let num_bytes = bit_util::ceil(num_rows, 8);
   553|                 let buffer = MutableBuffer::new(num_bytes);
   554|                 let buffer = buffer.with_bitset(num_bytes, true);
   555|                 buffer.into()
   556|             }
   557|             Some(buffer) => buffer.clone(),
   558|         };
   559|         offset = write_buffer(&null_buffer, buffers, arrow_data, offset);
   560|     }
   561|     array_data.buffers().iter().for_each(|buffer| {
   562|         offset = write_buffer(buffer, buffers, arrow_data, offset);
   563|     });
   564|     if !matches!(array_data.data_type(), DataType::Dictionary(_, _)) {
   565|         array_data.child_data().iter().for_each(|data_ref| {
   566|             offset = write_array_data(
   567|                 data_ref,
   568|                 buffers,
   569|                 arrow_data,
   570|                 nodes,
   571|                 offset,
   572|                 data_ref.len(),
   573|                 data_ref.null_count(),
   574|             );
   575|         });
   576|     }
   577|     offset
   578| }
   579| fn write_buffer(
   580|     buffer: &Buffer,
   581|     buffers: &mut Vec<ipc::Buffer>,
   582|     arrow_data: &mut Vec<u8>,
   583|     offset: i64,
   584| ) -> i64 {
   585|     let len = buffer.len();
   586|     let pad_len = pad_to_8(len as u32);
   587|     let total_len: i64 = (len + pad_len) as i64;
   588|     buffers.push(ipc::Buffer::new(offset, total_len));
   589|     arrow_data.extend_from_slice(buffer.as_slice());
   590|     arrow_data.extend_from_slice(&vec![0u8; pad_len][..]);


# ====================================================================
# FILE: parquet/src/arrow/arrow_writer.rs
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 62-168 ---
    62|             self.writer.close_row_group(row_group_writer)?;
    63|         }
    64|         Ok(())
    65|     }
    66|     pub fn close(&mut self) -> Result<parquet_format::FileMetaData> {
    67|         self.writer.close()
    68|     }
    69| }
    70| #[inline]
    71| #[allow(clippy::borrowed_box)]
    72| fn get_col_writer(
    73|     row_group_writer: &mut Box<dyn RowGroupWriter>,
    74| ) -> Result<ColumnWriter> {
    75|     let col_writer = row_group_writer
    76|         .next_column()?
    77|         .expect("Unable to get column writer");
    78|     Ok(col_writer)
    79| }
    80| #[allow(clippy::borrowed_box)]
    81| fn write_leaves(
    82|     row_group_writer: &mut Box<dyn RowGroupWriter>,
    83|     array: &arrow_array::ArrayRef,
    84|     levels: &mut Vec<LevelInfo>,
    85| ) -> Result<()> {
    86|     match array.data_type() {
    87|         ArrowDataType::Null
    88|         | ArrowDataType::Boolean
    89|         | ArrowDataType::Int8
    90|         | ArrowDataType::Int16
    91|         | ArrowDataType::Int32
    92|         | ArrowDataType::Int64
    93|         | ArrowDataType::UInt8
    94|         | ArrowDataType::UInt16
    95|         | ArrowDataType::UInt32
    96|         | ArrowDataType::UInt64
    97|         | ArrowDataType::Float32
    98|         | ArrowDataType::Float64
    99|         | ArrowDataType::Timestamp(_, _)
   100|         | ArrowDataType::Date32
   101|         | ArrowDataType::Date64
   102|         | ArrowDataType::Time32(_)
   103|         | ArrowDataType::Time64(_)
   104|         | ArrowDataType::Duration(_)
   105|         | ArrowDataType::Interval(_)
   106|         | ArrowDataType::LargeBinary
   107|         | ArrowDataType::Binary
   108|         | ArrowDataType::Utf8
   109|         | ArrowDataType::LargeUtf8
   110|         | ArrowDataType::Decimal(_, _)
   111|         | ArrowDataType::FixedSizeBinary(_) => {
   112|             let mut col_writer = get_col_writer(row_group_writer)?;
   113|             write_leaf(
   114|                 &mut col_writer,
   115|                 array,
   116|                 levels.pop().expect("Levels exhausted"),
   117|             )?;
   118|             row_group_writer.close_column(col_writer)?;
   119|             Ok(())
   120|         }
   121|         ArrowDataType::List(_) | ArrowDataType::LargeList(_) => {
   122|             let data = array.data();
   123|             let child_array = arrow_array::make_array(data.child_data()[0].clone());
   124|             write_leaves(row_group_writer, &child_array, levels)?;
   125|             Ok(())
   126|         }
   127|         ArrowDataType::Struct(_) => {
   128|             let struct_array: &arrow_array::StructArray = array
   129|                 .as_any()
   130|                 .downcast_ref::<arrow_array::StructArray>()
   131|                 .expect("Unable to get struct array");
   132|             for field in struct_array.columns() {
   133|                 write_leaves(row_group_writer, field, levels)?;
   134|             }
   135|             Ok(())
   136|         }
   137|         ArrowDataType::Map(_, _) => {
   138|             let map_array: &arrow_array::MapArray = array
   139|                 .as_any()
   140|                 .downcast_ref::<arrow_array::MapArray>()
   141|                 .expect("Unable to get map array");
   142|             write_leaves(row_group_writer, &map_array.keys(), levels)?;
   143|             write_leaves(row_group_writer, &map_array.values(), levels)?;
   144|             Ok(())
   145|         }
   146|         ArrowDataType::Dictionary(_, value_type) => {
   147|             let array = arrow::compute::cast(array, value_type)?;
   148|             let mut col_writer = get_col_writer(row_group_writer)?;
   149|             write_leaf(
   150|                 &mut col_writer,
   151|                 &array,
   152|                 levels.pop().expect("Levels exhausted"),
   153|             )?;
   154|             row_group_writer.close_column(col_writer)?;
   155|             Ok(())
   156|         }
   157|         ArrowDataType::Float16 => Err(ParquetError::ArrowError(
   158|             "Float16 arrays not supported".to_string(),
   159|         )),
   160|         ArrowDataType::FixedSizeList(_, _) | ArrowDataType::Union(_) => {
   161|             Err(ParquetError::NYI(
   162|                 format!(
   163|                     "Attempting to write an Arrow type {:?} to parquet that is not yet implemented",
   164|                     array.data_type()
   165|                 )
   166|             ))
   167|         }
   168|     }


# ====================================================================
# FILE: parquet/src/record/reader.rs
# Total hunks: 4
# ====================================================================
# --- HUNK 1: Lines 42-82 ---
    42|                 0,
    43|                 0,
    44|                 &paths,
    45|                 row_group_reader,
    46|             );
    47|             readers.push(reader);
    48|         }
    49|         Reader::GroupReader(None, 0, readers)
    50|     }
    51|     pub fn as_iter(
    52|         &self,
    53|         descr: SchemaDescPtr,
    54|         row_group_reader: &dyn RowGroupReader,
    55|     ) -> ReaderIter {
    56|         let num_records = row_group_reader.metadata().num_rows() as usize;
    57|         ReaderIter::new(self.build(descr, row_group_reader), num_records)
    58|     }
    59|     fn reader_tree(
    60|         &self,
    61|         field: TypePtr,
    62|         path: &mut Vec<String>,
    63|         mut curr_def_level: i16,
    64|         mut curr_rep_level: i16,
    65|         paths: &HashMap<ColumnPath, usize>,
    66|         row_group_reader: &dyn RowGroupReader,
    67|     ) -> Reader {
    68|         assert!(field.get_basic_info().has_repetition());
    69|         let repetition = field.get_basic_info().repetition();
    70|         match repetition {
    71|             Repetition::OPTIONAL => {
    72|                 curr_def_level += 1;
    73|             }
    74|             Repetition::REPEATED => {
    75|                 curr_def_level += 1;
    76|                 curr_rep_level += 1;
    77|             }
    78|             _ => {}
    79|         }
    80|         path.push(String::from(field.name()));
    81|         let reader = if field.is_primitive() {
    82|             let col_path = ColumnPath::new(path.to_vec());

# --- HUNK 2: Lines 90-147 ---
    90|             Reader::PrimitiveReader(field, Box::new(column))
    91|         } else {
    92|             match field.get_basic_info().converted_type() {
    93|                 ConvertedType::LIST => {
    94|                     assert_eq!(
    95|                         field.get_fields().len(),
    96|                         1,
    97|                         "Invalid list type {:?}",
    98|                         field
    99|                     );
   100|                     let repeated_field = field.get_fields()[0].clone();
   101|                     assert_eq!(
   102|                         repeated_field.get_basic_info().repetition(),
   103|                         Repetition::REPEATED,
   104|                         "Invalid list type {:?}",
   105|                         field
   106|                     );
   107|                     if Reader::is_element_type(&repeated_field) {
   108|                         let reader = self.reader_tree(
   109|                             repeated_field,
   110|                             path,
   111|                             curr_def_level,
   112|                             curr_rep_level,
   113|                             paths,
   114|                             row_group_reader,
   115|                         );
   116|                         Reader::RepeatedReader(
   117|                             field,
   118|                             curr_def_level,
   119|                             curr_rep_level,
   120|                             Box::new(reader),
   121|                         )
   122|                     } else {
   123|                         let child_field = repeated_field.get_fields()[0].clone();
   124|                         path.push(String::from(repeated_field.name()));
   125|                         let reader = self.reader_tree(
   126|                             child_field,
   127|                             path,
   128|                             curr_def_level + 1,
   129|                             curr_rep_level + 1,
   130|                             paths,
   131|                             row_group_reader,
   132|                         );
   133|                         path.pop();
   134|                         Reader::RepeatedReader(
   135|                             field,
   136|                             curr_def_level,
   137|                             curr_rep_level,
   138|                             Box::new(reader),
   139|                         )
   140|                     }
   141|                 }
   142|                 ConvertedType::MAP | ConvertedType::MAP_KEY_VALUE => {
   143|                     assert_eq!(
   144|                         field.get_fields().len(),
   145|                         1,
   146|                         "Invalid map type: {:?}",
   147|                         field

# --- HUNK 3: Lines 156-248 ---
   156|                         key_value_type.get_basic_info().repetition(),
   157|                         Repetition::REPEATED,
   158|                         "Invalid map type: {:?}",
   159|                         field
   160|                     );
   161|                     assert_eq!(
   162|                         key_value_type.get_fields().len(),
   163|                         2,
   164|                         "Invalid map type: {:?}",
   165|                         field
   166|                     );
   167|                     path.push(String::from(key_value_type.name()));
   168|                     let key_type = &key_value_type.get_fields()[0];
   169|                     assert!(
   170|                         key_type.is_primitive(),
   171|                         "Map key type is expected to be a primitive type, but found {:?}",
   172|                         key_type
   173|                     );
   174|                     let key_reader = self.reader_tree(
   175|                         key_type.clone(),
   176|                         path,
   177|                         curr_def_level + 1,
   178|                         curr_rep_level + 1,
   179|                         paths,
   180|                         row_group_reader,
   181|                     );
   182|                     let value_type = &key_value_type.get_fields()[1];
   183|                     let value_reader = self.reader_tree(
   184|                         value_type.clone(),
   185|                         path,
   186|                         curr_def_level + 1,
   187|                         curr_rep_level + 1,
   188|                         paths,
   189|                         row_group_reader,
   190|                     );
   191|                     path.pop();
   192|                     Reader::KeyValueReader(
   193|                         field,
   194|                         curr_def_level,
   195|                         curr_rep_level,
   196|                         Box::new(key_reader),
   197|                         Box::new(value_reader),
   198|                     )
   199|                 }
   200|                 _ if repetition == Repetition::REPEATED => {
   201|                     let required_field = Type::group_type_builder(field.name())
   202|                         .with_repetition(Repetition::REQUIRED)
   203|                         .with_converted_type(field.get_basic_info().converted_type())
   204|                         .with_fields(&mut Vec::from(field.get_fields()))
   205|                         .build()
   206|                         .unwrap();
   207|                     path.pop();
   208|                     let reader = self.reader_tree(
   209|                         Arc::new(required_field),
   210|                         path,
   211|                         curr_def_level,
   212|                         curr_rep_level,
   213|                         paths,
   214|                         row_group_reader,
   215|                     );
   216|                     Reader::RepeatedReader(
   217|                         field,
   218|                         curr_def_level - 1,
   219|                         curr_rep_level - 1,
   220|                         Box::new(reader),
   221|                     )
   222|                 }
   223|                 _ => {
   224|                     let mut readers = Vec::new();
   225|                     for child in field.get_fields() {
   226|                         let reader = self.reader_tree(
   227|                             child.clone(),
   228|                             path,
   229|                             curr_def_level,
   230|                             curr_rep_level,
   231|                             paths,
   232|                             row_group_reader,
   233|                         );
   234|                         readers.push(reader);
   235|                     }
   236|                     Reader::GroupReader(Some(field), curr_def_level, readers)
   237|                 }
   238|             }
   239|         };
   240|         path.pop();
   241|         Reader::option(repetition, curr_def_level, reader)
   242|     }
   243| }
   244| pub enum Reader {
   245|     PrimitiveReader(TypePtr, Box<TripletIter>),
   246|     OptionReader(i16, Box<Reader>),
   247|     GroupReader(Option<TypePtr>, i16, Vec<Reader>),
   248|     RepeatedReader(TypePtr, i16, i16, Box<Reader>),


# ====================================================================
# FILE: parquet/src/util/bit_util.rs
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 263-304 ---
   263|                 &self.buffered_values,
   264|                 8,
   265|                 &mut self.buffer[self.byte_offset..],
   266|             );
   267|             self.byte_offset += 8;
   268|             self.bit_offset -= 64;
   269|             self.buffered_values = 0;
   270|             self.buffered_values = v
   271|                 .checked_shr((num_bits - self.bit_offset) as u32)
   272|                 .unwrap_or(0);
   273|         }
   274|         assert!(self.bit_offset < 64);
   275|         true
   276|     }
   277|     #[inline]
   278|     pub fn put_aligned<T: AsBytes>(&mut self, val: T, num_bytes: usize) -> bool {
   279|         let result = self.get_next_byte_ptr(num_bytes);
   280|         if result.is_err() {
   281|             return false;
   282|         }
   283|         let ptr = result.unwrap();
   284|         memcpy_value(&val, num_bytes, ptr);
   285|         true
   286|     }
   287|     #[inline]
   288|     pub fn put_aligned_offset<T: AsBytes>(
   289|         &mut self,
   290|         val: T,
   291|         num_bytes: usize,
   292|         offset: usize,
   293|     ) -> bool {
   294|         if num_bytes + offset > self.max_bytes {
   295|             return false;
   296|         }
   297|         memcpy_value(
   298|             &val,
   299|             num_bytes,
   300|             &mut self.buffer[offset..offset + num_bytes],
   301|         );
   302|         true
   303|     }
   304|     #[inline]


# ====================================================================
# FILE: parquet_derive/src/parquet_field.rs
# Total hunks: 6
# ====================================================================
# --- HUNK 1: Lines 591-781 ---
   591|                                 None
   592|                             }
   593|                         }).collect();
   594|                         if let parquet::column::writer::ColumnWriter::Int32ColumnWriter ( ref mut typed ) = column_writer {
   595|                             typed . write_batch ( & vals [ .. ] , Some(&definition_levels[..]) , None ) ? ;
   596|                         }  else {
   597|                             panic!("Schema and struct disagree on type for {}" , stringify ! { optional_dumb_int } )
   598|                         }
   599|                     }
   600|         }).to_string());
   601|     }
   602|     #[test]
   603|     fn test_converting_to_column_writer_type() {
   604|         let snippet: proc_macro2::TokenStream = quote! {
   605|           struct ABasicStruct {
   606|             yes_no: bool,
   607|             name: String,
   608|           }
   609|         };
   610|         let fields = extract_fields(snippet);
   611|         let processed: Vec<_> = fields.iter().map(Field::from).collect();
   612|         let column_writers: Vec<_> = processed
   613|             .iter()
   614|             .map(|field| field.ty.column_writer())
   615|             .collect();
   616|         assert_eq!(
   617|             column_writers,
   618|             vec![
   619|                 syn::parse_quote!(
   620|                     parquet::column::writer::ColumnWriter::BoolColumnWriter
   621|                 ),
   622|                 syn::parse_quote!(
   623|                     parquet::column::writer::ColumnWriter::ByteArrayColumnWriter
   624|                 )
   625|             ]
   626|         );
   627|     }
   628|     #[test]
   629|     fn convert_basic_struct() {
   630|         let snippet: proc_macro2::TokenStream = quote! {
   631|           struct ABasicStruct {
   632|             yes_no: bool,
   633|             name: String,
   634|             length: usize
   635|           }
   636|         };
   637|         let fields = extract_fields(snippet);
   638|         let processed: Vec<_> = fields.iter().map(Field::from).collect();
   639|         assert_eq!(processed.len(), 3);
   640|         assert_eq!(
   641|             processed,
   642|             vec![
   643|                 Field {
   644|                     ident: syn::Ident::new("yes_no", proc_macro2::Span::call_site()),
   645|                     ty: Type::TypePath(syn::parse_quote!(bool)),
   646|                     is_a_byte_buf: false,
   647|                     third_party_type: None,
   648|                 },
   649|                 Field {
   650|                     ident: syn::Ident::new("name", proc_macro2::Span::call_site()),
   651|                     ty: Type::TypePath(syn::parse_quote!(String)),
   652|                     is_a_byte_buf: true,
   653|                     third_party_type: None,
   654|                 },
   655|                 Field {
   656|                     ident: syn::Ident::new("length", proc_macro2::Span::call_site()),
   657|                     ty: Type::TypePath(syn::parse_quote!(usize)),
   658|                     is_a_byte_buf: false,
   659|                     third_party_type: None,
   660|                 }
   661|             ]
   662|         )
   663|     }
   664|     #[test]
   665|     fn test_get_inner_type() {
   666|         let snippet: proc_macro2::TokenStream = quote! {
   667|           struct LotsOfInnerTypes {
   668|             a_vec: Vec<u8>,
   669|             a_option: std::option::Option<bool>,
   670|             a_silly_string: std::string::String,
   671|             a_complicated_thing: std::option::Option<std::result::Result<(),()>>,
   672|           }
   673|         };
   674|         let fields = extract_fields(snippet);
   675|         let converted_fields: Vec<_> = fields.iter().map(Type::from).collect();
   676|         let inner_types: Vec<_> = converted_fields
   677|             .iter()
   678|             .map(|field| field.inner_type())
   679|             .collect();
   680|         let inner_types_strs: Vec<_> = inner_types
   681|             .iter()
   682|             .map(|ty| (quote! { #ty }).to_string())
   683|             .collect();
   684|         assert_eq!(
   685|             inner_types_strs,
   686|             vec![
   687|                 "u8",
   688|                 "bool",
   689|                 "std :: string :: String",
   690|                 "std :: result :: Result < () , () >"
   691|             ]
   692|         )
   693|     }
   694|     #[test]
   695|     fn test_physical_type() {
   696|         use parquet::basic::Type as BasicType;
   697|         let snippet: proc_macro2::TokenStream = quote! {
   698|           struct LotsOfInnerTypes {
   699|             a_buf: Vec<u8>,
   700|             a_number: i32,
   701|             a_verbose_option: std::option::Option<bool>,
   702|             a_silly_string: std::string::String,
   703|             a_fix_byte_buf: [u8; 10],
   704|             a_complex_option: Option<&Vec<u8>>,
   705|             a_complex_vec: &Vec<&Option<u8>>,
   706|           }
   707|         };
   708|         let fields = extract_fields(snippet);
   709|         let converted_fields: Vec<_> = fields.iter().map(Type::from).collect();
   710|         let physical_types: Vec<_> = converted_fields
   711|             .iter()
   712|             .map(|ty| ty.physical_type())
   713|             .collect();
   714|         assert_eq!(
   715|             physical_types,
   716|             vec![
   717|                 BasicType::BYTE_ARRAY,
   718|                 BasicType::INT32,
   719|                 BasicType::BOOLEAN,
   720|                 BasicType::BYTE_ARRAY,
   721|                 BasicType::FIXED_LEN_BYTE_ARRAY,
   722|                 BasicType::BYTE_ARRAY,
   723|                 BasicType::INT32
   724|             ]
   725|         )
   726|     }
   727|     #[test]
   728|     fn test_convert_comprehensive_owned_struct() {
   729|         let snippet: proc_macro2::TokenStream = quote! {
   730|           struct VecHolder {
   731|             a_vec: Vec<u8>,
   732|             a_option: std::option::Option<bool>,
   733|             a_silly_string: std::string::String,
   734|             a_complicated_thing: std::option::Option<std::result::Result<(),()>>,
   735|           }
   736|         };
   737|         let fields = extract_fields(snippet);
   738|         let converted_fields: Vec<_> = fields.iter().map(Type::from).collect();
   739|         assert_eq!(
   740|             converted_fields,
   741|             vec![
   742|                 Type::Vec(Box::new(Type::TypePath(syn::parse_quote!(u8)))),
   743|                 Type::Option(Box::new(Type::TypePath(syn::parse_quote!(bool)))),
   744|                 Type::TypePath(syn::parse_quote!(std::string::String)),
   745|                 Type::Option(Box::new(Type::TypePath(
   746|                     syn::parse_quote!(std::result::Result<(),()>)
   747|                 ))),
   748|             ]
   749|         );
   750|     }
   751|     #[test]
   752|     fn test_convert_borrowed_struct() {
   753|         let snippet: proc_macro2::TokenStream = quote! {
   754|           struct Borrower<'a> {
   755|             a_str: &'a str,
   756|             a_borrowed_option: &'a Option<bool>,
   757|             so_many_borrows: &'a Option<&'a str>,
   758|           }
   759|         };
   760|         let fields = extract_fields(snippet);
   761|         let types: Vec<_> = fields.iter().map(Type::from).collect();
   762|         assert_eq!(
   763|             types,
   764|             vec![
   765|                 Type::Reference(
   766|                     Some(syn::Lifetime::new("'a", proc_macro2::Span::call_site())),
   767|                     Box::new(Type::TypePath(syn::parse_quote!(str)))
   768|                 ),
   769|                 Type::Reference(
   770|                     Some(syn::Lifetime::new("'a", proc_macro2::Span::call_site())),
   771|                     Box::new(Type::Option(Box::new(Type::TypePath(syn::parse_quote!(
   772|                         bool
   773|                     )))))
   774|                 ),
   775|                 Type::Reference(
   776|                     Some(syn::Lifetime::new("'a", proc_macro2::Span::call_site())),
   777|                     Box::new(Type::Option(Box::new(Type::Reference(
   778|                         Some(syn::Lifetime::new("'a", proc_macro2::Span::call_site())),
   779|                         Box::new(Type::TypePath(syn::parse_quote!(str)))
   780|                     ))))
   781|                 ),

