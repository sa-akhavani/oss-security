--- a/backend/apps/audio/main.py
+++ b/backend/apps/audio/main.py
@@ -28,21 +28,20 @@
     AUDIO_STT_OPENAI_API_BASE_URL,
     AUDIO_STT_OPENAI_API_KEY,
     AUDIO_TTS_OPENAI_API_BASE_URL,
     AUDIO_TTS_OPENAI_API_KEY,
     AUDIO_TTS_API_KEY,
     AUDIO_STT_ENGINE,
     AUDIO_STT_MODEL,
     AUDIO_TTS_ENGINE,
     AUDIO_TTS_MODEL,
     AUDIO_TTS_VOICE,
-    AUDIO_TTS_SPLIT_ON,
     AppConfig,
     CORS_ALLOW_ORIGIN,
 )
 from constants import ERROR_MESSAGES
 from utils.utils import (
     get_current_user,
     get_verified_user,
     get_admin_user,
 )
 log = logging.getLogger(__name__)
@@ -59,33 +58,31 @@
 app.state.config.STT_OPENAI_API_BASE_URL = AUDIO_STT_OPENAI_API_BASE_URL
 app.state.config.STT_OPENAI_API_KEY = AUDIO_STT_OPENAI_API_KEY
 app.state.config.STT_ENGINE = AUDIO_STT_ENGINE
 app.state.config.STT_MODEL = AUDIO_STT_MODEL
 app.state.config.TTS_OPENAI_API_BASE_URL = AUDIO_TTS_OPENAI_API_BASE_URL
 app.state.config.TTS_OPENAI_API_KEY = AUDIO_TTS_OPENAI_API_KEY
 app.state.config.TTS_ENGINE = AUDIO_TTS_ENGINE
 app.state.config.TTS_MODEL = AUDIO_TTS_MODEL
 app.state.config.TTS_VOICE = AUDIO_TTS_VOICE
 app.state.config.TTS_API_KEY = AUDIO_TTS_API_KEY
-app.state.config.TTS_SPLIT_ON = AUDIO_TTS_SPLIT_ON
 whisper_device_type = DEVICE_TYPE if DEVICE_TYPE and DEVICE_TYPE == "cuda" else "cpu"
 log.info(f"whisper_device_type: {whisper_device_type}")
 SPEECH_CACHE_DIR = Path(CACHE_DIR).joinpath("./audio/speech/")
 SPEECH_CACHE_DIR.mkdir(parents=True, exist_ok=True)
 class TTSConfigForm(BaseModel):
     OPENAI_API_BASE_URL: str
     OPENAI_API_KEY: str
     API_KEY: str
     ENGINE: str
     MODEL: str
     VOICE: str
-    SPLIT_ON: str
 class STTConfigForm(BaseModel):
     OPENAI_API_BASE_URL: str
     OPENAI_API_KEY: str
     ENGINE: str
     MODEL: str
 class AudioConfigUpdateForm(BaseModel):
     tts: TTSConfigForm
     stt: STTConfigForm
 from pydub import AudioSegment
 from pydub.utils import mediainfo
@@ -110,53 +107,50 @@
 @app.get("/config")
 async def get_audio_config(user=Depends(get_admin_user)):
     return {
         "tts": {
             "OPENAI_API_BASE_URL": app.state.config.TTS_OPENAI_API_BASE_URL,
             "OPENAI_API_KEY": app.state.config.TTS_OPENAI_API_KEY,
             "API_KEY": app.state.config.TTS_API_KEY,
             "ENGINE": app.state.config.TTS_ENGINE,
             "MODEL": app.state.config.TTS_MODEL,
             "VOICE": app.state.config.TTS_VOICE,
-            "SPLIT_ON": app.state.config.TTS_SPLIT_ON,
         },
         "stt": {
             "OPENAI_API_BASE_URL": app.state.config.STT_OPENAI_API_BASE_URL,
             "OPENAI_API_KEY": app.state.config.STT_OPENAI_API_KEY,
             "ENGINE": app.state.config.STT_ENGINE,
             "MODEL": app.state.config.STT_MODEL,
         },
     }
 @app.post("/config/update")
 async def update_audio_config(
     form_data: AudioConfigUpdateForm, user=Depends(get_admin_user)
 ):
     app.state.config.TTS_OPENAI_API_BASE_URL = form_data.tts.OPENAI_API_BASE_URL
     app.state.config.TTS_OPENAI_API_KEY = form_data.tts.OPENAI_API_KEY
     app.state.config.TTS_API_KEY = form_data.tts.API_KEY
     app.state.config.TTS_ENGINE = form_data.tts.ENGINE
     app.state.config.TTS_MODEL = form_data.tts.MODEL
     app.state.config.TTS_VOICE = form_data.tts.VOICE
-    app.state.config.TTS_SPLIT_ON = form_data.tts.SPLIT_ON
     app.state.config.STT_OPENAI_API_BASE_URL = form_data.stt.OPENAI_API_BASE_URL
     app.state.config.STT_OPENAI_API_KEY = form_data.stt.OPENAI_API_KEY
     app.state.config.STT_ENGINE = form_data.stt.ENGINE
     app.state.config.STT_MODEL = form_data.stt.MODEL
     return {
         "tts": {
             "OPENAI_API_BASE_URL": app.state.config.TTS_OPENAI_API_BASE_URL,
             "OPENAI_API_KEY": app.state.config.TTS_OPENAI_API_KEY,
             "API_KEY": app.state.config.TTS_API_KEY,
             "ENGINE": app.state.config.TTS_ENGINE,
             "MODEL": app.state.config.TTS_MODEL,
             "VOICE": app.state.config.TTS_VOICE,
-            "SPLIT_ON": app.state.config.TTS_SPLIT_ON,
         },
         "stt": {
             "OPENAI_API_BASE_URL": app.state.config.STT_OPENAI_API_BASE_URL,
             "OPENAI_API_KEY": app.state.config.STT_OPENAI_API_KEY,
             "ENGINE": app.state.config.STT_ENGINE,
             "MODEL": app.state.config.STT_MODEL,
         },
     }
 @app.post("/speech")
 async def speech(request: Request, user=Depends(get_verified_user)):

--- a/backend/apps/images/main.py
+++ b/backend/apps/images/main.py
@@ -8,21 +8,20 @@
 from typing import Optional
 from pydantic import BaseModel
 from pathlib import Path
 import mimetypes
 import uuid
 import base64
 import json
 import logging
 import re
 import requests
-import asyncio
 from utils.utils import (
     get_verified_user,
     get_admin_user,
 )
 from apps.images.utils.comfyui import (
     ComfyUIWorkflow,
     ComfyUIGenerateImageForm,
     comfyui_generate_image,
 )
 from constants import ERROR_MESSAGES
@@ -433,22 +432,21 @@
             data = {
                 "prompt": form_data.prompt,
                 "batch_size": form_data.n,
                 "width": width,
                 "height": height,
             }
             if app.state.config.IMAGE_STEPS is not None:
                 data["steps"] = app.state.config.IMAGE_STEPS
             if form_data.negative_prompt is not None:
                 data["negative_prompt"] = form_data.negative_prompt
-            r = await asyncio.to_thread(
-                requests.post,
+            r = requests.post(
                 url=f"{app.state.config.AUTOMATIC1111_BASE_URL}/sdapi/v1/txt2img",
                 json=data,
                 headers={"authorization": get_automatic1111_api_auth()},
             )
             res = r.json()
             log.debug(f"res: {res}")
             images = []
             for image in res["images"]:
                 image_filename = save_b64_image(image)
                 images.append({"url": f"/cache/image/generations/{image_filename}"})

--- a/backend/apps/ollama/main.py
+++ b/backend/apps/ollama/main.py
@@ -101,42 +101,37 @@
         log.error(f"Connection error: {e}")
         return None
 async def cleanup_response(
     response: Optional[aiohttp.ClientResponse],
     session: Optional[aiohttp.ClientSession],
 ):
     if response:
         response.close()
     if session:
         await session.close()
-async def post_streaming_url(
-    url: str, payload: Union[str, bytes], stream: bool = True, content_type=None
-):
+async def post_streaming_url(url: str, payload: Union[str, bytes], stream: bool = True):
     r = None
     try:
         session = aiohttp.ClientSession(
             trust_env=True, timeout=aiohttp.ClientTimeout(total=AIOHTTP_CLIENT_TIMEOUT)
         )
         r = await session.post(
             url,
             data=payload,
             headers={"Content-Type": "application/json"},
         )
         r.raise_for_status()
         if stream:
-            headers = dict(r.headers)
-            if content_type:
-                headers["Content-Type"] = content_type
             return StreamingResponse(
                 r.content,
                 status_code=r.status,
-                headers=headers,
+                headers=dict(r.headers),
                 background=BackgroundTask(
                     cleanup_response, response=r, session=session
                 ),
             )
         else:
             res = await r.json()
             await cleanup_response(r, session)
             return res
     except Exception as e:
         error_detail = "Open WebUI: Server Connection Error"
@@ -589,46 +584,38 @@
 async def generate_chat_completion(
     form_data: GenerateChatCompletionForm,
     url_idx: Optional[int] = None,
     user=Depends(get_verified_user),
 ):
     payload = {**form_data.model_dump(exclude_none=True)}
     log.debug(f"{payload = }")
     if "metadata" in payload:
         del payload["metadata"]
     model_id = form_data.model
-    if app.state.config.ENABLE_MODEL_FILTER:
-        if user.role == "user" and model_id not in app.state.config.MODEL_FILTER_LIST:
-            raise HTTPException(
-                status_code=403,
-                detail="Model not found",
-            )
     model_info = Models.get_model_by_id(model_id)
     if model_info:
         if model_info.base_model_id:
             payload["model"] = model_info.base_model_id
         params = model_info.params.model_dump()
         if params:
             if payload.get("options") is None:
                 payload["options"] = {}
             payload["options"] = apply_model_params_to_body_ollama(
                 params, payload["options"]
             )
             payload = apply_model_system_prompt_to_body(params, payload, user)
     if ":" not in payload["model"]:
         payload["model"] = f"{payload['model']}:latest"
     url = get_ollama_url(url_idx, payload["model"])
     log.info(f"url: {url}")
     log.debug(payload)
-    return await post_streaming_url(
-        f"{url}/api/chat", json.dumps(payload), content_type="application/x-ndjson"
-    )
+    return await post_streaming_url(f"{url}/api/chat", json.dumps(payload))
 class OpenAIChatMessageContent(BaseModel):
     type: str
     model_config = ConfigDict(extra="allow")
 class OpenAIChatMessage(BaseModel):
     role: str
     content: Union[str, OpenAIChatMessageContent]
     model_config = ConfigDict(extra="allow")
 class OpenAIChatCompletionForm(BaseModel):
     model: str
     messages: list[OpenAIChatMessage]
@@ -638,26 +625,20 @@
 async def generate_openai_chat_completion(
     form_data: dict,
     url_idx: Optional[int] = None,
     user=Depends(get_verified_user),
 ):
     completion_form = OpenAIChatCompletionForm(**form_data)
     payload = {**completion_form.model_dump(exclude_none=True, exclude=["metadata"])}
     if "metadata" in payload:
         del payload["metadata"]
     model_id = completion_form.model
-    if app.state.config.ENABLE_MODEL_FILTER:
-        if user.role == "user" and model_id not in app.state.config.MODEL_FILTER_LIST:
-            raise HTTPException(
-                status_code=403,
-                detail="Model not found",
-            )
     model_info = Models.get_model_by_id(model_id)
     if model_info:
         if model_info.base_model_id:
             payload["model"] = model_info.base_model_id
         params = model_info.params.model_dump()
         if params:
             payload = apply_model_params_to_body_openai(params, payload)
             payload = apply_model_system_prompt_to_body(params, payload, user)
     if ":" not in payload["model"]:
         payload["model"] = f"{payload['model']}:latest"

--- a/backend/apps/rag/main.py
+++ b/backend/apps/rag/main.py
@@ -77,22 +77,20 @@
 from config import (
     AppConfig,
     ENV,
     SRC_LOG_LEVELS,
     UPLOAD_DIR,
     DOCS_DIR,
     CONTENT_EXTRACTION_ENGINE,
     TIKA_SERVER_URL,
     RAG_TOP_K,
     RAG_RELEVANCE_THRESHOLD,
-    RAG_FILE_MAX_SIZE,
-    RAG_FILE_MAX_COUNT,
     RAG_EMBEDDING_ENGINE,
     RAG_EMBEDDING_MODEL,
     RAG_EMBEDDING_MODEL_AUTO_UPDATE,
     RAG_EMBEDDING_MODEL_TRUST_REMOTE_CODE,
     ENABLE_RAG_HYBRID_SEARCH,
     ENABLE_RAG_WEB_LOADER_SSL_VERIFICATION,
     RAG_RERANKING_MODEL,
     PDF_EXTRACT_IMAGES,
     RAG_RERANKING_MODEL_AUTO_UPDATE,
     RAG_RERANKING_MODEL_TRUST_REMOTE_CODE,
@@ -122,22 +120,20 @@
     RAG_EMBEDDING_OPENAI_BATCH_SIZE,
     CORS_ALLOW_ORIGIN,
 )
 from constants import ERROR_MESSAGES
 log = logging.getLogger(__name__)
 log.setLevel(SRC_LOG_LEVELS["RAG"])
 app = FastAPI()
 app.state.config = AppConfig()
 app.state.config.TOP_K = RAG_TOP_K
 app.state.config.RELEVANCE_THRESHOLD = RAG_RELEVANCE_THRESHOLD
-app.state.config.FILE_MAX_SIZE = RAG_FILE_MAX_SIZE
-app.state.config.FILE_MAX_COUNT = RAG_FILE_MAX_COUNT
 app.state.config.ENABLE_RAG_HYBRID_SEARCH = ENABLE_RAG_HYBRID_SEARCH
 app.state.config.ENABLE_RAG_WEB_LOADER_SSL_VERIFICATION = (
     ENABLE_RAG_WEB_LOADER_SSL_VERIFICATION
 )
 app.state.config.CONTENT_EXTRACTION_ENGINE = CONTENT_EXTRACTION_ENGINE
 app.state.config.TIKA_SERVER_URL = TIKA_SERVER_URL
 app.state.config.CHUNK_SIZE = CHUNK_SIZE
 app.state.config.CHUNK_OVERLAP = CHUNK_OVERLAP
 app.state.config.RAG_EMBEDDING_ENGINE = RAG_EMBEDDING_ENGINE
 app.state.config.RAG_EMBEDDING_MODEL = RAG_EMBEDDING_MODEL
@@ -320,24 +316,20 @@
         log.exception(f"Problem updating reranking model: {e}")
         raise HTTPException(
             status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
             detail=ERROR_MESSAGES.DEFAULT(e),
         )
 @app.get("/config")
 async def get_rag_config(user=Depends(get_admin_user)):
     return {
         "status": True,
         "pdf_extract_images": app.state.config.PDF_EXTRACT_IMAGES,
-        "file": {
-            "max_size": app.state.config.FILE_MAX_SIZE,
-            "max_count": app.state.config.FILE_MAX_COUNT,
-        },
         "content_extraction": {
             "engine": app.state.config.CONTENT_EXTRACTION_ENGINE,
             "tika_server_url": app.state.config.TIKA_SERVER_URL,
         },
         "chunk": {
             "chunk_size": app.state.config.CHUNK_SIZE,
             "chunk_overlap": app.state.config.CHUNK_OVERLAP,
         },
         "youtube": {
             "language": app.state.config.YOUTUBE_LOADER_LANGUAGE,
@@ -355,23 +347,20 @@
                 "serpstack_api_key": app.state.config.SERPSTACK_API_KEY,
                 "serpstack_https": app.state.config.SERPSTACK_HTTPS,
                 "serper_api_key": app.state.config.SERPER_API_KEY,
                 "serply_api_key": app.state.config.SERPLY_API_KEY,
                 "tavily_api_key": app.state.config.TAVILY_API_KEY,
                 "result_count": app.state.config.RAG_WEB_SEARCH_RESULT_COUNT,
                 "concurrent_requests": app.state.config.RAG_WEB_SEARCH_CONCURRENT_REQUESTS,
             },
         },
     }
-class FileConfig(BaseModel):
-    max_size: Optional[int] = None
-    max_count: Optional[int] = None
 class ContentExtractionConfig(BaseModel):
     engine: str = ""
     tika_server_url: Optional[str] = None
 class ChunkParamUpdateForm(BaseModel):
     chunk_size: int
     chunk_overlap: int
 class YoutubeLoaderConfig(BaseModel):
     language: list[str]
     translation: Optional[str] = None
 class WebSearchConfig(BaseModel):
@@ -386,35 +375,31 @@
     serper_api_key: Optional[str] = None
     serply_api_key: Optional[str] = None
     tavily_api_key: Optional[str] = None
     result_count: Optional[int] = None
     concurrent_requests: Optional[int] = None
 class WebConfig(BaseModel):
     search: WebSearchConfig
     web_loader_ssl_verification: Optional[bool] = None
 class ConfigUpdateForm(BaseModel):
     pdf_extract_images: Optional[bool] = None
-    file: Optional[FileConfig] = None
     content_extraction: Optional[ContentExtractionConfig] = None
     chunk: Optional[ChunkParamUpdateForm] = None
     youtube: Optional[YoutubeLoaderConfig] = None
     web: Optional[WebConfig] = None
 @app.post("/config/update")
 async def update_rag_config(form_data: ConfigUpdateForm, user=Depends(get_admin_user)):
     app.state.config.PDF_EXTRACT_IMAGES = (
         form_data.pdf_extract_images
         if form_data.pdf_extract_images is not None
         else app.state.config.PDF_EXTRACT_IMAGES
     )
-    if form_data.file is not None:
-        app.state.config.FILE_MAX_SIZE = form_data.file.max_size
-        app.state.config.FILE_MAX_COUNT = form_data.file.max_count
     if form_data.content_extraction is not None:
         log.info(f"Updating text settings: {form_data.content_extraction}")
         app.state.config.CONTENT_EXTRACTION_ENGINE = form_data.content_extraction.engine
         app.state.config.TIKA_SERVER_URL = form_data.content_extraction.tika_server_url
     if form_data.chunk is not None:
         app.state.config.CHUNK_SIZE = form_data.chunk.chunk_size
         app.state.config.CHUNK_OVERLAP = form_data.chunk.chunk_overlap
     if form_data.youtube is not None:
         app.state.config.YOUTUBE_LOADER_LANGUAGE = form_data.youtube.language
         app.state.YOUTUBE_LOADER_TRANSLATION = form_data.youtube.translation
@@ -437,24 +422,20 @@
         app.state.config.SERPER_API_KEY = form_data.web.search.serper_api_key
         app.state.config.SERPLY_API_KEY = form_data.web.search.serply_api_key
         app.state.config.TAVILY_API_KEY = form_data.web.search.tavily_api_key
         app.state.config.RAG_WEB_SEARCH_RESULT_COUNT = form_data.web.search.result_count
         app.state.config.RAG_WEB_SEARCH_CONCURRENT_REQUESTS = (
             form_data.web.search.concurrent_requests
         )
     return {
         "status": True,
         "pdf_extract_images": app.state.config.PDF_EXTRACT_IMAGES,
-        "file": {
-            "max_size": app.state.config.FILE_MAX_SIZE,
-            "max_count": app.state.config.FILE_MAX_COUNT,
-        },
         "content_extraction": {
             "engine": app.state.config.CONTENT_EXTRACTION_ENGINE,
             "tika_server_url": app.state.config.TIKA_SERVER_URL,
         },
         "chunk": {
             "chunk_size": app.state.config.CHUNK_SIZE,
             "chunk_overlap": app.state.config.CHUNK_OVERLAP,
         },
         "youtube": {
             "language": app.state.config.YOUTUBE_LOADER_LANGUAGE,
@@ -1171,43 +1152,43 @@
                                         ),
                                     }
                                 ),
                             )
                 except Exception as e:
                     log.exception(e)
                     pass
         except Exception as e:
             log.exception(e)
     return True
-@app.post("/reset/db")
+@app.get("/reset/db")
 def reset_vector_db(user=Depends(get_admin_user)):
     CHROMA_CLIENT.reset()
-@app.post("/reset/uploads")
+@app.get("/reset/uploads")
 def reset_upload_dir(user=Depends(get_admin_user)) -> bool:
     folder = f"{UPLOAD_DIR}"
     try:
         if os.path.exists(folder):
             for filename in os.listdir(folder):
                 file_path = os.path.join(folder, filename)
                 try:
                     if os.path.isfile(file_path) or os.path.islink(file_path):
                         os.unlink(file_path)  # Remove the file or link
                     elif os.path.isdir(file_path):
                         shutil.rmtree(file_path)  # Remove the directory
                 except Exception as e:
                     print(f"Failed to delete {file_path}. Reason: {e}")
         else:
             print(f"The directory {folder} does not exist")
     except Exception as e:
         print(f"Failed to process the directory {folder}. Reason: {e}")
     return True
-@app.post("/reset")
+@app.get("/reset")
 def reset(user=Depends(get_admin_user)) -> bool:
     folder = f"{UPLOAD_DIR}"
     for filename in os.listdir(folder):
         file_path = os.path.join(folder, filename)
         try:
             if os.path.isfile(file_path) or os.path.islink(file_path):
                 os.unlink(file_path)
             elif os.path.isdir(file_path):
                 shutil.rmtree(file_path)
         except Exception as e:

--- a/backend/apps/rag/utils.py
+++ b/backend/apps/rag/utils.py
@@ -104,32 +104,29 @@
     }
     return result
 def query_collection(
     collection_names: list[str],
     query: str,
     embedding_function,
     k: int,
 ):
     results = []
     for collection_name in collection_names:
-        if collection_name:
-            try:
-                result = query_doc(
-                    collection_name=collection_name,
-                    query=query,
-                    k=k,
-                    embedding_function=embedding_function,
-                )
-                results.append(result)
-            except Exception:
-                pass
-        else:
+        try:
+            result = query_doc(
+                collection_name=collection_name,
+                query=query,
+                k=k,
+                embedding_function=embedding_function,
+            )
+            results.append(result)
+        except Exception:
             pass
     return merge_and_sort_query_results(results, k=k)
 def query_collection_with_hybrid_search(
     collection_names: list[str],
     query: str,
     embedding_function,
     k: int,
     reranking_function,
     r: float,
 ):
@@ -202,21 +199,21 @@
 ):
     log.debug(f"files: {files} {messages} {embedding_function} {reranking_function}")
     query = get_last_user_message(messages)
     extracted_collections = []
     relevant_contexts = []
     for file in files:
         context = None
         collection_names = (
             file["collection_names"]
             if file["type"] == "collection"
-            else [file["collection_name"]] if file["collection_name"] else []
+            else [file["collection_name"]]
         )
         collection_names = set(collection_names).difference(extracted_collections)
         if not collection_names:
             log.debug(f"skipping {file} as it has already been extracted")
             continue
         try:
             if file["type"] == "text":
                 context = file["content"]
             else:
                 if hybrid_search:

--- a/backend/apps/webui/internal/db.py
+++ b/backend/apps/webui/internal/db.py
@@ -1,43 +1,50 @@
 import os
 import logging
 import json
 from contextlib import contextmanager
+from peewee_migrate import Router
+from apps.webui.internal.wrappers import register_connection
 from typing import Optional, Any
 from typing_extensions import Self
 from sqlalchemy import create_engine, types, Dialect
-from sqlalchemy.sql.type_api import _T
 from sqlalchemy.ext.declarative import declarative_base
 from sqlalchemy.orm import sessionmaker, scoped_session
-from peewee_migrate import Router
-from apps.webui.internal.wrappers import register_connection
-from env import SRC_LOG_LEVELS, BACKEND_DIR, DATABASE_URL
+from sqlalchemy.sql.type_api import _T
+from config import SRC_LOG_LEVELS, DATA_DIR, DATABASE_URL, BACKEND_DIR
 log = logging.getLogger(__name__)
 log.setLevel(SRC_LOG_LEVELS["DB"])
 class JSONField(types.TypeDecorator):
     impl = types.Text
     cache_ok = True
     def process_bind_param(self, value: Optional[_T], dialect: Dialect) -> Any:
         return json.dumps(value)
     def process_result_value(self, value: Optional[_T], dialect: Dialect) -> Any:
         if value is not None:
             return json.loads(value)
     def copy(self, **kw: Any) -> Self:
         return JSONField(self.impl.length)
     def db_value(self, value):
         return json.dumps(value)
     def python_value(self, value):
         if value is not None:
             return json.loads(value)
+if os.path.exists(f"{DATA_DIR}/ollama.db"):
+    os.rename(f"{DATA_DIR}/ollama.db", f"{DATA_DIR}/webui.db")
+    log.info("Database migrated from Ollama-WebUI successfully.")
+else:
+    pass
 def handle_peewee_migration(DATABASE_URL):
     try:
-        db = register_connection(DATABASE_URL.replace("postgresql://", "postgres://"))
+        db = register_connection(
+            DATABASE_URL.replace("postgresql://", "postgres://").replace("%40", "@")
+        )
         migrate_dir = BACKEND_DIR / "apps" / "webui" / "internal" / "migrations"
         router = Router(db, logger=log, migrate_dir=migrate_dir)
         router.run()
         db.close()
     except Exception as e:
         log.error(f"Failed to initialize the database connection: {e}")
         raise
     finally:
         if db and not db.is_closed():
             db.close()

--- a/backend/apps/webui/internal/wrappers.py
+++ b/backend/apps/webui/internal/wrappers.py
@@ -1,17 +1,17 @@
 from contextvars import ContextVar
 from peewee import *
 from peewee import PostgresqlDatabase, InterfaceError as PeeWeeInterfaceError
 import logging
 from playhouse.db_url import connect, parse
 from playhouse.shortcuts import ReconnectMixin
-from env import SRC_LOG_LEVELS
+from config import SRC_LOG_LEVELS
 log = logging.getLogger(__name__)
 log.setLevel(SRC_LOG_LEVELS["DB"])
 db_state_default = {"closed": None, "conn": None, "ctx": None, "transactions": None}
 db_state = ContextVar("db_state", default=db_state_default.copy())
 class PeeweeConnectionState(object):
     def __init__(self, **kwargs):
         super().__setattr__("_state", db_state)
         super().__init__(**kwargs)
     def __setattr__(self, name, value):
         self._state.get()[name] = value
@@ -20,25 +20,31 @@
         return value
 class CustomReconnectMixin(ReconnectMixin):
     reconnect_errors = (
         (OperationalError, "termin"),
         (InterfaceError, "closed"),
         (PeeWeeInterfaceError, "closed"),
     )
 class ReconnectingPostgresqlDatabase(CustomReconnectMixin, PostgresqlDatabase):
     pass
 def register_connection(db_url):
-    db = connect(db_url, unquote_password=True)
+    db = connect(db_url)
     if isinstance(db, PostgresqlDatabase):
         db.autoconnect = True
         db.reuse_if_open = True
         log.info("Connected to PostgreSQL database")
-        connection = parse(db_url, unquote_password=True)
-        db = ReconnectingPostgresqlDatabase(**connection)
+        connection = parse(db_url)
+        db = ReconnectingPostgresqlDatabase(
+            connection["database"],
+            user=connection["user"],
+            password=connection["password"],
+            host=connection["host"],
+            port=connection["port"],
+        )
         db.connect(reuse_if_open=True)
     elif isinstance(db, SqliteDatabase):
         db.autoconnect = True
         db.reuse_if_open = True
         log.info("Connected to SQLite database")
     else:
         raise ValueError("Unsupported database connection")
     return db

--- a/backend/apps/webui/main.py
+++ b/backend/apps/webui/main.py
@@ -44,25 +44,23 @@
     ENABLE_MESSAGE_RATING,
     AppConfig,
     OAUTH_USERNAME_CLAIM,
     OAUTH_PICTURE_CLAIM,
     OAUTH_EMAIL_CLAIM,
     CORS_ALLOW_ORIGIN,
 )
 from apps.socket.main import get_event_call, get_event_emitter
 import inspect
 import json
-import logging
 from typing import Iterator, Generator, AsyncGenerator
 from pydantic import BaseModel
 app = FastAPI()
-log = logging.getLogger(__name__)
 app.state.config = AppConfig()
 app.state.config.ENABLE_SIGNUP = ENABLE_SIGNUP
 app.state.config.ENABLE_LOGIN_FORM = ENABLE_LOGIN_FORM
 app.state.config.JWT_EXPIRES_IN = JWT_EXPIRES_IN
 app.state.AUTH_TRUSTED_EMAIL_HEADER = WEBUI_AUTH_TRUSTED_EMAIL_HEADER
 app.state.AUTH_TRUSTED_NAME_HEADER = WEBUI_AUTH_TRUSTED_NAME_HEADER
 app.state.config.SHOW_ADMIN_DETAILS = SHOW_ADMIN_DETAILS
 app.state.config.ADMIN_EMAIL = ADMIN_EMAIL
 app.state.config.DEFAULT_MODELS = DEFAULT_MODELS
 app.state.config.DEFAULT_PROMPT_SUGGESTIONS = DEFAULT_PROMPT_SUGGESTIONS
@@ -185,35 +183,42 @@
         return f"{line}\n\n"
     else:
         line = openai_chat_chunk_message_template(form_data["model"], line)
         return f"data: {json.dumps(line)}\n\n"
 def get_pipe_id(form_data: dict) -> str:
     pipe_id = form_data["model"]
     if "." in pipe_id:
         pipe_id, _ = pipe_id.split(".", 1)
     print(pipe_id)
     return pipe_id
-def get_function_params(function_module, form_data, user, extra_params=None):
-    if extra_params is None:
-        extra_params = {}
+def get_function_params(function_module, form_data, user, extra_params={}):
     pipe_id = get_pipe_id(form_data)
     sig = inspect.signature(function_module.pipe)
-    params = {"body": form_data} | {
-        k: v for k, v in extra_params.items() if k in sig.parameters
-    }
-    if "__user__" in params and hasattr(function_module, "UserValves"):
-        user_valves = Functions.get_user_valves_by_id_and_user_id(pipe_id, user.id)
+    params = {"body": form_data}
+    for key, value in extra_params.items():
+        if key in sig.parameters:
+            params[key] = value
+    if "__user__" in sig.parameters:
+        __user__ = {
+            "id": user.id,
+            "email": user.email,
+            "name": user.name,
+            "role": user.role,
+        }
         try:
-            params["__user__"]["valves"] = function_module.UserValves(**user_valves)
+            if hasattr(function_module, "UserValves"):
+                __user__["valves"] = function_module.UserValves(
+                    **Functions.get_user_valves_by_id_and_user_id(pipe_id, user.id)
+                )
         except Exception as e:
-            log.exception(e)
-            params["__user__"]["valves"] = function_module.UserValves()
+            print(e)
+        params["__user__"] = __user__
     return params
 async def generate_function_chat_completion(form_data, user):
     model_id = form_data.get("model")
     model_info = Models.get_model_by_id(model_id)
     metadata = form_data.pop("metadata", {})
     files = metadata.get("files", [])
     tool_ids = metadata.get("tool_ids", [])
     if tool_ids is None:
         tool_ids = []
     __event_emitter__ = None
@@ -221,39 +226,29 @@
     __task__ = None
     if metadata:
         if all(k in metadata for k in ("session_id", "chat_id", "message_id")):
             __event_emitter__ = get_event_emitter(metadata)
             __event_call__ = get_event_call(metadata)
         __task__ = metadata.get("task", None)
     extra_params = {
         "__event_emitter__": __event_emitter__,
         "__event_call__": __event_call__,
         "__task__": __task__,
+    }
+    tools_params = {
+        **extra_params,
+        "__model__": app.state.MODELS[form_data["model"]],
+        "__messages__": form_data["messages"],
         "__files__": files,
-        "__user__": {
-            "id": user.id,
-            "email": user.email,
-            "name": user.name,
-            "role": user.role,
-        },
     }
-    extra_params["__tools__"] = get_tools(
-        app,
-        tool_ids,
-        user,
-        {
-            **extra_params,
-            "__model__": app.state.MODELS[form_data["model"]],
-            "__messages__": form_data["messages"],
-            "__files__": files,
-        },
-    )
+    tools = get_tools(app, tool_ids, user, tools_params)
+    extra_params["__tools__"] = tools
     if model_info:
         if model_info.base_model_id:
             form_data["model"] = model_info.base_model_id
         params = model_info.params.model_dump()
         form_data = apply_model_params_to_body_openai(params, form_data)
         form_data = apply_model_system_prompt_to_body(params, form_data, user)
     pipe_id = get_pipe_id(form_data)
     function_module = get_function_module(pipe_id)
     pipe = function_module.pipe
     params = get_function_params(function_module, form_data, user, extra_params)

--- a/backend/apps/webui/models/auths.py
+++ b/backend/apps/webui/models/auths.py
@@ -1,19 +1,19 @@
 from pydantic import BaseModel
 from typing import Optional
 import uuid
 import logging
 from sqlalchemy import String, Column, Boolean, Text
+from apps.webui.models.users import UserModel, Users
 from utils.utils import verify_password
-from apps.webui.models.users import UserModel, Users
 from apps.webui.internal.db import Base, get_db
-from env import SRC_LOG_LEVELS
+from config import SRC_LOG_LEVELS
 log = logging.getLogger(__name__)
 log.setLevel(SRC_LOG_LEVELS["MODELS"])
 class Auth(Base):
     __tablename__ = "auth"
     id = Column(String, primary_key=True)
     email = Column(String)
     password = Column(Text)
     active = Column(Boolean)
 class AuthModel(BaseModel):
     id: str

--- a/backend/apps/webui/models/chats.py
+++ b/backend/apps/webui/models/chats.py
@@ -179,35 +179,34 @@
                 query = query.filter_by(archived=False)
             all_chats = (
                 query.order_by(Chat.updated_at.desc())
                 .all()
             )
             return [ChatModel.model_validate(chat) for chat in all_chats]
     def get_chat_title_id_list_by_user_id(
         self,
         user_id: str,
         include_archived: bool = False,
-        skip: Optional[int] = None,
-        limit: Optional[int] = None,
+        skip: int = 0,
+        limit: int = -1,
     ) -> list[ChatTitleIdResponse]:
         with get_db() as db:
             query = db.query(Chat).filter_by(user_id=user_id)
             if not include_archived:
                 query = query.filter_by(archived=False)
-            query = query.order_by(Chat.updated_at.desc()).with_entities(
-                Chat.id, Chat.title, Chat.updated_at, Chat.created_at
-            )
-            if limit:
-                query = query.limit(limit)
-            if skip:
-                query = query.offset(skip)
-            all_chats = query.all()
+            all_chats = (
+                query.order_by(Chat.updated_at.desc())
+                .with_entities(Chat.id, Chat.title, Chat.updated_at, Chat.created_at)
+                .limit(limit)
+                .offset(skip)
+                .all()
+            )
             return [
                 ChatTitleIdResponse.model_validate(
                     {
                         "id": chat[0],
                         "title": chat[1],
                         "updated_at": chat[2],
                         "created_at": chat[3],
                     }
                 )
                 for chat in all_chats

--- a/backend/apps/webui/models/documents.py
+++ b/backend/apps/webui/models/documents.py
@@ -1,18 +1,18 @@
 from pydantic import BaseModel, ConfigDict
 from typing import Optional
 import time
 import logging
 from sqlalchemy import String, Column, BigInteger, Text
 from apps.webui.internal.db import Base, get_db
 import json
-from env import SRC_LOG_LEVELS
+from config import SRC_LOG_LEVELS
 log = logging.getLogger(__name__)
 log.setLevel(SRC_LOG_LEVELS["MODELS"])
 class Document(Base):
     __tablename__ = "document"
     collection_name = Column(String, primary_key=True)
     name = Column(String, unique=True)
     title = Column(Text)
     filename = Column(Text)
     content = Column(Text, nullable=True)
     user_id = Column(String)

--- a/backend/apps/webui/models/files.py
+++ b/backend/apps/webui/models/files.py
@@ -1,18 +1,18 @@
 from pydantic import BaseModel, ConfigDict
 from typing import Union, Optional
 import time
 import logging
 from sqlalchemy import Column, String, BigInteger, Text
 from apps.webui.internal.db import JSONField, Base, get_db
 import json
-from env import SRC_LOG_LEVELS
+from config import SRC_LOG_LEVELS
 log = logging.getLogger(__name__)
 log.setLevel(SRC_LOG_LEVELS["MODELS"])
 class File(Base):
     __tablename__ = "file"
     id = Column(String, primary_key=True)
     user_id = Column(String)
     filename = Column(Text)
     meta = Column(JSONField)
     created_at = Column(BigInteger)
 class FileModel(BaseModel):
@@ -57,26 +57,20 @@
     def get_file_by_id(self, id: str) -> Optional[FileModel]:
         with get_db() as db:
             try:
                 file = db.get(File, id)
                 return FileModel.model_validate(file)
             except Exception:
                 return None
     def get_files(self) -> list[FileModel]:
         with get_db() as db:
             return [FileModel.model_validate(file) for file in db.query(File).all()]
-    def get_files_by_user_id(self, user_id: str) -> list[FileModel]:
-        with get_db() as db:
-            return [
-                FileModel.model_validate(file)
-                for file in db.query(File).filter_by(user_id=user_id).all()
-            ]
     def delete_file_by_id(self, id: str) -> bool:
         with get_db() as db:
             try:
                 db.query(File).filter_by(id=id).delete()
                 db.commit()
                 return True
             except Exception:
                 return False
     def delete_all_files(self) -> bool:
         with get_db() as db:

--- a/backend/apps/webui/models/functions.py
+++ b/backend/apps/webui/models/functions.py
@@ -1,20 +1,20 @@
 from pydantic import BaseModel, ConfigDict
 from typing import Union, Optional
 import time
 import logging
 from sqlalchemy import Column, String, Text, BigInteger, Boolean
 from apps.webui.internal.db import JSONField, Base, get_db
 from apps.webui.models.users import Users
 import json
 import copy
-from env import SRC_LOG_LEVELS
+from config import SRC_LOG_LEVELS
 log = logging.getLogger(__name__)
 log.setLevel(SRC_LOG_LEVELS["MODELS"])
 class Function(Base):
     __tablename__ = "function"
     id = Column(String, primary_key=True)
     user_id = Column(String)
     name = Column(Text)
     type = Column(Text)
     content = Column(Text)
     meta = Column(JSONField)

--- a/backend/apps/webui/models/models.py
+++ b/backend/apps/webui/models/models.py
@@ -1,16 +1,16 @@
 import logging
 from typing import Optional, List
 from pydantic import BaseModel, ConfigDict
 from sqlalchemy import Column, BigInteger, Text
 from apps.webui.internal.db import Base, JSONField, get_db
-from env import SRC_LOG_LEVELS
+from config import SRC_LOG_LEVELS
 import time
 log = logging.getLogger(__name__)
 log.setLevel(SRC_LOG_LEVELS["MODELS"])
 class ModelParams(BaseModel):
     model_config = ConfigDict(extra="allow")
     pass
 class ModelMeta(BaseModel):
     profile_image_url: Optional[str] = "/static/favicon.png"
     description: Optional[str] = None
     """

--- a/backend/apps/webui/models/tags.py
+++ b/backend/apps/webui/models/tags.py
@@ -1,19 +1,19 @@
 from pydantic import BaseModel, ConfigDict
 from typing import Optional
 import json
 import uuid
 import time
 import logging
 from sqlalchemy import String, Column, BigInteger, Text
 from apps.webui.internal.db import Base, get_db
-from env import SRC_LOG_LEVELS
+from config import SRC_LOG_LEVELS
 log = logging.getLogger(__name__)
 log.setLevel(SRC_LOG_LEVELS["MODELS"])
 class Tag(Base):
     __tablename__ = "tag"
     id = Column(String, primary_key=True)
     name = Column(String)
     user_id = Column(String)
     data = Column(Text, nullable=True)
 class ChatIdTag(Base):
     __tablename__ = "chatidtag"

--- a/backend/apps/webui/models/tools.py
+++ b/backend/apps/webui/models/tools.py
@@ -1,20 +1,20 @@
 from pydantic import BaseModel, ConfigDict
 from typing import Optional
 import time
 import logging
 from sqlalchemy import String, Column, BigInteger, Text
 from apps.webui.internal.db import Base, JSONField, get_db
 from apps.webui.models.users import Users
 import json
 import copy
-from env import SRC_LOG_LEVELS
+from config import SRC_LOG_LEVELS
 log = logging.getLogger(__name__)
 log.setLevel(SRC_LOG_LEVELS["MODELS"])
 class Tool(Base):
     __tablename__ = "tool"
     id = Column(String, primary_key=True)
     user_id = Column(String)
     name = Column(Text)
     content = Column(Text)
     specs = Column(JSONField)
     meta = Column(JSONField)

--- a/backend/apps/webui/routers/auths.py
+++ b/backend/apps/webui/routers/auths.py
@@ -137,25 +137,21 @@
             "id": user.id,
             "email": user.email,
             "name": user.name,
             "role": user.role,
             "profile_image_url": user.profile_image_url,
         }
     else:
         raise HTTPException(400, detail=ERROR_MESSAGES.INVALID_CRED)
 @router.post("/signup", response_model=SigninResponse)
 async def signup(request: Request, response: Response, form_data: SignupForm):
-    if (
-        not request.app.state.config.ENABLE_SIGNUP
-        and request.app.state.config.ENABLE_LOGIN_FORM
-        and WEBUI_AUTH
-    ):
+    if not request.app.state.config.ENABLE_SIGNUP and WEBUI_AUTH:
         raise HTTPException(
             status.HTTP_403_FORBIDDEN, detail=ERROR_MESSAGES.ACCESS_PROHIBITED
         )
     if not validate_email_format(form_data.email.lower()):
         raise HTTPException(
             status.HTTP_400_BAD_REQUEST, detail=ERROR_MESSAGES.INVALID_EMAIL_FORMAT
         )
     if Users.get_user_by_email(form_data.email.lower()):
         raise HTTPException(400, detail=ERROR_MESSAGES.EMAIL_TAKEN)
     try:

--- a/backend/apps/webui/routers/files.py
+++ b/backend/apps/webui/routers/files.py
@@ -68,24 +68,21 @@
                 detail=ERROR_MESSAGES.DEFAULT("Error uploading file"),
             )
     except Exception as e:
         log.exception(e)
         raise HTTPException(
             status_code=status.HTTP_400_BAD_REQUEST,
             detail=ERROR_MESSAGES.DEFAULT(e),
         )
 @router.get("/", response_model=list[FileModel])
 async def list_files(user=Depends(get_verified_user)):
-    if user.role == "admin":
-        files = Files.get_files()
-    else:
-        files = Files.get_files_by_user_id(user.id)
+    files = Files.get_files()
     return files
 @router.delete("/all")
 async def delete_all_files(user=Depends(get_admin_user)):
     result = Files.delete_all_files()
     if result:
         folder = f"{UPLOAD_DIR}"
         try:
             if os.path.exists(folder):
                 for filename in os.listdir(folder):
                     file_path = os.path.join(folder, filename)
@@ -102,67 +99,67 @@
             print(f"Failed to process the directory {folder}. Reason: {e}")
         return {"message": "All files deleted successfully"}
     else:
         raise HTTPException(
             status_code=status.HTTP_400_BAD_REQUEST,
             detail=ERROR_MESSAGES.DEFAULT("Error deleting files"),
         )
 @router.get("/{id}", response_model=Optional[FileModel])
 async def get_file_by_id(id: str, user=Depends(get_verified_user)):
     file = Files.get_file_by_id(id)
-    if file and (file.user_id == user.id or user.role == "admin"):
+    if file:
         return file
     else:
         raise HTTPException(
             status_code=status.HTTP_404_NOT_FOUND,
             detail=ERROR_MESSAGES.NOT_FOUND,
         )
 @router.get("/{id}/content", response_model=Optional[FileModel])
 async def get_file_content_by_id(id: str, user=Depends(get_verified_user)):
     file = Files.get_file_by_id(id)
-    if file and (file.user_id == user.id or user.role == "admin"):
+    if file:
         file_path = Path(file.meta["path"])
         if file_path.is_file():
             print(f"file_path: {file_path}")
             return FileResponse(file_path)
         else:
             raise HTTPException(
                 status_code=status.HTTP_404_NOT_FOUND,
                 detail=ERROR_MESSAGES.NOT_FOUND,
             )
     else:
         raise HTTPException(
             status_code=status.HTTP_404_NOT_FOUND,
             detail=ERROR_MESSAGES.NOT_FOUND,
         )
 @router.get("/{id}/content/{file_name}", response_model=Optional[FileModel])
 async def get_file_content_by_id(id: str, user=Depends(get_verified_user)):
     file = Files.get_file_by_id(id)
-    if file and (file.user_id == user.id or user.role == "admin"):
+    if file:
         file_path = Path(file.meta["path"])
         if file_path.is_file():
             print(f"file_path: {file_path}")
             return FileResponse(file_path)
         else:
             raise HTTPException(
                 status_code=status.HTTP_404_NOT_FOUND,
                 detail=ERROR_MESSAGES.NOT_FOUND,
             )
     else:
         raise HTTPException(
             status_code=status.HTTP_404_NOT_FOUND,
             detail=ERROR_MESSAGES.NOT_FOUND,
         )
 @router.delete("/{id}")
 async def delete_file_by_id(id: str, user=Depends(get_verified_user)):
     file = Files.get_file_by_id(id)
-    if file and (file.user_id == user.id or user.role == "admin"):
+    if file:
         result = Files.delete_file_by_id(id)
         if result:
             return {"message": "File deleted successfully"}
         else:
             raise HTTPException(
                 status_code=status.HTTP_400_BAD_REQUEST,
                 detail=ERROR_MESSAGES.DEFAULT("Error deleting file"),
             )
     else:
         raise HTTPException(

--- a/backend/apps/webui/routers/memories.py
+++ b/backend/apps/webui/routers/memories.py
@@ -31,59 +31,20 @@
     memory = Memories.insert_new_memory(user.id, form_data.content)
     memory_embedding = request.app.state.EMBEDDING_FUNCTION(memory.content)
     collection = CHROMA_CLIENT.get_or_create_collection(name=f"user-memory-{user.id}")
     collection.upsert(
         documents=[memory.content],
         ids=[memory.id],
         embeddings=[memory_embedding],
         metadatas=[{"created_at": memory.created_at}],
     )
     return memory
-class QueryMemoryForm(BaseModel):
-    content: str
-    k: Optional[int] = 1
-@router.post("/query")
-async def query_memory(
-    request: Request, form_data: QueryMemoryForm, user=Depends(get_verified_user)
-):
-    query_embedding = request.app.state.EMBEDDING_FUNCTION(form_data.content)
-    collection = CHROMA_CLIENT.get_or_create_collection(name=f"user-memory-{user.id}")
-    results = collection.query(
-        query_embeddings=[query_embedding],
-        n_results=form_data.k,  # how many results to return
-    )
-    return results
-@router.post("/reset", response_model=bool)
-async def reset_memory_from_vector_db(
-    request: Request, user=Depends(get_verified_user)
-):
-    CHROMA_CLIENT.delete_collection(f"user-memory-{user.id}")
-    collection = CHROMA_CLIENT.get_or_create_collection(name=f"user-memory-{user.id}")
-    memories = Memories.get_memories_by_user_id(user.id)
-    for memory in memories:
-        memory_embedding = request.app.state.EMBEDDING_FUNCTION(memory.content)
-        collection.upsert(
-            documents=[memory.content],
-            ids=[memory.id],
-            embeddings=[memory_embedding],
-        )
-    return True
-@router.delete("/delete/user", response_model=bool)
-async def delete_memory_by_user_id(user=Depends(get_verified_user)):
-    result = Memories.delete_memories_by_user_id(user.id)
-    if result:
-        try:
-            CHROMA_CLIENT.delete_collection(f"user-memory-{user.id}")
-        except Exception as e:
-            log.error(e)
-        return True
-    return False
 @router.post("/{memory_id}/update", response_model=Optional[MemoryModel])
 async def update_memory_by_id(
     memory_id: str,
     request: Request,
     form_data: MemoryUpdateModel,
     user=Depends(get_verified_user),
 ):
     memory = Memories.update_memory_by_id(memory_id, form_data.content)
     if memory is None:
         raise HTTPException(status_code=404, detail="Memory not found")
@@ -94,20 +55,59 @@
         )
         collection.upsert(
             documents=[form_data.content],
             ids=[memory.id],
             embeddings=[memory_embedding],
             metadatas=[
                 {"created_at": memory.created_at, "updated_at": memory.updated_at}
             ],
         )
     return memory
+class QueryMemoryForm(BaseModel):
+    content: str
+    k: Optional[int] = 1
+@router.post("/query")
+async def query_memory(
+    request: Request, form_data: QueryMemoryForm, user=Depends(get_verified_user)
+):
+    query_embedding = request.app.state.EMBEDDING_FUNCTION(form_data.content)
+    collection = CHROMA_CLIENT.get_or_create_collection(name=f"user-memory-{user.id}")
+    results = collection.query(
+        query_embeddings=[query_embedding],
+        n_results=form_data.k,  # how many results to return
+    )
+    return results
+@router.get("/reset", response_model=bool)
+async def reset_memory_from_vector_db(
+    request: Request, user=Depends(get_verified_user)
+):
+    CHROMA_CLIENT.delete_collection(f"user-memory-{user.id}")
+    collection = CHROMA_CLIENT.get_or_create_collection(name=f"user-memory-{user.id}")
+    memories = Memories.get_memories_by_user_id(user.id)
+    for memory in memories:
+        memory_embedding = request.app.state.EMBEDDING_FUNCTION(memory.content)
+        collection.upsert(
+            documents=[memory.content],
+            ids=[memory.id],
+            embeddings=[memory_embedding],
+        )
+    return True
+@router.delete("/user", response_model=bool)
+async def delete_memory_by_user_id(user=Depends(get_verified_user)):
+    result = Memories.delete_memories_by_user_id(user.id)
+    if result:
+        try:
+            CHROMA_CLIENT.delete_collection(f"user-memory-{user.id}")
+        except Exception as e:
+            log.error(e)
+        return True
+    return False
 @router.delete("/{memory_id}", response_model=bool)
 async def delete_memory_by_id(memory_id: str, user=Depends(get_verified_user)):
     result = Memories.delete_memory_by_id_and_user_id(memory_id, user.id)
     if result:
         collection = CHROMA_CLIENT.get_or_create_collection(
             name=f"user-memory-{user.id}"
         )
         collection.delete(ids=[memory_id])
         return True
     return False

--- a/backend/apps/webui/utils.py
+++ b/backend/apps/webui/utils.py
@@ -1,17 +1,15 @@
 from importlib import util
 import os
 import re
 import sys
 import subprocess
-from apps.webui.models.tools import Tools
-from apps.webui.models.functions import Functions
 from config import TOOLS_DIR, FUNCTIONS_DIR
 def extract_frontmatter(file_path):
     """
     Extract frontmatter as a dictionary from the specified file path.
     """
     frontmatter = {}
     frontmatter_started = False
     frontmatter_ended = False
     frontmatter_pattern = re.compile(r"^\s*([a-z_]+):\s*(.*)\s*$", re.IGNORECASE)
     try:
@@ -32,51 +30,37 @@
                         frontmatter[key.strip()] = value.strip()
     except FileNotFoundError:
         print(f"Error: The file {file_path} does not exist.")
         return {}
     except Exception as e:
         print(f"An error occurred: {e}")
         return {}
     return frontmatter
 def load_toolkit_module_by_id(toolkit_id):
     toolkit_path = os.path.join(TOOLS_DIR, f"{toolkit_id}.py")
-    if not os.path.exists(toolkit_path):
-        tool = Tools.get_tool_by_id(toolkit_id)
-        if tool:
-            with open(toolkit_path, "w") as file:
-                file.write(tool.content)
-        else:
-            raise Exception(f"Toolkit not found: {toolkit_id}")
     spec = util.spec_from_file_location(toolkit_id, toolkit_path)
     module = util.module_from_spec(spec)
     frontmatter = extract_frontmatter(toolkit_path)
     try:
         install_frontmatter_requirements(frontmatter.get("requirements", ""))
         spec.loader.exec_module(module)
         print(f"Loaded module: {module.__name__}")
         if hasattr(module, "Tools"):
             return module.Tools(), frontmatter
         else:
             raise Exception("No Tools class found")
     except Exception as e:
         print(f"Error loading module: {toolkit_id}")
         os.rename(toolkit_path, f"{toolkit_path}.error")
         raise e
 def load_function_module_by_id(function_id):
     function_path = os.path.join(FUNCTIONS_DIR, f"{function_id}.py")
-    if not os.path.exists(function_path):
-        function = Functions.get_function_by_id(function_id)
-        if function:
-            with open(function_path, "w") as file:
-                file.write(function.content)
-        else:
-            raise Exception(f"Function not found: {function_id}")
     spec = util.spec_from_file_location(function_id, function_path)
     module = util.module_from_spec(spec)
     frontmatter = extract_frontmatter(function_path)
     try:
         install_frontmatter_requirements(frontmatter.get("requirements", ""))
         spec.loader.exec_module(module)
         print(f"Loaded module: {module.__name__}")
         if hasattr(module, "Pipe"):
             return module.Pipe(), "pipe", frontmatter
         elif hasattr(module, "Filter"):

--- a/backend/config.py
+++ b/backend/config.py
@@ -1,214 +1,205 @@
-from sqlalchemy import create_engine, Column, Integer, DateTime, JSON, func
-from contextlib import contextmanager
 import os
 import sys
 import logging
 import importlib.metadata
 import pkgutil
 from urllib.parse import urlparse
-from datetime import datetime
 import chromadb
 from chromadb import Settings
+from bs4 import BeautifulSoup
 from typing import TypeVar, Generic
 from pydantic import BaseModel
 from typing import Optional
 from pathlib import Path
 import json
 import yaml
+import markdown
 import requests
 import shutil
-from apps.webui.internal.db import Base, get_db
 from constants import ERROR_MESSAGES
-from env import (
-    ENV,
-    VERSION,
-    SAFE_MODE,
-    GLOBAL_LOG_LEVEL,
-    SRC_LOG_LEVELS,
-    BASE_DIR,
-    DATA_DIR,
-    BACKEND_DIR,
-    FRONTEND_BUILD_DIR,
-    WEBUI_NAME,
-    WEBUI_URL,
-    WEBUI_FAVICON_URL,
-    WEBUI_BUILD_HASH,
-    CONFIG_DATA,
-    DATABASE_URL,
-    CHANGELOG,
-    WEBUI_AUTH,
-    WEBUI_AUTH_TRUSTED_EMAIL_HEADER,
-    WEBUI_AUTH_TRUSTED_NAME_HEADER,
-    WEBUI_SECRET_KEY,
-    WEBUI_SESSION_COOKIE_SAME_SITE,
-    WEBUI_SESSION_COOKIE_SECURE,
-    log,
-)
+BACKEND_DIR = Path(__file__).parent  # the path containing this file
+BASE_DIR = BACKEND_DIR.parent  # the path containing the backend/
+print(BASE_DIR)
+try:
+    from dotenv import load_dotenv, find_dotenv
+    load_dotenv(find_dotenv(str(BASE_DIR / ".env")))
+except ImportError:
+    print("dotenv not installed, skipping...")
+log_levels = ["CRITICAL", "ERROR", "WARNING", "INFO", "DEBUG"]
+GLOBAL_LOG_LEVEL = os.environ.get("GLOBAL_LOG_LEVEL", "").upper()
+if GLOBAL_LOG_LEVEL in log_levels:
+    logging.basicConfig(stream=sys.stdout, level=GLOBAL_LOG_LEVEL, force=True)
+else:
+    GLOBAL_LOG_LEVEL = "INFO"
+log = logging.getLogger(__name__)
+log.info(f"GLOBAL_LOG_LEVEL: {GLOBAL_LOG_LEVEL}")
+log_sources = [
+    "AUDIO",
+    "COMFYUI",
+    "CONFIG",
+    "DB",
+    "IMAGES",
+    "MAIN",
+    "MODELS",
+    "OLLAMA",
+    "OPENAI",
+    "RAG",
+    "WEBHOOK",
+]
+SRC_LOG_LEVELS = {}
+for source in log_sources:
+    log_env_var = source + "_LOG_LEVEL"
+    SRC_LOG_LEVELS[source] = os.environ.get(log_env_var, "").upper()
+    if SRC_LOG_LEVELS[source] not in log_levels:
+        SRC_LOG_LEVELS[source] = GLOBAL_LOG_LEVEL
+    log.info(f"{log_env_var}: {SRC_LOG_LEVELS[source]}")
+log.setLevel(SRC_LOG_LEVELS["CONFIG"])
 class EndpointFilter(logging.Filter):
     def filter(self, record: logging.LogRecord) -> bool:
         return record.getMessage().find("/health") == -1
 logging.getLogger("uvicorn.access").addFilter(EndpointFilter())
-def run_migrations():
-    print("Running migrations")
+WEBUI_NAME = os.environ.get("WEBUI_NAME", "Open WebUI")
+if WEBUI_NAME != "Open WebUI":
+    WEBUI_NAME += " (Open WebUI)"
+WEBUI_URL = os.environ.get("WEBUI_URL", "http://localhost:3000")
+WEBUI_FAVICON_URL = "https://openwebui.com/favicon.png"
+ENV = os.environ.get("ENV", "dev")
+try:
+    PACKAGE_DATA = json.loads((BASE_DIR / "package.json").read_text())
+except Exception:
     try:
-        from alembic.config import Config
-        from alembic import command
-        alembic_cfg = Config("alembic.ini")
-        command.upgrade(alembic_cfg, "head")
-    except Exception as e:
-        print(f"Error: {e}")
-run_migrations()
-class Config(Base):
-    __tablename__ = "config"
-    id = Column(Integer, primary_key=True)
-    data = Column(JSON, nullable=False)
-    version = Column(Integer, nullable=False, default=0)
-    created_at = Column(DateTime, nullable=False, server_default=func.now())
-    updated_at = Column(DateTime, nullable=True, onupdate=func.now())
-def load_json_config():
-    with open(f"{DATA_DIR}/config.json", "r") as file:
-        return json.load(file)
-def save_to_db(data):
-    with get_db() as db:
-        existing_config = db.query(Config).first()
-        if not existing_config:
-            new_config = Config(data=data, version=0)
-            db.add(new_config)
-        else:
-            existing_config.data = data
-            existing_config.updated_at = datetime.now()
-            db.add(existing_config)
-        db.commit()
-if os.path.exists(f"{DATA_DIR}/config.json"):
-    data = load_json_config()
-    save_to_db(data)
-    os.rename(f"{DATA_DIR}/config.json", f"{DATA_DIR}/old_config.json")
+        PACKAGE_DATA = {"version": importlib.metadata.version("open-webui")}
+    except importlib.metadata.PackageNotFoundError:
+        PACKAGE_DATA = {"version": "0.0.0"}
+VERSION = PACKAGE_DATA["version"]
+def parse_section(section):
+    items = []
+    for li in section.find_all("li"):
+        raw_html = str(li)
+        text = li.get_text(separator=" ", strip=True)
+        parts = text.split(": ", 1)
+        title = parts[0].strip() if len(parts) > 1 else ""
+        content = parts[1].strip() if len(parts) > 1 else text
+        items.append({"title": title, "content": content, "raw": raw_html})
+    return items
+try:
+    changelog_path = BASE_DIR / "CHANGELOG.md"
+    with open(str(changelog_path.absolute()), "r", encoding="utf8") as file:
+        changelog_content = file.read()
+except Exception:
+    changelog_content = (pkgutil.get_data("open_webui", "CHANGELOG.md") or b"").decode()
+html_content = markdown.markdown(changelog_content)
+soup = BeautifulSoup(html_content, "html.parser")
+changelog_json = {}
+for version in soup.find_all("h2"):
+    version_number = version.get_text().strip().split(" - ")[0][1:-1]  # Remove brackets
+    date = version.get_text().strip().split(" - ")[1]
+    version_data = {"date": date}
+    current = version.find_next_sibling()
+    while current and current.name != "h2":
+        if current.name == "h3":
+            section_title = current.get_text().lower()  # e.g., "added", "fixed"
+            section_items = parse_section(current.find_next_sibling("ul"))
+            version_data[section_title] = section_items
+        current = current.find_next_sibling()
+    changelog_json[version_number] = version_data
+CHANGELOG = changelog_json
+SAFE_MODE = os.environ.get("SAFE_MODE", "false").lower() == "true"
+WEBUI_BUILD_HASH = os.environ.get("WEBUI_BUILD_HASH", "dev-build")
+DATA_DIR = Path(os.getenv("DATA_DIR", BACKEND_DIR / "data")).resolve()
+FRONTEND_BUILD_DIR = Path(os.getenv("FRONTEND_BUILD_DIR", BASE_DIR / "build")).resolve()
+RESET_CONFIG_ON_START = (
+    os.environ.get("RESET_CONFIG_ON_START", "False").lower() == "true"
+)
+if RESET_CONFIG_ON_START:
+    try:
+        os.remove(f"{DATA_DIR}/config.json")
+        with open(f"{DATA_DIR}/config.json", "w") as f:
+            f.write("{}")
+    except Exception:
+        pass
+try:
+    CONFIG_DATA = json.loads((DATA_DIR / "config.json").read_text())
+except Exception:
+    CONFIG_DATA = {}
 def save_config():
     try:
         with open(f"{DATA_DIR}/config.json", "w") as f:
             json.dump(CONFIG_DATA, f, indent="\t")
     except Exception as e:
         log.exception(e)
-DEFAULT_CONFIG = {
-    "version": 0,
-    "ui": {
-        "default_locale": "",
-        "prompt_suggestions": [
-            {
-                "title": [
-                    "Help me study",
-                    "vocabulary for a college entrance exam",
-                ],
-                "content": "Help me study vocabulary: write a sentence for me to fill in the blank, and I'll try to pick the correct option.",
-            },
-            {
-                "title": [
-                    "Give me ideas",
-                    "for what to do with my kids' art",
-                ],
-                "content": "What are 5 creative things I could do with my kids' art? I don't want to throw them away, but it's also so much clutter.",
-            },
-            {
-                "title": ["Tell me a fun fact", "about the Roman Empire"],
-                "content": "Tell me a random fun fact about the Roman Empire",
-            },
-            {
-                "title": [
-                    "Show me a code snippet",
-                    "of a website's sticky header",
-                ],
-                "content": "Show me a code snippet of a website's sticky header in CSS and JavaScript.",
-            },
-            {
-                "title": [
-                    "Explain options trading",
-                    "if I'm familiar with buying and selling stocks",
-                ],
-                "content": "Explain options trading in simple terms if I'm familiar with buying and selling stocks.",
-            },
-            {
-                "title": ["Overcome procrastination", "give me tips"],
-                "content": "Could you start by asking me about instances when I procrastinate the most and then give me some suggestions to overcome it?",
-            },
-            {
-                "title": [
-                    "Grammar check",
-                    "rewrite it for better readability ",
-                ],
-                "content": 'Check the following sentence for grammar and clarity: "[sentence]". Rewrite it for better readability while maintaining its original meaning.',
-            },
-        ],
-    },
-}
-def get_config():
-    with get_db() as db:
-        config_entry = db.query(Config).order_by(Config.id.desc()).first()
-        return config_entry.data if config_entry else DEFAULT_CONFIG
-CONFIG_DATA = get_config()
 def get_config_value(config_path: str):
     path_parts = config_path.split(".")
     cur_config = CONFIG_DATA
     for key in path_parts:
         if key in cur_config:
             cur_config = cur_config[key]
         else:
             return None
     return cur_config
 T = TypeVar("T")
 class PersistentConfig(Generic[T]):
     def __init__(self, env_name: str, config_path: str, env_value: T):
         self.env_name = env_name
         self.config_path = config_path
         self.env_value = env_value
         self.config_value = get_config_value(config_path)
         if self.config_value is not None:
-            log.info(f"'{env_name}' loaded from the latest database entry")
+            log.info(f"'{env_name}' loaded from config.json")
             self.value = self.config_value
         else:
             self.value = env_value
     def __str__(self):
         return str(self.value)
     @property
     def __dict__(self):
         raise TypeError(
             "PersistentConfig object cannot be converted to dict, use config_get or .value instead."
         )
     def __getattribute__(self, item):
         if item == "__dict__":
             raise TypeError(
                 "PersistentConfig object cannot be converted to dict, use config_get or .value instead."
             )
         return super().__getattribute__(item)
     def save(self):
-        log.info(f"Saving '{self.env_name}' to the database")
+        if self.env_value == self.value:
+            if self.config_value == self.value:
+                return
+        log.info(f"Saving '{self.env_name}' to config.json")
         path_parts = self.config_path.split(".")
-        sub_config = CONFIG_DATA
+        config = CONFIG_DATA
         for key in path_parts[:-1]:
-            if key not in sub_config:
-                sub_config[key] = {}
-            sub_config = sub_config[key]
-        sub_config[path_parts[-1]] = self.value
-        save_to_db(CONFIG_DATA)
+            if key not in config:
+                config[key] = {}
+            config = config[key]
+        config[path_parts[-1]] = self.value
+        save_config()
         self.config_value = self.value
 class AppConfig:
     _state: dict[str, PersistentConfig]
     def __init__(self):
         super().__setattr__("_state", {})
     def __setattr__(self, key, value):
         if isinstance(value, PersistentConfig):
             self._state[key] = value
         else:
             self._state[key].value = value
             self._state[key].save()
     def __getattr__(self, key):
         return self._state[key].value
+WEBUI_AUTH = os.environ.get("WEBUI_AUTH", "True").lower() == "true"
+WEBUI_AUTH_TRUSTED_EMAIL_HEADER = os.environ.get(
+    "WEBUI_AUTH_TRUSTED_EMAIL_HEADER", None
+)
+WEBUI_AUTH_TRUSTED_NAME_HEADER = os.environ.get("WEBUI_AUTH_TRUSTED_NAME_HEADER", None)
 JWT_EXPIRES_IN = PersistentConfig(
     "JWT_EXPIRES_IN", "auth.jwt_expiry", os.environ.get("JWT_EXPIRES_IN", "-1")
 )
 ENABLE_OAUTH_SIGNUP = PersistentConfig(
     "ENABLE_OAUTH_SIGNUP",
     "oauth.enable_signup",
     os.environ.get("ENABLE_OAUTH_SIGNUP", "False").lower() == "true",
 )
 OAUTH_MERGE_ACCOUNTS_BY_EMAIL = PersistentConfig(
     "OAUTH_MERGE_ACCOUNTS_BY_EMAIL",
@@ -684,20 +675,36 @@
     ),
 )
 TOOLS_FUNCTION_CALLING_PROMPT_TEMPLATE = PersistentConfig(
     "TOOLS_FUNCTION_CALLING_PROMPT_TEMPLATE",
     "task.tools.prompt_template",
     os.environ.get(
         "TOOLS_FUNCTION_CALLING_PROMPT_TEMPLATE",
         """Available Tools: {{TOOLS}}\nReturn an empty string if no tools match the query. If a function tool matches, construct and return a JSON object in the format {\"name\": \"functionName\", \"parameters\": {\"requiredFunctionParamKey\": \"requiredFunctionParamValue\"}} using the appropriate tool and its parameters. Only return the object and limit the response to the JSON object without additional text.""",
     ),
 )
+WEBUI_SECRET_KEY = os.environ.get(
+    "WEBUI_SECRET_KEY",
+    os.environ.get(
+        "WEBUI_JWT_SECRET_KEY", "t0p-s3cr3t"
+    ),  # DEPRECATED: remove at next major version
+)
+WEBUI_SESSION_COOKIE_SAME_SITE = os.environ.get(
+    "WEBUI_SESSION_COOKIE_SAME_SITE",
+    os.environ.get("WEBUI_SESSION_COOKIE_SAME_SITE", "lax"),
+)
+WEBUI_SESSION_COOKIE_SECURE = os.environ.get(
+    "WEBUI_SESSION_COOKIE_SECURE",
+    os.environ.get("WEBUI_SESSION_COOKIE_SECURE", "false").lower() == "true",
+)
+if WEBUI_AUTH and WEBUI_SECRET_KEY == "":
+    raise ValueError(ERROR_MESSAGES.ENV_VAR_NOT_FOUND)
 CONTENT_EXTRACTION_ENGINE = PersistentConfig(
     "CONTENT_EXTRACTION_ENGINE",
     "rag.CONTENT_EXTRACTION_ENGINE",
     os.environ.get("CONTENT_EXTRACTION_ENGINE", "").lower(),
 )
 TIKA_SERVER_URL = PersistentConfig(
     "TIKA_SERVER_URL",
     "rag.tika_server_url",
     os.getenv("TIKA_SERVER_URL", "http://tika:9998"),  # Default for sidecar deployment
 )
@@ -719,38 +726,20 @@
 )
 RAG_RELEVANCE_THRESHOLD = PersistentConfig(
     "RAG_RELEVANCE_THRESHOLD",
     "rag.relevance_threshold",
     float(os.environ.get("RAG_RELEVANCE_THRESHOLD", "0.0")),
 )
 ENABLE_RAG_HYBRID_SEARCH = PersistentConfig(
     "ENABLE_RAG_HYBRID_SEARCH",
     "rag.enable_hybrid_search",
     os.environ.get("ENABLE_RAG_HYBRID_SEARCH", "").lower() == "true",
-)
-RAG_FILE_MAX_COUNT = PersistentConfig(
-    "RAG_FILE_MAX_COUNT",
-    "rag.file.max_count",
-    (
-        int(os.environ.get("RAG_FILE_MAX_COUNT"))
-        if os.environ.get("RAG_FILE_MAX_COUNT")
-        else None
-    ),
-)
-RAG_FILE_MAX_SIZE = PersistentConfig(
-    "RAG_FILE_MAX_SIZE",
-    "rag.file.max_size",
-    (
-        int(os.environ.get("RAG_FILE_MAX_SIZE"))
-        if os.environ.get("RAG_FILE_MAX_SIZE")
-        else None
-    ),
 )
 ENABLE_RAG_WEB_LOADER_SSL_VERIFICATION = PersistentConfig(
     "ENABLE_RAG_WEB_LOADER_SSL_VERIFICATION",
     "rag.enable_web_loader_ssl_verification",
     os.environ.get("ENABLE_RAG_WEB_LOADER_SSL_VERIFICATION", "True").lower() == "true",
 )
 RAG_EMBEDDING_ENGINE = PersistentConfig(
     "RAG_EMBEDDING_ENGINE",
     "rag.embedding_engine",
     os.environ.get("RAG_EMBEDDING_ENGINE", ""),
@@ -1138,15 +1127,13 @@
 AUDIO_TTS_MODEL = PersistentConfig(
     "AUDIO_TTS_MODEL",
     "audio.tts.model",
     os.getenv("AUDIO_TTS_MODEL", "tts-1"),  # OpenAI default model
 )
 AUDIO_TTS_VOICE = PersistentConfig(
     "AUDIO_TTS_VOICE",
     "audio.tts.voice",
     os.getenv("AUDIO_TTS_VOICE", "alloy"),  # OpenAI default voice
 )
-AUDIO_TTS_SPLIT_ON = PersistentConfig(
-    "AUDIO_TTS_SPLIT_ON",
-    "audio.tts.split_on",
-    os.getenv("AUDIO_TTS_SPLIT_ON", "punctuation"),
-)
+DATABASE_URL = os.environ.get("DATABASE_URL", f"sqlite:///{DATA_DIR}/webui.db")
+if "postgres://" in DATABASE_URL:
+    DATABASE_URL = DATABASE_URL.replace("postgres://", "postgresql://")

--- a/backend/env.py
+++ b//dev/null
@@ -1,142 +0,0 @@
-from pathlib import Path
-import os
-import logging
-import sys
-import json
-import importlib.metadata
-import pkgutil
-from urllib.parse import urlparse
-from datetime import datetime
-import markdown
-from bs4 import BeautifulSoup
-from constants import ERROR_MESSAGES
-BACKEND_DIR = Path(__file__).parent  # the path containing this file
-BASE_DIR = BACKEND_DIR.parent  # the path containing the backend/
-print(BASE_DIR)
-try:
-    from dotenv import load_dotenv, find_dotenv
-    load_dotenv(find_dotenv(str(BASE_DIR / ".env")))
-except ImportError:
-    print("dotenv not installed, skipping...")
-log_levels = ["CRITICAL", "ERROR", "WARNING", "INFO", "DEBUG"]
-GLOBAL_LOG_LEVEL = os.environ.get("GLOBAL_LOG_LEVEL", "").upper()
-if GLOBAL_LOG_LEVEL in log_levels:
-    logging.basicConfig(stream=sys.stdout, level=GLOBAL_LOG_LEVEL, force=True)
-else:
-    GLOBAL_LOG_LEVEL = "INFO"
-log = logging.getLogger(__name__)
-log.info(f"GLOBAL_LOG_LEVEL: {GLOBAL_LOG_LEVEL}")
-log_sources = [
-    "AUDIO",
-    "COMFYUI",
-    "CONFIG",
-    "DB",
-    "IMAGES",
-    "MAIN",
-    "MODELS",
-    "OLLAMA",
-    "OPENAI",
-    "RAG",
-    "WEBHOOK",
-]
-SRC_LOG_LEVELS = {}
-for source in log_sources:
-    log_env_var = source + "_LOG_LEVEL"
-    SRC_LOG_LEVELS[source] = os.environ.get(log_env_var, "").upper()
-    if SRC_LOG_LEVELS[source] not in log_levels:
-        SRC_LOG_LEVELS[source] = GLOBAL_LOG_LEVEL
-    log.info(f"{log_env_var}: {SRC_LOG_LEVELS[source]}")
-log.setLevel(SRC_LOG_LEVELS["CONFIG"])
-WEBUI_NAME = os.environ.get("WEBUI_NAME", "Open WebUI")
-if WEBUI_NAME != "Open WebUI":
-    WEBUI_NAME += " (Open WebUI)"
-WEBUI_URL = os.environ.get("WEBUI_URL", "http://localhost:3000")
-WEBUI_FAVICON_URL = "https://openwebui.com/favicon.png"
-ENV = os.environ.get("ENV", "dev")
-try:
-    PACKAGE_DATA = json.loads((BASE_DIR / "package.json").read_text())
-except Exception:
-    try:
-        PACKAGE_DATA = {"version": importlib.metadata.version("open-webui")}
-    except importlib.metadata.PackageNotFoundError:
-        PACKAGE_DATA = {"version": "0.0.0"}
-VERSION = PACKAGE_DATA["version"]
-def parse_section(section):
-    items = []
-    for li in section.find_all("li"):
-        raw_html = str(li)
-        text = li.get_text(separator=" ", strip=True)
-        parts = text.split(": ", 1)
-        title = parts[0].strip() if len(parts) > 1 else ""
-        content = parts[1].strip() if len(parts) > 1 else text
-        items.append({"title": title, "content": content, "raw": raw_html})
-    return items
-try:
-    changelog_path = BASE_DIR / "CHANGELOG.md"
-    with open(str(changelog_path.absolute()), "r", encoding="utf8") as file:
-        changelog_content = file.read()
-except Exception:
-    changelog_content = (pkgutil.get_data("open_webui", "CHANGELOG.md") or b"").decode()
-html_content = markdown.markdown(changelog_content)
-soup = BeautifulSoup(html_content, "html.parser")
-changelog_json = {}
-for version in soup.find_all("h2"):
-    version_number = version.get_text().strip().split(" - ")[0][1:-1]  # Remove brackets
-    date = version.get_text().strip().split(" - ")[1]
-    version_data = {"date": date}
-    current = version.find_next_sibling()
-    while current and current.name != "h2":
-        if current.name == "h3":
-            section_title = current.get_text().lower()  # e.g., "added", "fixed"
-            section_items = parse_section(current.find_next_sibling("ul"))
-            version_data[section_title] = section_items
-        current = current.find_next_sibling()
-    changelog_json[version_number] = version_data
-CHANGELOG = changelog_json
-SAFE_MODE = os.environ.get("SAFE_MODE", "false").lower() == "true"
-WEBUI_BUILD_HASH = os.environ.get("WEBUI_BUILD_HASH", "dev-build")
-DATA_DIR = Path(os.getenv("DATA_DIR", BACKEND_DIR / "data")).resolve()
-FRONTEND_BUILD_DIR = Path(os.getenv("FRONTEND_BUILD_DIR", BASE_DIR / "build")).resolve()
-RESET_CONFIG_ON_START = (
-    os.environ.get("RESET_CONFIG_ON_START", "False").lower() == "true"
-)
-if RESET_CONFIG_ON_START:
-    try:
-        os.remove(f"{DATA_DIR}/config.json")
-        with open(f"{DATA_DIR}/config.json", "w") as f:
-            f.write("{}")
-    except Exception:
-        pass
-try:
-    CONFIG_DATA = json.loads((DATA_DIR / "config.json").read_text())
-except Exception:
-    CONFIG_DATA = {}
-if os.path.exists(f"{DATA_DIR}/ollama.db"):
-    os.rename(f"{DATA_DIR}/ollama.db", f"{DATA_DIR}/webui.db")
-    log.info("Database migrated from Ollama-WebUI successfully.")
-else:
-    pass
-DATABASE_URL = os.environ.get("DATABASE_URL", f"sqlite:///{DATA_DIR}/webui.db")
-if "postgres://" in DATABASE_URL:
-    DATABASE_URL = DATABASE_URL.replace("postgres://", "postgresql://")
-WEBUI_AUTH = os.environ.get("WEBUI_AUTH", "True").lower() == "true"
-WEBUI_AUTH_TRUSTED_EMAIL_HEADER = os.environ.get(
-    "WEBUI_AUTH_TRUSTED_EMAIL_HEADER", None
-)
-WEBUI_AUTH_TRUSTED_NAME_HEADER = os.environ.get("WEBUI_AUTH_TRUSTED_NAME_HEADER", None)
-WEBUI_SECRET_KEY = os.environ.get(
-    "WEBUI_SECRET_KEY",
-    os.environ.get(
-        "WEBUI_JWT_SECRET_KEY", "t0p-s3cr3t"
-    ),  # DEPRECATED: remove at next major version
-)
-WEBUI_SESSION_COOKIE_SAME_SITE = os.environ.get(
-    "WEBUI_SESSION_COOKIE_SAME_SITE",
-    os.environ.get("WEBUI_SESSION_COOKIE_SAME_SITE", "lax"),
-)
-WEBUI_SESSION_COOKIE_SECURE = os.environ.get(
-    "WEBUI_SESSION_COOKIE_SECURE",
-    os.environ.get("WEBUI_SESSION_COOKIE_SECURE", "false").lower() == "true",
-)
-if WEBUI_AUTH and WEBUI_SECRET_KEY == "":
-    raise ValueError(ERROR_MESSAGES.ENV_VAR_NOT_FOUND)

--- a/backend/main.py
+++ b/backend/main.py
@@ -67,21 +67,20 @@
 )
 from utils.tools import get_tools
 from utils.misc import (
     get_last_user_message,
     add_or_update_system_message,
     prepend_to_first_user_message_content,
     parse_duration,
 )
 from apps.rag.utils import get_rag_context, rag_template
 from config import (
-    run_migrations,
     WEBUI_NAME,
     WEBUI_URL,
     WEBUI_AUTH,
     ENV,
     VERSION,
     CHANGELOG,
     FRONTEND_BUILD_DIR,
     CACHE_DIR,
     STATIC_DIR,
     DEFAULT_LOCALE,
@@ -134,20 +133,28 @@
  / _ \ _ __   ___ _ __   \ \      / /__| |__ | | | |_ _|
 | | | | '_ \ / _ \ '_ \   \ \ /\ / / _ \ '_ \| | | || | 
 | |_| | |_) |  __/ | | |   \ V  V /  __/ |_) | |_| || | 
  \___/| .__/ \___|_| |_|    \_/\_/ \___|_.__/ \___/|___|
       |_|                                               
 v{VERSION} - building the best open-source AI user interface.
 {f"Commit: {WEBUI_BUILD_HASH}" if WEBUI_BUILD_HASH != "dev-build" else ""}
 https://github.com/open-webui/open-webui
 """
 )
+def run_migrations():
+    try:
+        from alembic.config import Config
+        from alembic import command
+        alembic_cfg = Config("alembic.ini")
+        command.upgrade(alembic_cfg, "head")
+    except Exception as e:
+        print(f"Error: {e}")
 @asynccontextmanager
 async def lifespan(app: FastAPI):
     run_migrations()
     yield
 app = FastAPI(
     docs_url="/docs" if ENV == "dev" else None, redoc_url=None, lifespan=lifespan
 )
 app.state.config = AppConfig()
 app.state.config.ENABLE_OPENAI_API = ENABLE_OPENAI_API
 app.state.config.ENABLE_OLLAMA_API = ENABLE_OLLAMA_API
@@ -218,38 +225,33 @@
         if hasattr(function_module, "valves") and hasattr(function_module, "Valves"):
             valves = Functions.get_function_valves_by_id(filter_id)
             function_module.valves = function_module.Valves(
                 **(valves if valves else {})
             )
         if not hasattr(function_module, "inlet"):
             continue
         try:
             inlet = function_module.inlet
             sig = inspect.signature(inlet)
-            params = {"body": body} | {
-                k: v
-                for k, v in {
-                    **extra_params,
-                    "__model__": model,
-                    "__id__": filter_id,
-                }.items()
-                if k in sig.parameters
-            }
-            if "__user__" in params and hasattr(function_module, "UserValves"):
+            params = {"body": body}
+            custom_params = {**extra_params, "__model__": model, "__id__": filter_id}
+            if hasattr(function_module, "UserValves") and "__user__" in sig.parameters:
                 try:
-                    params["__user__"]["valves"] = function_module.UserValves(
-                        **Functions.get_user_valves_by_id_and_user_id(
-                            filter_id, params["__user__"]["id"]
-                        )
+                    uid = custom_params["__user__"]["id"]
+                    custom_params["__user__"]["valves"] = function_module.UserValves(
+                        **Functions.get_user_valves_by_id_and_user_id(filter_id, uid)
                     )
                 except Exception as e:
                     print(e)
+            for key, value in custom_params.items():
+                if key in sig.parameters:
+                    params[key] = value
             if inspect.iscoroutinefunction(inlet):
                 body = await inlet(**params)
             else:
                 body = inlet(**params)
         except Exception as e:
             print(f"Error: {e}")
             raise e
     if skip_files and "files" in body.get("metadata", {}):
         del body["metadata"]["files"]
     return body, {}
@@ -278,38 +280,34 @@
         if response.background is not None:
             await response.background()
     else:
         content = response["choices"][0]["message"]["content"]
     return content
 async def chat_completion_tools_handler(
     body: dict, user: UserModel, extra_params: dict
 ) -> tuple[dict, dict]:
     metadata = body.get("metadata", {})
     tool_ids = metadata.get("tool_ids", None)
-    log.debug(f"{tool_ids=}")
     if not tool_ids:
         return body, {}
     skip_files = False
     contexts = []
     citations = []
     task_model_id = get_task_model_id(body["model"])
-    tools = get_tools(
-        webui_app,
-        tool_ids,
-        user,
-        {
-            **extra_params,
-            "__model__": app.state.MODELS[task_model_id],
-            "__messages__": body["messages"],
-            "__files__": metadata.get("files", []),
-        },
-    )
+    log.debug(f"{tool_ids=}")
+    custom_params = {
+        **extra_params,
+        "__model__": app.state.MODELS[task_model_id],
+        "__messages__": body["messages"],
+        "__files__": metadata.get("files", []),
+    }
+    tools = get_tools(webui_app, tool_ids, user, custom_params)
     log.info(f"{tools=}")
     specs = [tool["spec"] for tool in tools.values()]
     tools_specs = json.dumps(specs)
     tools_function_calling_prompt = tools_function_calling_generation_template(
         app.state.config.TOOLS_FUNCTION_CALLING_PROMPT_TEMPLATE, tools_specs
     )
     log.info(f"{tools_function_calling_prompt=}")
     payload = get_tools_function_calling_payload(
         body["messages"], task_model_id, tools_function_calling_prompt
     )
@@ -398,52 +396,48 @@
             body, model, user = await get_body_and_model_and_user(request)
         except Exception as e:
             return JSONResponse(
                 status_code=status.HTTP_400_BAD_REQUEST,
                 content={"detail": str(e)},
             )
         metadata = {
             "chat_id": body.pop("chat_id", None),
             "message_id": body.pop("id", None),
             "session_id": body.pop("session_id", None),
-            "tool_ids": body.get("tool_ids", None),
-            "files": body.get("files", None),
+            "valves": body.pop("valves", None),
+            "tool_ids": body.pop("tool_ids", None),
+            "files": body.pop("files", None),
         }
         body["metadata"] = metadata
+        __user__ = {
+            "id": user.id,
+            "email": user.email,
+            "name": user.name,
+            "role": user.role,
+        }
         extra_params = {
+            "__user__": __user__,
             "__event_emitter__": get_event_emitter(metadata),
             "__event_call__": get_event_call(metadata),
-            "__user__": {
-                "id": user.id,
-                "email": user.email,
-                "name": user.name,
-                "role": user.role,
-            },
         }
         data_items = []
         contexts = []
         citations = []
         try:
             body, flags = await chat_completion_filter_functions_handler(
                 body, model, extra_params
             )
         except Exception as e:
             return JSONResponse(
                 status_code=status.HTTP_400_BAD_REQUEST,
                 content={"detail": str(e)},
             )
-        metadata = {
-            **metadata,
-            "tool_ids": body.pop("tool_ids", None),
-            "files": body.pop("files", None),
-        }
-        body["metadata"] = metadata
         try:
             body, flags = await chat_completion_tools_handler(body, user, extra_params)
             contexts.extend(flags.get("contexts", []))
             citations.extend(flags.get("citations", []))
         except Exception as e:
             log.exception(e)
         try:
             body, flags = await chat_completion_files_handler(body)
             contexts.extend(flags.get("contexts", []))
             citations.extend(flags.get("citations", []))
@@ -757,26 +751,20 @@
             return {"data": models}
     return {"data": models}
 @app.post("/api/chat/completions")
 async def generate_chat_completions(form_data: dict, user=Depends(get_verified_user)):
     model_id = form_data["model"]
     if model_id not in app.state.MODELS:
         raise HTTPException(
             status_code=status.HTTP_404_NOT_FOUND,
             detail="Model not found",
         )
-    if app.state.config.ENABLE_MODEL_FILTER:
-        if user.role == "user" and model_id not in app.state.config.MODEL_FILTER_LIST:
-            raise HTTPException(
-                status_code=status.HTTP_403_FORBIDDEN,
-                detail="Model not found",
-            )
     model = app.state.MODELS[model_id]
     if model.get("pipe"):
         return await generate_function_chat_completion(form_data, user=user)
     if model["owned_by"] == "ollama":
         return await generate_ollama_chat_completion(form_data, user=user)
     else:
         return await generate_openai_chat_completion(form_data, user=user)
 @app.post("/api/chat/completed")
 async def chat_completed(form_data: dict, user=Depends(get_verified_user)):
     data = form_data
@@ -1476,29 +1464,24 @@
             ),
         },
         **(
             {
                 "default_models": webui_app.state.config.DEFAULT_MODELS,
                 "default_prompt_suggestions": webui_app.state.config.DEFAULT_PROMPT_SUGGESTIONS,
                 "audio": {
                     "tts": {
                         "engine": audio_app.state.config.TTS_ENGINE,
                         "voice": audio_app.state.config.TTS_VOICE,
-                        "split_on": audio_app.state.config.TTS_SPLIT_ON,
                     },
                     "stt": {
                         "engine": audio_app.state.config.STT_ENGINE,
                     },
-                },
-                "file": {
-                    "max_size": rag_app.state.config.FILE_MAX_SIZE,
-                    "max_count": rag_app.state.config.FILE_MAX_COUNT,
                 },
                 "permissions": {**webui_app.state.config.USER_PERMISSIONS},
             }
             if user is not None
             else {}
         ),
     }
 @app.get("/api/config/model/filter")
 async def get_model_filter_config(user=Depends(get_admin_user)):
     return {

--- a/backend/migrations/env.py
+++ b/backend/migrations/env.py
@@ -7,21 +7,21 @@
 from apps.webui.models.chats import Chat
 from apps.webui.models.documents import Document
 from apps.webui.models.memories import Memory
 from apps.webui.models.models import Model
 from apps.webui.models.prompts import Prompt
 from apps.webui.models.tags import Tag, ChatIdTag
 from apps.webui.models.tools import Tool
 from apps.webui.models.users import User
 from apps.webui.models.files import File
 from apps.webui.models.functions import Function
-from env import DATABASE_URL
+from config import DATABASE_URL
 config = context.config
 if config.config_file_name is not None:
     fileConfig(config.config_file_name, disable_existing_loggers=False)
 target_metadata = Auth.metadata
 DB_URL = DATABASE_URL
 if DB_URL:
     config.set_main_option("sqlalchemy.url", DB_URL.replace("%", "%%"))
 def run_migrations_offline() -> None:
     """Run migrations in 'offline' mode.
     This configures the context with just a URL

--- a/backend/migrations/versions/ca81bd47c050_add_config_table.py
+++ b//dev/null
@@ -1,32 +0,0 @@
-"""Add config table
-Revision ID: ca81bd47c050
-Revises: 7e5b5dc7342b
-Create Date: 2024-08-25 15:26:35.241684
-"""
-from typing import Sequence, Union
-from alembic import op
-import sqlalchemy as sa
-import apps.webui.internal.db
-revision: str = "ca81bd47c050"
-down_revision: Union[str, None] = "7e5b5dc7342b"
-branch_labels: Union[str, Sequence[str], None] = None
-depends_on: Union[str, Sequence[str], None] = None
-def upgrade():
-    op.create_table(
-        "config",
-        sa.Column("id", sa.Integer, primary_key=True),
-        sa.Column("data", sa.JSON(), nullable=False),
-        sa.Column("version", sa.Integer, nullable=False),
-        sa.Column(
-            "created_at", sa.DateTime(), nullable=False, server_default=sa.func.now()
-        ),
-        sa.Column(
-            "updated_at",
-            sa.DateTime(),
-            nullable=True,
-            server_default=sa.func.now(),
-            onupdate=sa.func.now(),
-        ),
-    )
-def downgrade():
-    op.drop_table("config")

--- a/backend/utils/misc.py
+++ b/backend/utils/misc.py
@@ -53,21 +53,21 @@
     return messages
 def add_or_update_system_message(content: str, messages: list[dict]):
     """
     Adds a new system message at the beginning of the messages list
     or updates the existing system message at the beginning.
     :param msg: The message to be added or appended.
     :param messages: The list of message dictionaries.
     :return: The updated list of message dictionaries.
     """
     if messages and messages[0].get("role") == "system":
-        messages[0]["content"] = f"{content}\n{messages[0]['content']}"
+        messages[0]["content"] += f"{content}\n{messages[0]['content']}"
     else:
         messages.insert(0, {"role": "system", "content": content})
     return messages
 def openai_chat_message_template(model: str):
     return {
         "id": f"{model}-{str(uuid.uuid4())}",
         "created": int(time.time()),
         "model": model,
         "choices": [{"index": 0, "logprobs": None, "finish_reason": None}],
     }

--- a/backend/utils/utils.py
+++ b/backend/utils/utils.py
@@ -1,36 +1,36 @@
 from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
 from fastapi import HTTPException, status, Depends, Request
 from apps.webui.models.users import Users
 from typing import Union, Optional
 from constants import ERROR_MESSAGES
 from passlib.context import CryptContext
-from datetime import datetime, timedelta, UTC
+from datetime import datetime, timedelta
 import jwt
 import uuid
 import logging
-from env import WEBUI_SECRET_KEY
+import config
 logging.getLogger("passlib").setLevel(logging.ERROR)
-SESSION_SECRET = WEBUI_SECRET_KEY
+SESSION_SECRET = config.WEBUI_SECRET_KEY
 ALGORITHM = "HS256"
 bearer_security = HTTPBearer(auto_error=False)
 pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")
 def verify_password(plain_password, hashed_password):
     return (
         pwd_context.verify(plain_password, hashed_password) if hashed_password else None
     )
 def get_password_hash(password):
     return pwd_context.hash(password)
 def create_token(data: dict, expires_delta: Union[timedelta, None] = None) -> str:
     payload = data.copy()
     if expires_delta:
-        expire = datetime.now(UTC) + expires_delta
+        expire = datetime.utcnow() + expires_delta
         payload.update({"exp": expire})
     encoded_jwt = jwt.encode(payload, SESSION_SECRET, algorithm=ALGORITHM)
     return encoded_jwt
 def decode_token(token: str) -> Optional[dict]:
     try:
         decoded = jwt.decode(token, SESSION_SECRET, algorithms=[ALGORITHM])
         return decoded
     except Exception:
         return None
 def extract_token_from_auth_header(auth_header: str):

--- a/src/lib/apis/audio/index.ts
+++ b/src/lib/apis/audio/index.ts
@@ -106,24 +106,21 @@
 		.catch((err) => {
 			error = err.detail;
 			console.log(err);
 			return null;
 		});
 	if (error) {
 		throw error;
 	}
 	return res;
 };
-interface AvailableModelsResponse {
-	models: { name: string; id: string }[] | { id: string }[];
-}
-export const getModels = async (token: string = ''): Promise<AvailableModelsResponse> => {
+export const getModels = async (token: string = '') => {
 	let error = null;
 	const res = await fetch(`${AUDIO_API_BASE_URL}/models`, {
 		method: 'GET',
 		headers: {
 			'Content-Type': 'application/json',
 			Authorization: `Bearer ${token}`
 		}
 	})
 		.then(async (res) => {
 			if (!res.ok) throw await res.json();

--- a/src/lib/apis/memories/index.ts
+++ b/src/lib/apis/memories/index.ts
@@ -126,21 +126,21 @@
 			console.log(err);
 			return null;
 		});
 	if (error) {
 		throw error;
 	}
 	return res;
 };
 export const deleteMemoriesByUserId = async (token: string) => {
 	let error = null;
-	const res = await fetch(`${WEBUI_API_BASE_URL}/memories/delete/user`, {
+	const res = await fetch(`${WEBUI_API_BASE_URL}/memories/user`, {
 		method: 'DELETE',
 		headers: {
 			Accept: 'application/json',
 			'Content-Type': 'application/json',
 			authorization: `Bearer ${token}`
 		}
 	})
 		.then(async (res) => {
 			if (!res.ok) throw await res.json();
 			return res.json();

--- a/src/lib/apis/rag/index.ts
+++ b/src/lib/apis/rag/index.ts
@@ -337,21 +337,21 @@
 			return null;
 		});
 	if (error) {
 		throw error;
 	}
 	return res;
 };
 export const resetUploadDir = async (token: string) => {
 	let error = null;
 	const res = await fetch(`${RAG_API_BASE_URL}/reset/uploads`, {
-		method: 'POST',
+		method: 'GET',
 		headers: {
 			Accept: 'application/json',
 			authorization: `Bearer ${token}`
 		}
 	})
 		.then(async (res) => {
 			if (!res.ok) throw await res.json();
 			return res.json();
 		})
 		.catch((err) => {
@@ -359,21 +359,21 @@
 			return null;
 		});
 	if (error) {
 		throw error;
 	}
 	return res;
 };
 export const resetVectorDB = async (token: string) => {
 	let error = null;
 	const res = await fetch(`${RAG_API_BASE_URL}/reset/db`, {
-		method: 'POST',
+		method: 'GET',
 		headers: {
 			Accept: 'application/json',
 			authorization: `Bearer ${token}`
 		}
 	})
 		.then(async (res) => {
 			if (!res.ok) throw await res.json();
 			return res.json();
 		})
 		.catch((err) => {

--- a/src/lib/types/index.ts
+++ b/src/lib/types/index.ts
@@ -1,14 +1,9 @@
 export type Banner = {
 	id: string;
 	type: string;
 	title?: string;
 	content: string;
 	url?: string;
 	dismissible?: boolean;
 	timestamp: number;
 };
-export enum TTS_RESPONSE_SPLIT {
-	PUNCTUATION = 'punctuation',
-	PARAGRAPHS = 'paragraphs',
-	NONE = 'none'
-}

--- a/src/lib/utils/index.ts
+++ b/src/lib/utils/index.ts
@@ -1,14 +1,13 @@
 import { v4 as uuidv4 } from 'uuid';
 import sha256 from 'js-sha256';
 import { WEBUI_BASE_URL } from '$lib/constants';
-import { TTS_RESPONSE_SPLIT } from '$lib/types';
 const convertLatexToSingleLine = (content) => {
 	const patterns = [
 		/(\$\$\s[\s\S]*?\s\$\$)/g, // Match $$ ... $$
 		/(\\\[[\s\S]*?\\\])/g, // Match \[ ... \]
 		/(\\begin\{[a-z]+\}[\s\S]*?\\end\{[a-z]+\})/g // Match \begin{...} ... \end{...}
 	];
 	patterns.forEach((pattern) => {
 		content = content.replace(pattern, (match) => {
 			return match.replace(/\s*\n\s*/g, ' ').trim();
 		});
@@ -214,31 +213,20 @@
 	let match;
 	while ((match = regex.exec(text)) !== null) {
 		matches.push({
 			word: match[1],
 			startIndex: match.index,
 			endIndex: regex.lastIndex - 1
 		});
 	}
 	return matches;
 };
-export const removeLastWordFromString = (inputString, wordString) => {
-	const words = inputString.split(' ');
-	if (words.at(-1) === wordString) {
-		words.pop();
-	}
-	let resultString = words.join(' ');
-	if (resultString !== '') {
-		resultString += ' ';
-	}
-	return resultString;
-};
 export const removeFirstHashWord = (inputString) => {
 	const words = inputString.split(' ');
 	const index = words.findIndex((word) => word.startsWith('#'));
 	if (index !== -1) {
 		words.splice(index, 1);
 	}
 	const resultString = words.join(' ');
 	return resultString;
 };
 export const transformFileName = (fileName) => {
@@ -287,21 +275,21 @@
 		return { latitude, longitude };
 	} else {
 		return `${latitude.toFixed(3)}, ${longitude.toFixed(3)} (lat, long)`;
 	}
 };
 const convertOpenAIMessages = (convo) => {
 	const mapping = convo['mapping'];
 	const messages = [];
 	let currentId = '';
 	let lastId = null;
-	for (const message_id in mapping) {
+	for (let message_id in mapping) {
 		const message = mapping[message_id];
 		currentId = message_id;
 		try {
 			if (
 				messages.length == 0 &&
 				(message['message'] == null ||
 					(message['message']['content']['parts']?.[0] == '' &&
 						message['message']['content']['text'] == null))
 			) {
 				continue;
@@ -319,21 +307,21 @@
 					done: true,
 					context: null
 				};
 				messages.push(new_chat);
 				lastId = currentId;
 			}
 		} catch (error) {
 			console.log('Error with', message, '\nError:', error);
 		}
 	}
-	const history: Record<PropertyKey, (typeof messages)[number]> = {};
+	let history = {};
 	messages.forEach((obj) => (history[obj.id] = obj));
 	const chat = {
 		history: {
 			currentId: currentId,
 			messages: history // Need to convert this to not a list and instead a json object
 		},
 		models: ['gpt-3.5-turbo'],
 		messages: messages,
 		options: {},
 		timestamp: convo['create_time'],
@@ -347,128 +335,96 @@
 		return false;
 	}
 	const lastMessage = messages[messages.length - 1];
 	if (lastMessage.childrenIds.length !== 0) {
 		return false;
 	}
 	const firstMessage = messages[0];
 	if (firstMessage.parentId !== null) {
 		return false;
 	}
-	for (const message of messages) {
+	for (let message of messages) {
 		if (typeof message.content !== 'string') {
 			return false;
 		}
 	}
 	return true;
 };
 export const convertOpenAIChats = (_chats) => {
 	const chats = [];
 	let failed = 0;
-	for (const convo of _chats) {
+	for (let convo of _chats) {
 		const chat = convertOpenAIMessages(convo);
 		if (validateChat(chat)) {
 			chats.push({
 				id: convo['id'],
 				user_id: '',
 				title: convo['title'],
 				chat: chat,
 				timestamp: convo['timestamp']
 			});
 		} else {
 			failed++;
 		}
 	}
 	console.log(failed, 'Conversations could not be imported');
 	return chats;
 };
-export const isValidHttpUrl = (string: string) => {
+export const isValidHttpUrl = (string) => {
 	let url;
 	try {
 		url = new URL(string);
 	} catch (_) {
 		return false;
 	}
 	return url.protocol === 'http:' || url.protocol === 'https:';
 };
-export const removeEmojis = (str: string) => {
+export const removeEmojis = (str) => {
 	const emojiRegex = /[\uD800-\uDBFF][\uDC00-\uDFFF]|\uD83C[\uDC00-\uDFFF]|\uD83D[\uDC00-\uDE4F]/g;
 	return str.replace(emojiRegex, '');
 };
-export const removeFormattings = (str: string) => {
+export const removeFormattings = (str) => {
 	return str.replace(/(\*)(.*?)\1/g, '').replace(/(```)(.*?)\1/gs, '');
 };
-export const cleanText = (content: string) => {
-	return removeFormattings(removeEmojis(content.trim()));
-};
-const codeBlockRegex = /```[\s\S]*?```/g;
-export const extractSentences = (text: string) => {
-	const codeBlocks: string[] = [];
+export const extractSentences = (text) => {
+	const codeBlockRegex = /```[\s\S]*?```/g;
+	let codeBlocks = [];
 	let index = 0;
 	text = text.replace(codeBlockRegex, (match) => {
-		const placeholder = `\u0000${index}\u0000`; // Use a unique placeholder
+		let placeholder = `\u0000${index}\u0000`; // Use a unique placeholder
 		codeBlocks[index++] = match;
 		return placeholder;
 	});
 	let sentences = text.split(/(?<=[.!?])\s+/);
 	sentences = sentences.map((sentence) => {
 		return sentence.replace(/\u0000(\d+)\u0000/g, (_, idx) => codeBlocks[idx]);
 	});
-	return sentences.map(cleanText).filter(Boolean);
-};
-export const extractParagraphsForAudio = (text: string) => {
-	const codeBlocks: string[] = [];
-	let index = 0;
-	text = text.replace(codeBlockRegex, (match) => {
-		const placeholder = `\u0000${index}\u0000`; // Use a unique placeholder
-		codeBlocks[index++] = match;
-		return placeholder;
-	});
-	let paragraphs = text.split(/\n+/);
-	paragraphs = paragraphs.map((paragraph) => {
-		return paragraph.replace(/\u0000(\d+)\u0000/g, (_, idx) => codeBlocks[idx]);
-	});
-	return paragraphs.map(cleanText).filter(Boolean);
-};
-export const extractSentencesForAudio = (text: string) => {
+	return sentences
+		.map((sentence) => removeFormattings(removeEmojis(sentence.trim())))
+		.filter((sentence) => sentence);
+};
+export const extractSentencesForAudio = (text) => {
 	return extractSentences(text).reduce((mergedTexts, currentText) => {
 		const lastIndex = mergedTexts.length - 1;
 		if (lastIndex >= 0) {
 			const previousText = mergedTexts[lastIndex];
 			const wordCount = previousText.split(/\s+/).length;
-			const charCount = previousText.length;
-			if (wordCount < 4 || charCount < 50) {
+			if (wordCount < 2) {
 				mergedTexts[lastIndex] = previousText + ' ' + currentText;
 			} else {
 				mergedTexts.push(currentText);
 			}
 		} else {
 			mergedTexts.push(currentText);
 		}
 		return mergedTexts;
-	}, [] as string[]);
-};
-export const getMessageContentParts = (content: string, split_on: string = 'punctuation') => {
-	const messageContentParts: string[] = [];
-	switch (split_on) {
-		default:
-		case TTS_RESPONSE_SPLIT.PUNCTUATION:
-			messageContentParts.push(...extractSentencesForAudio(content));
-			break;
-		case TTS_RESPONSE_SPLIT.PARAGRAPHS:
-			messageContentParts.push(...extractParagraphsForAudio(content));
-			break;
-		case TTS_RESPONSE_SPLIT.NONE:
-			messageContentParts.push(cleanText(content));
-			break;
-	}
-	return messageContentParts;
+	}, []);
 };
 export const blobToFile = (blob, fileName) => {
 	const file = new File([blob], fileName, { type: blob.type });
 	return file;
 };
 /**
  * @param {string} template - The template string containing placeholders.
  * @returns {string} The template string with the placeholders replaced by the prompt.
  */
 export const promptTemplate = (
