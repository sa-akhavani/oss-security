# ====================================================================
# FILE: peewee.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 53-93 ---
    53| except ImportError:
    54|     psycopg2 = pg_errors = None
    55| try:
    56|     from psycopg2.extras import register_uuid as pg_register_uuid
    57|     pg_register_uuid()
    58| except Exception:
    59|     pass
    60| try:
    61|     from psycopg import errors as pg3_errors
    62| except ImportError:
    63|     pg3_errors = None
    64| mysql_passwd = False
    65| try:
    66|     import pymysql as mysql
    67| except ImportError:
    68|     try:
    69|         import MySQLdb as mysql
    70|         mysql_passwd = True
    71|     except ImportError:
    72|         mysql = None
    73| __version__ = '3.18.3'
    74| __all__ = [
    75|     'AnyField',
    76|     'AsIs',
    77|     'AutoField',
    78|     'BareField',
    79|     'BigAutoField',
    80|     'BigBitField',
    81|     'BigIntegerField',
    82|     'BinaryUUIDField',
    83|     'BitField',
    84|     'BlobField',
    85|     'BooleanField',
    86|     'Case',
    87|     'Cast',
    88|     'CharField',
    89|     'Check',
    90|     'chunked',
    91|     'Column',
    92|     'CompositeKey',
    93|     'Context',


# ====================================================================
# FILE: playhouse/postgres_ext.py
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 27-107 ---
    27| except:
    28|     Json = None
    29| logger = logging.getLogger('peewee')
    30| HCONTAINS_DICT = '@>'
    31| HCONTAINS_KEYS = '?&'
    32| HCONTAINS_KEY = '?'
    33| HCONTAINS_ANY_KEY = '?|'
    34| HKEY = '->'
    35| HUPDATE = '||'
    36| ACONTAINS = '@>'
    37| ACONTAINED_BY = '<@'
    38| ACONTAINS_ANY = '&&'
    39| TS_MATCH = '@@'
    40| JSONB_CONTAINS = '@>'
    41| JSONB_CONTAINED_BY = '<@'
    42| JSONB_CONTAINS_KEY = '?'
    43| JSONB_CONTAINS_ANY_KEY = '?|'
    44| JSONB_CONTAINS_ALL_KEYS = '?&'
    45| JSONB_EXISTS = '?'
    46| JSONB_REMOVE = '-'
    47| JSONB_PATH = '#>'
    48| class _LookupNode(ColumnBase):
    49|     def __init__(self, node, parts):
    50|         self.node = node
    51|         self.parts = parts
    52|         super(_LookupNode, self).__init__()
    53|     def clone(self):
    54|         return type(self)(self.node, list(self.parts))
    55|     def __hash__(self):
    56|         return hash((self.__class__.__name__, id(self)))
    57| class _JsonLookupBase(_LookupNode):
    58|     def __init__(self, node, parts, as_json=False):
    59|         super(_JsonLookupBase, self).__init__(node, parts)
    60|         self._as_json = as_json
    61|     def clone(self):
    62|         return type(self)(self.node, list(self.parts), self._as_json)
    63|     @Node.copy
    64|     def as_json(self, as_json=True):
    65|         self._as_json = as_json
    66|     def concat(self, rhs):
    67|         if not isinstance(rhs, Node):
    68|             rhs = Json(rhs)
    69|         return Expression(self.as_json(True), OP.CONCAT, rhs)
    70|     def contains(self, other):
    71|         return Expression(self.as_json(True), JSONB_CONTAINS, Json(other))
    72|     def contained_by(self, other):
    73|         return Expression(self.as_json(True), JSONB_CONTAINED_BY, Json(other))
    74|     def contains_any(self, *keys):
    75|         return Expression(
    76|             self.as_json(True),
    77|             JSONB_CONTAINS_ANY_KEY,
    78|             Value(list(keys), unpack=False))
    79|     def contains_all(self, *keys):
    80|         return Expression(
    81|             self.as_json(True),
    82|             JSONB_CONTAINS_ALL_KEYS,
    83|             Value(list(keys), unpack=False))
    84|     def has_key(self, key):
    85|         return Expression(self.as_json(True), JSONB_CONTAINS_KEY, key)
    86|     def path(self, *keys):
    87|         return JsonPath(self.as_json(True), keys)
    88| class JsonLookup(_JsonLookupBase):
    89|     def __getitem__(self, value):
    90|         return JsonLookup(self.node, self.parts + [value], self._as_json)
    91|     def __sql__(self, ctx):
    92|         ctx.sql(self.node)
    93|         for part in self.parts[:-1]:
    94|             ctx.literal('->').sql(part)
    95|         if self.parts:
    96|             (ctx
    97|              .literal('->' if self._as_json else '->>')
    98|              .sql(self.parts[-1]))
    99|         return ctx
   100| class JsonPath(_JsonLookupBase):
   101|     def __sql__(self, ctx):
   102|         return (ctx
   103|                 .sql(self.node)
   104|                 .literal('#>' if self._as_json else '#>>')
   105|                 .sql(Value('{%s}' % ','.join(map(str, self.parts)))))
   106| class ObjectSlice(_LookupNode):
   107|     @classmethod


# ====================================================================
# FILE: playhouse/shortcuts.py
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 48-95 ---
    48|                 continue
    49|             exclude.update((m2m, m2m.rel_model._meta.manytomany[m2m.backref]))
    50|             for fkf in m2m.through_model._meta.refs:
    51|                 exclude.add(fkf)
    52|             accum = []
    53|             for rel_obj in getattr(model, name):
    54|                 accum.append(model_to_dict(
    55|                     rel_obj,
    56|                     recurse=recurse,
    57|                     backrefs=backrefs,
    58|                     only=only,
    59|                     exclude=exclude,
    60|                     max_depth=max_depth - 1))
    61|             data[name] = accum
    62|     for field in model._meta.sorted_fields:
    63|         if should_skip(field):
    64|             continue
    65|         field_data = model.__data__.get(field.name)
    66|         if isinstance(field, ForeignKeyField) and recurse:
    67|             if field_data is not None:
    68|                 rel_obj = getattr(model, field.name)
    69|                 field_data = model_to_dict(
    70|                     rel_obj,
    71|                     recurse=recurse,
    72|                     backrefs=backrefs,
    73|                     only=only,
    74|                     exclude=exclude,
    75|                     seen=seen | set((field,)),
    76|                     max_depth=max_depth - 1)
    77|             else:
    78|                 field_data = None
    79|         data[field.name] = field_data
    80|     if extra_attrs:
    81|         for attr_name in extra_attrs:
    82|             attr = getattr(model, attr_name)
    83|             if callable_(attr):
    84|                 data[attr_name] = attr()
    85|             else:
    86|                 data[attr_name] = attr
    87|     if backrefs and recurse:
    88|         for foreign_key, rel_model in model._meta.backrefs.items():
    89|             if foreign_key.backref == '+': continue
    90|             descriptor = getattr(model_class, foreign_key.backref)
    91|             if descriptor in exclude or foreign_key in exclude:
    92|                 continue
    93|             if only and (descriptor not in only) and (foreign_key not in only):
    94|                 continue
    95|             accum = []

# --- HUNK 2: Lines 182-226 ---
   182|     REALLY know what you are doing) and definitely has no business being used
   183|     with Sqlite. If you wish to use with Postgres, you will need to adapt the
   184|     `reconnect_errors` attribute to something appropriate for Postgres.
   185|     """
   186|     reconnect_errors = (
   187|         (OperationalError, '2006'),  # MySQL server has gone away.
   188|         (OperationalError, '2013'),  # Lost connection to MySQL server.
   189|         (OperationalError, '2014'),  # Commands out of sync.
   190|         (OperationalError, '4031'),  # Client interaction timeout.
   191|         (OperationalError, 'MySQL Connection not available.'),
   192|     )
   193|     def __init__(self, *args, **kwargs):
   194|         super(ReconnectMixin, self).__init__(*args, **kwargs)
   195|         self._reconnect_errors = {}
   196|         for exc_class, err_fragment in self.reconnect_errors:
   197|             self._reconnect_errors.setdefault(exc_class, [])
   198|             self._reconnect_errors[exc_class].append(err_fragment.lower())
   199|     def execute_sql(self, sql, params=None, commit=None):
   200|         if commit is not None:
   201|             __deprecated__('"commit" has been deprecated and is a no-op.')
   202|         return self._reconnect(super(ReconnectMixin, self).execute_sql,
   203|                                sql, params)
   204|     def begin(self, *args, **kwargs):
   205|         return self._reconnect(super(ReconnectMixin, self).begin,
   206|                                *args, **kwargs)
   207|     def _reconnect(self, func, *args, **kwargs):
   208|         try:
   209|             return func(*args, **kwargs)
   210|         except Exception as exc:
   211|             if self.in_transaction():
   212|                 raise exc
   213|             exc_class = type(exc)
   214|             if exc_class not in self._reconnect_errors:
   215|                 raise exc
   216|             exc_repr = str(exc).lower()
   217|             for err_fragment in self._reconnect_errors[exc_class]:
   218|                 if err_fragment in exc_repr:
   219|                     break
   220|             else:
   221|                 raise exc
   222|             if not self.is_closed():
   223|                 self.close()
   224|                 self.connect()
   225|             return func(*args, **kwargs)
   226| def resolve_multimodel_query(query, key='_model_identifier'):


# ====================================================================
# FILE: playhouse/sqlite_ext.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 416-456 ---
   416|             explicit_ordering)
   417|     @classmethod
   418|     def search_lucene(cls, term, weights=None, with_score=False,
   419|                       score_alias='score', explicit_ordering=False):
   420|         """Full-text search for selected `term` using BM25 algorithm."""
   421|         return cls._search(
   422|             term,
   423|             weights,
   424|             with_score,
   425|             score_alias,
   426|             cls.lucene,
   427|             explicit_ordering)
   428| _alphabet = 'abcdefghijklmnopqrstuvwxyz'
   429| _alphanum = (set('\t ,"(){}*:_+0123456789') |
   430|              set(_alphabet) |
   431|              set(_alphabet.upper()) |
   432|              set((chr(26),)))
   433| _invalid_ascii = set(chr(p) for p in range(128) if chr(p) not in _alphanum)
   434| del _alphabet
   435| del _alphanum
   436| _quote_re = re.compile(r'[^\s"]+|"[^"\\]*(?:\\.[^"\\]*)*"')
   437| class FTS5Model(BaseFTSModel):
   438|     """
   439|     Requires SQLite >= 3.9.0.
   440|     Table options:
   441|     content: table name of external content, or empty string for "contentless"
   442|     content_rowid: column name of external content primary key
   443|     prefix: integer(s). Ex: '2' or '2 3 4'
   444|     tokenize: porter, unicode61, ascii. Ex: 'porter unicode61'
   445|     The unicode tokenizer supports the following parameters:
   446|     * remove_diacritics (1 or 0, default is 1)
   447|     * tokenchars (string of characters, e.g. '-_'
   448|     * separators (string of characters)
   449|     Parameters are passed as alternating parameter name and value, so:
   450|     {'tokenize': "unicode61 remove_diacritics 0 tokenchars '-_'"}
   451|     Content-less tables:
   452|     If you don't need the full-text content in it's original form, you can
   453|     specify a content-less table. Searches and auxiliary functions will work
   454|     as usual, but the only values returned when SELECT-ing can be rowid. Also
   455|     content-less tables do not support UPDATE or DELETE.
   456|     External content tables:

