# ====================================================================
# FILE: alerts/migrations/0002_alter_messagingserviceconfig_project.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-18 ---
     1| from django.db import migrations, models
     2| import django.db.models.deletion
     3| class Migration(migrations.Migration):
     4|     dependencies = [
     5|         ("projects", "0014_alter_projectmembership_project"),
     6|         ("alerts", "0001_initial"),
     7|     ]
     8|     operations = [
     9|         migrations.AlterField(
    10|             model_name="messagingserviceconfig",
    11|             name="project",
    12|             field=models.ForeignKey(
    13|                 on_delete=django.db.models.deletion.DO_NOTHING,
    14|                 related_name="service_configs",
    15|                 to="projects.project",
    16|             ),
    17|         ),
    18|     ]


# ====================================================================
# FILE: alerts/models.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-11 ---
     1| from django.db import models
     2| from projects.models import Project
     3| from .service_backends.slack import SlackBackend
     4| class MessagingServiceConfig(models.Model):
     5|     project = models.ForeignKey(Project, on_delete=models.DO_NOTHING, related_name="service_configs")
     6|     display_name = models.CharField(max_length=100, blank=False,
     7|                                     help_text='For display in the UI, e.g. "#general on company Slack"')
     8|     kind = models.CharField(choices=[("slack", "Slack (or compatible)"), ], max_length=20, default="slack")
     9|     config = models.TextField(blank=False)
    10|     def get_backend(self):
    11|         return SlackBackend(self)


# ====================================================================
# FILE: bugsink/context_processors.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-73 ---
     1| from datetime import timedelta
     2| from collections import namedtuple
     3| from django.conf import settings
     4| from django.utils import timezone
     5| from django.utils.safestring import mark_safe
     6| from django.urls import reverse
     7| from django.contrib.auth.models import AnonymousUser
     8| from django.db.utils import OperationalError
     9| from django.db.models import Sum
    10| from bugsink.app_settings import get_settings, CB_ANYBODY
    11| from bugsink.transaction import durable_atomic
    12| from bugsink.timed_sqlite_backend.base import different_runtime_limit
    13| from snappea.settings import get_settings as get_snappea_settings
    14| from snappea.models import Task, Stat
    15| from phonehome.models import Installation
    16| SystemWarning = namedtuple('SystemWarning', ['message', 'ignore_url'])
    17| EMAIL_BACKEND_WARNING = mark_safe(
    18|     """Email is not set up, emails won't be sent. To get the most out of Bugsink, please
    19|     <a href="https://www.bugsink.com/docs/settings/#email" target="_blank" class="font-bold text-slate-800
    20|     dark:text-slate-100">set up email</a>.""")
    21| def get_snappea_warnings():
    22|     if get_snappea_settings().TASK_ALWAYS_EAGER:
    23|         return []
    24|     with durable_atomic(using="snappea"):
    25|         with different_runtime_limit(0.1, using="snappea"):
    26|             try:
    27|                 task_count = Task.objects.all().count()
    28|             except OperationalError as e:
    29|                 if e.args[0] != "interrupted":
    30|                     raise
    31|                 task_count = "many"
    32|         if task_count == 0:
    33|             return []
    34|         ten_minutes_ago = timezone.now() - timedelta(minutes=10)
    35|         done = Stat.objects.filter(timestamp__gt=ten_minutes_ago).aggregate(done=Sum('done')).get('done', 0)
    36|         oldest_task_age = int(
    37|             (timezone.now() - Task.objects.all().order_by('created_at').first().created_at).total_seconds())
    38|     snappea_warning = f"Snappea has {task_count} tasks in the queue, the oldest being {oldest_task_age}s old. "
    39|     if done:
    40|         snappea_warning += f"It's processed approximately { done } tasks in the last 10 minutes. "
    41|     elif oldest_task_age > 70:
    42|         snappea_warning += "No tasks processed recently. Snappea may not be running, misconfigured or blocked."
    43|     else:
    44|         snappea_warning += "Snappea may be either backlogged, not running, misconfigured or blocked."
    45|     WARNING = SystemWarning((snappea_warning), None)
    46|     if task_count > 300:
    47|         return [WARNING]
    48|     if oldest_task_age > 5:
    49|         return [WARNING]
    50|     return []
    51| def useful_settings_processor(request):
    52|     """Adds useful settings (and more) to the context."""
    53|     def get_system_warnings():
    54|         installation = Installation.objects.get()
    55|         system_warnings = []
    56|         if settings.EMAIL_BACKEND in [
    57|                 'bugsink.email_backends.QuietConsoleEmailBackend'] and not installation.silence_email_system_warning:
    58|             if getattr(request, "user", AnonymousUser()).is_superuser:
    59|                 ignore_url = reverse("silence_email_system_warning")
    60|             else:
    61|                 ignore_url = None
    62|             system_warnings.append(SystemWarning(EMAIL_BACKEND_WARNING, ignore_url))
    63|         return system_warnings + get_snappea_warnings()
    64|     return {
    65|         'site_title': get_settings().SITE_TITLE,
    66|         'registration_enabled': get_settings().USER_REGISTRATION == CB_ANYBODY,
    67|         'app_settings': get_settings(),
    68|         'system_warnings': get_system_warnings,
    69|     }
    70| def logged_in_user_processor(request):
    71|     return {
    72|         'logged_in_user': getattr(request, "user", AnonymousUser()),
    73|     }


# ====================================================================
# FILE: bugsink/decorators.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-79 ---
     1| from functools import wraps
     2| from django.shortcuts import get_object_or_404
     3| from django.core.exceptions import PermissionDenied
     4| from projects.models import Project
     5| from issues.models import Issue
     6| from events.models import Event
     7| from .transaction import durable_atomic, immediate_atomic
     8| def login_exempt(view):
     9|     view.login_exempt = True
    10|     return view
    11| def project_membership_required(function):
    12|     @wraps(function)
    13|     def wrapper(request, *args, **kwargs):
    14|         if "project_pk" not in kwargs:
    15|             raise TypeError("project_pk must be passed as a keyword argument")
    16|         project_pk = kwargs.pop("project_pk")
    17|         project = get_object_or_404(Project, pk=project_pk)
    18|         kwargs["project"] = project
    19|         if request.user.is_superuser:
    20|             return function(request, *args, **kwargs)
    21|         if project.users.filter(pk=request.user.pk).exists():
    22|             return function(request, *args, **kwargs)
    23|         raise PermissionDenied("You don't have permission to access this project")
    24|     return wrapper
    25| def issue_membership_required(function):
    26|     @wraps(function)
    27|     def wrapper(request, *args, **kwargs):
    28|         if "issue_pk" not in kwargs:
    29|             raise TypeError("issue_pk must be passed as a keyword argument")
    30|         issue_pk = kwargs.pop("issue_pk")
    31|         issue = get_object_or_404(Issue, pk=issue_pk, is_deleted=False)
    32|         kwargs["issue"] = issue
    33|         if request.user.is_superuser:
    34|             return function(request, *args, **kwargs)
    35|         if issue.project.users.filter(pk=request.user.pk).exists():
    36|             return function(request, *args, **kwargs)
    37|         raise PermissionDenied("You don't have permission to access this project")
    38|     return wrapper
    39| def event_membership_required(function):
    40|     @wraps(function)
    41|     def wrapper(request, *args, **kwargs):
    42|         if "event_pk" not in kwargs:
    43|             raise TypeError("event_pk must be passed as a keyword argument")
    44|         event_pk = kwargs.pop("event_pk")
    45|         event = get_object_or_404(Event, pk=event_pk)
    46|         kwargs["event"] = event
    47|         if request.user.is_superuser:
    48|             return function(request, *args, **kwargs)
    49|         if event.project.users.filter(pk=request.user.pk).exists():
    50|             return function(request, *args, **kwargs)
    51|         raise PermissionDenied("You don't have permission to access this project")
    52|     return wrapper
    53| def atomic_for_request_method(function, *decorator_args, **decorator_kwargs):
    54|     """
    55|     Wrap the request in the kind of atomic transaction matching its request method:
    56|     This is what immediate_atomic is for.
    57|     This might be surprising if you think about transactions as mainly a means of guaranteeing atomicity of writes (as
    58|     is directly implied by Django's naming). The thing we're going for is snapshot isolation (given by SQLite in WAL
    59|     mode (which we have turned on) in combination with use of transactions).
    60|     I want to have snapshot isolation because it's a mental model that I can understand. I'd argue it's the natural or
    61|     implicit mental model, and I'd rather have my program behave like so than spend _any_ time thinking about subtleties
    62|     such as "what if you select an event and an issue that are slightly out of sync" or to hunt down any hard to
    63|     reproduce bugs caused by such inconsistencies.
    64|     This is provided as a decorator; the expected use case is to wrap an entire view function. The reason is that, in
    65|     practice, reads which should be inside the transaction happen very early, namely when doing the various
    66|     membership_required checks. (the results of these reads are passed into the view function as event/issue/project)
    67|     (Path not taken: one could say that the membership_required tests are separate from the actual handling of the
    68|     request, whether that's a pure display request or an update. Instead of wrapping the transaction around everything,
    69|     you could re-select inside the view function. Potential advantage: shorter transactions (mostly relevant for writes,
    70|     since read-transactions are non-blocking). Disadvantage: one more query, and more complexity)
    71|     """
    72|     @wraps(function)
    73|     def wrapper(request, *args, **kwargs):
    74|         if request.method in ["POST", "PUT", "PATCH", "DELETE"]:
    75|             with immediate_atomic(*decorator_args, **decorator_kwargs):
    76|                 return function(request, *args, **kwargs)
    77|         with durable_atomic(*decorator_args, **decorator_kwargs):
    78|             return function(request, *args, **kwargs)
    79|     return wrapper


# ====================================================================
# FILE: bugsink/transaction.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-128 ---
     1| from contextlib import contextmanager
     2| import logging
     3| import time
     4| from functools import partial
     5| import types
     6| import threading
     7| from django.db import transaction as django_db_transaction
     8| from django.db import DEFAULT_DB_ALIAS
     9| from snappea.settings import get_settings as get_snappea_settings
    10| performance_logger = logging.getLogger("bugsink.performance.db")
    11| local_storage = threading.local()
    12| immediate_semaphores = {
    13|     DEFAULT_DB_ALIAS: threading.Semaphore(1),
    14|     "snappea": threading.Semaphore(1),
    15| }
    16| class SemaphoreContext:
    17|     def __init__(self, using):
    18|         self.using = using
    19|     def __enter__(self):
    20|         t0 = time.time()
    21|         if not immediate_semaphores[self.using].acquire(timeout=10):
    22|             raise RuntimeError("Could not acquire immediate_semaphore")
    23|         took = time.time() - t0
    24|         inc_stat(self.using, "get_write_lock", took)
    25|         using_clause = f" ({ self.using })" if self.using != DEFAULT_DB_ALIAS else ""
    26|         performance_logger.info(f"{took * 1000:6.2f}ms BEGIN IMMEDIATE, A.K.A. get-write-lock{using_clause}")
    27|     def __exit__(self, exc_type, exc_value, traceback):
    28|         immediate_semaphores[self.using].release()
    29| class SuperDurableAtomic(django_db_transaction.Atomic):
    30|     """'super' durable because it is durable in tests as well"""
    31|     def __enter__(self):
    32|         connection = django_db_transaction.get_connection(self.using)
    33|         if (self.durable and connection.atomic_blocks):
    34|             if not connection.atomic_blocks[-1]._from_testcase:
    35|                 raise RuntimeError("A durable atomic block cannot be nested within another atomic block.")
    36|             raise RuntimeError("A durable atomic block cannot be nested -- not even in tests.")
    37|         super(SuperDurableAtomic, self).__enter__()
    38|     def __exit__(self, exc_type, exc_value, traceback):
    39|         super(SuperDurableAtomic, self).__exit__(exc_type, exc_value, traceback)
    40| def durable_atomic(using=None, savepoint=True):
    41|     if callable(using):
    42|         return SuperDurableAtomic(DEFAULT_DB_ALIAS, savepoint, durable=True)(using)
    43|     return SuperDurableAtomic(using, savepoint, durable=True)
    44| def _start_transaction_under_autocommit_patched(self):
    45|     self.cursor().execute("BEGIN IMMEDIATE")
    46| class ImmediateAtomic(SuperDurableAtomic):
    47|     """
    48|     Sqlite specific (for other DBs this is simply ignored).
    49|     immediate_atomic allows us to begin atomic transactions using BEGIN IMMEDIATE instead of the default BEGIN. The
    50|     sqlite docs explain a context in which this is useful:
    51|     > Another example: X starts a read transaction using BEGIN and SELECT, then Y makes a changes to the database using
    52|     > UPDATE. Then X tries to make a change to the database using UPDATE. The attempt by X to escalate its transaction
    53|     > from a read transaction to a write transaction fails with an SQLITE_BUSY_SNAPSHOT error because the snapshot of
    54|     > the database being viewed by X is no longer the latest version of the database. If X were allowed to write, it
    55|     > would fork the history of the database file, which is something SQLite does not support. [..]
    56|     > **If X starts a transaction that will initially only read but X knows it will eventually want to write and does
    57|     > not want to be troubled with possible SQLITE_BUSY_SNAPSHOT errors that arise because another connection jumped
    58|     > ahead of it in line, then X can issue BEGIN IMMEDIATE to start its transaction instead of just an ordinary
    59|     > BEGIN.** The BEGIN IMMEDIATE command goes ahead and starts a write transaction, and thus blocks all other writers.
    60|     > If the BEGIN IMMEDIATE operation succeeds, then no subsequent operations in that transaction will ever fail with
    61|     > an SQLITE_BUSY error.
    62|     Django 5.1 will introduce the option to configure BEGIN IMMEDIATE, but only globally. This is not what we want,
    63|     because it unnecessarily escalates read-only-transactions into write-transactions.
    64|     https://github.com/django/django/pull/17760
    65|     PoC of the problem (which indeed goes away by converting to immediate); run in 2 separate shells to demonstrate it:
    66|     from time import sleep
    67|     from django.contrib.auth.models import User
    68|     from django.db import transaction
    69|     @transaction.atomic()
    70|     def read_sleep_write():
    71|         print("I am going to read")
    72|         user = User.objects.first()
    73|         print("I am going to sleep")
    74|         sleep(5)
    75|         print("I am going to write")
    76|         user.save() # no need to actually change the user, as long as we run a write query
    77|     One more note that I have trouble integrating into the story-line. Django says
    78|     > Atomicity is the defining property of database transactions.
    79|     But this is not true. But we also care about isolation (views on the data) and about serializability (the order of
    80|     transactions). In particular serializability (locking out other writers) is what we are after here.
    81|     """
    82|     def __enter__(self):
    83|         connection = django_db_transaction.get_connection(self.using)
    84|         if hasattr(connection, "_start_transaction_under_autocommit"):
    85|             self._start_transaction_under_autocommit_original = connection._start_transaction_under_autocommit
    86|             connection._start_transaction_under_autocommit = types.MethodType(
    87|                 _start_transaction_under_autocommit_patched, connection)
    88|         super(ImmediateAtomic, self).__enter__()
    89|         if connection.vendor != 'sqlite':
    90|             from django.contrib.contenttypes.models import ContentType
    91|             ContentType.objects.select_for_update().order_by("pk").first()
    92|         self.t0 = time.time()
    93|     def __exit__(self, exc_type, exc_value, traceback):
    94|         super(ImmediateAtomic, self).__exit__(exc_type, exc_value, traceback)
    95|         took = time.time() - self.t0
    96|         inc_stat(self.using, "immediate_transaction", took)
    97|         using_clause = f" ({ self.using })" if self.using != DEFAULT_DB_ALIAS else ""
    98|         performance_logger.info(f"{took * 1000:6.2f}ms IMMEDIATE transaction{using_clause}")
    99|         connection = django_db_transaction.get_connection(self.using)
   100|         if hasattr(self, "_start_transaction_under_autocommit_original"):
   101|             connection._start_transaction_under_autocommit = self._start_transaction_under_autocommit_original
   102|             del self._start_transaction_under_autocommit_original
   103| @contextmanager
   104| def immediate_atomic(using=None, savepoint=True, durable=True):
   105|     assert durable, "immediate_atomic should always be used with durable=True"
   106|     using = DEFAULT_DB_ALIAS if using is None else using  # harmonize to "default" at the top for downstream lookups
   107|     if callable(using):
   108|         immediate_atomic = ImmediateAtomic(DEFAULT_DB_ALIAS, savepoint, durable)(using)
   109|     else:
   110|         immediate_atomic = ImmediateAtomic(using, savepoint, durable)
   111|     if get_snappea_settings().TASK_ALWAYS_EAGER:
   112|         with immediate_atomic:
   113|             yield
   114|     else:
   115|         with SemaphoreContext(using), immediate_atomic:
   116|             yield
   117| def delay_on_commit(function, *args, **kwargs):
   118|     django_db_transaction.on_commit(partial(function.delay, *args, **kwargs))
   119| def inc_stat(using, stat, took):
   120|     if using != "default":
   121|         return  # function signature ready for such stats; not actually collected though
   122|     if not hasattr(local_storage, "stats"):
   123|         local_storage.stats = {}
   124|     if stat not in local_storage.stats:
   125|         local_storage.stats[stat] = 0
   126|     local_storage.stats[stat] += took
   127| def get_stat(stat):
   128|     return getattr(local_storage, "stats", {}).get(stat, 0)


# ====================================================================
# FILE: bugsink/utils.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-185 ---
     1| from collections import defaultdict
     2| from urllib.parse import urlparse
     3| from django.core.mail import EmailMultiAlternatives
     4| from django.template.loader import get_template
     5| from django.apps import apps
     6| from django.db.models import ForeignKey, F
     7| from .version import version
     8| def send_rendered_email(subject, base_template_name, recipient_list, context=None):
     9|     if context is None:
    10|         context = {}
    11|     html_content = get_template(base_template_name + ".html").render(context)
    12|     text_content = get_template(base_template_name + ".txt").render(context)
    13|     msg = EmailMultiAlternatives(
    14|         subject=subject,
    15|         body=text_content,
    16|         from_email=None,  # this is settings.DEFAULT_FROM_EMAIL
    17|         to=recipient_list,
    18|     )
    19|     msg.attach_alternative(html_content, "text/html")
    20|     msg.send()
    21| def deduce_allowed_hosts(base_url):
    22|     url = urlparse(base_url)
    23|     if url.hostname == "localhost" or url.hostname == "127.0.0.1":
    24|         return ["*"]
    25|     return [url.hostname] + ["localhost", "127.0.0.1"]
    26| def _name(type_):
    27|     try:
    28|         return type_.__module__ + "." + type_.__name__
    29|     except Exception:
    30|         try:
    31|             return type_.__name__
    32|         except Exception:
    33|             return "unknown"
    34| def fingerprint_exc(event, exc_info):
    35|     type_name = _name(exc_info[0])
    36|     if event["exception"]["values"][-1]["stacktrace"]["frames"][-1]["module"] == "bugsink.wsgi":
    37|         event['fingerprint'] = ['wsgi', type_name]
    38|     return event
    39| def fingerprint_log_record(event, log_record):
    40|     return event
    41| def fingerprint_before_send(event, hint):
    42|     if 'exc_info' in hint:
    43|         return fingerprint_exc(event, hint['exc_info'])
    44|     if 'log_record' in hint:
    45|         return fingerprint_log_record(event, hint['log_record'])
    46|     return event
    47| def eat_your_own_dogfood(sentry_dsn, **kwargs):
    48|     """
    49|     Configures your Bugsink installation to send messages to some Bugsink-compatible installation.
    50|     See https://www.bugsink.com/docs/dogfooding/
    51|     """
    52|     import sentry_sdk.serializer
    53|     sentry_sdk.serializer.MAX_DATABAG_DEPTH = float("inf")
    54|     sentry_sdk.serializer.MAX_DATABAG_BREADTH = float("inf")
    55|     if sentry_dsn is None:
    56|         return
    57|     default_kwargs = {
    58|         "dsn": sentry_dsn,
    59|         "traces_sample_rate": 0,
    60|         "send_default_pii": True,
    61|         "max_request_body_size": "always",
    62|         "in_app_include": [
    63|             "alerts",
    64|             "bsmain",
    65|             "bugsink",
    66|             "compat",
    67|             "events",
    68|             "ee",
    69|             "ingest",
    70|             "issues",
    71|             "performance",
    72|             "phonehome",
    73|             "projects",
    74|             "releases",
    75|             "sentry",
    76|             "sentry_sdk_extensions",
    77|             "snappea",
    78|             "tags",
    79|             "teams",
    80|             "theme",
    81|             "users",
    82|         ],
    83|         "release": version,
    84|         "before_send": fingerprint_before_send,
    85|     }
    86|     default_kwargs.update(kwargs)
    87|     sentry_sdk.init(
    88|         **default_kwargs,
    89|     )
    90| def get_model_topography():
    91|     """
    92|     Returns a dependency graph mapping:
    93|       referenced_model_key -> [
    94|           (referrer_model_class, fk_name),
    95|           ...
    96|       ]
    97|     """
    98|     dep_graph = defaultdict(list)
    99|     for model in apps.get_models():
   100|         for field in model._meta.get_fields(include_hidden=True):
   101|             if isinstance(field, ForeignKey):
   102|                 referenced_model = field.related_model
   103|                 referenced_key = f"{referenced_model._meta.app_label}.{referenced_model.__name__}"
   104|                 dep_graph[referenced_key].append((model, field.name))
   105|     return dep_graph
   106| def fields_for_prune_orphans(model):
   107|     if model.__name__ == "IssueTag":
   108|         return ("value_id",)
   109|     return ()
   110| def prune_orphans(model, d_ids_to_check):
   111|     """For some model, does dangling-model-cleanup.
   112|     In a sense the oposite of delete_deps; delete_deps takes care of deleting the recursive closure of things that point
   113|     to some root. The present function cleans up things that are being pointed to (and, after some other thing is
   114|     deleted, potentially are no longer being pointed to, hence 'orphaned').
   115|     This is the hardcoded edition (IssueTag only); we _could_ try to think about doing this generically based on the
   116|     dependency graph, but it's quite questionably whether a combination of generic & performant is easy to arrive at and
   117|     worth it.
   118|     pruning of TagValue is done "inline" (as opposed to using a GC-like vacuum "later") because, whatever the exact
   119|     performance trade-offs may be, the following holds true:
   120|     1. the inline version is easier to reason about, it "just happens ASAP", and in the context of a given issue;
   121|        vacuum-based has to take into consideration the full DB including non-orphaned values.
   122|     2. repeated work is somewhat minimalized b/c of the IssueTag/EventTag relationship as described in prune_tagvalues.
   123|     """
   124|     from tags.models import prune_tagvalues  # avoid circular import
   125|     if model.__name__ != "IssueTag":
   126|         return  # we only prune IssueTag orphans
   127|     ids_to_check = [d["value_id"] for d in d_ids_to_check]  # d_ids_to_check: mirrors fields_for_prune_orphans(model)
   128|     prune_tagvalues(ids_to_check)
   129| def do_pre_delete(project_id, model, pks_to_delete, is_for_project):
   130|     "More model-specific cleanup, if needed; only for Event model at the moment."
   131|     if model.__name__ != "Event":
   132|         return  # we only do more cleanup for Event
   133|     from projects.models import Project
   134|     from events.models import Event
   135|     from events.retention import cleanup_events_on_storage
   136|     cleanup_events_on_storage(
   137|         Event.objects.filter(pk__in=pks_to_delete).exclude(storage_backend=None)
   138|         .values_list("id", "storage_backend")
   139|     )
   140|     if is_for_project:
   141|         return
   142|     Project.objects.filter(id=project_id).update(stored_event_count=F('stored_event_count') - len(pks_to_delete))
   143| def delete_deps_with_budget(project_id, referring_model, fk_name, referred_ids, budget, dep_graph, is_for_project):
   144|     r"""
   145|     Deletes all objects of type referring_model that refer to any of the referred_ids via fk_name.
   146|     Returns the number of deleted objects.
   147|     And does this recursively (i.e. if there are further dependencies, it will delete those as well).
   148|         Caller              This Func
   149|           |                     |
   150|           V                     V
   151|      <unspecified>        referring_model
   152|              ^                  /
   153|              \-------fk_name----
   154|         referred_ids        relevant_ids (deduced using a query)
   155|     """
   156|     num_deleted = 0
   157|     relevant_ids = list(
   158|        referring_model.objects.filter(**{f"{fk_name}__in": referred_ids}).order_by(f"{fk_name}_id", 'pk').values(
   159|            *(('pk',) + fields_for_prune_orphans(referring_model))
   160|         )[:budget]
   161|     )
   162|     if not relevant_ids:
   163|         return 0
   164|     for_recursion = dep_graph.get(f"{referring_model._meta.app_label}.{referring_model.__name__}", [])
   165|     for model_for_recursion, fk_name_for_recursion in for_recursion:
   166|         num_deleted += delete_deps_with_budget(
   167|             project_id,
   168|             model_for_recursion,
   169|             fk_name_for_recursion,
   170|             [d["pk"] for d in relevant_ids],
   171|             budget - num_deleted,
   172|             dep_graph,
   173|             is_for_project,
   174|         )
   175|         if num_deleted >= budget:
   176|             return num_deleted
   177|     relevant_ids_after_rec = relevant_ids[:budget - num_deleted]
   178|     do_pre_delete(project_id, referring_model, [d['pk'] for d in relevant_ids_after_rec], is_for_project)
   179|     my_num_deleted, del_d = referring_model.objects.filter(pk__in=[d['pk'] for d in relevant_ids_after_rec]).delete()
   180|     num_deleted += my_num_deleted
   181|     assert set(del_d.keys()) == {referring_model._meta.label}  # assert no-cascading (we do that ourselves)
   182|     if is_for_project:
   183|         return num_deleted
   184|     prune_orphans(referring_model, relevant_ids_after_rec)
   185|     return num_deleted


# ====================================================================
# FILE: bugsink/wsgi.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-59 ---
     1| """
     2| WSGI config for bugsink project.
     3| It exposes the WSGI callable as a module-level variable named ``application``.
     4| For more information on this file, see
     5| https://docs.djangoproject.com/en/4.2/howto/deployment/wsgi/
     6| """
     7| import os
     8| import django
     9| from django.core.handlers.wsgi import WSGIHandler, WSGIRequest
    10| from django.core.exceptions import DisallowedHost
    11| os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'bugsink_conf')
    12| class CustomWSGIRequest(WSGIRequest):
    13|     """
    14|     Custom WSQIRequest subclass with 3 fixes/changes:
    15|     * Chunked Transfer Encoding (Django's behavior is broken)
    16|     * Skip ALLOWED_HOSTS validation for /health/ endpoints (see #140)
    17|     * Better error message for disallowed hosts
    18|     Note: used in all servers (in gunicorn through wsgi.py; in Django's runserver through WSGI_APPLICATION)
    19|     """
    20|     def __init__(self, environ):
    21|         """
    22|         We override this method to fix Django's behavior in the context of Chunked Transfer Encoding (Django's
    23|         behavior, behind Gunicorn, is broken). Django's breakage is in the super() of this method, in the combination
    24|         [1] defaulting (through a set-on-catch) to 0 for CONTENT_LENGTH when not present and [2] settings self._stream
    25|         to a LimitedStream with that length. The lines below undo this behavior iff the HTTP_TRANSFER_ENCODING header
    26|         is present. See:
    27|         * https://code.djangoproject.com/ticket/35838   (The Django problem)
    28|         * https://github.com/bugsink/bugsink/issues/9   (Why we need a fix)
    29|         """
    30|         super().__init__(environ)
    31|         if "CONTENT_LENGTH" not in environ and "HTTP_TRANSFER_ENCODING" in environ:
    32|             self._stream = self.environ["wsgi.input"]
    33|     def get_host(self):
    34|         """
    35|         We override this method to provide a more informative error message when the host is disallowed, i.e. we include
    36|         the current value of ALLOWED_HOSTS in the error message. That this is useful for debugging is self-evident.
    37|         We're leaking a bit of information here, but I don't think it's too much TBH -- especially in the light of ssl
    38|         certificates being specifically tied to the domain name.
    39|         """
    40|         from django.conf import settings
    41|         try:
    42|             return super().get_host()
    43|         except DisallowedHost as e:
    44|             if self.path.startswith == "/health/":
    45|                 return self._get_raw_host()
    46|             message = str(e)
    47|             if "ALLOWED_HOSTS" in message:
    48|                 allowed_hosts = settings.ALLOWED_HOSTS
    49|                 if settings.DEBUG and not allowed_hosts:
    50|                     allowed_hosts = [".localhost", "127.0.0.1", "[::1]"]
    51|                 message = message[:-1 * len(".")]
    52|                 message += ", which is currently set to %s." % repr(allowed_hosts)
    53|             raise DisallowedHost(message) from None
    54| class CustomWSGIHandler(WSGIHandler):
    55|     request_class = CustomWSGIRequest
    56| def custom_get_wsgi_application():
    57|     django.setup(set_prefix=False)
    58|     return CustomWSGIHandler()
    59| application = custom_get_wsgi_application()


# ====================================================================
# FILE: events/admin.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-87 ---
     1| import json
     2| from django.utils.html import escape, mark_safe
     3| from django.contrib import admin
     4| from django.views.decorators.csrf import csrf_protect
     5| from django.utils.decorators import method_decorator
     6| from bugsink.transaction import immediate_atomic
     7| from projects.admin import ProjectFilter
     8| from .models import Event
     9| csrf_protect_m = method_decorator(csrf_protect)
    10| @admin.register(Event)
    11| class EventAdmin(admin.ModelAdmin):
    12|     ordering = ['-timestamp']
    13|     search_fields = ['event_id', 'debug_info']
    14|     list_display = [
    15|         'timestamp',
    16|         'platform',
    17|         'level',
    18|         'sdk_name',
    19|         'sdk_version',
    20|         'debug_info',
    21|         'on_site',
    22|     ]
    23|     list_filter = [
    24|         ProjectFilter,
    25|         'platform',
    26|         'level',
    27|         'sdk_name',
    28|         'sdk_version',
    29|     ]
    30|     fields = [
    31|         'id',
    32|         'event_id',
    33|         'ingested_at',
    34|         'digested_at',
    35|         'calculated_type',
    36|         'calculated_value',
    37|         'issue',
    38|         'project',
    39|         'timestamp',
    40|         'platform',
    41|         'level',
    42|         'logger',
    43|         'transaction',
    44|         'server_name',
    45|         'release',
    46|         'dist',
    47|         'environment',
    48|         'sdk_name',
    49|         'sdk_version',
    50|         'debug_info',
    51|         'pretty_data',
    52|     ]
    53|     readonly_fields = [
    54|         'id',
    55|         'event_id',
    56|         'ingested_at',
    57|         'digested_at',
    58|         'calculated_type',
    59|         'calculated_value',
    60|         'issue',
    61|         'timestamp',
    62|         'project',
    63|         'pretty_data',
    64|     ]
    65|     def pretty_data(self, obj):
    66|         return mark_safe("<pre>" + escape(json.dumps(json.loads(obj.data), indent=2)) + "</pre>")
    67|     pretty_data.short_description = "Data"
    68|     def on_site(self, obj):
    69|         return mark_safe('<a href="' + escape(obj.get_absolute_url()) + '">View</a>')
    70|     def get_deleted_objects(self, objs, request):
    71|         to_delete = list(objs) + ["...all its related objects... (delayed)"]
    72|         model_count = {
    73|             Event: len(objs),
    74|         }
    75|         perms_needed = set()
    76|         protected = []
    77|         return to_delete, model_count, perms_needed, protected
    78|     def delete_queryset(self, request, queryset):
    79|         with immediate_atomic():
    80|             for obj in queryset:
    81|                 obj.delete_deferred()
    82|     def delete_model(self, request, obj):
    83|         with immediate_atomic():
    84|             obj.delete_deferred()
    85|     @csrf_protect_m
    86|     def delete_view(self, request, object_id, extra_context=None):
    87|         return self._delete_view(request, object_id, extra_context)


# ====================================================================
# FILE: events/factories.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-47 ---
     1| import json
     2| import uuid
     3| from django.utils import timezone
     4| from django.db.models import Max
     5| from issues.factories import get_or_create_issue
     6| from .models import Event
     7| def create_event(project=None, issue=None, timestamp=None, event_data=None):
     8|     if issue is None:
     9|         issue, _ = get_or_create_issue(project, event_data)
    10|     if project is None:
    11|         project = issue.project
    12|     if timestamp is None:
    13|         timestamp = timezone.now()
    14|     if event_data is None:
    15|         event_data = create_event_data()
    16|     max_current = Event.objects.filter(project=project).aggregate(
    17|         Max("digest_order"))["digest_order__max"]
    18|     issue_digest_order = max_current + 1 if max_current is not None else 1
    19|     grouping = issue.grouping_set.first()
    20|     return Event.objects.create(
    21|         project=project,
    22|         issue=issue,
    23|         grouping=grouping,
    24|         ingested_at=timestamp,
    25|         digested_at=timestamp,
    26|         timestamp=timestamp,
    27|         event_id=uuid.uuid4().hex,
    28|         data=json.dumps(event_data),
    29|         digest_order=issue_digest_order,
    30|         irrelevance_for_retention=0,
    31|     )
    32| def create_event_data(exception_type=None):
    33|     result = {
    34|         "event_id": uuid.uuid4().hex,
    35|         "timestamp": timezone.now().isoformat(),
    36|         "platform": "python",
    37|     }
    38|     if exception_type is not None:
    39|         result["exception"] = {
    40|             "values": [
    41|                 {
    42|                     "type": exception_type,
    43|                     "value": "This is a test exception",
    44|                 }
    45|             ]
    46|         }
    47|     return result


# ====================================================================
# FILE: events/management/commands/make_consistent.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-105 ---
     1| from django.core.management.base import BaseCommand
     2| from django.db.models import Count
     3| from releases.models import Release
     4| from issues.models import Issue, Grouping, TurningPoint
     5| from events.models import Event
     6| from projects.models import Project
     7| from tags.models import TagKey, TagValue, EventTag, IssueTag
     8| from bugsink.transaction import immediate_atomic
     9| from bugsink.timed_sqlite_backend.base import allow_long_running_queries
    10| from bugsink.moreiterutils import batched
    11| from projects.tasks import delete_project_deps
    12| from issues.tasks import delete_issue_deps
    13| class DryRunException(Exception):
    14|     pass
    15| def _delete_for_missing_fk(clazz, field_name):
    16|     """
    17|     Delete all objects of class clazz of which the field field_name points to a non-existing object or null.
    18|     Non-existing objects may come into being when people muddle in the database directly with foreign key checks turned
    19|     off (note that fk checks are turned off by default in sqlite's CLI for backwards compatibility reasons).
    20|     In the future it's further possible that there will be pieces the actual Bugsink code where FK-checks are turned off
    21|     temporarily (e.g. when deleting a project with very many related objects). (In March 2025 there was no such code
    22|     yet)
    23|     To make make_consistent() do what it says on the can, we need to delete these dangling objects.
    24|     """
    25|     BATCH_SIZE = 1_000
    26|     dangling_fks = set()
    27|     field = clazz._meta.get_field(field_name)
    28|     related_model = field.related_model
    29|     available_keys = set(related_model.objects.values_list('pk', flat=True))
    30|     for batch in batched(clazz.objects.values_list(field.get_attname(), flat=True).distinct(), BATCH_SIZE):
    31|         for key in batch:
    32|             if key not in available_keys:
    33|                 dangling_fks.add(key)
    34|     def _del(deletion_kwargs, msg_kind):
    35|         total_cnt, d_of_counts = clazz.objects.filter(**deletion_kwargs).delete()
    36|         count = d_of_counts.get(clazz._meta.label, 0)
    37|         if count == 0:
    38|             return
    39|         print("Deleted %d %ss, because their %s was %s" % (count, clazz.__name__, field_name, msg_kind))
    40|     _del({field.get_attname(): None}, "NULL")
    41|     for batch in batched(dangling_fks, BATCH_SIZE):
    42|         _del({field.get_attname() + '__in': batch}, "non-existing")
    43| def make_consistent():
    44|     for issue in Issue.objects.annotate(fresh_event_count=Count('event')).filter(fresh_event_count=0):
    45|         print("Deleting issue %s, because it has 0 events" % issue)
    46|         issue.delete()
    47|     _delete_for_missing_fk(Issue, 'project')
    48|     _delete_for_missing_fk(Grouping, 'project')
    49|     _delete_for_missing_fk(Grouping, 'issue')
    50|     _delete_for_missing_fk(TurningPoint, 'issue')
    51|     _delete_for_missing_fk(Release, 'project')
    52|     _delete_for_missing_fk(EventTag, 'issue')  # See #132 for the ordering of this statement
    53|     _delete_for_missing_fk(Event, 'project')
    54|     _delete_for_missing_fk(Event, 'issue')
    55|     _delete_for_missing_fk(IssueTag, 'project')
    56|     _delete_for_missing_fk(IssueTag, 'value')
    57|     _delete_for_missing_fk(IssueTag, 'issue')
    58|     _delete_for_missing_fk(EventTag, 'project')
    59|     _delete_for_missing_fk(EventTag, 'value')
    60|     _delete_for_missing_fk(EventTag, 'event')
    61|     _delete_for_missing_fk(TagValue, 'project')
    62|     _delete_for_missing_fk(TagValue, 'key')
    63|     _delete_for_missing_fk(TagKey, 'project')
    64|     for event in Event.objects.filter(turningpoint__isnull=False, never_evict=False).distinct():
    65|         print("Setting event %s to never_evict because it has a turningpoint" % event)
    66|         event.never_evict = True
    67|         event.save()
    68|     for issue in Issue.objects.all():
    69|         if issue.stored_event_count != issue.event_set.count():
    70|             print("Updating event count for issue %s from %d to %d" % (
    71|                 issue, issue.stored_event_count, issue.event_set.count()))
    72|             issue.stored_event_count = issue.event_set.count()
    73|             issue.save()
    74|     for project in Project.objects.all():
    75|         if project.stored_event_count != project.event_set.count():
    76|             print("Updating event count for project %s from %d to %d" % (
    77|                 project, project.stored_event_count, project.event_set.count()))
    78|             project.stored_event_count = project.event_set.count()
    79|             project.save()
    80|     for project in Project.objects.all():
    81|         if project.has_releases != project.release_set.exists():
    82|             print("Updating has_releases for project %s from %s to %s" % (
    83|                 project, project.has_releases, project.release_set.exists()))
    84|             project.has_releases = project.release_set.exists()
    85|             project.save()
    86| class Command(BaseCommand):
    87|     help = """Make the database consistent by deleting dangling objects (issues, events, etc) and updating counters."""
    88|     def add_arguments(self, parser):
    89|         parser.add_argument('--dry-run', action='store_true', help="Roll back all changes after making them.")
    90|     def handle(self, *args, **options):
    91|         allow_long_running_queries()
    92|         try:
    93|             with immediate_atomic():
    94|                 make_consistent()
    95|                 if options['dry_run']:
    96|                     raise DryRunException("Dry run requested; rolling back changes.")
    97|             if not options['dry_run']:
    98|                 for obj in Project.objects.filter(is_deleted=True):
    99|                     print("Enqueuing deletion of project dependencies for %s" % obj)
   100|                     delete_project_deps.delay(str(obj.pk))
   101|                 for obj in Issue.objects.filter(is_deleted=True):
   102|                     print("Enqueuing deletion of issue dependencies for %s" % obj)
   103|                     delete_issue_deps.delay(str(obj.project_id), str(obj.pk))
   104|         except DryRunException:
   105|             print("Changes have been rolled back (dry-run)")


# ====================================================================
# FILE: events/migrations/0020_remove_events_with_null_issue_or_grouping.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-13 ---
     1| from django.db import migrations
     2| def remove_events_with_null_fks(apps, schema_editor):
     3|     Event = apps.get_model("events", "Event")
     4|     Event.objects.filter(issue__isnull=True).delete()
     5|     Event.objects.filter(grouping__isnull=True).delete()
     6| class Migration(migrations.Migration):
     7|     dependencies = [
     8|         ("events", "0019_event_storage_backend"),
     9|         ("issues", "0020_remove_objects_with_null_issue"),
    10|     ]
    11|     operations = [
    12|         migrations.RunPython(remove_events_with_null_fks, reverse_code=migrations.RunPython.noop),
    13|     ]


# ====================================================================
# FILE: events/migrations/0021_alter_do_nothing.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-23 ---
     1| from django.db import migrations, models
     2| import django.db.models.deletion
     3| class Migration(migrations.Migration):
     4|     dependencies = [
     5|         ("issues", "0021_alter_do_nothing"),
     6|         ("events", "0020_remove_events_with_null_issue_or_grouping"),
     7|     ]
     8|     operations = [
     9|         migrations.AlterField(
    10|             model_name="event",
    11|             name="grouping",
    12|             field=models.ForeignKey(
    13|                 on_delete=django.db.models.deletion.DO_NOTHING, to="issues.grouping"
    14|             ),
    15|         ),
    16|         migrations.AlterField(
    17|             model_name="event",
    18|             name="issue",
    19|             field=models.ForeignKey(
    20|                 on_delete=django.db.models.deletion.DO_NOTHING, to="issues.issue"
    21|             ),
    22|         ),
    23|     ]


# ====================================================================
# FILE: events/migrations/0022_alter_event_project.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-16 ---
     1| from django.db import migrations, models
     2| import django.db.models.deletion
     3| class Migration(migrations.Migration):
     4|     dependencies = [
     5|         ("projects", "0014_alter_projectmembership_project"),
     6|         ("events", "0021_alter_do_nothing"),
     7|     ]
     8|     operations = [
     9|         migrations.AlterField(
    10|             model_name="event",
    11|             name="project",
    12|             field=models.ForeignKey(
    13|                 on_delete=django.db.models.deletion.DO_NOTHING, to="projects.project"
    14|             ),
    15|         ),
    16|     ]


# ====================================================================
# FILE: events/models.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-158 ---
     1| import re
     2| import json
     3| import uuid
     4| from django.db import models
     5| from django.db.utils import IntegrityError
     6| from django.utils.functional import cached_property
     7| from projects.models import Project
     8| from compat.timestamp import parse_timestamp
     9| from bugsink.transaction import delay_on_commit
    10| from issues.utils import get_title_for_exception_type_and_value
    11| from .retention import get_random_irrelevance
    12| from .storage_registry import get_write_storage, get_storage
    13| from .tasks import delete_event_deps
    14| class Platform(models.TextChoices):
    15|     AS3 = "as3"
    16|     C = "c"
    17|     CFML = "cfml"
    18|     COCOA = "cocoa"
    19|     CSHARP = "csharp"
    20|     ELIXIR = "elixir"
    21|     HASKELL = "haskell"
    22|     GO = "go"
    23|     GROOVY = "groovy"
    24|     JAVA = "java"
    25|     JAVASCRIPT = "javascript"
    26|     NATIVE = "native"
    27|     NODE = "node"
    28|     OBJC = "objc"
    29|     OTHER = "other"
    30|     PERL = "perl"
    31|     PHP = "php"
    32|     PYTHON = "python"
    33|     RUBY = "ruby"
    34| class Level(models.TextChoices):
    35|     FATAL = "fatal"
    36|     ERROR = "error"
    37|     WARNING = "warning"
    38|     INFO = "info"
    39|     DEBUG = "debug"
    40| def maybe_empty(s):
    41|     return "" if not s else s
    42| def write_to_storage(event_id, parsed_data):
    43|     """
    44|     event_id means event.id, i.e. the internal one. This saves us from thinking about the security implications of
    45|     using an externally provided ID across storage backends.
    46|     """
    47|     with get_write_storage().open(event_id, "w") as f:
    48|         json.dump(parsed_data, f)
    49| class Event(models.Model):
    50|     id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False, help_text="Bugsink-internal")
    51|     ingested_at = models.DateTimeField(blank=False, null=False)
    52|     digested_at = models.DateTimeField(db_index=True, blank=False, null=False)
    53|     issue = models.ForeignKey("issues.Issue", blank=False, null=False, on_delete=models.DO_NOTHING)
    54|     grouping = models.ForeignKey("issues.Grouping", blank=False, null=False, on_delete=models.DO_NOTHING)
    55|     event_id = models.UUIDField(primary_key=False, null=False, editable=False, help_text="As per the sent data")
    56|     project = models.ForeignKey(Project, blank=False, null=False, on_delete=models.DO_NOTHING)
    57|     data = models.TextField(blank=False, null=False)
    58|     timestamp = models.DateTimeField(db_index=True, blank=False, null=False)
    59|     platform = models.CharField(max_length=64, blank=False, null=False, choices=Platform.choices)
    60|     level = models.CharField(max_length=len("warning"), blank=True, null=False, choices=Level.choices)
    61|     logger = models.CharField(max_length=64, blank=True, null=False, default="")  # , db_index=True)
    62|     transaction = models.CharField(max_length=200, blank=True, null=False, default="")
    63|     server_name = models.CharField(max_length=255, blank=True, null=False, default="")
    64|     release = models.CharField(max_length=250, blank=True, null=False, default="")
    65|     dist = models.CharField(max_length=64, blank=True, null=False, default="")
    66|     environment = models.CharField(max_length=64, blank=True, null=False, default="")
    67|     sdk_name = models.CharField(max_length=255, blank=True, null=False, default="")
    68|     sdk_version = models.CharField(max_length=255, blank=True, null=False, default="")
    69|     debug_info = models.CharField(max_length=255, blank=True, null=False, default="")
    70|     calculated_type = models.CharField(max_length=128, blank=True, null=False, default="")
    71|     calculated_value = models.TextField(max_length=1024, blank=True, null=False, default="")
    72|     last_frame_filename = models.CharField(max_length=255, blank=True, null=False, default="")
    73|     last_frame_module = models.CharField(max_length=255, blank=True, null=False, default="")
    74|     last_frame_function = models.CharField(max_length=255, blank=True, null=False, default="")
    75|     digest_order = models.PositiveIntegerField(blank=False, null=False)
    76|     irrelevance_for_retention = models.PositiveIntegerField(blank=False, null=False)
    77|     never_evict = models.BooleanField(blank=False, null=False, default=False)
    78|     storage_backend = models.CharField(max_length=255, blank=True, null=True, default=None, editable=False)
    79|     class Meta:
    80|         unique_together = [
    81|             ("project", "event_id"),
    82|             ("issue", "digest_order"),
    83|         ]
    84|         indexes = [
    85|             models.Index(fields=["project", "never_evict", "digested_at", "irrelevance_for_retention"]),
    86|             models.Index(fields=["issue", "digested_at"]),
    87|         ]
    88|     def get_raw_data(self):
    89|         if self.storage_backend is None:
    90|             return self.data
    91|         storage = get_storage(self.storage_backend)
    92|         with storage.open(self.id, "r") as f:
    93|             return f.read()
    94|     def get_parsed_data(self):
    95|         if self.storage_backend is None:
    96|             return json.loads(self.data)
    97|         storage = get_storage(self.storage_backend)
    98|         with storage.open(self.id, "r") as f:
    99|             return json.load(f)
   100|     def get_absolute_url(self):
   101|         return f"/issues/issue/{ self.issue_id }/event/{ self.id }/"
   102|     def get_raw_link(self):
   103|         return "/events/event/%s/raw/" % self.id
   104|     def get_download_link(self):
   105|         return "/events/event/%s/download/" % self.id
   106|     def title(self):
   107|         return get_title_for_exception_type_and_value(self.calculated_type, self.calculated_value)
   108|     @classmethod
   109|     def from_ingested(cls, event_metadata, digested_at, digest_order, stored_event_count, issue, grouping, parsed_data,
   110|                       denormalized_fields):
   111|         irrelevance_for_retention = get_random_irrelevance(stored_event_count)
   112|         write_storage = get_write_storage()
   113|         try:
   114|             event = cls.objects.create(
   115|                 event_id=event_metadata["event_id"],  # the metadata is the envelope's event_id, which takes precedence
   116|                 project_id=event_metadata["project_id"],
   117|                 issue=issue,
   118|                 grouping=grouping,
   119|                 ingested_at=event_metadata["ingested_at"],
   120|                 digested_at=digested_at,
   121|                 data=json.dumps(parsed_data) if write_storage is None else "",
   122|                 storage_backend=None if write_storage is None else write_storage.name,
   123|                 timestamp=parse_timestamp(parsed_data["timestamp"]),
   124|                 platform=parsed_data["platform"][:64],
   125|                 level=maybe_empty(parsed_data.get("level", "")),
   126|                 logger=maybe_empty(parsed_data.get("logger", ""))[:64],
   127|                 server_name=maybe_empty(parsed_data.get("server_name", ""))[:255],
   128|                 release=maybe_empty(parsed_data.get("release", ""))[:250],
   129|                 dist=maybe_empty(parsed_data.get("dist", ""))[:64],
   130|                 environment=maybe_empty(parsed_data.get("environment", ""))[:64],
   131|                 sdk_name=maybe_empty(parsed_data.get("", {}).get("name", ""))[:255],
   132|                 sdk_version=maybe_empty(parsed_data.get("", {}).get("version", ""))[:255],
   133|                 debug_info=event_metadata["debug_info"][:255],
   134|                 digest_order=digest_order,
   135|                 irrelevance_for_retention=irrelevance_for_retention,
   136|                 **denormalized_fields,
   137|             )
   138|             created = True
   139|             if write_storage is not None:
   140|                 write_to_storage(event.id, parsed_data)
   141|             return event, created
   142|         except IntegrityError as e:
   143|             ignore_patterns = [
   144|                 r".*unique constraint failed.*events_event.*project_id.*events_event.*event_id",  # sqlite
   145|                 r".*duplicate entry.*for key.*events_event.events_event_project_id_event_id.*",  # mysql
   146|                 r".*duplicate key value violates unique constraint.*events_event_project_id_event_id.*",  # postgres
   147|             ]
   148|             if not any(re.match(p, str(e).lower()) for p in ignore_patterns):
   149|                 raise
   150|             return None, False
   151|     @cached_property
   152|     def get_tags(self):
   153|         return list(
   154|             self.tags.all().select_related("value", "value__key").order_by("value__key__key")
   155|         )
   156|     def delete_deferred(self):
   157|         """Schedules deletion of all related objects"""
   158|         delay_on_commit(delete_event_deps, str(self.project_id), str(self.id))


# ====================================================================
# FILE: events/retention.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-172 ---
     1| import logging
     2| from django.db.models import Q, Min, Max, Count
     3| from random import random
     4| from datetime import timezone, datetime
     5| from bugsink.moreiterutils import pairwise, map_N_until
     6| from performance.context_managers import time_and_query_count
     7| from .storage_registry import get_storage
     8| bugsink_logger = logging.getLogger("bugsink")
     9| performance_logger = logging.getLogger("bugsink.performance.retention")
    10| class EvictionCounts:
    11|     def __init__(self, total, per_issue):
    12|         self.total = total
    13|         self.per_issue = per_issue
    14|     def __add__(self, other):
    15|         return EvictionCounts(
    16|             self.total + other.total,
    17|             {k: self.per_issue.get(k, 0) + other.per_issue.get(k, 0)
    18|              for k in set(self.per_issue) | set(other.per_issue)})
    19|     def __repr__(self):
    20|         return f"EvictionCounts(total={self.total})"
    21| def get_epoch(datetime_obj):
    22|     assert datetime_obj.tzinfo == timezone.utc
    23|     return int(datetime_obj.timestamp() / 3600)
    24| def datetime_for_epoch(epoch):
    25|     return datetime.fromtimestamp(epoch * 3600, timezone.utc)
    26| def get_epoch_bounds(lower, upper=None):
    27|     if lower is None and upper is None:
    28|         return Q()
    29|     if lower is None:
    30|         return Q(digested_at__lt=datetime_for_epoch(upper))
    31|     if upper is None:
    32|         return Q(digested_at__gte=datetime_for_epoch(lower))
    33|     return Q(digested_at__gte=datetime_for_epoch(lower), digested_at__lt=datetime_for_epoch(upper))
    34| def nonzero_leading_bits(n):
    35|     """
    36|     Return the non-roundness of a number when represented in binary, i.e. the number of leading bits until the last 1.
    37|     examples:
    38|     100000 -> 1
    39|     101000 -> 3
    40|     110001 -> 6
    41|     """
    42|     s = format(n, 'b')
    43|     return len(s.rstrip('0'))
    44| def get_random_irrelevance(stored_event_count):
    45|     """
    46|     gets a fixed-at-creation irrelevance-score for an Event; the basic idea is: the more events you have for a certain
    47|     issue, the less relevant any new event will be _on average_; but when you have many events you will on average still
    48|     have more relevant events than if you have few events.
    49|     irrelevance is basically determined by `nonzero_leading_bits`; we add some randomization to avoid repeated outcomes
    50|     if `cnt` "hovers" around a certain value (which is likely to happen when there's repeated eviction/fill-up). 2 is
    51|     simply to correct for random() (which returns .5 on average).
    52|     """
    53|     assert stored_event_count >= 1
    54|     return nonzero_leading_bits(round(random() * stored_event_count * 2))
    55| def should_evict(project, timestamp, stored_event_count):
    56|     if stored_event_count > project.retention_max_event_count:  # > because: do something when _over_ the max
    57|         return True
    58|     return False
    59| def get_age_for_irrelevance(age_based_irrelevance):
    60|     return pow(4, age_based_irrelevance) - 1
    61| def get_epoch_bounds_with_irrelevance(project, current_timestamp, qs_kwargs={"never_evict": False}):
    62|     """Returns the epoch bounds for the project (newest first), with the age-based irrelevance for each epoch."""
    63|     from .models import Event
    64|     oldest = Event.objects.filter(project=project, **qs_kwargs).aggregate(val=Min('digested_at'))['val']
    65|     first_epoch = get_epoch(oldest) if oldest is not None else get_epoch(current_timestamp)
    66|     current_epoch = get_epoch(current_timestamp)
    67|     difference = current_epoch - first_epoch
    68|     ages = list(map_N_until(get_age_for_irrelevance, difference))  # e.g. [0, 3, 15]
    69|     epochs = [current_epoch - age for age in ages]  # e.g. [100, 97, 85]
    70|     swapped_bounds = pairwise([None] + epochs + [None])  # e.g. [(None, 100), (100, 97), (97, 85), (85, None)]
    71|     bounds = [(older, newer) for (newer, older) in swapped_bounds]  # e.g [(100, None), (97, 100), ...]
    72|     return [((lb, ub), age_based_irrelevance) for (age_based_irrelevance, (lb, ub)) in enumerate(bounds)]
    73| def get_irrelevance_pairs(project, epoch_bounds_with_irrelevance, qs_kwargs={"never_evict": False}):
    74|     """tuples of `age_based_irrelevance` and, per associated period, the max observed (evictable) event irrelevance"""
    75|     from .models import Event
    76|     for (lower_bound, upper_bound), age_based_irrelevance in epoch_bounds_with_irrelevance:
    77|         d = Event.objects.filter(
    78|             get_epoch_bounds(lower_bound, upper_bound),
    79|             project=project,
    80|             **qs_kwargs,
    81|         ).aggregate(Max('irrelevance_for_retention'))
    82|         max_event_irrelevance = d["irrelevance_for_retention__max"] or 0
    83|         yield (age_based_irrelevance, max_event_irrelevance)
    84| def filter_for_work(epoch_bounds_with_irrelevance, pairs, max_total_irrelevance):
    85|     for pair, ebwi in zip(pairs, epoch_bounds_with_irrelevance):
    86|         if sum(pair) > max_total_irrelevance:  # > because only if it is strictly greater will anything be evicted.
    87|             yield ebwi
    88| def eviction_target(max_event_count, stored_event_count):
    89|     return min(
    90|                max(
    91|                    int(max_event_count * 0.05),
    92|                    stored_event_count - max_event_count,
    93|                ),
    94|                500,
    95|            )
    96| def evict_for_max_events(project, timestamp, stored_event_count, include_never_evict=False):
    97|     qs_kwargs = {} if include_never_evict else {"never_evict": False}
    98|     with time_and_query_count() as phase0:
    99|         epoch_bounds_with_irrelevance = get_epoch_bounds_with_irrelevance(project, timestamp, qs_kwargs)
   100|         pairs = list(get_irrelevance_pairs(project, epoch_bounds_with_irrelevance, qs_kwargs))
   101|         max_total_irrelevance = orig_max_total_irrelevance = max(sum(pair) for pair in pairs)
   102|     with time_and_query_count() as phase1:
   103|         evicted = EvictionCounts(0, {})
   104|         target = eviction_target(project.retention_max_event_count, stored_event_count)
   105|         while evicted.total < target:
   106|             max_total_irrelevance -= 1
   107|             epoch_bounds_with_irrelevance_with_possible_work = list(
   108|                 filter_for_work(epoch_bounds_with_irrelevance, pairs, max_total_irrelevance))
   109|             evicted += evict_for_irrelevance(
   110|                 project,
   111|                 max_total_irrelevance,
   112|                 epoch_bounds_with_irrelevance_with_possible_work,
   113|                 include_never_evict,
   114|                 target - evicted.total,
   115|             )
   116|             if evicted.total < target and max_total_irrelevance <= -1:
   117|                 if not include_never_evict:
   118|                     return evicted + evict_for_max_events(project, timestamp, stored_event_count - evicted.total, True)
   119|                 bugsink_logger.error(
   120|                     "Failed to evict enough events; %d < %d (max %d, stored %d)", evicted.total, target,
   121|                     project.retention_max_event_count, stored_event_count)
   122|                 break
   123|     performance_logger.info(
   124|         "%6.2fms EVICT; down to %d, max irr. from %d to %d in %dms+%dms and %d+%d queries",
   125|         phase0.took + phase1.took,
   126|         stored_event_count - evicted.total - 1,  # down to: -1, because the +1 happens post-eviction
   127|         orig_max_total_irrelevance, max_total_irrelevance, phase0.took, phase1.took, phase0.count, phase1.count)
   128|     return evicted
   129| def evict_for_irrelevance(
   130|         project, max_total_irrelevance, epoch_bounds_with_irrelevance, include_never_evict=False, max_event_count=0):
   131|     evicted = EvictionCounts(0, {})
   132|     for (_, epoch_ub_exclusive), irrelevance_for_age in epoch_bounds_with_irrelevance:
   133|         max_item_irrelevance = max_total_irrelevance - irrelevance_for_age
   134|         current_max = max_event_count - evicted.total
   135|         evicted += evict_for_epoch_and_irrelevance(
   136|             project, epoch_ub_exclusive, max_item_irrelevance, current_max, include_never_evict)
   137|         if max_item_irrelevance <= -1:
   138|             break
   139|         if evicted.total >= max_event_count:
   140|             break
   141|     return evicted
   142| def evict_for_epoch_and_irrelevance(project, max_epoch, max_irrelevance, max_event_count, include_never_evict):
   143|     from issues.models import TurningPoint
   144|     from .models import Event
   145|     from tags.models import EventTag
   146|     qs_kwargs = {} if include_never_evict else {"never_evict": False}
   147|     qs = Event.objects.filter(project=project, irrelevance_for_retention__gt=max_irrelevance, **qs_kwargs)
   148|     if max_epoch is not None:
   149|         qs = qs.filter(digested_at__lt=datetime_for_epoch(max_epoch))
   150|     if include_never_evict:
   151|         TurningPoint.objects.filter(triggering_event__in=qs).update(triggering_event=None)
   152|     pks_to_delete = list(qs.order_by("digest_order")[:max_event_count].values_list("pk", flat=True))
   153|     if len(pks_to_delete) > 0:
   154|         cleanup_events_on_storage(
   155|             Event.objects.filter(pk__in=pks_to_delete).exclude(storage_backend=None)
   156|             .values_list("id", "storage_backend")
   157|         )
   158|         deletions_per_issue = {
   159|             d['issue_id']: d['count'] for d in
   160|             Event.objects.filter(pk__in=pks_to_delete).values("issue_id").annotate(count=Count("issue_id"))}
   161|         EventTag.objects.filter(event_id__in=pks_to_delete).delete()
   162|         nr_of_deletions = Event.objects.filter(pk__in=pks_to_delete).delete()[1].get("events.Event", 0)
   163|     else:
   164|         nr_of_deletions = 0
   165|         deletions_per_issue = {}
   166|     return EvictionCounts(nr_of_deletions, deletions_per_issue)
   167| def cleanup_events_on_storage(todos):
   168|     for event_id, storage_backend in todos:
   169|         try:
   170|             get_storage(storage_backend).delete(event_id)
   171|         except Exception as e:
   172|             bugsink_logger.error("Error during cleanup of %s on %s: %s", event_id, storage_backend, e)


# ====================================================================
# FILE: events/tasks.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-31 ---
     1| from snappea.decorators import shared_task
     2| from bugsink.utils import get_model_topography, delete_deps_with_budget
     3| from bugsink.transaction import immediate_atomic, delay_on_commit
     4| @shared_task
     5| def delete_event_deps(project_id, event_id):
     6|     from .models import Event   # avoid circular import
     7|     with immediate_atomic():
     8|         budget = 500
     9|         num_deleted = 0
    10|         dep_graph = get_model_topography()
    11|         for model_for_recursion, fk_name_for_recursion in dep_graph["events.Event"]:
    12|             this_num_deleted = delete_deps_with_budget(
    13|                 project_id,
    14|                 model_for_recursion,
    15|                 fk_name_for_recursion,
    16|                 [event_id],
    17|                 budget - num_deleted,
    18|                 dep_graph,
    19|                 is_for_project=False,
    20|             )
    21|             num_deleted += this_num_deleted
    22|             if num_deleted >= budget:
    23|                 delay_on_commit(delete_event_deps, project_id, event_id)
    24|                 return
    25|         if budget - num_deleted <= 0:
    26|             delay_on_commit(delete_event_deps, project_id, event_id)
    27|         else:
    28|             issue = Event.objects.get(pk=event_id).issue
    29|             Event.objects.filter(pk=event_id).delete()
    30|             issue.stored_event_count -= 1
    31|             issue.save(update_fields=["stored_event_count"])


# ====================================================================
# FILE: ingest/views.py
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 1-20 ---
     1| import hashlib
     2| import os
     3| import logging
     4| import io
     5| from datetime import datetime, timezone
     6| import json
     7| import jsonschema
     8| import fastjsonschema
     9| from django.conf import settings
    10| from django.shortcuts import get_object_or_404
    11| from django.db.models import Max, F
    12| from django.views import View
    13| from django.core import exceptions
    14| from django.core.exceptions import ValidationError
    15| from django.http import HttpResponse, JsonResponse
    16| from django.views.decorators.csrf import csrf_exempt
    17| from django.utils.decorators import method_decorator
    18| from django.contrib.auth.decorators import user_passes_test
    19| from compat.auth import parse_auth_header_value
    20| from compat.dsn import get_sentry_key, build_dsn

# --- HUNK 2: Lines 289-328 ---
   289|             else DontStoreEnvelope(input_stream)
   290|         try:
   291|             return self._post2(request, input_stream, ingested_at, project_pk)
   292|         finally:
   293|             input_stream.store()
   294|     def _post2(self, request, input_stream, ingested_at, project_pk=None):
   295|         parser = StreamingEnvelopeParser(input_stream)
   296|         envelope_headers = parser.get_envelope_headers()
   297|         if "dsn" in envelope_headers:
   298|             project = self.get_project(project_pk, get_sentry_key(envelope_headers["dsn"]))
   299|         else:
   300|             project = self.get_project_for_request(project_pk, request)
   301|         if project.quota_exceeded_until is not None and ingested_at < project.quota_exceeded_until:
   302|             return HttpResponse(status=HTTP_429_TOO_MANY_REQUESTS)
   303|         def factory(item_headers):
   304|             if item_headers.get("type") == "event":
   305|                 if get_settings().DIGEST_IMMEDIATELY:
   306|                     return MaxDataWriter("MAX_EVENT_SIZE", io.BytesIO())
   307|                 if "event_id" not in envelope_headers:
   308|                     raise ParseError("event_id not found in envelope headers")
   309|                 filename = get_filename_for_event_id(envelope_headers["event_id"])
   310|                 os.makedirs(os.path.dirname(filename), exist_ok=True)
   311|                 return MaxDataWriter("MAX_EVENT_SIZE", open(filename, 'wb'))
   312|             return NullWriter()
   313|         for item_headers, event_output_stream in parser.get_items(factory):
   314|             try:
   315|                 if item_headers.get("type") != "event":
   316|                     logger.info("skipping non-event item: %s", item_headers.get("type"))
   317|                     if item_headers.get("type") == "transaction":
   318|                         logger.info("discarding the rest of the envelope")
   319|                         break
   320|                     continue
   321|                 self.process_event(ingested_at, envelope_headers["event_id"], event_output_stream, project, request)
   322|                 break  # From the spec of type=event: This Item may occur at most once per Envelope. once seen: done
   323|             finally:
   324|                 event_output_stream.close()
   325|         return HttpResponse()
   326| @user_passes_test(lambda u: u.is_superuser)
   327| def download_envelope(request, envelope_id=None):
   328|     envelope = get_object_or_404(Envelope, pk=envelope_id)


# ====================================================================
# FILE: issues/admin.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-91 ---
     1| from django.contrib import admin
     2| from bugsink.transaction import immediate_atomic
     3| from django.utils.decorators import method_decorator
     4| from django.views.decorators.csrf import csrf_protect
     5| from .models import Issue, Grouping, TurningPoint
     6| from .forms import IssueAdminForm
     7| csrf_protect_m = method_decorator(csrf_protect)
     8| class GroupingInline(admin.TabularInline):
     9|     model = Grouping
    10|     extra = 0
    11|     exclude = ['project']
    12|     readonly_fields = [
    13|         'grouping_key',
    14|     ]
    15| class TurningPointInline(admin.TabularInline):
    16|     model = TurningPoint
    17|     extra = 0
    18|     exclude = ['project']
    19|     fields = [
    20|         "kind",
    21|         "timestamp",
    22|         "user",
    23|         "triggering_event",
    24|         "metadata",
    25|         "comment",
    26|     ]
    27|     readonly_fields = [
    28|         "user",  # readonly because it avoid thinking about well-implemented select-boxes
    29|         "triggering_event",  # readonly because it avoid thinking about well-implemented select-boxes
    30|         "metadata",  # readonly to avoid a big textbox
    31|         "comment",  # readonly to avoid a big textbox
    32|     ]
    33| @admin.register(Issue)
    34| class IssueAdmin(admin.ModelAdmin):
    35|     form = IssueAdminForm
    36|     fields = [
    37|         'project',
    38|         'friendly_id',
    39|         'calculated_type',
    40|         'calculated_value',
    41|         'last_seen',
    42|         'first_seen',
    43|         'is_resolved',
    44|         'fixed_at',
    45|         'events_at',
    46|         'is_muted',
    47|         'unmute_on_volume_based_conditions',
    48|         'unmute_after',
    49|         'digested_event_count',
    50|         'stored_event_count',
    51|     ]
    52|     inlines = [
    53|         GroupingInline,
    54|         TurningPointInline,
    55|     ]
    56|     list_display = [
    57|         "title",
    58|         "project",
    59|         "digested_event_count",
    60|         "stored_event_count",
    61|     ]
    62|     list_filter = [
    63|         "project",
    64|     ]
    65|     exclude = ["events"]
    66|     readonly_fields = [
    67|         'project',
    68|         'friendly_id',
    69|         'calculated_type',
    70|         'calculated_value',
    71|         'digested_event_count',
    72|         'stored_event_count',
    73|     ]
    74|     def get_deleted_objects(self, objs, request):
    75|         to_delete = list(objs) + ["...all its related objects... (delayed)"]
    76|         model_count = {
    77|             Issue: len(objs),
    78|         }
    79|         perms_needed = set()
    80|         protected = []
    81|         return to_delete, model_count, perms_needed, protected
    82|     def delete_queryset(self, request, queryset):
    83|         with immediate_atomic():
    84|             for obj in queryset:
    85|                 obj.delete_deferred()
    86|     def delete_model(self, request, obj):
    87|         with immediate_atomic():
    88|             obj.delete_deferred()
    89|     @csrf_protect_m
    90|     def delete_view(self, request, object_id, extra_context=None):
    91|         return self._delete_view(request, object_id, extra_context)


# ====================================================================
# FILE: issues/factories.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-37 ---
     1| import hashlib
     2| from django.utils import timezone
     3| from projects.models import Project
     4| from .models import Issue, Grouping
     5| from .utils import get_issue_grouper_for_data
     6| def get_or_create_issue(project=None, event_data=None):
     7|     """create issue for testing purposes (code basically stolen from ingest/views.py)"""
     8|     if event_data is None:
     9|         from events.factories import create_event_data
    10|         event_data = create_event_data()
    11|     if project is None:
    12|         project = Project.objects.create(name="Test project")
    13|     grouping_key = get_issue_grouper_for_data(event_data)
    14|     if not Grouping.objects.filter(project=project, grouping_key=grouping_key).exists():
    15|         issue = Issue.objects.create(
    16|             project=project,
    17|             **denormalized_issue_fields(),
    18|         )
    19|         issue_created = True
    20|         grouping = Grouping.objects.create(
    21|             project=project,
    22|             grouping_key=grouping_key,
    23|             grouping_key_hash=hashlib.sha256(grouping_key.encode()).hexdigest(),
    24|             issue=issue,
    25|         )
    26|     else:
    27|         grouping = Grouping.objects.get(project=project, grouping_key=grouping_key)
    28|         issue = grouping.issue
    29|         issue_created = False
    30|     return issue, issue_created
    31| def denormalized_issue_fields():
    32|     """placeholder values for the "denormalized" (cached, calculated) fields on Issue for which there is no default"""
    33|     return {
    34|         "first_seen": timezone.now(),
    35|         "last_seen": timezone.now(),
    36|         "digested_event_count": 1,
    37|     }


# ====================================================================
# FILE: issues/migrations/0018_issue_is_deleted.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-12 ---
     1| from django.db import migrations, models
     2| class Migration(migrations.Migration):
     3|     dependencies = [
     4|         ("issues", "0017_issue_list_indexes_must_start_with_project"),
     5|     ]
     6|     operations = [
     7|         migrations.AddField(
     8|             model_name="issue",
     9|             name="is_deleted",
    10|             field=models.BooleanField(default=False),
    11|         ),
    12|     ]


# ====================================================================
# FILE: issues/migrations/0019_alter_grouping_grouping_key_hash.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-12 ---
     1| from django.db import migrations, models
     2| class Migration(migrations.Migration):
     3|     dependencies = [
     4|         ("issues", "0018_issue_is_deleted"),
     5|     ]
     6|     operations = [
     7|         migrations.AlterField(
     8|             model_name="grouping",
     9|             name="grouping_key_hash",
    10|             field=models.CharField(max_length=64, null=True),
    11|         ),
    12|     ]


# ====================================================================
# FILE: issues/migrations/0020_remove_objects_with_null_issue.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-13 ---
     1| from django.db import migrations
     2| def remove_objects_with_null_issue(apps, schema_editor):
     3|     Grouping = apps.get_model("issues", "Grouping")
     4|     TurningPoint = apps.get_model("issues", "TurningPoint")
     5|     Grouping.objects.filter(issue__isnull=True).delete()
     6|     TurningPoint.objects.filter(issue__isnull=True).delete()
     7| class Migration(migrations.Migration):
     8|     dependencies = [
     9|         ("issues", "0019_alter_grouping_grouping_key_hash"),
    10|     ]
    11|     operations = [
    12|         migrations.RunPython(remove_objects_with_null_issue, reverse_code=migrations.RunPython.noop),
    13|     ]


# ====================================================================
# FILE: issues/migrations/0021_alter_do_nothing.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-22 ---
     1| from django.db import migrations, models
     2| import django.db.models.deletion
     3| class Migration(migrations.Migration):
     4|     dependencies = [
     5|         ("issues", "0020_remove_objects_with_null_issue"),
     6|     ]
     7|     operations = [
     8|         migrations.AlterField(
     9|             model_name="grouping",
    10|             name="issue",
    11|             field=models.ForeignKey(
    12|                 on_delete=django.db.models.deletion.DO_NOTHING, to="issues.issue"
    13|             ),
    14|         ),
    15|         migrations.AlterField(
    16|             model_name="turningpoint",
    17|             name="issue",
    18|             field=models.ForeignKey(
    19|                 on_delete=django.db.models.deletion.DO_NOTHING, to="issues.issue"
    20|             ),
    21|         ),
    22|     ]


# ====================================================================
# FILE: issues/migrations/0022_turningpoint_project.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-18 ---
     1| from django.db import migrations, models
     2| import django.db.models.deletion
     3| class Migration(migrations.Migration):
     4|     dependencies = [
     5|         ("projects", "0012_project_is_deleted"),
     6|         ("issues", "0021_alter_do_nothing"),
     7|     ]
     8|     operations = [
     9|         migrations.AddField(
    10|             model_name="turningpoint",
    11|             name="project",
    12|             field=models.ForeignKey(
    13|                 null=True,
    14|                 on_delete=django.db.models.deletion.DO_NOTHING,
    15|                 to="projects.project",
    16|             ),
    17|         ),
    18|     ]


# ====================================================================
# FILE: issues/migrations/0023_turningpoint_set_project.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-13 ---
     1| from django.db import migrations
     2| def turningpoint_set_project(apps, schema_editor):
     3|     TurningPoint = apps.get_model("issues", "TurningPoint")
     4|     for turningpoint in TurningPoint.objects.all():
     5|         turningpoint.project = turningpoint.issue.project
     6|         turningpoint.save(update_fields=["project"])
     7| class Migration(migrations.Migration):
     8|     dependencies = [
     9|         ("issues", "0022_turningpoint_project"),
    10|     ]
    11|     operations = [
    12|         migrations.RunPython(turningpoint_set_project, migrations.RunPython.noop),
    13|     ]


# ====================================================================
# FILE: issues/migrations/0024_turningpoint_project_alter_not_null.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-16 ---
     1| from django.db import migrations, models
     2| import django.db.models.deletion
     3| class Migration(migrations.Migration):
     4|     dependencies = [
     5|         ("projects", "0012_project_is_deleted"),
     6|         ("issues", "0023_turningpoint_set_project"),
     7|     ]
     8|     operations = [
     9|         migrations.AlterField(
    10|             model_name="turningpoint",
    11|             name="project",
    12|             field=models.ForeignKey(
    13|                 on_delete=django.db.models.deletion.DO_NOTHING, to="projects.project"
    14|             ),
    15|         ),
    16|     ]


# ====================================================================
# FILE: issues/migrations/0025_alter_grouping_project_alter_issue_project.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-23 ---
     1| from django.db import migrations, models
     2| import django.db.models.deletion
     3| class Migration(migrations.Migration):
     4|     dependencies = [
     5|         ("projects", "0014_alter_projectmembership_project"),
     6|         ("issues", "0024_turningpoint_project_alter_not_null"),
     7|     ]
     8|     operations = [
     9|         migrations.AlterField(
    10|             model_name="grouping",
    11|             name="project",
    12|             field=models.ForeignKey(
    13|                 on_delete=django.db.models.deletion.DO_NOTHING, to="projects.project"
    14|             ),
    15|         ),
    16|         migrations.AlterField(
    17|             model_name="issue",
    18|             name="project",
    19|             field=models.ForeignKey(
    20|                 on_delete=django.db.models.deletion.DO_NOTHING, to="projects.project"
    21|             ),
    22|         ),
    23|     ]


# ====================================================================
# FILE: issues/models.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-324 ---
     1| import json
     2| import uuid
     3| from functools import partial
     4| from django.db import models, transaction
     5| from django.db.models import F, Value
     6| from django.db.models.functions import Concat
     7| from django.template.defaultfilters import date as default_date_filter
     8| from django.conf import settings
     9| from django.utils.functional import cached_property
    10| from bugsink.volume_based_condition import VolumeBasedCondition
    11| from bugsink.transaction import delay_on_commit
    12| from alerts.tasks import send_unmute_alert
    13| from compat.timestamp import parse_timestamp, format_timestamp
    14| from tags.models import IssueTag, TagValue
    15| from .utils import (
    16|     parse_lines, serialize_lines, filter_qs_for_fixed_at, exclude_qs_for_fixed_at,
    17|     get_title_for_exception_type_and_value)
    18| from .tasks import delete_issue_deps
    19| class IncongruentStateException(Exception):
    20|     pass
    21| class Issue(models.Model):
    22|     """
    23|     An Issue models a group of similar events. In particular: it models the result of both automatic (client-side and
    24|     server-side) and manual ("merge") grouping.
    25|     """
    26|     id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    27|     project = models.ForeignKey(
    28|         "projects.Project", blank=False, null=False, on_delete=models.DO_NOTHING)
    29|     is_deleted = models.BooleanField(default=False)
    30|     digest_order = models.PositiveIntegerField(blank=False, null=False)
    31|     last_seen = models.DateTimeField(blank=False, null=False)  # based on event.ingested_at
    32|     first_seen = models.DateTimeField(blank=False, null=False)  # based on event.ingested_at
    33|     digested_event_count = models.IntegerField(blank=False, null=False)
    34|     stored_event_count = models.IntegerField(blank=False, null=False, default=0, editable=False)
    35|     calculated_type = models.CharField(max_length=128, blank=True, null=False, default="")
    36|     calculated_value = models.TextField(max_length=1024, blank=True, null=False, default="")
    37|     transaction = models.CharField(max_length=200, blank=True, null=False, default="")
    38|     last_frame_filename = models.CharField(max_length=255, blank=True, null=False, default="")
    39|     last_frame_module = models.CharField(max_length=255, blank=True, null=False, default="")
    40|     last_frame_function = models.CharField(max_length=255, blank=True, null=False, default="")
    41|     is_resolved = models.BooleanField(default=False)
    42|     is_resolved_by_next_release = models.BooleanField(default=False)
    43|     fixed_at = models.TextField(blank=True, null=False, default='')  # line-separated list
    44|     events_at = models.TextField(blank=True, null=False, default='')  # line-separated list
    45|     is_muted = models.BooleanField(default=False)
    46|     unmute_on_volume_based_conditions = models.TextField(blank=False, null=False, default="[]")  # json string
    47|     unmute_after = models.DateTimeField(blank=True, null=True)
    48|     next_unmute_check = models.PositiveIntegerField(null=False, default=0)
    49|     def save(self, *args, **kwargs):
    50|         if self.digest_order is None:
    51|             max_current = self.digest_order = Issue.objects.filter(project=self.project).aggregate(
    52|                 models.Max("digest_order"))["digest_order__max"]
    53|             self.digest_order = max_current + 1 if max_current is not None else 1
    54|         super().save(*args, **kwargs)
    55|     def delete_deferred(self):
    56|         """Marks the issue as deleted, and schedules deletion of all related objects"""
    57|         self.is_deleted = True
    58|         self.save(update_fields=["is_deleted"])
    59|         self.grouping_set.all().update(grouping_key_hash=None)
    60|         delay_on_commit(delete_issue_deps, str(self.project_id), str(self.id))
    61|     def friendly_id(self):
    62|         return f"{ self.project.slug.upper() }-{ self.digest_order }"
    63|     def get_absolute_url(self):
    64|         return f"/issues/issue/{ self.id }/event/last/"
    65|     def title(self):
    66|         return get_title_for_exception_type_and_value(self.calculated_type, self.calculated_value)
    67|     def get_fixed_at(self):
    68|         return parse_lines(self.fixed_at)
    69|     def get_events_at(self):
    70|         return parse_lines(self.events_at)
    71|     def get_events_at_2(self):
    72|         return [e for e in self.get_events_at() if e != ""]
    73|     def add_fixed_at(self, release_version):
    74|         fixed_at = self.get_fixed_at()
    75|         if release_version not in fixed_at:
    76|             fixed_at.append(release_version)
    77|             self.fixed_at = serialize_lines(fixed_at)
    78|     def get_unmute_on_volume_based_conditions(self):
    79|         return [
    80|             VolumeBasedCondition.from_dict(vbc_s)
    81|             for vbc_s in json.loads(self.unmute_on_volume_based_conditions)
    82|         ]
    83|     def occurs_in_last_release(self):
    84|         latest_release = self.project.get_latest_release()
    85|         return latest_release.version in self.events_at
    86|     def turningpoint_set_all(self):
    87|         return self.turningpoint_set.all().select_related("user")
    88|     @cached_property
    89|     def tags_summary(self):
    90|         return self._get_issue_tags(4, "...")
    91|     @cached_property
    92|     def tags_all(self):
    93|         return self._get_issue_tags(25, "Other...")
    94|     def _get_issue_tags(self, other_cutoff, other_label):
    95|         result = []
    96|         if self.digested_event_count > other_cutoff:
    97|             base_qs = self.tags.filter(key__mostly_unique=False)
    98|         else:
    99|             base_qs = self.tags
   100|         ds = base_qs.values("key")\
   101|             .annotate(count_sum=models.Sum("count"))\
   102|             .distinct()\
   103|             .order_by("key__key")
   104|         for d in ds:
   105|             issue_tags = [
   106|                 issue_tag
   107|                 for issue_tag in
   108|                 (IssueTag.objects
   109|                  .filter(issue=self, key=d['key'])  # note: project is implied through issue
   110|                  .order_by("-count")
   111|                  .select_related("value", "key")[:other_cutoff + 1]  # +1 to see if we need to add "Other"
   112|                  )
   113|             ]
   114|             total_seen = d["count_sum"]
   115|             seen_till_now = 0
   116|             if len(issue_tags) > other_cutoff:
   117|                 issue_tags = issue_tags[:other_cutoff - 1]  # cut off one more to make room for "Other"
   118|             for i, issue_tag in enumerate(issue_tags):
   119|                 issue_tag.pct = int(issue_tag.count / total_seen * 100)
   120|                 seen_till_now += issue_tag.count
   121|             if seen_till_now < total_seen:
   122|                 issue_tags.append({
   123|                     "value": TagValue(value=other_label),
   124|                     "count": total_seen - seen_till_now,
   125|                     "pct": int((total_seen - seen_till_now) / total_seen * 100),
   126|                 })
   127|             result.append(issue_tags)
   128|         return result
   129|     class Meta:
   130|         unique_together = [
   131|             ("project", "digest_order"),
   132|         ]
   133|         indexes = [
   134|             models.Index(fields=["project", "is_resolved", "is_muted", "last_seen"], name="issue_list_open"),
   135|             models.Index(fields=["project", "is_muted", "last_seen"], name="issue_list_muted"),
   136|             models.Index(fields=["project", "is_resolved", "last_seen"], name="issue_list_resolved"),  # and unresolved
   137|             models.Index(fields=["project", "last_seen"], name="issue_list_all"),  # all
   138|         ]
   139| class Grouping(models.Model):
   140|     """
   141|     Grouping models the automatic part of Events should be grouped into Issues. In particular: an automatically
   142|     calculated grouping key (from the event data, with a key role for the SDK-side fingerprint).
   143|     They are separated out into a separate model to allow for manually merging (after the fact) multiple such groupings
   144|     into a single issue. (such manual merging is not yet implemented, but the data-model is already prepared for it)
   145|     """
   146|     project = models.ForeignKey(
   147|         "projects.Project", blank=False, null=False, on_delete=models.DO_NOTHING)
   148|     grouping_key = models.TextField(blank=False, null=False)
   149|     grouping_key_hash = models.CharField(max_length=64, blank=False, null=True)
   150|     issue = models.ForeignKey("Issue", blank=False, null=False, on_delete=models.DO_NOTHING)
   151|     def __str__(self):
   152|         return self.grouping_key
   153|     class Meta:
   154|         unique_together = [
   155|             ("project", "grouping_key_hash"),
   156|         ]
   157| def format_unmute_reason(unmute_metadata):
   158|     if "mute_until" in unmute_metadata:
   159|         d = unmute_metadata["mute_until"]
   160|         plural_s = "" if d["nr_of_periods"] == 1 else "s"
   161|         return f"More than { d['volume'] } events per { d['nr_of_periods'] } { d['period'] }{ plural_s } occurred, "\
   162|                f"unmuting the issue."
   163|     d = unmute_metadata["mute_for"]
   164|     formatted_date = default_date_filter(d['unmute_after'], 'j M G:i')
   165|     return f"An event was observed after the mute-deadline of { formatted_date } and the issue was unmuted."
   166| class IssueStateManager(object):
   167|     """basically: a namespace; with static methods that combine field-setting in a single place"""
   168|     @staticmethod
   169|     def resolve(issue):
   170|         issue.is_resolved = True
   171|         issue.add_fixed_at("")  # i.e. fixed in the no-release-info-available release
   172|         IssueStateManager.unmute(issue)
   173|     @staticmethod
   174|     def resolve_by_latest(issue):
   175|         issue.is_resolved = True
   176|         issue.add_fixed_at(issue.project.get_latest_release().version)
   177|         IssueStateManager.unmute(issue)  # as in IssueStateManager.resolve()
   178|     @staticmethod
   179|     def resolve_by_release(issue, release_version):
   180|         issue.is_resolved = True
   181|         issue.add_fixed_at(release_version)
   182|         IssueStateManager.unmute(issue)  # as in IssueStateManager.resolve()
   183|     @staticmethod
   184|     def resolve_by_next(issue):
   185|         issue.is_resolved = True
   186|         issue.is_resolved_by_next_release = True
   187|         IssueStateManager.unmute(issue)  # as in IssueStateManager.resolve()
   188|     @staticmethod
   189|     def reopen(issue):
   190|         issue.is_resolved = False
   191|         IssueStateManager.unmute(issue)
   192|     @staticmethod
   193|     def mute(issue, unmute_on_volume_based_conditions="[]", unmute_after=None):
   194|         if issue.is_resolved:
   195|             raise IncongruentStateException("Cannot mute a resolved issue")
   196|         issue.is_muted = True
   197|         issue.unmute_on_volume_based_conditions = unmute_on_volume_based_conditions
   198|         issue.next_unmute_check = 0
   199|         if unmute_after is not None:
   200|             issue.unmute_after = unmute_after
   201|     @staticmethod
   202|     def unmute(issue, triggering_event=None, unmute_metadata=None):
   203|         if issue.is_muted:
   204|             issue.is_muted = False
   205|             issue.unmute_on_volume_based_conditions = "[]"
   206|             issue.unmute_after = None
   207|             if triggering_event is not None:
   208|                 if issue.project.alert_on_unmute:
   209|                     transaction.on_commit(partial(
   210|                         send_unmute_alert.delay,
   211|                         str(issue.id), format_unmute_reason(unmute_metadata)))
   212|                 if unmute_metadata is not None and "mute_for" in unmute_metadata:
   213|                     unmute_metadata["mute_for"]["unmute_after"] = \
   214|                         format_timestamp(unmute_metadata["mute_for"]["unmute_after"])
   215|                 TurningPoint.objects.create(
   216|                     project_id=issue.project_id,
   217|                     issue=issue, triggering_event=triggering_event, timestamp=triggering_event.ingested_at,
   218|                     kind=TurningPointKind.UNMUTED, metadata=json.dumps(unmute_metadata))
   219|                 triggering_event.never_evict = True  # .save() will be called by the caller of this function
   220|     @staticmethod
   221|     def delete(issue):
   222|         issue.delete_deferred()
   223|     @staticmethod
   224|     def get_unmute_thresholds(issue):
   225|         unmute_vbcs = [
   226|             VolumeBasedCondition.from_dict(vbc_s)
   227|             for vbc_s in json.loads(issue.unmute_on_volume_based_conditions)
   228|         ]
   229|         return [(vbc.period, vbc.nr_of_periods, vbc.volume) for vbc in unmute_vbcs]
   230| class IssueQuerysetStateManager(object):
   231|     """
   232|     This is exaclty the same as IssueStateManager, but it works on querysets instead of single objects.
   233|     The reason we do this as a copy/pasta (and not by just passing a queryset with a single element) is twofold:
   234|     * the qs-approach is harder to comprehend; understanding can be aided by referring back to the simple approach
   235|     * performance: the qs-approach may take a few queries to deal with a whole set; but when working on a single object
   236|         a single .save() is enough.
   237|     """
   238|     def _resolve_at(issue_qs, release_version):
   239|         filter_qs_for_fixed_at(issue_qs, release_version).update(
   240|             is_resolved=True,
   241|         )
   242|         exclude_qs_for_fixed_at(issue_qs, "").update(
   243|             is_resolved=True,
   244|             fixed_at=Concat(F("fixed_at"), Value(release_version + "\n")),
   245|         )
   246|         issue_qs.update(
   247|             fixed_at=Concat(F("fixed_at"), Value(release_version + "\n")),
   248|         )
   249|     @staticmethod
   250|     def resolve(issue_qs):
   251|         IssueQuerysetStateManager._resolve_at(issue_qs, "")  # i.e. fixed in the no-release-info-available release
   252|         IssueQuerysetStateManager.unmute(issue_qs)
   253|     @staticmethod
   254|     def resolve_by_latest(issue_qs):
   255|         raise NotImplementedError("resolve_by_latest is not implemented - see comments above")
   256|     @staticmethod
   257|     def resolve_by_release(issue_qs, release_version):
   258|         IssueQuerysetStateManager._resolve_at(issue_qs, release_version)
   259|         IssueQuerysetStateManager.unmute(issue_qs)  # as in IssueQuerysetStateManager.resolve()
   260|     @staticmethod
   261|     def resolve_by_next(issue_qs):
   262|         issue_qs.update(
   263|             is_resolved=True,
   264|             is_resolved_by_next_release=True,
   265|         )
   266|         IssueQuerysetStateManager.unmute(issue_qs)  # as in IssueQuerysetStateManager.resolve()
   267|     @staticmethod
   268|     def reopen(issue_qs):
   269|         raise NotImplementedError("reopen is not implemented - see comments above")
   270|     @staticmethod
   271|     def mute(issue_qs, unmute_on_volume_based_conditions="[]", unmute_after=None):
   272|         if issue_qs.filter(is_resolved=True).exists():
   273|             raise IncongruentStateException("Cannot mute a resolved issue")
   274|         issue_qs.update(
   275|             is_muted=True,
   276|             unmute_on_volume_based_conditions=unmute_on_volume_based_conditions,
   277|             next_unmute_check=0,
   278|         )
   279|         if unmute_after is not None:
   280|             issue_qs.update(unmute_after=unmute_after)
   281|     @staticmethod
   282|     def unmute(issue_qs, triggering_event=None):
   283|         issue_qs.update(
   284|             is_muted=False,
   285|             unmute_on_volume_based_conditions="[]",
   286|             unmute_after=None,
   287|         )
   288|         assert triggering_event is None, "this method can only be called from the UI, i.e. user-not-event-triggered"
   289|         for issue in issue_qs:
   290|             IssueStateManager.unmute(issue, triggering_event)
   291|     @staticmethod
   292|     def delete(issue_qs):
   293|         for issue in issue_qs:
   294|             issue.delete_deferred()
   295| class TurningPointKind(models.IntegerChoices):
   296|     FIRST_SEEN = 1, "First seen"
   297|     RESOLVED = 2, "Resolved"
   298|     MUTED = 3, "Muted"
   299|     REGRESSED = 4, "Marked as regressed"
   300|     UNMUTED = 5, "Unmuted"
   301|     NEXT_MATERIALIZED = 10, "Release info added"
   302|     MANUAL_ANNOTATION = 100, "Manual annotation"
   303| class TurningPoint(models.Model):
   304|     """A TurningPoint models a point in time in the history of an issue."""
   305|     project = models.ForeignKey("projects.Project", blank=False, null=False, on_delete=models.DO_NOTHING)
   306|     issue = models.ForeignKey("Issue", blank=False, null=False, on_delete=models.DO_NOTHING)
   307|     triggering_event = models.ForeignKey("events.Event", blank=True, null=True, on_delete=models.DO_NOTHING)
   308|     user = models.ForeignKey(settings.AUTH_USER_MODEL, blank=True, null=True, on_delete=models.SET_NULL)
   309|     timestamp = models.DateTimeField(blank=False, null=False)  # this info is also in the event, but event is nullable
   310|     kind = models.IntegerField(blank=False, null=False, choices=TurningPointKind.choices)
   311|     metadata = models.TextField(blank=False, null=False, default="{}")  # json string
   312|     comment = models.TextField(blank=True, null=False, default="")
   313|     class Meta:
   314|         ordering = ["-timestamp", "-id"]
   315|         indexes = [
   316|             models.Index(fields=["timestamp"]),
   317|         ]
   318|     def parsed_metadata(self):
   319|         if not hasattr(self, "_parsed_metadata"):
   320|             self._parsed_metadata = json.loads(self.metadata)
   321|             if "mute_for" in self._parsed_metadata and "unmute_after" in self._parsed_metadata["mute_for"]:
   322|                 self._parsed_metadata["mute_for"]["unmute_after"] = \
   323|                     parse_timestamp(self._parsed_metadata["mute_for"]["unmute_after"])
   324|         return self._parsed_metadata


# ====================================================================
# FILE: issues/tasks.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-59 ---
     1| from snappea.decorators import shared_task
     2| from bugsink.utils import get_model_topography, delete_deps_with_budget
     3| from bugsink.transaction import immediate_atomic, delay_on_commit
     4| def get_model_topography_with_issue_override():
     5|     """
     6|     Returns the model topography with ordering adjusted to prefer deletions via .issue, when available.
     7|     This assumes that Issue is not only the root of the dependency graph, but also that if a model has an .issue
     8|     ForeignKey, deleting it via that path is sufficient, meaning we can safely avoid visiting the same model again
     9|     through other ForeignKey routes (e.g. Event.grouping or TurningPoint.triggering_event).
    10|     The preference is encoded via an explicit list of models, which are visited early and only via their .issue path.
    11|     """
    12|     from issues.models import TurningPoint, Grouping
    13|     from events.models import Event
    14|     from tags.models import IssueTag, EventTag
    15|     preferred = [
    16|         TurningPoint,  # above Event, to avoid deletions via .triggering_event
    17|         EventTag,      # above Event, to avoid deletions via .event
    18|         Event,         # above Grouping, to avoid deletions via .grouping
    19|         Grouping,
    20|         IssueTag,
    21|     ]
    22|     def as_preferred(lst):
    23|         """
    24|         Sorts the list of (model, fk_name) tuples such that the models are in the preferred order as indicated above,
    25|         and models which occur with another fk_name are pruned
    26|         """
    27|         return sorted(
    28|             [(model, fk_name) for model, fk_name in lst if fk_name == "issue" or model not in preferred],
    29|             key=lambda x: preferred.index(x[0]) if x[0] in preferred else len(preferred),
    30|         )
    31|     topo = get_model_topography()
    32|     for k, lst in topo.items():
    33|         topo[k] = as_preferred(lst)
    34|     return topo
    35| @shared_task
    36| def delete_issue_deps(project_id, issue_id):
    37|     from .models import Issue   # avoid circular import
    38|     with immediate_atomic():
    39|         budget = 500
    40|         num_deleted = 0
    41|         dep_graph = get_model_topography_with_issue_override()
    42|         for model_for_recursion, fk_name_for_recursion in dep_graph["issues.Issue"]:
    43|             this_num_deleted = delete_deps_with_budget(
    44|                 project_id,
    45|                 model_for_recursion,
    46|                 fk_name_for_recursion,
    47|                 [issue_id],
    48|                 budget - num_deleted,
    49|                 dep_graph,
    50|                 is_for_project=False,
    51|             )
    52|             num_deleted += this_num_deleted
    53|             if num_deleted >= budget:
    54|                 delay_on_commit(delete_issue_deps, project_id, issue_id)
    55|                 return
    56|         if budget - num_deleted <= 0:
    57|             delay_on_commit(delete_issue_deps, project_id, issue_id)
    58|         else:
    59|             Issue.objects.filter(pk=issue_id).delete()


# ====================================================================
# FILE: issues/urls.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-52 ---
     1| from django.urls import path, register_converter
     2| from .views import (
     3|     issue_list, issue_event_stacktrace, issue_event_details, issue_event_list, issue_history, issue_grouping,
     4|     issue_event_breadcrumbs, event_by_internal_id, history_comment_new, history_comment_edit, history_comment_delete,
     5|     issue_tags)
     6| def regex_converter(passed_regex):
     7|     class RegexConverter:
     8|         regex = passed_regex
     9|         def to_python(self, value):
    10|             return value
    11|         def to_url(self, value):
    12|             return value
    13|     return RegexConverter
    14| register_converter(regex_converter("(first|last)"), "first-last")
    15| register_converter(regex_converter("(prev|next)"), "prev-next")
    16| urlpatterns = [
    17|     path('<int:project_pk>/', issue_list, {"state_filter": "open"}, name="issue_list_open"),
    18|     path('<int:project_pk>/unresolved', issue_list, {"state_filter": "unresolved"}, name="issue_list_unresolved"),
    19|     path('<int:project_pk>/resolved/', issue_list, {"state_filter": "resolved"}, name="issue_list_resolved"),
    20|     path('<int:project_pk>/muted/', issue_list, {"state_filter": "muted"}, name="issue_list_muted"),
    21|     path('<int:project_pk>/all/', issue_list, {"state_filter": "all"}, name="issue_list_all"),
    22|     path('issue/<uuid:issue_pk>/event/<uuid:event_pk>/', issue_event_stacktrace, name="event_stacktrace"),
    23|     path('issue/<uuid:issue_pk>/event/<uuid:event_pk>/details/', issue_event_details, name="event_details"),
    24|     path('issue/<uuid:issue_pk>/event/<uuid:event_pk>/breadcrumbs/', issue_event_breadcrumbs, name="event_breadcrumbs"),
    25|     path('issue/<uuid:issue_pk>/event/<int:digest_order>/', issue_event_stacktrace, name="event_stacktrace"),
    26|     path('issue/<uuid:issue_pk>/event/<int:digest_order>/details/', issue_event_details, name="event_details"),
    27|     path('issue/<uuid:issue_pk>/event/<int:digest_order>/breadcrumbs/', issue_event_breadcrumbs,
    28|          name="event_breadcrumbs"),
    29|     path('issue/<uuid:issue_pk>/event/<int:digest_order>/', issue_event_stacktrace, name="event_stacktrace"),
    30|     path('issue/<uuid:issue_pk>/event/<int:digest_order>/details/', issue_event_details, name="event_details"),
    31|     path('issue/<uuid:issue_pk>/event/<int:digest_order>/breadcrumbs/', issue_event_breadcrumbs,
    32|          name="event_breadcrumbs"),
    33|     path('issue/<uuid:issue_pk>/event/<int:digest_order>/<prev-next:nav>/', issue_event_stacktrace,
    34|          name="event_stacktrace"),
    35|     path('issue/<uuid:issue_pk>/event/<int:digest_order>/<prev-next:nav>/details/', issue_event_details,
    36|          name="event_details"),
    37|     path('issue/<uuid:issue_pk>/event/<int:digest_order>/<prev-next:nav>/breadcrumbs/', issue_event_breadcrumbs,
    38|          name="event_breadcrumbs"),
    39|     path('issue/<uuid:issue_pk>/event/<first-last:nav>/', issue_event_stacktrace, name="event_stacktrace"),
    40|     path('issue/<uuid:issue_pk>/event/<first-last:nav>/details/', issue_event_details, name="event_details"),
    41|     path(
    42|         'issue/<uuid:issue_pk>/event/<first-last:nav>/breadcrumbs/', issue_event_breadcrumbs, name="event_breadcrumbs"),
    43|     path('issue/<uuid:issue_pk>/tags/', issue_tags),
    44|     path('issue/<uuid:issue_pk>/history/', issue_history),
    45|     path('issue/<uuid:issue_pk>/grouping/', issue_grouping),
    46|     path('issue/<uuid:issue_pk>/events/', issue_event_list),
    47|     path('event/<uuid:event_pk>/', event_by_internal_id, name="event_by_internal_id"),
    48|     path('issue/<uuid:issue_pk>/history/comment/', history_comment_new, name="history_comment_new"),
    49|     path('issue/<uuid:issue_pk>/history/comment/<int:comment_pk>/', history_comment_edit, name="history_comment_edit"),
    50|     path('issue/<uuid:issue_pk>/history/comment/<int:comment_pk>/delete/', history_comment_delete,
    51|          name="history_comment_delete"),
    52| ]


# ====================================================================
# FILE: issues/views.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-571 ---
     1| from collections import namedtuple
     2| import json
     3| import sentry_sdk
     4| import logging
     5| from django.db.models import Q
     6| from django.utils import timezone
     7| from django.shortcuts import render, get_object_or_404, redirect
     8| from django.http import HttpResponseRedirect, HttpResponseNotAllowed
     9| from django.utils.safestring import mark_safe
    10| from django.template.defaultfilters import date
    11| from django.urls import reverse
    12| from django.core.exceptions import PermissionDenied
    13| from django.http import Http404
    14| from django.core.paginator import Paginator, Page
    15| from django.db.utils import OperationalError
    16| from django.conf import settings
    17| from django.utils.functional import cached_property
    18| from sentry.utils.safe import get_path
    19| from sentry_sdk_extensions import capture_or_log_exception
    20| from bugsink.decorators import project_membership_required, issue_membership_required, atomic_for_request_method
    21| from bugsink.transaction import durable_atomic
    22| from bugsink.period_utils import add_periods_to_datetime
    23| from bugsink.timed_sqlite_backend.base import different_runtime_limit
    24| from events.models import Event
    25| from events.ua_stuff import get_contexts_enriched_with_ua
    26| from compat.timestamp import format_timestamp
    27| from projects.models import ProjectMembership
    28| from tags.search import search_issues, search_events, search_events_optimized
    29| from .models import Issue, IssueQuerysetStateManager, IssueStateManager, TurningPoint, TurningPointKind
    30| from .forms import CommentForm
    31| from .utils import get_values, get_main_exception
    32| from events.utils import annotate_with_meta, apply_sourcemaps
    33| logger = logging.getLogger("bugsink.issues")
    34| MuteOption = namedtuple("MuteOption", ["for_or_until", "period_name", "nr_of_periods", "gte_threshold"])
    35| GLOBAL_MUTE_OPTIONS = [
    36|     MuteOption("for", "day", 1, None),
    37|     MuteOption("for", "week", 1, None),
    38|     MuteOption("for", "month", 1, None),
    39|     MuteOption("for", "month", 3, None),
    40|     MuteOption("until", "hour", 1, 5),
    41|     MuteOption("until", "hour", 24, 5),
    42|     MuteOption("until", "hour", 24, 100),
    43| ]
    44| class EagerPaginator(Paginator):
    45|     def _get_page(self, *args, **kwargs):
    46|         object_list = args[0]
    47|         object_list = list(object_list)
    48|         return Page(object_list, *(args[1:]), **kwargs)
    49| class KnownCountPaginator(EagerPaginator):
    50|     """optimization: we know the total count of the queryset, so we can avoid a count() query"""
    51|     def __init__(self, *args, **kwargs):
    52|         self._count = kwargs.pop("count")
    53|         super().__init__(*args, **kwargs)
    54|     @property
    55|     def count(self):
    56|         return self._count
    57| class UncountablePage(Page):
    58|     """The Page subclass to be used with UncountablePaginator."""
    59|     @cached_property
    60|     def has_next(self):
    61|         return len(self.object_list) == self.paginator.per_page
    62|     @cached_property
    63|     def end_index(self):
    64|         return (self.paginator.per_page * (self.number - 1)) + len(self.object_list)
    65| class UncountablePaginator(EagerPaginator):
    66|     """optimization: counting is too expensive; to be used in a template w/o .count and .last"""
    67|     def __init__(self, *args, **kwargs):
    68|         super().__init__(*args, **kwargs)
    69|     def _get_page(self, *args, **kwargs):
    70|         object_list = args[0]
    71|         object_list = list(object_list)
    72|         return UncountablePage(object_list, *(args[1:]), **kwargs)
    73|     @property
    74|     def count(self):
    75|         return 1_000_000_000  # big enough to be bigger than what you can click through or store in the DB.
    76| def _request_repr(parsed_data):
    77|     if "request" not in parsed_data:
    78|         return ""
    79|     return parsed_data["request"].get("method", "") + " " + parsed_data["request"].get("url", "")
    80| def _is_valid_action(action, issue):
    81|     """We take the 'strict' approach of complaining even when the action is simply a no-op, because you're already in
    82|     the desired state."""
    83|     if action == "delete":
    84|         return True
    85|     if issue.is_resolved:
    86|         return False
    87|     if action.startswith("resolved_release:"):
    88|         release_version = action.split(":", 1)[1]
    89|         if release_version + "\n" in issue.events_at:
    90|             return False
    91|     elif action.startswith("mute"):
    92|         if issue.is_muted:
    93|             return False
    94|     elif action == "unmute":
    95|         if not issue.is_muted:
    96|             return False
    97|     return True
    98| def _q_for_invalid_for_action(action):
    99|     """returns a Q obj of issues for which the action is not valid."""
   100|     if action == "delete":
   101|         return Q(pk__in=[])
   102|     illegal_conditions = Q(is_resolved=True)  # any action is illegal on resolved issues (as per our current UI)
   103|     if action.startswith("resolved_release:"):
   104|         release_version = action.split(":", 1)[1]
   105|         illegal_conditions = illegal_conditions | Q(events_at__contains=release_version + "\n")
   106|     elif action.startswith("mute"):
   107|         illegal_conditions = illegal_conditions | Q(is_muted=True)
   108|     elif action == "unmute":
   109|         illegal_conditions = illegal_conditions | Q(is_muted=False)
   110|     return illegal_conditions
   111| def _make_history(issue_or_qs, action, user):
   112|     if action == "delete":
   113|         return  # we're about to delete the issue, so no history is needed (nor possible)
   114|     elif action == "resolve":
   115|         kind = TurningPointKind.RESOLVED
   116|     elif action.startswith("resolved"):
   117|         kind = TurningPointKind.RESOLVED
   118|     elif action.startswith("mute"):
   119|         kind = TurningPointKind.MUTED
   120|     elif action == "unmute":
   121|         kind = TurningPointKind.UNMUTED
   122|     else:
   123|         raise ValueError(f"unknown action: {action}")
   124|     if action.startswith("mute_for:"):
   125|         mute_for_params = action.split(":", 1)[1]
   126|         period_name, nr_of_periods, _ = mute_for_params.split(",")
   127|         unmute_after = add_periods_to_datetime(timezone.now(), int(nr_of_periods), period_name)
   128|         metadata = {"mute_for": {
   129|             "period_name": period_name, "nr_of_periods": int(nr_of_periods),
   130|             "unmute_after": format_timestamp(unmute_after)}}
   131|     elif action.startswith("mute_until:"):
   132|         mute_for_params = action.split(":", 1)[1]
   133|         period_name, nr_of_periods, gte_threshold = mute_for_params.split(",")
   134|         metadata = {"mute_until": {
   135|             "period_name": period_name, "nr_of_periods": int(nr_of_periods), "gte_threshold": gte_threshold}}
   136|     elif action == "mute":
   137|         metadata = {"mute_unconditionally": True}
   138|     elif action.startswith("resolved_release:"):
   139|         release_version = action.split(":", 1)[1]
   140|         metadata = {"resolved_release": release_version}
   141|     elif action == "resolved_next":
   142|         metadata = {"resolve_by_next": True}
   143|     elif action == "resolve":
   144|         metadata = {"resolved_unconditionally": True}
   145|     else:
   146|         metadata = {}
   147|     now = timezone.now()
   148|     if isinstance(issue_or_qs, Issue):
   149|         TurningPoint.objects.create(
   150|             project=issue_or_qs.project,
   151|             issue=issue_or_qs, kind=kind, user=user, metadata=json.dumps(metadata), timestamp=now)
   152|     else:
   153|         TurningPoint.objects.bulk_create([
   154|             TurningPoint(
   155|                 project_id=issue.project_id, issue=issue, kind=kind, user=user, metadata=json.dumps(metadata),
   156|                 timestamp=now)
   157|             for issue in issue_or_qs
   158|         ])
   159| def _apply_action(manager, issue_or_qs, action, user):
   160|     _make_history(issue_or_qs, action, user)
   161|     if action == "resolve":
   162|         manager.resolve(issue_or_qs)
   163|     elif action.startswith("resolved_release:"):
   164|         release_version = action.split(":", 1)[1]
   165|         manager.resolve_by_release(issue_or_qs, release_version)
   166|     elif action == "resolved_next":
   167|         manager.resolve_by_next(issue_or_qs)
   168|     elif action == "mute":
   169|         manager.mute(issue_or_qs)
   170|     elif action.startswith("mute_for:"):
   171|         mute_for_params = action.split(":", 1)[1]
   172|         period_name, nr_of_periods, _ = mute_for_params.split(",")
   173|         unmute_after = add_periods_to_datetime(timezone.now(), int(nr_of_periods), period_name)
   174|         manager.mute(issue_or_qs, unmute_after=unmute_after)
   175|     elif action.startswith("mute_until:"):
   176|         mute_for_params = action.split(":", 1)[1]
   177|         period_name, nr_of_periods, gte_threshold = mute_for_params.split(",")
   178|         manager.mute(issue_or_qs, unmute_on_volume_based_conditions=json.dumps([{
   179|             "period": period_name,
   180|             "nr_of_periods": int(nr_of_periods),
   181|             "volume": int(gte_threshold),
   182|         }]))
   183|     elif action == "unmute":
   184|         manager.unmute(issue_or_qs)
   185|     elif action == "delete":
   186|         manager.delete(issue_or_qs)
   187| def issue_list(request, project_pk, state_filter="open"):
   188|     project, unapplied_issue_ids = _issue_list_pt_1(request, project_pk=project_pk, state_filter=state_filter)
   189|     with durable_atomic():
   190|         return _issue_list_pt_2(request, project, state_filter, unapplied_issue_ids)
   191| @atomic_for_request_method
   192| @project_membership_required
   193| def _issue_list_pt_1(request, project, state_filter="open"):
   194|     if request.method == "POST":
   195|         issue_ids = request.POST.getlist('issue_ids[]')
   196|         issue_qs = Issue.objects.filter(pk__in=issue_ids)
   197|         illegal_conditions = _q_for_invalid_for_action(request.POST["action"])
   198|         unapplied_issue_ids = list(issue_qs.filter(illegal_conditions).values_list("id", flat=True))
   199|         _apply_action(
   200|             IssueQuerysetStateManager, issue_qs.exclude(illegal_conditions), request.POST["action"], request.user)
   201|     else:
   202|         unapplied_issue_ids = None
   203|     return project, unapplied_issue_ids
   204| def _issue_list_pt_2(request, project, state_filter, unapplied_issue_ids):
   205|     d_state_filter = {
   206|         "open": lambda qs: qs.filter(is_resolved=False, is_muted=False),
   207|         "unresolved": lambda qs: qs.filter(is_resolved=False),
   208|         "resolved": lambda qs: qs.filter(is_resolved=True),
   209|         "muted": lambda qs: qs.filter(is_muted=True),
   210|         "all": lambda qs: qs,
   211|     }
   212|     issue_list = d_state_filter[state_filter](
   213|         Issue.objects.filter(project=project, is_deleted=False)
   214|     ).order_by("-last_seen")
   215|     if request.GET.get("q"):
   216|         issue_list = search_issues(project, issue_list, request.GET["q"])
   217|     paginator = UncountablePaginator(issue_list, 250)
   218|     page_number = request.GET.get("page")
   219|     page_obj = paginator.get_page(page_number)
   220|     try:
   221|         member = ProjectMembership.objects.get(project=project, user=request.user)
   222|     except ProjectMembership.DoesNotExist:
   223|         member = None  # this can happen if the user is superuser (as per `project_membership_required` decorator)
   224|     return render(request, "issues/issue_list.html", {
   225|         "project": project,
   226|         "member": member,
   227|         "state_filter": state_filter,
   228|         "mute_options": GLOBAL_MUTE_OPTIONS,
   229|         "unapplied_issue_ids": unapplied_issue_ids,
   230|         "disable_resolve_buttons": state_filter in ("resolved"),
   231|         "disable_mute_buttons": state_filter in ("resolved", "muted"),
   232|         "disable_unmute_buttons": state_filter in ("resolved", "open"),
   233|         "q": request.GET.get("q", ""),
   234|         "page_obj": page_obj,
   235|     })
   236| def event_by_internal_id(request, event_pk):
   237|     event = get_object_or_404(Event, id=event_pk)
   238|     issue = event.issue
   239|     return redirect(issue_event_stacktrace, issue_pk=issue.pk, event_pk=event.pk)
   240| def _handle_post(request, issue):
   241|     if _is_valid_action(request.POST["action"], issue):
   242|         _apply_action(IssueStateManager, issue, request.POST["action"], request.user)
   243|         issue.save()
   244|     return HttpResponseRedirect(request.path_info)
   245| def _get_event(qs, issue, event_pk, digest_order, nav, bounds):
   246|     """
   247|     Returns the event using the "url lookup".
   248|     The passed qs is "something you can use to deduce digest_order (for next/prev)."
   249|     When a direct (non-nav) method is used, we do _not_ check against existence in qs; this is more performant, and it's
   250|     not clear that being pedantic in this case is actually more valuable from a UX perspective.
   251|     """
   252|     if nav is not None:
   253|         if nav not in ["first", "last", "prev", "next"]:
   254|             raise Http404("Cannot look up with '%s'" % nav)
   255|         if nav == "first":
   256|             digest_order = bounds[0]
   257|         elif nav == "last":
   258|             digest_order = bounds[1]
   259|         elif nav in ["prev", "next"]:
   260|             if digest_order is None:
   261|                 raise Http404("Cannot look up with '%s' without digest_order" % nav)
   262|             if nav == "prev":
   263|                 digest_order = qs.filter(digest_order__lt=digest_order).values_list("digest_order", flat=True)\
   264|                     .order_by("-digest_order").first()
   265|             elif nav == "next":
   266|                 digest_order = qs.filter(digest_order__gt=digest_order).values_list("digest_order", flat=True)\
   267|                     .order_by("digest_order").first()
   268|         if digest_order is None:
   269|             raise Event.DoesNotExist
   270|         return Event.objects.get(issue=issue, digest_order=digest_order)
   271|     elif event_pk is not None:
   272|         try:
   273|             return Event.objects.get(pk=event_pk)
   274|         except Event.DoesNotExist:
   275|             return Event.objects.get(event_id=event_pk)
   276|     elif digest_order is not None:
   277|         return Event.objects.get(digest_order=digest_order)
   278|     else:
   279|         raise Http404("Either event_pk, nav, or digest_order must be provided")
   280| def _event_count(request, issue, event_x_qs):
   281|     with different_runtime_limit(0.1):
   282|         try:
   283|             return event_x_qs.count() if request.GET.get("q") else issue.stored_event_count
   284|         except OperationalError as e:
   285|             if e.args[0] != "interrupted":
   286|                 raise
   287|             return "many"
   288| @atomic_for_request_method
   289| @issue_membership_required
   290| def issue_event_stacktrace(request, issue, event_pk=None, digest_order=None, nav=None):
   291|     if request.method == "POST":
   292|         return _handle_post(request, issue)
   293|     event_x_qs = search_events_optimized(issue.project, issue, request.GET.get("q", ""))
   294|     first_do, last_do = _first_last(event_x_qs)
   295|     try:
   296|         event = _get_event(event_x_qs, issue, event_pk, digest_order, nav, (first_do, last_do))
   297|     except Event.DoesNotExist:
   298|         return issue_event_404(request, issue, event_x_qs, "stacktrace", "event_stacktrace")
   299|     parsed_data = event.get_parsed_data()
   300|     exceptions = get_values(parsed_data["exception"]) if "exception" in parsed_data else None
   301|     try:
   302|         meta_values = get_values(parsed_data.get("_meta", {}).get("exception", {"values": {}}))
   303|         annotate_with_meta(exceptions, meta_values)
   304|     except Exception as e:
   305|         sentry_sdk.capture_exception(e)
   306|     try:
   307|         apply_sourcemaps(parsed_data)
   308|     except Exception as e:
   309|         if settings.DEBUG or settings.I_AM_RUNNING == "TEST":
   310|             raise
   311|         capture_or_log_exception(e, logger)
   312|     stack_of_plates = event.platform != "python"  # Python is the only platform that has chronological stacktraces
   313|     if exceptions is not None and len(exceptions) > 0:
   314|         if exceptions[-1].get('stacktrace') and exceptions[-1]['stacktrace'].get('frames'):
   315|             exceptions[-1]['stacktrace']['frames'][-1]['raise_point'] = True
   316|         if stack_of_plates:
   317|             exceptions = [e for e in reversed(exceptions)]
   318|             for exception in exceptions:
   319|                 if not exception.get('stacktrace'):
   320|                     continue
   321|                 exception['stacktrace']['frames'] = [f for f in reversed(exception['stacktrace']['frames'])]
   322|     return render(request, "issues/stacktrace.html", {
   323|         "tab": "stacktrace",
   324|         "this_view": "event_stacktrace",
   325|         "project": issue.project,
   326|         "issue": issue,
   327|         "event": event,
   328|         "is_event_page": True,
   329|         "parsed_data": parsed_data,
   330|         "request_repr": _request_repr(parsed_data),
   331|         "exceptions": exceptions,
   332|         "stack_of_plates": stack_of_plates,
   333|         "mute_options": GLOBAL_MUTE_OPTIONS,
   334|         "q": request.GET.get("q", ""),
   335|         "event_qs_count": _event_count(request, issue, event_x_qs) if request.GET.get("q") else None,
   336|         "has_prev": event.digest_order > first_do,
   337|         "has_next": event.digest_order < last_do,
   338|     })
   339| def issue_event_404(request, issue, event_x_qs, tab, this_view):
   340|     """If the Event is 404, but the issue is not, we can still show the issue page; we show a message for the event"""
   341|     return render(request, "issues/event_404.html", {
   342|         "tab": tab,
   343|         "this_view": this_view,
   344|         "project": issue.project,
   345|         "issue": issue,
   346|         "is_event_page": False,  # this variable is used to denote "we have event-related info", which we don't
   347|         "mute_options": GLOBAL_MUTE_OPTIONS,
   348|         "q": request.GET.get("q", ""),
   349|         "event_qs_count": _event_count(request, issue, event_x_qs),
   350|     })
   351| @atomic_for_request_method
   352| @issue_membership_required
   353| def issue_event_breadcrumbs(request, issue, event_pk=None, digest_order=None, nav=None):
   354|     if request.method == "POST":
   355|         return _handle_post(request, issue)
   356|     event_x_qs = search_events_optimized(issue.project, issue, request.GET.get("q", ""))
   357|     first_do, last_do = _first_last(event_x_qs)
   358|     try:
   359|         event = _get_event(event_x_qs, issue, event_pk, digest_order, nav, (first_do, last_do))
   360|     except Event.DoesNotExist:
   361|         return issue_event_404(request, issue, event_x_qs, "breadcrumbs", "event_breadcrumbs")
   362|     parsed_data = event.get_parsed_data()
   363|     return render(request, "issues/breadcrumbs.html", {
   364|         "tab": "breadcrumbs",
   365|         "this_view": "event_breadcrumbs",
   366|         "project": issue.project,
   367|         "issue": issue,
   368|         "event": event,
   369|         "is_event_page": True,
   370|         "request_repr": _request_repr(parsed_data),
   371|         "breadcrumbs": get_values(parsed_data.get("breadcrumbs")),
   372|         "mute_options": GLOBAL_MUTE_OPTIONS,
   373|         "q": request.GET.get("q", ""),
   374|         "event_qs_count": _event_count(request, issue, event_x_qs) if request.GET.get("q") else None,
   375|         "has_prev": event.digest_order > first_do,
   376|         "has_next": event.digest_order < last_do,
   377|     })
   378| def _date_with_milis_html(timestamp):
   379|     return mark_safe(
   380|         date(timestamp, "j M G:i:s") + "." +
   381|         '<span class="text-xs">' + date(timestamp, "u")[:3] + '</span>')
   382| def _first_last(qs_with_digest_order):
   383|     first = qs_with_digest_order.order_by("digest_order").values_list("digest_order", flat=True).first()
   384|     last = qs_with_digest_order.order_by("-digest_order").values_list("digest_order", flat=True).first()
   385|     return first, last
   386| @atomic_for_request_method
   387| @issue_membership_required
   388| def issue_event_details(request, issue, event_pk=None, digest_order=None, nav=None):
   389|     if request.method == "POST":
   390|         return _handle_post(request, issue)
   391|     event_x_qs = search_events_optimized(issue.project, issue, request.GET.get("q", ""))
   392|     first_do, last_do = _first_last(event_x_qs)
   393|     try:
   394|         event = _get_event(event_x_qs, issue, event_pk, digest_order, nav, (first_do, last_do))
   395|     except Event.DoesNotExist:
   396|         return issue_event_404(request, issue, event_x_qs, "event-details", "event_details")
   397|     parsed_data = event.get_parsed_data()
   398|     key_info = [
   399|         ("title", event.title()),
   400|         ("transaction", issue.transaction),
   401|         ("event_id", event.event_id),
   402|         ("bugsink_internal_id", event.id),
   403|     ]
   404|     if get_path(get_main_exception(parsed_data), "mechanism", "handled") is not None:
   405|         key_info += [
   406|             ("handled", get_path(get_main_exception(parsed_data), "mechanism", "handled")),
   407|         ]
   408|     key_info += [
   409|         ("mechanism", get_path(get_main_exception(parsed_data), "mechanism", "type")),
   410|         ("issue_id", issue.id),
   411|         ("timestamp", _date_with_milis_html(event.timestamp)),
   412|         ("ingested at", _date_with_milis_html(event.ingested_at)),
   413|         ("digested at", _date_with_milis_html(event.digested_at)),
   414|         ("digest order", event.digest_order),
   415|     ]
   416|     logentry_info = []
   417|     if parsed_data.get("logger") or parsed_data.get("logentry") or parsed_data.get("message"):
   418|         if "level" in parsed_data:
   419|             logentry_info.append(("level", parsed_data["level"]))
   420|         if parsed_data.get("logger"):
   421|             logentry_info.append(("logger", parsed_data["logger"]))
   422|         logentry_key = "logentry" if "logentry" in parsed_data else "message"
   423|         if isinstance(parsed_data.get(logentry_key), dict):
   424|             if parsed_data.get(logentry_key, {}).get("formatted"):
   425|                 logentry_info.append(("formatted", parsed_data[logentry_key]["formatted"]))
   426|             if parsed_data.get(logentry_key, {}).get("message"):
   427|                 logentry_info.append(("message", parsed_data[logentry_key]["message"]))
   428|             params = parsed_data.get(logentry_key, {}).get("params", {})
   429|             if isinstance(params, list):
   430|                 for param_i, param_v in enumerate(params):
   431|                     logentry_info.append(("#%s" % param_i, param_v))
   432|             elif isinstance(params, dict):
   433|                 for param_k, param_v in params.items():
   434|                     logentry_info.append((param_k, param_v))
   435|         elif isinstance(parsed_data.get(logentry_key), str):  # robust for top-level as str (see #55)
   436|             logentry_info.append(("message", parsed_data[logentry_key]))
   437|     key_info += [
   438|         ("grouping key", event.grouping.grouping_key),
   439|     ]
   440|     deployment_info = \
   441|         ([("release", parsed_data["release"])] if "release" in parsed_data else []) + \
   442|         ([("environment", parsed_data["environment"])] if "environment" in parsed_data else []) + \
   443|         ([("server_name", parsed_data["server_name"])] if "server_name" in parsed_data else [])
   444|     contexts = get_contexts_enriched_with_ua(parsed_data)
   445|     return render(request, "issues/event_details.html", {
   446|         "tab": "event-details",
   447|         "this_view": "event_details",
   448|         "project": issue.project,
   449|         "issue": issue,
   450|         "event": event,
   451|         "is_event_page": True,
   452|         "parsed_data": parsed_data,
   453|         "request_repr": _request_repr(parsed_data),
   454|         "key_info": key_info,
   455|         "logentry_info": logentry_info,
   456|         "deployment_info": deployment_info,
   457|         "contexts": contexts,
   458|         "mute_options": GLOBAL_MUTE_OPTIONS,
   459|         "q": request.GET.get("q", ""),
   460|         "event_qs_count": _event_count(request, issue, event_x_qs) if request.GET.get("q") else None,
   461|         "has_prev": event.digest_order > first_do,
   462|         "has_next": event.digest_order < last_do,
   463|     })
   464| @atomic_for_request_method
   465| @issue_membership_required
   466| def issue_history(request, issue):
   467|     if request.method == "POST":
   468|         return _handle_post(request, issue)
   469|     event_qs = search_events(issue.project, issue, request.GET.get("q", ""))
   470|     last_event = event_qs.order_by("digest_order").last()
   471|     return render(request, "issues/history.html", {
   472|         "tab": "history",
   473|         "project": issue.project,
   474|         "issue": issue,
   475|         "is_event_page": False,
   476|         "request_repr": _request_repr(last_event.get_parsed_data()) if last_event is not None else "",
   477|         "mute_options": GLOBAL_MUTE_OPTIONS,
   478|     })
   479| @atomic_for_request_method
   480| @issue_membership_required
   481| def issue_tags(request, issue):
   482|     if request.method == "POST":
   483|         return _handle_post(request, issue)
   484|     event_qs = search_events(issue.project, issue, request.GET.get("q", ""))
   485|     last_event = event_qs.order_by("digest_order").last()
   486|     return render(request, "issues/tags.html", {
   487|         "tab": "tags",
   488|         "project": issue.project,
   489|         "issue": issue,
   490|         "is_event_page": False,
   491|         "request_repr": _request_repr(last_event.get_parsed_data()) if last_event is not None else "",
   492|         "mute_options": GLOBAL_MUTE_OPTIONS,
   493|     })
   494| @atomic_for_request_method
   495| @issue_membership_required
   496| def issue_grouping(request, issue):
   497|     if request.method == "POST":
   498|         return _handle_post(request, issue)
   499|     event_qs = search_events(issue.project, issue, request.GET.get("q", ""))
   500|     last_event = event_qs.order_by("digest_order").last()
   501|     return render(request, "issues/grouping.html", {
   502|         "tab": "grouping",
   503|         "project": issue.project,
   504|         "issue": issue,
   505|         "is_event_page": False,
   506|         "request_repr": _request_repr(last_event.get_parsed_data()) if last_event is not None else "",
   507|         "mute_options": GLOBAL_MUTE_OPTIONS,
   508|     })
   509| @atomic_for_request_method
   510| @issue_membership_required
   511| def issue_event_list(request, issue):
   512|     if request.method == "POST":
   513|         return _handle_post(request, issue)
   514|     if "q" in request.GET:
   515|         event_list = search_events(issue.project, issue, request.GET["q"]).order_by("digest_order")
   516|         event_x_qs = search_events_optimized(issue.project, issue, request.GET.get("q", ""))
   517|         paginator = KnownCountPaginator(event_list, 250, count=event_x_qs.count())
   518|     else:
   519|         event_list = issue.event_set.order_by("digest_order")
   520|         paginator = KnownCountPaginator(event_list, 250, count=issue.stored_event_count)
   521|     page_number = request.GET.get("page")
   522|     page_obj = paginator.get_page(page_number)
   523|     last_event = event_list.last()
   524|     return render(request, "issues/event_list.html", {
   525|         "tab": "event-list",
   526|         "project": issue.project,
   527|         "issue": issue,
   528|         "event_list": event_list,
   529|         "is_event_page": False,
   530|         "request_repr": _request_repr(last_event.get_parsed_data()) if last_event is not None else "",
   531|         "mute_options": GLOBAL_MUTE_OPTIONS,
   532|         "q": request.GET.get("q", ""),
   533|         "page_obj": page_obj,
   534|     })
   535| @atomic_for_request_method
   536| @issue_membership_required
   537| def history_comment_new(request, issue):
   538|     if request.method == "POST":
   539|         form = CommentForm(request.POST)
   540|         assert form.is_valid()  # we have only a textfield with no validation properties; also: no html-side handling
   541|         if form.cleaned_data["comment"] != "":
   542|             TurningPoint.objects.create(
   543|                 project=issue.project,
   544|                 issue=issue, kind=TurningPointKind.MANUAL_ANNOTATION, user=request.user,
   545|                 comment=form.cleaned_data["comment"],
   546|                 timestamp=timezone.now())
   547|         return redirect(issue_history, issue_pk=issue.pk)
   548|     return HttpResponseNotAllowed(["POST"])
   549| @atomic_for_request_method
   550| @issue_membership_required
   551| def history_comment_edit(request, issue, comment_pk):
   552|     comment = get_object_or_404(TurningPoint, pk=comment_pk, issue_id=issue.pk)
   553|     if comment.user_id != request.user.id:
   554|         raise PermissionDenied("You can only edit your own comments")
   555|     if request.method == "POST":
   556|         form = CommentForm(request.POST, instance=comment)
   557|         assert form.is_valid()
   558|         form.save()
   559|         return redirect(reverse(issue_history, kwargs={'issue_pk': issue.pk}) + f"#comment-{ comment_pk }")
   560| @atomic_for_request_method
   561| @issue_membership_required
   562| def history_comment_delete(request, issue, comment_pk):
   563|     comment = get_object_or_404(TurningPoint, pk=comment_pk, issue_id=issue.pk)
   564|     if comment.user_id != request.user.id:
   565|         raise PermissionDenied("You can only delete your own comments")
   566|     if comment.kind != TurningPointKind.MANUAL_ANNOTATION:
   567|         raise PermissionDenied("You can only delete manual annotations")
   568|     if request.method == "POST":
   569|         comment.delete()
   570|         return redirect(reverse(issue_history, kwargs={'issue_pk': issue.pk}))
   571|     return HttpResponseNotAllowed(["POST"])


# ====================================================================
# FILE: projects/admin.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-72 ---
     1| from django.contrib import admin
     2| from django.utils.decorators import method_decorator
     3| from django.views.decorators.csrf import csrf_protect
     4| from admin_auto_filters.filters import AutocompleteFilter
     5| from bugsink.transaction import immediate_atomic
     6| from .models import Project, ProjectMembership
     7| csrf_protect_m = method_decorator(csrf_protect)
     8| class ProjectFilter(AutocompleteFilter):
     9|     title = 'Project'
    10|     field_name = 'project'
    11| class UserFilter(AutocompleteFilter):
    12|     title = 'User'
    13|     field_name = 'user'
    14| class ProjectMembershipInline(admin.TabularInline):
    15|     model = ProjectMembership
    16|     autocomplete_fields = [
    17|         'user',
    18|     ]
    19|     extra = 0
    20| @admin.register(Project)
    21| class ProjectAdmin(admin.ModelAdmin):
    22|     search_fields = [
    23|         'name',
    24|     ]
    25|     list_display = [
    26|         'name',
    27|         'dsn',
    28|         'digested_event_count',
    29|         'stored_event_count',
    30|     ]
    31|     readonly_fields = [
    32|         'dsn',
    33|     ]
    34|     inlines = [
    35|         ProjectMembershipInline,
    36|     ]
    37|     prepopulated_fields = {
    38|         'slug': ['name'],
    39|     }
    40|     def get_deleted_objects(self, objs, request):
    41|         to_delete = list(objs) + ["...all its related objects... (delayed)"]
    42|         model_count = {
    43|             Project: len(objs),
    44|         }
    45|         perms_needed = set()
    46|         protected = []
    47|         return to_delete, model_count, perms_needed, protected
    48|     def delete_queryset(self, request, queryset):
    49|         with immediate_atomic():
    50|             for obj in queryset:
    51|                 obj.delete_deferred()
    52|     def delete_model(self, request, obj):
    53|         with immediate_atomic():
    54|             obj.delete_deferred()
    55|     @csrf_protect_m
    56|     def delete_view(self, request, object_id, extra_context=None):
    57|         return self._delete_view(request, object_id, extra_context)
    58| @admin.register(ProjectMembership)
    59| class ProjectMembershipAdmin(admin.ModelAdmin):
    60|     list_filter = [
    61|         ProjectFilter,
    62|         UserFilter,
    63|     ]
    64|     list_display = [
    65|         'project',
    66|         'user',
    67|         'send_email_alerts',
    68|     ]
    69|     autocomplete_fields = [
    70|         'project',
    71|         'user',
    72|     ]


# ====================================================================
# FILE: projects/migrations/0012_project_is_deleted.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-12 ---
     1| from django.db import migrations, models
     2| class Migration(migrations.Migration):
     3|     dependencies = [
     4|         ("projects", "0011_fill_stored_event_count"),
     5|     ]
     6|     operations = [
     7|         migrations.AddField(
     8|             model_name="project",
     9|             name="is_deleted",
    10|             field=models.BooleanField(default=False),
    11|         ),
    12|     ]


# ====================================================================
# FILE: projects/migrations/0013_delete_objects_pointing_to_null_project.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-26 ---
     1| from django.db import migrations
     2| def delete_objects_pointing_to_null_project(apps, schema_editor):
     3|     preferred = [
     4|         'tags.EventTag',
     5|         'tags.IssueTag',
     6|         'tags.TagValue',
     7|         'tags.TagKey',
     8|         'events.Event',
     9|         'issues.Grouping',
    10|         'releases.Release',
    11|         'issues.Issue',
    12|     ]
    13|     for model_name in preferred:
    14|         model = apps.get_model(*model_name.split('.'))
    15|         model.objects.filter(project__isnull=True).delete()
    16| class Migration(migrations.Migration):
    17|     dependencies = [
    18|         ("projects", "0012_project_is_deleted"),
    19|         ("issues", "0024_turningpoint_project_alter_not_null"),
    20|         ("tags", "0004_alter_do_nothing"),
    21|         ("releases", "0002_release_releases_re_sort_ep_5c07c8_idx"),
    22|         ("events", "0021_alter_do_nothing"),
    23|     ]
    24|     operations = [
    25|         migrations.RunPython(delete_objects_pointing_to_null_project, reverse_code=migrations.RunPython.noop),
    26|     ]


# ====================================================================
# FILE: projects/migrations/0014_alter_projectmembership_project.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-15 ---
     1| from django.db import migrations, models
     2| import django.db.models.deletion
     3| class Migration(migrations.Migration):
     4|     dependencies = [
     5|         ("projects", "0013_delete_objects_pointing_to_null_project"),
     6|     ]
     7|     operations = [
     8|         migrations.AlterField(
     9|             model_name="projectmembership",
    10|             name="project",
    11|             field=models.ForeignKey(
    12|                 on_delete=django.db.models.deletion.DO_NOTHING, to="projects.project"
    13|             ),
    14|         ),
    15|     ]


# ====================================================================
# FILE: projects/models.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-88 ---
     1| import uuid
     2| from django.db import models
     3| from django.conf import settings
     4| from django.utils.text import slugify
     5| from bugsink.app_settings import get_settings
     6| from bugsink.transaction import delay_on_commit
     7| from compat.dsn import build_dsn
     8| from teams.models import TeamMembership
     9| from .tasks import delete_project_deps
    10| class ProjectRole(models.IntegerChoices):
    11|     MEMBER = 0
    12|     ADMIN = 1
    13| class ProjectVisibility(models.IntegerChoices):
    14|     JOINABLE = 1  # anyone can join
    15|     DISCOVERABLE = 10
    16|     TEAM_MEMBERS = 99
    17| class Project(models.Model):
    18|     team = models.ForeignKey("teams.Team", blank=False, null=True, on_delete=models.SET_NULL)
    19|     name = models.CharField(max_length=255, blank=False, null=False, unique=True)
    20|     slug = models.SlugField(max_length=50, blank=False, null=False, unique=True)
    21|     is_deleted = models.BooleanField(default=False)
    22|     sentry_key = models.UUIDField(editable=False, default=uuid.uuid4)
    23|     users = models.ManyToManyField(settings.AUTH_USER_MODEL, blank=True, through="ProjectMembership")
    24|     has_releases = models.BooleanField(editable=False, default=False)
    25|     digested_event_count = models.PositiveIntegerField(null=False, blank=False, default=0, editable=False)
    26|     stored_event_count = models.IntegerField(blank=False, null=False, default=0, editable=False)
    27|     alert_on_new_issue = models.BooleanField(default=True)
    28|     alert_on_regression = models.BooleanField(default=True)
    29|     alert_on_unmute = models.BooleanField(default=True)
    30|     visibility = models.IntegerField(
    31|         choices=ProjectVisibility.choices, default=ProjectVisibility.TEAM_MEMBERS,
    32|         help_text="Which users can see this project and its issues?")
    33|     quota_exceeded_until = models.DateTimeField(null=True, blank=True)
    34|     next_quota_check = models.PositiveIntegerField(null=False, default=0)
    35|     retention_max_event_count = models.PositiveIntegerField(default=10_000)
    36|     def __str__(self):
    37|         return self.name
    38|     def get_absolute_url(self):
    39|         return f"/issues/{ self.id }/"
    40|     @property
    41|     def dsn(self):
    42|         return build_dsn(str(get_settings().BASE_URL), self.id, self.sentry_key.hex)
    43|     def get_latest_release(self):
    44|         from releases.models import ordered_releases
    45|         if not hasattr(self, "_latest_release"):  # per-instance cache
    46|             self._latest_release = list(ordered_releases(project=self))[-1]
    47|         return self._latest_release
    48|     def save(self, *args, **kwargs):
    49|         if self.slug in [None, ""]:
    50|             base_slug = slugify(self.name)
    51|             similar_slugs = Project.objects.filter(slug__startswith=base_slug).values_list("slug", flat=True)
    52|             self.slug = base_slug
    53|             i = 0
    54|             while self.slug in similar_slugs:
    55|                 self.slug = f"{base_slug}-{i}"
    56|                 i += 1
    57|         super().save(*args, **kwargs)
    58|     def delete_deferred(self):
    59|         """Marks the project as deleted, and schedules deletion of all related objects"""
    60|         self.is_deleted = True
    61|         self.save(update_fields=["is_deleted"])
    62|         delay_on_commit(delete_project_deps, str(self.id))
    63|     def is_joinable(self, user=None):
    64|         if user is not None:
    65|             try:
    66|                 TeamMembership.objects.get(team=self.team, user=user)
    67|                 return True
    68|             except TeamMembership.DoesNotExist:
    69|                 pass
    70|         return self.visibility <= ProjectVisibility.JOINABLE
    71|     def is_discoverable(self):
    72|         return self.visibility <= ProjectVisibility.DISCOVERABLE
    73|     class Meta:
    74|         indexes = [
    75|             models.Index(fields=["name"]),
    76|         ]
    77| class ProjectMembership(models.Model):
    78|     project = models.ForeignKey(Project, on_delete=models.DO_NOTHING)
    79|     user = models.ForeignKey(settings.AUTH_USER_MODEL, on_delete=models.CASCADE)
    80|     send_email_alerts = models.BooleanField(default=None, null=True)
    81|     role = models.IntegerField(choices=ProjectRole.choices, default=ProjectRole.MEMBER)
    82|     accepted = models.BooleanField(default=False)
    83|     def __str__(self):
    84|         return f"{self.user} project membership of {self.project}"
    85|     class Meta:
    86|         unique_together = ("project", "user")
    87|     def is_admin(self):
    88|         return self.role == ProjectRole.ADMIN


# ====================================================================
# FILE: projects/tasks.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-106 ---
     1| from django.urls import reverse
     2| from snappea.decorators import shared_task
     3| from bugsink.app_settings import get_settings
     4| from bugsink.utils import send_rendered_email
     5| from bugsink.transaction import immediate_atomic, delay_on_commit
     6| from bugsink.utils import get_model_topography, delete_deps_with_budget
     7| @shared_task
     8| def send_project_invite_email_new_user(email, project_pk, token):
     9|     from .models import Project   # avoid circular import
    10|     project = Project.objects.get(pk=project_pk)
    11|     send_rendered_email(
    12|         subject='You have been invited to join "%s"' % project.name,
    13|         base_template_name="mails/project_membership_invite_new_user",
    14|         recipient_list=[email],
    15|         context={
    16|             "site_title": get_settings().SITE_TITLE,
    17|             "base_url": get_settings().BASE_URL + "/",
    18|             "project_name": project.name,
    19|             "url": get_settings().BASE_URL + reverse("project_members_accept_new_user", kwargs={
    20|                 "token": token,
    21|                 "project_pk": project_pk,
    22|             }),
    23|         },
    24|     )
    25| @shared_task
    26| def send_project_invite_email(email, project_pk):
    27|     from .models import Project   # avoid circular import
    28|     project = Project.objects.get(pk=project_pk)
    29|     send_rendered_email(
    30|         subject='You have been invited to join "%s"' % project.name,
    31|         base_template_name="mails/project_membership_invite",
    32|         recipient_list=[email],
    33|         context={
    34|             "site_title": get_settings().SITE_TITLE,
    35|             "base_url": get_settings().BASE_URL + "/",
    36|             "project_name": project.name,
    37|             "url": get_settings().BASE_URL + reverse("project_members_accept", kwargs={
    38|                 "project_pk": project_pk,
    39|             }),
    40|         },
    41|     )
    42| def get_model_topography_with_project_override():
    43|     """
    44|     Returns the model topography with ordering adjusted to prefer deletions via .project, when available.
    45|     This assumes that Project is not only the root of the dependency graph, but also that if a model has an .project
    46|     ForeignKey, deleting it via that path is sufficient, meaning we can safely avoid visiting the same model again
    47|     through other ForeignKey routes (e.g. any of the .issue paths).
    48|     The preference is encoded via an explicit list of models, which are visited early and only via their .project path.
    49|     """
    50|     from issues.models import Issue, TurningPoint, Grouping
    51|     from events.models import Event
    52|     from tags.models import IssueTag, EventTag, TagValue, TagKey
    53|     from alerts.models import MessagingServiceConfig
    54|     from releases.models import Release
    55|     from projects.models import ProjectMembership
    56|     preferred = [
    57|         EventTag,      # above Event, to avoid deletions via .event
    58|         IssueTag,
    59|         TagValue,
    60|         TagKey,
    61|         TurningPoint,  # above Event, to avoid deletions via .triggering_event
    62|         Event,         # above Grouping, to avoid deletions via .grouping
    63|         Grouping,
    64|         MessagingServiceConfig,
    65|         ProjectMembership,
    66|         Release,
    67|         Issue,         # at the bottom, most everything points to this, we'd rather delete those things via .project
    68|     ]
    69|     def as_preferred(lst):
    70|         """
    71|         Sorts the list of (model, fk_name) tuples such that the models are in the preferred order as indicated above,
    72|         and models which occur with another fk_name are pruned
    73|         """
    74|         return sorted(
    75|             [(model, fk_name) for model, fk_name in lst if fk_name == "project" or model not in preferred],
    76|             key=lambda x: preferred.index(x[0]) if x[0] in preferred else len(preferred),
    77|         )
    78|     topo = get_model_topography()
    79|     for k, lst in topo.items():
    80|         topo[k] = as_preferred(lst)
    81|     return topo
    82| @shared_task
    83| def delete_project_deps(project_id):
    84|     from .models import Project   # avoid circular import
    85|     with immediate_atomic():
    86|         budget = 500
    87|         num_deleted = 0
    88|         dep_graph = get_model_topography_with_project_override()
    89|         for model_for_recursion, fk_name_for_recursion in dep_graph["projects.Project"]:
    90|             this_num_deleted = delete_deps_with_budget(
    91|                 project_id,
    92|                 model_for_recursion,
    93|                 fk_name_for_recursion,
    94|                 [project_id],
    95|                 budget - num_deleted,
    96|                 dep_graph,
    97|                 is_for_project=True,
    98|             )
    99|             num_deleted += this_num_deleted
   100|             if num_deleted >= budget:
   101|                 delay_on_commit(delete_project_deps, project_id)
   102|                 return
   103|         if budget - num_deleted <= 0:
   104|             delay_on_commit(delete_project_deps, project_id)
   105|         else:
   106|             Project.objects.filter(pk=project_id).delete()


# ====================================================================
# FILE: projects/views.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-346 ---
     1| import json
     2| from datetime import timedelta
     3| from django.shortcuts import render
     4| from django.db import models
     5| from django.shortcuts import redirect
     6| from django.http import Http404, HttpResponseRedirect
     7| from django.core.exceptions import PermissionDenied
     8| from django.contrib.auth import get_user_model
     9| from django.contrib import messages
    10| from django.contrib.auth import logout
    11| from django.urls import reverse
    12| from django.utils import timezone
    13| from users.models import EmailVerification
    14| from teams.models import TeamMembership, Team, TeamRole
    15| from bugsink.app_settings import get_settings, CB_ANYBODY, CB_MEMBERS, CB_ADMINS
    16| from bugsink.decorators import login_exempt, atomic_for_request_method
    17| from alerts.models import MessagingServiceConfig
    18| from alerts.forms import MessagingServiceConfigForm
    19| from alerts.service_backends.slack import SlackConfigForm
    20| from .models import Project, ProjectMembership, ProjectRole, ProjectVisibility
    21| from .forms import ProjectMembershipForm, MyProjectMembershipForm, ProjectMemberInviteForm, ProjectForm
    22| from .tasks import send_project_invite_email, send_project_invite_email_new_user
    23| User = get_user_model()
    24| @atomic_for_request_method
    25| def project_list(request, ownership_filter=None):
    26|     my_memberships = ProjectMembership.objects.filter(user=request.user)
    27|     my_team_memberships = TeamMembership.objects.filter(user=request.user)
    28|     my_projects = Project.objects.filter(
    29|         projectmembership__in=my_memberships, is_deleted=False).order_by('name').distinct()
    30|     my_teams_projects = \
    31|         Project.objects \
    32|         .filter(team__teammembership__in=my_team_memberships, is_deleted=False) \
    33|         .exclude(projectmembership__in=my_memberships) \
    34|         .order_by('name').distinct()
    35|     if request.user.is_superuser:
    36|         other_projects = Project.objects \
    37|             .filter(is_deleted=False) \
    38|             .exclude(projectmembership__in=my_memberships) \
    39|             .exclude(team__teammembership__in=my_team_memberships) \
    40|             .order_by('name').distinct()
    41|     else:
    42|         other_projects = Project.objects \
    43|             .filter(is_deleted=False) \
    44|             .exclude(projectmembership__in=my_memberships) \
    45|             .exclude(team__teammembership__in=my_team_memberships) \
    46|             .exclude(visibility=ProjectVisibility.TEAM_MEMBERS) \
    47|             .order_by('name').distinct()
    48|     if ownership_filter is None:
    49|         if my_projects.exists():
    50|             return redirect('project_list_mine')
    51|         if my_teams_projects.exists():
    52|             return redirect('project_list_teams')
    53|         if other_projects.exists():
    54|             return redirect('project_list_other')
    55|         return redirect('project_list_mine')  # if nothing to show, might as well show your own
    56|     if request.method == 'POST':
    57|         full_action_str = request.POST.get('action')
    58|         action, project_pk = full_action_str.split(":", 1)
    59|         if action == "leave":
    60|             ProjectMembership.objects.filter(project=project_pk, user=request.user.id).delete()
    61|         elif action == "join":
    62|             project = Project.objects.get(id=project_pk)
    63|             if not project.is_joinable(user=request.user) and not request.user.is_superuser:
    64|                 raise PermissionDenied("This project is not joinable")
    65|             messages.success(request, 'You have joined the project "%s"' % project.name)
    66|             ProjectMembership.objects.create(
    67|                 project_id=project_pk, user_id=request.user.id, role=ProjectRole.MEMBER, accepted=True)
    68|             return redirect('project_member_settings', project_pk=project_pk, user_pk=request.user.id)
    69|     if ownership_filter == "mine":
    70|         base_qs = my_projects
    71|     elif ownership_filter == "teams":
    72|         base_qs = my_teams_projects
    73|     elif ownership_filter == "other":
    74|         base_qs = other_projects
    75|     else:
    76|         raise ValueError(f"Invalid ownership_filter: {ownership_filter}")
    77|     project_list = base_qs.annotate(
    78|         member_count=models.Count(
    79|             'projectmembership', distinct=True, filter=models.Q(projectmembership__accepted=True)),
    80|     ).select_related('team')
    81|     if ownership_filter == "mine":
    82|         my_memberships_dict = {m.project_id: m for m in my_memberships}
    83|         project_list_2 = []
    84|         for project in project_list:
    85|             project.member = my_memberships_dict.get(project.id)
    86|             project_list_2.append(project)
    87|         project_list = project_list_2
    88|     return render(request, 'projects/project_list.html', {
    89|         'can_create':
    90|             request.user.is_superuser or TeamMembership.objects.filter(user=request.user, role=TeamRole.ADMIN).exists(),
    91|         'ownership_filter': ownership_filter,
    92|         'project_list': project_list,
    93|     })
    94| @atomic_for_request_method
    95| def project_new(request):
    96|     if not (request.user.is_superuser or TeamMembership.objects.filter(user=request.user,
    97|             role=TeamRole.ADMIN).exists()):
    98|         raise PermissionDenied("You need to be a team admin to create a project")
    99|     if get_settings().SINGLE_TEAM and Team.objects.count() == 0:
   100|         Team.objects.create(name="Single Team")
   101|     if request.user.is_superuser:
   102|         team_qs = Team.objects.all()
   103|     else:
   104|         my_admin_memberships = TeamMembership.objects.filter(user=request.user, role=TeamRole.ADMIN, accepted=True)
   105|         team_qs = Team.objects.filter(teammembership__in=my_admin_memberships).distinct()
   106|     if request.method == 'POST':
   107|         form = ProjectForm(request.POST, team_qs=team_qs)
   108|         if form.is_valid():
   109|             project = form.save()
   110|             ProjectMembership.objects.create(project=project, user=request.user, role=ProjectRole.ADMIN, accepted=True)
   111|             return redirect('project_sdk_setup', project_pk=project.id)
   112|     else:
   113|         form = ProjectForm(team_qs=team_qs)
   114|     return render(request, 'projects/project_new.html', {
   115|         'form': form,
   116|     })
   117| def _check_project_admin(project, user):
   118|     if not user.is_superuser and \
   119|        not ProjectMembership.objects.filter(
   120|             project=project, user=user, role=ProjectRole.ADMIN, accepted=True).exists() and \
   121|        not TeamMembership.objects.filter(team=project.team, user=user, role=TeamRole.ADMIN, accepted=True).exists():
   122|         raise PermissionDenied("You are not an admin of this project")
   123| @atomic_for_request_method
   124| def project_edit(request, project_pk):
   125|     project = Project.objects.get(id=project_pk, is_deleted=False)
   126|     _check_project_admin(project, request.user)
   127|     if request.method == 'POST':
   128|         action = request.POST.get('action')
   129|         if action == 'delete':
   130|             if (not request.user.is_superuser
   131|                 and not ProjectMembership.objects.filter(
   132|                     project=project, user=request.user, role=ProjectRole.ADMIN, accepted=True).exists()
   133|                 and not TeamMembership.objects.filter(
   134|                     team=project.team, user=request.user, role=TeamRole.ADMIN, accepted=True).exists()):
   135|                 raise PermissionDenied("Only project or team admins can delete projects")
   136|             project.delete_deferred()
   137|             messages.success(request, f'Project "{project.name}" has been deleted successfully.')
   138|             return redirect('project_list')
   139|         form = ProjectForm(request.POST, instance=project)
   140|         if form.is_valid():
   141|             form.save()
   142|             return redirect('project_members', project_pk=project.id)
   143|     else:
   144|         form = ProjectForm(instance=project)
   145|     return render(request, 'projects/project_edit.html', {
   146|         'project': project,
   147|         'form': form,
   148|     })
   149| @atomic_for_request_method
   150| def project_members(request, project_pk):
   151|     project = Project.objects.get(id=project_pk, is_deleted=False)
   152|     _check_project_admin(project, request.user)
   153|     if request.method == 'POST':
   154|         full_action_str = request.POST.get('action')
   155|         action, user_id = full_action_str.split(":", 1)
   156|         if action == "remove":
   157|             ProjectMembership.objects.filter(project=project_pk, user=user_id).delete()
   158|         elif action == "reinvite":
   159|             user = User.objects.get(id=user_id)
   160|             _send_project_invite_email(user, project_pk)
   161|             messages.success(request, f"Invitation resent to {user.email}")
   162|     return render(request, 'projects/project_members.html', {
   163|         'project': project,
   164|         'members': project.projectmembership_set.all().select_related('user'),
   165|     })
   166| def _send_project_invite_email(user, project_pk):
   167|     """Send an email to a user inviting them to a project; (for new users this includes the email-verification link)"""
   168|     if user.is_active:
   169|         send_project_invite_email.delay(user.email, project_pk)
   170|     else:
   171|         verification = EmailVerification.objects.create(user=user, email=user.username)
   172|         send_project_invite_email_new_user.delay(user.email, project_pk, verification.token)
   173| @atomic_for_request_method
   174| def project_members_invite(request, project_pk):
   175|     project = Project.objects.get(id=project_pk, is_deleted=False)
   176|     _check_project_admin(project, request.user)
   177|     if get_settings().USER_REGISTRATION in [CB_ANYBODY, CB_MEMBERS]:
   178|         user_must_exist = False
   179|     elif get_settings().USER_REGISTRATION == CB_ADMINS and request.user.is_superuser:
   180|         user_must_exist = False
   181|     else:
   182|         user_must_exist = True
   183|     if request.method == 'POST':
   184|         form = ProjectMemberInviteForm(user_must_exist, request.POST)
   185|         if form.is_valid():
   186|             email = form.cleaned_data['email']
   187|             user, user_created = User.objects.get_or_create(
   188|                 email=email, defaults={'username': email, 'is_active': False})
   189|             _send_project_invite_email(user, project_pk)
   190|             _, membership_created = ProjectMembership.objects.get_or_create(project=project, user=user, defaults={
   191|                 'role': form.cleaned_data['role'],
   192|                 'accepted': False,
   193|             })
   194|             if membership_created:
   195|                 messages.success(request, f"Invitation sent to {email}")
   196|             else:
   197|                 messages.success(
   198|                     request, f"Invitation resent to {email} (it was previously sent and we just sent it again)")
   199|             if request.POST.get('action') == "invite_and_add_another":
   200|                 return redirect('project_members_invite', project_pk=project_pk)
   201|             return redirect('project_members', project_pk=project_pk)
   202|     else:
   203|         form = ProjectMemberInviteForm(user_must_exist)
   204|     return render(request, 'projects/project_members_invite.html', {
   205|         'project': project,
   206|         'form': form,
   207|     })
   208| @atomic_for_request_method
   209| def project_member_settings(request, project_pk, user_pk):
   210|     try:
   211|         your_membership = ProjectMembership.objects.get(project=project_pk, user=request.user)
   212|     except ProjectMembership.DoesNotExist:
   213|         raise PermissionDenied("You are not a member of this project")
   214|     if not your_membership.accepted:
   215|         return redirect("project_members_accept", project_pk=project_pk)
   216|     this_is_you = str(user_pk) == str(request.user.id)
   217|     if not this_is_you:
   218|         _check_project_admin(Project.objects.get(id=project_pk, is_deleted=False), request.user)
   219|         membership = ProjectMembership.objects.get(project=project_pk, user=user_pk)
   220|         create_form = lambda data: ProjectMembershipForm(data, instance=membership)  # noqa
   221|     else:
   222|         edit_role = your_membership.role == ProjectRole.ADMIN or request.user.is_superuser
   223|         create_form = lambda data: MyProjectMembershipForm(data=data, instance=your_membership, edit_role=edit_role)  # noqa
   224|     if request.method == 'POST':
   225|         form = create_form(request.POST)
   226|         if form.is_valid():
   227|             form.save()
   228|             if this_is_you:
   229|                 return redirect('project_list')
   230|             return redirect('project_members', project_pk=project_pk)
   231|     else:
   232|         form = create_form(None)
   233|     return render(request, 'projects/project_member_settings.html', {
   234|         'this_is_you': this_is_you,
   235|         'user': User.objects.get(id=user_pk),
   236|         'project': Project.objects.get(id=project_pk, is_deleted=False),
   237|         'form': form,
   238|     })
   239| @atomic_for_request_method
   240| @login_exempt  # no login is required, the token is what identifies the user
   241| def project_members_accept_new_user(request, project_pk, token):
   242|     EmailVerification.objects.filter(
   243|         created_at__lt=timezone.now() - timedelta(get_settings().USER_REGISTRATION_VERIFY_EMAIL_EXPIRY)).delete()
   244|     try:
   245|         verification = EmailVerification.objects.get(token=token)
   246|     except EmailVerification.DoesNotExist:
   247|         raise Http404("Invalid or expired token")
   248|     user = verification.user
   249|     if not user.has_usable_password() or not user.is_active:
   250|         return HttpResponseRedirect(reverse("reset_password", kwargs={"token": token}) + "?next=" + reverse(
   251|             project_members_accept, kwargs={"project_pk": project_pk})
   252|         )
   253|     if request.user.is_authenticated and request.user != user:
   254|         logout(request)
   255|     verification.delete()
   256|     return redirect("project_members_accept", project_pk=project_pk)
   257| @atomic_for_request_method
   258| def project_members_accept(request, project_pk):
   259|     project = Project.objects.get(id=project_pk, is_deleted=False)
   260|     membership = ProjectMembership.objects.get(project=project, user=request.user)
   261|     if membership.accepted:
   262|         return redirect("project_member_settings", project_pk=project_pk, user_pk=request.user.id)
   263|     if request.method == 'POST':
   264|         if request.POST["action"] == "decline":
   265|             membership.delete()
   266|             return redirect("home")
   267|         if request.POST["action"] == "accept":
   268|             membership.accepted = True
   269|             membership.save()
   270|             return redirect("project_member_settings", project_pk=project_pk, user_pk=request.user.id)
   271|         raise Http404("Invalid action")
   272|     return render(request, "projects/project_members_accept.html", {"project": project, "membership": membership})
   273| @atomic_for_request_method
   274| def project_sdk_setup(request, project_pk, platform=""):
   275|     project = Project.objects.get(id=project_pk, is_deleted=False)
   276|     if not request.user.is_superuser and not ProjectMembership.objects.filter(project=project, user=request.user,
   277|                                                                               accepted=True).exists():
   278|         raise PermissionDenied("You are not a member of this project")
   279|     assert platform in ["", "python", "javascript", "php"]
   280|     template_name = "projects/project_sdk_setup%s.html" % ("_" + platform if platform else "")
   281|     return render(request, template_name, {
   282|         "project": project,
   283|         "dsn": project.dsn,
   284|     })
   285| @atomic_for_request_method
   286| def project_alerts_setup(request, project_pk):
   287|     project = Project.objects.get(id=project_pk, is_deleted=False)
   288|     _check_project_admin(project, request.user)
   289|     if request.method == 'POST':
   290|         full_action_str = request.POST.get('action')
   291|         action, service_id = full_action_str.split(":", 1)
   292|         if action == "remove":
   293|             MessagingServiceConfig.objects.filter(project=project_pk, id=service_id).delete()
   294|         elif action == "test":
   295|             service = MessagingServiceConfig.objects.get(project=project_pk, id=service_id)
   296|             service_backend = service.get_backend()
   297|             service_backend.send_test_message()
   298|             messages.success(
   299|                 request, "Test message sent; check the configured service to see if it arrived.")
   300|     return render(request, 'projects/project_alerts_setup.html', {
   301|         'project': project,
   302|         'service_configs': project.service_configs.all(),
   303|     })
   304| @atomic_for_request_method
   305| def project_messaging_service_add(request, project_pk):
   306|     project = Project.objects.get(id=project_pk, is_deleted=False)
   307|     _check_project_admin(project, request.user)
   308|     if request.method == 'POST':
   309|         form = MessagingServiceConfigForm(project, request.POST)
   310|         config_form = SlackConfigForm(data=request.POST)
   311|         if form.is_valid() and config_form.is_valid():
   312|             service = form.save(commit=False)
   313|             service.config = json.dumps(config_form.get_config())
   314|             service.save()
   315|             messages.success(request, "Messaging service added successfully.")
   316|             return redirect('project_alerts_setup', project_pk=project_pk)
   317|     else:
   318|         form = MessagingServiceConfigForm(project)
   319|         config_form = SlackConfigForm()
   320|     return render(request, 'projects/project_messaging_service_edit.html', {
   321|         'project': project,
   322|         'form': form,
   323|         'config_form': config_form,
   324|     })
   325| @atomic_for_request_method
   326| def project_messaging_service_edit(request, project_pk, service_pk):
   327|     project = Project.objects.get(id=project_pk, is_deleted=False)
   328|     _check_project_admin(project, request.user)
   329|     instance = project.service_configs.get(id=service_pk)
   330|     if request.method == 'POST':
   331|         form = MessagingServiceConfigForm(project, request.POST, instance=instance)
   332|         config_form = SlackConfigForm(data=request.POST)
   333|         if form.is_valid() and config_form.is_valid():
   334|             service = form.save(commit=False)
   335|             service.config = json.dumps(config_form.get_config())
   336|             service.save()
   337|             messages.success(request, "Messaging service updated successfully.")
   338|             return redirect('project_alerts_setup', project_pk=project_pk)
   339|     else:
   340|         form = MessagingServiceConfigForm(project, instance=instance)
   341|         config_form = SlackConfigForm(config=json.loads(instance.config))
   342|     return render(request, 'projects/project_messaging_service_edit.html', {
   343|         'project': project,
   344|         'form': form,
   345|         'config_form': config_form,
   346|     })


# ====================================================================
# FILE: releases/migrations/0003_alter_release_project.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-16 ---
     1| from django.db import migrations, models
     2| import django.db.models.deletion
     3| class Migration(migrations.Migration):
     4|     dependencies = [
     5|         ("projects", "0014_alter_projectmembership_project"),
     6|         ("releases", "0002_release_releases_re_sort_ep_5c07c8_idx"),
     7|     ]
     8|     operations = [
     9|         migrations.AlterField(
    10|             model_name="release",
    11|             name="project",
    12|             field=models.ForeignKey(
    13|                 on_delete=django.db.models.deletion.DO_NOTHING, to="projects.project"
    14|             ),
    15|         ),
    16|     ]


# ====================================================================
# FILE: releases/models.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-101 ---
     1| import json
     2| import re
     3| import uuid
     4| from semver.version import Version
     5| from django.db import models
     6| from django.utils import timezone
     7| from django.db.models.functions import Concat
     8| from django.db.models import Value
     9| from issues.models import Issue, TurningPoint, TurningPointKind
    10| RE_PACKAGE_VERSION = re.compile('((?P<package>.*)[@])?(?P<version>.*)')
    11| def is_valid_semver(full_version):
    12|     try:
    13|         version = RE_PACKAGE_VERSION.match(full_version).groupdict()["version"]
    14|         Version.parse(version)
    15|         return True
    16|     except ValueError:
    17|         return False
    18| def release_sort_key(release):
    19|     return (
    20|         release.sort_epoch,
    21|         Version.parse(release.semver) if release.is_semver else release.date_released
    22|     )
    23| def ordered_releases(*filter_args, **filter_kwargs):
    24|     """Sorting Release objects in code (as opposed to in-DB) to facilitate semver-based sorting when applicable"""
    25|     releases = Release.objects.filter(*filter_args, **filter_kwargs)
    26|     return sorted(releases, key=release_sort_key)
    27| class Release(models.Model):
    28|     id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    29|     project = models.ForeignKey("projects.Project", blank=False, null=False, on_delete=models.DO_NOTHING)
    30|     version = models.CharField(max_length=250, null=False, blank=False)
    31|     date_released = models.DateTimeField(default=timezone.now)
    32|     semver = models.CharField(max_length=255, null=False, editable=False)
    33|     is_semver = models.BooleanField(editable=False)
    34|     sort_epoch = models.IntegerField(editable=False)
    35|     def save(self, *args, **kwargs):
    36|         if self.is_semver is None:
    37|             self.is_semver = is_valid_semver(self.version)
    38|             if self.is_semver:
    39|                 self.semver = RE_PACKAGE_VERSION.match(self.version)["version"]
    40|             any_release_from_last_epoch = Release.objects.filter(project=self.project).order_by("sort_epoch").last()
    41|             if any_release_from_last_epoch is None:
    42|                 self.sort_epoch = 0
    43|             elif self.is_semver == any_release_from_last_epoch.is_semver:
    44|                 self.sort_epoch = any_release_from_last_epoch.sort_epoch
    45|             else:
    46|                 self.sort_epoch = any_release_from_last_epoch.sort_epoch + 1
    47|         super(Release, self).save(*args, **kwargs)
    48|     class Meta:
    49|         unique_together = ("project", "version")
    50|         indexes = [
    51|             models.Index(fields=["sort_epoch"]),
    52|         ]
    53|     def get_short_version(self):
    54|         if self.version == "":
    55|             return "no version"
    56|         if self.is_semver:
    57|             return self.version
    58|         return self.version[:12]
    59| def create_release_if_needed(project, version, event, issue=None):
    60|     if version is None:
    61|         raise ValueError('The None-like version must be the empty string')
    62|     version = sanitize_version(version)
    63|     release, release_created = Release.objects.get_or_create(project=project, version=version)
    64|     if release_created and version != "":
    65|         if not project.has_releases:
    66|             project.has_releases = True
    67|             project.save()
    68|         if release == project.get_latest_release():
    69|             resolved_by_next_qs = Issue.objects.filter(project=project, is_resolved_by_next_release=True)
    70|             TurningPoint.objects.bulk_create([TurningPoint(
    71|                     project=project,
    72|                     issue=issue, kind=TurningPointKind.NEXT_MATERIALIZED, triggering_event=event,
    73|                     metadata=json.dumps({"actual_release": release.version}), timestamp=event.ingested_at)
    74|                 for issue in resolved_by_next_qs
    75|             ])
    76|             event.never_evict = True  # .save() will be called by the caller of this function
    77|             resolved_by_next_qs.update(
    78|                 fixed_at=Concat("fixed_at", Value(release.version + "\n")),
    79|                 is_resolved_by_next_release=False,
    80|                 )
    81|             if issue is not None and issue.is_resolved_by_next_release:
    82|                 issue.fixed_at = issue.fixed_at + release.version + "\n"
    83|                 issue.is_resolved_by_next_release = False
    84|     return release
    85| def sanitize_version(version):
    86|     """
    87|     Implements the folllowing restrictions are from the Sentry documentation:
    88|     > There are a few restrictions -- the release name cannot:
    89|     >
    90|     > - contain newlines, tabulator characters, forward slashes(/), or back slashes(\\)
    91|     > - be (in their entirety) period (.), double period (..), or space ( )
    92|     > - exceed 200 characters
    93|     It does so as sanitize-dont-raise, i.e. it will return a sanitized version of the input string, but will not raise
    94|     an exception if the input string is invalid. Reason: we care about having valid data (and we rely e.g. on the lack
    95|     of newlines for our parsing), but we never want an invalid input to lead to discarded events. And there's no one
    96|     to 'read' a rejected event and fix it.
    97|     """
    98|     step_1 = version.replace("\n", "").replace("\t", "").replace("/", "").replace("\\", "")
    99|     step_2 = "sanitized" if step_1 in (".", "..", " ") else step_1
   100|     step_3 = step_2[:200]
   101|     return step_3


# ====================================================================
# FILE: snappea/foreman.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-219 ---
     1| import contextlib
     2| import os
     3| import glob
     4| import uuid
     5| import sys
     6| import json
     7| import logging
     8| import time
     9| import signal
    10| import threading
    11| from inotify_simple import INotify, flags
    12| import sentry_sdk
    13| from django.conf import settings
    14| from django.db import connections
    15| from sentry_sdk_extensions import capture_or_log_exception
    16| from performance.context_managers import time_to_logger
    17| from bugsink.transaction import durable_atomic, get_stat
    18| from . import registry
    19| from .models import Task
    20| from .datastructures import Workers
    21| from .settings import get_settings
    22| from .utils import run_task_context
    23| from .stats import Stats
    24| logger = logging.getLogger("snappea.foreman")
    25| performance_logger = logging.getLogger("bugsink.performance.snappea")
    26| def short_id(task_id):
    27|     return f"{task_id:06}"[-6:-3] + "-" + f"{task_id:06}"[-3:]
    28| class Foreman:
    29|     """
    30|     The Foreman starts workers, as (threading.Thread) threads, based on snappea.Task objects it finds in the sqlite
    31|     database for that purpose (we use the DB as a simple MQ, we call this DBasMQ).
    32|     The Foreman code itself is single-threaded, so it can be easily reasoned about.
    33|     We provide an at-most-once guarantee: Tasks that are picked up are removed from the DB before the works starts.
    34|     This fits with our model of background tasks, namely
    35|     * things that you want to happen
    36|     * but you don't want to wait for them in the request-response loop
    37|     * getting them done for sure is not more important than in the server itself (which is also subject to os.kill)
    38|     * you don't care about the answer as part of your code (of course, the DB can be affected)
    39|     The read/writes to the DB-as-MQ are as such:
    40|     * "some other process" (the HTTP server) writes _new_ Tasks
    41|     * the Foreman reads Tasks (determines the workload)
    42|     * the Foreman deletes (a write operation) Tasks (when done)
    43|     Because the Foreman has a single sequential loop, and because it is the only thing that _updates_ tasks, there is no
    44|     need for a locking model of some sort. sqlite locks the whole DB on-write, of course, but in this case we don't use
    45|     that as a feature. The throughput of our MQ is limited by the speed with which we can do writes to sqlite (2 writes
    46|     and at most 2 reads are needed per task (2 reads, because 1 to determine 'no more work'; when there are many items
    47|     at the same time, the average amount of reads may be <1 because we read a whole list)). Performance on personal
    48|     laptop: 1000 trivial tasks are finished enqueue-to-finished in a few seconds.
    49|     The main idea is this endless loop of checking for new work and doing it. This leaves the question of how we "go to
    50|     sleep" when there is no more work and how we wake up from that. This is implemented using inotify on a directory
    51|     created specifically for that purpose (for each Task a file is dropped there) (and a blocking read on the INotify
    52|     object). Note that this idea is somewhat incidental though (0MQ or polling the DB in a busy loop are some
    53|     alternatives). Performance: write/inotify/delete of a single wake-up call is in the order of n*e-5 on my laptop.
    54|     """
    55|     def __init__(self):
    56|         threading.current_thread().name = "FOREMAN"
    57|         self.settings = get_settings()
    58|         self.workers = Workers()
    59|         self.stats = Stats()
    60|         self.stopping = False
    61|         signal.signal(signal.SIGINT, self.handle_signal)
    62|         signal.signal(signal.SIGTERM, self.handle_signal)
    63|         if not os.path.exists(self.settings.WAKEUP_CALLS_DIR):
    64|             os.makedirs(self.settings.WAKEUP_CALLS_DIR, exist_ok=True)
    65|         self.wakeup_calls = INotify()
    66|         self.wakeup_calls.add_watch(self.settings.WAKEUP_CALLS_DIR, flags.CREATE)
    67|         pid = os.getpid()
    68|         logger.info(" =========  SNAPPEA  =========")
    69|         if self.settings.TASK_ALWAYS_EAGER:
    70|             logger.info("Startup: Can't run Foreman in TASK_ALWAYS_EAGER mode, EXIT")
    71|             sys.exit(1)
    72|         try:
    73|             if os.path.exists(self.settings.PID_FILE):
    74|                 with open(self.settings.PID_FILE, "r") as f:
    75|                     old_pid = int(f.read())
    76|                 if os.path.exists(f"/proc/{old_pid}"):
    77|                     logger.error("Startup: snappea is already running with pid %s, EXIT", old_pid)
    78|                     sys.exit(1)
    79|                 else:
    80|                     logger.warning("Startup: stale pid file found, removing %s", self.settings.PID_FILE)
    81|                     os.remove(self.settings.PID_FILE)
    82|         except Exception as e:
    83|             logger.error("Startup: Ignored Error while checking PID file", exc_info=e)
    84|         os.makedirs(os.path.dirname(self.settings.PID_FILE), exist_ok=True)
    85|         with open(self.settings.PID_FILE, "w") as f:
    86|             f.write(str(pid))
    87|         logger.info("Startup: pid is %s", pid)
    88|         logger.info("Startup: DB-as-MQ location: %s", settings.DATABASES["snappea"]["NAME"])
    89|         logger.info("Startup: Wake up calls location: %s", self.settings.WAKEUP_CALLS_DIR)
    90|         self.signal_semaphore = threading.Semaphore(0)
    91|         self.worker_semaphore = threading.Semaphore(self.settings.NUM_WORKERS)
    92|     def connection_close(self, using="default"):
    93|         connections[using].close()
    94|     def run_in_thread(self, task_id, function, *args, **kwargs):
    95|         task_name = "%s.%s" % (function.__module__, function.__name__)
    96|         logger.info('Starting %s for "%s" with %s, %s', short_id(task_id), task_name, args, kwargs)
    97|         def non_failing_function(*inner_args, **inner_kwargs):
    98|             t0 = time.time()
    99|             try:
   100|                 with run_task_context(inner_args, inner_kwargs):
   101|                     function(*inner_args, **inner_kwargs)
   102|             except Exception as e:
   103|                 errored = True  # at the top to avoid error-in-handler leaving us with unset variable
   104|                 if sentry_sdk.is_initialized():
   105|                     logger.warning("Snappea caught Exception: %s", str(e))
   106|                 capture_or_log_exception(e, logger)
   107|             else:
   108|                 errored = False
   109|             finally:
   110|                 for connection in connections.all():
   111|                     connection.close()
   112|                 runtime = time.time() - t0
   113|                 logger.info('Worker done for "%s" in %.3fs', task_name, runtime)
   114|                 self.stats.done(
   115|                     task_name, runtime, get_stat("get_write_lock"), get_stat("immediate_transaction"), errored)
   116|                 self.workers.stopped(task_id)
   117|                 self.worker_semaphore.release()
   118|         worker_thread = threading.Thread(
   119|             target=non_failing_function, args=args, kwargs=kwargs, name=f"{short_id(task_id)}")
   120|         worker_thread.daemon = True
   121|         self.workers.start(task_id, worker_thread)
   122|         return worker_thread
   123|     def handle_signal(self, sig, frame):
   124|         logger.debug("Received %s signal", signal.strsignal(sig))
   125|         if not self.stopping:  # without this if-statement, repeated signals would extend the deadline
   126|             self.stopping = True
   127|             self.stop_deadline = time.time() + self.settings.GRACEFUL_TIMEOUT
   128|         with open(os.path.join(self.settings.WAKEUP_CALLS_DIR, str(uuid.uuid4())), "w"):
   129|             pass
   130|         self.worker_semaphore.release()
   131|     def run_forever(self):
   132|         try:
   133|             self._run_forever()
   134|         except Exception:
   135|             logger.info("Stopping: CAUGHT exception in Foreman")
   136|             self.stop_deadline = time.time() + self.settings.GRACEFUL_TIMEOUT
   137|             self.stop()
   138|             logger.info("Stopping: EXCEPTION in Foreman")
   139|             raise
   140|     def _run_forever(self):
   141|         pre_existing_wakeup_notifications = glob.glob(os.path.join(self.settings.WAKEUP_CALLS_DIR, "*"))
   142|         if len(pre_existing_wakeup_notifications) > 0:
   143|             logger.info("Startup: Clearing %s items from wakeup dir", len(pre_existing_wakeup_notifications))
   144|             for filename in pre_existing_wakeup_notifications:
   145|                 os.remove(filename)
   146|         logger.info("Startup: Clearing Task backlog")
   147|         while self.create_workers() == self.settings.TASK_QS_LIMIT:
   148|             pass
   149|         logger.info("Startup: Task backlog empty now, proceeding to main loop")
   150|         while True:
   151|             logger.debug("Main loop: Waiting for wakeup call")
   152|             for event in self.wakeup_calls.read():
   153|                 logger.debug("Main loop: Removing wakeup notification %s", event.name)
   154|                 with contextlib.suppress(FileNotFoundError):
   155|                     os.unlink(os.path.join(self.settings.WAKEUP_CALLS_DIR, event.name))
   156|             self.check_for_stopping()  # check after .read() - it may have unblocked via handle_signal()
   157|             while self.create_workers() == self.settings.TASK_QS_LIMIT:
   158|                 pass  # `== TASK_QS_LIMIT`: as documented above
   159|             self.check_for_stopping()
   160|     def create_workers(self):
   161|         """returns the number of workers created (AKA tasks done)"""
   162|         logger.debug("Create workers: Querying for tasks")
   163|         with durable_atomic(using="snappea"):
   164|             tasks = list(Task.objects.all()[:self.settings.TASK_QS_LIMIT])
   165|         task_i = -1
   166|         for task_i, task in enumerate(tasks):
   167|             logger.debug("Create workers: Creating worker for with task %s", short_id(task.id))
   168|             logger.debug("Create workers: Checking (maybe waiting) for available worker slots")
   169|             self.worker_semaphore.acquire()
   170|             logger.debug("Create workers: Worker slot available")
   171|             self.check_for_stopping()  # check after .acquire() - it may have unblocked via handle_signal()
   172|             task_id = task.id
   173|             try:
   174|                 function = registry[task.task_name]
   175|                 args = json.loads(task.args)
   176|                 kwargs = json.loads(task.kwargs)
   177|             except Exception as e:
   178|                 logger.error('Create workers: can\'t execute "%s": %s', task.task_name, e)
   179|                 with time_to_logger(performance_logger, "Snappea delete Task"):
   180|                     task.delete()  # we delete the task because we can't do anything with it, and we don't want to hang
   181|                 capture_or_log_exception(e, logger)
   182|                 self.worker_semaphore.release()
   183|                 continue
   184|             self.check_for_stopping()  # check_for_stopping() right before taking on the work
   185|             with time_to_logger(performance_logger, "Snappea Task.delete()"):
   186|                 task.delete()
   187|             self.run_in_thread(task_id, function, *args, **kwargs)
   188|         task_count = task_i + 1
   189|         if task_count == 0:
   190|             self.connection_close(using="snappea")
   191|         logger.debug("Create workers: %s tasks popped from queue", task_count)
   192|         return task_count
   193|     def check_for_stopping(self):
   194|         if not self.stopping:
   195|             return
   196|         self.stop()
   197|         logger.info("Stopping: EXIT")
   198|         sys.exit()
   199|     def stop(self):
   200|         if self.settings.WORKAHOLIC:
   201|             with durable_atomic(using="snappea"):
   202|                 if Task.objects.exists():
   203|                     logger.info("Not stopping yet: Workaholic mode, waiting for all tasks to finish")
   204|                     return
   205|         logger.info("Stopping: waiting for/stopping workers")
   206|         for task_id, worker_thread in self.workers.list():
   207|             if worker_thread.is_alive():
   208|                 time_left = self.stop_deadline - time.time()
   209|                 if time_left > 0:
   210|                     worker_thread.join(time_left)
   211|                     if worker_thread.is_alive():
   212|                         logger.info(
   213|                             "Stopping: %s did not die in %.1fs, proceeding to kill",
   214|                             short_id(task_id), self.settings.GRACEFUL_TIMEOUT)
   215|                 else:
   216|                     logger.info(
   217|                         "Stopping: %s did not die in %.1fs, proceeding to kill",
   218|                         short_id(task_id), self.settings.GRACEFUL_TIMEOUT)
   219|         os.remove(self.settings.PID_FILE)


# ====================================================================
# FILE: tags/management/commands/vacuum_eventless_issuetags.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-7 ---
     1| from django.core.management.base import BaseCommand
     2| from tags.tasks import vacuum_eventless_issuetags
     3| class Command(BaseCommand):
     4|     help = "Kick off tag cleanup by vacuuming IssueTag objects for which there is no EventTag equivalent"
     5|     def handle(self, *args, **options):
     6|         vacuum_eventless_issuetags.delay()
     7|         self.stdout.write("Started tag vacuum via task queue.")


# ====================================================================
# FILE: tags/management/commands/vacuum_tags.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-7 ---
     1| from django.core.management.base import BaseCommand
     2| from tags.tasks import vacuum_tagvalues
     3| class Command(BaseCommand):
     4|     help = "Kick off tag cleanup by vacuuming orphaned TagValue and TagKey entries."
     5|     def handle(self, *args, **options):
     6|         vacuum_tagvalues.delay()
     7|         self.stdout.write("Started tag vacuum via task queue.")


# ====================================================================
# FILE: tags/migrations/0002_no_cascade.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-36 ---
     1| from django.db import migrations, models
     2| import django.db.models.deletion
     3| class Migration(migrations.Migration):
     4|     dependencies = [
     5|         ("tags", "0001_initial"),
     6|     ]
     7|     operations = [
     8|         migrations.AlterField(
     9|             model_name="eventtag",
    10|             name="value",
    11|             field=models.ForeignKey(
    12|                 on_delete=django.db.models.deletion.DO_NOTHING, to="tags.tagvalue"
    13|             ),
    14|         ),
    15|         migrations.AlterField(
    16|             model_name="issuetag",
    17|             name="key",
    18|             field=models.ForeignKey(
    19|                 on_delete=django.db.models.deletion.DO_NOTHING, to="tags.tagkey"
    20|             ),
    21|         ),
    22|         migrations.AlterField(
    23|             model_name="issuetag",
    24|             name="value",
    25|             field=models.ForeignKey(
    26|                 on_delete=django.db.models.deletion.DO_NOTHING, to="tags.tagvalue"
    27|             ),
    28|         ),
    29|         migrations.AlterField(
    30|             model_name="tagvalue",
    31|             name="key",
    32|             field=models.ForeignKey(
    33|                 on_delete=django.db.models.deletion.DO_NOTHING, to="tags.tagkey"
    34|             ),
    35|         ),
    36|     ]


# ====================================================================
# FILE: tags/migrations/0003_remove_objects_with_null_issue.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-13 ---
     1| from django.db import migrations
     2| def remove_objects_with_null_issue(apps, schema_editor):
     3|     EventTag = apps.get_model("tags", "EventTag")
     4|     IssueTag = apps.get_model("tags", "IssueTag")
     5|     EventTag.objects.filter(issue__isnull=True).delete()
     6|     IssueTag.objects.filter(issue__isnull=True).delete()
     7| class Migration(migrations.Migration):
     8|     dependencies = [
     9|         ("tags", "0002_no_cascade"),
    10|     ]
    11|     operations = [
    12|         migrations.RunPython(remove_objects_with_null_issue, reverse_code=migrations.RunPython.noop),
    13|     ]


# ====================================================================
# FILE: tags/migrations/0004_alter_do_nothing.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-27 ---
     1| from django.db import migrations, models
     2| import django.db.models.deletion
     3| class Migration(migrations.Migration):
     4|     dependencies = [
     5|         ("issues", "0021_alter_do_nothing"),
     6|         ("tags", "0003_remove_objects_with_null_issue"),
     7|     ]
     8|     operations = [
     9|         migrations.AlterField(
    10|             model_name="eventtag",
    11|             name="issue",
    12|             field=models.ForeignKey(
    13|                 on_delete=django.db.models.deletion.DO_NOTHING,
    14|                 related_name="event_tags",
    15|                 to="issues.issue",
    16|             ),
    17|         ),
    18|         migrations.AlterField(
    19|             model_name="issuetag",
    20|             name="issue",
    21|             field=models.ForeignKey(
    22|                 on_delete=django.db.models.deletion.DO_NOTHING,
    23|                 related_name="tags",
    24|                 to="issues.issue",
    25|             ),
    26|         ),
    27|     ]


# ====================================================================
# FILE: tags/migrations/0005_alter_eventtag_project_alter_issuetag_project_and_more.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-37 ---
     1| from django.db import migrations, models
     2| import django.db.models.deletion
     3| class Migration(migrations.Migration):
     4|     dependencies = [
     5|         ("projects", "0014_alter_projectmembership_project"),
     6|         ("tags", "0004_alter_do_nothing"),
     7|     ]
     8|     operations = [
     9|         migrations.AlterField(
    10|             model_name="eventtag",
    11|             name="project",
    12|             field=models.ForeignKey(
    13|                 on_delete=django.db.models.deletion.DO_NOTHING, to="projects.project"
    14|             ),
    15|         ),
    16|         migrations.AlterField(
    17|             model_name="issuetag",
    18|             name="project",
    19|             field=models.ForeignKey(
    20|                 on_delete=django.db.models.deletion.DO_NOTHING, to="projects.project"
    21|             ),
    22|         ),
    23|         migrations.AlterField(
    24|             model_name="tagkey",
    25|             name="project",
    26|             field=models.ForeignKey(
    27|                 on_delete=django.db.models.deletion.DO_NOTHING, to="projects.project"
    28|             ),
    29|         ),
    30|         migrations.AlterField(
    31|             model_name="tagvalue",
    32|             name="project",
    33|             field=models.ForeignKey(
    34|                 on_delete=django.db.models.deletion.DO_NOTHING, to="projects.project"
    35|             ),
    36|         ),
    37|     ]


# ====================================================================
# FILE: tags/models.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-114 ---
     1| """
     2| Tags provide support for arbitrary key/value pairs (both strings) on Events and Issues, allowing for searching &
     3| counting. Some notes:
     4| * Arbitrary Tags can be set programatically in the SDKs, which we need to support (Sentry API Compatability).
     5| * Some "synthetic" Tags are introduced by Bugsink itself: attributes of an Event are deduced and stored explicitly as a
     6|   Tag. The main reason to do this: stay flexible in terms of DB design and allow for generic code for searching and
     7|   counting (especially in the light of Issues, where a single tag can have many values). _However_, we don't make a
     8|   commitment to any particular implementation, and if the deduce-and-store approach turns out to be a performance
     9|   bottleneck, it may be replaced. Particular notes on what we deduce are in `deduce_tags`.
    10| https://docs.sentry.io/platforms/python/enriching-events/tags/
    11| > Tag keys have a maximum length of 32 characters and can contain only letters (a-zA-Z), numbers (0-9), underscores (_),
    12| > periods (.), colons (:), and dashes (-).
    13| >
    14| > Tag values have a maximum length of 200 characters and they cannot contain the newline (\n) character.
    15| """
    16| from django.db import models
    17| from django.db.models import Q, F
    18| from projects.models import Project
    19| from tags.utils import deduce_tags, is_mostly_unique
    20| from bugsink.moreiterutils import batched
    21| class TagKey(models.Model):
    22|     project = models.ForeignKey(Project, blank=False, null=False, on_delete=models.DO_NOTHING)
    23|     key = models.CharField(max_length=32, blank=False, null=False)
    24|     mostly_unique = models.BooleanField(default=False)
    25|     class Meta:
    26|         unique_together = ('project', 'key')
    27|     def __str__(self):
    28|         return f"{self.key}"
    29| class TagValue(models.Model):
    30|     project = models.ForeignKey(Project, blank=False, null=False, on_delete=models.DO_NOTHING)
    31|     key = models.ForeignKey(TagKey, blank=False, null=False, on_delete=models.DO_NOTHING)
    32|     value = models.CharField(max_length=200, blank=False, null=False, db_index=True)
    33|     class Meta:
    34|         unique_together = ('key', 'value')
    35|     def __str__(self):
    36|         return f"{self.key.key}:{self.value}"
    37| class EventTag(models.Model):
    38|     project = models.ForeignKey(Project, blank=False, null=False, on_delete=models.DO_NOTHING)
    39|     value = models.ForeignKey(TagValue, blank=False, null=False, on_delete=models.DO_NOTHING)
    40|     issue = models.ForeignKey(
    41|         'issues.Issue', blank=False, null=False, on_delete=models.DO_NOTHING, related_name="event_tags")
    42|     digest_order = models.PositiveIntegerField(blank=False, null=False)
    43|     event = models.ForeignKey('events.Event', blank=False, null=False, on_delete=models.DO_NOTHING, related_name='tags')
    44|     class Meta:
    45|         unique_together = ('value', 'event')
    46|         indexes = [
    47|             models.Index(fields=['event']),  # for lookups by event (for event-details page, event-deletions)
    48|             models.Index(fields=['value', 'issue', 'digest_order']),
    49|         ]
    50| class IssueTag(models.Model):
    51|     project = models.ForeignKey(Project, blank=False, null=False, on_delete=models.DO_NOTHING)
    52|     key = models.ForeignKey(TagKey, blank=False, null=False, on_delete=models.DO_NOTHING)
    53|     value = models.ForeignKey(TagValue, blank=False, null=False, on_delete=models.DO_NOTHING)
    54|     issue = models.ForeignKey('issues.Issue', blank=False, null=False, on_delete=models.DO_NOTHING, related_name='tags')
    55|     count = models.PositiveIntegerField(default=0)
    56|     class Meta:
    57|         unique_together = ('value', 'issue')
    58|         indexes = [
    59|             models.Index(fields=['issue', 'key', 'count']),
    60|         ]
    61| def _or_join(q_objects):
    62|     if len(q_objects) == 0:
    63|         raise ValueError("empty list of Q objects")
    64|     result = q_objects[0]
    65|     for q in q_objects[1:]:
    66|         result |= q
    67|     return result
    68| def digest_tags(event_data, event, issue):
    69|     tags = {
    70|         k: str(v)[:200] for k, v in deduce_tags(event_data).items()
    71|     }
    72|     store_tags(event, issue, tags)
    73| def store_tags(event, issue, tags):
    74|     for kv_batch in batched(tags.items(), 64):
    75|         _store_tags(event, issue, {k: v for k, v in kv_batch})
    76| def _store_tags(event, issue, tags):
    77|     if not tags:
    78|         return  # short-circuit; which is a performance optimization which also avoids some the need for further guards
    79|     TagKey.objects.bulk_create([
    80|         TagKey(project_id=event.project_id, key=key, mostly_unique=is_mostly_unique(key)) for key in tags.keys()
    81|     ], ignore_conflicts=True)
    82|     tag_key_objects = TagKey.objects.filter(project_id=event.project_id, key__in=tags.keys())
    83|     TagValue.objects.bulk_create([
    84|         TagValue(project_id=event.project_id, key=key_obj, value=tags[key_obj.key]) for key_obj in tag_key_objects
    85|     ], ignore_conflicts=True)
    86|     tag_value_objects = TagValue.objects.filter(_or_join([
    87|         Q(key=key_obj, value=tags[key_obj.key]) for key_obj in tag_key_objects]))
    88|     EventTag.objects.bulk_create([
    89|         EventTag(
    90|             project_id=event.project_id,
    91|             value=tag_value,
    92|             event=event,
    93|             issue=issue,
    94|             digest_order=event.digest_order,
    95|         ) for tag_value in tag_value_objects
    96|     ], ignore_conflicts=True)
    97|     IssueTag.objects.bulk_create([
    98|         IssueTag(
    99|             project_id=event.project_id,
   100|             key_id=tag_value.key_id,
   101|             value=tag_value,
   102|             issue=issue,
   103|         ) for tag_value in tag_value_objects
   104|     ], ignore_conflicts=True)
   105|     IssueTag.objects.filter(value__in=tag_value_objects, issue=issue).update(
   106|         count=F('count') + 1
   107|     )
   108| def prune_tagvalues(ids_to_check):
   109|     used_in_issuetag = set(
   110|         IssueTag.objects.filter(value_id__in=ids_to_check).values_list('value_id', flat=True)
   111|     )
   112|     unused = [pk for pk in ids_to_check if pk not in used_in_issuetag]
   113|     if unused:
   114|         TagValue.objects.filter(id__in=unused).delete()


# ====================================================================
# FILE: tags/tasks.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-80 ---
     1| from django.db.models import Q
     2| from snappea.decorators import shared_task
     3| from bugsink.moreiterutils import batched
     4| from bugsink.transaction import immediate_atomic, delay_on_commit
     5| from tags.models import TagValue, TagKey, EventTag, IssueTag, _or_join, prune_tagvalues
     6| BATCH_SIZE = 10_000
     7| @shared_task
     8| def vacuum_tagvalues(min_id=0):
     9|     with immediate_atomic():
    10|         ids_to_check = list(
    11|             TagValue.objects
    12|             .filter(id__gt=min_id)
    13|             .order_by('id')
    14|             .values_list('id', flat=True)[:BATCH_SIZE]
    15|         )
    16|         if not ids_to_check:
    17|             delay_on_commit(vacuum_tagkeys, 0)
    18|             return
    19|         used_in_event = set(
    20|             EventTag.objects.filter(value_id__in=ids_to_check).values_list('value_id', flat=True)
    21|         )
    22|         used_in_issue = set(
    23|             IssueTag.objects.filter(value_id__in=ids_to_check).values_list('value_id', flat=True)
    24|         )
    25|         unused = [pk for pk in ids_to_check if pk not in used_in_event and pk not in used_in_issue]
    26|         if unused:
    27|             TagValue.objects.filter(id__in=unused).delete()
    28|     vacuum_tagvalues.delay(ids_to_check[-1])
    29| @shared_task
    30| def vacuum_tagkeys(min_id=0):
    31|     with immediate_atomic():
    32|         ids_to_check = list(
    33|             TagKey.objects
    34|             .filter(id__gt=min_id)
    35|             .order_by('id')
    36|             .values_list('id', flat=True)[:BATCH_SIZE]
    37|         )
    38|         if not ids_to_check:
    39|             return  # done
    40|         used = set(
    41|             TagValue.objects.filter(key_id__in=ids_to_check).values_list('key_id', flat=True)
    42|         )
    43|         unused = [pk for pk in ids_to_check if pk not in used]
    44|         if unused:
    45|             TagKey.objects.filter(id__in=unused).delete()
    46|     vacuum_tagkeys.delay(ids_to_check[-1])
    47| @shared_task
    48| def vacuum_eventless_issuetags(min_id=0):
    49|     BATCH_SIZE = 2048
    50|     INNER_BATCH_SIZE = 64
    51|     with immediate_atomic():
    52|         issue_tag_infos = list(
    53|             IssueTag.objects
    54|             .filter(id__gt=min_id)
    55|             .order_by('id')
    56|             .values('id', 'issue_id', 'value_id')[:BATCH_SIZE]
    57|         )
    58|         for issue_tag_infos_batch in batched(issue_tag_infos, INNER_BATCH_SIZE):
    59|             matching_eventtags = _or_join([
    60|                 Q(issue_id=it['issue_id'], value_id=it['value_id']) for it in issue_tag_infos_batch
    61|             ])
    62|             if matching_eventtags:
    63|                 in_use_issue_value_pairs = set(
    64|                     EventTag.objects
    65|                     .filter(matching_eventtags)
    66|                     .values_list('issue_id', 'value_id')
    67|                 )
    68|             else:
    69|                 in_use_issue_value_pairs = set()
    70|             stale_issuetags = [
    71|                 it
    72|                 for it in issue_tag_infos_batch
    73|                 if (it['issue_id'], it['value_id']) not in in_use_issue_value_pairs
    74|             ]
    75|             if stale_issuetags:
    76|                 IssueTag.objects.filter(id__in=[it['id'] for it in stale_issuetags]).delete()
    77|                 prune_tagvalues([it['value_id'] for it in stale_issuetags])
    78|     if not issue_tag_infos:
    79|         return
    80|     vacuum_eventless_issuetags.delay(issue_tag_infos[-1]['id'])


# ====================================================================
# FILE: teams/views.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-257 ---
     1| from datetime import timedelta
     2| from django.db import models
     3| from django.shortcuts import render, redirect
     4| from django.contrib.auth import get_user_model
     5| from django.http import Http404, HttpResponseRedirect
     6| from django.core.exceptions import PermissionDenied
     7| from django.utils import timezone
     8| from django.urls import reverse
     9| from django.contrib import messages
    10| from django.contrib.auth import logout
    11| from users.models import EmailVerification
    12| from bugsink.app_settings import get_settings, CB_ANYBODY, CB_ADMINS, CB_MEMBERS
    13| from bugsink.decorators import login_exempt, atomic_for_request_method
    14| from .models import Team, TeamMembership, TeamRole, TeamVisibility
    15| from .forms import TeamMemberInviteForm, TeamMembershipForm, MyTeamMembershipForm, TeamForm
    16| from .tasks import send_team_invite_email, send_team_invite_email_new_user
    17| User = get_user_model()
    18| @atomic_for_request_method
    19| def team_list(request, ownership_filter=None):
    20|     my_memberships = TeamMembership.objects.filter(user=request.user)
    21|     my_teams = Team.objects.filter(teammembership__in=my_memberships)
    22|     if request.user.is_superuser:
    23|         other_teams = Team.objects\
    24|             .exclude(teammembership__in=my_memberships)\
    25|             .order_by('name').distinct()
    26|     else:
    27|         other_teams = Team.objects\
    28|             .exclude(teammembership__in=my_memberships)\
    29|             .exclude(visibility=TeamVisibility.HIDDEN)\
    30|             .order_by('name').distinct()
    31|     if ownership_filter is None:
    32|         if my_teams.exists() or not other_teams.exists():
    33|             return redirect('team_list_mine')
    34|         return redirect('team_list_other')
    35|     if request.method == 'POST':
    36|         full_action_str = request.POST.get('action')
    37|         action, team_pk = full_action_str.split(":", 1)
    38|         if action == "leave":
    39|             TeamMembership.objects.filter(team=team_pk, user=request.user.id).delete()
    40|         elif action == "join":
    41|             team = Team.objects.get(id=team_pk)
    42|             if not team.is_joinable() and not request.user.is_superuser:
    43|                 raise PermissionDenied("This team is not joinable")
    44|             messages.success(request, 'You have joined the team "%s"' % team.name)
    45|             TeamMembership.objects.create(team_id=team_pk, user_id=request.user.id, role=TeamRole.MEMBER, accepted=True)
    46|             return redirect('team_member_settings', team_pk=team_pk, user_pk=request.user.id)
    47|     if ownership_filter == "mine":
    48|         base_qs = my_teams
    49|     elif ownership_filter == "other":
    50|         base_qs = other_teams
    51|     else:
    52|         raise ValueError("Invalid ownership_filter")
    53|     team_list = base_qs.annotate(
    54|         project_count=models.Count('project', distinct=True),
    55|         member_count=models.Count('teammembership', distinct=True, filter=models.Q(teammembership__accepted=True)),
    56|     )
    57|     if ownership_filter == "mine":
    58|         my_memberships_dict = {m.team_id: m for m in my_memberships}
    59|         team_list_2 = []
    60|         for team in team_list:
    61|             team.member = my_memberships_dict.get(team.id)
    62|             team_list_2.append(team)
    63|         team_list = team_list_2
    64|     return render(request, 'teams/team_list.html', {
    65|         'can_create':
    66|             get_settings().TEAM_CREATION in [CB_ANYBODY, CB_MEMBERS] or
    67|             (request.user.is_superuser and get_settings().TEAM_CREATION == CB_ADMINS),
    68|         'ownership_filter': ownership_filter,
    69|         'team_list': team_list,
    70|     })
    71| @atomic_for_request_method
    72| def team_new(request):
    73|     if not (get_settings().TEAM_CREATION in [CB_ANYBODY, CB_MEMBERS] or
    74|             (request.user.is_superuser and get_settings().TEAM_CREATION == CB_ADMINS)):
    75|         raise PermissionDenied("You are not allowed to create teams")
    76|     if request.method == 'POST':
    77|         form = TeamForm(request.POST)
    78|         if form.is_valid():
    79|             team = form.save()
    80|             TeamMembership.objects.create(team=team, user=request.user, role=TeamRole.ADMIN, accepted=True)
    81|             return redirect('team_members', team_pk=team.id)
    82|     else:
    83|         form = TeamForm()
    84|     return render(request, 'teams/team_new.html', {
    85|         'form': form,
    86|     })
    87| @atomic_for_request_method
    88| def team_edit(request, team_pk):
    89|     team = Team.objects.get(id=team_pk)
    90|     if (not TeamMembership.objects.filter(team=team, user=request.user, role=TeamRole.ADMIN, accepted=True).exists() and
    91|             not request.user.is_superuser):
    92|         raise PermissionDenied("You are not an admin of this team")
    93|     if request.method == 'POST':
    94|         action = request.POST.get('action')
    95|         if action == 'delete':
    96|             if not (TeamMembership.objects.filter(team=team, user=request.user, role=TeamRole.ADMIN, accepted=True).exists() or
    97|                     request.user.is_superuser):
    98|                 raise PermissionDenied("Only team admins can delete teams")
    99|             team.project_set.all().delete()
   100|             team.delete()
   101|             messages.success(request, f'Team "{team.name}" has been deleted successfully.')
   102|             return redirect('team_list')
   103|         form = TeamForm(request.POST, instance=team)
   104|         if form.is_valid():
   105|             form.save()
   106|             return redirect('team_members', team_pk=team.id)
   107|     else:
   108|         form = TeamForm(instance=team)
   109|     return render(request, 'teams/team_edit.html', {
   110|         'team': team,
   111|         'form': form,
   112|     })
   113| @atomic_for_request_method
   114| def team_members(request, team_pk):
   115|     team = Team.objects.get(id=team_pk)
   116|     if (not TeamMembership.objects.filter(team=team, user=request.user, role=TeamRole.ADMIN, accepted=True).exists() and
   117|             not request.user.is_superuser):
   118|         raise PermissionDenied("You are not an admin of this team")
   119|     if request.method == 'POST':
   120|         full_action_str = request.POST.get('action')
   121|         action, user_id = full_action_str.split(":", 1)
   122|         if action == "remove":
   123|             TeamMembership.objects.filter(team=team_pk, user=user_id).delete()
   124|         elif action == "reinvite":
   125|             user = User.objects.get(id=user_id)
   126|             _send_team_invite_email(user, team_pk)
   127|             messages.success(request, f"Invitation resent to {user.email}")
   128|     return render(request, 'teams/team_members.html', {
   129|         'team': team,
   130|         'members': team.teammembership_set.all().select_related('user'),
   131|     })
   132| def _send_team_invite_email(user, team_pk):
   133|     """Send an email to a user inviting them to a team; (for new users this includes the email-verification link)"""
   134|     if user.is_active:
   135|         send_team_invite_email.delay(user.email, team_pk)
   136|     else:
   137|         verification = EmailVerification.objects.create(user=user, email=user.username)
   138|         send_team_invite_email_new_user.delay(user.email, team_pk, verification.token)
   139| @atomic_for_request_method
   140| def team_members_invite(request, team_pk):
   141|     team = Team.objects.get(id=team_pk)
   142|     if (not TeamMembership.objects.filter(team=team, user=request.user, role=TeamRole.ADMIN, accepted=True).exists() and
   143|             not request.user.is_superuser):
   144|         raise PermissionDenied("You are not an admin of this team")
   145|     if get_settings().USER_REGISTRATION in [CB_ANYBODY, CB_MEMBERS]:
   146|         user_must_exist = False
   147|     elif get_settings().USER_REGISTRATION == CB_ADMINS and request.user.is_superuser:
   148|         user_must_exist = False
   149|     else:
   150|         user_must_exist = True
   151|     if request.method == 'POST':
   152|         form = TeamMemberInviteForm(user_must_exist, request.POST)
   153|         if form.is_valid():
   154|             email = form.cleaned_data['email']
   155|             user, user_created = User.objects.get_or_create(
   156|                 email=email, defaults={'username': email, 'is_active': False})
   157|             _send_team_invite_email(user, team_pk)
   158|             _, membership_created = TeamMembership.objects.get_or_create(team=team, user=user, defaults={
   159|                 'role': form.cleaned_data['role'],
   160|                 'accepted': False,
   161|             })
   162|             if membership_created:
   163|                 messages.success(request, f"Invitation sent to {email}")
   164|             else:
   165|                 messages.success(
   166|                     request, f"Invitation resent to {email} (it was previously sent and we just sent it again)")
   167|             if request.POST.get('action') == "invite_and_add_another":
   168|                 return redirect('team_members_invite', team_pk=team_pk)
   169|             return redirect('team_members', team_pk=team_pk)
   170|     else:
   171|         form = TeamMemberInviteForm(user_must_exist)
   172|     return render(request, 'teams/team_members_invite.html', {
   173|         'team': team,
   174|         'form': form,
   175|     })
   176| @atomic_for_request_method
   177| def team_member_settings(request, team_pk, user_pk):
   178|     try:
   179|         your_membership = TeamMembership.objects.get(team=team_pk, user=request.user)
   180|     except TeamMembership.DoesNotExist:
   181|         raise PermissionDenied("You are not a member of this team")
   182|     if not your_membership.accepted:
   183|         return redirect("team_members_accept", team_pk=team_pk)
   184|     this_is_you = str(user_pk) == str(request.user.id)
   185|     if not this_is_you:
   186|         if not request.user.is_superuser or not your_membership.role == TeamRole.ADMIN:
   187|             raise PermissionDenied("You are not an admin of this team")
   188|         membership = TeamMembership.objects.get(team=team_pk, user=user_pk)
   189|         create_form = lambda data: TeamMembershipForm(data, instance=membership)  # noqa
   190|     else:
   191|         edit_role = your_membership.role == TeamRole.ADMIN or request.user.is_superuser
   192|         create_form = lambda data: MyTeamMembershipForm(data=data, instance=your_membership, edit_role=edit_role)  # noqa
   193|     if request.method == 'POST':
   194|         form = create_form(request.POST)
   195|         if form.is_valid():
   196|             form.save()
   197|             if this_is_you:
   198|                 return redirect('team_list')
   199|             return redirect('team_members', team_pk=team_pk)
   200|     else:
   201|         form = create_form(None)
   202|     return render(request, 'teams/team_member_settings.html', {
   203|         'this_is_you': this_is_you,
   204|         'user': User.objects.get(id=user_pk),
   205|         'team': Team.objects.get(id=team_pk),
   206|         'form': form,
   207|     })
   208| @atomic_for_request_method
   209| @login_exempt  # no login is required, the token is what identifies the user
   210| def team_members_accept_new_user(request, team_pk, token):
   211|     EmailVerification.objects.filter(
   212|         created_at__lt=timezone.now() - timedelta(get_settings().USER_REGISTRATION_VERIFY_EMAIL_EXPIRY)).delete()
   213|     try:
   214|         verification = EmailVerification.objects.get(token=token)
   215|     except EmailVerification.DoesNotExist:
   216|         raise Http404("Invalid or expired token")
   217|     user = verification.user
   218|     if not user.has_usable_password() or not user.is_active:
   219|         return HttpResponseRedirect(reverse("reset_password", kwargs={"token": token}) + "?next=" + reverse(
   220|             team_members_accept, kwargs={"team_pk": team_pk})
   221|         )
   222|     if request.user.is_authenticated and request.user != user:
   223|         logout(request)
   224|     verification.delete()
   225|     return redirect("team_members_accept", team_pk=team_pk)
   226| @atomic_for_request_method
   227| def team_members_accept(request, team_pk):
   228|     team = Team.objects.get(id=team_pk)
   229|     membership = TeamMembership.objects.get(team=team, user=request.user)
   230|     if membership.accepted:
   231|         return redirect("team_member_settings", team_pk=team_pk, user_pk=request.user.id)
   232|     if request.method == 'POST':
   233|         if request.POST["action"] == "decline":
   234|             membership.delete()
   235|             return redirect("home")
   236|         if request.POST["action"] == "accept":
   237|             membership.accepted = True
   238|             membership.save()
   239|             return redirect("team_member_settings", team_pk=team_pk, user_pk=request.user.id)
   240|         raise Http404("Invalid action")
   241|     return render(request, "teams/team_members_accept.html", {"team": team, "membership": membership})
   242| DEBUG_CONTEXTS = {
   243|     "team_membership_invite_new_user": {
   244|         "site_title": get_settings().SITE_TITLE,
   245|         "base_url": get_settings().BASE_URL + "/",
   246|         "team_name": "Some team",
   247|         "url": "http://example.com/confirm-email/1234567890abcdef",  # nonsense to avoid circular import
   248|     },
   249|     "team_membership_invite": {
   250|         "site_title": get_settings().SITE_TITLE,
   251|         "base_url": get_settings().BASE_URL + "/",
   252|         "team_name": "Some team",
   253|         "url": "http://example.com/confirm-email/1234567890abcdef",  # nonsense to avoid circular import
   254|     },
   255| }
   256| def debug_email(request, template_name):
   257|     return render(request, "mails/" + template_name + ".html", DEBUG_CONTEXTS[template_name])


# ====================================================================
# FILE: theme/static_src/tailwind.config.js
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-68 ---
     1| /**
     2|  * This is a minimal config.
     3|  *
     4|  * If you need the full config, get it from here:
     5|  * https://unpkg.com/browse/tailwindcss@latest/stubs/defaultConfig.stub.js
     6|  */
     7| const defaultTheme = require("tailwindcss/defaultTheme");
     8| module.exports = {
     9|     darkMode: ['selector', '[data-theme="dark"]'],
    10|     content: [
    11|         /**
    12|          * HTML. Paths to Django template files that will contain Tailwind CSS classes.
    13|          */
    14|         /*  Templates within theme app (<tailwind_app_name>/templates), e.g. base.html. */
    15|         '../templates/**/*.html',
    16|         /*
    17|          * Main templates directory of the project (BASE_DIR/templates).
    18|          * Adjust the following line to match your project structure.
    19|          */
    20|         '../../templates/**/*.html',
    21|         /*
    22|          * Templates in other django apps (BASE_DIR/<any_app_name>/templates).
    23|          * Adjust the following line to match your project structure.
    24|          */
    25|         '../../**/templates/**/*.html',
    26|         /**
    27|          * JS: If you use Tailwind CSS in JavaScript, uncomment the following lines and make sure
    28|          * patterns match your project structure.
    29|          */
    30|         /* JS 1: Ignore any JavaScript in node_modules folder. */
    31|         /* JS 2: Process all JavaScript files in the project. */
    32|         /**
    33|          * Python: If you use Tailwind CSS classes in Python, uncomment the following line
    34|          * and make sure the pattern below matches your project structure.
    35|          */
    36|         "../../issues/views.py",
    37|         "../../theme/templatetags/code.py",
    38|         "../../theme/templatetags/tailwind_forms.py",
    39|     ],
    40|     theme: {
    41|       extend: {
    42|         spacing: {
    43|           '128': '32rem',
    44|         },
    45|         fontFamily: {
    46|           sans: [
    47|             '"IBM Plex Sans"',
    48|             ...defaultTheme.fontFamily.sans,
    49|           ],
    50|           mono: [
    51|             '"IBM Plex Mono"',
    52|             ...defaultTheme.fontFamily.mono,
    53|           ],
    54|         },
    55|       },
    56|     },
    57|     plugins: [
    58|         /**
    59|          * '@tailwindcss/forms' is the forms plugin that provides a minimal styling
    60|          * for forms. If you don't like it or have own styling for forms,
    61|          * comment the line below to disable '@tailwindcss/forms'.
    62|          */
    63|         require('@tailwindcss/forms'),
    64|         require('@tailwindcss/typography'),
    65|         require('@tailwindcss/line-clamp'),
    66|         require('@tailwindcss/aspect-ratio'),
    67|     ],
    68| }


# ====================================================================
# FILE: theme/templatetags/code.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-24 ---
     1| from pygments import highlight
     2| from pygments.lexers import get_lexer_by_name
     3| from pygments.formatters import HtmlFormatter
     4| from django import template
     5| register = template.Library()
     6| @register.tag(name="code")
     7| def do_code(parser, token):
     8|     nodelist = parser.parse(("endcode",))
     9|     parser.delete_first_token()
    10|     return CodeNode(nodelist)
    11| class CodeNode(template.Node):
    12|     def __init__(self, nodelist):
    13|         self.nodelist = nodelist
    14|     def render(self, context):
    15|         content = self.nodelist.render(context)
    16|         content = "\n".join([line.rstrip() for line in content.split("\n")])
    17|         lang_identifier, code = content.split("\n", 1)
    18|         assert lang_identifier.startswith(":::") or lang_identifier.startswith("#!"), \
    19|             "Expected code block identifier ':::' or '#!' not " + lang_identifier
    20|         lang = lang_identifier[3:].strip() if lang_identifier.startswith(":::") else lang_identifier[2:].strip()
    21|         is_shebang = lang_identifier.startswith("#!")
    22|         formatter = HtmlFormatter(linenos="table" if is_shebang else False)
    23|         lexer = get_lexer_by_name(lang, stripall=True)
    24|         return highlight(code, lexer, formatter).replace("highlight", "p-4 mt-4 bg-slate-50 dark:bg-slate-800 syntax-coloring")


# ====================================================================
# FILE: theme/templatetags/tailwind_forms.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-20 ---
     1| from django import template
     2| register = template.Library()
     3| @register.inclusion_tag('tailwind_forms/formfield.html')
     4| def tailwind_formfield(formfield, implicit=False):
     5|     if not formfield:
     6|         return {"formfield": None}
     7|     if formfield.errors:
     8|         formfield.field.widget.attrs['class'] = "bg-red-50 dark:bg-red-900"
     9|     else:
    10|         formfield.field.widget.attrs['class'] = "bg-slate-50 dark:bg-slate-800"
    11|     formfield.field.widget.attrs['class'] += " pl-4 py-2 md:py-4 focus:outline-none w-full"
    12|     if implicit:
    13|         formfield.field.widget.attrs['placeholder'] = formfield.label
    14|     return {
    15|         'formfield': formfield,
    16|         'implicit': implicit,
    17|     }
    18| @register.inclusion_tag('tailwind_forms/formfield.html')
    19| def tailwind_formfield_implicit(formfield):
    20|     return tailwind_formfield(formfield, True)


# ====================================================================
# FILE: users/forms.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-96 ---
     1| import urllib.parse
     2| from django import forms
     3| from django.urls import reverse
     4| from django.contrib.auth.forms import UserCreationForm as BaseUserCreationForm, SetPasswordForm as BaseSetPasswordForm
     5| from django.core.validators import EmailValidator
     6| from django.contrib.auth import get_user_model
     7| from django.core.exceptions import ValidationError
     8| from django.contrib.auth import password_validation
     9| from django.forms import ModelForm
    10| from django.utils.html import escape, mark_safe
    11| TRUE_FALSE_CHOICES = (
    12|     (True, 'Yes'),
    13|     (False, 'No')
    14| )
    15| def _(x):
    16|     return x
    17| User = get_user_model()
    18| class UserCreationForm(BaseUserCreationForm):
    19|     def __init__(self, *args, **kwargs):
    20|         super().__init__(*args, **kwargs)
    21|         self.fields['username'].validators = [EmailValidator()]
    22|         self.fields['username'].label = "Email"
    23|         self.fields['username'].help_text = None  # "Email" is descriptive enough
    24|         self.fields['password1'].help_text = "At least 8 characters"
    25|         self.fields['password2'].help_text = None  # "Confirm password" is descriptive enough
    26|     class Meta:
    27|         model = User
    28|         fields = ("username",)
    29|     def clean_username(self):
    30|         if User.objects.filter(username=self.cleaned_data['username'], is_active=False).exists():
    31|             raise ValidationError(mark_safe(
    32|                 'This email is already registered but not yet confirmed. Please check your email for the confirmation '
    33|                 'link or <b><a href="' + reverse("resend_confirmation") + "?email=" +
    34|                 urllib.parse.quote(escape(self.cleaned_data['username'])) + '">request it again</a></b>.'))
    35|         return self.cleaned_data['username']
    36|     def _post_clean(self):
    37|         ModelForm._post_clean(self)  # commented out because we want to skip the direct superclass
    38|         password = self.cleaned_data.get("password1")
    39|         if password:
    40|             try:
    41|                 password_validation.validate_password(password, self.instance)
    42|             except ValidationError as error:
    43|                 self.add_error("password1", error)
    44|     def save(self, **kwargs):
    45|         commit = kwargs.pop("commit", True)
    46|         user = super().save(commit=False)
    47|         user.email = user.username
    48|         if commit:
    49|             user.save()
    50|         return user
    51| class UserEditForm(ModelForm):
    52|     def __init__(self, *args, **kwargs):
    53|         super().__init__(*args, **kwargs)
    54|         self.fields['username'].validators = [EmailValidator()]
    55|         self.fields['username'].label = "Email"
    56|         self.fields['username'].help_text = None  # "Email" is descriptive enough
    57|     class Meta:
    58|         model = User
    59|         fields = ("username",)
    60|     def clean_username(self):
    61|         if User.objects.exclude(pk=self.instance.pk).filter(username=self.cleaned_data['username']).exists():
    62|             raise ValidationError(mark_safe("This email is already registered by another user."))
    63|         return self.cleaned_data['username']
    64|     def save(self, **kwargs):
    65|         commit = kwargs.pop("commit", True)
    66|         user = super().save(commit=False)
    67|         user.email = user.username
    68|         if commit:
    69|             user.save()
    70|         return user
    71| class ResendConfirmationForm(forms.Form):
    72|     email = forms.EmailField()
    73| class RequestPasswordResetForm(forms.Form):
    74|     email = forms.EmailField()
    75|     def clean_email(self):
    76|         email = self.cleaned_data['email']
    77|         if not User.objects.filter(username=email).exists():
    78|             raise ValidationError("This email is not registered.")
    79|         return email
    80| class SetPasswordForm(BaseSetPasswordForm):
    81|     def __init__(self, *args, **kwargs):
    82|         super().__init__(*args, **kwargs)
    83|         self.fields['new_password1'].help_text = "At least 8 characters"
    84|         self.fields['new_password2'].help_text = None  # "Confirm password" is descriptive enough
    85| class PreferencesForm(ModelForm):
    86|     send_email_alerts = forms.ChoiceField(
    87|         label=_("Send email alerts"), choices=TRUE_FALSE_CHOICES, required=False, widget=forms.Select())
    88|     theme_preference = forms.ChoiceField(
    89|         label=_("Theme preference"),
    90|         choices=User.THEME_CHOICES,
    91|         required=True,
    92|         widget=forms.Select(),
    93|     )
    94|     class Meta:
    95|         model = User
    96|         fields = ("send_email_alerts", "theme_preference",)


# ====================================================================
# FILE: users/migrations/0002_user_theme_preference.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-12 ---
     1| from django.db import migrations, models
     2| class Migration(migrations.Migration):
     3|     dependencies = [
     4|         ('users', '0001_initial'),
     5|     ]
     6|     operations = [
     7|         migrations.AddField(
     8|             model_name='user',
     9|             name='theme_preference',
    10|             field=models.CharField(choices=[('system', 'System Default'), ('light', 'Light'), ('dark', 'Dark')], default='system', max_length=10),
    11|         ),
    12|     ]


# ====================================================================
# FILE: users/models.py
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-26 ---
     1| import secrets
     2| from django.db import models
     3| from django.contrib.auth.models import AbstractUser
     4| from django.conf import settings
     5| class User(AbstractUser):
     6|     send_email_alerts = models.BooleanField(default=True, blank=True)
     7|     THEME_CHOICES = [
     8|         ("system", "System Default"),
     9|         ("light", "Light"),
    10|         ("dark", "Dark"),
    11|     ]
    12|     theme_preference = models.CharField(
    13|         max_length=10,
    14|         choices=THEME_CHOICES,
    15|         default="system",
    16|         blank=False,
    17|     )
    18|     class Meta:
    19|         db_table = 'auth_user'
    20| class EmailVerification(models.Model):
    21|     user = models.ForeignKey(settings.AUTH_USER_MODEL, on_delete=models.CASCADE)
    22|     email = models.EmailField()  # redundant, but future-proof for when we allow multiple emails per user
    23|     token = models.CharField(max_length=64, default=secrets.token_urlsafe, blank=False, null=False)
    24|     created_at = models.DateTimeField(auto_now_add=True)
    25|     def __str__(self):
    26|         return f"{self.user} ({self.email})"

