--- a//dev/null
+++ b/.devcontainer/android/postStartCommand.sh
@@ -0,0 +1,2 @@
+set -e
+nohup bash -c 'flock -n /var/lock/emulator.lock -c '\''${ANDROID_SDK_ROOT}/emulator/emulator -avd ${EMULATOR_NAME_X64} -no-window -no-audio -no-snapstorage'\''&' >/dev/null 2>&1

--- a//dev/null
+++ b/.devcontainer/scripts/onCreateCommand.sh
@@ -0,0 +1,32 @@
+set -e
+function wasm_common() {
+    case "$1" in
+    wasm)
+        ./build.sh mono+libs -os browser -c Release
+        ;;
+    wasm-multithreaded)
+        ./build.sh mono+libs -os browser -c Release /p:WasmEnableThreads=true
+        ;;
+    *)
+    ./dotnet.sh tool install dotnet-serve --version 1.10.172 --tool-path ./.dotnet-tools-global
+    ;;
+    esac
+}
+opt=$1
+case "$opt" in
+    libraries)
+        ./build.sh libs+clr -rc Release
+        ./build.sh libs.tests -restore
+    ;;
+    android)
+        ./build.sh mono+libs -os android
+        ./build.sh libs.tests -restore
+    ;;
+    wasm)
+        wasm_common $opt
+    ;;
+    wasm-multithreaded)
+        wasm_common $opt
+    ;;
+esac
+git rev-parse HEAD > ./artifacts/prebuild.sha

--- a//dev/null
+++ b/.devcontainer/scripts/postCreateCommand.sh
@@ -0,0 +1,8 @@
+set -e
+opt=$1
+case "$opt" in
+    android)
+        ${ANDROID_SDK_ROOT}/cmdline-tools/cmdline-tools/bin/avdmanager -s create avd --name ${EMULATOR_NAME_X64} --package "system-images;android-${SDK_API_LEVEL};default;x86_64"
+    ;;
+esac
+git reset --hard $(cat ./artifacts/prebuild.sha)

--- a//dev/null
+++ b/docs/design/datacontracts/contract_csharp_api_design.cs
@@ -0,0 +1,271 @@
+namespace DataContracts
+{
+    class DataContractTypeAttribute : System.Attribute {}
+    class DataContractLayoutAttribute : System.Attribute
+    {
+        public DataContractLayoutAttribute(uint version, uint typeSize) { Version = version; TypeSize = typeSize; }
+        public uint Version;
+        public uint TypeSize;
+    }
+    class DataContractGlobalsAttribute : System.Attribute
+    {
+        public DataContractGlobalsAttribute(string name, uint version) { Name = name; Version = version; }
+        public string Name;
+        public uint Version;
+    }
+    class DataContractAlgorithmAttribute : System.Attribute
+    {
+        public DataContractAlgorithmAttribute(params uint []version) { Name = name; Version = version; }
+        public uint[] Version;
+    }
+    struct TargetPointer
+    {
+        public ulong Value;
+        public static TargetPointer Null = new TargetPointer(0);
+    }
+    public readonly struct TargetSpan
+    {
+        public TargetSpan(TargetPointer address, ulong size)
+        {
+            Address = address;
+            Size = size;
+        }
+        public TargetPointer Address { get; }
+        public ulong Size { get; }
+    }
+    struct TargetNInt
+    {
+        public long Value;
+    }
+    struct TargetNUInt
+    {
+        public ulong Value;
+    }
+    enum FieldType
+    {
+        Int8Type,
+        UInt8Type,
+        Int16Type,
+        UInt16Type,
+        Int32Type,
+        UInt32Type,
+        Int64Type,
+        UInt64Type,
+        NIntType,
+        NUIntType,
+        PointerType,
+    }
+    struct FieldLayout
+    {
+        public int Offset;
+        public FieldType Type;
+    }
+    interface IContract
+    {
+        string Name { get; }
+        uint Version { get; }
+    }
+    sealed class Target
+    {
+        public int CurrentEpoch = 0;
+        public T Read<T>(ulong address) where T : unmanaged, IBinaryInteger<T>, IMinMaxValue<T>;
+        TargetPointer ReadPointer(ulong address);
+        byte[] ReadByteArray(TargetPointer pointer, ulong size);
+        void FillByteArray(TargetPointer pointer, byte[] array, ulong size);
+        TargetPointer GetTargetPointerForField(TargetPointer pointer, FieldLayout fieldLayout);
+        T ReadGlobal<T>(string globalName) where T : unmanaged, IBinaryInteger<T>, IMinMaxValue<T>;
+        TargetPointer ReadGlobalPointer(string globalName);
+        Contracts.Registry Contracts { get; }
+    }
+    namespace Contracts
+    {
+        class Registry
+        {
+            MethodTableContract MethodTableContract;
+        }
+        class DataStructureContract
+        {
+            string MethodTableName {get;}
+            List<Tuple<string, FieldLayout>> FieldData;
+        }
+        interface MethodTableContract : IContract
+        {
+            public virtual int DynamicTypeID(TargetPointer methodTablePointer) { throw new NotImplementedException(); }
+            public virtual int BaseSize(TargetPointer methodTablePointer) { throw new NotImplementedException(); }
+        }
+    }
+    namespace ContractImplementation
+    {
+        static class PredefinedContracts
+        {
+            public static IContract GetContract(string name, uint version, Target target)
+            {
+            }
+        }
+        [DataContractGlobals("FeatureFlags", 1)]
+        public class FeatureFlags_1
+        {
+            public const int FeatureComInterop = 0;
+        }
+        [DataContractGlobals("FeatureFlags", 2)]
+        public class FeatureFlags_2
+        {
+            public const int FeatureComInterop = 1;
+        }
+        [DataContractAlgorithm(1)]
+        readonly struct MethodTableContract_1 : Contracts.MethodTableContract
+        {
+            DataContracts.Target Target;
+            readonly uint ContractVersion;
+            public MethodTableContract_1(DataContracts.Target target, uint contractVersion) { Target = target; ContractVersion = contractVersion; }
+            public virtual int DynamicTypeID(TargetPointer methodTablePointer) { return new MethodTable(_target, methodTablePointer).dynamicTypeId; }
+            public virtual int BaseSize(TargetPointer methodTablePointer) { return new MethodTable(_target, methodTablePointer).baseSizeAndFlags & 0x3FFFFFFF; }
+        }
+        [DataContractAlgorithm(2, 3)]
+        readonly struct MethodTableContract_2 : Contracts.MethodTableContract
+        {
+            DataContracts.Target Target;
+            readonly uint ContractVersion;
+            public MethodTableContract_2(DataContracts.Target target, uint contractVersion) { Target = target; }
+            public virtual int DynamicTypeID(TargetPointer methodTablePointer)
+            {
+                throw new NotImplementedException();
+            }
+            public virtual int BaseSize(TargetPointer methodTablePointer)
+            {
+                return new MethodTable(_target, methodTablePointer).baseSizeAndFlags & ((ContractVersion == 3) ? 0x1FFFFFFF : 0x3FFFFFFF);
+            }
+        }
+        [DataContractType]
+        partial struct MethodTable
+        {
+            partial void Get_dynamicTypeId_optional(ref int value);
+            partial void Get_baseSizeAndFlags(ref int value);
+            [DataContractLayout(1, 8)]
+            public class DataLayout1
+            {
+                [FieldOffset(0)]
+                public int dynamicTypeId;
+                [FieldOffset(4)]
+                public int baseSize;
+            }
+            [DataContractLayout(2, 4)]
+            public class DataLayout2
+            {
+                [FieldOffset(0)]
+                public int baseSize;
+            }
+            public uint TypeSize => _layout.TypeSize;
+            void Get_dynamicTypeId_optional(ref int value)
+            {
+                value = dynamicTypeId;
+            }
+            void Get_baseSizeAndFlags(ref int value)
+            {
+                value = baseSizeAndFlags;
+            }
+            private static int LayoutIndex = DataContracts.Target.RegisterLayout(MethodTableLayout.GetLayoutByTarget);
+            public readonly TargetPointer Pointer;
+            private int _epoch;
+            private readonly MethodTableLayout _layout;
+            public MethodTable(DataContracts.Target target, TargetPointer pointer)
+            {
+                Pointer = pointer;
+                _epoch = Int32.MinInt;
+                _layout = target.GetLayoutByIndex(LayoutIndex);
+            }
+            class MethodTableLayout
+            {
+                public static object GetLayoutByTarget(DataContracts.Target target)
+                {
+                    return new MethodTableLayout(target);
+                }
+                public readonly uint TypeSize;
+                private MethodTableLayout(DataContracts.Target target)
+                {
+                    Target = target;
+                    TypeSize = target.Contract.GetTypeSize("MethodTable");
+                    if (!_target.Contract.TryGetFieldLayout("MethodTable", "dynamicTypeId", out var dynamicTypeIdField))
+                    {
+                        dynamicTypeId_Offset = -1;
+                    }
+                    else
+                    {
+                        if (dynamicTypeIdField.Type != FieldType.Int32Type)
+                            dynamicTypeId_Offset = -2;
+                        else
+                            dynamicTypeId_Offset = dynamicTypeIdField.Offset;
+                    }
+                    if (!_target.Contract.TryGetFieldLayout("MethodTable", "baseSizeAndFlags", out var baseSizeAndFlagsField))
+                    {
+                        baseSizeAndFlags_Offset = -1;
+                    }
+                    else
+                    {
+                        if (baseSizeAndFlagsField.Type != FieldType.Int32Type)
+                            baseSizeAndFlags_Offset = -2;
+                        else
+                            baseSizeAndFlags_Offset = baseSizeAndFlagsField.Offset;
+                    }
+                }
+                public readonly DataContracts.Target Target;
+                int dynamicTypeId_Offset;
+                public int dynamicTypeId(TargetPointer pointer)
+                {
+                    if (dynamicTypeId_Offset == -1)
+                    {
+                        throw new Exception("MethodTable has no field dynamicTypeId");
+                    }
+                    if (dynamicTypeId_Offset == -2)
+                    {
+                        throw new Exception("MethodTable field dynamicTypeId does not have type int32");
+                    }
+                    return _target.ReadInt32(pointer + dynamicTypeId_Offset);
+                }
+                public bool Has_dynamicTypeId => dynamicTypeId_Offset >= 0;
+                int baseSizeAndFlags_Offset;
+                public int baseSizeAndFlags(TargetPointer pointer)
+                {
+                    if (baseSizeAndFlags_Offset == -1)
+                    {
+                        throw new Exception("MethodTable has no field baseSizeAndFlags");
+                    }
+                    if (baseSizeAndFlags_Offset == -2)
+                    {
+                        throw new Exception("MethodTable field baseSizeAndFlags does not have type int32");
+                    }
+                    return _target.ReadInt32(pointer + baseSizeAndFlags_Offset);
+                }
+            }
+            private int _dynamicTypeId;
+            public int dynamicTypeId
+            {
+                get
+                {
+                    int currentEpoch = _layout.Target.CurrentEpoch;
+                    if (_epoch != currentEpoch)
+                    {
+                        _dynamicTypeId = _layout.dynamicTypeId(Pointer);
+                        _epoch = currentEpoch;
+                    }
+                    return _dynamicTypeId;
+                }
+            }
+            public bool Has_dynamicTypeId => layout.Has_dynamicTypeId;
+            private int _baseSizeAndFlags;
+            public int baseSizeAndFlags
+            {
+                get
+                {
+                    int currentEpoch = _layout.Target.CurrentEpoch;
+                    if (_epoch != currentEpoch)
+                    {
+                        _baseSizeAndFlags = _layout.baseSizeAndFlags(Pointer);
+                        _epoch = currentEpoch;
+                    }
+                    return _baseSizeAndFlags;
+                }
+            }
+        }
+    }
+}

--- a//dev/null
+++ b/eng/build.sh
@@ -0,0 +1,499 @@
+set -ue
+source="${BASH_SOURCE[0]}"
+while [[ -h "$source" ]]; do
+  scriptroot="$( cd -P "$( dirname "$source" )" && pwd )"
+  source="$(readlink "$source")"
+  [[ $source != /* ]] && source="$scriptroot/$source"
+done
+scriptroot="$( cd -P "$( dirname "$source" )" && pwd )"
+usage()
+{
+  echo "Common settings:"
+  echo "  --arch (-a)                     Target platform: x86, x64, arm, armv6, armel, arm64, loongarch64, riscv64, s390x, ppc64le or wasm."
+  echo "                                  [Default: Your machine's architecture.]"
+  echo "  --binaryLog (-bl)               Output binary log."
+  echo "  --cross                         Optional argument to signify cross compilation."
+  echo "  --configuration (-c)            Build configuration: Debug, Release or Checked."
+  echo "                                  Checked is exclusive to the CLR subset. It is the same as Debug, except code is"
+  echo "                                  compiled with optimizations enabled."
+  echo "                                  [Default: Debug]"
+  echo "  --help (-h)                     Print help and exit."
+  echo "  --hostConfiguration (-hc)       Host build configuration: Debug, Release or Checked."
+  echo "                                  [Default: Debug]"
+  echo "  --librariesConfiguration (-lc)  Libraries build configuration: Debug or Release."
+  echo "                                  [Default: Debug]"
+  echo "  --os                            Target operating system: windows, linux, freebsd, osx, maccatalyst, tvos,"
+  echo "                                  tvossimulator, ios, iossimulator, android, browser, wasi, netbsd, illumos, solaris"
+  echo "                                  linux-musl, linux-bionic, tizen, or haiku."
+  echo "                                  [Default: Your machine's OS.]"
+  echo "  --outputrid <rid>               Optional argument that overrides the target rid name."
+  echo "  --projects <value>              Project or solution file(s) to build."
+  echo "  --runtimeConfiguration (-rc)    Runtime build configuration: Debug, Release or Checked."
+  echo "                                  Checked is exclusive to the CLR runtime. It is the same as Debug, except code is"
+  echo "                                  compiled with optimizations enabled."
+  echo "                                  [Default: Debug]"
+  echo "  -runtimeFlavor (-rf)            Runtime flavor: CoreCLR or Mono."
+  echo "                                  [Default: CoreCLR]"
+  echo "  --subset (-s)                   Build a subset, print available subsets with -subset help."
+  echo "                                 '--subset' can be omitted if the subset is given as the first argument."
+  echo "                                  [Default: Builds the entire repo.]"
+  echo "  --usemonoruntime                Product a .NET runtime with Mono as the underlying runtime."
+  echo "  --verbosity (-v)                MSBuild verbosity: q[uiet], m[inimal], n[ormal], d[etailed], and diag[nostic]."
+  echo "                                  [Default: Minimal]"
+  echo ""
+  echo "Actions (defaults to --restore --build):"
+  echo "  --build (-b)               Build all source projects."
+  echo "                             This assumes --restore has been run already."
+  echo "  --clean                    Clean the solution."
+  echo "  --pack                     Package build outputs into NuGet packages."
+  echo "  --publish                  Publish artifacts (e.g. symbols)."
+  echo "                             This assumes --build has been run already."
+  echo "  --rebuild                  Rebuild all source projects."
+  echo "  --restore (-r)             Restore dependencies."
+  echo "  --sign                     Sign build outputs."
+  echo "  --test (-t)                Incrementally builds and runs tests."
+  echo "                             Use in conjunction with --testnobuild to only run tests."
+  echo ""
+  echo "Libraries settings:"
+  echo "  --allconfigurations        Build packages for all build configurations."
+  echo "  --coverage                 Collect code coverage when testing."
+  echo "  --framework (-f)           Build framework: net9.0 or net48."
+  echo "                             [Default: net9.0]"
+  echo "  --testnobuild              Skip building tests when invoking -test."
+  echo "  --testscope                Test scope, allowed values: innerloop, outerloop, all."
+  echo ""
+  echo "Native build settings:"
+  echo "  --clang                    Optional argument to build using clang in PATH (default)."
+  echo "  --clangx                   Optional argument to build using clang version x (used for Clang 7 and newer)."
+  echo "  --clangx.y                 Optional argument to build using clang version x.y (used for Clang 6 and older)."
+  echo "  --cmakeargs                User-settable additional arguments passed to CMake."
+  echo "  --gcc                      Optional argument to build using gcc in PATH (default)."
+  echo "  --gccx.y                   Optional argument to build using gcc version x.y."
+  echo "  --portablebuild            Optional argument: set to false to force a non-portable build."
+  echo "  --keepnativesymbols        Optional argument: set to true to keep native symbols/debuginfo in generated binaries."
+  echo "  --ninja                    Optional argument: set to true to use Ninja instead of Make to run the native build."
+  echo "  --pgoinstrument            Optional argument: build PGO-instrumented runtime"
+  echo "  --fsanitize                Optional argument: Specify native sanitizers to instrument the native build with. Supported values are: 'address'."
+  echo ""
+  echo "Command line arguments starting with '/p:' are passed through to MSBuild."
+  echo "Arguments can also be passed in with a single hyphen."
+  echo ""
+  echo "Here are some quick examples. These assume you are on a Linux x64 machine:"
+  echo ""
+  echo "* Build CoreCLR for Linux x64 on Release configuration:"
+  echo "./build.sh clr -c release"
+  echo ""
+  echo "* Build Debug libraries with a Release runtime for Linux x64."
+  echo "./build.sh clr+libs -rc release"
+  echo ""
+  echo "* Build Release libraries and their tests with a Checked runtime for Linux x64, and run the tests."
+  echo "./build.sh clr+libs+libs.tests -rc checked -lc release -test"
+  echo ""
+  echo "* Build CoreCLR for Linux x64 on Debug configuration using Clang 9."
+  echo "./build.sh clr -clang9"
+  echo ""
+  echo "* Build CoreCLR for Linux x64 on Debug configuration using GCC 8.4."
+  echo "./build.sh clr -gcc8.4"
+  echo ""
+  echo "* Build CoreCLR for Linux x64 using extra compiler flags (-fstack-clash-protection)."
+  echo "EXTRA_CFLAGS=-fstack-clash-protection EXTRA_CXXFLAGS=-fstack-clash-protection ./build.sh clr"
+  echo ""
+  echo "* Cross-compile CoreCLR runtime for Linux ARM64 on Release configuration."
+  echo "./build.sh clr.runtime -arch arm64 -c release -cross"
+  echo ""
+  echo "However, for this example, you need to already have ROOTFS_DIR set up."
+  echo "Further information on this can be found here:"
+  echo "https://github.com/dotnet/runtime/blob/main/docs/workflow/building/coreclr/linux-instructions.md"
+  echo ""
+  echo "* Build Mono runtime for Linux x64 on Release configuration."
+  echo "./build.sh mono -c release"
+  echo ""
+  echo "* Build Release coreclr corelib, crossgen corelib and update Debug libraries testhost to run test on an updated corelib."
+  echo "./build.sh clr.corelib+clr.nativecorelib+libs.pretest -rc release"
+  echo ""
+  echo "* Build Debug mono corelib and update Release libraries testhost to run test on an updated corelib."
+  echo "./build.sh mono.corelib+libs.pretest -rc debug -c release"
+  echo ""
+  echo ""
+  echo "For more general information, check out https://github.com/dotnet/runtime/blob/main/docs/workflow/README.md"
+}
+initDistroRid()
+{
+    source "$scriptroot"/common/native/init-distro-rid.sh
+    local passedRootfsDir=""
+    local targetOs="$1"
+    local targetArch="$2"
+    local isCrossBuild="$3"
+    if [[ $isCrossBuild == 1 && "$targetOs" != "osx" && "$targetOs" != "ios" && "$targetOs" != "iossimulator" && "$targetOs" != "tvos" && "$targetOs" != "tvossimulator" && "$targetOs" != "maccatalyst" ]]; then
+        passedRootfsDir=${ROOTFS_DIR}
+    fi
+    initDistroRidGlobal "${targetOs}" "${targetArch}" "${passedRootfsDir}"
+}
+showSubsetHelp()
+{
+  "$scriptroot/common/build.sh" "-restore" "-build" "/p:Subset=help" "/clp:nosummary /tl:false"
+}
+arguments=''
+cmakeargs=''
+extraargs=''
+crossBuild=0
+portableBuild=1
+source $scriptroot/common/native/init-os-and-arch.sh
+hostArch=$arch
+declare -a actions=("b" "build" "r" "restore" "rebuild" "testnobuild" "sign" "publish" "clean")
+actInt=($(comm -12 <(printf '%s\n' "${actions[@]/#/-}" | sort) <(printf '%s\n' "${@/#--/-}" | sort)))
+firstArgumentChecked=0
+while [[ $# > 0 ]]; do
+  opt="$(echo "${1/#--/-}" | tr "[:upper:]" "[:lower:]")"
+  if [[ $firstArgumentChecked -eq 0 && $opt =~ ^[a-zA-Z.+]+$ ]]; then
+    if [[ "$opt" == "help" ]]; then
+      showSubsetHelp
+      exit 0
+    fi
+    arguments="$arguments /p:Subset=$1"
+    shift 1
+    continue
+  fi
+  firstArgumentChecked=1
+  case "$opt" in
+     -help|-h|-\?|/?)
+      usage
+      exit 0
+      ;;
+     -subset|-s)
+      if [ -z ${2+x} ]; then
+        showSubsetHelp
+        exit 0
+      else
+        passedSubset="$(echo "$2" | tr "[:upper:]" "[:lower:]")"
+        if [[ "$passedSubset" == "help" ]]; then
+          showSubsetHelp
+          exit 0
+        fi
+        arguments="$arguments /p:Subset=$2"
+        shift 2
+      fi
+      ;;
+     -arch|-a)
+      if [ -z ${2+x} ]; then
+        echo "No architecture supplied. See help (--help) for supported architectures." 1>&2
+        exit 1
+      fi
+      passedArch="$(echo "$2" | tr "[:upper:]" "[:lower:]")"
+      case "$passedArch" in
+        x64|x86|arm|armv6|armel|arm64|loongarch64|riscv64|s390x|ppc64le|wasm)
+          arch=$passedArch
+          ;;
+        *)
+          echo "Unsupported target architecture '$2'."
+          echo "The allowed values are x86, x64, arm, armv6, armel, arm64, loongarch64, riscv64, s390x, ppc64le and wasm."
+          exit 1
+          ;;
+      esac
+      shift 2
+      ;;
+     -configuration|-c)
+      if [ -z ${2+x} ]; then
+        echo "No configuration supplied. See help (--help) for supported configurations." 1>&2
+        exit 1
+      fi
+      passedConfig="$(echo "$2" | tr "[:upper:]" "[:lower:]")"
+      case "$passedConfig" in
+        debug|release|checked)
+          val="$(tr '[:lower:]' '[:upper:]' <<< ${passedConfig:0:1})${passedConfig:1}"
+          ;;
+        *)
+          echo "Unsupported target configuration '$2'."
+          echo "The allowed values are Debug, Release, and Checked."
+          exit 1
+          ;;
+      esac
+      arguments="$arguments -configuration $val"
+      shift 2
+      ;;
+     -framework|-f)
+      if [ -z ${2+x} ]; then
+        echo "No framework supplied. See help (--help) for supported frameworks." 1>&2
+        exit 1
+      fi
+      val="$(echo "$2" | tr "[:upper:]" "[:lower:]")"
+      arguments="$arguments /p:BuildTargetFramework=$val"
+      shift 2
+      ;;
+     -os)
+      if [ -z ${2+x} ]; then
+        echo "No target operating system supplied. See help (--help) for supported target operating systems." 1>&2
+        exit 1
+      fi
+      passedOS="$(echo "$2" | tr "[:upper:]" "[:lower:]")"
+      case "$passedOS" in
+        windows)
+          os="windows" ;;
+        linux)
+          os="linux" ;;
+        freebsd)
+          os="freebsd" ;;
+        osx)
+          os="osx" ;;
+        maccatalyst)
+          os="maccatalyst" ;;
+        tvos)
+          os="tvos" ;;
+        tvossimulator)
+          os="tvossimulator" ;;
+        ios)
+          os="ios" ;;
+        iossimulator)
+          os="iossimulator" ;;
+        android)
+          os="android" ;;
+        browser)
+          os="browser" ;;
+        wasi)
+          os="wasi" ;;
+        illumos)
+          os="illumos" ;;
+        solaris)
+          os="solaris" ;;
+        linux-bionic)
+          os="linux"
+          __PortableTargetOS=linux-bionic
+          ;;
+        linux-musl)
+          os="linux"
+          __PortableTargetOS=linux-musl
+          ;;
+        haiku)
+          os="haiku" ;;
+        *)
+          echo "Unsupported target OS '$2'."
+          echo "Try 'build.sh --help' for values supported by '--os'."
+          exit 1
+          ;;
+      esac
+      arguments="$arguments /p:TargetOS=$os"
+      shift 2
+      ;;
+     -allconfigurations)
+      arguments="$arguments /p:BuildAllConfigurations=true"
+      shift 1
+      ;;
+     -testscope)
+      if [ -z ${2+x} ]; then
+        echo "No test scope supplied. See help (--help) for supported test scope values." 1>&2
+        exit 1
+      fi
+      arguments="$arguments /p:TestScope=$2"
+      shift 2
+      ;;
+     -testnobuild)
+      arguments="$arguments /p:TestNoBuild=true"
+      shift 1
+      ;;
+     -coverage)
+      arguments="$arguments /p:Coverage=true"
+      shift 1
+      ;;
+     -runtimeconfiguration|-rc)
+      if [ -z ${2+x} ]; then
+        echo "No runtime configuration supplied. See help (--help) for supported runtime configurations." 1>&2
+        exit 1
+      fi
+      passedRuntimeConf="$(echo "$2" | tr "[:upper:]" "[:lower:]")"
+      case "$passedRuntimeConf" in
+        debug|release|checked)
+          val="$(tr '[:lower:]' '[:upper:]' <<< ${passedRuntimeConf:0:1})${passedRuntimeConf:1}"
+          ;;
+        *)
+          echo "Unsupported runtime configuration '$2'."
+          echo "The allowed values are Debug, Release, and Checked."
+          exit 1
+          ;;
+      esac
+      arguments="$arguments /p:RuntimeConfiguration=$val"
+      shift 2
+      ;;
+     -runtimeflavor|-rf)
+      if [ -z ${2+x} ]; then
+        echo "No runtime flavor supplied. See help (--help) for supported runtime flavors." 1>&2
+        exit 1
+      fi
+      passedRuntimeFlav="$(echo "$2" | tr "[:upper:]" "[:lower:]")"
+      case "$passedRuntimeFlav" in
+        coreclr|mono)
+          val="$(tr '[:lower:]' '[:upper:]' <<< ${passedRuntimeFlav:0:1})${passedRuntimeFlav:1}"
+          ;;
+        *)
+          echo "Unsupported runtime flavor '$2'."
+          echo "The allowed values are CoreCLR and Mono."
+          exit 1
+          ;;
+      esac
+      arguments="$arguments /p:RuntimeFlavor=$val"
+      shift 2
+      ;;
+     -usemonoruntime)
+      arguments="$arguments /p:PrimaryRuntimeFlavor=Mono"
+      shift 1
+      ;;
+     -librariesconfiguration|-lc)
+      if [ -z ${2+x} ]; then
+        echo "No libraries configuration supplied. See help (--help) for supported libraries configurations." 1>&2
+        exit 1
+      fi
+      passedLibConf="$(echo "$2" | tr "[:upper:]" "[:lower:]")"
+      case "$passedLibConf" in
+        debug|release)
+          val="$(tr '[:lower:]' '[:upper:]' <<< ${passedLibConf:0:1})${passedLibConf:1}"
+          ;;
+        *)
+          echo "Unsupported libraries configuration '$2'."
+          echo "The allowed values are Debug and Release."
+          exit 1
+          ;;
+      esac
+      arguments="$arguments /p:LibrariesConfiguration=$val"
+      shift 2
+      ;;
+     -hostconfiguration|-hc)
+      if [ -z ${2+x} ]; then
+        echo "No host configuration supplied. See help (--help) for supported host configurations." 1>&2
+        exit 1
+      fi
+      passedHostConf="$(echo "$2" | tr "[:upper:]" "[:lower:]")"
+      case "$passedHostConf" in
+        debug|release|checked)
+          val="$(tr '[:lower:]' '[:upper:]' <<< ${passedHostConf:0:1})${passedHostConf:1}"
+          ;;
+        *)
+          echo "Unsupported host configuration '$2'."
+          echo "The allowed values are Debug, Release, and Checked."
+          exit 1
+          ;;
+      esac
+      arguments="$arguments /p:HostConfiguration=$val"
+      shift 2
+      ;;
+     -cross)
+      crossBuild=1
+      arguments="$arguments /p:CrossBuild=True"
+      shift 1
+      ;;
+     *crossbuild=true*)
+      crossBuild=1
+      extraargs="$extraargs $1"
+      shift 1
+      ;;
+     -clang*)
+      compiler="${opt/#-/}" # -clang-9 => clang-9 or clang-9 => (unchanged)
+      arguments="$arguments /p:Compiler=$compiler /p:CppCompilerAndLinker=$compiler"
+      shift 1
+      ;;
+     -cmakeargs)
+      if [ -z ${2+x} ]; then
+        echo "No cmake args supplied." 1>&2
+        exit 1
+      fi
+      cmakeargs="${cmakeargs} $2"
+      shift 2
+      ;;
+     -gcc*)
+      compiler="${opt/#-/}" # -gcc-9 => gcc-9 or gcc-9 => (unchanged)
+      arguments="$arguments /p:Compiler=$compiler /p:CppCompilerAndLinker=$compiler"
+      shift 1
+      ;;
+     -outputrid)
+      if [ -z ${2+x} ]; then
+        echo "No value for outputrid is supplied. See help (--help) for supported values." 1>&2
+        exit 1
+      fi
+      arguments="$arguments /p:OutputRID=$(echo "$2" | tr "[:upper:]" "[:lower:]")"
+      shift 2
+      ;;
+     -portablebuild)
+      if [ -z ${2+x} ]; then
+        echo "No value for portablebuild is supplied. See help (--help) for supported values." 1>&2
+        exit 1
+      fi
+      passedPortable="$(echo "$2" | tr "[:upper:]" "[:lower:]")"
+      if [ "$passedPortable" = false ]; then
+        portableBuild=0
+        arguments="$arguments /p:PortableBuild=false"
+      fi
+      shift 2
+      ;;
+     -keepnativesymbols)
+      if [ -z ${2+x} ]; then
+        echo "No value for keepNativeSymbols is supplied. See help (--help) for supported values." 1>&2
+        exit 1
+      fi
+      passedKeepNativeSymbols="$(echo "$2" | tr "[:upper:]" "[:lower:]")"
+      if [ "$passedKeepNativeSymbols" = true ]; then
+        arguments="$arguments /p:KeepNativeSymbols=true"
+      fi
+      shift 2
+      ;;
+      -ninja)
+      if [ -z ${2+x} ]; then
+        arguments="$arguments /p:Ninja=true"
+        shift 1
+      else
+        ninja="$(echo "$2" | tr "[:upper:]" "[:lower:]")"
+        if [ "$ninja" = true ]; then
+          arguments="$arguments /p:Ninja=true"
+          shift 2
+        elif [ "$ninja" = false ]; then
+          arguments="$arguments /p:Ninja=false"
+          shift 2
+        else
+          arguments="$arguments /p:Ninja=true"
+          shift 1
+        fi
+      fi
+      ;;
+      -pgoinstrument)
+      arguments="$arguments /p:PgoInstrument=true"
+      shift 1
+      ;;
+      -fsanitize)
+      if [ -z ${2+x} ]; then
+        echo "No value for -fsanitize is supplied. See help (--help) for supported values." 1>&2
+        exit 1
+      fi
+      arguments="$arguments /p:EnableNativeSanitizers=$2"
+      shift 2
+      ;;
+      -fsanitize=*)
+      sanitizers="${opt/#-fsanitize=/}" # -fsanitize=address => address
+      arguments="$arguments /p:EnableNativeSanitizers=$sanitizers"
+      shift 2
+      ;;
+      -verbose)
+      arguments="$arguments /p:CoreclrVerbose=true"
+      shift 1
+      ;;
+      *)
+      extraargs="$extraargs $1"
+      shift 1
+      ;;
+  esac
+done
+if [ ${#actInt[@]} -eq 0 ]; then
+    arguments="-restore -build $arguments"
+fi
+if [[ "$os" == "browser" ]]; then
+    arch=wasm
+fi
+if [[ "$os" == "wasi" ]]; then
+    arch=wasm
+fi
+if [[ "${TreatWarningsAsErrors:-}" == "false" ]]; then
+    arguments="$arguments -warnAsError 0"
+fi
+arguments="$arguments -tl:false"
+initDistroRid "$os" "$arch" "$crossBuild"
+export DOTNETSDK_ALLOW_TARGETING_PACK_CACHING=0
+cmakeargs="${cmakeargs// /%20}"
+arguments="$arguments /p:TargetArchitecture=$arch /p:BuildArchitecture=$hostArch"
+arguments="$arguments /p:CMakeArgs=\"$cmakeargs\" $extraargs"
+"$scriptroot/common/build.sh" $arguments

--- a//dev/null
+++ b/eng/common/SetupNugetSources.sh
@@ -0,0 +1,108 @@
+ConfigFile=$1
+CredToken=$2
+NL='\n'
+TB='    '
+source="${BASH_SOURCE[0]}"
+while [[ -h "$source" ]]; do
+  scriptroot="$( cd -P "$( dirname "$source" )" && pwd )"
+  source="$(readlink "$source")"
+  [[ $source != /* ]] && source="$scriptroot/$source"
+done
+scriptroot="$( cd -P "$( dirname "$source" )" && pwd )"
+. "$scriptroot/tools.sh"
+if [ ! -f "$ConfigFile" ]; then
+    Write-PipelineTelemetryError -Category 'Build' "Error: Eng/common/SetupNugetSources.sh returned a non-zero exit code. Couldn't find the NuGet config file: $ConfigFile"
+    ExitWithExitCode 1
+fi
+if [[ `uname -s` == "Darwin" ]]; then
+    NL=$'\\\n'
+    TB=''
+fi
+grep -i "<packageSources>" $ConfigFile
+if [ "$?" != "0" ]; then
+    echo "Adding <packageSources>...</packageSources> section."
+    ConfigNodeHeader="<configuration>"
+    PackageSourcesTemplate="${TB}<packageSources>${NL}${TB}</packageSources>"
+    sed -i.bak "s|$ConfigNodeHeader|$ConfigNodeHeader${NL}$PackageSourcesTemplate|" $ConfigFile
+fi
+grep -i "<packageSourceCredentials>" $ConfigFile
+if [ "$?" != "0" ]; then
+    echo "Adding <packageSourceCredentials>...</packageSourceCredentials> section."
+    PackageSourcesNodeFooter="</packageSources>"
+    PackageSourceCredentialsTemplate="${TB}<packageSourceCredentials>${NL}${TB}</packageSourceCredentials>"
+    sed -i.bak "s|$PackageSourcesNodeFooter|$PackageSourcesNodeFooter${NL}$PackageSourceCredentialsTemplate|" $ConfigFile
+fi
+PackageSources=()
+grep -i "<add key=\"dotnet3.1\"" $ConfigFile
+if [ "$?" == "0" ]; then
+    grep -i "<add key=\"dotnet3.1-internal\"" $ConfigFile
+    if [ "$?" != "0" ]; then
+        echo "Adding dotnet3.1-internal to the packageSources."
+        PackageSourcesNodeFooter="</packageSources>"
+        PackageSourceTemplate="${TB}<add key=\"dotnet3.1-internal\" value=\"https://pkgs.dev.azure.com/dnceng/_packaging/dotnet3.1-internal/nuget/v2\" />"
+        sed -i.bak "s|$PackageSourcesNodeFooter|$PackageSourceTemplate${NL}$PackageSourcesNodeFooter|" $ConfigFile
+    fi
+    PackageSources+=('dotnet3.1-internal')
+    grep -i "<add key=\"dotnet3.1-internal-transport\">" $ConfigFile
+    if [ "$?" != "0" ]; then
+        echo "Adding dotnet3.1-internal-transport to the packageSources."
+        PackageSourcesNodeFooter="</packageSources>"
+        PackageSourceTemplate="${TB}<add key=\"dotnet3.1-internal-transport\" value=\"https://pkgs.dev.azure.com/dnceng/_packaging/dotnet3.1-internal-transport/nuget/v2\" />"
+        sed -i.bak "s|$PackageSourcesNodeFooter|$PackageSourceTemplate${NL}$PackageSourcesNodeFooter|" $ConfigFile
+    fi
+    PackageSources+=('dotnet3.1-internal-transport')
+fi
+DotNetVersions=('5' '6' '7' '8' '9')
+for DotNetVersion in ${DotNetVersions[@]} ; do
+    FeedPrefix="dotnet${DotNetVersion}";
+    grep -i "<add key=\"$FeedPrefix\"" $ConfigFile
+    if [ "$?" == "0" ]; then
+        grep -i "<add key=\"$FeedPrefix-internal\"" $ConfigFile
+        if [ "$?" != "0" ]; then
+            echo "Adding $FeedPrefix-internal to the packageSources."
+            PackageSourcesNodeFooter="</packageSources>"
+            PackageSourceTemplate="${TB}<add key=\"$FeedPrefix-internal\" value=\"https://pkgs.dev.azure.com/dnceng/internal/_packaging/$FeedPrefix-internal/nuget/v2\" />"
+            sed -i.bak "s|$PackageSourcesNodeFooter|$PackageSourceTemplate${NL}$PackageSourcesNodeFooter|" $ConfigFile
+        fi
+        PackageSources+=("$FeedPrefix-internal")
+        grep -i "<add key=\"$FeedPrefix-internal-transport\">" $ConfigFile
+        if [ "$?" != "0" ]; then
+            echo "Adding $FeedPrefix-internal-transport to the packageSources."
+            PackageSourcesNodeFooter="</packageSources>"
+            PackageSourceTemplate="${TB}<add key=\"$FeedPrefix-internal-transport\" value=\"https://pkgs.dev.azure.com/dnceng/internal/_packaging/$FeedPrefix-internal-transport/nuget/v2\" />"
+            sed -i.bak "s|$PackageSourcesNodeFooter|$PackageSourceTemplate${NL}$PackageSourcesNodeFooter|" $ConfigFile
+        fi
+        PackageSources+=("$FeedPrefix-internal-transport")
+    fi
+done
+PrevIFS=$IFS
+IFS=$'\n'
+PackageSources+="$IFS"
+PackageSources+=$(grep -oh '"darc-int-[^"]*"' $ConfigFile | tr -d '"')
+IFS=$PrevIFS
+if [ "$CredToken" ]; then
+    for FeedName in ${PackageSources[@]} ; do
+        grep -i "<$FeedName>" $ConfigFile 
+        if [ "$?" != "0" ]; then
+            echo "Adding credentials for $FeedName."
+            PackageSourceCredentialsNodeFooter="</packageSourceCredentials>"
+            NewCredential="${TB}${TB}<$FeedName>${NL}<add key=\"Username\" value=\"dn-bot\" />${NL}<add key=\"ClearTextPassword\" value=\"$CredToken\" />${NL}</$FeedName>"
+            sed -i.bak "s|$PackageSourceCredentialsNodeFooter|$NewCredential${NL}$PackageSourceCredentialsNodeFooter|" $ConfigFile
+        fi
+    done
+fi
+grep -i "<disabledPackageSources>" $ConfigFile
+if [ "$?" == "0" ]; then
+    DisabledDarcIntSources=()
+    echo "Re-enabling any disabled \"darc-int\" package sources in $ConfigFile"
+    DisabledDarcIntSources+=$(grep -oh '"darc-int-[^"]*" value="true"' $ConfigFile  | tr -d '"')
+    for DisabledSourceName in ${DisabledDarcIntSources[@]} ; do
+        if [[ $DisabledSourceName == darc-int* ]]
+            then
+                OldDisableValue="<add key=\"$DisabledSourceName\" value=\"true\" />"
+                NewDisableValue="<!-- Reenabled for build : $DisabledSourceName -->"
+                sed -i.bak "s|$OldDisableValue|$NewDisableValue|" $ConfigFile
+                echo "Neutralized disablePackageSources entry for '$DisabledSourceName'"
+        fi
+    done
+fi

--- a//dev/null
+++ b/eng/common/build.sh
@@ -0,0 +1,228 @@
+set -u
+set -e
+usage()
+{
+  echo "Common settings:"
+  echo "  --configuration <value>    Build configuration: 'Debug' or 'Release' (short: -c)"
+  echo "  --verbosity <value>        Msbuild verbosity: q[uiet], m[inimal], n[ormal], d[etailed], and diag[nostic] (short: -v)"
+  echo "  --binaryLog                Create MSBuild binary log (short: -bl)"
+  echo "  --help                     Print help and exit (short: -h)"
+  echo ""
+  echo "Actions:"
+  echo "  --restore                  Restore dependencies (short: -r)"
+  echo "  --build                    Build solution (short: -b)"
+  echo "  --sourceBuild              Source-build the solution (short: -sb)"
+  echo "                             Will additionally trigger the following actions: --restore, --build, --pack"
+  echo "                             If --configuration is not set explicitly, will also set it to 'Release'"
+  echo "  --productBuild             Build the solution in the way it will be built in the full .NET product (VMR) build (short: -pb)"
+  echo "                             Will additionally trigger the following actions: --restore, --build, --pack"
+  echo "                             If --configuration is not set explicitly, will also set it to 'Release'"
+  echo "  --rebuild                  Rebuild solution"
+  echo "  --test                     Run all unit tests in the solution (short: -t)"
+  echo "  --integrationTest          Run all integration tests in the solution"
+  echo "  --performanceTest          Run all performance tests in the solution"
+  echo "  --pack                     Package build outputs into NuGet packages and Willow components"
+  echo "  --sign                     Sign build outputs"
+  echo "  --publish                  Publish artifacts (e.g. symbols)"
+  echo "  --clean                    Clean the solution"
+  echo ""
+  echo "Advanced settings:"
+  echo "  --projects <value>       Project or solution file(s) to build"
+  echo "  --ci                     Set when running on CI server"
+  echo "  --excludeCIBinarylog     Don't output binary log (short: -nobl)"
+  echo "  --prepareMachine         Prepare machine for CI run, clean up processes after build"
+  echo "  --nodeReuse <value>      Sets nodereuse msbuild parameter ('true' or 'false')"
+  echo "  --warnAsError <value>    Sets warnaserror msbuild parameter ('true' or 'false')"
+  echo ""
+  echo "Command line arguments not listed above are passed thru to msbuild."
+  echo "Arguments can also be passed in with a single hyphen."
+}
+source="${BASH_SOURCE[0]}"
+while [[ -h "$source" ]]; do
+  scriptroot="$( cd -P "$( dirname "$source" )" && pwd )"
+  source="$(readlink "$source")"
+  [[ $source != /* ]] && source="$scriptroot/$source"
+done
+scriptroot="$( cd -P "$( dirname "$source" )" && pwd )"
+restore=false
+build=false
+source_build=false
+product_build=false
+rebuild=false
+test=false
+integration_test=false
+performance_test=false
+pack=false
+publish=false
+sign=false
+public=false
+ci=false
+clean=false
+warn_as_error=true
+node_reuse=true
+binary_log=false
+exclude_ci_binary_log=false
+pipelines_log=false
+projects=''
+configuration=''
+prepare_machine=false
+verbosity='minimal'
+runtime_source_feed=''
+runtime_source_feed_key=''
+properties=''
+while [[ $# > 0 ]]; do
+  opt="$(echo "${1/#--/-}" | tr "[:upper:]" "[:lower:]")"
+  case "$opt" in
+    -help|-h)
+      usage
+      exit 0
+      ;;
+    -clean)
+      clean=true
+      ;;
+    -configuration|-c)
+      configuration=$2
+      shift
+      ;;
+    -verbosity|-v)
+      verbosity=$2
+      shift
+      ;;
+    -binarylog|-bl)
+      binary_log=true
+      ;;
+    -excludecibinarylog|-nobl)
+      exclude_ci_binary_log=true
+      ;;
+    -pipelineslog|-pl)
+      pipelines_log=true
+      ;;
+    -restore|-r)
+      restore=true
+      ;;
+    -build|-b)
+      build=true
+      ;;
+    -rebuild)
+      rebuild=true
+      ;;
+    -pack)
+      pack=true
+      ;;
+    -sourcebuild|-sb)
+      build=true
+      source_build=true
+      product_build=true
+      restore=true
+      pack=true
+      ;;
+    -productBuild|-pb)
+      build=true
+      product_build=true
+      restore=true
+      pack=true
+      ;;
+    -test|-t)
+      test=true
+      ;;
+    -integrationtest)
+      integration_test=true
+      ;;
+    -performancetest)
+      performance_test=true
+      ;;
+    -sign)
+      sign=true
+      ;;
+    -publish)
+      publish=true
+      ;;
+    -preparemachine)
+      prepare_machine=true
+      ;;
+    -projects)
+      projects=$2
+      shift
+      ;;
+    -ci)
+      ci=true
+      ;;
+    -warnaserror)
+      warn_as_error=$2
+      shift
+      ;;
+    -nodereuse)
+      node_reuse=$2
+      shift
+      ;;
+    -runtimesourcefeed)
+      runtime_source_feed=$2
+      shift
+      ;;
+     -runtimesourcefeedkey)
+      runtime_source_feed_key=$2
+      shift
+      ;;
+    *)
+      properties="$properties $1"
+      ;;
+  esac
+  shift
+done
+if [[ -z "$configuration" ]]; then
+  if [[ "$source_build" = true ]]; then configuration="Release"; else configuration="Debug"; fi
+fi
+if [[ "$ci" == true ]]; then
+  pipelines_log=true
+  node_reuse=false
+  if [[ "$exclude_ci_binary_log" == false ]]; then
+    binary_log=true
+  fi
+fi
+. "$scriptroot/tools.sh"
+function InitializeCustomToolset {
+  local script="$eng_root/restore-toolset.sh"
+  if [[ -a "$script" ]]; then
+    . "$script"
+  fi
+}
+function Build {
+  InitializeToolset
+  InitializeCustomToolset
+  if [[ ! -z "$projects" ]]; then
+    properties="$properties /p:Projects=$projects"
+  fi
+  local bl=""
+  if [[ "$binary_log" == true ]]; then
+    bl="/bl:\"$log_dir/Build.binlog\""
+  fi
+  MSBuild $_InitializeToolset \
+    $bl \
+    /p:Configuration=$configuration \
+    /p:RepoRoot="$repo_root" \
+    /p:Restore=$restore \
+    /p:Build=$build \
+    /p:DotNetBuildRepo=$product_build \
+    /p:ArcadeBuildFromSource=$source_build \
+    /p:DotNetBuildSourceOnly=$source_build \
+    /p:Rebuild=$rebuild \
+    /p:Test=$test \
+    /p:Pack=$pack \
+    /p:IntegrationTest=$integration_test \
+    /p:PerformanceTest=$performance_test \
+    /p:Sign=$sign \
+    /p:Publish=$publish \
+    $properties
+  ExitWithExitCode 0
+}
+if [[ "$clean" == true ]]; then
+  if [ -d "$artifacts_dir" ]; then
+    rm -rf $artifacts_dir
+    echo "Artifacts directory deleted."
+  fi
+  exit 0
+fi
+if [[ "$restore" == true ]]; then
+  InitializeNativeTools
+fi
+Build

--- a//dev/null
+++ b/eng/common/cross/build-android-rootfs.sh
@@ -0,0 +1,105 @@
+set -e
+__NDK_Version=r21
+usage()
+{
+    echo "Creates a toolchain and sysroot used for cross-compiling for Android."
+    echo
+    echo "Usage: $0 [BuildArch] [ApiLevel]"
+    echo
+    echo "BuildArch is the target architecture of Android. Currently only arm64 is supported."
+    echo "ApiLevel is the target Android API level. API levels usually match to Android releases. See https://source.android.com/source/build-numbers.html"
+    echo
+    echo "By default, the toolchain and sysroot will be generated in cross/android-rootfs/toolchain/[BuildArch]. You can change this behavior"
+    echo "by setting the TOOLCHAIN_DIR environment variable"
+    echo
+    echo "By default, the NDK will be downloaded into the cross/android-rootfs/android-ndk-$__NDK_Version directory. If you already have an NDK installation,"
+    echo "you can set the NDK_DIR environment variable to have this script use that installation of the NDK."
+    echo "By default, this script will generate a file, android_platform, in the root of the ROOTFS_DIR directory that contains the RID for the supported and tested Android build: android.28-arm64. This file is to replace '/etc/os-release', which is not available for Android."
+    exit 1
+}
+__ApiLevel=28 # The minimum platform for arm64 is API level 21 but the minimum version that support glob(3) is 28. See $ANDROID_NDK/toolchains/llvm/prebuilt/linux-x86_64/sysroot/usr/include/glob.h
+__BuildArch=arm64
+__AndroidArch=aarch64
+__AndroidToolchain=aarch64-linux-android
+for i in "$@"
+    do
+        lowerI="$(echo $i | tr "[:upper:]" "[:lower:]")"
+        case $lowerI in
+        -?|-h|--help)
+            usage
+            exit 1
+            ;;
+        arm64)
+            __BuildArch=arm64
+            __AndroidArch=aarch64
+            __AndroidToolchain=aarch64-linux-android
+            ;;
+        arm)
+            __BuildArch=arm
+            __AndroidArch=arm
+            __AndroidToolchain=arm-linux-androideabi
+            ;;
+        *[0-9])
+            __ApiLevel=$i
+            ;;
+        *)
+            __UnprocessedBuildArgs="$__UnprocessedBuildArgs $i"
+            ;;
+    esac
+done
+__ScriptBaseDir="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
+__CrossDir="$__ScriptBaseDir/../../../.tools/android-rootfs"
+if [[ ! -f "$__CrossDir" ]]; then
+    mkdir -p "$__CrossDir"
+fi
+__CrossDir="$( cd "$__CrossDir" && pwd )"
+__NDK_Dir="$__CrossDir/android-ndk-$__NDK_Version"
+__lldb_Dir="$__CrossDir/lldb"
+__ToolchainDir="$__CrossDir/android-ndk-$__NDK_Version"
+if [[ -n "$TOOLCHAIN_DIR" ]]; then
+    __ToolchainDir=$TOOLCHAIN_DIR
+fi
+if [[ -n "$NDK_DIR" ]]; then
+    __NDK_Dir=$NDK_DIR
+fi
+echo "Target API level: $__ApiLevel"
+echo "Target architecture: $__BuildArch"
+echo "NDK location: $__NDK_Dir"
+echo "Target Toolchain location: $__ToolchainDir"
+if [ ! -d $__NDK_Dir ]; then
+    echo Downloading the NDK into $__NDK_Dir
+    mkdir -p $__NDK_Dir
+    wget -q --progress=bar:force:noscroll --show-progress https://dl.google.com/android/repository/android-ndk-$__NDK_Version-linux-x86_64.zip -O $__CrossDir/android-ndk-$__NDK_Version-linux-x86_64.zip
+    unzip -q $__CrossDir/android-ndk-$__NDK_Version-linux-x86_64.zip -d $__CrossDir
+fi
+if [ ! -d $__lldb_Dir ]; then
+    mkdir -p $__lldb_Dir
+    echo Downloading LLDB into $__lldb_Dir
+    wget -q --progress=bar:force:noscroll --show-progress https://dl.google.com/android/repository/lldb-2.3.3614996-linux-x86_64.zip -O $__CrossDir/lldb-2.3.3614996-linux-x86_64.zip
+    unzip -q $__CrossDir/lldb-2.3.3614996-linux-x86_64.zip -d $__lldb_Dir
+fi
+echo "Download dependencies..."
+__TmpDir=$__CrossDir/tmp/$__BuildArch/
+mkdir -p "$__TmpDir"
+__AndroidPackages="libicu"
+__AndroidPackages+=" libandroid-glob"
+__AndroidPackages+=" liblzma"
+__AndroidPackages+=" krb5"
+__AndroidPackages+=" openssl"
+for path in $(wget -qO- https://packages.termux.dev/termux-main-21/dists/stable/main/binary-$__AndroidArch/Packages |\
+    grep -A15 "Package: \(${__AndroidPackages// /\\|}\)" | grep -v "static\|tool" | grep Filename); do
+    if [[ "$path" != "Filename:" ]]; then
+        echo "Working on: $path"
+        wget -qO- https://packages.termux.dev/termux-main-21/$path | dpkg -x - "$__TmpDir"
+    fi
+done
+cp -R "$__TmpDir/data/data/com.termux/files/usr/"* "$__ToolchainDir/sysroot/usr/"
+echo "Generating platform file..."
+echo "RID=android.${__ApiLevel}-${__BuildArch}" > $__ToolchainDir/sysroot/android_platform
+echo "Now to build coreclr, libraries and installers; run:"
+echo ROOTFS_DIR=\$\(realpath $__ToolchainDir/sysroot\) ./build.sh --cross --arch $__BuildArch \
+    --subsetCategory coreclr
+echo ROOTFS_DIR=\$\(realpath $__ToolchainDir/sysroot\) ./build.sh --cross --arch $__BuildArch \
+    --subsetCategory libraries
+echo ROOTFS_DIR=\$\(realpath $__ToolchainDir/sysroot\) ./build.sh --cross --arch $__BuildArch \
+    --subsetCategory installer

--- a//dev/null
+++ b/eng/common/cross/build-rootfs.sh
@@ -0,0 +1,679 @@
+set -e
+usage()
+{
+    echo "Usage: $0 [BuildArch] [CodeName] [lldbx.y] [llvmx[.y]] [--skipunmount] --rootfsdir <directory>]"
+    echo "BuildArch can be: arm(default), arm64, armel, armv6, ppc64le, riscv64, s390x, x64, x86"
+    echo "CodeName - optional, Code name for Linux, can be: xenial(default), zesty, bionic, alpine"
+    echo "                               for alpine can be specified with version: alpineX.YY or alpineedge"
+    echo "                               for FreeBSD can be: freebsd13, freebsd14"
+    echo "                               for illumos can be: illumos"
+    echo "                               for Haiku can be: haiku."
+    echo "lldbx.y - optional, LLDB version, can be: lldb3.9(default), lldb4.0, lldb5.0, lldb6.0 no-lldb. Ignored for alpine and FreeBSD"
+    echo "llvmx[.y] - optional, LLVM version for LLVM related packages."
+    echo "--skipunmount - optional, will skip the unmount of rootfs folder."
+    echo "--skipsigcheck - optional, will skip package signature checks (allowing untrusted packages)."
+    echo "--use-mirror - optional, use mirror URL to fetch resources, when available."
+    echo "--jobs N - optional, restrict to N jobs."
+    exit 1
+}
+__CodeName=xenial
+__CrossDir=$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )
+__BuildArch=arm
+__AlpineArch=armv7
+__FreeBSDArch=arm
+__FreeBSDMachineArch=armv7
+__IllumosArch=arm7
+__HaikuArch=arm
+__QEMUArch=arm
+__UbuntuArch=armhf
+__UbuntuRepo=
+__UbuntuSuites="updates security backports"
+__LLDB_Package="liblldb-3.9-dev"
+__SkipUnmount=0
+__UbuntuPackages="build-essential"
+__AlpinePackages="alpine-base"
+__AlpinePackages+=" build-base"
+__AlpinePackages+=" linux-headers"
+__AlpinePackages+=" lldb-dev"
+__AlpinePackages+=" python3"
+__AlpinePackages+=" libedit"
+__UbuntuPackages+=" symlinks"
+__UbuntuPackages+=" libicu-dev"
+__UbuntuPackages+=" liblttng-ust-dev"
+__UbuntuPackages+=" libunwind8-dev"
+__UbuntuPackages+=" libnuma-dev"
+__AlpinePackages+=" gettext-dev"
+__AlpinePackages+=" icu-dev"
+__AlpinePackages+=" libunwind-dev"
+__AlpinePackages+=" lttng-ust-dev"
+__AlpinePackages+=" compiler-rt"
+__AlpinePackages+=" numactl-dev"
+__UbuntuPackages+=" libcurl4-openssl-dev"
+__UbuntuPackages+=" libkrb5-dev"
+__UbuntuPackages+=" libssl-dev"
+__UbuntuPackages+=" zlib1g-dev"
+__AlpinePackages+=" curl-dev"
+__AlpinePackages+=" krb5-dev"
+__AlpinePackages+=" openssl-dev"
+__AlpinePackages+=" zlib-dev"
+__FreeBSDBase="13.3-RELEASE"
+__FreeBSDPkg="1.17.0"
+__FreeBSDABI="13"
+__FreeBSDPackages="libunwind"
+__FreeBSDPackages+=" icu"
+__FreeBSDPackages+=" libinotify"
+__FreeBSDPackages+=" openssl"
+__FreeBSDPackages+=" krb5"
+__FreeBSDPackages+=" terminfo-db"
+__IllumosPackages="icu"
+__IllumosPackages+=" mit-krb5"
+__IllumosPackages+=" openssl"
+__IllumosPackages+=" zlib"
+__HaikuPackages="gcc_syslibs"
+__HaikuPackages+=" gcc_syslibs_devel"
+__HaikuPackages+=" gmp"
+__HaikuPackages+=" gmp_devel"
+__HaikuPackages+=" icu66"
+__HaikuPackages+=" icu66_devel"
+__HaikuPackages+=" krb5"
+__HaikuPackages+=" krb5_devel"
+__HaikuPackages+=" libiconv"
+__HaikuPackages+=" libiconv_devel"
+__HaikuPackages+=" llvm12_libunwind"
+__HaikuPackages+=" llvm12_libunwind_devel"
+__HaikuPackages+=" mpfr"
+__HaikuPackages+=" mpfr_devel"
+__HaikuPackages+=" openssl"
+__HaikuPackages+=" openssl_devel"
+__HaikuPackages+=" zlib"
+__HaikuPackages+=" zlib_devel"
+__UbuntuPackages+=" libomp5"
+__UbuntuPackages+=" libomp-dev"
+__AlpineKeys='
+4a6a0840:MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA1yHJxQgsHQREclQu4Ohe\nqxTxd1tHcNnvnQTu/UrTky8wWvgXT+jpveroeWWnzmsYlDI93eLI2ORakxb3gA2O\nQ0Ry4ws8vhaxLQGC74uQR5+/yYrLuTKydFzuPaS1dK19qJPXB8GMdmFOijnXX4SA\njixuHLe1WW7kZVtjL7nufvpXkWBGjsfrvskdNA/5MfxAeBbqPgaq0QMEfxMAn6/R\nL5kNepi/Vr4S39Xvf2DzWkTLEK8pcnjNkt9/aafhWqFVW7m3HCAII6h/qlQNQKSo\nGuH34Q8GsFG30izUENV9avY7hSLq7nggsvknlNBZtFUcmGoQrtx3FmyYsIC8/R+B\nywIDAQAB
+5243ef4b:MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAvNijDxJ8kloskKQpJdx+\nmTMVFFUGDoDCbulnhZMJoKNkSuZOzBoFC94omYPtxnIcBdWBGnrm6ncbKRlR+6oy\nDO0W7c44uHKCFGFqBhDasdI4RCYP+fcIX/lyMh6MLbOxqS22TwSLhCVjTyJeeH7K\naA7vqk+QSsF4TGbYzQDDpg7+6aAcNzg6InNePaywA6hbT0JXbxnDWsB+2/LLSF2G\nmnhJlJrWB1WGjkz23ONIWk85W4S0XB/ewDefd4Ly/zyIciastA7Zqnh7p3Ody6Q0\nsS2MJzo7p3os1smGjUF158s6m/JbVh4DN6YIsxwl2OjDOz9R0OycfJSDaBVIGZzg\ncQIDAQAB
+524d27bb:MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAr8s1q88XpuJWLCZALdKj\nlN8wg2ePB2T9aIcaxryYE/Jkmtu+ZQ5zKq6BT3y/udt5jAsMrhHTwroOjIsF9DeG\ne8Y3vjz+Hh4L8a7hZDaw8jy3CPag47L7nsZFwQOIo2Cl1SnzUc6/owoyjRU7ab0p\niWG5HK8IfiybRbZxnEbNAfT4R53hyI6z5FhyXGS2Ld8zCoU/R4E1P0CUuXKEN4p0\n64dyeUoOLXEWHjgKiU1mElIQj3k/IF02W89gDj285YgwqA49deLUM7QOd53QLnx+\nxrIrPv3A+eyXMFgexNwCKQU9ZdmWa00MjjHlegSGK8Y2NPnRoXhzqSP9T9i2HiXL\nVQIDAQAB
+5261cecb:MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAwlzMkl7b5PBdfMzGdCT0\ncGloRr5xGgVmsdq5EtJvFkFAiN8Ac9MCFy/vAFmS8/7ZaGOXoCDWbYVLTLOO2qtX\nyHRl+7fJVh2N6qrDDFPmdgCi8NaE+3rITWXGrrQ1spJ0B6HIzTDNEjRKnD4xyg4j\ng01FMcJTU6E+V2JBY45CKN9dWr1JDM/nei/Pf0byBJlMp/mSSfjodykmz4Oe13xB\nCa1WTwgFykKYthoLGYrmo+LKIGpMoeEbY1kuUe04UiDe47l6Oggwnl+8XD1MeRWY\nsWgj8sF4dTcSfCMavK4zHRFFQbGp/YFJ/Ww6U9lA3Vq0wyEI6MCMQnoSMFwrbgZw\nwwIDAQAB
+58199dcc:MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA3v8/ye/V/t5xf4JiXLXa\nhWFRozsnmn3hobON20GdmkrzKzO/eUqPOKTpg2GtvBhK30fu5oY5uN2ORiv2Y2ht\neLiZ9HVz3XP8Fm9frha60B7KNu66FO5P2o3i+E+DWTPqqPcCG6t4Znk2BypILcit\nwiPKTsgbBQR2qo/cO01eLLdt6oOzAaF94NH0656kvRewdo6HG4urbO46tCAizvCR\nCA7KGFMyad8WdKkTjxh8YLDLoOCtoZmXmQAiwfRe9pKXRH/XXGop8SYptLqyVVQ+\ntegOD9wRs2tOlgcLx4F/uMzHN7uoho6okBPiifRX+Pf38Vx+ozXh056tjmdZkCaV\naQIDAQAB
+58cbb476:MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAoSPnuAGKtRIS5fEgYPXD\n8pSGvKAmIv3A08LBViDUe+YwhilSHbYXUEAcSH1KZvOo1WT1x2FNEPBEFEFU1Eyc\n+qGzbA03UFgBNvArurHQ5Z/GngGqE7IarSQFSoqewYRtFSfp+TL9CUNBvM0rT7vz\n2eMu3/wWG+CBmb92lkmyWwC1WSWFKO3x8w+Br2IFWvAZqHRt8oiG5QtYvcZL6jym\nY8T6sgdDlj+Y+wWaLHs9Fc+7vBuyK9C4O1ORdMPW15qVSl4Lc2Wu1QVwRiKnmA+c\nDsH/m7kDNRHM7TjWnuj+nrBOKAHzYquiu5iB3Qmx+0gwnrSVf27Arc3ozUmmJbLj\nzQIDAQAB
+58e4f17d:MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAvBxJN9ErBgdRcPr5g4hV\nqyUSGZEKuvQliq2Z9SRHLh2J43+EdB6A+yzVvLnzcHVpBJ+BZ9RV30EM9guck9sh\nr+bryZcRHyjG2wiIEoduxF2a8KeWeQH7QlpwGhuobo1+gA8L0AGImiA6UP3LOirl\nI0G2+iaKZowME8/tydww4jx5vG132JCOScMjTalRsYZYJcjFbebQQolpqRaGB4iG\nWqhytWQGWuKiB1A22wjmIYf3t96l1Mp+FmM2URPxD1gk/BIBnX7ew+2gWppXOK9j\n1BJpo0/HaX5XoZ/uMqISAAtgHZAqq+g3IUPouxTphgYQRTRYpz2COw3NF43VYQrR\nbQIDAQAB
+60ac2099:MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAwR4uJVtJOnOFGchnMW5Y\nj5/waBdG1u5BTMlH+iQMcV5+VgWhmpZHJCBz3ocD+0IGk2I68S5TDOHec/GSC0lv\n6R9o6F7h429GmgPgVKQsc8mPTPtbjJMuLLs4xKc+viCplXc0Nc0ZoHmCH4da6fCV\ntdpHQjVe6F9zjdquZ4RjV6R6JTiN9v924dGMAkbW/xXmamtz51FzondKC52Gh8Mo\n/oA0/T0KsCMCi7tb4QNQUYrf+Xcha9uus4ww1kWNZyfXJB87a2kORLiWMfs2IBBJ\nTmZ2Fnk0JnHDb8Oknxd9PvJPT0mvyT8DA+KIAPqNvOjUXP4bnjEHJcoCP9S5HkGC\nIQIDAQAB
+6165ee59:MIICIjANBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEAutQkua2CAig4VFSJ7v54\nALyu/J1WB3oni7qwCZD3veURw7HxpNAj9hR+S5N/pNeZgubQvJWyaPuQDm7PTs1+\ntFGiYNfAsiibX6Rv0wci3M+z2XEVAeR9Vzg6v4qoofDyoTbovn2LztaNEjTkB+oK\ntlvpNhg1zhou0jDVYFniEXvzjckxswHVb8cT0OMTKHALyLPrPOJzVtM9C1ew2Nnc\n3848xLiApMu3NBk0JqfcS3Bo5Y2b1FRVBvdt+2gFoKZix1MnZdAEZ8xQzL/a0YS5\nHd0wj5+EEKHfOd3A75uPa/WQmA+o0cBFfrzm69QDcSJSwGpzWrD1ScH3AK8nWvoj\nv7e9gukK/9yl1b4fQQ00vttwJPSgm9EnfPHLAtgXkRloI27H6/PuLoNvSAMQwuCD\nhQRlyGLPBETKkHeodfLoULjhDi1K2gKJTMhtbnUcAA7nEphkMhPWkBpgFdrH+5z4\nLxy+3ek0cqcI7K68EtrffU8jtUj9LFTUC8dERaIBs7NgQ/LfDbDfGh9g6qVj1hZl\nk9aaIPTm/xsi8v3u+0qaq7KzIBc9s59JOoA8TlpOaYdVgSQhHHLBaahOuAigH+VI\nisbC9vmqsThF2QdDtQt37keuqoda2E6sL7PUvIyVXDRfwX7uMDjlzTxHTymvq2Ck\nhtBqojBnThmjJQFgZXocHG8CAwEAAQ==
+61666e3f:MIICIjANBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEAlEyxkHggKCXC2Wf5Mzx4\nnZLFZvU2bgcA3exfNPO/g1YunKfQY+Jg4fr6tJUUTZ3XZUrhmLNWvpvSwDS19ZmC\nIXOu0+V94aNgnhMsk9rr59I8qcbsQGIBoHzuAl8NzZCgdbEXkiY90w1skUw8J57z\nqCsMBydAueMXuWqF5nGtYbi5vHwK42PffpiZ7G5Kjwn8nYMW5IZdL6ZnMEVJUWC9\nI4waeKg0yskczYDmZUEAtrn3laX9677ToCpiKrvmZYjlGl0BaGp3cxggP2xaDbUq\nqfFxWNgvUAb3pXD09JM6Mt6HSIJaFc9vQbrKB9KT515y763j5CC2KUsilszKi3mB\nHYe5PoebdjS7D1Oh+tRqfegU2IImzSwW3iwA7PJvefFuc/kNIijfS/gH/cAqAK6z\nbhdOtE/zc7TtqW2Wn5Y03jIZdtm12CxSxwgtCF1NPyEWyIxAQUX9ACb3M0FAZ61n\nfpPrvwTaIIxxZ01L3IzPLpbc44x/DhJIEU+iDt6IMTrHOphD9MCG4631eIdB0H1b\n6zbNX1CXTsafqHRFV9XmYYIeOMggmd90s3xIbEujA6HKNP/gwzO6CDJ+nHFDEqoF\nSkxRdTkEqjTjVKieURW7Swv7zpfu5PrsrrkyGnsRrBJJzXlm2FOOxnbI2iSL1B5F\nrO5kbUxFeZUIDq+7Yv4kLWcCAwEAAQ==
+616a9724:MIICIjANBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEAnC+bR4bHf/L6QdU4puhQ\ngl1MHePszRC38bzvVFDUJsmCaMCL2suCs2A2yxAgGb9pu9AJYLAmxQC4mM3jNqhg\n/E7yuaBbek3O02zN/ctvflJ250wZCy+z0ZGIp1ak6pu1j14IwHokl9j36zNfGtfv\nADVOcdpWITFFlPqwq1qt/H3UsKVmtiF3BNWWTeUEQwKvlU8ymxgS99yn0+4OPyNT\nL3EUeS+NQJtDS01unau0t7LnjUXn+XIneWny8bIYOQCuVR6s/gpIGuhBaUqwaJOw\n7jkJZYF2Ij7uPb4b5/R3vX2FfxxqEHqssFSg8FFUNTZz3qNZs0CRVyfA972g9WkJ\nhPfn31pQYil4QGRibCMIeU27YAEjXoqfJKEPh4UWMQsQLrEfdGfb8VgwrPbniGfU\nL3jKJR3VAafL9330iawzVQDlIlwGl6u77gEXMl9K0pfazunYhAp+BMP+9ot5ckK+\nosmrqj11qMESsAj083GeFdfV3pXEIwUytaB0AKEht9DbqUfiE/oeZ/LAXgySMtVC\nsbC4ESmgVeY2xSBIJdDyUap7FR49GGrw0W49NUv9gRgQtGGaNVQQO9oGL2PBC41P\niWF9GLoX30HIz1P8PF/cZvicSSPkQf2Z6TV+t0ebdGNS5DjapdnCrq8m9Z0pyKsQ\nuxAL2a7zX8l5i1CZh1ycUGsCAwEAAQ==
+616abc23:MIICIjANBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEA0MfCDrhODRCIxR9Dep1s\neXafh5CE5BrF4WbCgCsevyPIdvTeyIaW4vmO3bbG4VzhogDZju+R3IQYFuhoXP5v\nY+zYJGnwrgz3r5wYAvPnLEs1+dtDKYOgJXQj+wLJBW1mzRDL8FoRXOe5iRmn1EFS\nwZ1DoUvyu7/J5r0itKicZp3QKED6YoilXed+1vnS4Sk0mzN4smuMR9eO1mMCqNp9\n9KTfRDHTbakIHwasECCXCp50uXdoW6ig/xUAFanpm9LtK6jctNDbXDhQmgvAaLXZ\nLvFqoaYJ/CvWkyYCgL6qxvMvVmPoRv7OPcyni4xR/WgWa0MSaEWjgPx3+yj9fiMA\n1S02pFWFDOr5OUF/O4YhFJvUCOtVsUPPfA/Lj6faL0h5QI9mQhy5Zb9TTaS9jB6p\nLw7u0dJlrjFedk8KTJdFCcaGYHP6kNPnOxMylcB/5WcztXZVQD5WpCicGNBxCGMm\nW64SgrV7M07gQfL/32QLsdqPUf0i8hoVD8wfQ3EpbQzv6Fk1Cn90bZqZafg8XWGY\nwddhkXk7egrr23Djv37V2okjzdqoyLBYBxMz63qQzFoAVv5VoY2NDTbXYUYytOvG\nGJ1afYDRVWrExCech1mX5ZVUB1br6WM+psFLJFoBFl6mDmiYt0vMYBddKISsvwLl\nIJQkzDwtXzT2cSjoj3T5QekCAwEAAQ==
+616ac3bc:MIICIjANBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEAvaaoSLab+IluixwKV5Od\n0gib2YurjPatGIbn5Ov2DLUFYiebj2oJINXJSwUOO+4WcuHFEqiL/1rya+k5hLZt\nhnPL1tn6QD4rESznvGSasRCQNT2vS/oyZbTYJRyAtFkEYLlq0t3S3xBxxHWuvIf0\nqVxVNYpQWyM3N9RIeYBR/euXKJXileSHk/uq1I5wTC0XBIHWcthczGN0m9wBEiWS\n0m3cnPk4q0Ea8mUJ91Rqob19qETz6VbSPYYpZk3qOycjKosuwcuzoMpwU8KRiMFd\n5LHtX0Hx85ghGsWDVtS0c0+aJa4lOMGvJCAOvDfqvODv7gKlCXUpgumGpLdTmaZ8\n1RwqspAe3IqBcdKTqRD4m2mSg23nVx2FAY3cjFvZQtfooT7q1ItRV5RgH6FhQSl7\n+6YIMJ1Bf8AAlLdRLpg+doOUGcEn+pkDiHFgI8ylH1LKyFKw+eXaAml/7DaWZk1d\ndqggwhXOhc/UUZFQuQQ8A8zpA13PcbC05XxN2hyP93tCEtyynMLVPtrRwDnHxFKa\nqKzs3rMDXPSXRn3ZZTdKH3069ApkEjQdpcwUh+EmJ1Ve/5cdtzT6kKWCjKBFZP/s\n91MlRrX2BTRdHaU5QJkUheUtakwxuHrdah2F94lRmsnQlpPr2YseJu6sIE+Dnx4M\nCfhdVbQL2w54R645nlnohu8CAwEAAQ==
+616adfeb:MIICIjANBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEAq0BFD1D4lIxQcsqEpQzU\npNCYM3aP1V/fxxVdT4DWvSI53JHTwHQamKdMWtEXetWVbP5zSROniYKFXd/xrD9X\n0jiGHey3lEtylXRIPxe5s+wXoCmNLcJVnvTcDtwx/ne2NLHxp76lyc25At+6RgE6\nADjLVuoD7M4IFDkAsd8UQ8zM0Dww9SylIk/wgV3ZkifecvgUQRagrNUdUjR56EBZ\nraQrev4hhzOgwelT0kXCu3snbUuNY/lU53CoTzfBJ5UfEJ5pMw1ij6X0r5S9IVsy\nKLWH1hiO0NzU2c8ViUYCly4Fe9xMTFc6u2dy/dxf6FwERfGzETQxqZvSfrRX+GLj\n/QZAXiPg5178hT/m0Y3z5IGenIC/80Z9NCi+byF1WuJlzKjDcF/TU72zk0+PNM/H\nKuppf3JT4DyjiVzNC5YoWJT2QRMS9KLP5iKCSThwVceEEg5HfhQBRT9M6KIcFLSs\nmFjx9kNEEmc1E8hl5IR3+3Ry8G5/bTIIruz14jgeY9u5jhL8Vyyvo41jgt9sLHR1\n/J1TxKfkgksYev7PoX6/ZzJ1ksWKZY5NFoDXTNYUgzFUTOoEaOg3BAQKadb3Qbbq\nXIrxmPBdgrn9QI7NCgfnAY3Tb4EEjs3ON/BNyEhUENcXOH6I1NbcuBQ7g9P73kE4\nVORdoc8MdJ5eoKBpO8Ww8HECAwEAAQ==
+616ae350:MIICIjANBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEAyduVzi1mWm+lYo2Tqt/0\nXkCIWrDNP1QBMVPrE0/ZlU2bCGSoo2Z9FHQKz/mTyMRlhNqTfhJ5qU3U9XlyGOPJ\npiM+b91g26pnpXJ2Q2kOypSgOMOPA4cQ42PkHBEqhuzssfj9t7x47ppS94bboh46\nxLSDRff/NAbtwTpvhStV3URYkxFG++cKGGa5MPXBrxIp+iZf9GnuxVdST5PGiVGP\nODL/b69sPJQNbJHVquqUTOh5Ry8uuD2WZuXfKf7/C0jC/ie9m2+0CttNu9tMciGM\nEyKG1/Xhk5iIWO43m4SrrT2WkFlcZ1z2JSf9Pjm4C2+HovYpihwwdM/OdP8Xmsnr\nDzVB4YvQiW+IHBjStHVuyiZWc+JsgEPJzisNY0Wyc/kNyNtqVKpX6dRhMLanLmy+\nf53cCSI05KPQAcGj6tdL+D60uKDkt+FsDa0BTAobZ31OsFVid0vCXtsbplNhW1IF\nHwsGXBTVcfXg44RLyL8Lk/2dQxDHNHzAUslJXzPxaHBLmt++2COa2EI1iWlvtznk\nOk9WP8SOAIj+xdqoiHcC4j72BOVVgiITIJNHrbppZCq6qPR+fgXmXa+sDcGh30m6\n9Wpbr28kLMSHiENCWTdsFij+NQTd5S47H7XTROHnalYDuF1RpS+DpQidT5tUimaT\nJZDr++FjKrnnijbyNF8b98UCAwEAAQ==
+616db30d:MIICIjANBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEAnpUpyWDWjlUk3smlWeA0\nlIMW+oJ38t92CRLHH3IqRhyECBRW0d0aRGtq7TY8PmxjjvBZrxTNDpJT6KUk4LRm\na6A6IuAI7QnNK8SJqM0DLzlpygd7GJf8ZL9SoHSH+gFsYF67Cpooz/YDqWrlN7Vw\ntO00s0B+eXy+PCXYU7VSfuWFGK8TGEv6HfGMALLjhqMManyvfp8hz3ubN1rK3c8C\nUS/ilRh1qckdbtPvoDPhSbTDmfU1g/EfRSIEXBrIMLg9ka/XB9PvWRrekrppnQzP\nhP9YE3x/wbFc5QqQWiRCYyQl/rgIMOXvIxhkfe8H5n1Et4VAorkpEAXdsfN8KSVv\nLSMazVlLp9GYq5SUpqYX3KnxdWBgN7BJoZ4sltsTpHQ/34SXWfu3UmyUveWj7wp0\nx9hwsPirVI00EEea9AbP7NM2rAyu6ukcm4m6ATd2DZJIViq2es6m60AE6SMCmrQF\nwmk4H/kdQgeAELVfGOm2VyJ3z69fQuywz7xu27S6zTKi05Qlnohxol4wVb6OB7qG\nLPRtK9ObgzRo/OPumyXqlzAi/Yvyd1ZQk8labZps3e16bQp8+pVPiumWioMFJDWV\nGZjCmyMSU8V6MB6njbgLHoyg2LCukCAeSjbPGGGYhnKLm1AKSoJh3IpZuqcKCk5C\n8CM1S15HxV78s9dFntEqIokCAwEAAQ==
+'
+__Keyring=
+__KeyringFile="/usr/share/keyrings/ubuntu-archive-keyring.gpg"
+__SkipSigCheck=0
+__UseMirror=0
+__UnprocessedBuildArgs=
+while :; do
+    if [[ "$#" -le 0 ]]; then
+        break
+    fi
+    lowerI="$(echo "$1" | tr "[:upper:]" "[:lower:]")"
+    case $lowerI in
+        -\?|-h|--help)
+            usage
+            ;;
+        arm)
+            __BuildArch=arm
+            __UbuntuArch=armhf
+            __AlpineArch=armv7
+            __QEMUArch=arm
+            ;;
+        arm64)
+            __BuildArch=arm64
+            __UbuntuArch=arm64
+            __AlpineArch=aarch64
+            __QEMUArch=aarch64
+            __FreeBSDArch=arm64
+            __FreeBSDMachineArch=aarch64
+            ;;
+        armel)
+            __BuildArch=armel
+            __UbuntuArch=armel
+            __UbuntuRepo="http://ftp.debian.org/debian/"
+            __CodeName=jessie
+            __KeyringFile="/usr/share/keyrings/debian-archive-keyring.gpg"
+            ;;
+        armv6)
+            __BuildArch=armv6
+            __UbuntuArch=armhf
+            __QEMUArch=arm
+            __UbuntuRepo="http://raspbian.raspberrypi.org/raspbian/"
+            __CodeName=buster
+            __KeyringFile="/usr/share/keyrings/raspbian-archive-keyring.gpg"
+            __LLDB_Package="liblldb-6.0-dev"
+            __UbuntuSuites=
+            if [[ -e "$__KeyringFile" ]]; then
+                __Keyring="--keyring $__KeyringFile"
+            fi
+            ;;
+        riscv64)
+            __BuildArch=riscv64
+            __AlpineArch=riscv64
+            __AlpinePackages="${__AlpinePackages// lldb-dev/}"
+            __QEMUArch=riscv64
+            __UbuntuArch=riscv64
+            __UbuntuPackages="${__UbuntuPackages// libunwind8-dev/}"
+            unset __LLDB_Package
+            ;;
+        ppc64le)
+            __BuildArch=ppc64le
+            __AlpineArch=ppc64le
+            __QEMUArch=ppc64le
+            __UbuntuArch=ppc64el
+            __UbuntuRepo="http://ports.ubuntu.com/ubuntu-ports/"
+            __UbuntuPackages="${__UbuntuPackages// libunwind8-dev/}"
+            __UbuntuPackages="${__UbuntuPackages// libomp-dev/}"
+            __UbuntuPackages="${__UbuntuPackages// libomp5/}"
+            unset __LLDB_Package
+            ;;
+        s390x)
+            __BuildArch=s390x
+            __AlpineArch=s390x
+            __QEMUArch=s390x
+            __UbuntuArch=s390x
+            __UbuntuRepo="http://ports.ubuntu.com/ubuntu-ports/"
+            __UbuntuPackages="${__UbuntuPackages// libunwind8-dev/}"
+            __UbuntuPackages="${__UbuntuPackages// libomp-dev/}"
+            __UbuntuPackages="${__UbuntuPackages// libomp5/}"
+            unset __LLDB_Package
+            ;;
+        x64)
+            __BuildArch=x64
+            __AlpineArch=x86_64
+            __UbuntuArch=amd64
+            __FreeBSDArch=amd64
+            __FreeBSDMachineArch=amd64
+            __illumosArch=x86_64
+            __HaikuArch=x86_64
+            __UbuntuRepo="http://archive.ubuntu.com/ubuntu/"
+            ;;
+        x86)
+            __BuildArch=x86
+            __UbuntuArch=i386
+            __AlpineArch=x86
+            __UbuntuRepo="http://archive.ubuntu.com/ubuntu/"
+            ;;
+        lldb*)
+            version="$(echo "$lowerI" | tr -d '[:alpha:]-=')"
+            majorVersion="${version%%.*}"
+            [ -z "${version##*.*}" ] && minorVersion="${version#*.}"
+            if [ -z "$minorVersion" ]; then
+                minorVersion=0
+            fi
+            if [ "$majorVersion" -le 6 ]; then
+                version="$majorVersion.$minorVersion"
+            else
+                version="$majorVersion"
+            fi
+            __LLDB_Package="liblldb-${version}-dev"
+            ;;
+        no-lldb)
+            unset __LLDB_Package
+            ;;
+        llvm*)
+            version="$(echo "$lowerI" | tr -d '[:alpha:]-=')"
+            __LLVM_MajorVersion="${version%%.*}"
+            [ -z "${version##*.*}" ] && __LLVM_MinorVersion="${version#*.}"
+            if [ -z "$__LLVM_MinorVersion" ]; then
+                __LLVM_MinorVersion=0
+            fi
+            if [ "$__LLVM_MajorVersion" -gt 6 ]; then
+                __LLVM_MinorVersion=
+            fi
+            ;;
+        xenial) # Ubuntu 16.04
+            if [[ "$__CodeName" != "jessie" ]]; then
+                __CodeName=xenial
+            fi
+            ;;
+        zesty) # Ubuntu 17.04
+            if [[ "$__CodeName" != "jessie" ]]; then
+                __CodeName=zesty
+            fi
+            ;;
+        bionic) # Ubuntu 18.04
+            if [[ "$__CodeName" != "jessie" ]]; then
+                __CodeName=bionic
+            fi
+            ;;
+        focal) # Ubuntu 20.04
+            if [[ "$__CodeName" != "jessie" ]]; then
+                __CodeName=focal
+            fi
+            ;;
+        jammy) # Ubuntu 22.04
+            if [[ "$__CodeName" != "jessie" ]]; then
+                __CodeName=jammy
+            fi
+            ;;
+        noble) # Ubuntu 24.04
+            if [[ "$__CodeName" != "jessie" ]]; then
+                __CodeName=noble
+            fi
+            if [[ -n "$__LLDB_Package" ]]; then
+                __LLDB_Package="liblldb-18-dev"
+            fi
+            ;;
+        jessie) # Debian 8
+            __CodeName=jessie
+            __KeyringFile="/usr/share/keyrings/debian-archive-keyring.gpg"
+            if [[ -z "$__UbuntuRepo" ]]; then
+                __UbuntuRepo="http://ftp.debian.org/debian/"
+            fi
+            ;;
+        stretch) # Debian 9
+            __CodeName=stretch
+            __LLDB_Package="liblldb-6.0-dev"
+            __KeyringFile="/usr/share/keyrings/debian-archive-keyring.gpg"
+            if [[ -z "$__UbuntuRepo" ]]; then
+                __UbuntuRepo="http://ftp.debian.org/debian/"
+            fi
+            ;;
+        buster) # Debian 10
+            __CodeName=buster
+            __LLDB_Package="liblldb-6.0-dev"
+            __KeyringFile="/usr/share/keyrings/debian-archive-keyring.gpg"
+            if [[ -z "$__UbuntuRepo" ]]; then
+                __UbuntuRepo="http://ftp.debian.org/debian/"
+            fi
+            ;;
+        bullseye) # Debian 11
+            __CodeName=bullseye
+            __KeyringFile="/usr/share/keyrings/debian-archive-keyring.gpg"
+            if [[ -z "$__UbuntuRepo" ]]; then
+                __UbuntuRepo="http://ftp.debian.org/debian/"
+            fi
+            ;;
+        bookworm) # Debian 12
+            __CodeName=bookworm
+            __KeyringFile="/usr/share/keyrings/debian-archive-keyring.gpg"
+            if [[ -z "$__UbuntuRepo" ]]; then
+                __UbuntuRepo="http://ftp.debian.org/debian/"
+            fi
+            ;;
+        sid) # Debian sid
+            __CodeName=sid
+            __KeyringFile="/usr/share/keyrings/debian-archive-keyring.gpg"
+            if [[ -z "$__UbuntuRepo" ]]; then
+                __UbuntuRepo="http://ftp.debian.org/debian/"
+            fi
+            ;;
+        tizen)
+            __CodeName=
+            __UbuntuRepo=
+            __Tizen=tizen
+            ;;
+        alpine*)
+            __CodeName=alpine
+            __UbuntuRepo=
+            if [[ "$lowerI" == "alpineedge" ]]; then
+                __AlpineVersion=edge
+            else
+                version="$(echo "$lowerI" | tr -d '[:alpha:]-=')"
+                __AlpineMajorVersion="${version%%.*}"
+                __AlpineMinorVersion="${version#*.}"
+                __AlpineVersion="$__AlpineMajorVersion.$__AlpineMinorVersion"
+            fi
+            ;;
+        freebsd13)
+            __CodeName=freebsd
+            __SkipUnmount=1
+            ;;
+        freebsd14)
+            __CodeName=freebsd
+            __FreeBSDBase="14.0-RELEASE"
+            __FreeBSDABI="14"
+            __SkipUnmount=1
+            ;;
+        illumos)
+            __CodeName=illumos
+            __SkipUnmount=1
+            ;;
+        haiku)
+            __CodeName=haiku
+            __SkipUnmount=1
+            ;;
+        --skipunmount)
+            __SkipUnmount=1
+            ;;
+        --skipsigcheck)
+            __SkipSigCheck=1
+            ;;
+        --rootfsdir|-rootfsdir)
+            shift
+            __RootfsDir="$1"
+            ;;
+        --use-mirror)
+            __UseMirror=1
+            ;;
+        --use-jobs)
+            shift
+            MAXJOBS=$1
+            ;;
+        *)
+            __UnprocessedBuildArgs="$__UnprocessedBuildArgs $1"
+            ;;
+    esac
+    shift
+done
+case "$__AlpineVersion" in
+    3.14) __AlpinePackages+=" llvm11-libs" ;;
+    3.15) __AlpinePackages+=" llvm12-libs" ;;
+    3.16) __AlpinePackages+=" llvm13-libs" ;;
+    3.17) __AlpinePackages+=" llvm15-libs" ;;
+    edge) __AlpineLlvmLibsLookup=1 ;;
+    *)
+        if [[ "$__AlpineArch" =~ s390x|ppc64le ]]; then
+            __AlpineVersion=3.15 # minimum version that supports lldb-dev
+            __AlpinePackages+=" llvm12-libs"
+        elif [[ "$__AlpineArch" == "x86" ]]; then
+            __AlpineVersion=3.17 # minimum version that supports lldb-dev
+            __AlpinePackages+=" llvm15-libs"
+        elif [[ "$__AlpineArch" == "riscv64" ]]; then
+            __AlpineLlvmLibsLookup=1
+            __AlpineVersion=edge # minimum version with APKINDEX.tar.gz (packages archive)
+        else
+            __AlpineVersion=3.13 # 3.13 to maximize compatibility
+            __AlpinePackages+=" llvm10-libs"
+            if [[ "$__AlpineArch" == "armv7" ]]; then
+                __AlpinePackages="${__AlpinePackages//numactl-dev/}"
+            fi
+        fi
+esac
+if [[ "$__AlpineVersion" =~ 3\.1[345] ]]; then
+    __AlpinePackages="${__AlpinePackages/compiler-rt/compiler-rt-static}"
+fi
+if [[ "$__BuildArch" == "armel" ]]; then
+    __LLDB_Package="lldb-3.5-dev"
+fi
+if [[ "$__CodeName" == "xenial" && "$__UbuntuArch" == "armhf" ]]; then
+    __UbuntuPackages="${__UbuntuPackages//libnuma-dev/}"
+fi
+__UbuntuPackages+=" ${__LLDB_Package:-}"
+if [[ -z "$__UbuntuRepo" ]]; then
+    __UbuntuRepo="http://ports.ubuntu.com/"
+fi
+if [[ -n "$__LLVM_MajorVersion" ]]; then
+    __UbuntuPackages+=" libclang-common-${__LLVM_MajorVersion}${__LLVM_MinorVersion:+.$__LLVM_MinorVersion}-dev"
+fi
+if [[ -z "$__RootfsDir" && -n "$ROOTFS_DIR" ]]; then
+    __RootfsDir="$ROOTFS_DIR"
+fi
+if [[ -z "$__RootfsDir" ]]; then
+    __RootfsDir="$__CrossDir/../../../.tools/rootfs/$__BuildArch"
+fi
+if [[ -d "$__RootfsDir" ]]; then
+    if [[ "$__SkipUnmount" == "0" ]]; then
+        umount "$__RootfsDir"/* || true
+    fi
+    rm -rf "$__RootfsDir"
+fi
+mkdir -p "$__RootfsDir"
+__RootfsDir="$( cd "$__RootfsDir" && pwd )"
+__hasWget=
+ensureDownloadTool()
+{
+    if command -v wget &> /dev/null; then
+        __hasWget=1
+    elif command -v curl &> /dev/null; then
+        __hasWget=0
+    else
+        >&2 echo "ERROR: either wget or curl is required by this script."
+        exit 1
+    fi
+}
+if [[ "$__CodeName" == "alpine" ]]; then
+    __ApkToolsVersion=2.12.11
+    __ApkToolsDir="$(mktemp -d)"
+    __ApkKeysDir="$(mktemp -d)"
+    arch="$(uname -m)"
+    ensureDownloadTool
+    if [[ "$__hasWget" == 1 ]]; then
+        wget -P "$__ApkToolsDir" "https://gitlab.alpinelinux.org/api/v4/projects/5/packages/generic/v$__ApkToolsVersion/$arch/apk.static"
+    else
+        curl -SLO --create-dirs --output-dir "$__ApkToolsDir" "https://gitlab.alpinelinux.org/api/v4/projects/5/packages/generic/v$__ApkToolsVersion/$arch/apk.static"
+    fi
+    if [[ "$arch" == "x86_64" ]]; then
+      __ApkToolsSHA512SUM="53e57b49230da07ef44ee0765b9592580308c407a8d4da7125550957bb72cb59638e04f8892a18b584451c8d841d1c7cb0f0ab680cc323a3015776affaa3be33"
+    elif [[ "$arch" == "aarch64" ]]; then
+      __ApkToolsSHA512SUM="9e2b37ecb2b56c05dad23d379be84fd494c14bd730b620d0d576bda760588e1f2f59a7fcb2f2080577e0085f23a0ca8eadd993b4e61c2ab29549fdb71969afd0"
+    else
+      echo "WARNING: add missing hash for your host architecture. To find the value, use: 'find /tmp -name apk.static -exec sha512sum {} \;'"
+    fi
+    echo "$__ApkToolsSHA512SUM $__ApkToolsDir/apk.static" | sha512sum -c
+    chmod +x "$__ApkToolsDir/apk.static"
+    if [[ -f "/usr/bin/qemu-$__QEMUArch-static" ]]; then
+        mkdir -p "$__RootfsDir"/usr/bin
+        cp -v "/usr/bin/qemu-$__QEMUArch-static" "$__RootfsDir/usr/bin"
+    fi
+    if [[ "$__AlpineVersion" == "edge" ]]; then
+        version=edge
+    else
+        version="v$__AlpineVersion"
+    fi
+    for line in $__AlpineKeys; do
+        id="${line%%:*}"
+        content="${line#*:}"
+        echo -e "-----BEGIN PUBLIC KEY-----\n$content\n-----END PUBLIC KEY-----" > "$__ApkKeysDir/alpine-devel@lists.alpinelinux.org-$id.rsa.pub"
+    done
+    if [[ "$__SkipSigCheck" == "1" ]]; then
+        __ApkSignatureArg="--allow-untrusted"
+    else
+        __ApkSignatureArg="--keys-dir $__ApkKeysDir"
+    fi
+    "$__ApkToolsDir/apk.static" \
+        -X "http://dl-cdn.alpinelinux.org/alpine/$version/main" \
+        -X "http://dl-cdn.alpinelinux.org/alpine/$version/community" \
+        -U $__ApkSignatureArg --root "$__RootfsDir" --arch "$__AlpineArch" --initdb add
+    if [[ "$__AlpineLlvmLibsLookup" == 1 ]]; then
+        __AlpinePackages+=" $("$__ApkToolsDir/apk.static" \
+            -X "http://dl-cdn.alpinelinux.org/alpine/$version/main" \
+            -X "http://dl-cdn.alpinelinux.org/alpine/$version/community" \
+            -U $__ApkSignatureArg --root "$__RootfsDir" --arch "$__AlpineArch" \
+            search 'llvm*-libs' | grep -E '^llvm' | sort | tail -1 | sed 's/-[^-]*//2g')"
+    fi
+    "$__ApkToolsDir/apk.static" \
+        -X "http://dl-cdn.alpinelinux.org/alpine/$version/main" \
+        -X "http://dl-cdn.alpinelinux.org/alpine/$version/community" \
+        -U $__ApkSignatureArg --root "$__RootfsDir" --arch "$__AlpineArch" \
+        add $__AlpinePackages
+    rm -r "$__ApkToolsDir"
+elif [[ "$__CodeName" == "freebsd" ]]; then
+    mkdir -p "$__RootfsDir"/usr/local/etc
+    JOBS=${MAXJOBS:="$(getconf _NPROCESSORS_ONLN)"}
+    ensureDownloadTool
+    if [[ "$__hasWget" == 1 ]]; then
+        wget -O- "https://download.freebsd.org/ftp/releases/${__FreeBSDArch}/${__FreeBSDMachineArch}/${__FreeBSDBase}/base.txz" | tar -C "$__RootfsDir" -Jxf - ./lib ./usr/lib ./usr/libdata ./usr/include ./usr/share/keys ./etc ./bin/freebsd-version
+    else
+        curl -SL "https://download.freebsd.org/ftp/releases/${__FreeBSDArch}/${__FreeBSDMachineArch}/${__FreeBSDBase}/base.txz" | tar -C "$__RootfsDir" -Jxf - ./lib ./usr/lib ./usr/libdata ./usr/include ./usr/share/keys ./etc ./bin/freebsd-version
+    fi
+    echo "ABI = \"FreeBSD:${__FreeBSDABI}:${__FreeBSDMachineArch}\"; FINGERPRINTS = \"${__RootfsDir}/usr/share/keys\"; REPOS_DIR = [\"${__RootfsDir}/etc/pkg\"]; REPO_AUTOUPDATE = NO; RUN_SCRIPTS = NO;" > "${__RootfsDir}"/usr/local/etc/pkg.conf
+    echo "FreeBSD: { url: \"pkg+http://pkg.FreeBSD.org/\${ABI}/quarterly\", mirror_type: \"srv\", signature_type: \"fingerprints\", fingerprints: \"${__RootfsDir}/usr/share/keys/pkg\", enabled: yes }" > "${__RootfsDir}"/etc/pkg/FreeBSD.conf
+    mkdir -p "$__RootfsDir"/tmp
+    if [[ "$__hasWget" == 1 ]]; then
+        wget -O- "https://github.com/freebsd/pkg/archive/${__FreeBSDPkg}.tar.gz" | tar -C "$__RootfsDir"/tmp -zxf -
+    else
+        curl -SL "https://github.com/freebsd/pkg/archive/${__FreeBSDPkg}.tar.gz" | tar -C "$__RootfsDir"/tmp -zxf -
+    fi
+    cd "$__RootfsDir/tmp/pkg-${__FreeBSDPkg}"
+    mkdir -p "$__RootfsDir"/host/etc
+    ./autogen.sh && ./configure --prefix="$__RootfsDir"/host && make -j "$JOBS" && make install
+    rm -rf "$__RootfsDir/tmp/pkg-${__FreeBSDPkg}"
+    INSTALL_AS_USER=$(whoami) "$__RootfsDir"/host/sbin/pkg -r "$__RootfsDir" -C "$__RootfsDir"/usr/local/etc/pkg.conf update
+    INSTALL_AS_USER=$(whoami) "$__RootfsDir"/host/sbin/pkg -r "$__RootfsDir" -C "$__RootfsDir"/usr/local/etc/pkg.conf install --yes $__FreeBSDPackages
+elif [[ "$__CodeName" == "illumos" ]]; then
+    mkdir "$__RootfsDir/tmp"
+    pushd "$__RootfsDir/tmp"
+    JOBS=${MAXJOBS:="$(getconf _NPROCESSORS_ONLN)"}
+    ensureDownloadTool
+    echo "Downloading sysroot."
+    if [[ "$__hasWget" == 1 ]]; then
+        wget -O- https://github.com/illumos/sysroot/releases/download/20181213-de6af22ae73b-v1/illumos-sysroot-i386-20181213-de6af22ae73b-v1.tar.gz | tar -C "$__RootfsDir" -xzf -
+    else
+        curl -SL https://github.com/illumos/sysroot/releases/download/20181213-de6af22ae73b-v1/illumos-sysroot-i386-20181213-de6af22ae73b-v1.tar.gz | tar -C "$__RootfsDir" -xzf -
+    fi
+    echo "Building binutils. Please wait.."
+    if [[ "$__hasWget" == 1 ]]; then
+        wget -O- https://ftp.gnu.org/gnu/binutils/binutils-2.42.tar.xz | tar -xJf -
+    else
+        curl -SL https://ftp.gnu.org/gnu/binutils/binutils-2.42.tar.xz | tar -xJf -
+    fi
+    mkdir build-binutils && cd build-binutils
+    ../binutils-2.42/configure --prefix="$__RootfsDir" --target="${__illumosArch}-sun-solaris2.11" --program-prefix="${__illumosArch}-illumos-" --with-sysroot="$__RootfsDir"
+    make -j "$JOBS" && make install && cd ..
+    echo "Building gcc. Please wait.."
+    if [[ "$__hasWget" == 1 ]]; then
+        wget -O- https://ftp.gnu.org/gnu/gcc/gcc-13.3.0/gcc-13.3.0.tar.xz | tar -xJf -
+    else
+        curl -SL https://ftp.gnu.org/gnu/gcc/gcc-13.3.0/gcc-13.3.0.tar.xz | tar -xJf -
+    fi
+    CFLAGS="-fPIC"
+    CXXFLAGS="-fPIC"
+    CXXFLAGS_FOR_TARGET="-fPIC"
+    CFLAGS_FOR_TARGET="-fPIC"
+    export CFLAGS CXXFLAGS CXXFLAGS_FOR_TARGET CFLAGS_FOR_TARGET
+    mkdir build-gcc && cd build-gcc
+    ../gcc-13.3.0/configure --prefix="$__RootfsDir" --target="${__illumosArch}-sun-solaris2.11" --program-prefix="${__illumosArch}-illumos-" --with-sysroot="$__RootfsDir" --with-gnu-as       \
+        --with-gnu-ld --disable-nls --disable-libgomp --disable-libquadmath --disable-libssp --disable-libvtv --disable-libcilkrts --disable-libada --disable-libsanitizer \
+        --disable-libquadmath-support --disable-shared --enable-tls
+    make -j "$JOBS" && make install && cd ..
+    BaseUrl=https://pkgsrc.smartos.org
+    if [[ "$__UseMirror" == 1 ]]; then
+        BaseUrl=https://pkgsrc.smartos.skylime.net
+    fi
+    BaseUrl="$BaseUrl/packages/SmartOS/2019Q4/${__illumosArch}/All"
+    echo "Downloading manifest"
+    if [[ "$__hasWget" == 1 ]]; then
+        wget "$BaseUrl"
+    else
+        curl -SLO "$BaseUrl"
+    fi
+    echo "Downloading dependencies."
+    read -ra array <<<"$__IllumosPackages"
+    for package in "${array[@]}"; do
+        echo "Installing '$package'"
+        package="$(sed -En '/.*href="('"$package"'-[0-9].*).tgz".*/h;$!d;g;s//\1/p' All)"
+        echo "Resolved name '$package'"
+        if [[ "$__hasWget" == 1 ]]; then
+            wget "$BaseUrl"/"$package".tgz
+        else
+            curl -SLO "$BaseUrl"/"$package".tgz
+        fi
+        ar -x "$package".tgz
+        tar --skip-old-files -xzf "$package".tmp.tg* -C "$__RootfsDir" 2>/dev/null
+    done
+    echo "Cleaning up temporary files."
+    popd
+    rm -rf "$__RootfsDir"/{tmp,+*}
+    mkdir -p "$__RootfsDir"/usr/include/net
+    mkdir -p "$__RootfsDir"/usr/include/netpacket
+    if [[ "$__hasWget" == 1 ]]; then
+        wget -P "$__RootfsDir"/usr/include/net https://raw.githubusercontent.com/illumos/illumos-gate/master/usr/src/uts/common/io/bpf/net/bpf.h
+        wget -P "$__RootfsDir"/usr/include/net https://raw.githubusercontent.com/illumos/illumos-gate/master/usr/src/uts/common/io/bpf/net/dlt.h
+        wget -P "$__RootfsDir"/usr/include/netpacket https://raw.githubusercontent.com/illumos/illumos-gate/master/usr/src/uts/common/inet/sockmods/netpacket/packet.h
+        wget -P "$__RootfsDir"/usr/include/sys https://raw.githubusercontent.com/illumos/illumos-gate/master/usr/src/uts/common/sys/sdt.h
+    else
+        curl -SLO --create-dirs --output-dir "$__RootfsDir"/usr/include/net https://raw.githubusercontent.com/illumos/illumos-gate/master/usr/src/uts/common/io/bpf/net/bpf.h
+        curl -SLO --create-dirs --output-dir "$__RootfsDir"/usr/include/net https://raw.githubusercontent.com/illumos/illumos-gate/master/usr/src/uts/common/io/bpf/net/dlt.h
+        curl -SLO --create-dirs --output-dir "$__RootfsDir"/usr/include/netpacket https://raw.githubusercontent.com/illumos/illumos-gate/master/usr/src/uts/common/inet/sockmods/netpacket/packet.h
+        curl -SLO --create-dirs --output-dir "$__RootfsDir"/usr/include/sys https://raw.githubusercontent.com/illumos/illumos-gate/master/usr/src/uts/common/sys/sdt.h
+    fi
+elif [[ "$__CodeName" == "haiku" ]]; then
+    JOBS=${MAXJOBS:="$(getconf _NPROCESSORS_ONLN)"}
+    echo "Building Haiku sysroot for $__HaikuArch"
+    mkdir -p "$__RootfsDir/tmp"
+    pushd "$__RootfsDir/tmp"
+    mkdir "$__RootfsDir/tmp/download"
+    ensureDownloadTool
+    echo "Downloading Haiku package tool"
+    git clone https://github.com/haiku/haiku-toolchains-ubuntu --depth 1 "$__RootfsDir/tmp/script"
+    if [[ "$__hasWget" == 1 ]]; then
+        wget -O "$__RootfsDir/tmp/download/hosttools.zip" "$("$__RootfsDir/tmp/script/fetch.sh" --hosttools)"
+    else
+        curl -SLo "$__RootfsDir/tmp/download/hosttools.zip" "$("$__RootfsDir/tmp/script/fetch.sh" --hosttools)"
+    fi
+    unzip -o "$__RootfsDir/tmp/download/hosttools.zip" -d "$__RootfsDir/tmp/bin"
+    DepotBaseUrl="https://depot.haiku-os.org/__api/v2/pkg/get-pkg"
+    HpkgBaseUrl="https://eu.hpkg.haiku-os.org/haiku/master/$__HaikuArch/current"
+    echo "Downloading Haiku packages"
+    read -ra array <<<"$__HaikuPackages"
+    for package in "${array[@]}"; do
+        echo "Downloading $package..."
+        if [[ "$__hasWget" == 1 ]]; then
+            hpkgDownloadUrl="$(wget -qO- --post-data '{"name":"'"$package"'","repositorySourceCode":"haikuports_'$__HaikuArch'","versionType":"LATEST","naturalLanguageCode":"en"}' \
+                --header 'Content-Type:application/json' "$DepotBaseUrl" | jq -r '.result.versions[].hpkgDownloadURL')"
+            wget -P "$__RootfsDir/tmp/download" "$hpkgDownloadUrl"
+        else
+            hpkgDownloadUrl="$(curl -sSL -XPOST --data '{"name":"'"$package"'","repositorySourceCode":"haikuports_'$__HaikuArch'","versionType":"LATEST","naturalLanguageCode":"en"}' \
+                --header 'Content-Type:application/json' "$DepotBaseUrl" | jq -r '.result.versions[].hpkgDownloadURL')"
+            curl -SLO --create-dirs --output-dir "$__RootfsDir/tmp/download" "$hpkgDownloadUrl"
+        fi
+    done
+    for package in haiku haiku_devel; do
+        echo "Downloading $package..."
+        if [[ "$__hasWget" == 1 ]]; then
+            hpkgVersion="$(wget -qO- "$HpkgBaseUrl" | sed -n 's/^.*version: "\([^"]*\)".*$/\1/p')"
+            wget -P "$__RootfsDir/tmp/download" "$HpkgBaseUrl/packages/$package-$hpkgVersion-1-$__HaikuArch.hpkg"
+        else
+            hpkgVersion="$(curl -sSL "$HpkgBaseUrl" | sed -n 's/^.*version: "\([^"]*\)".*$/\1/p')"
+            curl -SLO --create-dirs --output-dir "$__RootfsDir/tmp/download" "$HpkgBaseUrl/packages/$package-$hpkgVersion-1-$__HaikuArch.hpkg"
+        fi
+    done
+    echo "Setting up sysroot and extracting required packages"
+    mkdir -p "$__RootfsDir/boot/system"
+    for file in "$__RootfsDir/tmp/download/"*.hpkg; do
+        echo "Extracting $file..."
+        LD_LIBRARY_PATH="$__RootfsDir/tmp/bin" "$__RootfsDir/tmp/bin/package" extract -C "$__RootfsDir/boot/system" "$file"
+    done
+    echo "Downloading Haiku buildtools"
+    if [[ "$__hasWget" == 1 ]]; then
+        wget -O "$__RootfsDir/tmp/download/buildtools.zip" "$("$__RootfsDir/tmp/script/fetch.sh" --buildtools --arch=$__HaikuArch)"
+    else
+        curl -SLo "$__RootfsDir/tmp/download/buildtools.zip" "$("$__RootfsDir/tmp/script/fetch.sh" --buildtools --arch=$__HaikuArch)"
+    fi
+    unzip -o "$__RootfsDir/tmp/download/buildtools.zip" -d "$__RootfsDir"
+    echo "Cleaning up temporary files"
+    popd
+    rm -rf "$__RootfsDir/tmp"
+elif [[ -n "$__CodeName" ]]; then
+    if [[ "$__SkipSigCheck" == "0" ]]; then
+        __Keyring="$__Keyring --force-check-gpg"
+    fi
+    echo running debootstrap "--variant=minbase" $__Keyring --arch "$__UbuntuArch" "$__CodeName" "$__RootfsDir" "$__UbuntuRepo"
+    debootstrap "--variant=minbase" $__Keyring --arch "$__UbuntuArch" "$__CodeName" "$__RootfsDir" "$__UbuntuRepo"
+    mkdir -p "$__RootfsDir/etc/apt/sources.list.d/"
+    cat > "$__RootfsDir/etc/apt/sources.list.d/$__CodeName.sources" <<EOF
+Types: deb
+URIs: $__UbuntuRepo
+Suites: $__CodeName $(echo $__UbuntuSuites | xargs -n 1 | xargs -I {} echo -n "$__CodeName-{} ")
+Components: main universe
+Signed-By: $__KeyringFile
+EOF
+    chroot "$__RootfsDir" apt-get update
+    chroot "$__RootfsDir" apt-get -f -y install
+    chroot "$__RootfsDir" apt-get -y install $__UbuntuPackages
+    chroot "$__RootfsDir" symlinks -cr /usr
+    chroot "$__RootfsDir" apt-get clean
+    if [[ "$__SkipUnmount" == "0" ]]; then
+        umount "$__RootfsDir"/* || true
+    fi
+    if [[ "$__BuildArch" == "armel" && "$__CodeName" == "jessie" ]]; then
+        pushd "$__RootfsDir"
+        patch -p1 < "$__CrossDir/$__BuildArch/armel.jessie.patch"
+        popd
+    fi
+elif [[ "$__Tizen" == "tizen" ]]; then
+    ROOTFS_DIR="$__RootfsDir" "$__CrossDir/tizen-build-rootfs.sh" "$__BuildArch"
+else
+    echo "Unsupported target platform."
+    usage
+fi

--- a//dev/null
+++ b/eng/common/cross/tizen-build-rootfs.sh
@@ -0,0 +1,69 @@
+set -e
+ARCH=$1
+LINK_ARCH=$ARCH
+case "$ARCH" in
+    arm)
+        TIZEN_ARCH="armv7hl"
+        ;;
+    armel)
+        TIZEN_ARCH="armv7l"
+        LINK_ARCH="arm"
+        ;;
+    arm64)
+        TIZEN_ARCH="aarch64"
+        ;;
+    x86)
+        TIZEN_ARCH="i686"
+        ;;
+    x64)
+        TIZEN_ARCH="x86_64"
+        LINK_ARCH="x86"
+        ;;
+    riscv64)
+        TIZEN_ARCH="riscv64"
+        LINK_ARCH="riscv"
+        ;;
+    *)
+        echo "Unsupported architecture for tizen: $ARCH"
+        exit 1
+esac
+__CrossDir=$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )
+__TIZEN_CROSSDIR="$__CrossDir/${ARCH}/tizen"
+if [[ -z "$ROOTFS_DIR" ]]; then
+    echo "ROOTFS_DIR is not defined."
+    exit 1;
+fi
+TIZEN_TMP_DIR=$ROOTFS_DIR/tizen_tmp
+mkdir -p $TIZEN_TMP_DIR
+echo ">>Start downloading files"
+VERBOSE=1 $__CrossDir/tizen-fetch.sh $TIZEN_TMP_DIR $TIZEN_ARCH
+echo "<<Finish downloading files"
+echo ">>Start constructing Tizen rootfs"
+TIZEN_RPM_FILES=`ls $TIZEN_TMP_DIR/*.rpm`
+cd $ROOTFS_DIR
+for f in $TIZEN_RPM_FILES; do
+    rpm2cpio $f  | cpio -idm --quiet
+done
+echo "<<Finish constructing Tizen rootfs"
+rm -rf $TIZEN_TMP_DIR
+echo ">>Start configuring Tizen rootfs"
+ln -sfn asm-${LINK_ARCH} ./usr/include/asm
+patch -p1 < $__TIZEN_CROSSDIR/tizen.patch
+if [[ "$TIZEN_ARCH" == "riscv64" ]]; then
+    echo "Fixing broken symlinks in $PWD"
+    rm ./usr/lib64/libresolv.so
+    ln -s ../../lib64/libresolv.so.2 ./usr/lib64/libresolv.so
+    rm ./usr/lib64/libpthread.so
+    ln -s ../../lib64/libpthread.so.0 ./usr/lib64/libpthread.so
+    rm ./usr/lib64/libdl.so
+    ln -s ../../lib64/libdl.so.2 ./usr/lib64/libdl.so
+    rm ./usr/lib64/libutil.so
+    ln -s ../../lib64/libutil.so.1 ./usr/lib64/libutil.so
+    rm ./usr/lib64/libm.so
+    ln -s ../../lib64/libm.so.6 ./usr/lib64/libm.so
+    rm ./usr/lib64/librt.so
+    ln -s ../../lib64/librt.so.1 ./usr/lib64/librt.so
+    rm ./lib/ld-linux-riscv64-lp64d.so.1
+    ln -s ../lib64/ld-linux-riscv64-lp64d.so.1 ./lib/ld-linux-riscv64-lp64d.so.1
+fi
+echo "<<Finish configuring Tizen rootfs"

--- a//dev/null
+++ b/eng/common/cross/tizen-fetch.sh
@@ -0,0 +1,145 @@
+set -e
+if [[ -z "${VERBOSE// }" ]] || [ "$VERBOSE" -ne "$VERBOSE" ] 2>/dev/null; then
+    VERBOSE=0
+fi
+Log()
+{
+    if [ $VERBOSE -ge 1 ]; then
+        echo ${@:2}
+    fi
+}
+Inform()
+{
+    Log 1 -e "\x1B[0;34m$@\x1B[m"
+}
+Debug()
+{
+    Log 2 -e "\x1B[0;32m$@\x1B[m"
+}
+Error()
+{
+    >&2 Log 0 -e "\x1B[0;31m$@\x1B[m"
+}
+Fetch()
+{
+    URL=$1
+    FILE=$2
+    PROGRESS=$3
+    if [ $VERBOSE -ge 1 ] && [ $PROGRESS ]; then
+        CURL_OPT="--progress-bar"
+    else
+        CURL_OPT="--silent"
+    fi
+    curl $CURL_OPT $URL > $FILE
+}
+hash curl 2> /dev/null || { Error "Require 'curl' Aborting."; exit 1; }
+hash xmllint 2> /dev/null || { Error "Require 'xmllint' Aborting."; exit 1; }
+hash sha256sum 2> /dev/null || { Error "Require 'sha256sum' Aborting."; exit 1; }
+TMPDIR=$1
+if [ ! -d $TMPDIR ]; then
+    TMPDIR=./tizen_tmp
+    Debug "Create temporary directory : $TMPDIR"
+    mkdir -p $TMPDIR
+fi
+TIZEN_ARCH=$2
+TIZEN_URL=http://download.tizen.org/snapshots/TIZEN/Tizen
+BUILD_XML=build.xml
+REPOMD_XML=repomd.xml
+PRIMARY_XML=primary.xml
+TARGET_URL="http://__not_initialized"
+Xpath_get()
+{
+    XPATH_RESULT=''
+    XPATH=$1
+    XML_FILE=$2
+    RESULT=$(xmllint --xpath $XPATH $XML_FILE)
+    if [[ -z ${RESULT// } ]]; then
+        Error "Can not find target from $XML_FILE"
+        Debug "Xpath = $XPATH"
+        exit 1
+    fi
+    XPATH_RESULT=$RESULT
+}
+fetch_tizen_pkgs_init()
+{
+    TARGET=$1
+    PROFILE=$2
+    Debug "Initialize TARGET=$TARGET, PROFILE=$PROFILE"
+    TMP_PKG_DIR=$TMPDIR/tizen_${PROFILE}_pkgs
+    if [ -d $TMP_PKG_DIR ]; then rm -rf $TMP_PKG_DIR; fi
+    mkdir -p $TMP_PKG_DIR
+    PKG_URL=$TIZEN_URL/$PROFILE/latest
+    BUILD_XML_URL=$PKG_URL/$BUILD_XML
+    TMP_BUILD=$TMP_PKG_DIR/$BUILD_XML
+    TMP_REPOMD=$TMP_PKG_DIR/$REPOMD_XML
+    TMP_PRIMARY=$TMP_PKG_DIR/$PRIMARY_XML
+    TMP_PRIMARYGZ=${TMP_PRIMARY}.gz
+    Fetch $BUILD_XML_URL $TMP_BUILD
+    Debug "fetch $BUILD_XML_URL to $TMP_BUILD"
+    TARGET_XPATH="//build/buildtargets/buildtarget[@name=\"$TARGET\"]/repo[@type=\"binary\"]/text()"
+    Xpath_get $TARGET_XPATH $TMP_BUILD
+    TARGET_PATH=$XPATH_RESULT
+    TARGET_URL=$PKG_URL/$TARGET_PATH
+    REPOMD_URL=$TARGET_URL/repodata/repomd.xml
+    PRIMARY_XPATH='string(//*[local-name()="data"][@type="primary"]/*[local-name()="location"]/@href)'
+    Fetch $REPOMD_URL $TMP_REPOMD
+    Debug "fetch $REPOMD_URL to $TMP_REPOMD"
+    Xpath_get $PRIMARY_XPATH $TMP_REPOMD
+    PRIMARY_XML_PATH=$XPATH_RESULT
+    PRIMARY_URL=$TARGET_URL/$PRIMARY_XML_PATH
+    Fetch $PRIMARY_URL $TMP_PRIMARYGZ
+    Debug "fetch $PRIMARY_URL to $TMP_PRIMARYGZ"
+    gunzip $TMP_PRIMARYGZ
+    Debug "unzip $TMP_PRIMARYGZ to $TMP_PRIMARY"
+}
+fetch_tizen_pkgs()
+{
+    ARCH=$1
+    PACKAGE_XPATH_TPL='string(//*[local-name()="metadata"]/*[local-name()="package"][*[local-name()="name"][text()="_PKG_"]][*[local-name()="arch"][text()="_ARCH_"]]/*[local-name()="location"]/@href)'
+    PACKAGE_CHECKSUM_XPATH_TPL='string(//*[local-name()="metadata"]/*[local-name()="package"][*[local-name()="name"][text()="_PKG_"]][*[local-name()="arch"][text()="_ARCH_"]]/*[local-name()="checksum"]/text())'
+    for pkg in ${@:2}
+    do
+        Inform "Fetching... $pkg"
+        XPATH=${PACKAGE_XPATH_TPL/_PKG_/$pkg}
+        XPATH=${XPATH/_ARCH_/$ARCH}
+        Xpath_get $XPATH $TMP_PRIMARY
+        PKG_PATH=$XPATH_RESULT
+        XPATH=${PACKAGE_CHECKSUM_XPATH_TPL/_PKG_/$pkg}
+        XPATH=${XPATH/_ARCH_/$ARCH}
+        Xpath_get $XPATH $TMP_PRIMARY
+        CHECKSUM=$XPATH_RESULT
+        PKG_URL=$TARGET_URL/$PKG_PATH
+        PKG_FILE=$(basename $PKG_PATH)
+        PKG_PATH=$TMPDIR/$PKG_FILE
+        Debug "Download $PKG_URL to $PKG_PATH"
+        Fetch $PKG_URL $PKG_PATH true
+        echo "$CHECKSUM $PKG_PATH" | sha256sum -c - > /dev/null
+        if [ $? -ne 0 ]; then
+            Error "Fail to fetch $PKG_URL to $PKG_PATH"
+            Debug "Checksum = $CHECKSUM"
+            exit 1
+        fi
+    done
+}
+if [ "$TIZEN_ARCH" == "riscv64" ]; then
+    BASE="Tizen-Base-RISCV"
+    UNIFIED="Tizen-Unified-RISCV"
+else
+    BASE="Tizen-Base"
+    UNIFIED="Tizen-Unified"
+fi
+Inform "Initialize ${TIZEN_ARCH} base"
+fetch_tizen_pkgs_init standard $BASE
+Inform "fetch common packages"
+fetch_tizen_pkgs ${TIZEN_ARCH} gcc gcc-devel-static glibc glibc-devel libicu libicu-devel libatomic linux-glibc-devel keyutils keyutils-devel libkeyutils
+Inform "fetch coreclr packages"
+fetch_tizen_pkgs ${TIZEN_ARCH} libgcc libstdc++ libstdc++-devel libunwind libunwind-devel lttng-ust-devel lttng-ust userspace-rcu-devel userspace-rcu
+if [ "$TIZEN_ARCH" != "riscv64" ]; then
+    fetch_tizen_pkgs ${TIZEN_ARCH} lldb lldb-devel
+fi
+Inform "fetch corefx packages"
+fetch_tizen_pkgs ${TIZEN_ARCH} libcom_err libcom_err-devel zlib zlib-devel libopenssl11 libopenssl1.1-devel krb5 krb5-devel
+Inform "Initialize standard unified"
+fetch_tizen_pkgs_init standard $UNIFIED
+Inform "fetch corefx packages"
+fetch_tizen_pkgs ${TIZEN_ARCH} gssdp gssdp-devel tizen-release

--- a//dev/null
+++ b/eng/common/darc-init.sh
@@ -0,0 +1,66 @@
+source="${BASH_SOURCE[0]}"
+darcVersion=''
+versionEndpoint='https://maestro.dot.net/api/assets/darc-version?api-version=2020-02-20'
+verbosity='minimal'
+while [[ $# > 0 ]]; do
+  opt="$(echo "$1" | tr "[:upper:]" "[:lower:]")"
+  case "$opt" in
+    --darcversion)
+      darcVersion=$2
+      shift
+      ;;
+    --versionendpoint)
+      versionEndpoint=$2
+      shift
+      ;;
+    --verbosity)
+      verbosity=$2
+      shift
+      ;;
+    --toolpath)
+      toolpath=$2
+      shift
+      ;;
+    *)
+      echo "Invalid argument: $1"
+      usage
+      exit 1
+      ;;
+  esac
+  shift
+done
+while [[ -h "$source" ]]; do
+  scriptroot="$( cd -P "$( dirname "$source" )" && pwd )"
+  source="$(readlink "$source")"
+  [[ $source != /* ]] && source="$scriptroot/$source"
+done
+scriptroot="$( cd -P "$( dirname "$source" )" && pwd )"
+. "$scriptroot/tools.sh"
+if [ -z "$darcVersion" ]; then
+  darcVersion=$(curl -X GET "$versionEndpoint" -H "accept: text/plain")
+fi
+function InstallDarcCli {
+  local darc_cli_package_name="microsoft.dotnet.darc"
+  InitializeDotNetCli true
+  local dotnet_root=$_InitializeDotNetCli
+  if [ -z "$toolpath" ]; then
+    local tool_list=$($dotnet_root/dotnet tool list -g)
+    if [[ $tool_list = *$darc_cli_package_name* ]]; then
+      echo $($dotnet_root/dotnet tool uninstall $darc_cli_package_name -g)
+    fi
+  else
+    local tool_list=$($dotnet_root/dotnet tool list --tool-path "$toolpath")
+    if [[ $tool_list = *$darc_cli_package_name* ]]; then
+      echo $($dotnet_root/dotnet tool uninstall $darc_cli_package_name --tool-path "$toolpath")
+    fi
+  fi
+  local arcadeServicesSource="https://pkgs.dev.azure.com/dnceng/public/_packaging/dotnet-tools/nuget/v3/index.json"
+  echo "Installing Darc CLI version $darcVersion..."
+  echo "You may need to restart your command shell if this is the first dotnet tool you have installed."
+  if [ -z "$toolpath" ]; then
+    echo $($dotnet_root/dotnet tool install $darc_cli_package_name --version $darcVersion --add-source "$arcadeServicesSource" -v $verbosity -g)
+  else
+    echo $($dotnet_root/dotnet tool install $darc_cli_package_name --version $darcVersion --add-source "$arcadeServicesSource" -v $verbosity --tool-path "$toolpath")
+  fi
+}
+InstallDarcCli

--- a//dev/null
+++ b/eng/common/dotnet-install.sh
@@ -0,0 +1,81 @@
+source="${BASH_SOURCE[0]}"
+while [[ -h "$source" ]]; do
+  scriptroot="$( cd -P "$( dirname "$source" )" && pwd )"
+  source="$(readlink "$source")"
+  [[ $source != /* ]] && source="$scriptroot/$source"
+done
+scriptroot="$( cd -P "$( dirname "$source" )" && pwd )"
+. "$scriptroot/tools.sh"
+version='Latest'
+architecture=''
+runtime='dotnet'
+runtimeSourceFeed=''
+runtimeSourceFeedKey=''
+while [[ $# > 0 ]]; do
+  opt="$(echo "$1" | tr "[:upper:]" "[:lower:]")"
+  case "$opt" in
+    -version|-v)
+      shift
+      version="$1"
+      ;;
+    -architecture|-a)
+      shift
+      architecture="$1"
+      ;;
+    -runtime|-r)
+      shift
+      runtime="$1"
+      ;;
+    -runtimesourcefeed)
+      shift
+      runtimeSourceFeed="$1"
+      ;;
+    -runtimesourcefeedkey)
+      shift
+      runtimeSourceFeedKey="$1"
+      ;;
+    *)
+      Write-PipelineTelemetryError -Category 'Build' -Message "Invalid argument: $1"
+      exit 1
+      ;;
+  esac
+  shift
+done
+cpuname=$(uname -m)
+case $cpuname in
+  arm64|aarch64)
+    buildarch=arm64
+    if [ "$(getconf LONG_BIT)" -lt 64 ]; then
+        buildarch=arm
+    fi
+    ;;
+  loongarch64)
+    buildarch=loongarch64
+    ;;
+  amd64|x86_64)
+    buildarch=x64
+    ;;
+  armv*l)
+    buildarch=arm
+    ;;
+  i[3-6]86)
+    buildarch=x86
+    ;;
+  riscv64)
+    buildarch=riscv64
+    ;;
+  *)
+    echo "Unknown CPU $cpuname detected, treating it as x64"
+    buildarch=x64
+    ;;
+esac
+dotnetRoot="${repo_root}.dotnet"
+if [[ $architecture != "" ]] && [[ $architecture != $buildarch ]]; then
+  dotnetRoot="$dotnetRoot/$architecture"
+fi
+InstallDotNet "$dotnetRoot" $version "$architecture" $runtime true $runtimeSourceFeed $runtimeSourceFeedKey || {
+  local exit_code=$?
+  Write-PipelineTelemetryError -Category 'InitializeToolset' -Message "dotnet-install.sh failed (exit code '$exit_code')." >&2
+  ExitWithExitCode $exit_code
+}
+ExitWithExitCode 0

--- a/src/coreclr/gc/gc.cpp
+++ b//dev/null
@@ -1,43254 +0,0 @@
-#include "gcpriv.h"
-#ifdef TARGET_AMD64
-#define USE_VXSORT
-#else
-#define USE_INTROSORT
-#endif
-#ifdef DACCESS_COMPILE
-#error this source file should not be compiled with DACCESS_COMPILE!
-#endif //DACCESS_COMPILE
-class gc_rand
-{
-public:
-    static uint64_t x;
-    static uint64_t get_rand()
-    {
-        x = (314159269*x+278281) & 0x7FFFFFFF;
-        return x;
-    }
-    static uint64_t get_rand(uint64_t r)
-    {
-        uint64_t x = (uint64_t)((get_rand() * r) >> 31);
-        return x;
-    }
-};
-uint64_t gc_rand::x = 0;
-#if defined(BACKGROUND_GC) && defined(FEATURE_EVENT_TRACE)
-BOOL bgc_heap_walk_for_etw_p = FALSE;
-#endif //BACKGROUND_GC && FEATURE_EVENT_TRACE
-#define MAX_PTR ((uint8_t*)(~(ptrdiff_t)0))
-#define commit_min_th (16*OS_PAGE_SIZE)
-#define MIN_SOH_CROSS_GEN_REFS (400)
-#define MIN_LOH_CROSS_GEN_REFS (800)
-#ifdef SERVER_GC
-#define partial_size_th 100
-#define num_partial_refs 64
-#else //SERVER_GC
-#define partial_size_th 100
-#define num_partial_refs 32
-#endif //SERVER_GC
-#ifdef USE_REGIONS
-#define demotion_pinned_ratio_th (1)
-#define sip_surv_ratio_th (90)
-#define sip_old_card_surv_ratio_th (90)
-#else
-#define demotion_plug_len_th (6*1024*1024)
-#endif //USE_REGIONS
-#ifdef HOST_64BIT
-#define MARK_STACK_INITIAL_LENGTH 1024
-#else
-#define MARK_STACK_INITIAL_LENGTH 128
-#endif // HOST_64BIT
-#define LOH_PIN_QUEUE_LENGTH 100
-#define LOH_PIN_DECAY 10
-#define UOH_ALLOCATION_RETRY_MAX_COUNT 2
-#define MAX_YP_SPIN_COUNT_UNIT 32768
-uint32_t yp_spin_count_unit = 0;
-uint32_t original_spin_count_unit = 0;
-size_t loh_size_threshold = LARGE_OBJECT_SIZE;
-#ifdef GC_CONFIG_DRIVEN
-int compact_ratio = 0;
-#endif //GC_CONFIG_DRIVEN
-#ifdef FEATURE_SVR_GC
-bool g_built_with_svr_gc = true;
-#else
-bool g_built_with_svr_gc = false;
-#endif // FEATURE_SVR_GC
-#if defined(BUILDENV_DEBUG)
-uint8_t g_build_variant = 0;
-#elif defined(BUILDENV_CHECKED)
-uint8_t g_build_variant = 1;
-#else
-uint8_t g_build_variant = 2;
-#endif //BUILDENV_DEBUG
-VOLATILE(int32_t) g_no_gc_lock = -1;
-#ifdef TRACE_GC
-const char * const allocation_state_str[] = {
-    "start",
-    "can_allocate",
-    "cant_allocate",
-    "retry_allocate",
-    "try_fit",
-    "try_fit_new_seg",
-    "try_fit_after_cg",
-    "try_fit_after_bgc",
-    "try_free_full_seg_in_bgc",
-    "try_free_after_bgc",
-    "try_seg_end",
-    "acquire_seg",
-    "acquire_seg_after_cg",
-    "acquire_seg_after_bgc",
-    "check_and_wait_for_bgc",
-    "trigger_full_compact_gc",
-    "trigger_ephemeral_gc",
-    "trigger_2nd_ephemeral_gc",
-    "check_retry_seg"
-};
-const char * const msl_take_state_str[] = {
-    "get_large_seg",
-    "bgc_loh_sweep",
-    "wait_bgc",
-    "block_gc",
-    "clr_mem",
-    "clr_large_mem",
-    "t_eph_gc",
-    "t_full_gc",
-    "alloc_small",
-    "alloc_large",
-    "alloc_small_cant",
-    "alloc_large_cant",
-    "try_alloc",
-    "try_budget"
-};
-#endif //TRACE_GC
-#if (defined(DT_LOG) || defined(TRACE_GC))
-static const char* const str_gc_reasons[] =
-{
-    "alloc_soh",
-    "induced",
-    "lowmem",
-    "empty",
-    "alloc_loh",
-    "oos_soh",
-    "oos_loh",
-    "induced_noforce",
-    "gcstress",
-    "induced_lowmem",
-    "induced_compacting",
-    "lowmemory_host",
-    "pm_full_gc",
-    "lowmemory_host_blocking"
-};
-static const char* const str_gc_pause_modes[] =
-{
-    "batch",
-    "interactive",
-    "low_latency",
-    "sustained_low_latency",
-    "no_gc"
-};
-static const char* const str_root_kinds[] = {
-    "Stack",
-    "FinalizeQueue",
-    "Handles",
-    "OlderGen",
-    "SizedRef",
-    "Overflow",
-    "DependentHandles",
-    "NewFQ",
-    "Steal",
-    "BGC"
-};
-#endif //DT_LOG || TRACE_GC
-inline
-BOOL is_induced (gc_reason reason)
-{
-    return ((reason == reason_induced) ||
-            (reason == reason_induced_noforce) ||
-            (reason == reason_lowmemory) ||
-            (reason == reason_lowmemory_blocking) ||
-            (reason == reason_induced_compacting) ||
-            (reason == reason_induced_aggressive) ||
-            (reason == reason_lowmemory_host) ||
-            (reason == reason_lowmemory_host_blocking));
-}
-inline
-BOOL is_induced_blocking (gc_reason reason)
-{
-    return ((reason == reason_induced) ||
-            (reason == reason_lowmemory_blocking) ||
-            (reason == reason_induced_compacting) ||
-            (reason == reason_induced_aggressive) ||
-            (reason == reason_lowmemory_host_blocking));
-}
-gc_oh_num gen_to_oh(int gen)
-{
-    switch (gen)
-    {
-        case soh_gen0:
-            return gc_oh_num::soh;
-        case soh_gen1:
-            return gc_oh_num::soh;
-        case soh_gen2:
-            return gc_oh_num::soh;
-        case loh_generation:
-            return gc_oh_num::loh;
-        case poh_generation:
-            return gc_oh_num::poh;
-        default:
-            assert(false);
-            return gc_oh_num::unknown;
-    }
-}
-uint64_t qpf;
-double qpf_ms;
-double qpf_us;
-uint64_t GetHighPrecisionTimeStamp()
-{
-    int64_t ts = GCToOSInterface::QueryPerformanceCounter();
-    return (uint64_t)((double)ts * qpf_us);
-}
-uint64_t RawGetHighPrecisionTimeStamp()
-{
-    return (uint64_t)GCToOSInterface::QueryPerformanceCounter();
-}
-#ifdef BGC_SERVO_TUNING
-bool gc_heap::bgc_tuning::enable_fl_tuning = false;
-uint32_t gc_heap::bgc_tuning::memory_load_goal = 0;
-uint32_t gc_heap::bgc_tuning::memory_load_goal_slack = 0;
-uint64_t gc_heap::bgc_tuning::available_memory_goal = 0;
-bool gc_heap::bgc_tuning::panic_activated_p = false;
-double gc_heap::bgc_tuning::accu_error_panic = 0.0;
-double gc_heap::bgc_tuning::above_goal_kp = 0.0;
-double gc_heap::bgc_tuning::above_goal_ki = 0.0;
-bool gc_heap::bgc_tuning::enable_kd = false;
-bool gc_heap::bgc_tuning::enable_ki = false;
-bool gc_heap::bgc_tuning::enable_smooth = false;
-bool gc_heap::bgc_tuning::enable_tbh = false;
-bool gc_heap::bgc_tuning::enable_ff = false;
-bool gc_heap::bgc_tuning::enable_gradual_d = false;
-double gc_heap::bgc_tuning::above_goal_kd = 0.0;
-double gc_heap::bgc_tuning::above_goal_ff = 0.0;
-double gc_heap::bgc_tuning::num_gen1s_smooth_factor = 0.0;
-double gc_heap::bgc_tuning::ml_kp = 0.0;
-double gc_heap::bgc_tuning::ml_ki = 0.0;
-double gc_heap::bgc_tuning::accu_error = 0.0;
-bool gc_heap::bgc_tuning::fl_tuning_triggered = false;
-size_t gc_heap::bgc_tuning::num_bgcs_since_tuning_trigger = 0;
-bool gc_heap::bgc_tuning::next_bgc_p = false;
-size_t gc_heap::bgc_tuning::gen1_index_last_bgc_end;
-size_t gc_heap::bgc_tuning::gen1_index_last_bgc_start;
-size_t gc_heap::bgc_tuning::gen1_index_last_bgc_sweep;
-size_t gc_heap::bgc_tuning::actual_num_gen1s_to_trigger;
-gc_heap::bgc_tuning::tuning_calculation gc_heap::bgc_tuning::gen_calc[2];
-gc_heap::bgc_tuning::tuning_stats gc_heap::bgc_tuning::gen_stats[2];
-gc_heap::bgc_tuning::bgc_size_data gc_heap::bgc_tuning::current_bgc_end_data[2];
-size_t gc_heap::bgc_tuning::last_stepping_bgc_count = 0;
-uint32_t gc_heap::bgc_tuning::last_stepping_mem_load = 0;
-uint32_t gc_heap::bgc_tuning::stepping_interval = 0;
-bool gc_heap::bgc_tuning::use_stepping_trigger_p = true;
-double gc_heap::bgc_tuning::gen2_ratio_correction = 0.0;
-double gc_heap::bgc_tuning::ratio_correction_step = 0.0;
-int gc_heap::saved_bgc_tuning_reason = -1;
-#endif //BGC_SERVO_TUNING
-inline
-size_t round_up_power2 (size_t size)
-{
-    DWORD highest_set_bit_index;
-    if (0 ==
-#ifdef HOST_64BIT
-        BitScanReverse64(
-#else
-        BitScanReverse(
-#endif
-            &highest_set_bit_index, size - 1)) { return 1; }
-    return static_cast<size_t>(2) << highest_set_bit_index;
-}
-inline
-size_t round_down_power2 (size_t size)
-{
-    DWORD highest_set_bit_index;
-    if (0 ==
-#ifdef HOST_64BIT
-        BitScanReverse64(
-#else
-        BitScanReverse(
-#endif
-            &highest_set_bit_index, size)) { return 0; }
-    return static_cast<size_t>(1) << highest_set_bit_index;
-}
-inline
-int index_of_highest_set_bit (size_t value)
-{
-    DWORD highest_set_bit_index;
-    return (0 ==
-#ifdef HOST_64BIT
-        BitScanReverse64(
-#else
-        BitScanReverse(
-#endif
-            &highest_set_bit_index, value)) ? -1 : static_cast<int>(highest_set_bit_index);
-}
-inline
-int relative_index_power2_plug (size_t power2)
-{
-    int index = index_of_highest_set_bit (power2);
-    assert (index <= MAX_INDEX_POWER2);
-    return ((index < MIN_INDEX_POWER2) ? 0 : (index - MIN_INDEX_POWER2));
-}
-inline
-int relative_index_power2_free_space (size_t power2)
-{
-    int index = index_of_highest_set_bit (power2);
-    assert (index <= MAX_INDEX_POWER2);
-    return ((index < MIN_INDEX_POWER2) ? -1 : (index - MIN_INDEX_POWER2));
-}
-inline
-float mb (size_t num)
-{
-    return (float)((float)num / 1000.0 / 1000.0);
-}
-#ifdef BACKGROUND_GC
-uint32_t bgc_alloc_spin_count = 140;
-uint32_t bgc_alloc_spin_count_uoh = 16;
-uint32_t bgc_alloc_spin = 2;
-inline
-void c_write (uint32_t& place, uint32_t value)
-{
-    Interlocked::Exchange (&place, value);
-}
-const size_t bgc_min_per_heap = 4*1024*1024;
-int gc_heap::gchist_index = 0;
-gc_mechanisms_store gc_heap::gchist[max_history_count];
-#ifndef MULTIPLE_HEAPS
-VOLATILE(bgc_state) gc_heap::current_bgc_state = bgc_not_in_process;
-int gc_heap::gchist_index_per_heap = 0;
-gc_heap::gc_history gc_heap::gchist_per_heap[max_history_count];
-#endif //MULTIPLE_HEAPS
-#endif //BACKGROUND_GC
-void gc_heap::add_to_history_per_heap()
-{
-#if defined(GC_HISTORY) && defined(BACKGROUND_GC)
-    gc_history* current_hist = &gchist_per_heap[gchist_index_per_heap];
-    current_hist->gc_index = settings.gc_index;
-    current_hist->current_bgc_state = current_bgc_state;
-    size_t elapsed = dd_gc_elapsed_time (dynamic_data_of (0));
-    current_hist->gc_time_ms = (uint32_t)(elapsed / 1000);
-    current_hist->gc_efficiency = (elapsed ? (total_promoted_bytes / elapsed) : total_promoted_bytes);
-#ifndef USE_REGIONS
-    current_hist->eph_low = generation_allocation_start (generation_of (max_generation - 1));
-    current_hist->gen0_start = generation_allocation_start (generation_of (0));
-    current_hist->eph_high = heap_segment_allocated (ephemeral_heap_segment);
-#endif //!USE_REGIONS
-#ifdef BACKGROUND_GC
-    current_hist->bgc_lowest = background_saved_lowest_address;
-    current_hist->bgc_highest = background_saved_highest_address;
-#endif //BACKGROUND_GC
-    current_hist->fgc_lowest = lowest_address;
-    current_hist->fgc_highest = highest_address;
-    current_hist->g_lowest = g_gc_lowest_address;
-    current_hist->g_highest = g_gc_highest_address;
-    gchist_index_per_heap++;
-    if (gchist_index_per_heap == max_history_count)
-    {
-        gchist_index_per_heap = 0;
-    }
-#endif //GC_HISTORY && BACKGROUND_GC
-}
-void gc_heap::add_to_history()
-{
-#if defined(GC_HISTORY) && defined(BACKGROUND_GC)
-    gc_mechanisms_store* current_settings = &gchist[gchist_index];
-    current_settings->store (&settings);
-    gchist_index++;
-    if (gchist_index == max_history_count)
-    {
-        gchist_index = 0;
-    }
-#endif //GC_HISTORY && BACKGROUND_GC
-}
-#ifdef GC_CONFIG_DRIVEN
-BOOL   gc_config_log_on = FALSE;
-FILE* gc_config_log = NULL;
-#define gc_config_log_buffer_size (1*1024) // TEMP
-uint8_t* gc_config_log_buffer = 0;
-size_t gc_config_log_buffer_offset = 0;
-void log_va_msg_config(const char *fmt, va_list args)
-{
-    const int BUFFERSIZE = 256;
-    static char rgchBuffer[BUFFERSIZE];
-    char *  pBuffer  = &rgchBuffer[0];
-    pBuffer[0] = '\n';
-    int buffer_start = 1;
-    int msg_len = _vsnprintf_s (&pBuffer[buffer_start], BUFFERSIZE - buffer_start, _TRUNCATE, fmt, args );
-    assert (msg_len != -1);
-    msg_len += buffer_start;
-    if ((gc_config_log_buffer_offset + msg_len) > gc_config_log_buffer_size)
-    {
-        fwrite(gc_config_log_buffer, gc_config_log_buffer_offset, 1, gc_config_log);
-        fflush(gc_config_log);
-        gc_config_log_buffer_offset = 0;
-    }
-    memcpy (gc_config_log_buffer + gc_config_log_buffer_offset, pBuffer, msg_len);
-    gc_config_log_buffer_offset += msg_len;
-}
-void GCLogConfig (const char *fmt, ... )
-{
-    if (gc_config_log_on && (gc_config_log != NULL))
-    {
-        va_list     args;
-        va_start( args, fmt );
-        log_va_msg_config (fmt, args);
-    }
-}
-#endif // GC_CONFIG_DRIVEN
-void GCHeap::Shutdown()
-{
-#if defined(TRACE_GC) && defined(SIMPLE_DPRINTF) && !defined(BUILD_AS_STANDALONE)
-    flush_gc_log (true);
-#endif //TRACE_GC && SIMPLE_DPRINTF && !BUILD_AS_STANDALONE
-}
-#ifdef SYNCHRONIZATION_STATS
-static unsigned int         gc_count_during_log;
-static const unsigned int   log_interval = 5000;
-static uint64_t             log_start_tick;
-static unsigned int         gc_lock_contended;
-static int64_t              log_start_hires;
-static uint64_t             suspend_ee_during_log;
-static uint64_t             restart_ee_during_log;
-static uint64_t             gc_during_log;
-#endif //SYNCHRONIZATION_STATS
-void
-init_sync_log_stats()
-{
-#ifdef SYNCHRONIZATION_STATS
-    if (gc_count_during_log == 0)
-    {
-        gc_heap::init_sync_stats();
-        suspend_ee_during_log = 0;
-        restart_ee_during_log = 0;
-        gc_during_log = 0;
-        gc_lock_contended = 0;
-        log_start_tick = GCToOSInterface::GetLowPrecisionTimeStamp();
-        log_start_hires = GCToOSInterface::QueryPerformanceCounter();
-    }
-    gc_count_during_log++;
-#endif //SYNCHRONIZATION_STATS
-}
-void
-process_sync_log_stats()
-{
-#ifdef SYNCHRONIZATION_STATS
-    uint64_t log_elapsed = GCToOSInterface::GetLowPrecisionTimeStamp() - log_start_tick;
-    if (log_elapsed > log_interval)
-    {
-        uint64_t total = GCToOSInterface::QueryPerformanceCounter() - log_start_hires;
-        printf("\n_________________________________________________________________________________\n"
-            "Past %d(s): #%3d GCs; Total gc_lock contended: %8u; GC: %12u\n"
-            "SuspendEE: %8u; RestartEE: %8u GC %.3f%%\n",
-            log_interval / 1000,
-            gc_count_during_log,
-            gc_lock_contended,
-            (unsigned int)(gc_during_log / gc_count_during_log),
-            (unsigned int)(suspend_ee_during_log / gc_count_during_log),
-            (unsigned int)(restart_ee_during_log / gc_count_during_log),
-            (double)(100.0f * gc_during_log / total));
-        gc_heap::print_sync_stats(gc_count_during_log);
-        gc_count_during_log = 0;
-    }
-#endif //SYNCHRONIZATION_STATS
-}
-#ifdef MULTIPLE_HEAPS
-uint32_t g_num_active_processors = 0;
-enum gc_join_stage
-{
-    gc_join_init_cpu_mapping = 0,
-    gc_join_done = 1,
-    gc_join_generation_determined = 2,
-    gc_join_begin_mark_phase = 3,
-    gc_join_scan_dependent_handles = 4,
-    gc_join_rescan_dependent_handles = 5,
-    gc_join_scan_sizedref_done = 6,
-    gc_join_null_dead_short_weak = 7,
-    gc_join_scan_finalization = 8,
-    gc_join_null_dead_long_weak = 9,
-    gc_join_null_dead_syncblk = 10,
-    gc_join_decide_on_compaction = 11,
-    gc_join_rearrange_segs_compaction = 12,
-    gc_join_adjust_handle_age_compact = 13,
-    gc_join_adjust_handle_age_sweep = 14,
-    gc_join_begin_relocate_phase = 15,
-    gc_join_relocate_phase_done = 16,
-    gc_join_verify_objects_done = 17,
-    gc_join_start_bgc = 18,
-    gc_join_restart_ee = 19,
-    gc_join_concurrent_overflow = 20,
-    gc_join_suspend_ee = 21,
-    gc_join_bgc_after_ephemeral = 22,
-    gc_join_allow_fgc = 23,
-    gc_join_bgc_sweep = 24,
-    gc_join_suspend_ee_verify = 25,
-    gc_join_restart_ee_verify = 26,
-    gc_join_set_state_free = 27,
-    gc_r_join_update_card_bundle = 28,
-    gc_join_after_absorb = 29,
-    gc_join_verify_copy_table = 30,
-    gc_join_after_reset = 31,
-    gc_join_after_ephemeral_sweep = 32,
-    gc_join_after_profiler_heap_walk = 33,
-    gc_join_minimal_gc = 34,
-    gc_join_after_commit_soh_no_gc = 35,
-    gc_join_expand_loh_no_gc = 36,
-    gc_join_final_no_gc = 37,
-    gc_join_disable_software_write_watch = 38,
-    gc_join_merge_temp_fl = 39,
-    gc_join_max = 40
-};
-enum gc_join_flavor
-{
-    join_flavor_server_gc = 0,
-    join_flavor_bgc = 1
-};
-#define first_thread_arrived 2
-#pragma warning(push)
-#pragma warning(disable:4324) // don't complain if DECLSPEC_ALIGN actually pads
-struct DECLSPEC_ALIGN(HS_CACHE_LINE_SIZE) join_structure
-{
-    int n_threads;
-    DECLSPEC_ALIGN(HS_CACHE_LINE_SIZE)
-    GCEvent joined_event[3]; // the last event in the array is only used for first_thread_arrived.
-    Volatile<int> lock_color;
-    VOLATILE(BOOL) wait_done;
-    VOLATILE(BOOL) joined_p;
-    DECLSPEC_ALIGN(HS_CACHE_LINE_SIZE)
-    VOLATILE(int) join_lock;
-    VOLATILE(int) r_join_lock;
-};
-#pragma warning(pop)
-enum join_type
-{
-    type_last_join = 0,
-    type_join = 1,
-    type_restart = 2,
-    type_first_r_join = 3,
-    type_r_join = 4
-};
-enum join_time
-{
-    time_start = 0,
-    time_end = 1
-};
-enum join_heap_index
-{
-    join_heap_restart = 100,
-    join_heap_r_restart = 200
-};
-class t_join
-{
-    join_structure join_struct;
-    int id;
-    gc_join_flavor flavor;
-#ifdef JOIN_STATS
-    uint64_t start[MAX_SUPPORTED_CPUS], end[MAX_SUPPORTED_CPUS], start_seq;
-    int thd;
-    uint64_t start_tick;
-    uint64_t elapsed_total[gc_join_max], wake_total[gc_join_max], seq_loss_total[gc_join_max], par_loss_total[gc_join_max], in_join_total[gc_join_max];
-#endif //JOIN_STATS
-public:
-    BOOL init (int n_th, gc_join_flavor f)
-    {
-        dprintf (JOIN_LOG, ("Initializing join structure"));
-        join_struct.n_threads = n_th;
-        join_struct.lock_color = 0;
-        for (int i = 0; i < 3; i++)
-        {
-            if (!join_struct.joined_event[i].IsValid())
-            {
-                join_struct.joined_p = FALSE;
-                dprintf (JOIN_LOG, ("Creating join event %d", i));
-                if (!join_struct.joined_event[i].CreateManualEventNoThrow(FALSE))
-                    return FALSE;
-            }
-        }
-        join_struct.join_lock = join_struct.n_threads;
-        join_struct.r_join_lock = join_struct.n_threads;
-        join_struct.wait_done = FALSE;
-        flavor = f;
-#ifdef JOIN_STATS
-        start_tick = GCToOSInterface::GetLowPrecisionTimeStamp();
-#endif //JOIN_STATS
-        return TRUE;
-    }
-    void update_n_threads(int n_th)
-    {
-        join_struct.n_threads = n_th;
-        join_struct.join_lock = n_th;
-        join_struct.r_join_lock = n_th;
-    }
-    int get_num_threads()
-    {
-        return join_struct.n_threads;
-    }
-    int get_join_lock()
-    {
-        return VolatileLoadWithoutBarrier (&join_struct.join_lock);
-    }
-    void destroy ()
-    {
-        dprintf (JOIN_LOG, ("Destroying join structure"));
-        for (int i = 0; i < 3; i++)
-        {
-            if (join_struct.joined_event[i].IsValid())
-                join_struct.joined_event[i].CloseEvent();
-        }
-    }
-    inline void fire_event (int heap, join_time time, join_type type, int join_id)
-    {
-        FIRE_EVENT(GCJoin_V2, heap, time, type, join_id);
-    }
-    void join (gc_heap* gch, int join_id)
-    {
-#ifdef JOIN_STATS
-        end[gch->heap_number] = get_ts();
-#endif //JOIN_STATS
-        assert (!join_struct.joined_p);
-        int color = join_struct.lock_color.LoadWithoutBarrier();
-        if (Interlocked::Decrement(&join_struct.join_lock) != 0)
-        {
-            dprintf (JOIN_LOG, ("join%d(%d): Join() Waiting...join_lock is now %d",
-                flavor, join_id, (int32_t)(join_struct.join_lock)));
-            fire_event (gch->heap_number, time_start, type_join, join_id);
-            if (color == join_struct.lock_color.LoadWithoutBarrier())
-            {
-respin:
-                int spin_count = 128 * yp_spin_count_unit;
-                for (int j = 0; j < spin_count; j++)
-                {
-                    if (color != join_struct.lock_color.LoadWithoutBarrier())
-                    {
-                        break;
-                    }
-                    YieldProcessor();           // indicate to the processor that we are spinning
-                }
-                if (color == join_struct.lock_color.LoadWithoutBarrier())
-                {
-                    dprintf (JOIN_LOG, ("join%d(%d): Join() hard wait on reset event %d, join_lock is now %d",
-                        flavor, join_id, color, (int32_t)(join_struct.join_lock)));
-                    uint32_t dwJoinWait = join_struct.joined_event[color].Wait(INFINITE, FALSE);
-                    if (dwJoinWait != WAIT_OBJECT_0)
-                    {
-                        STRESS_LOG1 (LF_GC, LL_FATALERROR, "joined event wait failed with code: %zx", dwJoinWait);
-                        FATAL_GC_ERROR ();
-                    }
-                }
-                if (color == join_struct.lock_color.LoadWithoutBarrier())
-                {
-                    dprintf (9999, ("---h%d %d j%d %d - respin!!! (c:%d-%d)",
-                        gch->heap_number, join_id, join_struct.n_threads, color, join_struct.lock_color.LoadWithoutBarrier()));
-                    goto respin;
-                }
-                dprintf (JOIN_LOG, ("join%d(%d): Join() done, join_lock is %d",
-                    flavor, join_id, (int32_t)(join_struct.join_lock)));
-            }
-            fire_event (gch->heap_number, time_end, type_join, join_id);
-#ifdef JOIN_STATS
-            start[gch->heap_number] = get_ts();
-            Interlocked::ExchangeAdd(&in_join_total[join_id], (start[gch->heap_number] - end[gch->heap_number]));
-#endif //JOIN_STATS
-        }
-        else
-        {
-            fire_event (gch->heap_number, time_start, type_last_join, join_id);
-            join_struct.joined_p = TRUE;
-            dprintf (JOIN_LOG, ("join%d(%d): Last thread to complete the join, setting id", flavor, join_id));
-            join_struct.joined_event[!color].Reset();
-            id = join_id;
-#ifdef JOIN_STATS
-            thd = gch->heap_number;
-            start_seq = get_ts();
-            Interlocked::ExchangeAdd(&in_join_total[join_id], (start_seq - end[gch->heap_number]));
-#endif //JOIN_STATS
-        }
-    }
-    BOOL r_join (gc_heap* gch, int join_id)
-    {
-        if (join_struct.n_threads == 1)
-        {
-            return TRUE;
-        }
-        if (Interlocked::CompareExchange(&join_struct.r_join_lock, 0, join_struct.n_threads) == 0)
-        {
-            fire_event (gch->heap_number, time_start, type_join, join_id);
-            dprintf (JOIN_LOG, ("r_join() Waiting..."));
-respin:
-            int spin_count = 256 * yp_spin_count_unit;
-            for (int j = 0; j < spin_count; j++)
-            {
-                if (join_struct.wait_done)
-                {
-                    break;
-                }
-                YieldProcessor();           // indicate to the processor that we are spinning
-            }
-            if (!join_struct.wait_done)
-            {
-                dprintf (JOIN_LOG, ("Join() hard wait on reset event %d", first_thread_arrived));
-                uint32_t dwJoinWait = join_struct.joined_event[first_thread_arrived].Wait(INFINITE, FALSE);
-                if (dwJoinWait != WAIT_OBJECT_0)
-                {
-                    STRESS_LOG1 (LF_GC, LL_FATALERROR, "joined event wait failed with code: %zx", dwJoinWait);
-                    FATAL_GC_ERROR ();
-                }
-            }
-            if (!join_struct.wait_done)
-            {
-                goto respin;
-            }
-            dprintf (JOIN_LOG, ("r_join() done"));
-            fire_event (gch->heap_number, time_end, type_join, join_id);
-            return FALSE;
-        }
-        else
-        {
-            fire_event (gch->heap_number, time_start, type_first_r_join, join_id);
-            return TRUE;
-        }
-    }
-#ifdef JOIN_STATS
-    uint64_t get_ts()
-    {
-        return GCToOSInterface::QueryPerformanceCounter();
-    }
-    void start_ts (gc_heap* gch)
-    {
-        start[gch->heap_number] = get_ts();
-    }
-#endif //JOIN_STATS
-    void restart()
-    {
-#ifdef JOIN_STATS
-        uint64_t elapsed_seq = get_ts() - start_seq;
-        uint64_t max = 0, sum = 0, wake = 0;
-        uint64_t min_ts = start[0];
-        for (int i = 1; i < join_struct.n_threads; i++)
-        {
-            if(min_ts > start[i]) min_ts = start[i];
-        }
-        for (int i = 0; i < join_struct.n_threads; i++)
-        {
-            uint64_t wake_delay = start[i] - min_ts;
-            uint64_t elapsed = end[i] - start[i];
-            if (max < elapsed)
-                max = elapsed;
-            sum += elapsed;
-            wake += wake_delay;
-        }
-        uint64_t seq_loss = (join_struct.n_threads - 1)*elapsed_seq;
-        uint64_t par_loss = join_struct.n_threads*max - sum;
-        double efficiency = 0.0;
-        if (max > 0)
-            efficiency = sum*100.0/(join_struct.n_threads*max);
-        const double ts_scale = 1e-6;
-        elapsed_total[id] += sum;
-        wake_total[id] += wake;
-        seq_loss_total[id] += seq_loss;
-        par_loss_total[id] += par_loss;
-        if (GCToOSInterface::GetLowPrecisionTimeStamp() - start_tick > 10*1000)
-        {
-            printf("**** summary *****\n");
-            for (int i = 0; i < 16; i++)
-            {
-                printf("join #%3d  elapsed_total = %8g wake_loss = %8g seq_loss = %8g  par_loss = %8g  in_join_total = %8g\n",
-                   i,
-                   ts_scale*elapsed_total[i],
-                   ts_scale*wake_total[i],
-                   ts_scale*seq_loss_total[i],
-                   ts_scale*par_loss_total[i],
-                   ts_scale*in_join_total[i]);
-                elapsed_total[i] = wake_total[i] = seq_loss_total[i] = par_loss_total[i] = in_join_total[i] = 0;
-            }
-            start_tick = GCToOSInterface::GetLowPrecisionTimeStamp();
-        }
-#endif //JOIN_STATS
-        fire_event (join_heap_restart, time_start, type_restart, -1);
-        assert (join_struct.joined_p);
-        join_struct.joined_p = FALSE;
-        join_struct.join_lock = join_struct.n_threads;
-        dprintf (JOIN_LOG, ("join%d(%d): Restarting from join: join_lock is %d", flavor, id, (int32_t)(join_struct.join_lock)));
-        int color = join_struct.lock_color.LoadWithoutBarrier();
-        join_struct.lock_color = !color;
-        join_struct.joined_event[color].Set();
-        fire_event (join_heap_restart, time_end, type_restart, -1);
-#ifdef JOIN_STATS
-        start[thd] = get_ts();
-#endif //JOIN_STATS
-    }
-    BOOL joined()
-    {
-        dprintf (JOIN_LOG, ("join%d(%d): joined, join_lock is %d", flavor, id, (int32_t)(join_struct.join_lock)));
-        return join_struct.joined_p;
-    }
-    void r_restart()
-    {
-        if (join_struct.n_threads != 1)
-        {
-            fire_event (join_heap_r_restart, time_start, type_restart, -1);
-            join_struct.wait_done = TRUE;
-            join_struct.joined_event[first_thread_arrived].Set();
-            fire_event (join_heap_r_restart, time_end, type_restart, -1);
-        }
-    }
-    void r_init()
-    {
-        if (join_struct.n_threads != 1)
-        {
-            join_struct.r_join_lock = join_struct.n_threads;
-            join_struct.wait_done = FALSE;
-            join_struct.joined_event[first_thread_arrived].Reset();
-        }
-    }
-};
-t_join gc_t_join;
-#ifdef BACKGROUND_GC
-t_join bgc_t_join;
-#endif //BACKGROUND_GC
-#endif //MULTIPLE_HEAPS
-#define spin_and_switch(count_to_spin, expr) \
-{ \
-    for (int j = 0; j < count_to_spin; j++) \
-    { \
-        if (expr) \
-        { \
-            break;\
-        } \
-        YieldProcessor(); \
-    } \
-    if (!(expr)) \
-    { \
-        GCToOSInterface::YieldThread(0); \
-    } \
-}
-#define spin_and_wait(count_to_spin, expr) \
-{ \
-    while (!expr) \
-    { \
-        for (int j = 0; j < count_to_spin; j++) \
-        { \
-            if (expr) \
-            { \
-                break; \
-            } \
-                YieldProcessor (); \
-        } \
-        if (!(expr)) \
-        { \
-            GCToOSInterface::YieldThread (0); \
-        } \
-    } \
-}
-#ifdef BACKGROUND_GC
-#define max_pending_allocs 64
-class exclusive_sync
-{
-    VOLATILE(uint8_t*) rwp_object;
-    VOLATILE(int32_t) needs_checking;
-    int spin_count;
-    uint8_t cache_separator[HS_CACHE_LINE_SIZE - (sizeof (spin_count) + sizeof (needs_checking) + sizeof (rwp_object))];
-    VOLATILE(uint8_t*) alloc_objects[max_pending_allocs];
-    int find_free_index ()
-    {
-        for (int i = 0; i < max_pending_allocs; i++)
-        {
-            if (alloc_objects [i] == (uint8_t*)0)
-            {
-                return i;
-            }
-        }
-        return -1;
-    }
-public:
-    void init()
-    {
-        spin_count = 32 * (g_num_processors - 1);
-        rwp_object = 0;
-        needs_checking = 0;
-        for (int i = 0; i < max_pending_allocs; i++)
-        {
-            alloc_objects [i] = (uint8_t*)0;
-        }
-    }
-    void check()
-    {
-        for (int i = 0; i < max_pending_allocs; i++)
-        {
-            if (alloc_objects [i] != (uint8_t*)0)
-            {
-                FATAL_GC_ERROR();
-            }
-        }
-    }
-    void bgc_mark_set (uint8_t* obj)
-    {
-        dprintf (3, ("cm: probing %p", obj));
-retry:
-        if (Interlocked::CompareExchange(&needs_checking, 1, 0) == 0)
-        {
-            for (int i = 0; i < max_pending_allocs; i++)
-            {
-                if (obj == alloc_objects[i])
-                {
-                    needs_checking = 0;
-                    dprintf (3, ("cm: will spin"));
-                    spin_and_switch (spin_count, (obj != alloc_objects[i]));
-                    goto retry;
-                }
-            }
-            rwp_object = obj;
-            needs_checking = 0;
-            dprintf (3, ("cm: set %p", obj));
-            return;
-        }
-        else
-        {
-            spin_and_switch (spin_count, (needs_checking == 0));
-            goto retry;
-        }
-    }
-    int uoh_alloc_set (uint8_t* obj)
-    {
-        if (!gc_heap::cm_in_progress)
-        {
-            return -1;
-        }
-retry:
-        dprintf (3, ("uoh alloc: probing %p", obj));
-        if (Interlocked::CompareExchange(&needs_checking, 1, 0) == 0)
-        {
-            if (obj == rwp_object)
-            {
-                needs_checking = 0;
-                spin_and_switch (spin_count, (obj != rwp_object));
-                goto retry;
-            }
-            else
-            {
-                int cookie = find_free_index();
-                if (cookie != -1)
-                {
-                    alloc_objects[cookie] = obj;
-                    needs_checking = 0;
-                    dprintf (3, ("uoh alloc: set %p at %d", obj, cookie));
-                    return cookie;
-                }
-                else
-                {
-                    needs_checking = 0;
-                    dprintf (3, ("uoh alloc: setting %p will spin to acquire a free index", obj));
-                    spin_and_switch (spin_count, (find_free_index () != -1));
-                    goto retry;
-                }
-            }
-        }
-        else
-        {
-            dprintf (3, ("uoh alloc: will spin on checking %p", obj));
-            spin_and_switch (spin_count, (needs_checking == 0));
-            goto retry;
-        }
-    }
-    void bgc_mark_done ()
-    {
-        dprintf (3, ("cm: release lock on %p", (uint8_t *)rwp_object));
-        rwp_object = 0;
-    }
-    void uoh_alloc_done_with_index (int index)
-    {
-        dprintf (3, ("uoh alloc: release lock on %p based on %d", (uint8_t *)alloc_objects[index], index));
-        assert ((index >= 0) && (index < max_pending_allocs));
-        alloc_objects[index] = (uint8_t*)0;
-    }
-    void uoh_alloc_done (uint8_t* obj)
-    {
-        if (!gc_heap::cm_in_progress)
-        {
-            return;
-        }
-        for (int i = 0; i < max_pending_allocs; i++)
-        {
-            if (alloc_objects [i] == obj)
-            {
-                uoh_alloc_done_with_index(i);
-                return;
-            }
-        }
-        dprintf (3, ("uoh alloc: could not release lock on %p", obj));
-    }
-};
-#endif //BACKGROUND_GC
-void reset_memory (uint8_t* o, size_t sizeo);
-#ifdef WRITE_WATCH
-#ifndef FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-static bool virtual_alloc_hardware_write_watch = false;
-#endif // !FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-static bool hardware_write_watch_capability = false;
-void hardware_write_watch_api_supported()
-{
-    if (GCToOSInterface::SupportsWriteWatch())
-    {
-        hardware_write_watch_capability = true;
-        dprintf (2, ("WriteWatch supported"));
-    }
-    else
-    {
-        dprintf (2,("WriteWatch not supported"));
-    }
-}
-inline bool can_use_hardware_write_watch()
-{
-    return hardware_write_watch_capability;
-}
-inline bool can_use_write_watch_for_gc_heap()
-{
-#ifdef FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-    return true;
-#else // !FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-    return can_use_hardware_write_watch();
-#endif // FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-}
-inline bool can_use_write_watch_for_card_table()
-{
-#ifdef FEATURE_MANUALLY_MANAGED_CARD_BUNDLES
-    return true;
-#else
-    return can_use_hardware_write_watch();
-#endif
-}
-#else //WRITE_WATCH
-#define mem_reserve (MEM_RESERVE)
-#endif //WRITE_WATCH
-void WaitLongerNoInstru (int i)
-{
-    bool bToggleGC = GCToEEInterface::EnablePreemptiveGC();
-    if (g_fSuspensionPending == 0)
-    {
-        if  (g_num_processors > 1)
-        {
-            YieldProcessor();           // indicate to the processor that we are spinning
-            if  (i & 0x01f)
-                GCToOSInterface::YieldThread (0);
-            else
-                GCToOSInterface::Sleep (5);
-        }
-        else
-            GCToOSInterface::Sleep (5);
-    }
-    if (bToggleGC)
-    {
-#ifdef _DEBUG
-        if (gc_heap::gc_started)
-        {
-            gc_heap::wait_for_gc_done();
-        }
-#endif // _DEBUG
-        GCToEEInterface::DisablePreemptiveGC();
-    }
-    else if (g_fSuspensionPending > 0)
-    {
-        g_theGCHeap->WaitUntilGCComplete();
-    }
-}
-inline
-static void safe_switch_to_thread()
-{
-    bool cooperative_mode = gc_heap::enable_preemptive();
-    GCToOSInterface::YieldThread(0);
-    gc_heap::disable_preemptive(cooperative_mode);
-}
-#define check_msl_status(msg, size) if (msl_status == msl_retry_different_heap) \
-    { \
-        dprintf (5555, ("h%d RETRY %s(%Id)", heap_number, msg, size)); \
-        return a_state_retry_allocate; \
-    }
-static const int32_t lock_free = -1;
-static const int32_t lock_taken = 0;
-static const int32_t lock_decommissioned = 1;
-bool gc_heap::should_move_heap (GCSpinLock* msl)
-{
-#ifdef MULTIPLE_HEAPS
-    if (msl->lock == lock_decommissioned)
-    {
-        dprintf (5555, ("heap#%d got decommissioned! need to retry", heap_number));
-    }
-    return (msl->lock == lock_decommissioned);
-#else //MULTIPLE_HEAPS
-    return false;
-#endif //MULTIPLE_HEAPS
-}
-enter_msl_status gc_heap::enter_spin_lock_msl_helper (GCSpinLock* msl)
-{
-    do
-    {
-#ifdef DYNAMIC_HEAP_COUNT
-        uint64_t start = GetHighPrecisionTimeStamp();
-#endif //DYNAMIC_HEAP_COUNT
-        unsigned int i = 0;
-        while (VolatileLoad (&msl->lock) != lock_free)
-        {
-            if (should_move_heap (msl))
-            {
-                return msl_retry_different_heap;
-            }
-            if ((++i & 7) && !IsGCInProgress ())
-            {
-                if (g_num_processors > 1)
-                {
-#ifndef MULTIPLE_HEAPS
-                    int spin_count = 32 * yp_spin_count_unit;
-#else //!MULTIPLE_HEAPS
-                    int spin_count = yp_spin_count_unit;
-#endif //!MULTIPLE_HEAPS
-                    for (int j = 0; j < spin_count; j++)
-                    {
-                        if (VolatileLoad (&msl->lock) == lock_free || IsGCInProgress ())
-                            break;
-                        YieldProcessor ();
-                    }
-                    if (VolatileLoad (&msl->lock) != lock_free && !IsGCInProgress ())
-                    {
-#ifdef DYNAMIC_HEAP_COUNT
-                        start -= GetHighPrecisionTimeStamp();
-#endif //DYNAMIC_HEAP_COUNT
-                        safe_switch_to_thread ();
-#ifdef DYNAMIC_HEAP_COUNT
-                        start += GetHighPrecisionTimeStamp();
-#endif //DYNAMIC_HEAP_COUNT
-                    }
-                }
-                else
-                {
-                    safe_switch_to_thread ();
-                }
-            }
-            else
-            {
-#ifdef DYNAMIC_HEAP_COUNT
-                start -= GetHighPrecisionTimeStamp();
-#endif //DYNAMIC_HEAP_COUNT
-                WaitLongerNoInstru (i);
-#ifdef DYNAMIC_HEAP_COUNT
-                start += GetHighPrecisionTimeStamp();
-#endif //DYNAMIC_HEAP_COUNT
-            }
-        }
-#ifdef DYNAMIC_HEAP_COUNT
-        uint64_t end = GetHighPrecisionTimeStamp();
-        Interlocked::ExchangeAdd64 (&msl->msl_wait_time, end - start);
-        dprintf (3, ("h%d wait for msl lock wait time %zd, total wait time: %zd", heap_number, (end - start), msl->msl_wait_time));
-#endif //DYNAMIC_HEAP_COUNT
-    }
-    while (Interlocked::CompareExchange (&msl->lock, lock_taken, lock_free) != lock_free);
-    return msl_entered;
-}
-inline
-enter_msl_status gc_heap::enter_spin_lock_msl (GCSpinLock* msl)
-{
-    if (Interlocked::CompareExchange (&msl->lock, lock_taken, lock_free) == lock_free)
-        return msl_entered;
-    return enter_spin_lock_msl_helper (msl);
-}
-inline
-static void enter_spin_lock_noinstru (RAW_KEYWORD(volatile) int32_t* lock)
-{
-retry:
-    if (Interlocked::CompareExchange(lock, lock_taken, lock_free) != lock_free)
-    {
-        unsigned int i = 0;
-        while (VolatileLoad(lock) != lock_free)
-        {
-            assert (VolatileLoad(lock) != lock_decommissioned);
-            if ((++i & 7) && !IsGCInProgress())
-            {
-                if  (g_num_processors > 1)
-                {
-#ifndef MULTIPLE_HEAPS
-                    int spin_count = 32 * yp_spin_count_unit;
-#else //!MULTIPLE_HEAPS
-                    int spin_count = yp_spin_count_unit;
-#endif //!MULTIPLE_HEAPS
-                    for (int j = 0; j < spin_count; j++)
-                    {
-                        if  (VolatileLoad(lock) == lock_free || IsGCInProgress())
-                            break;
-                        YieldProcessor();           // indicate to the processor that we are spinning
-                    }
-                    if  (VolatileLoad(lock) != lock_free && !IsGCInProgress())
-                    {
-                        safe_switch_to_thread();
-                    }
-                }
-                else
-                {
-                    safe_switch_to_thread();
-                }
-            }
-            else
-            {
-                WaitLongerNoInstru(i);
-            }
-        }
-        goto retry;
-    }
-}
-inline
-static BOOL try_enter_spin_lock_noinstru(RAW_KEYWORD(volatile) int32_t* lock)
-{
-    return (Interlocked::CompareExchange(&*lock, lock_taken, lock_free) == lock_free);
-}
-inline
-static void leave_spin_lock_noinstru (RAW_KEYWORD(volatile) int32_t* lock)
-{
-    VolatileStore<int32_t>((int32_t*)lock, lock_free);
-}
-#ifdef _DEBUG
-inline
-static void enter_spin_lock (GCSpinLock *pSpinLock)
-{
-    enter_spin_lock_noinstru (&pSpinLock->lock);
-    assert (pSpinLock->holding_thread == (Thread*)-1);
-    pSpinLock->holding_thread = GCToEEInterface::GetThread();
-}
-inline
-static BOOL try_enter_spin_lock(GCSpinLock *pSpinLock)
-{
-    BOOL ret = try_enter_spin_lock_noinstru(&pSpinLock->lock);
-    if (ret)
-        pSpinLock->holding_thread = GCToEEInterface::GetThread();
-    return ret;
-}
-inline
-static void leave_spin_lock(GCSpinLock *pSpinLock)
-{
-    bool gc_thread_p = GCToEEInterface::WasCurrentThreadCreatedByGC();
-    pSpinLock->released_by_gc_p = gc_thread_p;
-    pSpinLock->holding_thread = (Thread*) -1;
-    if (pSpinLock->lock != lock_free)
-        leave_spin_lock_noinstru(&pSpinLock->lock);
-}
-#define ASSERT_HOLDING_SPIN_LOCK(pSpinLock) \
-    _ASSERTE((pSpinLock)->holding_thread == GCToEEInterface::GetThread());
-#define ASSERT_NOT_HOLDING_SPIN_LOCK(pSpinLock) \
-    _ASSERTE((pSpinLock)->holding_thread != GCToEEInterface::GetThread());
-#else //_DEBUG
-void WaitLonger (int i
-#ifdef SYNCHRONIZATION_STATS
-    , GCSpinLock* spin_lock
-#endif //SYNCHRONIZATION_STATS
-    )
-{
-#ifdef SYNCHRONIZATION_STATS
-    (spin_lock->num_wait_longer)++;
-#endif //SYNCHRONIZATION_STATS
-    bool bToggleGC = GCToEEInterface::EnablePreemptiveGC();
-    assert (bToggleGC);
-    if (!gc_heap::gc_started)
-    {
-#ifdef SYNCHRONIZATION_STATS
-        (spin_lock->num_switch_thread_w)++;
-#endif //SYNCHRONIZATION_STATS
-        if  (g_num_processors > 1)
-        {
-            YieldProcessor();           // indicate to the processor that we are spinning
-            if  (i & 0x01f)
-                GCToOSInterface::YieldThread (0);
-            else
-                GCToOSInterface::Sleep (5);
-        }
-        else
-            GCToOSInterface::Sleep (5);
-    }
-    if (gc_heap::gc_started)
-    {
-        gc_heap::wait_for_gc_done();
-    }
-    if (bToggleGC)
-    {
-#ifdef SYNCHRONIZATION_STATS
-        (spin_lock->num_disable_preemptive_w)++;
-#endif //SYNCHRONIZATION_STATS
-        GCToEEInterface::DisablePreemptiveGC();
-    }
-}
-inline
-static void enter_spin_lock (GCSpinLock* spin_lock)
-{
-retry:
-    if (Interlocked::CompareExchange(&spin_lock->lock, lock_taken, lock_free) != lock_free)
-    {
-        unsigned int i = 0;
-        while (spin_lock->lock != lock_free)
-        {
-            assert (spin_lock->lock != lock_decommissioned);
-            if ((++i & 7) && !gc_heap::gc_started)
-            {
-                if  (g_num_processors > 1)
-                {
-#ifndef MULTIPLE_HEAPS
-                    int spin_count = 32 * yp_spin_count_unit;
-#else //!MULTIPLE_HEAPS
-                    int spin_count = yp_spin_count_unit;
-#endif //!MULTIPLE_HEAPS
-                    for (int j = 0; j < spin_count; j++)
-                    {
-                        if  (spin_lock->lock == lock_free || gc_heap::gc_started)
-                            break;
-                        YieldProcessor();           // indicate to the processor that we are spinning
-                    }
-                    if  (spin_lock->lock != lock_free && !gc_heap::gc_started)
-                    {
-#ifdef SYNCHRONIZATION_STATS
-                        (spin_lock->num_switch_thread)++;
-#endif //SYNCHRONIZATION_STATS
-                        bool cooperative_mode = gc_heap::enable_preemptive ();
-                        GCToOSInterface::YieldThread(0);
-                        gc_heap::disable_preemptive (cooperative_mode);
-                    }
-                }
-                else
-                    GCToOSInterface::YieldThread(0);
-            }
-            else
-            {
-                WaitLonger(i
-#ifdef SYNCHRONIZATION_STATS
-                        , spin_lock
-#endif //SYNCHRONIZATION_STATS
-                    );
-            }
-        }
-        goto retry;
-    }
-}
-inline
-static BOOL try_enter_spin_lock(GCSpinLock* spin_lock)
-{
-    return (Interlocked::CompareExchange(&spin_lock->lock, lock_taken, lock_free) == lock_free);
-}
-inline
-static void leave_spin_lock (GCSpinLock * spin_lock)
-{
-    spin_lock->lock = lock_free;
-}
-#define ASSERT_HOLDING_SPIN_LOCK(pSpinLock)
-#endif //_DEBUG
-bool gc_heap::enable_preemptive ()
-{
-    return GCToEEInterface::EnablePreemptiveGC();
-}
-void gc_heap::disable_preemptive (bool restore_cooperative)
-{
-    if (restore_cooperative)
-    {
-        GCToEEInterface::DisablePreemptiveGC();
-    }
-}
-typedef void **  PTR_PTR;
-inline
-void memclr ( uint8_t* mem, size_t size)
-{
-    dprintf (3, ("MEMCLR: %p, %zd", mem, size));
-    assert ((size & (sizeof(PTR_PTR)-1)) == 0);
-    assert (sizeof(PTR_PTR) == DATA_ALIGNMENT);
-    memset (mem, 0, size);
-}
-void memcopy (uint8_t* dmem, uint8_t* smem, size_t size)
-{
-    const size_t sz4ptr = sizeof(PTR_PTR)*4;
-    const size_t sz2ptr = sizeof(PTR_PTR)*2;
-    const size_t sz1ptr = sizeof(PTR_PTR)*1;
-    assert ((size & (sizeof (PTR_PTR)-1)) == 0);
-    assert (sizeof(PTR_PTR) == DATA_ALIGNMENT);
-    if (size >= sz4ptr)
-    {
-        do
-        {
-            ((PTR_PTR)dmem)[0] = ((PTR_PTR)smem)[0];
-            ((PTR_PTR)dmem)[1] = ((PTR_PTR)smem)[1];
-            ((PTR_PTR)dmem)[2] = ((PTR_PTR)smem)[2];
-            ((PTR_PTR)dmem)[3] = ((PTR_PTR)smem)[3];
-            dmem += sz4ptr;
-            smem += sz4ptr;
-        }
-        while ((size -= sz4ptr) >= sz4ptr);
-    }
-    if (size & sz2ptr)
-    {
-        ((PTR_PTR)dmem)[0] = ((PTR_PTR)smem)[0];
-        ((PTR_PTR)dmem)[1] = ((PTR_PTR)smem)[1];
-        dmem += sz2ptr;
-        smem += sz2ptr;
-    }
-    if (size & sz1ptr)
-    {
-        ((PTR_PTR)dmem)[0] = ((PTR_PTR)smem)[0];
-    }
-}
-inline
-ptrdiff_t round_down (ptrdiff_t add, int pitch)
-{
-    return ((add / pitch) * pitch);
-}
-#if defined(FEATURE_STRUCTALIGN) && defined(RESPECT_LARGE_ALIGNMENT)
-#error FEATURE_STRUCTALIGN should imply !RESPECT_LARGE_ALIGNMENT
-#endif
-#if defined(FEATURE_STRUCTALIGN) && defined(FEATURE_LOH_COMPACTION)
-#error FEATURE_STRUCTALIGN and FEATURE_LOH_COMPACTION are mutually exclusive
-#endif
-inline
-BOOL same_large_alignment_p (uint8_t* p1, uint8_t* p2)
-{
-#ifdef RESPECT_LARGE_ALIGNMENT
-    const size_t LARGE_ALIGNMENT_MASK = 2 * DATA_ALIGNMENT - 1;
-    return ((((size_t)p1 ^ (size_t)p2) & LARGE_ALIGNMENT_MASK) == 0);
-#else
-    UNREFERENCED_PARAMETER(p1);
-    UNREFERENCED_PARAMETER(p2);
-    return TRUE;
-#endif // RESPECT_LARGE_ALIGNMENT
-}
-inline
-size_t switch_alignment_size (BOOL already_padded_p)
-{
-#ifndef RESPECT_LARGE_ALIGNMENT
-    assert (!"Should not be called");
-#endif // RESPECT_LARGE_ALIGNMENT
-    if (already_padded_p)
-        return DATA_ALIGNMENT;
-    else
-        return Align (min_obj_size) | DATA_ALIGNMENT;
-}
-#ifdef FEATURE_STRUCTALIGN
-void set_node_aligninfo (uint8_t *node, int requiredAlignment, ptrdiff_t pad);
-void clear_node_aligninfo (uint8_t *node);
-#else // FEATURE_STRUCTALIGN
-#define node_realigned(node)    (((plug_and_reloc*)(node))[-1].reloc & 1)
-void set_node_realigned (uint8_t* node);
-void clear_node_realigned(uint8_t* node);
-#endif // FEATURE_STRUCTALIGN
-inline
-size_t AlignQword (size_t nbytes)
-{
-#ifdef FEATURE_STRUCTALIGN
-    return Align (nbytes);
-#else // FEATURE_STRUCTALIGN
-    return (nbytes + 7) & ~7;
-#endif // FEATURE_STRUCTALIGN
-}
-inline
-BOOL Aligned (size_t n)
-{
-    return (n & ALIGNCONST) == 0;
-}
-#define OBJECT_ALIGNMENT_OFFSET (sizeof(MethodTable *))
-#ifdef FEATURE_STRUCTALIGN
-#define MAX_STRUCTALIGN OS_PAGE_SIZE
-#else // FEATURE_STRUCTALIGN
-#define MAX_STRUCTALIGN 0
-#endif // FEATURE_STRUCTALIGN
-#ifdef FEATURE_STRUCTALIGN
-inline
-ptrdiff_t AdjustmentForMinPadSize(ptrdiff_t pad, int requiredAlignment)
-{
-    if ((size_t)(pad - DATA_ALIGNMENT) < Align (min_obj_size) - DATA_ALIGNMENT)
-    {
-        return requiredAlignment;
-    }
-    return 0;
-}
-inline
-uint8_t* StructAlign (uint8_t* origPtr, int requiredAlignment, ptrdiff_t alignmentOffset=OBJECT_ALIGNMENT_OFFSET)
-{
-    _ASSERTE(((size_t)origPtr & ALIGNCONST) == 0);
-    _ASSERTE(((requiredAlignment - 1) & requiredAlignment) == 0);
-    _ASSERTE(requiredAlignment >= sizeof(void *));
-    _ASSERTE(requiredAlignment <= MAX_STRUCTALIGN);
-    uint8_t* result = (uint8_t*)Align ((size_t)origPtr + alignmentOffset, requiredAlignment-1) - alignmentOffset;
-    ptrdiff_t alignpad = result - origPtr;
-    return result + AdjustmentForMinPadSize (alignpad, requiredAlignment);
-}
-inline
-ptrdiff_t ComputeStructAlignPad (uint8_t* plug, int requiredAlignment, size_t alignmentOffset=OBJECT_ALIGNMENT_OFFSET)
-{
-    return StructAlign (plug, requiredAlignment, alignmentOffset) - plug;
-}
-BOOL IsStructAligned (uint8_t *ptr, int requiredAlignment)
-{
-    return StructAlign (ptr, requiredAlignment) == ptr;
-}
-inline
-ptrdiff_t ComputeMaxStructAlignPad (int requiredAlignment)
-{
-    if (requiredAlignment == DATA_ALIGNMENT)
-        return 0;
-    return requiredAlignment + Align (min_obj_size) - DATA_ALIGNMENT;
-}
-inline
-ptrdiff_t ComputeMaxStructAlignPadLarge (int requiredAlignment)
-{
-    if (requiredAlignment <= get_alignment_constant (TRUE)+1)
-        return 0;
-    return requiredAlignment + Align (min_obj_size) * 2 - DATA_ALIGNMENT;
-}
-uint8_t* gc_heap::pad_for_alignment (uint8_t* newAlloc, int requiredAlignment, size_t size, alloc_context* acontext)
-{
-    uint8_t* alignedPtr = StructAlign (newAlloc, requiredAlignment);
-    if (alignedPtr != newAlloc) {
-        make_unused_array (newAlloc, alignedPtr - newAlloc);
-    }
-    acontext->alloc_ptr = alignedPtr + Align (size);
-    return alignedPtr;
-}
-uint8_t* gc_heap::pad_for_alignment_large (uint8_t* newAlloc, int requiredAlignment, size_t size)
-{
-    uint8_t* alignedPtr = StructAlign (newAlloc, requiredAlignment);
-    if (alignedPtr != newAlloc) {
-        make_unused_array (newAlloc, alignedPtr - newAlloc);
-    }
-    if (alignedPtr < newAlloc + ComputeMaxStructAlignPadLarge (requiredAlignment)) {
-        make_unused_array (alignedPtr + AlignQword (size), newAlloc + ComputeMaxStructAlignPadLarge (requiredAlignment) - alignedPtr);
-    }
-    return alignedPtr;
-}
-#else // FEATURE_STRUCTALIGN
-#define ComputeMaxStructAlignPad(requiredAlignment) 0
-#define ComputeMaxStructAlignPadLarge(requiredAlignment) 0
-#endif // FEATURE_STRUCTALIGN
-#ifdef SERVER_GC
-#define CLR_SIZE ((size_t)(8*1024+32))
-#else //SERVER_GC
-#define CLR_SIZE ((size_t)(8*1024+32))
-#endif //SERVER_GC
-#define END_SPACE_AFTER_GC (loh_size_threshold + MAX_STRUCTALIGN)
-#define END_SPACE_AFTER_GC_FL (END_SPACE_AFTER_GC + Align (min_obj_size))
-#if defined(BACKGROUND_GC) && !defined(USE_REGIONS)
-#define SEGMENT_INITIAL_COMMIT (2*OS_PAGE_SIZE)
-#else
-#define SEGMENT_INITIAL_COMMIT (OS_PAGE_SIZE)
-#endif //BACKGROUND_GC && !USE_REGIONS
-const size_t min_segment_size_hard_limit = 1024*1024*16;
-inline
-size_t align_on_segment_hard_limit (size_t add)
-{
-    return ((size_t)(add + (min_segment_size_hard_limit - 1)) & ~(min_segment_size_hard_limit - 1));
-}
-#ifdef SERVER_GC
-#ifdef HOST_64BIT
-#define INITIAL_ALLOC ((size_t)((size_t)4*1024*1024*1024))
-#define LHEAP_ALLOC   ((size_t)(1024*1024*256))
-#else
-#define INITIAL_ALLOC ((size_t)(1024*1024*64))
-#define LHEAP_ALLOC   ((size_t)(1024*1024*32))
-#endif  // HOST_64BIT
-#else //SERVER_GC
-#ifdef HOST_64BIT
-#define INITIAL_ALLOC ((size_t)(1024*1024*256))
-#define LHEAP_ALLOC   ((size_t)(1024*1024*128))
-#else
-#define INITIAL_ALLOC ((size_t)(1024*1024*16))
-#define LHEAP_ALLOC   ((size_t)(1024*1024*16))
-#endif  // HOST_64BIT
-#endif //SERVER_GC
-const size_t etw_allocation_tick = 100*1024;
-const size_t low_latency_alloc = 256*1024;
-const size_t fgn_check_quantum = 2*1024*1024;
-#ifdef MH_SC_MARK
-const int max_snoop_level = 128;
-#endif //MH_SC_MARK
-#ifdef CARD_BUNDLE
-#define SH_TH_CARD_BUNDLE  (40*1024*1024)
-#define MH_TH_CARD_BUNDLE  (180*1024*1024)
-#endif //CARD_BUNDLE
-#define MIN_DECOMMIT_SIZE  (100*OS_PAGE_SIZE)
-#define DECOMMIT_SIZE_PER_MILLISECOND (160*1024)
-#define DECOMMIT_TIME_STEP_MILLISECONDS (100)
-inline
-size_t align_on_page (size_t add)
-{
-    return ((add + OS_PAGE_SIZE - 1) & ~((size_t)OS_PAGE_SIZE - 1));
-}
-inline
-uint8_t* align_on_page (uint8_t* add)
-{
-    return (uint8_t*)align_on_page ((size_t) add);
-}
-inline
-size_t align_lower_page (size_t add)
-{
-    return (add & ~((size_t)OS_PAGE_SIZE - 1));
-}
-inline
-uint8_t* align_lower_page (uint8_t* add)
-{
-    return (uint8_t*)align_lower_page ((size_t)add);
-}
-inline
-size_t align_write_watch_lower_page (size_t add)
-{
-    return (add & ~(WRITE_WATCH_UNIT_SIZE - 1));
-}
-inline
-uint8_t* align_write_watch_lower_page (uint8_t* add)
-{
-    return (uint8_t*)align_lower_page ((size_t)add);
-}
-inline
-BOOL power_of_two_p (size_t integer)
-{
-    return !(integer & (integer-1));
-}
-inline
-BOOL oddp (size_t integer)
-{
-    return (integer & 1) != 0;
-}
-size_t logcount (size_t word)
-{
-    assert (word < 0x10000);
-    size_t count;
-    count = (word & 0x5555) + ( (word >> 1 ) & 0x5555);
-    count = (count & 0x3333) + ( (count >> 2) & 0x3333);
-    count = (count & 0x0F0F) + ( (count >> 4) & 0x0F0F);
-    count = (count & 0x00FF) + ( (count >> 8) & 0x00FF);
-    return count;
-}
-void stomp_write_barrier_resize(bool is_runtime_suspended, bool requires_upper_bounds_check)
-{
-    WriteBarrierParameters args = {};
-    args.operation = WriteBarrierOp::StompResize;
-    args.is_runtime_suspended = is_runtime_suspended;
-    args.requires_upper_bounds_check = requires_upper_bounds_check;
-    args.card_table = g_gc_card_table;
-#ifdef FEATURE_MANUALLY_MANAGED_CARD_BUNDLES
-    args.card_bundle_table = g_gc_card_bundle_table;
-#endif
-    args.lowest_address = g_gc_lowest_address;
-    args.highest_address = g_gc_highest_address;
-#ifdef FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-    if (SoftwareWriteWatch::IsEnabledForGCHeap())
-    {
-        args.write_watch_table = g_gc_sw_ww_table;
-    }
-#endif // FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-    GCToEEInterface::StompWriteBarrier(&args);
-}
-#ifdef USE_REGIONS
-void region_write_barrier_settings (WriteBarrierParameters* args,
-                                    gc_heap::region_info* map_region_to_generation_skewed,
-                                    uint8_t region_shr)
-{
-    switch (GCConfig::GetGCWriteBarrier())
-    {
-    default:
-    case GCConfig::WRITE_BARRIER_DEFAULT:
-    case GCConfig::WRITE_BARRIER_REGION_BIT:
-        args->region_to_generation_table = (uint8_t*)map_region_to_generation_skewed;
-        args->region_shr = region_shr;
-        args->region_use_bitwise_write_barrier = true;
-        break;
-    case GCConfig::WRITE_BARRIER_REGION_BYTE:
-        args->region_to_generation_table = (uint8_t*)map_region_to_generation_skewed;
-        args->region_shr = region_shr;
-        assert (args->region_use_bitwise_write_barrier == false);
-        break;
-    case GCConfig::WRITE_BARRIER_SERVER:
-        assert (args->region_use_bitwise_write_barrier == false);
-        assert (args->region_to_generation_table == nullptr);
-        assert (args->region_shr == 0);
-        break;
-    }
-}
-#endif //USE_REGIONS
-void stomp_write_barrier_ephemeral (uint8_t* ephemeral_low, uint8_t* ephemeral_high
-#ifdef USE_REGIONS
-                                   , gc_heap::region_info* map_region_to_generation_skewed
-                                   , uint8_t region_shr
-#endif //USE_REGIONS
-                                   )
-{
-#ifndef USE_REGIONS
-    initGCShadow();
-#endif
-    WriteBarrierParameters args = {};
-    args.operation = WriteBarrierOp::StompEphemeral;
-    args.is_runtime_suspended = true;
-    args.ephemeral_low = ephemeral_low;
-    args.ephemeral_high = ephemeral_high;
-#ifdef USE_REGIONS
-    region_write_barrier_settings (&args, map_region_to_generation_skewed, region_shr);
-#endif //USE_REGIONS
-    GCToEEInterface::StompWriteBarrier(&args);
-}
-void stomp_write_barrier_initialize(uint8_t* ephemeral_low, uint8_t* ephemeral_high
-#ifdef USE_REGIONS
-                                   , gc_heap::region_info* map_region_to_generation_skewed
-                                   , uint8_t region_shr
-#endif //USE_REGIONS
-                                   )
-{
-    WriteBarrierParameters args = {};
-    args.operation = WriteBarrierOp::Initialize;
-    args.is_runtime_suspended = true;
-    args.requires_upper_bounds_check = false;
-    args.card_table = g_gc_card_table;
-#ifdef FEATURE_MANUALLY_MANAGED_CARD_BUNDLES
-    args.card_bundle_table = g_gc_card_bundle_table;
-#endif
-    args.lowest_address = g_gc_lowest_address;
-    args.highest_address = g_gc_highest_address;
-    args.ephemeral_low = ephemeral_low;
-    args.ephemeral_high = ephemeral_high;
-#ifdef USE_REGIONS
-    region_write_barrier_settings (&args, map_region_to_generation_skewed, region_shr);
-#endif //USE_REGIONS
-    GCToEEInterface::StompWriteBarrier(&args);
-}
-#define lowbits(wrd, bits) ((wrd) & ((1 << (bits))-1))
-#define highbits(wrd, bits) ((wrd) & ~((1 << (bits))-1))
-static static_data static_data_table[latency_level_last - latency_level_first + 1][total_generation_count] =
-{
-    {
-        {0, 0, 40000, 0.5f, 9.0f, 20.0f, (1000 * 1000), 1},
-        {160*1024, 0, 80000, 0.5f, 2.0f, 7.0f, (10 * 1000 * 1000), 10},
-        {256*1024, SSIZE_T_MAX, 200000, 0.25f, 1.2f, 1.8f, (100 * 1000 * 1000), 100},
-        {3*1024*1024, SSIZE_T_MAX, 0, 0.0f, 1.25f, 4.5f, 0, 0},
-        {3*1024*1024, SSIZE_T_MAX, 0, 0.0f, 1.25f, 4.5f, 0, 0},
-    },
-    {
-        {0, 0, 40000, 0.5f,
-#ifdef MULTIPLE_HEAPS
-            20.0f, 40.0f,
-#else
-            9.0f, 20.0f,
-#endif //MULTIPLE_HEAPS
-            (1000 * 1000), 1},
-        {256*1024, 0, 80000, 0.5f, 2.0f, 7.0f, (10 * 1000 * 1000), 10},
-        {256*1024, SSIZE_T_MAX, 200000, 0.25f, 1.2f, 1.8f, (100 * 1000 * 1000), 100},
-        {3*1024*1024, SSIZE_T_MAX, 0, 0.0f, 1.25f, 4.5f, 0, 0},
-        {3*1024*1024, SSIZE_T_MAX, 0, 0.0f, 1.25f, 4.5f, 0, 0}
-    },
-};
-class mark;
-class generation;
-class heap_segment;
-class CObjectHeader;
-class dynamic_data;
-class l_heap;
-class sorted_table;
-class c_synchronize;
-#ifdef FEATURE_PREMORTEM_FINALIZATION
-static
-HRESULT AllocateCFinalize(CFinalize **pCFinalize);
-#endif // FEATURE_PREMORTEM_FINALIZATION
-uint8_t* tree_search (uint8_t* tree, uint8_t* old_address);
-#ifdef USE_INTROSORT
-#define _sort introsort::sort
-#elif defined(USE_VXSORT)
-#else //USE_INTROSORT
-#define _sort qsort1
-void qsort1(uint8_t** low, uint8_t** high, unsigned int depth);
-#endif //USE_INTROSORT
-void* virtual_alloc (size_t size);
-void* virtual_alloc (size_t size, bool use_large_pages_p, uint16_t numa_node = NUMA_NODE_UNDEFINED);
-/* per heap static initialization */
-#if defined(BACKGROUND_GC) && !defined(MULTIPLE_HEAPS)
-uint32_t*   gc_heap::mark_array;
-#endif //BACKGROUND_GC && !MULTIPLE_HEAPS
-uint8_t**   gc_heap::g_mark_list;
-uint8_t**   gc_heap::g_mark_list_copy;
-size_t      gc_heap::mark_list_size;
-size_t      gc_heap::g_mark_list_total_size;
-bool        gc_heap::mark_list_overflow;
-#ifdef USE_REGIONS
-uint8_t***  gc_heap::g_mark_list_piece;
-size_t      gc_heap::g_mark_list_piece_size;
-size_t      gc_heap::g_mark_list_piece_total_size;
-#endif //USE_REGIONS
-seg_mapping* seg_mapping_table;
-#ifdef FEATURE_BASICFREEZE
-sorted_table* gc_heap::seg_table;
-#endif //FEATURE_BASICFREEZE
-#ifdef MULTIPLE_HEAPS
-GCEvent     gc_heap::ee_suspend_event;
-size_t      gc_heap::min_gen0_balance_delta = 0;
-size_t      gc_heap::min_balance_threshold = 0;
-#endif //MULTIPLE_HEAPS
-VOLATILE(BOOL) gc_heap::gc_started;
-#ifdef MULTIPLE_HEAPS
-GCEvent     gc_heap::gc_start_event;
-bool        gc_heap::gc_thread_no_affinitize_p = false;
-uintptr_t   process_mask = 0;
-int         gc_heap::n_heaps;       // current number of heaps
-int         gc_heap::n_max_heaps;   // maximum number of heaps
-gc_heap**   gc_heap::g_heaps;
-#if !defined(USE_REGIONS) || defined(_DEBUG)
-size_t*     gc_heap::g_promoted;
-#endif //!USE_REGIONS || _DEBUG
-#ifdef MH_SC_MARK
-int*        gc_heap::g_mark_stack_busy;
-#endif //MH_SC_MARK
-#ifdef BACKGROUND_GC
-size_t*     gc_heap::g_bpromoted;
-#endif //BACKGROUND_GC
-BOOL        gc_heap::gradual_decommit_in_progress_p = FALSE;
-size_t      gc_heap::max_decommit_step_size = 0;
-#else  //MULTIPLE_HEAPS
-#if !defined(USE_REGIONS) || defined(_DEBUG)
-size_t      gc_heap::g_promoted;
-#endif //!USE_REGIONS || _DEBUG
-#ifdef BACKGROUND_GC
-size_t      gc_heap::g_bpromoted;
-#endif //BACKGROUND_GC
-const int n_heaps = 1;
-#endif //MULTIPLE_HEAPS
-size_t      gc_heap::card_table_element_layout[total_bookkeeping_elements + 1];
-uint8_t*    gc_heap::bookkeeping_start = nullptr;
-#ifdef USE_REGIONS
-uint8_t*    gc_heap::bookkeeping_covered_committed = nullptr;
-size_t      gc_heap::bookkeeping_sizes[total_bookkeeping_elements];
-#endif //USE_REGIONS
-size_t      gc_heap::reserved_memory = 0;
-size_t      gc_heap::reserved_memory_limit = 0;
-BOOL        gc_heap::g_low_memory_status;
-static gc_reason gc_trigger_reason = reason_empty;
-gc_latency_level gc_heap::latency_level = latency_level_default;
-gc_mechanisms  gc_heap::settings;
-gc_history_global gc_heap::gc_data_global;
-uint64_t    gc_heap::gc_last_ephemeral_decommit_time = 0;
-CLRCriticalSection gc_heap::check_commit_cs;
-#ifdef COMMITTED_BYTES_SHADOW
-CLRCriticalSection gc_heap::decommit_lock;
-#endif //COMMITTED_BYTES_SHADOW
-size_t      gc_heap::current_total_committed = 0;
-size_t      gc_heap::committed_by_oh[recorded_committed_bucket_counts];
-size_t      gc_heap::current_total_committed_bookkeeping = 0;
-BOOL        gc_heap::reset_mm_p = TRUE;
-#ifdef FEATURE_EVENT_TRACE
-bool gc_heap::informational_event_enabled_p = false;
-uint64_t*   gc_heap::gc_time_info = 0;
-#ifdef BACKGROUND_GC
-uint64_t*   gc_heap::bgc_time_info = 0;
-#endif //BACKGROUND_GC
-size_t      gc_heap::physical_memory_from_config = 0;
-size_t      gc_heap::gen0_min_budget_from_config = 0;
-size_t      gc_heap::gen0_max_budget_from_config = 0;
-int         gc_heap::high_mem_percent_from_config = 0;
-bool        gc_heap::use_frozen_segments_p = false;
-#ifdef FEATURE_LOH_COMPACTION
-gc_heap::etw_loh_compact_info* gc_heap::loh_compact_info;
-#endif //FEATURE_LOH_COMPACTION
-#endif //FEATURE_EVENT_TRACE
-bool        gc_heap::hard_limit_config_p = false;
-#if defined(SHORT_PLUGS) && !defined(USE_REGIONS)
-double      gc_heap::short_plugs_pad_ratio = 0;
-#endif //SHORT_PLUGS && !USE_REGIONS
-int         gc_heap::generation_skip_ratio_threshold = 0;
-int         gc_heap::conserve_mem_setting = 0;
-bool        gc_heap::spin_count_unit_config_p = false;
-uint64_t    gc_heap::suspended_start_time = 0;
-uint64_t    gc_heap::end_gc_time = 0;
-uint64_t    gc_heap::total_suspended_time = 0;
-uint64_t    gc_heap::process_start_time = 0;
-last_recorded_gc_info gc_heap::last_ephemeral_gc_info;
-last_recorded_gc_info gc_heap::last_full_blocking_gc_info;
-uint64_t    gc_heap::last_alloc_reset_suspended_end_time = 0;
-size_t      gc_heap::max_peak_heap_size = 0;
-VOLATILE(size_t) gc_heap::llc_size = 0;
-#ifdef BACKGROUND_GC
-last_recorded_gc_info gc_heap::last_bgc_info[2];
-VOLATILE(bool)        gc_heap::is_last_recorded_bgc = false;
-VOLATILE(int)         gc_heap::last_bgc_info_index = 0;
-#endif //BACKGROUND_GC
-#ifdef DYNAMIC_HEAP_COUNT
-size_t      gc_heap::hc_change_cancelled_count_prep = 0;
-#ifdef BACKGROUND_GC
-int         gc_heap::bgc_th_creation_hist_index = 0;
-gc_heap::bgc_thread_creation_history gc_heap::bgc_th_creation_hist[max_bgc_thread_creation_count];
-size_t      gc_heap::bgc_th_count_created = 0;
-size_t      gc_heap::bgc_th_count_created_th_existed = 0;
-size_t      gc_heap::bgc_th_count_creation_failed = 0;
-size_t      gc_heap::bgc_init_gc_index = 0;
-VOLATILE(short) gc_heap::bgc_init_n_heaps = 0;
-size_t      gc_heap::hc_change_cancelled_count_bgc = 0;
-#endif //BACKGROUND_GC
-#endif //DYNAMIC_HEAP_COUNT
-#if defined(HOST_64BIT)
-#define MAX_ALLOWED_MEM_LOAD 85
-#define MIN_YOUNGEST_GEN_DESIRED (16*1024*1024)
-size_t      gc_heap::youngest_gen_desired_th;
-#endif //HOST_64BIT
-uint64_t    gc_heap::mem_one_percent = 0;
-uint32_t    gc_heap::high_memory_load_th = 0;
-uint32_t    gc_heap::m_high_memory_load_th;
-uint32_t    gc_heap::v_high_memory_load_th;
-bool        gc_heap::is_restricted_physical_mem;
-uint64_t    gc_heap::total_physical_mem = 0;
-uint64_t    gc_heap::entry_available_physical_mem = 0;
-size_t      gc_heap::heap_hard_limit = 0;
-size_t      gc_heap::heap_hard_limit_oh[total_oh_count];
-#ifdef USE_REGIONS
-size_t      gc_heap::regions_range = 0;
-#endif //USE_REGIONS
-bool        affinity_config_specified_p = false;
-#ifdef USE_REGIONS
-region_allocator global_region_allocator;
-uint8_t*(*initial_regions)[total_generation_count][2] = nullptr;
-size_t      gc_heap::region_count = 0;
-gc_heap::region_info* gc_heap::map_region_to_generation = nullptr;
-gc_heap::region_info* gc_heap::map_region_to_generation_skewed = nullptr;
-#endif //USE_REGIONS
-#ifdef BACKGROUND_GC
-GCEvent     gc_heap::bgc_start_event;
-gc_mechanisms gc_heap::saved_bgc_settings;
-gc_history_global gc_heap::bgc_data_global;
-GCEvent     gc_heap::background_gc_done_event;
-GCEvent     gc_heap::ee_proceed_event;
-bool        gc_heap::gc_can_use_concurrent = false;
-bool        gc_heap::temp_disable_concurrent_p = false;
-uint32_t    gc_heap::cm_in_progress = FALSE;
-BOOL        gc_heap::dont_restart_ee_p = FALSE;
-BOOL        gc_heap::keep_bgc_threads_p = FALSE;
-GCEvent     gc_heap::bgc_threads_sync_event;
-BOOL        gc_heap::do_ephemeral_gc_p = FALSE;
-BOOL        gc_heap::do_concurrent_p = FALSE;
-size_t      gc_heap::ephemeral_fgc_counts[max_generation];
-VOLATILE(c_gc_state) gc_heap::current_c_gc_state = c_gc_state_free;
-VOLATILE(BOOL) gc_heap::gc_background_running = FALSE;
-#endif //BACKGROUND_GC
-#ifdef USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-uint8_t*    gc_heap::gc_low;
-uint8_t*    gc_heap::gc_high;
-#endif //MULTIPLE_HEAPS
-VOLATILE(uint8_t*)    gc_heap::ephemeral_low;
-VOLATILE(uint8_t*)    gc_heap::ephemeral_high;
-#endif //USE_REGIONS
-#ifndef MULTIPLE_HEAPS
-#ifdef SPINLOCK_HISTORY
-int         gc_heap::spinlock_info_index = 0;
-spinlock_info gc_heap::last_spinlock_info[max_saved_spinlock_info];
-allocation_state gc_heap::current_uoh_alloc_state = (allocation_state)-1;
-#endif //SPINLOCK_HISTORY
-uint32_t    gc_heap::fgn_maxgen_percent = 0;
-size_t      gc_heap::fgn_last_alloc = 0;
-int         gc_heap::generation_skip_ratio = 100;
-#ifdef FEATURE_CARD_MARKING_STEALING
-VOLATILE(size_t) gc_heap::n_eph_soh = 0;
-VOLATILE(size_t) gc_heap::n_gen_soh = 0;
-VOLATILE(size_t) gc_heap::n_eph_loh = 0;
-VOLATILE(size_t) gc_heap::n_gen_loh = 0;
-#endif //FEATURE_CARD_MARKING_STEALING
-uint64_t    gc_heap::loh_alloc_since_cg = 0;
-BOOL        gc_heap::elevation_requested = FALSE;
-BOOL        gc_heap::last_gc_before_oom = FALSE;
-BOOL        gc_heap::sufficient_gen0_space_p = FALSE;
-#ifdef BACKGROUND_GC
-uint8_t*    gc_heap::background_saved_lowest_address = 0;
-uint8_t*    gc_heap::background_saved_highest_address = 0;
-uint8_t*    gc_heap::next_sweep_obj = 0;
-uint8_t*    gc_heap::current_sweep_pos = 0;
-#ifdef DOUBLY_LINKED_FL
-heap_segment* gc_heap::current_sweep_seg = 0;
-#endif //DOUBLY_LINKED_FL
-exclusive_sync* gc_heap::bgc_alloc_lock;
-#endif //BACKGROUND_GC
-oom_history gc_heap::oom_info;
-int         gc_heap::oomhist_index_per_heap = 0;
-oom_history gc_heap::oomhist_per_heap[max_oom_history_count];
-fgm_history gc_heap::fgm_result;
-size_t      gc_heap::allocated_since_last_gc[total_oh_count];
-#ifndef USE_REGIONS
-BOOL        gc_heap::ro_segments_in_range = FALSE;
-uint8_t*    gc_heap::ephemeral_low;
-uint8_t*    gc_heap::ephemeral_high;
-BOOL        gc_heap::ephemeral_promotion;
-uint8_t*    gc_heap::saved_ephemeral_plan_start[ephemeral_generation_count];
-size_t      gc_heap::saved_ephemeral_plan_start_size[ephemeral_generation_count];
-#endif //!USE_REGIONS
-uint8_t*    gc_heap::lowest_address;
-uint8_t*    gc_heap::highest_address;
-short*      gc_heap::brick_table;
-uint32_t*   gc_heap::card_table;
-#ifdef CARD_BUNDLE
-uint32_t*   gc_heap::card_bundle_table;
-#endif //CARD_BUNDLE
-uint8_t*    gc_heap::gc_low = 0;
-uint8_t*    gc_heap::gc_high = 0;
-#ifndef USE_REGIONS
-uint8_t*    gc_heap::demotion_low;
-uint8_t*    gc_heap::demotion_high;
-BOOL        gc_heap::demote_gen1_p = TRUE;
-uint8_t*    gc_heap::last_gen1_pin_end;
-#endif //!USE_REGIONS
-gen_to_condemn_tuning gc_heap::gen_to_condemn_reasons;
-size_t      gc_heap::etw_allocation_running_amount[total_oh_count];
-uint64_t    gc_heap::total_alloc_bytes_soh = 0;
-uint64_t    gc_heap::total_alloc_bytes_uoh = 0;
-int         gc_heap::gc_policy = 0;
-uint64_t    gc_heap::allocation_running_time;
-size_t      gc_heap::allocation_running_amount;
-heap_segment* gc_heap::ephemeral_heap_segment = 0;
-#ifdef USE_REGIONS
-#ifdef STRESS_REGIONS
-OBJECTHANDLE* gc_heap::pinning_handles_for_alloc = 0;
-int         gc_heap::ph_index_per_heap = 0;
-int         gc_heap::pinning_seg_interval = 2;
-size_t      gc_heap::num_gen0_regions = 0;
-int         gc_heap::sip_seg_interval = 0;
-int         gc_heap::sip_seg_maxgen_interval = 0;
-size_t      gc_heap::num_condemned_regions = 0;
-#endif //STRESS_REGIONS
-region_free_list gc_heap::free_regions[count_free_region_kinds];
-int         gc_heap::num_regions_freed_in_sweep = 0;
-int         gc_heap::regions_per_gen[max_generation + 1];
-int         gc_heap::planned_regions_per_gen[max_generation + 1];
-int         gc_heap::sip_maxgen_regions_per_gen[max_generation + 1];
-heap_segment* gc_heap::reserved_free_regions_sip[max_generation];
-int         gc_heap::new_gen0_regions_in_plns = 0;
-int         gc_heap::new_regions_in_prr = 0;
-int         gc_heap::new_regions_in_threading = 0;
-size_t      gc_heap::end_gen0_region_space = 0;
-size_t      gc_heap::end_gen0_region_committed_space = 0;
-size_t      gc_heap::gen0_pinned_free_space = 0;
-bool        gc_heap::gen0_large_chunk_found = false;
-size_t*     gc_heap::survived_per_region = nullptr;
-size_t*     gc_heap::old_card_survived_per_region = nullptr;
-#endif //USE_REGIONS
-BOOL        gc_heap::blocking_collection = FALSE;
-heap_segment* gc_heap::freeable_uoh_segment = 0;
-uint64_t    gc_heap::time_bgc_last = 0;
-size_t      gc_heap::mark_stack_tos = 0;
-size_t      gc_heap::mark_stack_bos = 0;
-size_t      gc_heap::mark_stack_array_length = 0;
-mark*       gc_heap::mark_stack_array = 0;
-#if defined (_DEBUG) && defined (VERIFY_HEAP)
-BOOL        gc_heap::verify_pinned_queue_p = FALSE;
-#endif //_DEBUG && VERIFY_HEAP
-uint8_t*    gc_heap::oldest_pinned_plug = 0;
-size_t      gc_heap::num_pinned_objects = 0;
-#ifdef FEATURE_LOH_COMPACTION
-size_t      gc_heap::loh_pinned_queue_tos = 0;
-size_t      gc_heap::loh_pinned_queue_bos = 0;
-size_t      gc_heap::loh_pinned_queue_length = 0;
-mark*       gc_heap::loh_pinned_queue = 0;
-BOOL        gc_heap::loh_compacted_p = FALSE;
-#endif //FEATURE_LOH_COMPACTION
-#ifdef BACKGROUND_GC
-EEThreadId  gc_heap::bgc_thread_id;
-uint8_t*    gc_heap::background_written_addresses [array_size+2];
-heap_segment* gc_heap::freeable_soh_segment = 0;
-size_t      gc_heap::bgc_overflow_count = 0;
-size_t      gc_heap::bgc_begin_loh_size = 0;
-size_t      gc_heap::end_loh_size = 0;
-size_t      gc_heap::bgc_begin_poh_size = 0;
-size_t      gc_heap::end_poh_size = 0;
-size_t      gc_heap::uoh_a_no_bgc[uoh_generation_count] = {};
-size_t      gc_heap::uoh_a_bgc_marking[uoh_generation_count] = {};
-size_t      gc_heap::uoh_a_bgc_planning[uoh_generation_count] = {};
-#ifdef BGC_SERVO_TUNING
-size_t      gc_heap::bgc_maxgen_end_fl_size = 0;
-#endif //BGC_SERVO_TUNING
-size_t      gc_heap::bgc_loh_size_increased = 0;
-size_t      gc_heap::bgc_poh_size_increased = 0;
-size_t      gc_heap::background_soh_size_end_mark = 0;
-size_t      gc_heap::background_soh_alloc_count = 0;
-size_t      gc_heap::background_uoh_alloc_count = 0;
-uint8_t**   gc_heap::background_mark_stack_tos = 0;
-uint8_t**   gc_heap::background_mark_stack_array = 0;
-size_t      gc_heap::background_mark_stack_array_length = 0;
-BOOL        gc_heap::processed_eph_overflow_p = FALSE;
-#ifdef USE_REGIONS
-BOOL        gc_heap::background_overflow_p = FALSE;
-#else //USE_REGIONS
-uint8_t*    gc_heap::background_min_overflow_address =0;
-uint8_t*    gc_heap::background_max_overflow_address =0;
-uint8_t*    gc_heap::background_min_soh_overflow_address =0;
-uint8_t*    gc_heap::background_max_soh_overflow_address =0;
-heap_segment* gc_heap::saved_overflow_ephemeral_seg = 0;
-heap_segment* gc_heap::saved_sweep_ephemeral_seg = 0;
-uint8_t*    gc_heap::saved_sweep_ephemeral_start = 0;
-#endif //USE_REGIONS
-Thread*     gc_heap::bgc_thread = 0;
-uint8_t**   gc_heap::c_mark_list = 0;
-size_t      gc_heap::c_mark_list_length = 0;
-size_t      gc_heap::c_mark_list_index = 0;
-gc_history_per_heap gc_heap::bgc_data_per_heap;
-BOOL    gc_heap::bgc_thread_running;
-CLRCriticalSection gc_heap::bgc_threads_timeout_cs;
-#endif //BACKGROUND_GC
-uint8_t**   gc_heap::mark_list;
-uint8_t**   gc_heap::mark_list_index;
-uint8_t**   gc_heap::mark_list_end;
-#ifdef SNOOP_STATS
-snoop_stats_data gc_heap::snoop_stat;
-#endif //SNOOP_STATS
-uint8_t*    gc_heap::min_overflow_address = MAX_PTR;
-uint8_t*    gc_heap::max_overflow_address = 0;
-uint8_t*    gc_heap::shigh = 0;
-uint8_t*    gc_heap::slow = MAX_PTR;
-#ifndef USE_REGIONS
-size_t      gc_heap::ordered_free_space_indices[MAX_NUM_BUCKETS];
-size_t      gc_heap::saved_ordered_free_space_indices[MAX_NUM_BUCKETS];
-size_t      gc_heap::ordered_plug_indices[MAX_NUM_BUCKETS];
-size_t      gc_heap::saved_ordered_plug_indices[MAX_NUM_BUCKETS];
-BOOL        gc_heap::ordered_plug_indices_init = FALSE;
-BOOL        gc_heap::use_bestfit = FALSE;
-uint8_t*    gc_heap::bestfit_first_pin = 0;
-BOOL        gc_heap::commit_end_of_seg = FALSE;
-size_t      gc_heap::max_free_space_items = 0;
-size_t      gc_heap::free_space_buckets = 0;
-size_t      gc_heap::free_space_items = 0;
-int         gc_heap::trimmed_free_space_index = 0;
-size_t      gc_heap::total_ephemeral_plugs = 0;
-seg_free_spaces* gc_heap::bestfit_seg = 0;
-size_t      gc_heap::total_ephemeral_size = 0;
-#endif //!USE_REGIONS
-#ifdef HEAP_ANALYZE
-size_t      gc_heap::internal_root_array_length = initial_internal_roots;
-uint8_t**   gc_heap::internal_root_array = 0;
-size_t      gc_heap::internal_root_array_index = 0;
-BOOL        gc_heap::heap_analyze_success = TRUE;
-uint8_t*    gc_heap::current_obj = 0;
-size_t      gc_heap::current_obj_size = 0;
-#endif //HEAP_ANALYZE
-#ifdef GC_CONFIG_DRIVEN
-size_t gc_heap::interesting_data_per_gc[max_idp_count];
-#endif //GC_CONFIG_DRIVEN
-#endif //MULTIPLE_HEAPS
-no_gc_region_info gc_heap::current_no_gc_region_info;
-FinalizerWorkItem* gc_heap::finalizer_work;
-BOOL gc_heap::proceed_with_gc_p = FALSE;
-GCSpinLock gc_heap::gc_lock;
-#ifdef BACKGROUND_GC
-uint64_t gc_heap::total_uoh_a_last_bgc = 0;
-#endif //BACKGROUND_GC
-#ifdef USE_REGIONS
-region_free_list gc_heap::global_regions_to_decommit[count_free_region_kinds];
-region_free_list gc_heap::global_free_huge_regions;
-#else //USE_REGIONS
-size_t gc_heap::eph_gen_starts_size = 0;
-heap_segment* gc_heap::segment_standby_list;
-#endif //USE_REGIONS
-bool          gc_heap::use_large_pages_p = 0;
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-size_t        gc_heap::last_gc_end_time_us = 0;
-#endif //HEAP_BALANCE_INSTRUMENTATION
-#ifdef USE_REGIONS
-bool          gc_heap::enable_special_regions_p = false;
-#else //USE_REGIONS
-size_t        gc_heap::min_segment_size = 0;
-size_t        gc_heap::min_uoh_segment_size = 0;
-#endif //!USE_REGIONS
-size_t        gc_heap::min_segment_size_shr = 0;
-size_t        gc_heap::soh_segment_size = 0;
-size_t        gc_heap::segment_info_size = 0;
-#ifdef GC_CONFIG_DRIVEN
-size_t gc_heap::compact_or_sweep_gcs[2];
-#endif //GC_CONFIG_DRIVEN
-#ifdef FEATURE_LOH_COMPACTION
-BOOL                   gc_heap::loh_compaction_always_p = FALSE;
-gc_loh_compaction_mode gc_heap::loh_compaction_mode = loh_compaction_default;
-#endif //FEATURE_LOH_COMPACTION
-GCEvent gc_heap::full_gc_approach_event;
-GCEvent gc_heap::full_gc_end_event;
-uint32_t gc_heap::fgn_loh_percent = 0;
-#ifdef BACKGROUND_GC
-BOOL gc_heap::fgn_last_gc_was_concurrent = FALSE;
-#endif //BACKGROUND_GC
-VOLATILE(bool) gc_heap::full_gc_approach_event_set;
-size_t gc_heap::full_gc_counts[gc_type_max];
-bool gc_heap::maxgen_size_inc_p = false;
-#ifndef USE_REGIONS
-BOOL gc_heap::should_expand_in_full_gc = FALSE;
-#endif //!USE_REGIONS
-#ifdef DYNAMIC_HEAP_COUNT
-int gc_heap::dynamic_adaptation_mode = dynamic_adaptation_default;
-gc_heap::dynamic_heap_count_data_t SVR::gc_heap::dynamic_heap_count_data;
-size_t gc_heap::current_total_soh_stable_size = 0;
-uint64_t gc_heap::last_suspended_end_time = 0;
-uint64_t gc_heap::change_heap_count_time = 0;
-uint64_t gc_heap::total_change_heap_count = 0;
-uint64_t gc_heap::total_change_heap_count_time = 0;
-size_t gc_heap::gc_index_full_gc_end = 0;
-uint64_t gc_heap::before_distribute_free_regions_time = 0;
-bool gc_heap::trigger_initial_gen2_p = false;
-#ifdef BACKGROUND_GC
-bool gc_heap::trigger_bgc_for_rethreading_p = false;
-int gc_heap::total_bgc_threads = 0;
-int gc_heap::last_bgc_n_heaps = 0;
-int gc_heap::last_total_bgc_threads = 0;
-#endif //BACKGROUND_GC
-#ifdef STRESS_DYNAMIC_HEAP_COUNT
-int gc_heap::heaps_in_this_gc = 0;
-int gc_heap::bgc_to_ngc2_ratio = 0;
-#endif //STRESS_DYNAMIC_HEAP_COUNT
-#endif // DYNAMIC_HEAP_COUNT
-bool gc_heap::provisional_mode_triggered = false;
-bool gc_heap::pm_trigger_full_gc = false;
-size_t gc_heap::provisional_triggered_gc_count = 0;
-size_t gc_heap::provisional_off_gc_count = 0;
-size_t gc_heap::num_provisional_triggered = 0;
-bool   gc_heap::pm_stress_on = false;
-#ifdef HEAP_ANALYZE
-BOOL        gc_heap::heap_analyze_enabled = FALSE;
-#endif //HEAP_ANALYZE
-#ifndef MULTIPLE_HEAPS
-alloc_list gc_heap::gen2_alloc_list[NUM_GEN2_ALIST - 1];
-alloc_list gc_heap::loh_alloc_list [NUM_LOH_ALIST - 1];
-alloc_list gc_heap::poh_alloc_list [NUM_POH_ALIST - 1];
-#ifdef DOUBLY_LINKED_FL
-size_t gc_heap::gen2_removed_no_undo = 0;
-size_t gc_heap::saved_pinned_plug_index = INVALID_SAVED_PINNED_PLUG_INDEX;
-#endif //DOUBLY_LINKED_FL
-#ifdef FEATURE_EVENT_TRACE
-etw_bucket_info gc_heap::bucket_info[NUM_GEN2_ALIST];
-#endif //FEATURE_EVENT_TRACE
-dynamic_data gc_heap::dynamic_data_table [total_generation_count];
-gc_history_per_heap gc_heap::gc_data_per_heap;
-size_t gc_heap::total_promoted_bytes = 0;
-size_t gc_heap::finalization_promoted_bytes = 0;
-size_t gc_heap::maxgen_pinned_compact_before_advance = 0;
-uint8_t* gc_heap::alloc_allocated = 0;
-size_t gc_heap::allocation_quantum = CLR_SIZE;
-GCSpinLock gc_heap::more_space_lock_soh;
-GCSpinLock gc_heap::more_space_lock_uoh;
-#ifdef BACKGROUND_GC
-VOLATILE(int32_t) gc_heap::uoh_alloc_thread_count = 0;
-#endif //BACKGROUND_GC
-#ifdef SYNCHRONIZATION_STATS
-unsigned int gc_heap::good_suspension = 0;
-unsigned int gc_heap::bad_suspension = 0;
-uint64_t     gc_heap::total_msl_acquire = 0;
-unsigned int gc_heap::num_msl_acquired = 0;
-unsigned int gc_heap::num_high_msl_acquire = 0;
-unsigned int gc_heap::num_low_msl_acquire = 0;
-#endif //SYNCHRONIZATION_STATS
-size_t   gc_heap::alloc_contexts_used = 0;
-size_t   gc_heap::soh_allocation_no_gc = 0;
-size_t   gc_heap::loh_allocation_no_gc = 0;
-bool     gc_heap::no_gc_oom_p = false;
-heap_segment* gc_heap::saved_loh_segment_no_gc = 0;
-#endif //MULTIPLE_HEAPS
-#ifndef MULTIPLE_HEAPS
-BOOL        gc_heap::gen0_bricks_cleared = FALSE;
-int         gc_heap::gen0_must_clear_bricks = 0;
-#ifdef FEATURE_PREMORTEM_FINALIZATION
-CFinalize*  gc_heap::finalize_queue = 0;
-#endif // FEATURE_PREMORTEM_FINALIZATION
-#ifdef FEATURE_CARD_MARKING_STEALING
-VOLATILE(uint32_t) gc_heap::card_mark_chunk_index_soh;
-VOLATILE(bool) gc_heap::card_mark_done_soh;
-VOLATILE(uint32_t) gc_heap::card_mark_chunk_index_loh;
-VOLATILE(uint32_t) gc_heap::card_mark_chunk_index_poh;
-VOLATILE(bool) gc_heap::card_mark_done_uoh;
-#endif // FEATURE_CARD_MARKING_STEALING
-generation gc_heap::generation_table [total_generation_count];
-size_t     gc_heap::interesting_data_per_heap[max_idp_count];
-size_t     gc_heap::compact_reasons_per_heap[max_compact_reasons_count];
-size_t     gc_heap::expand_mechanisms_per_heap[max_expand_mechanisms_count];
-size_t     gc_heap::interesting_mechanism_bits_per_heap[max_gc_mechanism_bits_count];
-mark_queue_t gc_heap::mark_queue;
-#ifdef USE_REGIONS
-bool gc_heap::special_sweep_p = false;
-#endif //USE_REGIONS
-int gc_heap::loh_pinned_queue_decay = LOH_PIN_DECAY;
-#endif // MULTIPLE_HEAPS
-/* end of per heap static initialization */
-#ifdef USE_REGIONS
-const size_t uninitialized_end_gen0_region_space = (size_t)(-1);
-#endif //USE_REGIONS
-size_t     gc_heap::smoothed_desired_total[total_generation_count];
-/* end of static initialization */
-inline
-int get_start_generation_index()
-{
-#ifdef USE_REGIONS
-    return 0;
-#else
-    return max_generation;
-#endif //USE_REGIONS
-}
-inline
-int get_stop_generation_index (int condemned_gen_number)
-{
-#ifdef USE_REGIONS
-    return 0;
-#else
-    return condemned_gen_number;
-#endif //USE_REGIONS
-}
-void gen_to_condemn_tuning::print (int heap_num)
-{
-#ifdef DT_LOG
-    dprintf (DT_LOG_0, ("condemned reasons (%d %d)", condemn_reasons_gen, condemn_reasons_condition));
-    dprintf (DT_LOG_0, ("%s", record_condemn_reasons_gen_header));
-    gc_condemn_reason_gen r_gen;
-    for (int i = 0; i < gcrg_max; i++)
-    {
-        r_gen = (gc_condemn_reason_gen)(i);
-        str_reasons_gen[i * 2] = get_gen_char (get_gen (r_gen));
-    }
-    dprintf (DT_LOG_0, ("[%2d]%s", heap_num, str_reasons_gen));
-    dprintf (DT_LOG_0, ("%s", record_condemn_reasons_condition_header));
-    gc_condemn_reason_condition r_condition;
-    for (int i = 0; i < gcrc_max; i++)
-    {
-        r_condition = (gc_condemn_reason_condition)(i);
-        str_reasons_condition[i * 2] = get_condition_char (get_condition (r_condition));
-    }
-    dprintf (DT_LOG_0, ("[%2d]%s", heap_num, str_reasons_condition));
-#else
-    UNREFERENCED_PARAMETER(heap_num);
-#endif //DT_LOG
-}
-void gc_generation_data::print (int heap_num, int gen_num)
-{
-#if defined(SIMPLE_DPRINTF) && defined(DT_LOG)
-    dprintf (DT_LOG_0, ("[%2d]gen%d beg %zd fl %zd fo %zd end %zd fl %zd fo %zd in %zd p %zd np %zd alloc %zd",
-                heap_num, gen_num,
-                size_before,
-                free_list_space_before, free_obj_space_before,
-                size_after,
-                free_list_space_after, free_obj_space_after,
-                in, pinned_surv, npinned_surv,
-                new_allocation));
-#else
-    UNREFERENCED_PARAMETER(heap_num);
-    UNREFERENCED_PARAMETER(gen_num);
-#endif //SIMPLE_DPRINTF && DT_LOG
-}
-void gc_history_per_heap::set_mechanism (gc_mechanism_per_heap mechanism_per_heap, uint32_t value)
-{
-    uint32_t* mechanism = &mechanisms[mechanism_per_heap];
-    *mechanism = 0;
-    *mechanism |= mechanism_mask;
-    *mechanism |= (1 << value);
-#ifdef DT_LOG
-    gc_mechanism_descr* descr = &gc_mechanisms_descr[mechanism_per_heap];
-    dprintf (DT_LOG_0, ("setting %s: %s",
-            descr->name,
-            (descr->descr)[value]));
-#endif //DT_LOG
-}
-void gc_history_per_heap::print()
-{
-#if defined(SIMPLE_DPRINTF) && defined(DT_LOG)
-    for (int i = 0; i < (sizeof (gen_data)/sizeof (gc_generation_data)); i++)
-    {
-        gen_data[i].print (heap_index, i);
-    }
-    dprintf (DT_LOG_0, ("fla %zd flr %zd esa %zd ca %zd pa %zd paa %zd, rfle %d, ec %zd",
-                    maxgen_size_info.free_list_allocated,
-                    maxgen_size_info.free_list_rejected,
-                    maxgen_size_info.end_seg_allocated,
-                    maxgen_size_info.condemned_allocated,
-                    maxgen_size_info.pinned_allocated,
-                    maxgen_size_info.pinned_allocated_advance,
-                    maxgen_size_info.running_free_list_efficiency,
-                    extra_gen0_committed));
-    int mechanism = 0;
-    gc_mechanism_descr* descr = 0;
-    for (int i = 0; i < max_mechanism_per_heap; i++)
-    {
-        mechanism = get_mechanism ((gc_mechanism_per_heap)i);
-        if (mechanism >= 0)
-        {
-            descr = &gc_mechanisms_descr[(gc_mechanism_per_heap)i];
-            dprintf (DT_LOG_0, ("[%2d]%s%s",
-                        heap_index,
-                        descr->name,
-                        (descr->descr)[mechanism]));
-        }
-    }
-#endif //SIMPLE_DPRINTF && DT_LOG
-}
-void gc_history_global::print()
-{
-#ifdef DT_LOG
-    char str_settings[64];
-    memset (str_settings, '|', sizeof (char) * 64);
-    str_settings[max_global_mechanisms_count*2] = 0;
-    for (int i = 0; i < max_global_mechanisms_count; i++)
-    {
-        str_settings[i * 2] = (get_mechanism_p ((gc_global_mechanism_p)i) ? 'Y' : 'N');
-    }
-    dprintf (DT_LOG_0, ("[hp]|c|p|o|d|b|e|"));
-    dprintf (DT_LOG_0, ("%4d|%s", num_heaps, str_settings));
-    dprintf (DT_LOG_0, ("Condemned gen%d(reason: %s; mode: %s), youngest budget %zd(%d), memload %d",
-                        condemned_generation,
-                        str_gc_reasons[reason],
-                        str_gc_pause_modes[pause_mode],
-                        final_youngest_desired,
-                        gen0_reduction_count,
-                        mem_pressure));
-#endif //DT_LOG
-}
-uint32_t limit_time_to_uint32 (uint64_t time)
-{
-    time = min (time, (uint64_t)UINT32_MAX);
-    return (uint32_t)time;
-}
-void gc_heap::fire_per_heap_hist_event (gc_history_per_heap* current_gc_data_per_heap, int heap_num)
-{
-    maxgen_size_increase* maxgen_size_info = &(current_gc_data_per_heap->maxgen_size_info);
-    FIRE_EVENT(GCPerHeapHistory_V3,
-               (void *)(maxgen_size_info->free_list_allocated),
-               (void *)(maxgen_size_info->free_list_rejected),
-               (void *)(maxgen_size_info->end_seg_allocated),
-               (void *)(maxgen_size_info->condemned_allocated),
-               (void *)(maxgen_size_info->pinned_allocated),
-               (void *)(maxgen_size_info->pinned_allocated_advance),
-               maxgen_size_info->running_free_list_efficiency,
-               current_gc_data_per_heap->gen_to_condemn_reasons.get_reasons0(),
-               current_gc_data_per_heap->gen_to_condemn_reasons.get_reasons1(),
-               current_gc_data_per_heap->mechanisms[gc_heap_compact],
-               current_gc_data_per_heap->mechanisms[gc_heap_expand],
-               current_gc_data_per_heap->heap_index,
-               (void *)(current_gc_data_per_heap->extra_gen0_committed),
-               total_generation_count,
-               (uint32_t)(sizeof (gc_generation_data)),
-               (void *)&(current_gc_data_per_heap->gen_data[0]));
-    current_gc_data_per_heap->print();
-    current_gc_data_per_heap->gen_to_condemn_reasons.print (heap_num);
-}
-void gc_heap::fire_pevents()
-{
-    gc_history_global* current_gc_data_global = get_gc_data_global();
-    settings.record (current_gc_data_global);
-    current_gc_data_global->print();
-#ifdef FEATURE_EVENT_TRACE
-    if (!informational_event_enabled_p) return;
-    uint32_t count_time_info = (settings.concurrent ? max_bgc_time_type :
-                                (settings.compaction ? max_compact_time_type : max_sweep_time_type));
-#ifdef BACKGROUND_GC
-    uint64_t* time_info = (settings.concurrent ? bgc_time_info : gc_time_info);
-#else
-    uint64_t* time_info = gc_time_info;
-#endif //BACKGROUND_GC
-    uint32_t* time_info_32 = (uint32_t*)time_info;
-    for (uint32_t i = 0; i < count_time_info; i++)
-    {
-        time_info_32[i] = limit_time_to_uint32 (time_info[i]);
-    }
-    FIRE_EVENT(GCGlobalHeapHistory_V4,
-               current_gc_data_global->final_youngest_desired,
-               current_gc_data_global->num_heaps,
-               current_gc_data_global->condemned_generation,
-               current_gc_data_global->gen0_reduction_count,
-               current_gc_data_global->reason,
-               current_gc_data_global->global_mechanisms_p,
-               current_gc_data_global->pause_mode,
-               current_gc_data_global->mem_pressure,
-               current_gc_data_global->gen_to_condemn_reasons.get_reasons0(),
-               current_gc_data_global->gen_to_condemn_reasons.get_reasons1(),
-               count_time_info,
-               (uint32_t)(sizeof (uint32_t)),
-               (void*)time_info_32);
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < gc_heap::n_heaps; i++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[i];
-        gc_history_per_heap* current_gc_data_per_heap = hp->get_gc_data_per_heap();
-        fire_per_heap_hist_event (current_gc_data_per_heap, hp->heap_number);
-    }
-#else
-    gc_history_per_heap* current_gc_data_per_heap = get_gc_data_per_heap();
-    fire_per_heap_hist_event (current_gc_data_per_heap, heap_number);
-#endif //MULTIPLE_HEAPS
-#ifdef FEATURE_LOH_COMPACTION
-    if (!settings.concurrent && settings.loh_compaction)
-    {
-        FIRE_EVENT(GCLOHCompact,
-                   (uint16_t)get_num_heaps(),
-                   (uint32_t)(sizeof (etw_loh_compact_info)),
-                   (void *)loh_compact_info);
-    }
-#endif //FEATURE_LOH_COMPACTION
-#endif //FEATURE_EVENT_TRACE
-}
-void gc_heap::fire_committed_usage_event()
-{
-#if defined(FEATURE_EVENT_TRACE) && defined(USE_REGIONS)
-    if (!EVENT_ENABLED (GCMarkWithType)) return;
-    size_t total_committed = 0;
-    size_t committed_decommit = 0;
-    size_t committed_free = 0;
-    size_t committed_bookkeeping = 0;
-    size_t new_current_total_committed;
-    size_t new_current_total_committed_bookkeeping;
-    size_t new_committed_by_oh[recorded_committed_bucket_counts];
-    compute_committed_bytes(total_committed, committed_decommit, committed_free,
-                            committed_bookkeeping, new_current_total_committed, new_current_total_committed_bookkeeping,
-                            new_committed_by_oh);
-    size_t total_committed_in_use = new_committed_by_oh[soh] + new_committed_by_oh[loh] + new_committed_by_oh[poh];
-    size_t total_committed_in_global_decommit = committed_decommit;
-    size_t total_committed_in_free = committed_free;
-    size_t total_committed_in_global_free = new_committed_by_oh[recorded_committed_free_bucket] - total_committed_in_free - total_committed_in_global_decommit;
-    size_t total_bookkeeping_committed = committed_bookkeeping;
-    GCEventFireCommittedUsage_V1 (
-        (uint64_t)total_committed_in_use,
-        (uint64_t)total_committed_in_global_decommit,
-        (uint64_t)total_committed_in_free,
-        (uint64_t)total_committed_in_global_free,
-        (uint64_t)total_bookkeeping_committed
-    );
-#endif //FEATURE_EVENT_TRACE && USE_REGIONS
-}
-inline BOOL
-gc_heap::dt_low_ephemeral_space_p (gc_tuning_point tp)
-{
-    BOOL ret = FALSE;
-    switch (tp)
-    {
-        case tuning_deciding_condemned_gen:
-#ifndef USE_REGIONS
-        case tuning_deciding_compaction:
-        case tuning_deciding_expansion:
-#endif //USE_REGIONS
-        case tuning_deciding_full_gc:
-        {
-            ret = (!ephemeral_gen_fit_p (tp));
-            break;
-        }
-#ifndef USE_REGIONS
-        case tuning_deciding_promote_ephemeral:
-        {
-            size_t new_gen0size = approximate_new_allocation();
-            ptrdiff_t plan_ephemeral_size = total_ephemeral_size;
-            dprintf (GTC_LOG, ("h%d: plan eph size is %zd, new gen0 is %zd",
-                heap_number, plan_ephemeral_size, new_gen0size));
-            ret = ((soh_segment_size - segment_info_size) < (plan_ephemeral_size + new_gen0size));
-            break;
-        }
-#endif //USE_REGIONS
-        default:
-        {
-            assert (!"invalid tuning reason");
-            break;
-        }
-    }
-    return ret;
-}
-BOOL
-gc_heap::dt_high_frag_p (gc_tuning_point tp,
-                         int gen_number,
-                         BOOL elevate_p)
-{
-    BOOL ret = FALSE;
-    switch (tp)
-    {
-        case tuning_deciding_condemned_gen:
-        {
-            dynamic_data* dd = dynamic_data_of (gen_number);
-            float fragmentation_burden = 0;
-            if (elevate_p)
-            {
-                ret = (dd_fragmentation (dynamic_data_of (max_generation)) >= dd_max_size(dd));
-                if (ret)
-                {
-                    dprintf (6666, ("h%d: frag is %zd, max size is %zd",
-                        heap_number, dd_fragmentation (dd), dd_max_size(dd)));
-                }
-            }
-            else
-            {
-#ifndef MULTIPLE_HEAPS
-                if (gen_number == max_generation)
-                {
-                    size_t maxgen_size = generation_size (max_generation);
-                    float frag_ratio = (maxgen_size ? ((float)dd_fragmentation (dynamic_data_of (max_generation)) / (float)maxgen_size) : 0.0f);
-                    if (frag_ratio > 0.65)
-                    {
-                        dprintf (GTC_LOG, ("g2 FR: %d%%", (int)(frag_ratio*100)));
-                        return TRUE;
-                    }
-                }
-#endif //!MULTIPLE_HEAPS
-                size_t fr = generation_unusable_fragmentation (generation_of (gen_number), heap_number);
-                ret = (fr > dd_fragmentation_limit(dd));
-                if (ret)
-                {
-                    size_t gen_size = generation_size (gen_number);
-                    fragmentation_burden = (gen_size ? ((float)fr / (float)gen_size) : 0.0f);
-                    ret = (fragmentation_burden > dd_v_fragmentation_burden_limit (dd));
-                }
-                if (ret)
-                {
-                    dprintf (6666, ("h%d: gen%d, frag is %zd, alloc effi: %zu%%, unusable frag is %zd, ratio is %d",
-                        heap_number, gen_number, dd_fragmentation (dd),
-                        generation_allocator_efficiency_percent (generation_of (gen_number)),
-                        fr, (int)(fragmentation_burden * 100)));
-                }
-            }
-            break;
-        }
-        default:
-            break;
-    }
-    return ret;
-}
-inline BOOL
-gc_heap::dt_estimate_reclaim_space_p (gc_tuning_point tp, int gen_number)
-{
-    BOOL ret = FALSE;
-    switch (tp)
-    {
-        case tuning_deciding_condemned_gen:
-        {
-            if (gen_number == max_generation)
-            {
-                size_t est_maxgen_free = estimated_reclaim (gen_number);
-                uint32_t num_heaps = 1;
-#ifdef MULTIPLE_HEAPS
-                num_heaps = gc_heap::n_heaps;
-#endif //MULTIPLE_HEAPS
-                size_t min_frag_th = min_reclaim_fragmentation_threshold (num_heaps);
-                dprintf (GTC_LOG, ("h%d, min frag is %zd", heap_number, min_frag_th));
-                ret = (est_maxgen_free >= min_frag_th);
-            }
-            else
-            {
-                assert (0);
-            }
-            break;
-        }
-        default:
-            break;
-    }
-    return ret;
-}
-inline BOOL
-gc_heap::dt_estimate_high_frag_p (gc_tuning_point tp, int gen_number, uint64_t available_mem)
-{
-    BOOL ret = FALSE;
-    switch (tp)
-    {
-        case tuning_deciding_condemned_gen:
-        {
-            if (gen_number == max_generation)
-            {
-                dynamic_data* dd = dynamic_data_of (gen_number);
-                float est_frag_ratio = 0;
-                if (dd_current_size (dd) == 0)
-                {
-                    est_frag_ratio = 1;
-                }
-                else if ((dd_fragmentation (dd) == 0) || (dd_fragmentation (dd) + dd_current_size (dd) == 0))
-                {
-                    est_frag_ratio = 0;
-                }
-                else
-                {
-                    est_frag_ratio = (float)dd_fragmentation (dd) / (float)(dd_fragmentation (dd) + dd_current_size (dd));
-                }
-                size_t est_frag = (dd_fragmentation (dd) + (size_t)((dd_desired_allocation (dd) - dd_new_allocation (dd)) * est_frag_ratio));
-                dprintf (GTC_LOG, ("h%d: gen%d: current_size is %zd, frag is %zd, est_frag_ratio is %d%%, estimated frag is %zd",
-                    heap_number,
-                    gen_number,
-                    dd_current_size (dd),
-                    dd_fragmentation (dd),
-                    (int)(est_frag_ratio * 100),
-                    est_frag));
-                uint32_t num_heaps = 1;
-#ifdef MULTIPLE_HEAPS
-                num_heaps = gc_heap::n_heaps;
-#endif //MULTIPLE_HEAPS
-                uint64_t min_frag_th = min_high_fragmentation_threshold(available_mem, num_heaps);
-                ret = (est_frag >= min_frag_th);
-            }
-            else
-            {
-                assert (0);
-            }
-            break;
-        }
-        default:
-            break;
-    }
-    return ret;
-}
-inline BOOL
-gc_heap::dt_low_card_table_efficiency_p (gc_tuning_point tp)
-{
-    BOOL ret = FALSE;
-    switch (tp)
-    {
-    case tuning_deciding_condemned_gen:
-    {
-        /* promote into max-generation if the card table has too many
-        * generation faults besides the n -> 0
-        */
-        ret = (generation_skip_ratio < generation_skip_ratio_threshold);
-        break;
-    }
-    default:
-        break;
-    }
-    return ret;
-}
-inline BOOL
-gc_heap::dt_high_memory_load_p()
-{
-    return ((settings.entry_memory_load >= high_memory_load_th) || g_low_memory_status);
-}
-inline BOOL
-in_range_for_segment(uint8_t* add, heap_segment* seg)
-{
-    return ((add >= heap_segment_mem (seg)) && (add < heap_segment_reserved (seg)));
-}
-#ifdef FEATURE_BASICFREEZE
-struct bk
-{
-    uint8_t* add;
-    size_t val;
-};
-class sorted_table
-{
-private:
-    ptrdiff_t size;
-    ptrdiff_t count;
-    bk* slots;
-    bk* buckets() { return (slots + 1); }
-    uint8_t*& last_slot (bk* arr) { return arr[0].add; }
-    bk* old_slots;
-public:
-    static  sorted_table* make_sorted_table ();
-    BOOL    insert (uint8_t* add, size_t val);;
-    size_t  lookup (uint8_t*& add);
-    void    remove (uint8_t* add);
-    void    clear ();
-    void    delete_sorted_table();
-    void    delete_old_slots();
-    void    enqueue_old_slot(bk* sl);
-    BOOL    ensure_space_for_insert();
-};
-sorted_table*
-sorted_table::make_sorted_table ()
-{
-    size_t size = 400;
-    sorted_table* res = (sorted_table*)new (nothrow) char [sizeof (sorted_table) + (size + 1) * sizeof (bk)];
-    if (!res)
-        return 0;
-    res->size = size;
-    res->slots = (bk*)(res + 1);
-    res->old_slots = 0;
-    res->clear();
-    return res;
-}
-void
-sorted_table::delete_sorted_table()
-{
-    if (slots != (bk*)(this+1))
-    {
-        delete[] slots;
-    }
-    delete_old_slots();
-}
-void
-sorted_table::delete_old_slots()
-{
-    uint8_t* sl = (uint8_t*)old_slots;
-    while (sl)
-    {
-        uint8_t* dsl = sl;
-        sl = last_slot ((bk*)sl);
-        delete[] dsl;
-    }
-    old_slots = 0;
-}
-void
-sorted_table::enqueue_old_slot(bk* sl)
-{
-    last_slot (sl) = (uint8_t*)old_slots;
-    old_slots = sl;
-}
-inline
-size_t
-sorted_table::lookup (uint8_t*& add)
-{
-    ptrdiff_t high = (count-1);
-    ptrdiff_t low = 0;
-    ptrdiff_t ti;
-    ptrdiff_t mid;
-    bk* buck = buckets();
-    while (low <= high)
-    {
-        mid = ((low + high)/2);
-        ti = mid;
-        if (buck[ti].add > add)
-        {
-            if ((ti > 0) && (buck[ti-1].add <= add))
-            {
-                add = buck[ti-1].add;
-                return buck[ti - 1].val;
-            }
-            high = mid - 1;
-        }
-        else
-        {
-            if (buck[ti+1].add > add)
-            {
-                add = buck[ti].add;
-                return buck[ti].val;
-            }
-            low = mid + 1;
-        }
-    }
-    add = 0;
-    return 0;
-}
-BOOL
-sorted_table::ensure_space_for_insert()
-{
-    if (count == size)
-    {
-        size = (size * 3)/2;
-        assert((size * sizeof (bk)) > 0);
-        bk* res = (bk*)new (nothrow) char [(size + 1) * sizeof (bk)];
-        assert (res);
-        if (!res)
-            return FALSE;
-        last_slot (res) = 0;
-        memcpy (((bk*)res + 1), buckets(), count * sizeof (bk));
-        bk* last_old_slots = slots;
-        slots = res;
-        if (last_old_slots != (bk*)(this + 1))
-            enqueue_old_slot (last_old_slots);
-    }
-    return TRUE;
-}
-BOOL
-sorted_table::insert (uint8_t* add, size_t val)
-{
-    assert (count < size);
-    ptrdiff_t high = (count-1);
-    ptrdiff_t low = 0;
-    ptrdiff_t ti;
-    ptrdiff_t mid;
-    bk* buck = buckets();
-    while (low <= high)
-    {
-        mid = ((low + high)/2);
-        ti = mid;
-        if (buck[ti].add > add)
-        {
-            if ((ti == 0) || (buck[ti-1].add <= add))
-            {
-                for (ptrdiff_t k = count; k > ti;k--)
-                {
-                    buck [k] = buck [k-1];
-                }
-                buck[ti].add = add;
-                buck[ti].val = val;
-                count++;
-                return TRUE;
-            }
-            high = mid - 1;
-        }
-        else
-        {
-            if (buck[ti+1].add > add)
-            {
-                for (ptrdiff_t k = count; k > ti+1;k--)
-                {
-                    buck [k] = buck [k-1];
-                }
-                buck[ti+1].add = add;
-                buck[ti+1].val = val;
-                count++;
-                return TRUE;
-            }
-            low = mid + 1;
-        }
-    }
-    assert (0);
-    return TRUE;
-}
-void
-sorted_table::remove (uint8_t* add)
-{
-    ptrdiff_t high = (count-1);
-    ptrdiff_t low = 0;
-    ptrdiff_t ti;
-    ptrdiff_t mid;
-    bk* buck = buckets();
-    while (low <= high)
-    {
-        mid = ((low + high)/2);
-        ti = mid;
-        if (buck[ti].add > add)
-        {
-            if (buck[ti-1].add <= add)
-            {
-                for (ptrdiff_t k = ti; k < count; k++)
-                    buck[k-1] = buck[k];
-                count--;
-                return;
-            }
-            high = mid - 1;
-        }
-        else
-        {
-            if (buck[ti+1].add > add)
-            {
-                for (ptrdiff_t k = ti+1; k < count; k++)
-                    buck[k-1] = buck[k];
-                count--;
-                return;
-            }
-            low = mid + 1;
-        }
-    }
-    assert (0);
-}
-void
-sorted_table::clear()
-{
-    count = 1;
-    buckets()[0].add = MAX_PTR;
-}
-#endif //FEATURE_BASICFREEZE
-#ifdef USE_REGIONS
-inline
-size_t get_skewed_basic_region_index_for_address (uint8_t* address)
-{
-    assert ((g_gc_lowest_address <= address) && (address <= g_gc_highest_address));
-    size_t skewed_basic_region_index = (size_t)address >> gc_heap::min_segment_size_shr;
-    return skewed_basic_region_index;
-}
-inline
-size_t get_basic_region_index_for_address (uint8_t* address)
-{
-    size_t skewed_basic_region_index = get_skewed_basic_region_index_for_address (address);
-    return (skewed_basic_region_index - get_skewed_basic_region_index_for_address (g_gc_lowest_address));
-}
-inline
-heap_segment* get_region_info_for_address (uint8_t* address)
-{
-    size_t basic_region_index = (size_t)address >> gc_heap::min_segment_size_shr;
-    heap_segment* basic_region_info_entry = (heap_segment*)&seg_mapping_table[basic_region_index];
-    ptrdiff_t first_field = (ptrdiff_t)heap_segment_allocated (basic_region_info_entry);
-    if (first_field < 0)
-    {
-        basic_region_index += first_field;
-    }
-    return ((heap_segment*)(&seg_mapping_table[basic_region_index]));
-}
-inline
-heap_segment* get_region_info (uint8_t* region_start)
-{
-    size_t region_index = (size_t)region_start >> gc_heap::min_segment_size_shr;
-    heap_segment* region_info_entry = (heap_segment*)&seg_mapping_table[region_index];
-    dprintf (REGIONS_LOG, ("region info for region %p is at %zd, %zx (alloc: %p)",
-        region_start, region_index, (size_t)region_info_entry, heap_segment_allocated (region_info_entry)));
-    return (heap_segment*)&seg_mapping_table[region_index];
-}
-inline
-uint8_t* get_region_start (heap_segment* region_info)
-{
-    uint8_t* obj_start = heap_segment_mem (region_info);
-    return (obj_start - sizeof (aligned_plug_and_gap));
-}
-inline
-size_t get_region_size (heap_segment* region_info)
-{
-    return (size_t)(heap_segment_reserved (region_info) - get_region_start (region_info));
-}
-inline
-size_t get_region_committed_size (heap_segment* region)
-{
-    uint8_t* start = get_region_start (region);
-    uint8_t* committed = heap_segment_committed (region);
-    return committed - start;
-}
-inline bool is_free_region (heap_segment* region)
-{
-    return (heap_segment_allocated (region) == nullptr);
-}
-bool region_allocator::init (uint8_t* start, uint8_t* end, size_t alignment, uint8_t** lowest, uint8_t** highest)
-{
-    uint8_t* actual_start = start;
-    region_alignment = alignment;
-    large_region_alignment = LARGE_REGION_FACTOR * alignment;
-    global_region_start = (uint8_t*)align_region_up ((size_t)actual_start);
-    uint8_t* actual_end = end;
-    global_region_end = (uint8_t*)align_region_down ((size_t)actual_end);
-    global_region_left_used = global_region_start;
-    global_region_right_used = global_region_end;
-    num_left_used_free_units = 0;
-    num_right_used_free_units = 0;
-    size_t total_num_units = (global_region_end - global_region_start) / region_alignment;
-    total_free_units = (uint32_t)total_num_units;
-    uint32_t* unit_map = new (nothrow) uint32_t[total_num_units];
-    if (unit_map)
-    {
-        memset (unit_map, 0, sizeof (uint32_t) * total_num_units);
-        region_map_left_start = unit_map;
-        region_map_left_end = region_map_left_start;
-        region_map_right_start = unit_map + total_num_units;
-        region_map_right_end = region_map_right_start;
-        dprintf (REGIONS_LOG, ("start: %zx, end: %zx, total %zdmb(alignment: %zdmb), map units %zd",
-            (size_t)start, (size_t)end,
-            (size_t)((end - start) / 1024 / 1024),
-            (alignment / 1024 / 1024),
-            total_num_units));
-        *lowest = global_region_start;
-        *highest = global_region_end;
-    }
-    return (unit_map != 0);
-}
-inline
-uint8_t* region_allocator::region_address_of (uint32_t* map_index)
-{
-    return (global_region_start + ((map_index - region_map_left_start) * region_alignment));
-}
-inline
-uint32_t* region_allocator::region_map_index_of (uint8_t* address)
-{
-    return (region_map_left_start + ((address - global_region_start) / region_alignment));
-}
-void region_allocator::make_busy_block (uint32_t* index_start, uint32_t num_units)
-{
-#ifdef _DEBUG
-    dprintf (REGIONS_LOG, ("MBB[B: %zd] %d->%d", (size_t)num_units, (int)(index_start - region_map_left_start), (int)(index_start - region_map_left_start + num_units)));
-#endif //_DEBUG
-    ASSERT_HOLDING_SPIN_LOCK (&region_allocator_lock);
-    uint32_t* index_end = index_start + (num_units - 1);
-    *index_start = *index_end = num_units;
-}
-void region_allocator::make_free_block (uint32_t* index_start, uint32_t num_units)
-{
-#ifdef _DEBUG
-    dprintf (REGIONS_LOG, ("MFB[F: %zd] %d->%d", (size_t)num_units, (int)(index_start - region_map_left_start), (int)(index_start - region_map_left_start + num_units)));
-#endif //_DEBUG
-    ASSERT_HOLDING_SPIN_LOCK (&region_allocator_lock);
-    uint32_t* index_end = index_start + (num_units - 1);
-    *index_start = *index_end = region_alloc_free_bit | num_units;
-}
-void region_allocator::print_map (const char* msg)
-{
-    ASSERT_HOLDING_SPIN_LOCK (&region_allocator_lock);
-#ifdef _DEBUG
-    const char* heap_type = "UH";
-    dprintf (REGIONS_LOG, ("[%s]-----printing----%s", heap_type, msg));
-    uint32_t* current_index = region_map_left_start;
-    uint32_t* end_index = region_map_left_end;
-    uint32_t  count_free_units = 0;
-    for (int i = 0; i < 2; i++)
-    {
-        while (current_index < end_index)
-        {
-            uint32_t current_val = *current_index;
-            uint32_t current_num_units = get_num_units (current_val);
-            bool free_p = is_unit_memory_free (current_val);
-            dprintf (REGIONS_LOG, ("[%s][%s: %zd]%d->%d", heap_type, (free_p ? "F" : "B"), (size_t)current_num_units,
-                (int)(current_index - region_map_left_start),
-                (int)(current_index - region_map_left_start + current_num_units)));
-            if (free_p)
-            {
-                count_free_units += current_num_units;
-            }
-            current_index += current_num_units;
-        }
-        current_index = region_map_right_start;
-        end_index = region_map_right_end;
-        if (i == 0)
-        {
-            assert (count_free_units == num_left_used_free_units);
-        }
-        else
-        {
-            assert (count_free_units == num_left_used_free_units + num_right_used_free_units);
-        }
-    }
-    count_free_units += (uint32_t)(region_map_right_start - region_map_left_end);
-    assert(count_free_units == total_free_units);
-    uint32_t total_regions = (uint32_t)((global_region_end - global_region_start) / region_alignment);
-    dprintf (REGIONS_LOG, ("[%s]-----end printing----[%d total, left used %zd (free: %d), right used %zd (free: %d)]\n", heap_type, total_regions,
-        (region_map_left_end - region_map_left_start), num_left_used_free_units, (region_map_right_end - region_map_right_start), num_right_used_free_units));
-#endif //_DEBUG
-}
-uint8_t* region_allocator::allocate_end (uint32_t num_units, allocate_direction direction)
-{
-    uint8_t* alloc = NULL;
-    ASSERT_HOLDING_SPIN_LOCK (&region_allocator_lock);
-    if (global_region_left_used < global_region_right_used)
-    {
-        size_t end_remaining = global_region_right_used - global_region_left_used;
-        if ((end_remaining / region_alignment) >= num_units)
-        {
-            if (direction == allocate_forward)
-            {
-                make_busy_block (region_map_left_end, num_units);
-                region_map_left_end += num_units;
-                alloc = global_region_left_used;
-                global_region_left_used += num_units * region_alignment;
-            }
-            else
-            {
-                assert(direction == allocate_backward);
-                region_map_right_start -= num_units;
-                make_busy_block (region_map_right_start, num_units);
-                global_region_right_used -= num_units * region_alignment;
-                alloc = global_region_right_used;
-            }
-        }
-    }
-    return alloc;
-}
-void region_allocator::enter_spin_lock()
-{
-    while (true)
-    {
-        if (Interlocked::CompareExchange(&region_allocator_lock.lock, 0, -1) < 0)
-            break;
-        while (region_allocator_lock.lock >= 0)
-        {
-            YieldProcessor();           // indicate to the processor that we are spinning
-        }
-    }
-#ifdef _DEBUG
-    region_allocator_lock.holding_thread = GCToEEInterface::GetThread();
-#endif //_DEBUG
-}
-void region_allocator::leave_spin_lock()
-{
-#ifdef _DEBUG
-    region_allocator_lock.holding_thread = (Thread*)-1;
-#endif //_DEBUG
-    region_allocator_lock.lock = -1;
-}
-uint8_t* region_allocator::allocate (uint32_t num_units, allocate_direction direction, region_allocator_callback_fn fn)
-{
-    enter_spin_lock();
-    uint32_t* current_index;
-    uint32_t* end_index;
-    if (direction == allocate_forward)
-    {
-        current_index = region_map_left_start;
-        end_index = region_map_left_end;
-    }
-    else
-    {
-        assert(direction == allocate_backward);
-        current_index = region_map_right_end;
-        end_index = region_map_right_start;
-    }
-    dprintf (REGIONS_LOG, ("searching %d->%d", (int)(current_index - region_map_left_start), (int)(end_index - region_map_left_start)));
-    print_map ("before alloc");
-    if (((direction == allocate_forward) && (num_left_used_free_units >= num_units)) ||
-        ((direction == allocate_backward) && (num_right_used_free_units >= num_units)))
-    {
-        while (((direction == allocate_forward) && (current_index < end_index)) ||
-            ((direction == allocate_backward) && (current_index > end_index)))
-        {
-            uint32_t current_val = *(current_index - ((direction == allocate_backward) ? 1 : 0));
-            uint32_t current_num_units = get_num_units (current_val);
-            bool free_p = is_unit_memory_free (current_val);
-            dprintf (REGIONS_LOG, ("ALLOC[%s: %zd]%d->%d", (free_p ? "F" : "B"), (size_t)current_num_units,
-                (int)(current_index - region_map_left_start), (int)(current_index + current_num_units - region_map_left_start)));
-            if (free_p)
-            {
-                if (current_num_units >= num_units)
-                {
-                    dprintf (REGIONS_LOG, ("found %zd contiguous free units(%d->%d), sufficient",
-                        (size_t)current_num_units,
-                        (int)(current_index - region_map_left_start),
-                        (int)(current_index - region_map_left_start + current_num_units)));
-                    if (direction == allocate_forward)
-                    {
-                        assert (num_left_used_free_units >= num_units);
-                        num_left_used_free_units -= num_units;
-                    }
-                    else
-                    {
-                        assert (direction == allocate_backward);
-                        assert (num_right_used_free_units >= num_units);
-                        num_right_used_free_units -= num_units;
-                    }
-                    uint32_t* busy_block;
-                    uint32_t* free_block;
-                    if (direction == 1)
-                    {
-                        busy_block = current_index;
-                        free_block = current_index + num_units;
-                    }
-                    else
-                    {
-                        busy_block = current_index - num_units;
-                        free_block = current_index - current_num_units;
-                    }
-                    make_busy_block (busy_block, num_units);
-                    if ((current_num_units - num_units) > 0)
-                    {
-                        make_free_block (free_block, (current_num_units - num_units));
-                    }
-                    total_free_units -= num_units;
-                    print_map ("alloc: found in free");
-                    leave_spin_lock();
-                    return region_address_of (busy_block);
-                }
-            }
-            if (direction == allocate_forward)
-            {
-                current_index += current_num_units;
-            }
-            else
-            {
-                current_index -= current_num_units;
-            }
-        }
-    }
-    uint8_t* alloc = allocate_end (num_units, direction);
-    if (alloc)
-    {
-        total_free_units -= num_units;
-        if (fn != nullptr)
-        {
-            if (!fn (global_region_left_used))
-            {
-                delete_region_impl (alloc);
-                alloc = nullptr;
-            }
-        }
-        if (alloc)
-        {
-            print_map ("alloc: found at the end");
-        }
-    }
-    else
-    {
-        dprintf (REGIONS_LOG, ("couldn't find memory at the end! only %zd bytes left", (global_region_right_used - global_region_left_used)));
-    }
-    leave_spin_lock();
-    return alloc;
-}
-bool region_allocator::allocate_region (int gen_num, size_t size, uint8_t** start, uint8_t** end, allocate_direction direction, region_allocator_callback_fn fn)
-{
-    size_t alignment = region_alignment;
-    size_t alloc_size = align_region_up (size);
-    uint32_t num_units = (uint32_t)(alloc_size / alignment);
-    bool ret = false;
-    uint8_t* alloc = NULL;
-    dprintf (REGIONS_LOG, ("----GET %u-----", num_units));
-    alloc = allocate (num_units, direction, fn);
-    *start = alloc;
-    *end = alloc + alloc_size;
-    ret = (alloc != NULL);
-    gc_etw_segment_type segment_type;
-    if (gen_num == loh_generation)
-    {
-        segment_type = gc_etw_segment_large_object_heap;
-    }
-    else if (gen_num == poh_generation)
-    {
-        segment_type = gc_etw_segment_pinned_object_heap;
-    }
-    else
-    {
-        segment_type = gc_etw_segment_small_object_heap;
-    }
-    FIRE_EVENT(GCCreateSegment_V1, (alloc + sizeof (aligned_plug_and_gap)),
-                                  size - sizeof (aligned_plug_and_gap),
-                                  segment_type);
-    return ret;
-}
-bool region_allocator::allocate_basic_region (int gen_num, uint8_t** start, uint8_t** end, region_allocator_callback_fn fn)
-{
-    return allocate_region (gen_num, region_alignment, start, end, allocate_forward, fn);
-}
-bool region_allocator::allocate_large_region (int gen_num, uint8_t** start, uint8_t** end, allocate_direction direction, size_t size, region_allocator_callback_fn fn)
-{
-    if (size == 0)
-        size = large_region_alignment;
-    else
-    {
-        assert (round_up_power2(large_region_alignment) == large_region_alignment);
-        size = (size + (large_region_alignment - 1)) & ~(large_region_alignment - 1);
-    }
-    return allocate_region (gen_num, size, start, end, direction, fn);
-}
-void region_allocator::delete_region (uint8_t* region_start)
-{
-    enter_spin_lock();
-    delete_region_impl (region_start);
-    leave_spin_lock();
-}
-void region_allocator::delete_region_impl (uint8_t* region_start)
-{
-    ASSERT_HOLDING_SPIN_LOCK (&region_allocator_lock);
-    assert (is_region_aligned (region_start));
-    print_map ("before delete");
-    uint32_t* current_index = region_map_index_of (region_start);
-    uint32_t current_val = *current_index;
-    assert (!is_unit_memory_free (current_val));
-    dprintf (REGIONS_LOG, ("----DEL %d (%u units)-----", (*current_index - *region_map_left_start), current_val));
-    uint32_t* region_end_index = current_index + current_val;
-    uint8_t* region_end = region_address_of (region_end_index);
-    int free_block_size = current_val;
-    uint32_t* free_index = current_index;
-    if (free_index <= region_map_left_end)
-    {
-        num_left_used_free_units += free_block_size;
-    }
-    else
-    {
-        assert (free_index >= region_map_right_start);
-        num_right_used_free_units += free_block_size;
-    }
-    if ((current_index != region_map_left_start) && (current_index != region_map_right_start))
-    {
-        uint32_t previous_val = *(current_index - 1);
-        if (is_unit_memory_free(previous_val))
-        {
-            uint32_t previous_size = get_num_units (previous_val);
-            free_index -= previous_size;
-            free_block_size += previous_size;
-        }
-    }
-    if ((region_end != global_region_left_used) && (region_end != global_region_end))
-    {
-        uint32_t next_val = *region_end_index;
-        if (is_unit_memory_free(next_val))
-        {
-            uint32_t next_size = get_num_units (next_val);
-            free_block_size += next_size;
-            region_end += next_size;
-        }
-    }
-    if (region_end == global_region_left_used)
-    {
-        num_left_used_free_units -= free_block_size;
-        region_map_left_end = free_index;
-        dprintf (REGIONS_LOG, ("adjust global left used from %p to %p",
-            global_region_left_used, region_address_of (free_index)));
-        global_region_left_used = region_address_of (free_index);
-    }
-    else if (region_start == global_region_right_used)
-    {
-        num_right_used_free_units -= free_block_size;
-        region_map_right_start = free_index + free_block_size;
-        dprintf (REGIONS_LOG, ("adjust global right used from %p to %p",
-            global_region_right_used, region_address_of (free_index + free_block_size)));
-        global_region_right_used = region_address_of (free_index + free_block_size);
-    }
-    else
-    {
-        make_free_block (free_index, free_block_size);
-    }
-    total_free_units += current_val;
-    print_map ("after delete");
-}
-void region_allocator::move_highest_free_regions (int64_t n, bool small_region_p, region_free_list to_free_list[count_free_region_kinds])
-{
-    assert (n > 0);
-    uint32_t* current_index = region_map_left_end - 1;
-    uint32_t* lowest_index = region_map_left_start;
-    while (current_index >= lowest_index)
-    {
-        uint32_t current_val = *current_index;
-        uint32_t current_num_units = get_num_units (current_val);
-        bool free_p = is_unit_memory_free (current_val);
-        if (!free_p && ((current_num_units == 1) == small_region_p))
-        {
-            uint32_t* index = current_index - (current_num_units - 1);
-            heap_segment* region = get_region_info (region_address_of (index));
-            if (is_free_region (region) && !region_free_list::is_on_free_list (region, to_free_list))
-            {
-                if (n >= current_num_units)
-                {
-                    n -= current_num_units;
-                    region_free_list::unlink_region (region);
-                    region_free_list::add_region (region, to_free_list);
-                }
-                else
-                {
-                    break;
-                }
-            }
-        }
-        current_index -= current_num_units;
-    }
-}
-#endif //USE_REGIONS
-inline
-uint8_t* align_on_segment (uint8_t* add)
-{
-    return (uint8_t*)((size_t)(add + (((size_t)1 << gc_heap::min_segment_size_shr) - 1)) & ~(((size_t)1 << gc_heap::min_segment_size_shr) - 1));
-}
-inline
-uint8_t* align_lower_segment (uint8_t* add)
-{
-    return (uint8_t*)((size_t)(add) & ~(((size_t)1 << gc_heap::min_segment_size_shr) - 1));
-}
-size_t size_seg_mapping_table_of (uint8_t* from, uint8_t* end)
-{
-    from = align_lower_segment (from);
-    end = align_on_segment (end);
-    dprintf (1, ("from: %p, end: %p, size: %zx", from, end,
-        sizeof (seg_mapping)*(((size_t)(end - from) >> gc_heap::min_segment_size_shr))));
-    return (sizeof (seg_mapping)*((size_t)(end - from) >> gc_heap::min_segment_size_shr));
-}
-size_t size_region_to_generation_table_of (uint8_t* from, uint8_t* end)
-{
-    dprintf (1, ("from: %p, end: %p, size: %zx", from, end,
-        sizeof (uint8_t)*(((size_t)(end - from) >> gc_heap::min_segment_size_shr))));
-    return sizeof (uint8_t)*((size_t)(end - from) >> gc_heap::min_segment_size_shr);
-}
-inline
-size_t seg_mapping_word_of (uint8_t* add)
-{
-    return (size_t)add >> gc_heap::min_segment_size_shr;
-}
-#ifdef FEATURE_BASICFREEZE
-inline
-size_t ro_seg_begin_index (heap_segment* seg)
-{
-#ifdef USE_REGIONS
-    size_t begin_index = (size_t)heap_segment_mem (seg) >> gc_heap::min_segment_size_shr;
-#else
-    size_t begin_index = (size_t)seg >> gc_heap::min_segment_size_shr;
-#endif //USE_REGIONS
-    begin_index = max (begin_index, (size_t)g_gc_lowest_address >> gc_heap::min_segment_size_shr);
-    return begin_index;
-}
-inline
-size_t ro_seg_end_index (heap_segment* seg)
-{
-    size_t end_index = (size_t)(heap_segment_reserved (seg) - 1) >> gc_heap::min_segment_size_shr;
-    end_index = min (end_index, (size_t)g_gc_highest_address >> gc_heap::min_segment_size_shr);
-    return end_index;
-}
-void seg_mapping_table_add_ro_segment (heap_segment* seg)
-{
-    if ((heap_segment_reserved (seg) <= g_gc_lowest_address) || (heap_segment_mem (seg) >= g_gc_highest_address))
-        return;
-    for (size_t entry_index = ro_seg_begin_index (seg); entry_index <= ro_seg_end_index (seg); entry_index++)
-    {
-#ifdef USE_REGIONS
-        heap_segment* region = (heap_segment*)&seg_mapping_table[entry_index];
-        heap_segment_allocated (region) = (uint8_t*)ro_in_entry;
-#else
-        seg_mapping_table[entry_index].seg1 = (heap_segment*)((size_t)seg_mapping_table[entry_index].seg1 | ro_in_entry);
-#endif //USE_REGIONS
-    }
-}
-void seg_mapping_table_remove_ro_segment (heap_segment* seg)
-{
-    UNREFERENCED_PARAMETER(seg);
-#if 0
-#endif //0
-}
-heap_segment* ro_segment_lookup (uint8_t* o)
-{
-    uint8_t* ro_seg_start = o;
-    heap_segment* seg = (heap_segment*)gc_heap::seg_table->lookup (ro_seg_start);
-    if (ro_seg_start && in_range_for_segment (o, seg))
-        return seg;
-    else
-        return 0;
-}
-#endif //FEATURE_BASICFREEZE
-#ifndef USE_REGIONS
-void gc_heap::seg_mapping_table_add_segment (heap_segment* seg, gc_heap* hp)
-{
-    size_t seg_end = (size_t)(heap_segment_reserved (seg) - 1);
-    size_t begin_index = (size_t)seg >> gc_heap::min_segment_size_shr;
-    seg_mapping* begin_entry = &seg_mapping_table[begin_index];
-    size_t end_index = seg_end >> gc_heap::min_segment_size_shr;
-    seg_mapping* end_entry = &seg_mapping_table[end_index];
-    dprintf (2, ("adding seg %p(%zd)-%p(%zd)",
-        seg, begin_index, heap_segment_reserved (seg), end_index));
-    dprintf (2, ("before add: begin entry%zd: boundary: %p; end entry: %zd: boundary: %p",
-        begin_index, (seg_mapping_table[begin_index].boundary + 1),
-        end_index, (seg_mapping_table[end_index].boundary + 1)));
-#ifdef MULTIPLE_HEAPS
-#ifdef SIMPLE_DPRINTF
-    dprintf (2, ("begin %zd: h0: %p(%d), h1: %p(%d); end %zd: h0: %p(%d), h1: %p(%d)",
-        begin_index, (uint8_t*)(begin_entry->h0), (begin_entry->h0 ? begin_entry->h0->heap_number : -1),
-        (uint8_t*)(begin_entry->h1), (begin_entry->h1 ? begin_entry->h1->heap_number : -1),
-        end_index, (uint8_t*)(end_entry->h0), (end_entry->h0 ? end_entry->h0->heap_number : -1),
-        (uint8_t*)(end_entry->h1), (end_entry->h1 ? end_entry->h1->heap_number : -1)));
-#endif //SIMPLE_DPRINTF
-    assert (end_entry->boundary == 0);
-    assert (end_entry->h0 == 0);
-    end_entry->h0 = hp;
-    assert (begin_entry->h1 == 0);
-    begin_entry->h1 = hp;
-#else
-    UNREFERENCED_PARAMETER(hp);
-#endif //MULTIPLE_HEAPS
-    end_entry->boundary = (uint8_t*)seg_end;
-    dprintf (2, ("set entry %zd seg1 and %zd seg0 to %p", begin_index, end_index, seg));
-    assert ((begin_entry->seg1 == 0) || ((size_t)(begin_entry->seg1) == ro_in_entry));
-    begin_entry->seg1 = (heap_segment*)((size_t)(begin_entry->seg1) | (size_t)seg);
-    end_entry->seg0 = seg;
-    for (size_t entry_index = (begin_index + 1); entry_index <= (end_index - 1); entry_index++)
-    {
-        assert (seg_mapping_table[entry_index].boundary == 0);
-#ifdef MULTIPLE_HEAPS
-        assert (seg_mapping_table[entry_index].h0 == 0);
-        seg_mapping_table[entry_index].h1 = hp;
-#endif //MULTIPLE_HEAPS
-        seg_mapping_table[entry_index].seg1 = seg;
-    }
-    dprintf (2, ("after add: begin entry%zd: boundary: %p; end entry: %zd: boundary: %p",
-        begin_index, (seg_mapping_table[begin_index].boundary + 1),
-        end_index, (seg_mapping_table[end_index].boundary + 1)));
-#if defined(MULTIPLE_HEAPS) && defined(SIMPLE_DPRINTF)
-    dprintf (2, ("begin %zd: h0: %p(%d), h1: %p(%d); end: %zd h0: %p(%d), h1: %p(%d)",
-        begin_index, (uint8_t*)(begin_entry->h0), (begin_entry->h0 ? begin_entry->h0->heap_number : -1),
-        (uint8_t*)(begin_entry->h1), (begin_entry->h1 ? begin_entry->h1->heap_number : -1),
-        end_index, (uint8_t*)(end_entry->h0), (end_entry->h0 ? end_entry->h0->heap_number : -1),
-        (uint8_t*)(end_entry->h1), (end_entry->h1 ? end_entry->h1->heap_number : -1)));
-#endif //MULTIPLE_HEAPS && SIMPLE_DPRINTF
-}
-void gc_heap::seg_mapping_table_remove_segment (heap_segment* seg)
-{
-    size_t seg_end = (size_t)(heap_segment_reserved (seg) - 1);
-    size_t begin_index = (size_t)seg >> gc_heap::min_segment_size_shr;
-    seg_mapping* begin_entry = &seg_mapping_table[begin_index];
-    size_t end_index = seg_end >> gc_heap::min_segment_size_shr;
-    seg_mapping* end_entry = &seg_mapping_table[end_index];
-    dprintf (2, ("removing seg %p(%zd)-%p(%zd)",
-        seg, begin_index, heap_segment_reserved (seg), end_index));
-    assert (end_entry->boundary == (uint8_t*)seg_end);
-    end_entry->boundary = 0;
-#ifdef MULTIPLE_HEAPS
-    gc_heap* hp = heap_segment_heap (seg);
-    assert (end_entry->h0 == hp);
-    end_entry->h0 = 0;
-    assert (begin_entry->h1 == hp);
-    begin_entry->h1 = 0;
-#endif //MULTIPLE_HEAPS
-    assert (begin_entry->seg1 != 0);
-    begin_entry->seg1 = (heap_segment*)((size_t)(begin_entry->seg1) & ro_in_entry);
-    end_entry->seg0 = 0;
-    for (size_t entry_index = (begin_index + 1); entry_index <= (end_index - 1); entry_index++)
-    {
-        assert (seg_mapping_table[entry_index].boundary == 0);
-#ifdef MULTIPLE_HEAPS
-        assert (seg_mapping_table[entry_index].h0 == 0);
-        assert (seg_mapping_table[entry_index].h1 == hp);
-        seg_mapping_table[entry_index].h1 = 0;
-#endif //MULTIPLE_HEAPS
-        seg_mapping_table[entry_index].seg1 = 0;
-    }
-    dprintf (2, ("after remove: begin entry%zd: boundary: %p; end entry: %zd: boundary: %p",
-        begin_index, (seg_mapping_table[begin_index].boundary + 1),
-        end_index, (seg_mapping_table[end_index].boundary + 1)));
-#ifdef MULTIPLE_HEAPS
-    dprintf (2, ("begin %zd: h0: %p, h1: %p; end: %zd h0: %p, h1: %p",
-        begin_index, (uint8_t*)(begin_entry->h0), (uint8_t*)(begin_entry->h1),
-        end_index, (uint8_t*)(end_entry->h0), (uint8_t*)(end_entry->h1)));
-#endif //MULTIPLE_HEAPS
-}
-#endif //!USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-inline
-gc_heap* seg_mapping_table_heap_of_worker (uint8_t* o)
-{
-    size_t index = (size_t)o >> gc_heap::min_segment_size_shr;
-    seg_mapping* entry = &seg_mapping_table[index];
-#ifdef USE_REGIONS
-    gc_heap* hp = heap_segment_heap ((heap_segment*)entry);
-#else
-    gc_heap* hp = ((o > entry->boundary) ? entry->h1 : entry->h0);
-    dprintf (2, ("checking obj %p, index is %zd, entry: boundary: %p, h0: %p, seg0: %p, h1: %p, seg1: %p",
-        o, index, (entry->boundary + 1),
-        (uint8_t*)(entry->h0), (uint8_t*)(entry->seg0),
-        (uint8_t*)(entry->h1), (uint8_t*)(entry->seg1)));
-#ifdef _DEBUG
-    heap_segment* seg = ((o > entry->boundary) ? entry->seg1 : entry->seg0);
-#ifdef FEATURE_BASICFREEZE
-    if ((size_t)seg & ro_in_entry)
-        seg = (heap_segment*)((size_t)seg & ~ro_in_entry);
-#endif //FEATURE_BASICFREEZE
-#ifdef TRACE_GC
-    if (seg)
-    {
-        if (in_range_for_segment (o, seg))
-        {
-            dprintf (2, ("obj %p belongs to segment %p(-%p)", o, seg, (uint8_t*)heap_segment_allocated (seg)));
-        }
-        else
-        {
-            dprintf (2, ("found seg %p(-%p) for obj %p, but it's not on the seg",
-                seg, (uint8_t*)heap_segment_allocated (seg), o));
-        }
-    }
-    else
-    {
-        dprintf (2, ("could not find obj %p in any existing segments", o));
-    }
-#endif //TRACE_GC
-#endif //_DEBUG
-#endif //USE_REGIONS
-    return hp;
-}
-gc_heap* seg_mapping_table_heap_of (uint8_t* o)
-{
-    if ((o < g_gc_lowest_address) || (o >= g_gc_highest_address))
-        return 0;
-    return seg_mapping_table_heap_of_worker (o);
-}
-gc_heap* seg_mapping_table_heap_of_gc (uint8_t* o)
-{
-#ifdef FEATURE_BASICFREEZE
-    if ((o < g_gc_lowest_address) || (o >= g_gc_highest_address))
-        return 0;
-#endif //FEATURE_BASICFREEZE
-    return seg_mapping_table_heap_of_worker (o);
-}
-#endif //MULTIPLE_HEAPS
-heap_segment* seg_mapping_table_segment_of (uint8_t* o)
-{
-#ifdef FEATURE_BASICFREEZE
-    if ((o < g_gc_lowest_address) || (o >= g_gc_highest_address))
-        return ro_segment_lookup (o);
-#endif //FEATURE_BASICFREEZE
-    size_t index = (size_t)o >> gc_heap::min_segment_size_shr;
-    seg_mapping* entry = &seg_mapping_table[index];
-#ifdef USE_REGIONS
-    ptrdiff_t first_field = (ptrdiff_t)heap_segment_allocated ((heap_segment*)entry);
-    if (first_field == 0)
-    {
-        dprintf (REGIONS_LOG, ("asked for seg for %p, in a freed region mem: %p, committed %p",
-            o, heap_segment_mem ((heap_segment*)entry),
-            heap_segment_committed ((heap_segment*)entry)));
-        return 0;
-    }
-    assert (first_field != 0);
-    assert (first_field != ro_in_entry);
-    if (first_field < 0)
-    {
-        index += first_field;
-    }
-    heap_segment* seg = (heap_segment*)&seg_mapping_table[index];
-#else //USE_REGIONS
-    dprintf (2, ("checking obj %p, index is %zd, entry: boundary: %p, seg0: %p, seg1: %p",
-        o, index, (entry->boundary + 1),
-        (uint8_t*)(entry->seg0), (uint8_t*)(entry->seg1)));
-    heap_segment* seg = ((o > entry->boundary) ? entry->seg1 : entry->seg0);
-#ifdef FEATURE_BASICFREEZE
-    if ((size_t)seg & ro_in_entry)
-        seg = (heap_segment*)((size_t)seg & ~ro_in_entry);
-#endif //FEATURE_BASICFREEZE
-#endif //USE_REGIONS
-    if (seg)
-    {
-        if (in_range_for_segment (o, seg))
-        {
-            dprintf (2, ("obj %p belongs to segment %p(-%p)", o, (uint8_t*)heap_segment_mem(seg), (uint8_t*)heap_segment_reserved(seg)));
-        }
-        else
-        {
-            dprintf (2, ("found seg %p(-%p) for obj %p, but it's not on the seg, setting it to 0",
-                (uint8_t*)heap_segment_mem(seg), (uint8_t*)heap_segment_reserved(seg), o));
-            seg = 0;
-        }
-    }
-    else
-    {
-        dprintf (2, ("could not find obj %p in any existing segments", o));
-    }
-#ifdef FEATURE_BASICFREEZE
-    if (!seg)
-    {
-        seg = ro_segment_lookup (o);
-        if (seg && !in_range_for_segment (o, seg))
-            seg = 0;
-    }
-#endif //FEATURE_BASICFREEZE
-    return seg;
-}
-size_t gcard_of ( uint8_t*);
-#define GC_MARKED       (size_t)0x1
-#ifdef DOUBLY_LINKED_FL
-#define BGC_MARKED_BY_FGC (size_t)0x2
-#define MAKE_FREE_OBJ_IN_COMPACT (size_t)0x4
-#define ALLOWED_SPECIAL_HEADER_BITS (GC_MARKED|BGC_MARKED_BY_FGC|MAKE_FREE_OBJ_IN_COMPACT)
-#else //DOUBLY_LINKED_FL
-#define ALLOWED_SPECIAL_HEADER_BITS (GC_MARKED)
-#endif //!DOUBLY_LINKED_FL
-#ifdef HOST_64BIT
-#define SPECIAL_HEADER_BITS (0x7)
-#else
-#define SPECIAL_HEADER_BITS (0x3)
-#endif
-#define slot(i, j) ((uint8_t**)(i))[(j)+1]
-#define free_object_base_size (plug_skew + sizeof(ArrayBase))
-#define free_list_slot(x) ((uint8_t**)(x))[2]
-#define free_list_undo(x) ((uint8_t**)(x))[-1]
-#define UNDO_EMPTY ((uint8_t*)1)
-#ifdef DOUBLY_LINKED_FL
-#define free_list_prev(x) ((uint8_t**)(x))[3]
-#define PREV_EMPTY ((uint8_t*)1)
-void check_and_clear_in_free_list (uint8_t* o, size_t size)
-{
-    if (size >= min_free_list)
-    {
-        free_list_prev (o) = PREV_EMPTY;
-    }
-}
-void clear_prev_bit (uint8_t* o, size_t size)
-{
-    if (size >= min_free_list)
-    {
-        free_list_prev (o) = 0;
-    }
-}
-#endif //DOUBLY_LINKED_FL
-class CObjectHeader : public Object
-{
-public:
-#if defined(FEATURE_NATIVEAOT) || defined(BUILD_AS_STANDALONE)
-    uint32_t GetNumComponents()
-    {
-        return ((ArrayBase *)this)->GetNumComponents();
-    }
-    void Validate(BOOL bDeep=TRUE, BOOL bVerifyNextHeader = FALSE, BOOL bVerifySyncBlock = FALSE)
-    {
-        UNREFERENCED_PARAMETER(bVerifyNextHeader);
-        UNREFERENCED_PARAMETER(bVerifySyncBlock);
-        MethodTable * pMT = GetMethodTable();
-        _ASSERTE(pMT->SanityCheck());
-        bool noRangeChecks =
-            (GCConfig::GetHeapVerifyLevel() & GCConfig::HEAPVERIFY_NO_RANGE_CHECKS) == GCConfig::HEAPVERIFY_NO_RANGE_CHECKS;
-        BOOL fSmallObjectHeapPtr = FALSE, fLargeObjectHeapPtr = FALSE;
-        if (!noRangeChecks)
-        {
-            fSmallObjectHeapPtr = g_theGCHeap->IsHeapPointer(this, TRUE);
-            if (!fSmallObjectHeapPtr)
-                fLargeObjectHeapPtr = g_theGCHeap->IsHeapPointer(this);
-            _ASSERTE(fSmallObjectHeapPtr || fLargeObjectHeapPtr);
-        }
-#ifdef FEATURE_STRUCTALIGN
-        _ASSERTE(IsStructAligned((uint8_t *)this, GetMethodTable()->GetBaseAlignment()));
-#endif // FEATURE_STRUCTALIGN
-#if defined(FEATURE_64BIT_ALIGNMENT) && !defined(FEATURE_NATIVEAOT)
-        if (pMT->RequiresAlign8())
-        {
-            _ASSERTE((((size_t)this) & 0x7) == (pMT->IsValueType() ? 4U : 0U));
-        }
-#endif // FEATURE_64BIT_ALIGNMENT
-#ifdef VERIFY_HEAP
-        if (bDeep && (GCConfig::GetHeapVerifyLevel() & GCConfig::HEAPVERIFY_GC))
-            g_theGCHeap->ValidateObjectMember(this);
-#endif
-        if (fSmallObjectHeapPtr)
-        {
-#ifdef FEATURE_BASICFREEZE
-            _ASSERTE(!g_theGCHeap->IsLargeObject(this) || g_theGCHeap->IsInFrozenSegment(this));
-#else
-            _ASSERTE(!g_theGCHeap->IsLargeObject(this));
-#endif
-        }
-    }
-    void ValidateHeap(BOOL bDeep)
-    {
-        Validate(bDeep);
-    }
-#endif //FEATURE_NATIVEAOT || BUILD_AS_STANDALONE
-    MethodTable    *GetMethodTable() const
-    {
-        return( (MethodTable *) (((size_t) RawGetMethodTable()) & (~SPECIAL_HEADER_BITS)));
-    }
-    void SetMarked()
-    {
-        _ASSERTE(RawGetMethodTable());
-        RawSetMethodTable((MethodTable *) (((size_t) RawGetMethodTable()) | GC_MARKED));
-    }
-    BOOL IsMarked() const
-    {
-        return !!(((size_t)RawGetMethodTable()) & GC_MARKED);
-    }
-    void SetPinned()
-    {
-        assert (!(gc_heap::settings.concurrent));
-        GetHeader()->SetGCBit();
-    }
-    BOOL IsPinned() const
-    {
-        return !!((((CObjectHeader*)this)->GetHeader()->GetBits()) & BIT_SBLK_GC_RESERVE);
-    }
-    void ClearMarked()
-    {
-#ifdef DOUBLY_LINKED_FL
-        RawSetMethodTable ((MethodTable *)(((size_t) RawGetMethodTable()) & (~GC_MARKED)));
-#else
-        RawSetMethodTable (GetMethodTable());
-#endif //DOUBLY_LINKED_FL
-    }
-#ifdef DOUBLY_LINKED_FL
-    void SetBGCMarkBit()
-    {
-        RawSetMethodTable((MethodTable *) (((size_t) RawGetMethodTable()) | BGC_MARKED_BY_FGC));
-    }
-    BOOL IsBGCMarkBitSet() const
-    {
-        return !!(((size_t)RawGetMethodTable()) & BGC_MARKED_BY_FGC);
-    }
-    void ClearBGCMarkBit()
-    {
-        RawSetMethodTable((MethodTable *)(((size_t) RawGetMethodTable()) & (~BGC_MARKED_BY_FGC)));
-    }
-    void SetFreeObjInCompactBit()
-    {
-        RawSetMethodTable((MethodTable *) (((size_t) RawGetMethodTable()) | MAKE_FREE_OBJ_IN_COMPACT));
-    }
-    BOOL IsFreeObjInCompactBitSet() const
-    {
-        return !!(((size_t)RawGetMethodTable()) & MAKE_FREE_OBJ_IN_COMPACT);
-    }
-    void ClearFreeObjInCompactBit()
-    {
-#ifdef _DEBUG
-        Validate(FALSE);
-#endif //_DEBUG
-        RawSetMethodTable((MethodTable *)(((size_t) RawGetMethodTable()) & (~MAKE_FREE_OBJ_IN_COMPACT)));
-    }
-#endif //DOUBLY_LINKED_FL
-    size_t ClearSpecialBits()
-    {
-        size_t special_bits = ((size_t)RawGetMethodTable()) & SPECIAL_HEADER_BITS;
-        if (special_bits != 0)
-        {
-            assert ((special_bits & (~ALLOWED_SPECIAL_HEADER_BITS)) == 0);
-            RawSetMethodTable ((MethodTable*)(((size_t)RawGetMethodTable()) & ~(SPECIAL_HEADER_BITS)));
-        }
-        return special_bits;
-    }
-    void SetSpecialBits (size_t special_bits)
-    {
-        assert ((special_bits & (~ALLOWED_SPECIAL_HEADER_BITS)) == 0);
-        if (special_bits != 0)
-        {
-            RawSetMethodTable ((MethodTable*)(((size_t)RawGetMethodTable()) | special_bits));
-        }
-    }
-    CGCDesc *GetSlotMap ()
-    {
-        assert (GetMethodTable()->ContainsGCPointers());
-        return CGCDesc::GetCGCDescFromMT(GetMethodTable());
-    }
-    void SetFree(size_t size)
-    {
-        assert (size >= free_object_base_size);
-        assert (g_gc_pFreeObjectMethodTable->GetBaseSize() == free_object_base_size);
-        assert (g_gc_pFreeObjectMethodTable->RawGetComponentSize() == 1);
-        RawSetMethodTable( g_gc_pFreeObjectMethodTable );
-        size_t* numComponentsPtr = (size_t*) &((uint8_t*) this)[ArrayBase::GetOffsetOfNumComponents()];
-        *numComponentsPtr = size - free_object_base_size;
-#ifdef VERIFY_HEAP
-        assert (*numComponentsPtr >= 0);
-        if (GCConfig::GetHeapVerifyLevel() & GCConfig::HEAPVERIFY_GC)
-        {
-            memset (((uint8_t*)this)+sizeof(ArrayBase), 0xcc, *numComponentsPtr);
-#ifdef DOUBLY_LINKED_FL
-            if (*numComponentsPtr > 0)
-            {
-                free_list_slot (this) = 0;
-            }
-#endif //DOUBLY_LINKED_FL
-        }
-#endif //VERIFY_HEAP
-#ifdef DOUBLY_LINKED_FL
-        check_and_clear_in_free_list ((uint8_t*)this, size);
-#endif //DOUBLY_LINKED_FL
-    }
-    void UnsetFree()
-    {
-        size_t size = free_object_base_size - plug_skew;
-        PTR_PTR m = (PTR_PTR) this;
-        for (size_t i = 0; i < size / sizeof(PTR_PTR); i++)
-            *(m++) = 0;
-    }
-    BOOL IsFree () const
-    {
-        return (GetMethodTable() == g_gc_pFreeObjectMethodTable);
-    }
-#ifdef FEATURE_STRUCTALIGN
-    int GetRequiredAlignment () const
-    {
-        return GetMethodTable()->GetRequiredAlignment();
-    }
-#endif // FEATURE_STRUCTALIGN
-    BOOL ContainsGCPointers() const
-    {
-        return GetMethodTable()->ContainsGCPointers();
-    }
-#ifdef COLLECTIBLE_CLASS
-    BOOL Collectible() const
-    {
-        return GetMethodTable()->Collectible();
-    }
-    FORCEINLINE BOOL ContainsGCPointersOrCollectible() const
-    {
-        MethodTable *pMethodTable = GetMethodTable();
-        return (pMethodTable->ContainsGCPointers() || pMethodTable->Collectible());
-    }
-#endif //COLLECTIBLE_CLASS
-    Object* GetObjectBase() const
-    {
-        return (Object*) this;
-    }
-};
-#define header(i) ((CObjectHeader*)(i))
-#define method_table(o) ((CObjectHeader*)(o))->GetMethodTable()
-#ifdef DOUBLY_LINKED_FL
-inline
-BOOL is_on_free_list (uint8_t* o, size_t size)
-{
-    if (size >= min_free_list)
-    {
-        if (header(o)->GetMethodTable() == g_gc_pFreeObjectMethodTable)
-        {
-            return (free_list_prev (o) != PREV_EMPTY);
-        }
-    }
-    return FALSE;
-}
-inline
-void set_plug_bgc_mark_bit (uint8_t* node)
-{
-    header(node)->SetBGCMarkBit();
-}
-inline
-BOOL is_plug_bgc_mark_bit_set (uint8_t* node)
-{
-    return header(node)->IsBGCMarkBitSet();
-}
-inline
-void clear_plug_bgc_mark_bit (uint8_t* node)
-{
-    header(node)->ClearBGCMarkBit();
-}
-inline
-void set_free_obj_in_compact_bit (uint8_t* node)
-{
-    header(node)->SetFreeObjInCompactBit();
-}
-inline
-BOOL is_free_obj_in_compact_bit_set (uint8_t* node)
-{
-    return header(node)->IsFreeObjInCompactBitSet();
-}
-inline
-void clear_free_obj_in_compact_bit (uint8_t* node)
-{
-    header(node)->ClearFreeObjInCompactBit();
-}
-#endif //DOUBLY_LINKED_FL
-#ifdef SHORT_PLUGS
-inline
-void set_plug_padded (uint8_t* node)
-{
-    header(node)->SetMarked();
-}
-inline
-void clear_plug_padded (uint8_t* node)
-{
-    header(node)->ClearMarked();
-}
-inline
-BOOL is_plug_padded (uint8_t* node)
-{
-    return header(node)->IsMarked();
-}
-#else //SHORT_PLUGS
-inline void set_plug_padded (uint8_t* node){}
-inline void clear_plug_padded (uint8_t* node){}
-inline
-BOOL is_plug_padded (uint8_t* node){return FALSE;}
-#endif //SHORT_PLUGS
-inline
-size_t clear_special_bits (uint8_t* node)
-{
-    return header(node)->ClearSpecialBits();
-}
-inline
-void set_special_bits (uint8_t* node, size_t special_bits)
-{
-    header(node)->SetSpecialBits (special_bits);
-}
-inline size_t unused_array_size(uint8_t * p)
-{
-    assert(((CObjectHeader*)p)->IsFree());
-    size_t* numComponentsPtr = (size_t*)(p + ArrayBase::GetOffsetOfNumComponents());
-    return free_object_base_size + *numComponentsPtr;
-}
-inline
-heap_segment* heap_segment_non_sip (heap_segment* ns)
-{
-#ifdef USE_REGIONS
-    if ((ns == 0) || !heap_segment_swept_in_plan (ns))
-    {
-        return ns;
-    }
-    else
-    {
-        do
-        {
-            if (heap_segment_swept_in_plan (ns))
-            {
-                dprintf (REGIONS_LOG, ("region %p->%p SIP",
-                    heap_segment_mem (ns), heap_segment_allocated (ns)));
-            }
-            ns = heap_segment_next (ns);
-        } while ((ns != 0) && heap_segment_swept_in_plan (ns));
-        return ns;
-    }
-#else //USE_REGIONS
-    return ns;
-#endif //USE_REGIONS
-}
-inline
-heap_segment* heap_segment_next_non_sip (heap_segment* seg)
-{
-    heap_segment* ns = heap_segment_next (seg);
-#ifdef USE_REGIONS
-    return heap_segment_non_sip (ns);
-#else
-    return ns;
-#endif //USE_REGIONS
-}
-heap_segment* heap_segment_rw (heap_segment* ns)
-{
-    if ((ns == 0) || !heap_segment_read_only_p (ns))
-    {
-        return ns;
-    }
-    else
-    {
-        do
-        {
-            ns = heap_segment_next (ns);
-        } while ((ns != 0) && heap_segment_read_only_p (ns));
-        return ns;
-    }
-}
-heap_segment* heap_segment_next_rw (heap_segment* seg)
-{
-    heap_segment* ns = heap_segment_next (seg);
-    return heap_segment_rw (ns);
-}
-heap_segment* heap_segment_prev_rw (heap_segment* begin, heap_segment* seg)
-{
-    assert (begin != 0);
-    heap_segment* prev = begin;
-    heap_segment* current = heap_segment_next_rw (begin);
-    while (current && current != seg)
-    {
-        prev = current;
-        current = heap_segment_next_rw (current);
-    }
-    if (current == seg)
-    {
-        return prev;
-    }
-    else
-    {
-        return 0;
-    }
-}
-heap_segment* heap_segment_prev (heap_segment* begin, heap_segment* seg)
-{
-    assert (begin != 0);
-    heap_segment* prev = begin;
-    heap_segment* current = heap_segment_next (begin);
-    while (current && current != seg)
-    {
-        prev = current;
-        current = heap_segment_next (current);
-    }
-    if (current == seg)
-    {
-        return prev;
-    }
-    else
-    {
-        return 0;
-    }
-}
-heap_segment* heap_segment_in_range (heap_segment* ns)
-{
-    if ((ns == 0) || heap_segment_in_range_p (ns))
-    {
-        return ns;
-    }
-    else
-    {
-        do
-        {
-            ns = heap_segment_next (ns);
-        } while ((ns != 0) && !heap_segment_in_range_p (ns));
-        return ns;
-    }
-}
-heap_segment* heap_segment_next_in_range (heap_segment* seg)
-{
-    heap_segment* ns = heap_segment_next (seg);
-    return heap_segment_in_range (ns);
-}
-struct imemory_data
-{
-    uint8_t* memory_base;
-};
-struct numa_reserved_block
-{
-    uint8_t*        memory_base;
-    size_t          block_size;
-    numa_reserved_block() : memory_base(nullptr), block_size(0) { }
-};
-struct initial_memory_details
-{
-    imemory_data *initial_memory;
-    imemory_data *initial_normal_heap; // points into initial_memory_array
-    imemory_data *initial_large_heap;  // points into initial_memory_array
-    imemory_data *initial_pinned_heap; // points into initial_memory_array
-    size_t block_size_normal;
-    size_t block_size_large;
-    size_t block_size_pinned;
-    int block_count;                // # of blocks in each
-    int current_block_normal;
-    int current_block_large;
-    int current_block_pinned;
-    enum
-    {
-        ALLATONCE = 1,
-        EACH_GENERATION,
-        EACH_BLOCK,
-        ALLATONCE_SEPARATED_POH,
-        EACH_NUMA_NODE
-    };
-    size_t allocation_pattern;
-    size_t block_size(int i)
-    {
-        switch (i / block_count)
-        {
-            case 0: return block_size_normal;
-            case 1: return block_size_large;
-            case 2: return block_size_pinned;
-            default: __UNREACHABLE();
-        }
-    };
-    void* get_initial_memory (int gen, int h_number)
-    {
-        switch (gen)
-        {
-            case soh_gen0:
-            case soh_gen1:
-            case soh_gen2: return initial_normal_heap[h_number].memory_base;
-            case loh_generation: return initial_large_heap[h_number].memory_base;
-            case poh_generation: return initial_pinned_heap[h_number].memory_base;
-            default: __UNREACHABLE();
-        }
-    };
-    size_t get_initial_size (int gen)
-    {
-        switch (gen)
-        {
-            case soh_gen0:
-            case soh_gen1:
-            case soh_gen2: return block_size_normal;
-            case loh_generation: return block_size_large;
-            case poh_generation: return block_size_pinned;
-            default: __UNREACHABLE();
-        }
-    };
-    int numa_reserved_block_count;
-    numa_reserved_block* numa_reserved_block_table;
-};
-initial_memory_details memory_details;
-BOOL gc_heap::reserve_initial_memory (size_t normal_size, size_t large_size, size_t pinned_size,
-                                      int num_heaps, bool use_large_pages_p, bool separated_poh_p, uint16_t* heap_no_to_numa_node)
-{
-    BOOL reserve_success = FALSE;
-    assert (memory_details.initial_memory == 0);
-    memory_details.initial_memory = new (nothrow) imemory_data[num_heaps * (total_generation_count - ephemeral_generation_count)];
-    if (memory_details.initial_memory == 0)
-    {
-        dprintf (2, ("failed to reserve %zd bytes for imemory_data",
-            num_heaps * (total_generation_count - ephemeral_generation_count) * sizeof (imemory_data)));
-        return FALSE;
-    }
-    memory_details.initial_normal_heap = memory_details.initial_memory;
-    memory_details.initial_large_heap = memory_details.initial_normal_heap + num_heaps;
-    memory_details.initial_pinned_heap = memory_details.initial_large_heap + num_heaps;
-    memory_details.block_size_normal = normal_size;
-    memory_details.block_size_large = large_size;
-    memory_details.block_size_pinned = pinned_size;
-    memory_details.block_count = num_heaps;
-    memory_details.current_block_normal = 0;
-    memory_details.current_block_large = 0;
-    memory_details.current_block_pinned = 0;
-    g_gc_lowest_address = MAX_PTR;
-    g_gc_highest_address = 0;
-    if (((size_t)MAX_PTR - large_size) < normal_size)
-    {
-        dprintf (2, ("0x%zx + 0x%zx already overflow", normal_size, large_size));
-        return FALSE;
-    }
-    if (((size_t)MAX_PTR / memory_details.block_count) < (normal_size + large_size + pinned_size))
-    {
-        dprintf (2, ("(0x%zx + 0x%zx)*0x%x overflow", normal_size, large_size, memory_details.block_count));
-        return FALSE;
-    }
-    memory_details.numa_reserved_block_count = 0;
-    memory_details.numa_reserved_block_table = nullptr;
-    int numa_node_count = 0;
-    if (heap_no_to_numa_node != nullptr)
-    {
-        uint16_t highest_numa_node = 0;
-        for (int heap_no = 0; heap_no < num_heaps; heap_no++)
-        {
-            uint16_t heap_numa_node = heap_no_to_numa_node[heap_no];
-            highest_numa_node = max (highest_numa_node, heap_numa_node);
-        }
-        assert (highest_numa_node < MAX_SUPPORTED_CPUS);
-        numa_node_count = highest_numa_node + 1;
-        memory_details.numa_reserved_block_count = numa_node_count * (1 + separated_poh_p);
-        memory_details.numa_reserved_block_table = new (nothrow) numa_reserved_block[memory_details.numa_reserved_block_count];
-        if (memory_details.numa_reserved_block_table == nullptr)
-        {
-            dprintf(2, ("failed to reserve %zd bytes for numa_reserved_block data", memory_details.numa_reserved_block_count * sizeof(numa_reserved_block)));
-            memory_details.numa_reserved_block_count = 0;
-        }
-    }
-    if (memory_details.numa_reserved_block_table != nullptr)
-    {
-        size_t merged_pinned_size = separated_poh_p ? 0 : pinned_size;
-        for (int heap_no = 0; heap_no < num_heaps; heap_no++)
-        {
-            uint16_t heap_numa_node = heap_no_to_numa_node[heap_no];
-            numa_reserved_block * block = &memory_details.numa_reserved_block_table[heap_numa_node];
-            block->block_size += normal_size + large_size + merged_pinned_size;
-            if (separated_poh_p)
-            {
-                numa_reserved_block* pinned_block = &memory_details.numa_reserved_block_table[numa_node_count + heap_numa_node];
-                pinned_block->block_size += pinned_size;
-            }
-        }
-        bool failure = false;
-        for (int block_index = 0; block_index < memory_details.numa_reserved_block_count; block_index++)
-        {
-            numa_reserved_block * block = &memory_details.numa_reserved_block_table[block_index];
-            if (block->block_size == 0)
-                continue;
-            int numa_node = block_index % numa_node_count;
-            bool pinned_block = block_index >= numa_node_count;
-            block->memory_base = (uint8_t*)virtual_alloc (block->block_size, use_large_pages_p && !pinned_block, (uint16_t)numa_node);
-            if (block->memory_base == nullptr)
-            {
-                dprintf(2, ("failed to reserve %zd bytes for on NUMA node %u", block->block_size, numa_node));
-                failure = true;
-                break;
-            }
-            else
-            {
-                g_gc_lowest_address = min(g_gc_lowest_address, block->memory_base);
-                g_gc_highest_address = max(g_gc_highest_address, block->memory_base + block->block_size);
-            }
-        }
-        if (failure)
-        {
-            for (int block_index = 0; block_index < memory_details.numa_reserved_block_count; block_index++)
-            {
-                numa_reserved_block * block = &memory_details.numa_reserved_block_table[block_index];
-                if (block->memory_base != nullptr)
-                {
-                    virtual_free(block->memory_base, block->block_size);
-                    block->memory_base = nullptr;
-                }
-            }
-            delete [] memory_details.numa_reserved_block_table;
-            memory_details.numa_reserved_block_table = nullptr;
-            memory_details.numa_reserved_block_count = 0;
-        }
-        else
-        {
-            for (uint16_t numa_node = 0; numa_node < numa_node_count; numa_node++)
-            {
-                numa_reserved_block * block = &memory_details.numa_reserved_block_table[numa_node];
-                numa_reserved_block* pinned_block = separated_poh_p ?
-                    &memory_details.numa_reserved_block_table[numa_node_count + numa_node] : nullptr;
-                if (block->block_size == 0)
-                {
-                    assert((pinned_block == nullptr) || (pinned_block->block_size == 0));
-                    continue;
-                }
-                uint8_t* memory_base = block->memory_base;
-                uint8_t* pinned_memory_base = ((pinned_block == nullptr) ? nullptr : pinned_block->memory_base);
-                for (int heap_no = 0; heap_no < num_heaps; heap_no++)
-                {
-                    uint16_t heap_numa_node = heap_no_to_numa_node[heap_no];
-                    if (heap_numa_node != numa_node)
-                    {
-                        continue;
-                    }
-                    memory_details.initial_normal_heap[heap_no].memory_base = memory_base;
-                    memory_base += normal_size;
-                    memory_details.initial_large_heap[heap_no].memory_base = memory_base;
-                    memory_base += large_size;
-                    if (separated_poh_p)
-                    {
-                        memory_details.initial_pinned_heap[heap_no].memory_base = pinned_memory_base;
-                        pinned_memory_base += pinned_size;
-                    }
-                    else
-                    {
-                        memory_details.initial_pinned_heap[heap_no].memory_base = memory_base;
-                        memory_base += pinned_size;
-                    }
-                }
-                assert (memory_base == block->memory_base + block->block_size);
-                assert ((pinned_block == nullptr) || (pinned_memory_base == pinned_block->memory_base + pinned_block->block_size));
-            }
-            memory_details.allocation_pattern = initial_memory_details::EACH_NUMA_NODE;
-            reserve_success = TRUE;
-        }
-    }
-    if (!reserve_success)
-    {
-        size_t temp_pinned_size = (separated_poh_p ? 0 : pinned_size);
-        size_t separate_pinned_size = memory_details.block_count * pinned_size;
-        size_t requestedMemory = memory_details.block_count * (normal_size + large_size + temp_pinned_size);
-        uint8_t* allatonce_block = (uint8_t*)virtual_alloc(requestedMemory, use_large_pages_p);
-        uint8_t* separated_poh_block = nullptr;
-        if (allatonce_block && separated_poh_p)
-        {
-            separated_poh_block = (uint8_t*)virtual_alloc(separate_pinned_size, false);
-            if (!separated_poh_block)
-            {
-                virtual_free(allatonce_block, requestedMemory);
-                allatonce_block = nullptr;
-            }
-        }
-        if (allatonce_block)
-        {
-            if (separated_poh_p)
-            {
-                g_gc_lowest_address = min(allatonce_block, separated_poh_block);
-                g_gc_highest_address = max((allatonce_block + requestedMemory),
-                    (separated_poh_block + separate_pinned_size));
-                memory_details.allocation_pattern = initial_memory_details::ALLATONCE_SEPARATED_POH;
-            }
-            else
-            {
-                g_gc_lowest_address = allatonce_block;
-                g_gc_highest_address = allatonce_block + requestedMemory;
-                memory_details.allocation_pattern = initial_memory_details::ALLATONCE;
-            }
-            for (int i = 0; i < memory_details.block_count; i++)
-            {
-                memory_details.initial_normal_heap[i].memory_base = allatonce_block +
-                    (i * normal_size);
-                memory_details.initial_large_heap[i].memory_base = allatonce_block +
-                    (memory_details.block_count * normal_size) + (i * large_size);
-                if (separated_poh_p)
-                {
-                    memory_details.initial_pinned_heap[i].memory_base = separated_poh_block +
-                        (i * pinned_size);
-                }
-                else
-                {
-                    memory_details.initial_pinned_heap[i].memory_base = allatonce_block +
-                        (memory_details.block_count * (normal_size + large_size)) + (i * pinned_size);
-                }
-            }
-            reserve_success = TRUE;
-        }
-        else
-        {
-            uint8_t* b1 = (uint8_t*)virtual_alloc(memory_details.block_count * normal_size, use_large_pages_p);
-            uint8_t* b2 = (uint8_t*)virtual_alloc(memory_details.block_count * large_size, use_large_pages_p);
-            uint8_t* b3 = (uint8_t*)virtual_alloc(memory_details.block_count * pinned_size, use_large_pages_p && !separated_poh_p);
-            if (b1 && b2 && b3)
-            {
-                memory_details.allocation_pattern = initial_memory_details::EACH_GENERATION;
-                g_gc_lowest_address = min(b1, min(b2, b3));
-                g_gc_highest_address = max(b1 + memory_details.block_count * normal_size,
-                    max(b2 + memory_details.block_count * large_size,
-                        b3 + memory_details.block_count * pinned_size));
-                for (int i = 0; i < memory_details.block_count; i++)
-                {
-                    memory_details.initial_normal_heap[i].memory_base = b1 + (i * normal_size);
-                    memory_details.initial_large_heap[i].memory_base = b2 + (i * large_size);
-                    memory_details.initial_pinned_heap[i].memory_base = b3 + (i * pinned_size);
-                }
-                reserve_success = TRUE;
-            }
-            else
-            {
-                if (b1)
-                    virtual_free(b1, memory_details.block_count * normal_size);
-                if (b2)
-                    virtual_free(b2, memory_details.block_count * large_size);
-                if (b3)
-                    virtual_free(b3, memory_details.block_count * pinned_size);
-            }
-            if ((b2 == NULL) && (memory_details.block_count > 1))
-            {
-                memory_details.allocation_pattern = initial_memory_details::EACH_BLOCK;
-                imemory_data* current_block = memory_details.initial_memory;
-                for (int i = 0; i < (memory_details.block_count * (total_generation_count - ephemeral_generation_count)); i++, current_block++)
-                {
-                    size_t block_size = memory_details.block_size(i);
-                    uint16_t numa_node = NUMA_NODE_UNDEFINED;
-                    if (heap_no_to_numa_node != nullptr)
-                    {
-                        int heap_no = i % memory_details.block_count;
-                        numa_node = heap_no_to_numa_node[heap_no];
-                    }
-                    current_block->memory_base =
-                        (uint8_t*)virtual_alloc(block_size, use_large_pages_p, numa_node);
-                    if (current_block->memory_base == 0)
-                    {
-                        current_block = memory_details.initial_memory;
-                        for (int j = 0; j < i; j++, current_block++) {
-                            if (current_block->memory_base != 0) {
-                                block_size = memory_details.block_size(i);
-                                virtual_free(current_block->memory_base, block_size);
-                            }
-                        }
-                        reserve_success = FALSE;
-                        break;
-                    }
-                    else
-                    {
-                        if (current_block->memory_base < g_gc_lowest_address)
-                            g_gc_lowest_address = current_block->memory_base;
-                        if (((uint8_t*)current_block->memory_base + block_size) > g_gc_highest_address)
-                            g_gc_highest_address = (current_block->memory_base + block_size);
-                    }
-                    reserve_success = TRUE;
-                }
-            }
-        }
-    }
-    if (reserve_success && separated_poh_p)
-    {
-        for (int heap_no = 0; (reserve_success && (heap_no < num_heaps)); heap_no++)
-        {
-            if (!GCToOSInterface::VirtualCommit(memory_details.initial_pinned_heap[heap_no].memory_base, pinned_size))
-            {
-                reserve_success = FALSE;
-            }
-        }
-    }
-    return reserve_success;
-}
-void gc_heap::destroy_initial_memory()
-{
-    if (memory_details.initial_memory != NULL)
-    {
-        switch (memory_details.allocation_pattern)
-        {
-            case initial_memory_details::ALLATONCE:
-                virtual_free (memory_details.initial_memory[0].memory_base,
-                    memory_details.block_count*(memory_details.block_size_normal +
-                    memory_details.block_size_large + memory_details.block_size_pinned));
-                break;
-            case initial_memory_details::ALLATONCE_SEPARATED_POH:
-                virtual_free(memory_details.initial_memory[0].memory_base,
-                    memory_details.block_count * (memory_details.block_size_normal +
-                        memory_details.block_size_large));
-                virtual_free(memory_details.initial_pinned_heap[0].memory_base,
-                    memory_details.block_count * (memory_details.block_size_pinned));
-                break;
-            case initial_memory_details::EACH_GENERATION:
-                virtual_free (memory_details.initial_normal_heap[0].memory_base,
-                    memory_details.block_count*memory_details.block_size_normal);
-                virtual_free (memory_details.initial_large_heap[0].memory_base,
-                    memory_details.block_count*memory_details.block_size_large);
-                virtual_free (memory_details.initial_pinned_heap[0].memory_base,
-                    memory_details.block_count*memory_details.block_size_pinned);
-                break;
-            case initial_memory_details::EACH_BLOCK:
-            {
-                imemory_data* current_block = memory_details.initial_memory;
-                int total_block_count = memory_details.block_count *
-                    (total_generation_count - ephemeral_generation_count);
-                for (int i = 0; i < total_block_count; i++, current_block++)
-                {
-                    size_t block_size = memory_details.block_size (i);
-                    if (current_block->memory_base != NULL)
-                    {
-                        virtual_free (current_block->memory_base, block_size);
-                    }
-                }
-                break;
-            }
-            case initial_memory_details::EACH_NUMA_NODE:
-                for (int block_index = 0; block_index < memory_details.numa_reserved_block_count; block_index++)
-                {
-                    numa_reserved_block * block = &memory_details.numa_reserved_block_table[block_index];
-                    if (block->memory_base != nullptr)
-                    {
-                        virtual_free (block->memory_base, block->block_size);
-                    }
-                }
-                delete [] memory_details.numa_reserved_block_table;
-                break;
-            default:
-                assert (!"unexpected allocation_pattern");
-                break;
-        }
-        delete [] memory_details.initial_memory;
-        memory_details.initial_memory = NULL;
-        memory_details.initial_normal_heap = NULL;
-        memory_details.initial_large_heap = NULL;
-        memory_details.initial_pinned_heap = NULL;
-    }
-}
-heap_segment* make_initial_segment (int gen, int h_number, gc_heap* hp)
-{
-    void* mem = memory_details.get_initial_memory (gen, h_number);
-    size_t size = memory_details.get_initial_size (gen);
-    heap_segment* res = gc_heap::make_heap_segment ((uint8_t*)mem, size, hp, gen);
-    return res;
-}
-void* virtual_alloc (size_t size)
-{
-    return virtual_alloc(size, false);
-}
-void* virtual_alloc (size_t size, bool use_large_pages_p, uint16_t numa_node)
-{
-    size_t requested_size = size;
-    if ((gc_heap::reserved_memory_limit - gc_heap::reserved_memory) < requested_size)
-    {
-        gc_heap::reserved_memory_limit = gc_heap::reserved_memory_limit + requested_size;
-        if ((gc_heap::reserved_memory_limit - gc_heap::reserved_memory) < requested_size)
-        {
-            return 0;
-        }
-    }
-    uint32_t flags = VirtualReserveFlags::None;
-#ifndef FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-    if (virtual_alloc_hardware_write_watch)
-    {
-        flags = VirtualReserveFlags::WriteWatch;
-    }
-#endif // !FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-    void* prgmem = use_large_pages_p ?
-        GCToOSInterface::VirtualReserveAndCommitLargePages(requested_size, numa_node) :
-        GCToOSInterface::VirtualReserve(requested_size, card_size * card_word_width, flags, numa_node);
-    void *aligned_mem = prgmem;
-    if (prgmem)
-    {
-        uint8_t* end_mem = (uint8_t*)prgmem + requested_size;
-        if ((end_mem == 0) || ((size_t)(MAX_PTR - end_mem) <= END_SPACE_AFTER_GC))
-        {
-            GCToOSInterface::VirtualRelease (prgmem, requested_size);
-            dprintf (2, ("Virtual Alloc size %zd returned memory right against 4GB [%zx, %zx[ - discarding",
-                        requested_size, (size_t)prgmem, (size_t)((uint8_t*)prgmem+requested_size)));
-            prgmem = 0;
-            aligned_mem = 0;
-        }
-    }
-    if (prgmem)
-    {
-        gc_heap::reserved_memory += requested_size;
-    }
-    dprintf (2, ("Virtual Alloc size %zd: [%zx, %zx[",
-                 requested_size, (size_t)prgmem, (size_t)((uint8_t*)prgmem+requested_size)));
-    return aligned_mem;
-}
-static size_t get_valid_segment_size (BOOL large_seg=FALSE)
-{
-    size_t seg_size, initial_seg_size;
-    if (!large_seg)
-    {
-        initial_seg_size = INITIAL_ALLOC;
-        seg_size = static_cast<size_t>(GCConfig::GetSegmentSize());
-    }
-    else
-    {
-        initial_seg_size = LHEAP_ALLOC;
-        seg_size = static_cast<size_t>(GCConfig::GetSegmentSize()) / 2;
-    }
-#ifdef MULTIPLE_HEAPS
-#ifdef HOST_64BIT
-    if (!large_seg)
-#endif // HOST_64BIT
-    {
-        if (g_num_processors > 4)
-            initial_seg_size /= 2;
-        if (g_num_processors > 8)
-            initial_seg_size /= 2;
-    }
-#endif //MULTIPLE_HEAPS
-    if (!g_theGCHeap->IsValidSegmentSize(seg_size))
-    {
-        if ((seg_size >> 1) && !(seg_size >> 22))
-            seg_size = 1024*1024*4;
-        else
-            seg_size = initial_seg_size;
-    }
-#ifdef HOST_64BIT
-    seg_size = round_up_power2 (seg_size);
-#else
-    seg_size = round_down_power2 (seg_size);
-#endif // HOST_64BIT
-    return (seg_size);
-}
-#ifndef USE_REGIONS
-void
-gc_heap::compute_new_ephemeral_size()
-{
-    int eph_gen_max = max_generation - 1 - (settings.promotion ? 1 : 0);
-    size_t padding_size = 0;
-    for (int i = 0; i <= eph_gen_max; i++)
-    {
-        dynamic_data* dd = dynamic_data_of (i);
-        total_ephemeral_size += (dd_survived_size (dd) - dd_pinned_survived_size (dd));
-#ifdef RESPECT_LARGE_ALIGNMENT
-        total_ephemeral_size += dd_num_npinned_plugs (dd) * switch_alignment_size (FALSE);
-#endif //RESPECT_LARGE_ALIGNMENT
-#ifdef FEATURE_STRUCTALIGN
-        total_ephemeral_size += dd_num_npinned_plugs (dd) * MAX_STRUCTALIGN;
-#endif //FEATURE_STRUCTALIGN
-#ifdef SHORT_PLUGS
-        padding_size += dd_padding_size (dd);
-#endif //SHORT_PLUGS
-    }
-    total_ephemeral_size += eph_gen_starts_size;
-#ifdef RESPECT_LARGE_ALIGNMENT
-    size_t planned_ephemeral_size = heap_segment_plan_allocated (ephemeral_heap_segment) -
-                                       generation_plan_allocation_start (generation_of (max_generation-1));
-    total_ephemeral_size = min (total_ephemeral_size, planned_ephemeral_size);
-#endif //RESPECT_LARGE_ALIGNMENT
-#ifdef SHORT_PLUGS
-    total_ephemeral_size = Align ((size_t)((double)total_ephemeral_size * short_plugs_pad_ratio) + 1);
-    total_ephemeral_size += Align (DESIRED_PLUG_LENGTH);
-#endif //SHORT_PLUGS
-    dprintf (3, ("total ephemeral size is %zx, padding %zx(%zx)",
-        total_ephemeral_size,
-        padding_size, (total_ephemeral_size - padding_size)));
-}
-heap_segment*
-gc_heap::soh_get_segment_to_expand()
-{
-    size_t size = soh_segment_size;
-    ordered_plug_indices_init = FALSE;
-    use_bestfit = FALSE;
-    compute_new_ephemeral_size();
-    if ((settings.pause_mode != pause_low_latency) &&
-        (settings.pause_mode != pause_no_gc)
-#ifdef BACKGROUND_GC
-        && (!gc_heap::background_running_p())
-#endif //BACKGROUND_GC
-        )
-    {
-        assert (settings.condemned_generation <= max_generation);
-        allocator*  gen_alloc = ((settings.condemned_generation == max_generation) ? nullptr :
-                              generation_allocator (generation_of (max_generation)));
-        dprintf (2, ("(gen%d)soh_get_segment_to_expand", settings.condemned_generation));
-        heap_segment* fseg = heap_segment_rw (generation_start_segment (generation_of (max_generation)));
-        PREFIX_ASSUME(fseg != NULL);
-#ifdef SEG_REUSE_STATS
-        int try_reuse = 0;
-#endif //SEG_REUSE_STATS
-        heap_segment* seg = ephemeral_heap_segment;
-        while ((seg = heap_segment_prev_rw (fseg, seg)) && (seg != fseg))
-        {
-#ifdef SEG_REUSE_STATS
-        try_reuse++;
-#endif //SEG_REUSE_STATS
-            if (can_expand_into_p (seg, size/3, total_ephemeral_size, gen_alloc))
-            {
-                get_gc_data_per_heap()->set_mechanism (gc_heap_expand,
-                    (use_bestfit ? expand_reuse_bestfit : expand_reuse_normal));
-                if (settings.condemned_generation == max_generation)
-                {
-                    if (use_bestfit)
-                    {
-                        build_ordered_free_spaces (seg);
-                        dprintf (GTC_LOG, ("can use best fit"));
-                    }
-#ifdef SEG_REUSE_STATS
-                    dprintf (SEG_REUSE_LOG_0, ("(gen%d)soh_get_segment_to_expand: found seg #%d to reuse",
-                        settings.condemned_generation, try_reuse));
-#endif //SEG_REUSE_STATS
-                    dprintf (GTC_LOG, ("max_gen: Found existing segment to expand into %zx", (size_t)seg));
-                    return seg;
-                }
-                else
-                {
-#ifdef SEG_REUSE_STATS
-                    dprintf (SEG_REUSE_LOG_0, ("(gen%d)soh_get_segment_to_expand: found seg #%d to reuse - returning",
-                        settings.condemned_generation, try_reuse));
-#endif //SEG_REUSE_STATS
-                    dprintf (GTC_LOG, ("max_gen-1: Found existing segment to expand into %zx", (size_t)seg));
-                    if (settings.pause_mode != pause_sustained_low_latency)
-                    {
-                        dprintf (GTC_LOG, ("max_gen-1: SustainedLowLatency is set, acquire a new seg"));
-                        get_gc_data_per_heap()->set_mechanism (gc_heap_expand, expand_next_full_gc);
-                        return 0;
-                    }
-                }
-            }
-        }
-    }
-    heap_segment* result = get_segment (size, gc_oh_num::soh);
-    if(result)
-    {
-#ifdef BACKGROUND_GC
-        if (current_c_gc_state == c_gc_state_planning)
-        {
-            result->flags |= heap_segment_flags_swept;
-        }
-#endif //BACKGROUND_GC
-        FIRE_EVENT(GCCreateSegment_V1, heap_segment_mem(result),
-                                  (size_t)(heap_segment_reserved (result) - heap_segment_mem(result)),
-                                  gc_etw_segment_small_object_heap);
-    }
-    get_gc_data_per_heap()->set_mechanism (gc_heap_expand, (result ? expand_new_seg : expand_no_memory));
-    if (result == 0)
-    {
-        dprintf (2, ("h%d: failed to allocate a new segment!", heap_number));
-    }
-    else
-    {
-#ifdef MULTIPLE_HEAPS
-        heap_segment_heap (result) = this;
-#endif //MULTIPLE_HEAPS
-    }
-    dprintf (GTC_LOG, ("(gen%d)creating new segment %p", settings.condemned_generation, result));
-    return result;
-}
-heap_segment*
-gc_heap::get_segment (size_t size, gc_oh_num oh)
-{
-    assert(oh != gc_oh_num::unknown);
-    BOOL uoh_p = (oh == gc_oh_num::loh) || (oh == gc_oh_num::poh);
-    if (heap_hard_limit)
-        return NULL;
-    heap_segment* result = 0;
-    if (segment_standby_list != 0)
-    {
-        result = segment_standby_list;
-        heap_segment* last = 0;
-        while (result)
-        {
-            size_t hs = (size_t)(heap_segment_reserved (result) - (uint8_t*)result);
-            if ((hs >= size) && ((hs / 2) < size))
-            {
-                dprintf (2, ("Hoarded segment %zx found", (size_t) result));
-                if (last)
-                {
-                    heap_segment_next (last) = heap_segment_next (result);
-                }
-                else
-                {
-                    segment_standby_list = heap_segment_next (result);
-                }
-                break;
-            }
-            else
-            {
-                last = result;
-                result = heap_segment_next (result);
-            }
-        }
-    }
-    if (result)
-    {
-        init_heap_segment (result, __this);
-#ifdef BACKGROUND_GC
-        if (is_bgc_in_progress())
-        {
-            dprintf (GC_TABLE_LOG, ("hoarded seg %p, mark_array is %p", result, mark_array));
-            if (!commit_mark_array_new_seg (__this, result))
-            {
-                dprintf (GC_TABLE_LOG, ("failed to commit mark array for hoarded seg"));
-                if (segment_standby_list != 0)
-                {
-                    heap_segment_next (result) = segment_standby_list;
-                    segment_standby_list = result;
-                }
-                else
-                {
-                    segment_standby_list = result;
-                }
-                result = 0;
-            }
-        }
-#endif //BACKGROUND_GC
-        if (result)
-            seg_mapping_table_add_segment (result, __this);
-    }
-    if (!result)
-    {
-        void* mem = virtual_alloc (size);
-        if (!mem)
-        {
-            fgm_result.set_fgm (fgm_reserve_segment, size, uoh_p);
-            return 0;
-        }
-        result = make_heap_segment ((uint8_t*)mem, size, __this, (oh + max_generation));
-        if (result)
-        {
-            uint8_t* start;
-            uint8_t* end;
-            if (mem < g_gc_lowest_address)
-            {
-                start =  (uint8_t*)mem;
-            }
-            else
-            {
-                start = (uint8_t*)g_gc_lowest_address;
-            }
-            if (((uint8_t*)mem + size) > g_gc_highest_address)
-            {
-                end = (uint8_t*)mem + size;
-            }
-            else
-            {
-                end = (uint8_t*)g_gc_highest_address;
-            }
-            if (gc_heap::grow_brick_card_tables (start, end, size, result, __this, uoh_p) != 0)
-            {
-                size_t flags = 0;
-                if (oh == poh)
-                {
-                    flags = heap_segment_flags_poh;
-                }
-                else if (oh == loh)
-                {
-                    flags = heap_segment_flags_loh;
-                }
-                result->flags |= flags;
-                release_segment (result);
-                return 0;
-            }
-        }
-        else
-        {
-            fgm_result.set_fgm (fgm_commit_segment_beg, SEGMENT_INITIAL_COMMIT, uoh_p);
-            virtual_free (mem, size);
-        }
-        if (result)
-        {
-            seg_mapping_table_add_segment (result, __this);
-        }
-    }
-#ifdef BACKGROUND_GC
-    if (result)
-    {
-        ::record_changed_seg ((uint8_t*)result, heap_segment_reserved (result),
-                            settings.gc_index, current_bgc_state,
-                            seg_added);
-        bgc_verify_mark_array_cleared (result);
-    }
-#endif //BACKGROUND_GC
-    dprintf (GC_TABLE_LOG, ("h%d: new seg: %p-%p (%zd)", heap_number, result, ((uint8_t*)result + size), size));
-    return result;
-}
-void gc_heap::release_segment (heap_segment* sg)
-{
-    ptrdiff_t delta = 0;
-    FIRE_EVENT(GCFreeSegment_V1, heap_segment_mem(sg));
-    size_t reserved_size = (uint8_t*)heap_segment_reserved (sg) - (uint8_t*)sg;
-    reduce_committed_bytes (
-        sg,
-        ((uint8_t*)heap_segment_committed (sg) - (uint8_t*)sg),
-        (int) heap_segment_oh (sg)
-#ifdef MULTIPLE_HEAPS
-        , heap_segment_heap (sg)->heap_number
-#else
-        , -1
-#endif
-        , true
-        );
-    virtual_free (sg, reserved_size, sg);
-}
-BOOL gc_heap::set_ro_segment_in_range (heap_segment* seg)
-{
-    seg->flags |= heap_segment_flags_inrange;
-    ro_segments_in_range = TRUE;
-    return TRUE;
-}
-#endif //!USE_REGIONS
-heap_segment* gc_heap::get_segment_for_uoh (int gen_number, size_t size
-#ifdef MULTIPLE_HEAPS
-                                           , gc_heap* hp
-#endif //MULTIPLE_HEAPS
-                                           )
-{
-#ifndef MULTIPLE_HEAPS
-    gc_heap* hp = 0;
-#endif //MULTIPLE_HEAPS
-#ifdef USE_REGIONS
-    heap_segment* res = hp->get_new_region (gen_number, size);
-#else //USE_REGIONS
-    gc_oh_num oh = gen_to_oh (gen_number);
-    heap_segment* res = hp->get_segment (size, oh);
-#endif //USE_REGIONS
-    if (res != 0)
-    {
-#ifdef MULTIPLE_HEAPS
-        heap_segment_heap (res) = hp;
-#endif //MULTIPLE_HEAPS
-        size_t flags = (gen_number == poh_generation) ?
-            heap_segment_flags_poh :
-            heap_segment_flags_loh;
-#ifdef USE_REGIONS
-        assert ((res->flags & (heap_segment_flags_loh | heap_segment_flags_poh)) == flags);
-#else //USE_REGIONS
-        res->flags |= flags;
-        FIRE_EVENT(GCCreateSegment_V1,
-            heap_segment_mem(res),
-            (size_t)(heap_segment_reserved (res) - heap_segment_mem(res)),
-            (gen_number == poh_generation) ?
-                gc_etw_segment_pinned_object_heap :
-                gc_etw_segment_large_object_heap);
-#ifdef MULTIPLE_HEAPS
-        hp->thread_uoh_segment (gen_number, res);
-#else
-        thread_uoh_segment (gen_number, res);
-#endif //MULTIPLE_HEAPS
-#endif //USE_REGIONS
-        GCToEEInterface::DiagAddNewRegion(
-                            gen_number,
-                            heap_segment_mem (res),
-                            heap_segment_allocated (res),
-                            heap_segment_reserved (res)
-                        );
-    }
-    return res;
-}
-void gc_heap::thread_uoh_segment (int gen_number, heap_segment* new_seg)
-{
-    heap_segment* seg = generation_allocation_segment (generation_of (gen_number));
-    while (heap_segment_next_rw (seg))
-        seg = heap_segment_next_rw (seg);
-    heap_segment_next (seg) = new_seg;
-}
-heap_segment*
-gc_heap::get_uoh_segment (int gen_number, size_t size, BOOL* did_full_compact_gc, enter_msl_status* msl_status)
-{
-    *did_full_compact_gc = FALSE;
-    size_t last_full_compact_gc_count = get_full_compact_gc_count();
-    add_saved_spinlock_info (true, me_release, mt_get_large_seg, msl_entered);
-    leave_spin_lock (&more_space_lock_uoh);
-    enter_spin_lock (&gc_heap::gc_lock);
-    dprintf (SPINLOCK_LOG, ("[%d]Seg: Egc", heap_number));
-    size_t current_full_compact_gc_count = get_full_compact_gc_count();
-    if (current_full_compact_gc_count > last_full_compact_gc_count)
-    {
-        *did_full_compact_gc = TRUE;
-    }
-    if (should_move_heap (&more_space_lock_uoh))
-    {
-        *msl_status = msl_retry_different_heap;
-        leave_spin_lock (&gc_heap::gc_lock);
-        return NULL;
-    }
-    heap_segment* res = get_segment_for_uoh (gen_number, size
-#ifdef MULTIPLE_HEAPS
-                                            , this
-#endif //MULTIPLE_HEAPS
-                                            );
-    dprintf (SPINLOCK_LOG, ("[%d]Seg: A Lgc", heap_number));
-    leave_spin_lock (&gc_heap::gc_lock);
-    *msl_status = enter_spin_lock_msl (&more_space_lock_uoh);
-    if (*msl_status == msl_retry_different_heap)
-        return NULL;
-    add_saved_spinlock_info (true, me_acquire, mt_get_large_seg, *msl_status);
-    return res;
-}
-#ifdef MULTIPLE_HEAPS
-#ifdef HOST_X86
-#ifdef _MSC_VER
-#pragma warning(disable:4035)
-    static ptrdiff_t  get_cycle_count()
-    {
-        __asm   rdtsc
-    }
-#pragma warning(default:4035)
-#elif defined(__GNUC__)
-    static ptrdiff_t  get_cycle_count()
-    {
-        ptrdiff_t cycles;
-        ptrdiff_t cyclesHi;
-        __asm__ __volatile__
-        ("rdtsc":"=a" (cycles), "=d" (cyclesHi));
-        return cycles;
-    }
-#else //_MSC_VER
-#error Unknown compiler
-#endif //_MSC_VER
-#elif defined(TARGET_AMD64)
-#ifdef _MSC_VER
-extern "C" uint64_t __rdtsc();
-#pragma intrinsic(__rdtsc)
-    static ptrdiff_t get_cycle_count()
-    {
-        return (ptrdiff_t)__rdtsc();
-    }
-#elif defined(__GNUC__)
-    static ptrdiff_t get_cycle_count()
-    {
-        ptrdiff_t cycles;
-        ptrdiff_t cyclesHi;
-        __asm__ __volatile__
-        ("rdtsc":"=a" (cycles), "=d" (cyclesHi));
-        return (cyclesHi << 32) | cycles;
-    }
-#else // _MSC_VER
-    extern "C" ptrdiff_t get_cycle_count(void);
-#endif // _MSC_VER
-#elif defined(TARGET_LOONGARCH64)
-    static ptrdiff_t get_cycle_count()
-    {
-        __asm__ volatile ("break 0 \n");
-        return 0;
-    }
-#else
-    static ptrdiff_t get_cycle_count()
-    {
-        return 0;
-    }
-#endif //TARGET_X86
-struct node_heap_count
-{
-    int node_no;
-    int heap_count;
-};
-class heap_select
-{
-    heap_select() {}
-public:
-    static uint8_t* sniff_buffer;
-    static unsigned n_sniff_buffers;
-    static unsigned cur_sniff_index;
-    static uint16_t proc_no_to_heap_no[MAX_SUPPORTED_CPUS];
-    static uint16_t heap_no_to_proc_no[MAX_SUPPORTED_CPUS];
-    static uint16_t heap_no_to_numa_node[MAX_SUPPORTED_CPUS];
-    static uint16_t numa_node_to_heap_map[MAX_SUPPORTED_CPUS+4];
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-    static uint16_t total_numa_nodes;
-    static node_heap_count heaps_on_node[MAX_SUPPORTED_NODES];
-#endif
-    static int access_time(uint8_t *sniff_buffer, int heap_number, unsigned sniff_index, unsigned n_sniff_buffers)
-    {
-        ptrdiff_t start_cycles = get_cycle_count();
-        uint8_t sniff = sniff_buffer[(1 + heap_number*n_sniff_buffers + sniff_index)*HS_CACHE_LINE_SIZE];
-        assert (sniff == 0);
-        ptrdiff_t elapsed_cycles = get_cycle_count() - start_cycles;
-        elapsed_cycles += sniff;
-        return (int) elapsed_cycles;
-    }
-public:
-    static BOOL init(int n_heaps)
-    {
-        assert (sniff_buffer == NULL && n_sniff_buffers == 0);
-        if (!GCToOSInterface::CanGetCurrentProcessorNumber())
-        {
-            n_sniff_buffers = n_heaps*2+1;
-            size_t n_cache_lines = 1 + n_heaps * n_sniff_buffers + 1;
-            size_t sniff_buf_size = n_cache_lines * HS_CACHE_LINE_SIZE;
-            if (sniff_buf_size / HS_CACHE_LINE_SIZE != n_cache_lines) // check for overlow
-            {
-                return FALSE;
-            }
-            sniff_buffer = new (nothrow) uint8_t[sniff_buf_size];
-            if (sniff_buffer == 0)
-                return FALSE;
-            memset(sniff_buffer, 0, sniff_buf_size*sizeof(uint8_t));
-        }
-        bool do_numa = GCToOSInterface::CanEnableGCNumaAware();
-        uint16_t proc_no[MAX_SUPPORTED_CPUS];
-        uint16_t node_no[MAX_SUPPORTED_CPUS];
-        uint16_t max_node_no = 0;
-        uint16_t heap_num;
-        for (heap_num = 0; heap_num < n_heaps; heap_num++)
-        {
-            if (!GCToOSInterface::GetProcessorForHeap (heap_num, &proc_no[heap_num], &node_no[heap_num]))
-                break;
-            assert(proc_no[heap_num] < MAX_SUPPORTED_CPUS);
-            if (!do_numa || node_no[heap_num] == NUMA_NODE_UNDEFINED)
-                node_no[heap_num] = 0;
-            max_node_no = max(max_node_no, node_no[heap_num]);
-        }
-        int cur_heap_no = 0;
-        for (uint16_t cur_node_no = 0; cur_node_no <= max_node_no; cur_node_no++)
-        {
-            for (int i = 0; i < heap_num; i++)
-            {
-                if (node_no[i] != cur_node_no)
-                    continue;
-                heap_no_to_proc_no[cur_heap_no] = proc_no[i];
-                heap_no_to_numa_node[cur_heap_no] = cur_node_no;
-                cur_heap_no++;
-            }
-        }
-        return TRUE;
-    }
-    static void init_cpu_mapping(int heap_number)
-    {
-        if (GCToOSInterface::CanGetCurrentProcessorNumber())
-        {
-            uint32_t proc_no = GCToOSInterface::GetCurrentProcessorNumber();
-            proc_no_to_heap_no[proc_no % MAX_SUPPORTED_CPUS] = (uint16_t)heap_number;
-        }
-    }
-    static void mark_heap(int heap_number)
-    {
-        if (GCToOSInterface::CanGetCurrentProcessorNumber())
-            return;
-        for (unsigned sniff_index = 0; sniff_index < n_sniff_buffers; sniff_index++)
-            sniff_buffer[(1 + heap_number*n_sniff_buffers + sniff_index)*HS_CACHE_LINE_SIZE] &= 1;
-    }
-    static int select_heap(alloc_context* acontext)
-    {
-#ifndef TRACE_GC
-        UNREFERENCED_PARAMETER(acontext); // only referenced by dprintf
-#endif //TRACE_GC
-        if (GCToOSInterface::CanGetCurrentProcessorNumber())
-        {
-            uint32_t proc_no = GCToOSInterface::GetCurrentProcessorNumber();
-            int adjusted_heap = proc_no_to_heap_no[proc_no % MAX_SUPPORTED_CPUS];
-            if (adjusted_heap >= gc_heap::n_heaps)
-            {
-                adjusted_heap %= gc_heap::n_heaps;
-            }
-            return adjusted_heap;
-        }
-        unsigned sniff_index = Interlocked::Increment(&cur_sniff_index);
-        sniff_index %= n_sniff_buffers;
-        int best_heap = 0;
-        int best_access_time = 1000*1000*1000;
-        int second_best_access_time = best_access_time;
-        uint8_t *l_sniff_buffer = sniff_buffer;
-        unsigned l_n_sniff_buffers = n_sniff_buffers;
-        for (int heap_number = 0; heap_number < gc_heap::n_heaps; heap_number++)
-        {
-            int this_access_time = access_time(l_sniff_buffer, heap_number, sniff_index, l_n_sniff_buffers);
-            if (this_access_time < best_access_time)
-            {
-                second_best_access_time = best_access_time;
-                best_access_time = this_access_time;
-                best_heap = heap_number;
-            }
-            else if (this_access_time < second_best_access_time)
-            {
-                second_best_access_time = this_access_time;
-            }
-        }
-        if (best_access_time*2 < second_best_access_time)
-        {
-            sniff_buffer[(1 + best_heap*n_sniff_buffers + sniff_index)*HS_CACHE_LINE_SIZE] &= 1;
-            dprintf (3, ("select_heap yields crisp %d for context %p\n", best_heap, (void *)acontext));
-        }
-        else
-        {
-            dprintf (3, ("select_heap yields vague %d for context %p\n", best_heap, (void *)acontext ));
-        }
-        return best_heap;
-    }
-    static bool can_find_heap_fast()
-    {
-        return GCToOSInterface::CanGetCurrentProcessorNumber();
-    }
-    static uint16_t find_proc_no_from_heap_no(int heap_number)
-    {
-        return heap_no_to_proc_no[heap_number];
-    }
-    static uint16_t find_numa_node_from_heap_no(int heap_number)
-    {
-        return heap_no_to_numa_node[heap_number];
-    }
-    static void init_numa_node_to_heap_map(int nheaps)
-    {
-        numa_node_to_heap_map[heap_no_to_numa_node[0]] = 0;
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-        total_numa_nodes = 0;
-        memset (heaps_on_node, 0, sizeof (heaps_on_node));
-        heaps_on_node[0].node_no = heap_no_to_numa_node[0];
-        heaps_on_node[0].heap_count = 1;
-#endif //HEAP_BALANCE_INSTRUMENTATION
-        for (int i=1; i < nheaps; i++)
-        {
-            if (heap_no_to_numa_node[i] != heap_no_to_numa_node[i-1])
-            {
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-                total_numa_nodes++;
-                heaps_on_node[total_numa_nodes].node_no = heap_no_to_numa_node[i];
-#endif
-                numa_node_to_heap_map[heap_no_to_numa_node[i-1] + 1] =
-                numa_node_to_heap_map[heap_no_to_numa_node[i]] = (uint16_t)i;
-            }
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-            (heaps_on_node[total_numa_nodes].heap_count)++;
-#endif
-        }
-        numa_node_to_heap_map[heap_no_to_numa_node[nheaps-1] + 1] = (uint16_t)nheaps; //mark the end with nheaps
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-        total_numa_nodes++;
-#endif
-    }
-    static bool get_info_proc (int index, uint16_t* proc_no, uint16_t* node_no, int* start_heap, int* end_heap)
-    {
-        if (!GCToOSInterface::GetProcessorForHeap ((uint16_t)index, proc_no, node_no))
-            return false;
-        if (*node_no == NUMA_NODE_UNDEFINED)
-            *node_no = 0;
-        *start_heap = (int)numa_node_to_heap_map[*node_no];
-        *end_heap = (int)(numa_node_to_heap_map[*node_no + 1]);
-        return true;
-    }
-    static void distribute_other_procs (bool distribute_all_p)
-    {
-        if (affinity_config_specified_p)
-            return;
-        if (distribute_all_p)
-        {
-            uint16_t current_heap_no_on_node[MAX_SUPPORTED_CPUS];
-            memset (current_heap_no_on_node, 0, sizeof (current_heap_no_on_node));
-            uint16_t current_heap_no = 0;
-            uint16_t proc_no = 0;
-            uint16_t node_no = 0;
-            for (int i = gc_heap::n_heaps; i < (int)g_num_active_processors; i++)
-            {
-                int start_heap, end_heap;
-                if (!get_info_proc (i, &proc_no, &node_no, &start_heap, &end_heap))
-                    break;
-                if ((end_heap - start_heap) > 0)
-                {
-                    proc_no_to_heap_no[proc_no] = (current_heap_no_on_node[node_no] % (uint16_t)(end_heap - start_heap)) + (uint16_t)start_heap;
-                    (current_heap_no_on_node[node_no])++;
-                }
-                else
-                {
-                    proc_no_to_heap_no[proc_no] = current_heap_no % gc_heap::n_heaps;
-                    (current_heap_no)++;
-                }
-            }
-        }
-        else
-        {
-            uint16_t proc_no = 0;
-            uint16_t node_no = 0;
-            int current_node_no = -1;
-            int current_heap_on_node = -1;
-            for (int i = gc_heap::n_heaps; i < (int)g_num_active_processors; i++)
-            {
-                int start_heap, end_heap;
-                if (!get_info_proc (i, &proc_no, &node_no, &start_heap, &end_heap))
-                    break;
-                if ((end_heap - start_heap) > 0)
-                {
-                    if (node_no == current_node_no)
-                    {
-                        if (current_heap_on_node >= end_heap)
-                        {
-                            continue;
-                        }
-                    }
-                    else
-                    {
-                        current_node_no = node_no;
-                        current_heap_on_node = start_heap;
-                    }
-                    proc_no_to_heap_no[proc_no] = (uint16_t)current_heap_on_node;
-                    current_heap_on_node++;
-                }
-            }
-        }
-    }
-    static void get_heap_range_for_heap(int hn, int* start, int* end)
-    {
-        uint16_t numa_node = heap_no_to_numa_node[hn];
-        *start = (int)numa_node_to_heap_map[numa_node];
-        *end   = (int)(numa_node_to_heap_map[numa_node+1]);
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-        dprintf(HEAP_BALANCE_TEMP_LOG, ("TEMPget_heap_range: %d is in numa node %d, start = %d, end = %d", hn, numa_node, *start, *end));
-#endif //HEAP_BALANCE_INSTRUMENTATION
-    }
-};
-uint8_t* heap_select::sniff_buffer;
-unsigned heap_select::n_sniff_buffers;
-unsigned heap_select::cur_sniff_index;
-uint16_t heap_select::proc_no_to_heap_no[MAX_SUPPORTED_CPUS];
-uint16_t heap_select::heap_no_to_proc_no[MAX_SUPPORTED_CPUS];
-uint16_t heap_select::heap_no_to_numa_node[MAX_SUPPORTED_CPUS];
-uint16_t heap_select::numa_node_to_heap_map[MAX_SUPPORTED_CPUS+4];
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-uint16_t  heap_select::total_numa_nodes;
-node_heap_count heap_select::heaps_on_node[MAX_SUPPORTED_NODES];
-#endif
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-struct heap_balance_info
-{
-    uint64_t timestamp;
-    int tid;
-    int alloc_heap;
-    int ideal_proc_no;
-};
-#define default_max_hb_heap_balance_info 4096
-struct heap_balance_info_proc
-{
-    int count;
-    int index;
-    heap_balance_info hb_info[default_max_hb_heap_balance_info];
-};
-struct heap_balance_info_numa
-{
-    heap_balance_info_proc* hb_info_procs;
-};
-uint64_t start_raw_ts = 0;
-bool cpu_group_enabled_p = false;
-uint32_t procs_per_numa_node = 0;
-uint16_t total_numa_nodes_on_machine = 0;
-uint32_t procs_per_cpu_group = 0;
-uint16_t total_cpu_groups_on_machine = 0;
-heap_balance_info_numa* hb_info_numa_nodes = NULL;
-int get_proc_index_numa (int proc_no, int* numa_no)
-{
-    if (total_numa_nodes_on_machine == 1)
-    {
-        *numa_no = 0;
-        return proc_no;
-    }
-    else
-    {
-        if (cpu_group_enabled_p)
-        {
-            *numa_no = proc_no >> 6;
-            return (proc_no % 64);
-        }
-        else
-        {
-            *numa_no = proc_no / procs_per_numa_node;
-            return (proc_no % procs_per_numa_node);
-        }
-    }
-}
-void add_to_hb_numa (
-    int proc_no,
-    int ideal_proc_no,
-    int alloc_heap,
-    bool multiple_procs_p,
-    bool alloc_count_p,
-    bool set_ideal_p)
-{
-    int tid = (int)GCToOSInterface::GetCurrentThreadIdForLogging ();
-    uint64_t timestamp = RawGetHighPrecisionTimeStamp ();
-    int saved_proc_no = proc_no;
-    int numa_no = -1;
-    proc_no = get_proc_index_numa (proc_no, &numa_no);
-    heap_balance_info_numa* hb_info_numa_node = &hb_info_numa_nodes[numa_no];
-    heap_balance_info_proc* hb_info_proc = &(hb_info_numa_node->hb_info_procs[proc_no]);
-    int index = hb_info_proc->index;
-    int count = hb_info_proc->count;
-    if (index == count)
-    {
-        dprintf (HEAP_BALANCE_LOG, ("too much info between GCs, already logged %d entries", index));
-        GCToOSInterface::DebugBreak ();
-    }
-    heap_balance_info* hb_info = &(hb_info_proc->hb_info[index]);
-    dprintf (HEAP_BALANCE_TEMP_LOG, ("TEMP[p%3d->%3d(i:%3d), N%d] #%4d: %zd, tid %d, ah: %d, m: %d, p: %d, i: %d",
-        saved_proc_no, proc_no, ideal_proc_no, numa_no, index,
-        (timestamp - start_raw_ts) / 1000, tid, alloc_heap, (int)multiple_procs_p, (int)(!alloc_count_p), (int)set_ideal_p));
-    if (multiple_procs_p)
-    {
-        tid |= (1 << (sizeof (tid) * 8 - 1));
-    }
-    if (!alloc_count_p)
-    {
-        alloc_heap |= (1 << (sizeof (alloc_heap) * 8 - 1));
-    }
-    if (set_ideal_p)
-    {
-        alloc_heap |= (1 << (sizeof (alloc_heap) * 8 - 2));
-    }
-    hb_info->timestamp = timestamp;
-    hb_info->tid = tid;
-    hb_info->alloc_heap = alloc_heap;
-    hb_info->ideal_proc_no = ideal_proc_no;
-    (hb_info_proc->index)++;
-}
-const int hb_log_buffer_size = 4096;
-static char hb_log_buffer[hb_log_buffer_size];
-int last_hb_recorded_gc_index = -1;
-#endif //HEAP_BALANCE_INSTRUMENTATION
-void gc_heap::hb_log_balance_activities()
-{
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-    char* log_buffer = hb_log_buffer;
-    uint64_t now = GetHighPrecisionTimeStamp();
-    size_t time_since_last_gc_ms = (size_t)((now - last_gc_end_time_us) / 1000);
-    dprintf (HEAP_BALANCE_TEMP_LOG, ("TEMP%zd - %zd = %zd", now, last_gc_end_time_ms, time_since_last_gc_ms));
-    uint64_t min_timestamp = 0xffffffffffffffff;
-    uint64_t max_timestamp = 0;
-    for (int numa_node_index = 0; numa_node_index < total_numa_nodes_on_machine; numa_node_index++)
-    {
-        heap_balance_info_proc* hb_info_procs = hb_info_numa_nodes[numa_node_index].hb_info_procs;
-        for (int proc_index = 0; proc_index < (int)procs_per_numa_node; proc_index++)
-        {
-            heap_balance_info_proc* hb_info_proc = &hb_info_procs[proc_index];
-            int total_entries_on_proc = hb_info_proc->index;
-            if (total_entries_on_proc > 0)
-            {
-                min_timestamp = min (min_timestamp, hb_info_proc->hb_info[0].timestamp);
-                max_timestamp = max (max_timestamp, hb_info_proc->hb_info[total_entries_on_proc - 1].timestamp);
-            }
-        }
-    }
-    dprintf (HEAP_BALANCE_LOG, ("[GCA#%zd %zd-%zd-%zd]",
-        settings.gc_index, time_since_last_gc_ms, (min_timestamp - start_raw_ts), (max_timestamp - start_raw_ts)));
-    if (last_hb_recorded_gc_index == (int)settings.gc_index)
-    {
-        GCToOSInterface::DebugBreak ();
-    }
-    last_hb_recorded_gc_index = (int)settings.gc_index;
-    for (int numa_node_index = 0; numa_node_index < total_numa_nodes_on_machine; numa_node_index++)
-    {
-        heap_balance_info_proc* hb_info_procs = hb_info_numa_nodes[numa_node_index].hb_info_procs;
-        for (int proc_index = 0; proc_index < (int)procs_per_numa_node; proc_index++)
-        {
-            heap_balance_info_proc* hb_info_proc = &hb_info_procs[proc_index];
-            int total_entries_on_proc = hb_info_proc->index;
-            if (total_entries_on_proc > 0)
-            {
-                int total_exec_time_ms =
-                    (int)((double)(hb_info_proc->hb_info[total_entries_on_proc - 1].timestamp -
-                                   hb_info_proc->hb_info[0].timestamp) * qpf_ms);
-                dprintf (HEAP_BALANCE_LOG, ("[p%d]-%d-%dms",
-                    (proc_index + numa_node_index * procs_per_numa_node),
-                    total_entries_on_proc, total_exec_time_ms));
-            }
-            for (int i = 0; i < hb_info_proc->index; i++)
-            {
-                heap_balance_info* hb_info = &hb_info_proc->hb_info[i];
-                bool multiple_procs_p = false;
-                bool alloc_count_p = true;
-                bool set_ideal_p = false;
-                int tid = hb_info->tid;
-                int alloc_heap = hb_info->alloc_heap;
-                if (tid & (1 << (sizeof (tid) * 8 - 1)))
-                {
-                    multiple_procs_p = true;
-                    tid &= ~(1 << (sizeof (tid) * 8 - 1));
-                }
-                if (alloc_heap & (1 << (sizeof (alloc_heap) * 8 - 1)))
-                {
-                    alloc_count_p = false;
-                    alloc_heap &= ~(1 << (sizeof (alloc_heap) * 8 - 1));
-                }
-                if (alloc_heap & (1 << (sizeof (alloc_heap) * 8 - 2)))
-                {
-                    set_ideal_p = true;
-                    alloc_heap &= ~(1 << (sizeof (alloc_heap) * 8 - 2));
-                }
-                int ideal_proc_no = hb_info->ideal_proc_no;
-                int ideal_node_no = -1;
-                ideal_proc_no = get_proc_index_numa (ideal_proc_no, &ideal_node_no);
-                ideal_proc_no = ideal_proc_no + ideal_node_no * procs_per_numa_node;
-                dprintf (HEAP_BALANCE_LOG, ("%zd,%d,%d,%d%s%s%s",
-                    (hb_info->timestamp - start_raw_ts),
-                    tid,
-                    ideal_proc_no,
-                    (int)alloc_heap,
-                    (multiple_procs_p ? "|m" : ""), (!alloc_count_p ? "|p" : ""), (set_ideal_p ? "|i" : "")));
-            }
-        }
-    }
-    for (int numa_node_index = 0; numa_node_index < total_numa_nodes_on_machine; numa_node_index++)
-    {
-        heap_balance_info_proc* hb_info_procs = hb_info_numa_nodes[numa_node_index].hb_info_procs;
-        for (int proc_index = 0; proc_index < (int)procs_per_numa_node; proc_index++)
-        {
-            heap_balance_info_proc* hb_info_proc = &hb_info_procs[proc_index];
-            hb_info_proc->index = 0;
-        }
-    }
-#endif //HEAP_BALANCE_INSTRUMENTATION
-}
-void gc_heap::hb_log_new_allocation()
-{
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-    char* log_buffer = hb_log_buffer;
-    int desired_alloc_mb = (int)(dd_desired_allocation (g_heaps[0]->dynamic_data_of (0)) / 1024 / 1024);
-    int buffer_pos = sprintf_s (hb_log_buffer, hb_log_buffer_size, "[GC_alloc_mb]\n");
-    for (int numa_node_index = 0; numa_node_index < heap_select::total_numa_nodes; numa_node_index++)
-    {
-        int node_allocated_mb = 0;
-        buffer_pos += sprintf_s (hb_log_buffer + buffer_pos, hb_log_buffer_size - buffer_pos, "[N#%3d]",
-            desired_alloc_mb);
-        int heaps_on_node = heap_select::heaps_on_node[numa_node_index].heap_count;
-        for (int heap_index = 0; heap_index < heaps_on_node; heap_index++)
-        {
-            int actual_heap_index = heap_index + numa_node_index * heaps_on_node;
-            gc_heap* hp = g_heaps[actual_heap_index];
-            dynamic_data* dd0 = hp->dynamic_data_of (0);
-            int allocated_mb = (int)((dd_desired_allocation (dd0) - dd_new_allocation (dd0)) / 1024 / 1024);
-            node_allocated_mb += allocated_mb;
-            buffer_pos += sprintf_s (hb_log_buffer + buffer_pos, hb_log_buffer_size - buffer_pos, "%d,",
-                allocated_mb);
-        }
-        dprintf (HEAP_BALANCE_TEMP_LOG, ("TEMPN#%d a %dmb(%dmb)",
-            numa_node_index, node_allocated_mb, desired_alloc_mb));
-        buffer_pos += sprintf_s (hb_log_buffer + buffer_pos, hb_log_buffer_size - buffer_pos, "\n");
-    }
-    dprintf (HEAP_BALANCE_LOG, ("%s", hb_log_buffer));
-#endif //HEAP_BALANCE_INSTRUMENTATION
-}
-BOOL gc_heap::create_thread_support (int number_of_heaps)
-{
-    BOOL ret = FALSE;
-    if (!gc_start_event.CreateOSManualEventNoThrow (FALSE))
-    {
-        goto cleanup;
-    }
-    if (!ee_suspend_event.CreateOSAutoEventNoThrow (FALSE))
-    {
-        goto cleanup;
-    }
-    if (!gc_t_join.init (number_of_heaps, join_flavor_server_gc))
-    {
-        goto cleanup;
-    }
-    ret = TRUE;
-cleanup:
-    if (!ret)
-    {
-        destroy_thread_support();
-    }
-    return ret;
-}
-void gc_heap::destroy_thread_support ()
-{
-    if (ee_suspend_event.IsValid())
-    {
-        ee_suspend_event.CloseEvent();
-    }
-    if (gc_start_event.IsValid())
-    {
-        gc_start_event.CloseEvent();
-    }
-}
-void set_thread_affinity_for_heap (int heap_number, uint16_t proc_no)
-{
-    if (!GCToOSInterface::SetThreadAffinity (proc_no))
-    {
-        dprintf (1, ("Failed to set thread affinity for GC thread %d on proc #%d", heap_number, proc_no));
-    }
-}
-bool gc_heap::create_gc_thread ()
-{
-    dprintf (3, ("Creating gc thread\n"));
-    return GCToEEInterface::CreateThread(gc_thread_stub, this, false, ".NET Server GC");
-}
-#ifdef _MSC_VER
-#pragma warning(disable:4715) //IA64 xcompiler recognizes that without the 'break;' the while(1) will never end and therefore not return a value for that code path
-#endif //_MSC_VER
-void gc_heap::gc_thread_function ()
-{
-    assert (gc_done_event.IsValid());
-    assert (gc_start_event.IsValid());
-    dprintf (3, ("gc thread started"));
-    heap_select::init_cpu_mapping(heap_number);
-    while (1)
-    {
-        assert ((n_heaps <= heap_number) || !gc_t_join.joined());
-        if (heap_number == 0)
-        {
-            bool wait_on_time_out_p = gradual_decommit_in_progress_p;
-            uint32_t wait_time = DECOMMIT_TIME_STEP_MILLISECONDS;
-#ifdef DYNAMIC_HEAP_COUNT
-            if (
-#ifdef BACKGROUND_GC
-                !gc_heap::background_running_p () &&
-#endif
-                dynamic_heap_count_data.should_change_heap_count)
-            {
-                assert (dynamic_adaptation_mode == dynamic_adaptation_to_application_sizes);
-                wait_on_time_out_p = true;
-                dynamic_heap_count_data_t::sample& sample = dynamic_heap_count_data.samples[dynamic_heap_count_data.sample_index];
-                wait_time = min (wait_time, (uint32_t)(sample.elapsed_between_gcs / 1000 / 3));
-                wait_time = max (wait_time, 1u);
-                dprintf (6666, ("gc#0 thread waiting for %d ms (betwen GCs %I64d)", wait_time, sample.elapsed_between_gcs));
-            }
-#endif //DYNAMIC_HEAP_COUNT
-            uint32_t wait_result = gc_heap::ee_suspend_event.Wait(wait_on_time_out_p ? wait_time : INFINITE, FALSE);
-#ifdef DYNAMIC_HEAP_COUNT
-            dprintf (9999, ("waiting for ee done res %d (timeout %d, %I64d ms since last suspend end)(should_change_heap_count is %d) (gradual_decommit_in_progress_p %d)",
-                wait_result, wait_time, ((GetHighPrecisionTimeStamp() - last_suspended_end_time) / 1000),
-                dynamic_heap_count_data.should_change_heap_count, gradual_decommit_in_progress_p));
-#endif //DYNAMIC_HEAP_COUNT
-            if (wait_result == WAIT_TIMEOUT)
-            {
-#ifdef DYNAMIC_HEAP_COUNT
-                if (dynamic_heap_count_data.should_change_heap_count)
-                {
-#ifdef BACKGROUND_GC
-                    if (!gc_heap::background_running_p ())
-#endif //BACKGROUND_GC
-                    {
-                        dprintf (6666, ("changing heap count due to timeout"));
-                        add_to_hc_history (hc_record_before_check_timeout);
-                        check_heap_count();
-                    }
-                }
-#endif //DYNAMIC_HEAP_COUNT
-                if (gradual_decommit_in_progress_p)
-                {
-#ifdef COMMITTED_BYTES_SHADOW
-                    decommit_lock.Enter ();
-#endif //COMMITTED_BYTES_SHADOW
-                    gradual_decommit_in_progress_p = decommit_step (DECOMMIT_TIME_STEP_MILLISECONDS);
-#ifdef COMMITTED_BYTES_SHADOW
-                    decommit_lock.Leave ();
-#endif //COMMITTED_BYTES_SHADOW
-                }
-                continue;
-            }
-#ifdef DYNAMIC_HEAP_COUNT
-            if (dynamic_heap_count_data.should_change_heap_count)
-            {
-#ifdef BACKGROUND_GC
-                if (!gc_heap::background_running_p ())
-#endif //BACKGROUND_GC
-                {
-                    dprintf (6666, ("changing heap count at a GC start"));
-                    add_to_hc_history (hc_record_before_check_gc_start);
-                    check_heap_count ();
-                }
-            }
-            if ((gc_heap::dynamic_adaptation_mode == dynamic_adaptation_to_application_sizes) &&
-                (n_heaps != dynamic_heap_count_data.last_n_heaps))
-            {
-                int spin_count = 1024;
-                int idle_thread_count = n_max_heaps - n_heaps;
-                dprintf (9999, ("heap count changed %d->%d, idle should be %d and is %d", dynamic_heap_count_data.last_n_heaps, n_heaps,
-                    idle_thread_count, VolatileLoadWithoutBarrier (&dynamic_heap_count_data.idle_thread_count)));
-                if (idle_thread_count != dynamic_heap_count_data.idle_thread_count)
-                {
-                    spin_and_wait (spin_count, (idle_thread_count == dynamic_heap_count_data.idle_thread_count));
-                    dprintf (9999, ("heap count changed %d->%d, now idle is %d", dynamic_heap_count_data.last_n_heaps, n_heaps,
-                        VolatileLoadWithoutBarrier (&dynamic_heap_count_data.idle_thread_count)));
-                }
-                add_to_hc_history (hc_record_set_last_heaps);
-                dynamic_heap_count_data.last_n_heaps = n_heaps;
-            }
-#endif //DYNAMIC_HEAP_COUNT
-            suspended_start_time = GetHighPrecisionTimeStamp();
-            BEGIN_TIMING(suspend_ee_during_log);
-            dprintf (9999, ("h0 suspending EE in GC!"));
-            GCToEEInterface::SuspendEE(SUSPEND_FOR_GC);
-            dprintf (9999, ("h0 suspended EE in GC!"));
-            END_TIMING(suspend_ee_during_log);
-            proceed_with_gc_p = TRUE;
-            if (!should_proceed_with_gc())
-            {
-                update_collection_counts_for_no_gc();
-                proceed_with_gc_p = FALSE;
-            }
-            else
-            {
-                settings.init_mechanisms();
-#ifdef DYNAMIC_HEAP_COUNT
-                if (gc_heap::dynamic_adaptation_mode == dynamic_adaptation_to_application_sizes)
-                {
-                    assert (dynamic_heap_count_data.new_n_heaps == n_heaps);
-                }
-#endif //DYNAMIC_HEAP_COUNT
-                dprintf (9999, ("GC thread %d setting_gc_start_in_gc(h%d)", heap_number, n_heaps));
-                gc_start_event.Set();
-            }
-            dprintf (3, (ThreadStressLog::gcServerThread0StartMsg(), heap_number));
-        }
-        else
-        {
-            dprintf (9999, ("GC thread %d waiting_for_gc_start(%d)(gc%Id)", heap_number, n_heaps, VolatileLoadWithoutBarrier(&settings.gc_index)));
-            gc_start_event.Wait(INFINITE, FALSE);
-#ifdef DYNAMIC_HEAP_COUNT
-            dprintf (9999, ("GC thread %d waiting_done_gc_start(%d-%d)(i: %d)(gc%Id)",
-                heap_number, n_heaps, dynamic_heap_count_data.new_n_heaps, dynamic_heap_count_data.init_only_p, VolatileLoadWithoutBarrier (&settings.gc_index)));
-            if ((gc_heap::dynamic_adaptation_mode == dynamic_adaptation_to_application_sizes) &&
-                (dynamic_heap_count_data.new_n_heaps != n_heaps))
-            {
-                int old_n_heaps = n_heaps;
-                int new_n_heaps = dynamic_heap_count_data.new_n_heaps;
-                int num_threads_to_wake = max (new_n_heaps, old_n_heaps);
-                if (heap_number < num_threads_to_wake)
-                {
-                    dprintf (9999, ("h%d < %d, calling change", heap_number, num_threads_to_wake));
-                    change_heap_count (dynamic_heap_count_data.new_n_heaps);
-                    if (new_n_heaps < old_n_heaps)
-                    {
-                        dprintf (9999, ("h%d after change", heap_number));
-                        if (heap_number < new_n_heaps)
-                        {
-                            add_to_hc_history (hc_record_still_active);
-                            dprintf (9999, ("h%d < %d participating (dec)", heap_number, new_n_heaps));
-                        }
-                        else
-                        {
-                            Interlocked::Increment (&dynamic_heap_count_data.idle_thread_count);
-                            add_to_hc_history (hc_record_became_inactive);
-                            dprintf (9999, ("GC thread %d wait_on_idle(%d < %d)(gc%Id), total idle %d", heap_number, old_n_heaps, new_n_heaps,
-                                VolatileLoadWithoutBarrier (&settings.gc_index), VolatileLoadWithoutBarrier (&dynamic_heap_count_data.idle_thread_count)));
-                            gc_idle_thread_event.Wait (INFINITE, FALSE);
-                            dprintf (9999, ("GC thread %d waking_from_idle(%d)(gc%Id) after doing change", heap_number, n_heaps, VolatileLoadWithoutBarrier (&settings.gc_index)));
-                        }
-                    }
-                    else
-                    {
-                        add_to_hc_history ((heap_number < old_n_heaps) ? hc_record_still_active : hc_record_became_active);
-                        dprintf (9999, ("h%d < %d participating (inc)", heap_number, new_n_heaps));
-                    }
-                }
-                else
-                {
-                    Interlocked::Increment (&dynamic_heap_count_data.idle_thread_count);
-                    add_to_hc_history (hc_record_inactive_waiting);
-                    dprintf (9999, ("GC thread %d wait_on_idle(< max %d)(gc%Id), total  idle %d", heap_number, num_threads_to_wake,
-                        VolatileLoadWithoutBarrier (&settings.gc_index), VolatileLoadWithoutBarrier (&dynamic_heap_count_data.idle_thread_count)));
-                    gc_idle_thread_event.Wait (INFINITE, FALSE);
-                    dprintf (9999, ("GC thread %d waking_from_idle(%d)(gc%Id)", heap_number, n_heaps, VolatileLoadWithoutBarrier (&settings.gc_index)));
-                }
-                continue;
-            }
-#endif //DYNAMIC_HEAP_COUNT
-            dprintf (3, (ThreadStressLog::gcServerThreadNStartMsg(), heap_number));
-        }
-        assert ((heap_number == 0) || proceed_with_gc_p);
-        if (proceed_with_gc_p)
-        {
-            garbage_collect (GCHeap::GcCondemnedGeneration);
-            if (pm_trigger_full_gc)
-            {
-                garbage_collect_pm_full_gc();
-            }
-        }
-        if (heap_number == 0)
-        {
-            if (proceed_with_gc_p && (!settings.concurrent))
-            {
-                do_post_gc();
-            }
-#ifdef BACKGROUND_GC
-            recover_bgc_settings();
-#endif //BACKGROUND_GC
-#ifdef MULTIPLE_HEAPS
-#ifdef STRESS_DYNAMIC_HEAP_COUNT
-            dynamic_heap_count_data.lowest_heap_with_msl_uoh = -1;
-#endif //STRESS_DYNAMIC_HEAP_COUNT
-            for (int i = 0; i < gc_heap::n_heaps; i++)
-            {
-                gc_heap* hp = gc_heap::g_heaps[i];
-                leave_spin_lock(&hp->more_space_lock_soh);
-#ifdef STRESS_DYNAMIC_HEAP_COUNT
-                if ((dynamic_heap_count_data.lowest_heap_with_msl_uoh == -1) && (hp->uoh_msl_before_gc_p))
-                {
-                    dynamic_heap_count_data.lowest_heap_with_msl_uoh = i;
-                }
-                if (hp->uoh_msl_before_gc_p)
-                {
-                    dprintf (5555, ("h%d uoh msl was taken before GC", i));
-                    hp->uoh_msl_before_gc_p = false;
-                }
-#endif //STRESS_DYNAMIC_HEAP_COUNT
-            }
-#endif //MULTIPLE_HEAPS
-            gc_heap::gc_started = FALSE;
-#ifdef BACKGROUND_GC
-            gc_heap::add_bgc_pause_duration_0();
-#endif //BACKGROUND_GC
-            BEGIN_TIMING(restart_ee_during_log);
-            GCToEEInterface::RestartEE(TRUE);
-            END_TIMING(restart_ee_during_log);
-            process_sync_log_stats();
-            dprintf (SPINLOCK_LOG, ("GC Lgc"));
-            leave_spin_lock (&gc_heap::gc_lock);
-            gc_heap::internal_gc_done = true;
-            if (proceed_with_gc_p)
-                set_gc_done();
-            else
-            {
-                for (int i = 0; i < gc_heap::n_heaps; i++)
-                {
-                    gc_heap* hp = gc_heap::g_heaps[i];
-                    hp->set_gc_done();
-                }
-            }
-            if (gradual_decommit_in_progress_p)
-            {
-#ifdef COMMITTED_BYTES_SHADOW
-                decommit_lock.Enter ();
-#endif //COMMITTED_BYTES_SHADOW
-                gradual_decommit_in_progress_p = decommit_step (DECOMMIT_TIME_STEP_MILLISECONDS);
-#ifdef COMMITTED_BYTES_SHADOW
-                decommit_lock.Leave ();
-#endif //COMMITTED_BYTES_SHADOW
-            }
-        }
-        else
-        {
-            int spin_count = 32 * (gc_heap::n_heaps - 1);
-            while (!gc_heap::internal_gc_done && !GCHeap::SafeToRestartManagedThreads())
-            {
-                spin_and_switch (spin_count, (gc_heap::internal_gc_done || GCHeap::SafeToRestartManagedThreads()));
-            }
-            set_gc_done();
-        }
-    }
-}
-#ifdef _MSC_VER
-#pragma warning(default:4715) //IA64 xcompiler recognizes that without the 'break;' the while(1) will never end and therefore not return a value for that code path
-#endif //_MSC_VER
-#endif //MULTIPLE_HEAPS
-bool gc_heap::virtual_alloc_commit_for_heap (void* addr, size_t size, int h_number)
-{
-#ifdef MULTIPLE_HEAPS
-    if (GCToOSInterface::CanEnableGCNumaAware())
-    {
-        uint16_t numa_node = heap_select::find_numa_node_from_heap_no(h_number);
-        if (GCToOSInterface::VirtualCommit (addr, size, numa_node))
-            return true;
-    }
-#else //MULTIPLE_HEAPS
-    UNREFERENCED_PARAMETER(h_number);
-#endif //MULTIPLE_HEAPS
-    return GCToOSInterface::VirtualCommit(addr, size);
-}
-bool gc_heap::virtual_commit (void* address, size_t size, int bucket, int h_number, bool* hard_limit_exceeded_p)
-{
-    /**
-     * Here are all the possible cases for the commits:
-     *
-     * Case 1: This is for a particular generation - the bucket will be one of the gc_oh_num != unknown, and the h_number will be the right heap
-     * Case 2: This is for bookkeeping - the bucket will be recorded_committed_bookkeeping_bucket, and the h_number will be -1
-     *
-     * Note  : We never commit into free directly, so bucket != recorded_committed_free_bucket
-     */
-#ifndef HOST_64BIT
-    assert (heap_hard_limit == 0);
-#endif //!HOST_64BIT
-    assert(0 <= bucket && bucket < recorded_committed_bucket_counts);
-    assert(bucket < total_oh_count || h_number == -1);
-#ifdef USE_REGIONS
-    assert(bucket != recorded_committed_free_bucket);
-#endif //USE_REGIONS
-    dprintf(3, ("commit-accounting:  commit in %d [%p, %p) for heap %d", bucket, address, ((uint8_t*)address + size), h_number));
-    bool should_count =
-#ifdef USE_REGIONS
-        true;
-#else
-        (bucket != recorded_committed_ignored_bucket);
-#endif //USE_REGIONS
-    if (should_count)
-    {
-        check_commit_cs.Enter();
-        bool exceeded_p = false;
-        if (heap_hard_limit_oh[soh] != 0)
-        {
-            if ((bucket < total_oh_count) && (committed_by_oh[bucket] + size) > heap_hard_limit_oh[bucket])
-            {
-                exceeded_p = true;
-            }
-        }
-        else
-        {
-            size_t base = current_total_committed;
-            size_t limit = heap_hard_limit;
-            if ((base + size) > limit)
-            {
-                dprintf (1, ("%zd + %zd = %zd > limit %zd ", base, size, (base + size), limit));
-                exceeded_p = true;
-            }
-        }
-        if (!heap_hard_limit) {
-            exceeded_p = false;
-        }
-        if (!exceeded_p)
-        {
-#if defined(MULTIPLE_HEAPS) && defined(_DEBUG)
-            if ((h_number != -1) && (bucket < total_oh_count))
-            {
-                g_heaps[h_number]->committed_by_oh_per_heap[bucket] += size;
-            }
-#endif // MULTIPLE_HEAPS && _DEBUG
-            committed_by_oh[bucket] += size;
-            current_total_committed += size;
-            if (h_number < 0)
-                current_total_committed_bookkeeping += size;
-        }
-        check_commit_cs.Leave();
-        if (hard_limit_exceeded_p)
-            *hard_limit_exceeded_p = exceeded_p;
-        if (exceeded_p)
-        {
-            dprintf (1, ("can't commit %zx for %zd bytes > HARD LIMIT %zd", (size_t)address, size, heap_hard_limit));
-            return false;
-        }
-    }
-    bool commit_succeeded_p = ((h_number >= 0) ? (use_large_pages_p ? true :
-                              virtual_alloc_commit_for_heap (address, size, h_number)) :
-                              GCToOSInterface::VirtualCommit(address, size));
-    if (!commit_succeeded_p && should_count)
-    {
-        check_commit_cs.Enter();
-        committed_by_oh[bucket] -= size;
-#if defined(MULTIPLE_HEAPS) && defined(_DEBUG)
-        if ((h_number != -1) && (bucket < total_oh_count))
-        {
-            assert (g_heaps[h_number]->committed_by_oh_per_heap[bucket] >= size);
-            g_heaps[h_number]->committed_by_oh_per_heap[bucket] -= size;
-        }
-#endif // MULTIPLE_HEAPS && _DEBUG
-        dprintf (1, ("commit failed, updating %zd to %zd",
-                current_total_committed, (current_total_committed - size)));
-        current_total_committed -= size;
-        if (h_number < 0)
-        {
-            assert (current_total_committed_bookkeeping >= size);
-            current_total_committed_bookkeeping -= size;
-        }
-        check_commit_cs.Leave();
-    }
-    return commit_succeeded_p;
-}
-void gc_heap::reduce_committed_bytes (void* address, size_t size, int bucket, int h_number, bool decommit_succeeded_p)
-{
-    assert(0 <= bucket && bucket < recorded_committed_bucket_counts);
-    assert(bucket < total_oh_count || h_number == -1);
-    dprintf(3, ("commit-accounting:  decommit in %d [%p, %p) for heap %d", bucket, address, ((uint8_t*)address + size), h_number));
-#ifndef USE_REGIONS
-    if (bucket != recorded_committed_ignored_bucket)
-#endif
-    if (decommit_succeeded_p)
-    {
-        check_commit_cs.Enter();
-        assert (committed_by_oh[bucket] >= size);
-        committed_by_oh[bucket] -= size;
-#if defined(MULTIPLE_HEAPS) && defined(_DEBUG)
-        if ((h_number != -1) && (bucket < total_oh_count))
-        {
-            assert (g_heaps[h_number]->committed_by_oh_per_heap[bucket] >= size);
-            g_heaps[h_number]->committed_by_oh_per_heap[bucket] -= size;
-        }
-#endif // MULTIPLE_HEAPS && _DEBUG
-        assert (current_total_committed >= size);
-        current_total_committed -= size;
-        if (bucket == recorded_committed_bookkeeping_bucket)
-        {
-            assert (current_total_committed_bookkeeping >= size);
-            current_total_committed_bookkeeping -= size;
-        }
-        check_commit_cs.Leave();
-    }
-}
-bool gc_heap::virtual_decommit (void* address, size_t size, int bucket, int h_number)
-{
-    /**
-     * Here are all possible cases for the decommits:
-     *
-     * Case 1: This is for a particular generation - the bucket will be one of the gc_oh_num != unknown, and the h_number will be the right heap
-     * Case 2: This is for bookkeeping - the bucket will be recorded_committed_bookkeeping_bucket, and the h_number will be -1
-     * Case 3: This is for free - the bucket will be recorded_committed_free_bucket, and the h_number will be -1
-     */
-#ifndef HOST_64BIT
-    assert (heap_hard_limit == 0);
-#endif //!HOST_64BIT
-    bool decommit_succeeded_p = ((bucket != recorded_committed_bookkeeping_bucket) && use_large_pages_p) ? true : GCToOSInterface::VirtualDecommit (address, size);
-    reduce_committed_bytes (address, size, bucket, h_number, decommit_succeeded_p);
-    return decommit_succeeded_p;
-}
-void gc_heap::virtual_free (void* add, size_t allocated_size, heap_segment* sg)
-{
-    bool release_succeeded_p = GCToOSInterface::VirtualRelease (add, allocated_size);
-    if (release_succeeded_p)
-    {
-        reserved_memory -= allocated_size;
-        dprintf (2, ("Virtual Free size %zd: [%zx, %zx[",
-                    allocated_size, (size_t)add, (size_t)((uint8_t*)add + allocated_size)));
-    }
-}
-class mark
-{
-public:
-    uint8_t* first;
-    size_t len;
-    gap_reloc_pair saved_pre_plug;
-    gap_reloc_pair saved_pre_plug_reloc;
-    gap_reloc_pair saved_post_plug;
-    gap_reloc_pair saved_post_plug_reloc;
-    uint8_t* saved_pre_plug_info_reloc_start;
-    uint8_t* saved_post_plug_info_start;
-#ifdef SHORT_PLUGS
-    uint8_t* allocation_context_start_region;
-#endif //SHORT_PLUGS
-    BOOL saved_pre_p;
-    BOOL saved_post_p;
-#ifdef _DEBUG
-    gap_reloc_pair saved_post_plug_debug;
-#endif //_DEBUG
-    size_t get_max_short_bits()
-    {
-        return (sizeof (gap_reloc_pair) / sizeof (uint8_t*));
-    }
-    size_t get_pre_short_start_bit ()
-    {
-        return (sizeof (saved_pre_p) * 8 - 1 - (sizeof (gap_reloc_pair) / sizeof (uint8_t*)));
-    }
-    BOOL pre_short_p()
-    {
-        return (saved_pre_p & (1 << (sizeof (saved_pre_p) * 8 - 1)));
-    }
-    void set_pre_short()
-    {
-        saved_pre_p |= (1 << (sizeof (saved_pre_p) * 8 - 1));
-    }
-    void set_pre_short_bit (size_t bit)
-    {
-        saved_pre_p |= 1 << (get_pre_short_start_bit() + bit);
-    }
-    BOOL pre_short_bit_p (size_t bit)
-    {
-        return (saved_pre_p & (1 << (get_pre_short_start_bit() + bit)));
-    }
-#ifdef COLLECTIBLE_CLASS
-    void set_pre_short_collectible()
-    {
-        saved_pre_p |= 2;
-    }
-    BOOL pre_short_collectible_p()
-    {
-        return (saved_pre_p & 2);
-    }
-#endif //COLLECTIBLE_CLASS
-    size_t get_post_short_start_bit ()
-    {
-        return (sizeof (saved_post_p) * 8 - 1 - (sizeof (gap_reloc_pair) / sizeof (uint8_t*)));
-    }
-    BOOL post_short_p()
-    {
-        return (saved_post_p & (1 << (sizeof (saved_post_p) * 8 - 1)));
-    }
-    void set_post_short()
-    {
-        saved_post_p |= (1 << (sizeof (saved_post_p) * 8 - 1));
-    }
-    void set_post_short_bit (size_t bit)
-    {
-        saved_post_p |= 1 << (get_post_short_start_bit() + bit);
-    }
-    BOOL post_short_bit_p (size_t bit)
-    {
-        return (saved_post_p & (1 << (get_post_short_start_bit() + bit)));
-    }
-#ifdef COLLECTIBLE_CLASS
-    void set_post_short_collectible()
-    {
-        saved_post_p |= 2;
-    }
-    BOOL post_short_collectible_p()
-    {
-        return (saved_post_p & 2);
-    }
-#endif //COLLECTIBLE_CLASS
-    uint8_t* get_plug_address() { return first; }
-    BOOL has_pre_plug_info() { return saved_pre_p; }
-    BOOL has_post_plug_info() { return saved_post_p; }
-    gap_reloc_pair* get_pre_plug_reloc_info() { return &saved_pre_plug_reloc; }
-    gap_reloc_pair* get_post_plug_reloc_info() { return &saved_post_plug_reloc; }
-    void set_pre_plug_info_reloc_start (uint8_t* reloc) { saved_pre_plug_info_reloc_start = reloc; }
-    uint8_t* get_post_plug_info_start() { return saved_post_plug_info_start; }
-    void swap_pre_plug_and_saved()
-    {
-        gap_reloc_pair temp;
-        memcpy (&temp, (first - sizeof (plug_and_gap)), sizeof (temp));
-        memcpy ((first - sizeof (plug_and_gap)), &saved_pre_plug_reloc, sizeof (saved_pre_plug_reloc));
-        saved_pre_plug_reloc = temp;
-    }
-    void swap_post_plug_and_saved()
-    {
-        gap_reloc_pair temp;
-        memcpy (&temp, saved_post_plug_info_start, sizeof (temp));
-        memcpy (saved_post_plug_info_start, &saved_post_plug_reloc, sizeof (saved_post_plug_reloc));
-        saved_post_plug_reloc = temp;
-    }
-    void swap_pre_plug_and_saved_for_profiler()
-    {
-        gap_reloc_pair temp;
-        memcpy (&temp, (first - sizeof (plug_and_gap)), sizeof (temp));
-        memcpy ((first - sizeof (plug_and_gap)), &saved_pre_plug, sizeof (saved_pre_plug));
-        saved_pre_plug = temp;
-    }
-    void swap_post_plug_and_saved_for_profiler()
-    {
-        gap_reloc_pair temp;
-        memcpy (&temp, saved_post_plug_info_start, sizeof (temp));
-        memcpy (saved_post_plug_info_start, &saved_post_plug, sizeof (saved_post_plug));
-        saved_post_plug = temp;
-    }
-    size_t recover_plug_info()
-    {
-        size_t recovered_sweep_size = 0;
-        if (saved_pre_p)
-        {
-            if (gc_heap::settings.compaction)
-            {
-                dprintf (3, ("%p: REC Pre: %p-%p",
-                    first,
-                    &saved_pre_plug_reloc,
-                    saved_pre_plug_info_reloc_start));
-                memcpy (saved_pre_plug_info_reloc_start, &saved_pre_plug_reloc, sizeof (saved_pre_plug_reloc));
-            }
-            else
-            {
-                dprintf (3, ("%p: REC Pre: %p-%p",
-                    first,
-                    &saved_pre_plug,
-                    (first - sizeof (plug_and_gap))));
-                memcpy ((first - sizeof (plug_and_gap)), &saved_pre_plug, sizeof (saved_pre_plug));
-                recovered_sweep_size += sizeof (saved_pre_plug);
-            }
-        }
-        if (saved_post_p)
-        {
-            if (gc_heap::settings.compaction)
-            {
-                dprintf (3, ("%p: REC Post: %p-%p",
-                    first,
-                    &saved_post_plug_reloc,
-                    saved_post_plug_info_start));
-                memcpy (saved_post_plug_info_start, &saved_post_plug_reloc, sizeof (saved_post_plug_reloc));
-            }
-            else
-            {
-                dprintf (3, ("%p: REC Post: %p-%p",
-                    first,
-                    &saved_post_plug,
-                    saved_post_plug_info_start));
-                memcpy (saved_post_plug_info_start, &saved_post_plug, sizeof (saved_post_plug));
-                recovered_sweep_size += sizeof (saved_post_plug);
-            }
-        }
-        return recovered_sweep_size;
-    }
-};
-void gc_mechanisms::init_mechanisms()
-{
-    condemned_generation = 0;
-    promotion = FALSE;//TRUE;
-    compaction = TRUE;
-#ifdef FEATURE_LOH_COMPACTION
-    loh_compaction = gc_heap::loh_compaction_requested();
-#else
-    loh_compaction = FALSE;
-#endif //FEATURE_LOH_COMPACTION
-    heap_expansion = FALSE;
-    concurrent = FALSE;
-    demotion = FALSE;
-    elevation_reduced = FALSE;
-    found_finalizers = FALSE;
-#ifdef BACKGROUND_GC
-    background_p = gc_heap::background_running_p() != FALSE;
-#endif //BACKGROUND_GC
-    entry_memory_load = 0;
-    entry_available_physical_mem = 0;
-    exit_memory_load = 0;
-#ifdef STRESS_HEAP
-    stress_induced = FALSE;
-#endif // STRESS_HEAP
-}
-void gc_mechanisms::first_init()
-{
-    gc_index = 0;
-    gen0_reduction_count = 0;
-    should_lock_elevation = FALSE;
-    elevation_locked_count = 0;
-    reason = reason_empty;
-#ifdef BACKGROUND_GC
-    pause_mode = gc_heap::gc_can_use_concurrent ? pause_interactive : pause_batch;
-#ifdef _DEBUG
-    int debug_pause_mode = static_cast<int>(GCConfig::GetLatencyMode());
-    if (debug_pause_mode >= 0)
-    {
-        assert (debug_pause_mode <= pause_sustained_low_latency);
-        pause_mode = (gc_pause_mode)debug_pause_mode;
-    }
-#endif //_DEBUG
-#else //BACKGROUND_GC
-    pause_mode = pause_batch;
-#endif //BACKGROUND_GC
-    init_mechanisms();
-}
-void gc_mechanisms::record (gc_history_global* history)
-{
-#ifdef MULTIPLE_HEAPS
-    history->num_heaps = gc_heap::n_heaps;
-#else
-    history->num_heaps = 1;
-#endif //MULTIPLE_HEAPS
-    history->condemned_generation = condemned_generation;
-    history->gen0_reduction_count = gen0_reduction_count;
-    history->reason = reason;
-    history->pause_mode = (int)pause_mode;
-    history->mem_pressure = entry_memory_load;
-    history->global_mechanisms_p = 0;
-    if (concurrent)
-        history->set_mechanism_p (global_concurrent);
-    if (compaction)
-        history->set_mechanism_p (global_compaction);
-    if (promotion)
-        history->set_mechanism_p (global_promotion);
-    if (demotion)
-        history->set_mechanism_p (global_demotion);
-    if (card_bundles)
-        history->set_mechanism_p (global_card_bundles);
-    if (elevation_reduced)
-        history->set_mechanism_p (global_elevation);
-}
-/**********************************
-   called at the beginning of GC to fix the allocated size to
-   what is really allocated, or to turn the free area into an unused object
-   It needs to be called after all of the other allocation contexts have been
-   fixed since it relies on alloc_allocated.
- ********************************/
-void gc_heap::fix_youngest_allocation_area()
-{
-    assert (generation_allocation_pointer (youngest_generation) == nullptr);
-    assert (generation_allocation_limit (youngest_generation) == nullptr);
-    heap_segment_allocated (ephemeral_heap_segment) = alloc_allocated;
-    assert (heap_segment_mem (ephemeral_heap_segment) <= heap_segment_allocated (ephemeral_heap_segment));
-    assert (heap_segment_allocated (ephemeral_heap_segment) <= heap_segment_reserved (ephemeral_heap_segment));
-}
-void gc_heap::fix_allocation_context (alloc_context* acontext, BOOL for_gc_p,
-                                      BOOL record_ac_p)
-{
-    dprintf (3, ("Fixing allocation context %zx: ptr: %zx, limit: %zx",
-                 (size_t)acontext,
-                 (size_t)acontext->alloc_ptr, (size_t)acontext->alloc_limit));
-    if (acontext->alloc_ptr == 0)
-    {
-        return;
-    }
-    int align_const = get_alignment_constant (TRUE);
-#ifdef USE_REGIONS
-    bool is_ephemeral_heap_segment = in_range_for_segment (acontext->alloc_limit, ephemeral_heap_segment);
-#else // USE_REGIONS
-    bool is_ephemeral_heap_segment = true;
-#endif // USE_REGIONS
-    if ((!is_ephemeral_heap_segment) || ((size_t)(alloc_allocated - acontext->alloc_limit) > Align (min_obj_size, align_const)) ||
-        !for_gc_p)
-    {
-        uint8_t*  point = acontext->alloc_ptr;
-        size_t  size = (acontext->alloc_limit - acontext->alloc_ptr);
-        size += Align (min_obj_size, align_const);
-        assert ((size >= Align (min_obj_size)));
-        dprintf(3,("Making unused area [%zx, %zx[", (size_t)point,
-                    (size_t)point + size ));
-        make_unused_array (point, size);
-        if (for_gc_p)
-        {
-            generation_free_obj_space (generation_of (0)) += size;
-            if (record_ac_p)
-                alloc_contexts_used ++;
-        }
-    }
-    else if (for_gc_p)
-    {
-        assert (is_ephemeral_heap_segment);
-        alloc_allocated = acontext->alloc_ptr;
-        assert (heap_segment_allocated (ephemeral_heap_segment) <=
-                heap_segment_committed (ephemeral_heap_segment));
-        if (record_ac_p)
-            alloc_contexts_used ++;
-    }
-    if (for_gc_p)
-    {
-        acontext->alloc_bytes -= (acontext->alloc_limit - acontext->alloc_ptr);
-        total_alloc_bytes_soh -= (acontext->alloc_limit - acontext->alloc_ptr);
-        acontext->alloc_ptr = 0;
-        acontext->alloc_limit = acontext->alloc_ptr;
-    }
-}
-void repair_allocation (gc_alloc_context* acontext, void*)
-{
-    uint8_t*  point = acontext->alloc_ptr;
-    if (point != 0)
-    {
-        dprintf (3, ("Clearing [%zx, %zx[", (size_t)acontext->alloc_ptr,
-                     (size_t)acontext->alloc_limit+Align(min_obj_size)));
-        memclr (acontext->alloc_ptr - plug_skew,
-                (acontext->alloc_limit - acontext->alloc_ptr)+Align (min_obj_size));
-    }
-}
-void void_allocation (gc_alloc_context* acontext, void*)
-{
-    uint8_t*  point = acontext->alloc_ptr;
-    if (point != 0)
-    {
-        dprintf (3, ("Void [%zx, %zx[", (size_t)acontext->alloc_ptr,
-                     (size_t)acontext->alloc_limit+Align(min_obj_size)));
-        acontext->alloc_ptr = 0;
-        acontext->alloc_limit = acontext->alloc_ptr;
-    }
-}
-void gc_heap::repair_allocation_contexts (BOOL repair_p)
-{
-    GCToEEInterface::GcEnumAllocContexts (repair_p ? repair_allocation : void_allocation, NULL);
-}
-struct fix_alloc_context_args
-{
-    BOOL for_gc_p;
-    void* heap;
-};
-void fix_alloc_context (gc_alloc_context* acontext, void* param)
-{
-    fix_alloc_context_args* args = (fix_alloc_context_args*)param;
-    g_theGCHeap->FixAllocContext(acontext, (void*)(size_t)(args->for_gc_p), args->heap);
-}
-void gc_heap::fix_allocation_contexts (BOOL for_gc_p)
-{
-    fix_alloc_context_args args;
-    args.for_gc_p = for_gc_p;
-    args.heap = __this;
-    GCToEEInterface::GcEnumAllocContexts(fix_alloc_context, &args);
-    fix_youngest_allocation_area();
-}
-void gc_heap::fix_older_allocation_area (generation* older_gen)
-{
-    heap_segment* older_gen_seg = generation_allocation_segment (older_gen);
-    if (generation_allocation_limit (older_gen) !=
-        heap_segment_plan_allocated (older_gen_seg))
-    {
-        uint8_t*  point = generation_allocation_pointer (older_gen);
-        size_t  size = (generation_allocation_limit (older_gen) - generation_allocation_pointer (older_gen));
-        if (size != 0)
-        {
-            assert ((size >= Align (min_obj_size)));
-            dprintf(3,("Making unused area [%zx, %zx[", (size_t)point, (size_t)point+size));
-            make_unused_array (point, size);
-            if (size >= min_free_list)
-            {
-                generation_allocator (older_gen)->thread_item_front (point, size);
-                add_gen_free (older_gen->gen_num, size);
-                generation_free_list_space (older_gen) += size;
-            }
-            else
-            {
-                generation_free_obj_space (older_gen) += size;
-            }
-        }
-    }
-    else
-    {
-        assert (older_gen_seg != ephemeral_heap_segment);
-        heap_segment_plan_allocated (older_gen_seg) =
-            generation_allocation_pointer (older_gen);
-        generation_allocation_limit (older_gen) =
-            generation_allocation_pointer (older_gen);
-    }
-    generation_allocation_pointer (older_gen) = 0;
-    generation_allocation_limit (older_gen) = 0;
-}
-#ifdef MULTIPLE_HEAPS
-void gc_heap::fix_allocation_context_heaps (gc_alloc_context* gc_context, void*)
-{
-    alloc_context* acontext = (alloc_context*)gc_context;
-    GCHeap* pHomeHeap = acontext->get_home_heap ();
-    int home_hp_num = pHomeHeap ? pHomeHeap->pGenGCHeap->heap_number : 0;
-    if (home_hp_num >= gc_heap::n_heaps)
-    {
-        home_hp_num %= gc_heap::n_heaps;
-        acontext->set_home_heap (GCHeap::GetHeap (home_hp_num));
-    }
-    GCHeap* pAllocHeap = acontext->get_alloc_heap ();
-    int alloc_hp_num = pAllocHeap ? pAllocHeap->pGenGCHeap->heap_number : 0;
-    if (alloc_hp_num >= gc_heap::n_heaps)
-    {
-        alloc_hp_num %= gc_heap::n_heaps;
-        acontext->set_alloc_heap (GCHeap::GetHeap (alloc_hp_num));
-        gc_heap* hp = acontext->get_alloc_heap ()->pGenGCHeap;
-        hp->alloc_context_count++;
-    }
-}
-void gc_heap::fix_allocation_contexts_heaps()
-{
-    GCToEEInterface::GcEnumAllocContexts (fix_allocation_context_heaps, nullptr);
-}
-#endif //MULTIPLE_HEAPS
-void gc_heap::set_allocation_heap_segment (generation* gen)
-{
-#ifdef USE_REGIONS
-    heap_segment* seg = heap_segment_rw (generation_start_segment (gen));
-    dprintf (REGIONS_LOG, ("set gen%d alloc seg to start seg %p", gen->gen_num, heap_segment_mem (seg)));
-#else
-    uint8_t* p = generation_allocation_start (gen);
-    assert (p);
-    heap_segment* seg = generation_allocation_segment (gen);
-    if (in_range_for_segment (p, seg))
-        return;
-    seg = ephemeral_heap_segment;
-    if (!in_range_for_segment (p, seg))
-    {
-        seg = heap_segment_rw (generation_start_segment (gen));
-        PREFIX_ASSUME(seg != NULL);
-        while (!in_range_for_segment (p, seg))
-        {
-            seg = heap_segment_next_rw (seg);
-            PREFIX_ASSUME(seg != NULL);
-        }
-    }
-#endif //USE_REGIONS
-    generation_allocation_segment (gen) = seg;
-}
-void gc_heap::reset_allocation_pointers (generation* gen, uint8_t* start)
-{
-    assert (start);
-    assert (Align ((size_t)start) == (size_t)start);
-#ifndef USE_REGIONS
-    generation_allocation_start (gen) = start;
-#endif //!USE_REGIONS
-    generation_allocation_pointer (gen) =  0;//start + Align (min_obj_size);
-    generation_allocation_limit (gen) = 0;//generation_allocation_pointer (gen);
-    set_allocation_heap_segment (gen);
-}
-bool gc_heap::new_allocation_allowed (int gen_number)
-{
-    if (dd_new_allocation (dynamic_data_of (gen_number)) < 0)
-    {
-        if (gen_number != 0)
-        {
-            if (settings.concurrent)
-            {
-                dynamic_data* dd2 = dynamic_data_of (gen_number);
-                if (dd_new_allocation (dd2) <= (ptrdiff_t)(-2 * dd_desired_allocation (dd2)))
-                {
-                    return TRUE;
-                }
-            }
-        }
-        return FALSE;
-    }
-#ifndef MULTIPLE_HEAPS
-    else if ((settings.pause_mode != pause_no_gc) && (gen_number == 0))
-    {
-        dynamic_data* dd0 = dynamic_data_of (0);
-        dprintf (3, ("evaluating, running amount %zd - new %zd = %zd",
-            allocation_running_amount, dd_new_allocation (dd0),
-            (allocation_running_amount - dd_new_allocation (dd0))));
-        if ((allocation_running_amount - dd_new_allocation (dd0)) >
-            dd_min_size (dd0))
-        {
-            uint64_t ctime = GCToOSInterface::GetLowPrecisionTimeStamp();
-            if ((ctime - allocation_running_time) > 1000)
-            {
-                dprintf (2, (">1s since last gen0 gc"));
-                return FALSE;
-            }
-            else
-            {
-                allocation_running_amount = dd_new_allocation (dd0);
-            }
-        }
-    }
-#endif //MULTIPLE_HEAPS
-    return TRUE;
-}
-inline
-ptrdiff_t gc_heap::get_desired_allocation (int gen_number)
-{
-    return dd_desired_allocation (dynamic_data_of (gen_number));
-}
-inline
-ptrdiff_t  gc_heap::get_new_allocation (int gen_number)
-{
-    return dd_new_allocation (dynamic_data_of (gen_number));
-}
-inline
-ptrdiff_t  gc_heap::get_allocation (int gen_number)
-{
-    dynamic_data* dd = dynamic_data_of (gen_number);
-    return dd_desired_allocation (dd) - dd_new_allocation (dd);
-}
-inline
-BOOL grow_mark_stack (mark*& m, size_t& len, size_t init_len)
-{
-    size_t new_size = max (init_len, 2*len);
-    mark* tmp = new (nothrow) mark [new_size];
-    if (tmp)
-    {
-        memcpy (tmp, m, len * sizeof (mark));
-        delete[] m;
-        m = tmp;
-        len = new_size;
-        return TRUE;
-    }
-    else
-    {
-        dprintf (1, ("Failed to allocate %zd bytes for mark stack", (len * sizeof (mark))));
-        return FALSE;
-    }
-}
-inline
-uint8_t* pinned_plug (mark* m)
-{
-   return m->first;
-}
-inline
-size_t& pinned_len (mark* m)
-{
-    return m->len;
-}
-inline
-void set_new_pin_info (mark* m, uint8_t* pin_free_space_start)
-{
-    m->len = pinned_plug (m) - pin_free_space_start;
-#ifdef SHORT_PLUGS
-    m->allocation_context_start_region = pin_free_space_start;
-#endif //SHORT_PLUGS
-}
-#ifdef SHORT_PLUGS
-inline
-uint8_t*& pin_allocation_context_start_region (mark* m)
-{
-    return m->allocation_context_start_region;
-}
-uint8_t* get_plug_start_in_saved (uint8_t* old_loc, mark* pinned_plug_entry)
-{
-    uint8_t* saved_pre_plug_info = (uint8_t*)(pinned_plug_entry->get_pre_plug_reloc_info());
-    uint8_t* plug_start_in_saved = saved_pre_plug_info + (old_loc - (pinned_plug (pinned_plug_entry) - sizeof (plug_and_gap)));
-    dprintf (1, ("EP: %p(%p), %p", old_loc, pinned_plug (pinned_plug_entry), plug_start_in_saved));
-    return plug_start_in_saved;
-}
-inline
-void set_padding_in_expand (uint8_t* old_loc,
-                            BOOL set_padding_on_saved_p,
-                            mark* pinned_plug_entry)
-{
-    if (set_padding_on_saved_p)
-    {
-        set_plug_padded (get_plug_start_in_saved (old_loc, pinned_plug_entry));
-    }
-    else
-    {
-        set_plug_padded (old_loc);
-    }
-}
-inline
-void clear_padding_in_expand (uint8_t* old_loc,
-                              BOOL set_padding_on_saved_p,
-                              mark* pinned_plug_entry)
-{
-    if (set_padding_on_saved_p)
-    {
-        clear_plug_padded (get_plug_start_in_saved (old_loc, pinned_plug_entry));
-    }
-    else
-    {
-        clear_plug_padded (old_loc);
-    }
-}
-#endif //SHORT_PLUGS
-void gc_heap::reset_pinned_queue()
-{
-    mark_stack_tos = 0;
-    mark_stack_bos = 0;
-}
-void gc_heap::reset_pinned_queue_bos()
-{
-    mark_stack_bos = 0;
-}
-void gc_heap::merge_with_last_pinned_plug (uint8_t* last_pinned_plug, size_t plug_size)
-{
-    if (last_pinned_plug)
-    {
-        mark& last_m = mark_stack_array[mark_stack_tos - 1];
-        assert (last_pinned_plug == last_m.first);
-        if (last_m.saved_post_p)
-        {
-            last_m.saved_post_p = FALSE;
-            dprintf (3, ("setting last plug %p post to false", last_m.first));
-            memcpy ((last_m.first + last_m.len - sizeof (plug_and_gap)), &(last_m.saved_post_plug), sizeof (gap_reloc_pair));
-        }
-        last_m.len += plug_size;
-        dprintf (3, ("recovered the last part of plug %p, setting its plug size to %zx", last_m.first, last_m.len));
-    }
-}
-void gc_heap::set_allocator_next_pin (generation* gen)
-{
-    dprintf (3, ("SANP: gen%d, ptr; %p, limit: %p", gen->gen_num, generation_allocation_pointer (gen), generation_allocation_limit (gen)));
-    if (!(pinned_plug_que_empty_p()))
-    {
-        mark*  oldest_entry = oldest_pin();
-        uint8_t* plug = pinned_plug (oldest_entry);
-        if ((plug >= generation_allocation_pointer (gen)) &&
-            (plug <  generation_allocation_limit (gen)))
-        {
-#ifdef USE_REGIONS
-            assert (region_of (generation_allocation_pointer (gen)) ==
-                    region_of (generation_allocation_limit (gen) - 1));
-#endif //USE_REGIONS
-            generation_allocation_limit (gen) = pinned_plug (oldest_entry);
-            dprintf (3, ("SANP: get next pin free space in gen%d for alloc: %p->%p(%zd)",
-                gen->gen_num,
-                generation_allocation_pointer (gen), generation_allocation_limit (gen),
-                (generation_allocation_limit (gen) - generation_allocation_pointer (gen))));
-        }
-        else
-            assert (!((plug < generation_allocation_pointer (gen)) &&
-                      (plug >= heap_segment_mem (generation_allocation_segment (gen)))));
-    }
-}
-void gc_heap::set_pinned_info (uint8_t* last_pinned_plug, size_t plug_len, generation* gen)
-{
-#ifndef _DEBUG
-    UNREFERENCED_PARAMETER(last_pinned_plug);
-#endif //_DEBUG
-    mark& m = mark_stack_array[mark_stack_tos];
-    assert (m.first == last_pinned_plug);
-    m.len = plug_len;
-    mark_stack_tos++;
-    assert (gen != 0);
-    if (gen != 0)
-    {
-        set_allocator_next_pin (gen);
-    }
-}
-size_t gc_heap::deque_pinned_plug ()
-{
-    size_t m = mark_stack_bos;
-    dprintf (3, ("deque: %zd->%p", mark_stack_bos, pinned_plug (pinned_plug_of (m))));
-    mark_stack_bos++;
-    return m;
-}
-inline
-mark* gc_heap::pinned_plug_of (size_t bos)
-{
-    return &mark_stack_array [ bos ];
-}
-inline
-mark* gc_heap::oldest_pin ()
-{
-    return pinned_plug_of (mark_stack_bos);
-}
-inline
-BOOL gc_heap::pinned_plug_que_empty_p ()
-{
-    return (mark_stack_bos == mark_stack_tos);
-}
-inline
-mark* gc_heap::before_oldest_pin()
-{
-    if (mark_stack_bos >= 1)
-        return pinned_plug_of (mark_stack_bos-1);
-    else
-        return 0;
-}
-inline
-BOOL gc_heap::ephemeral_pointer_p (uint8_t* o)
-{
-#ifdef USE_REGIONS
-    int gen_num = object_gennum ((uint8_t*)o);
-    assert (gen_num >= 0);
-    return (gen_num < max_generation);
-#else
-    return ((o >= ephemeral_low) && (o < ephemeral_high));
-#endif //USE_REGIONS
-}
-inline
-bool gc_heap::is_in_find_object_range (uint8_t* o)
-{
-    if (o == nullptr)
-    {
-        return false;
-    }
-#if defined(USE_REGIONS) && defined(FEATURE_CONSERVATIVE_GC)
-    return ((o >= g_gc_lowest_address) && (o < bookkeeping_covered_committed));
-#else //USE_REGIONS && FEATURE_CONSERVATIVE_GC
-    if ((o >= g_gc_lowest_address) && (o < g_gc_highest_address))
-    {
-#ifdef USE_REGIONS
-        assert ((o >= g_gc_lowest_address) && (o < bookkeeping_covered_committed));
-#endif //USE_REGIONS
-        return true;
-    }
-    else
-    {
-        return false;
-    }
-#endif //USE_REGIONS && FEATURE_CONSERVATIVE_GC
-}
-#ifdef USE_REGIONS
-inline
-bool gc_heap::is_in_condemned_gc (uint8_t* o)
-{
-    assert ((o >= g_gc_lowest_address) && (o < g_gc_highest_address));
-    int condemned_gen = settings.condemned_generation;
-    if (condemned_gen < max_generation)
-    {
-        int gen = get_region_gen_num (o);
-        if (gen > condemned_gen)
-        {
-            return false;
-        }
-    }
-    return true;
-}
-inline
-bool gc_heap::should_check_brick_for_reloc (uint8_t* o)
-{
-    assert ((o >= g_gc_lowest_address) && (o < g_gc_highest_address));
-    size_t skewed_basic_region_index = get_skewed_basic_region_index_for_address (o);
-    return (map_region_to_generation_skewed[skewed_basic_region_index] & (RI_SIP|RI_GEN_MASK)) <= settings.condemned_generation;
-}
-#endif //USE_REGIONS
-#ifdef MH_SC_MARK
-inline
-int& gc_heap::mark_stack_busy()
-{
-    return  g_mark_stack_busy [(heap_number+2)*HS_CACHE_LINE_SIZE/sizeof(int)];
-}
-#endif //MH_SC_MARK
-void gc_heap::make_mark_stack (mark* arr)
-{
-    reset_pinned_queue();
-    mark_stack_array = arr;
-    mark_stack_array_length = MARK_STACK_INITIAL_LENGTH;
-#ifdef MH_SC_MARK
-    mark_stack_busy() = 0;
-#endif //MH_SC_MARK
-}
-#ifdef BACKGROUND_GC
-inline
-size_t& gc_heap::bpromoted_bytes(int thread)
-{
-#ifdef MULTIPLE_HEAPS
-    return g_bpromoted [thread*16];
-#else //MULTIPLE_HEAPS
-    UNREFERENCED_PARAMETER(thread);
-    return g_bpromoted;
-#endif //MULTIPLE_HEAPS
-}
-void gc_heap::make_background_mark_stack (uint8_t** arr)
-{
-    background_mark_stack_array = arr;
-    background_mark_stack_array_length = MARK_STACK_INITIAL_LENGTH;
-    background_mark_stack_tos = arr;
-}
-void gc_heap::make_c_mark_list (uint8_t** arr)
-{
-    c_mark_list = arr;
-    c_mark_list_index = 0;
-    c_mark_list_length = 1 + (OS_PAGE_SIZE / MIN_OBJECT_SIZE);
-}
-#endif //BACKGROUND_GC
-#ifdef CARD_BUNDLE
-static const size_t card_bundle_word_width = 32;
-static const size_t card_bundle_size = (size_t)(GC_PAGE_SIZE / (sizeof(uint32_t)*card_bundle_word_width));
-inline
-size_t card_bundle_word (size_t cardb)
-{
-    return cardb / card_bundle_word_width;
-}
-inline
-uint32_t card_bundle_bit (size_t cardb)
-{
-    return (uint32_t)(cardb % card_bundle_word_width);
-}
-size_t align_cardw_on_bundle (size_t cardw)
-{
-    return ((size_t)(cardw + card_bundle_size - 1) & ~(card_bundle_size - 1 ));
-}
-size_t cardw_card_bundle (size_t cardw)
-{
-    return cardw / card_bundle_size;
-}
-size_t card_bundle_cardw (size_t cardb)
-{
-    return cardb * card_bundle_size;
-}
-void gc_heap::card_bundle_clear (size_t cardb)
-{
-    uint32_t bit = (uint32_t)(1 << card_bundle_bit (cardb));
-    uint32_t* bundle = &card_bundle_table[card_bundle_word (cardb)];
-#ifdef MULTIPLE_HEAPS
-    if ((*bundle & bit) != 0)
-    {
-        Interlocked::And (bundle, ~bit);
-    }
-#else
-    *bundle &= ~bit;
-#endif
-    assert ((*bundle & bit) == 0);
-    dprintf (2, ("Cleared card bundle %zx [%zx, %zx[", cardb, (size_t)card_bundle_cardw (cardb),
-              (size_t)card_bundle_cardw (cardb+1)));
-}
-inline void set_bundle_bits (uint32_t* bundle, uint32_t bits)
-{
-#ifdef MULTIPLE_HEAPS
-    if ((*bundle & bits) != bits)
-    {
-        Interlocked::Or (bundle, bits);
-    }
-#else
-    *bundle |= bits;
-#endif
-    assert ((*bundle & bits) == bits);
-}
-void gc_heap::card_bundle_set (size_t cardb)
-{
-    uint32_t bits = (1 << card_bundle_bit (cardb));
-    set_bundle_bits (&card_bundle_table [card_bundle_word (cardb)], bits);
-}
-void gc_heap::card_bundles_set (size_t start_cardb, size_t end_cardb)
-{
-    if (start_cardb == end_cardb)
-    {
-        card_bundle_set(start_cardb);
-        return;
-    }
-    size_t start_word = card_bundle_word (start_cardb);
-    size_t end_word = card_bundle_word (end_cardb);
-    if (start_word < end_word)
-    {
-        uint32_t bits = highbits (~0u, card_bundle_bit (start_cardb));
-        set_bundle_bits (&card_bundle_table [start_word], bits);
-        if (card_bundle_bit (end_cardb))
-        {
-            bits = lowbits (~0u, card_bundle_bit (end_cardb));
-            set_bundle_bits (&card_bundle_table [end_word], bits);
-        }
-        for (size_t i = start_word + 1; i < end_word; i++)
-        {
-            card_bundle_table [i] = ~0u;
-        }
-    }
-    else
-    {
-        uint32_t bits = (highbits (~0u, card_bundle_bit (start_cardb)) &
-                          lowbits (~0u, card_bundle_bit (end_cardb)));
-        set_bundle_bits (&card_bundle_table [start_word], bits);
-    }
-}
-BOOL gc_heap::card_bundle_set_p (size_t cardb)
-{
-    return (card_bundle_table[card_bundle_word(cardb)] & (1 << card_bundle_bit (cardb)));
-}
-size_t size_card_bundle_of (uint8_t* from, uint8_t* end)
-{
-    size_t cbw_span = card_size * card_word_width * card_bundle_size * card_bundle_word_width;
-    from = (uint8_t*)((size_t)from & ~(cbw_span - 1));
-    end = (uint8_t*)((size_t)(end + (cbw_span - 1)) & ~(cbw_span - 1));
-    assert (((size_t)from & (cbw_span - 1)) == 0);
-    assert (((size_t)end  & (cbw_span - 1)) == 0);
-    return ((end - from) / cbw_span) * sizeof (uint32_t);
-}
-uint32_t* translate_card_bundle_table (uint32_t* cb, uint8_t* lowest_address)
-{
-    const size_t heap_bytes_for_bundle_word = card_size * card_word_width * card_bundle_size * card_bundle_word_width;
-    return (uint32_t*)((uint8_t*)cb - (((size_t)lowest_address / heap_bytes_for_bundle_word) * sizeof (uint32_t)));
-}
-void gc_heap::enable_card_bundles ()
-{
-    if (can_use_write_watch_for_card_table() && (!card_bundles_enabled()))
-    {
-        dprintf (1, ("Enabling card bundles"));
-        card_bundles_set (cardw_card_bundle (card_word (card_of (lowest_address))),
-                          cardw_card_bundle (align_cardw_on_bundle (card_word (card_of (highest_address)))));
-        settings.card_bundles = TRUE;
-    }
-}
-BOOL gc_heap::card_bundles_enabled ()
-{
-    return settings.card_bundles;
-}
-#endif // CARD_BUNDLE
-#if defined (HOST_64BIT)
-#define brick_size ((size_t)4096)
-#else
-#define brick_size ((size_t)2048)
-#endif //HOST_64BIT
-inline
-size_t gc_heap::brick_of (uint8_t* add)
-{
-    return (size_t)(add - lowest_address) / brick_size;
-}
-inline
-uint8_t* gc_heap::brick_address (size_t brick)
-{
-    return lowest_address + (brick_size * brick);
-}
-void gc_heap::clear_brick_table (uint8_t* from, uint8_t* end)
-{
-    size_t from_brick = brick_of (from);
-    size_t end_brick = brick_of (end);
-    memset (&brick_table[from_brick], 0, sizeof(brick_table[from_brick])*(end_brick-from_brick));
-}
-inline
-void gc_heap::set_brick (size_t index, ptrdiff_t val)
-{
-    if (val < -32767)
-    {
-        val = -32767;
-    }
-    assert (val < 32767);
-    if (val >= 0)
-        brick_table [index] = (short)val+1;
-    else
-        brick_table [index] = (short)val;
-    dprintf (3, ("set brick[%zx] to %d\n", index, (short)val));
-}
-inline
-int gc_heap::get_brick_entry (size_t index)
-{
-#ifdef MULTIPLE_HEAPS
-    return VolatileLoadWithoutBarrier(&brick_table [index]);
-#else
-    return brick_table[index];
-#endif
-}
-inline
-uint8_t* align_on_brick (uint8_t* add)
-{
-    return (uint8_t*)((size_t)(add + brick_size - 1) & ~(brick_size - 1));
-}
-inline
-uint8_t* align_lower_brick (uint8_t* add)
-{
-    return (uint8_t*)(((size_t)add) & ~(brick_size - 1));
-}
-size_t size_brick_of (uint8_t* from, uint8_t* end)
-{
-    assert (((size_t)from & (brick_size-1)) == 0);
-    assert (((size_t)end  & (brick_size-1)) == 0);
-    return ((end - from) / brick_size) * sizeof (short);
-}
-inline
-uint8_t* gc_heap::card_address (size_t card)
-{
-    return  (uint8_t*) (card_size * card);
-}
-inline
-size_t gc_heap::card_of ( uint8_t* object)
-{
-    return (size_t)(object) / card_size;
-}
-inline
-uint8_t* align_on_card (uint8_t* add)
-{
-    return (uint8_t*)((size_t)(add + card_size - 1) & ~(card_size - 1 ));
-}
-inline
-uint8_t* align_on_card_word (uint8_t* add)
-{
-    return (uint8_t*) ((size_t)(add + (card_size*card_word_width)-1) & ~(card_size*card_word_width - 1));
-}
-inline
-uint8_t* align_lower_card (uint8_t* add)
-{
-    return (uint8_t*)((size_t)add & ~(card_size-1));
-}
-inline
-void gc_heap::clear_card (size_t card)
-{
-    card_table [card_word (card)] =
-        (card_table [card_word (card)] & ~(1 << card_bit (card)));
-    dprintf (3,("Cleared card %zx [%zx, %zx[", card, (size_t)card_address (card),
-              (size_t)card_address (card+1)));
-}
-inline
-void gc_heap::set_card (size_t card)
-{
-    size_t word = card_word (card);
-    card_table[word] = (card_table [word] | (1 << card_bit (card)));
-#ifdef FEATURE_MANUALLY_MANAGED_CARD_BUNDLES
-    size_t bundle_to_set = cardw_card_bundle(word);
-    card_bundle_set(bundle_to_set);
-    dprintf (3,("Set card %zx [%zx, %zx[ and bundle %zx", card, (size_t)card_address (card), (size_t)card_address (card+1), bundle_to_set));
-#endif
-}
-inline
-BOOL  gc_heap::card_set_p (size_t card)
-{
-    return ( card_table [ card_word (card) ] & (1 << card_bit (card)));
-}
-size_t count_card_of (uint8_t* from, uint8_t* end)
-{
-    return card_word (gcard_of (end - 1)) - card_word (gcard_of (from)) + 1;
-}
-size_t size_card_of (uint8_t* from, uint8_t* end)
-{
-    return count_card_of (from, end) * sizeof(uint32_t);
-}
-class card_table_info
-{
-public:
-    unsigned    recount;
-    size_t      size;
-    uint32_t*   next_card_table;
-    uint8_t*    lowest_address;
-    uint8_t*    highest_address;
-    short*      brick_table;
-#ifdef CARD_BUNDLE
-    uint32_t*   card_bundle_table;
-#endif //CARD_BUNDLE
-#ifdef BACKGROUND_GC
-    uint32_t*   mark_array;
-#endif //BACKGROUND_GC
-};
-static_assert(offsetof(dac_card_table_info, size) == offsetof(card_table_info, size), "DAC card_table_info layout mismatch");
-static_assert(offsetof(dac_card_table_info, next_card_table) == offsetof(card_table_info, next_card_table), "DAC card_table_info layout mismatch");
-inline
-unsigned& card_table_refcount (uint32_t* c_table)
-{
-    return *(unsigned*)((char*)c_table - sizeof (card_table_info));
-}
-inline
-uint8_t*& card_table_lowest_address (uint32_t* c_table)
-{
-    return ((card_table_info*)((uint8_t*)c_table - sizeof (card_table_info)))->lowest_address;
-}
-uint32_t* translate_card_table (uint32_t* ct)
-{
-    return (uint32_t*)((uint8_t*)ct - card_word (gcard_of (card_table_lowest_address (ct))) * sizeof(uint32_t));
-}
-inline
-uint8_t*& card_table_highest_address (uint32_t* c_table)
-{
-    return ((card_table_info*)((uint8_t*)c_table - sizeof (card_table_info)))->highest_address;
-}
-inline
-short*& card_table_brick_table (uint32_t* c_table)
-{
-    return ((card_table_info*)((uint8_t*)c_table - sizeof (card_table_info)))->brick_table;
-}
-#ifdef CARD_BUNDLE
-inline
-uint32_t*& card_table_card_bundle_table (uint32_t* c_table)
-{
-    return ((card_table_info*)((uint8_t*)c_table - sizeof (card_table_info)))->card_bundle_table;
-}
-#endif //CARD_BUNDLE
-#ifdef BACKGROUND_GC
-inline
-uint32_t*& card_table_mark_array (uint32_t* c_table)
-{
-    return ((card_table_info*)((uint8_t*)c_table - sizeof (card_table_info)))->mark_array;
-}
-#ifdef HOST_64BIT
-#define mark_bit_pitch ((size_t)16)
-#else
-#define mark_bit_pitch ((size_t)8)
-#endif // HOST_64BIT
-#define mark_word_width ((size_t)32)
-#define mark_word_size (mark_word_width * mark_bit_pitch)
-inline
-uint8_t* align_on_mark_bit (uint8_t* add)
-{
-    return (uint8_t*)((size_t)(add + (mark_bit_pitch - 1)) & ~(mark_bit_pitch - 1));
-}
-inline
-uint8_t* align_lower_mark_bit (uint8_t* add)
-{
-    return (uint8_t*)((size_t)(add) & ~(mark_bit_pitch - 1));
-}
-inline
-BOOL is_aligned_on_mark_word (uint8_t* add)
-{
-    return ((size_t)add == ((size_t)(add) & ~(mark_word_size - 1)));
-}
-inline
-uint8_t* align_on_mark_word (uint8_t* add)
-{
-    return (uint8_t*)((size_t)(add + mark_word_size - 1) & ~(mark_word_size - 1));
-}
-inline
-uint8_t* align_lower_mark_word (uint8_t* add)
-{
-    return (uint8_t*)((size_t)(add) & ~(mark_word_size - 1));
-}
-inline
-size_t mark_bit_of (uint8_t* add)
-{
-    return ((size_t)add / mark_bit_pitch);
-}
-inline
-unsigned int mark_bit_bit (size_t mark_bit)
-{
-    return (unsigned int)(mark_bit % mark_word_width);
-}
-inline
-size_t mark_bit_word (size_t mark_bit)
-{
-    return (mark_bit / mark_word_width);
-}
-inline
-size_t mark_word_of (uint8_t* add)
-{
-    return ((size_t)add) / mark_word_size;
-}
-uint8_t* mark_word_address (size_t wd)
-{
-    return (uint8_t*)(wd*mark_word_size);
-}
-uint8_t* mark_bit_address (size_t mark_bit)
-{
-    return (uint8_t*)(mark_bit*mark_bit_pitch);
-}
-inline
-size_t mark_bit_bit_of (uint8_t* add)
-{
-    return  (((size_t)add / mark_bit_pitch) % mark_word_width);
-}
-inline
-unsigned int gc_heap::mark_array_marked(uint8_t* add)
-{
-    return mark_array [mark_word_of (add)] & (1 << mark_bit_bit_of (add));
-}
-inline
-BOOL gc_heap::is_mark_bit_set (uint8_t* add)
-{
-    return (mark_array [mark_word_of (add)] & (1 << mark_bit_bit_of (add)));
-}
-inline
-void gc_heap::mark_array_set_marked (uint8_t* add)
-{
-    size_t index = mark_word_of (add);
-    uint32_t val = (1 << mark_bit_bit_of (add));
-#ifdef MULTIPLE_HEAPS
-    Interlocked::Or (&(mark_array [index]), val);
-#else
-    mark_array [index] |= val;
-#endif
-}
-inline
-void gc_heap::mark_array_clear_marked (uint8_t* add)
-{
-    mark_array [mark_word_of (add)] &= ~(1 << mark_bit_bit_of (add));
-}
-size_t size_mark_array_of (uint8_t* from, uint8_t* end)
-{
-    assert (((size_t)from & ((mark_word_size)-1)) == 0);
-    assert (((size_t)end  & ((mark_word_size)-1)) == 0);
-    return sizeof (uint32_t)*(((end - from) / mark_word_size));
-}
-uint32_t* translate_mark_array (uint32_t* ma)
-{
-    return (uint32_t*)((uint8_t*)ma - size_mark_array_of (0, g_gc_lowest_address));
-}
-#ifdef FEATURE_BASICFREEZE
-void gc_heap::clear_mark_array (uint8_t* from, uint8_t* end)
-{
-    assert (gc_can_use_concurrent);
-    assert (end == align_on_mark_word (end));
-    uint8_t* current_lowest_address = background_saved_lowest_address;
-    uint8_t* current_highest_address = background_saved_highest_address;
-    if ((end <= current_highest_address) && (from >= current_lowest_address))
-    {
-        size_t beg_word = mark_word_of (align_on_mark_word (from));
-        size_t end_word = mark_word_of (align_on_mark_word (end));
-        dprintf (3, ("Calling clearing mark array [%zx, %zx[ for addresses [%zx, %zx[",
-                     (size_t)mark_word_address (beg_word),
-                     (size_t)mark_word_address (end_word),
-                     (size_t)from, (size_t)end));
-        uint8_t* op = from;
-        while (op < mark_word_address (beg_word))
-        {
-            mark_array_clear_marked (op);
-            op += mark_bit_pitch;
-        }
-        memset (&mark_array[beg_word], 0, (end_word - beg_word)*sizeof (uint32_t));
-#ifdef _DEBUG
-        size_t  markw = mark_word_of (align_on_mark_word (from));
-        size_t  markw_end = mark_word_of (align_on_mark_word (end));
-        while (markw < markw_end)
-        {
-            assert (!(mark_array [markw]));
-            markw++;
-        }
-        uint8_t* p = mark_word_address (markw_end);
-        while (p < end)
-        {
-            assert (!(mark_array_marked (p)));
-            p++;
-        }
-#endif //_DEBUG
-    }
-}
-#endif // FEATURE_BASICFREEZE
-#endif //BACKGROUND_GC
-inline
-uint32_t*& card_table_next (uint32_t* c_table)
-{
-    return ((card_table_info*)((uint8_t*)c_table - sizeof (card_table_info)))->next_card_table;
-}
-inline
-size_t& card_table_size (uint32_t* c_table)
-{
-    return ((card_table_info*)((uint8_t*)c_table - sizeof (card_table_info)))->size;
-}
-void own_card_table (uint32_t* c_table)
-{
-    card_table_refcount (c_table) += 1;
-}
-void destroy_card_table (uint32_t* c_table);
-void delete_next_card_table (uint32_t* c_table)
-{
-    uint32_t* n_table = card_table_next (c_table);
-    if (n_table)
-    {
-        if (card_table_next (n_table))
-        {
-            delete_next_card_table (n_table);
-        }
-        if (card_table_refcount (n_table) == 0)
-        {
-            destroy_card_table (n_table);
-            card_table_next (c_table) = 0;
-        }
-    }
-}
-void release_card_table (uint32_t* c_table)
-{
-    assert (card_table_refcount (c_table) >0);
-    card_table_refcount (c_table) -= 1;
-    if (card_table_refcount (c_table) == 0)
-    {
-        delete_next_card_table (c_table);
-        if (card_table_next (c_table) == 0)
-        {
-            destroy_card_table (c_table);
-            if (&g_gc_card_table[card_word (gcard_of(g_gc_lowest_address))] == c_table)
-            {
-                g_gc_card_table = 0;
-#ifdef FEATURE_MANUALLY_MANAGED_CARD_BUNDLES
-                g_gc_card_bundle_table = 0;
-#endif
-#ifdef FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-                SoftwareWriteWatch::StaticClose();
-#endif // FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-            }
-            else
-            {
-                uint32_t* p_table = &g_gc_card_table[card_word (gcard_of(g_gc_lowest_address))];
-                if (p_table)
-                {
-                    while (p_table && (card_table_next (p_table) != c_table))
-                        p_table = card_table_next (p_table);
-                    card_table_next (p_table) = 0;
-                }
-            }
-        }
-    }
-}
-void destroy_card_table (uint32_t* c_table)
-{
-    size_t size = card_table_size(c_table);
-    gc_heap::destroy_card_table_helper (c_table);
-    GCToOSInterface::VirtualRelease (&card_table_refcount(c_table), size);
-    dprintf (2, ("Table Virtual Free : %zx", (size_t)&card_table_refcount(c_table)));
-}
-void gc_heap::destroy_card_table_helper (uint32_t* c_table)
-{
-    uint8_t* lowest = card_table_lowest_address (c_table);
-    uint8_t* highest = card_table_highest_address (c_table);
-    get_card_table_element_layout(lowest, highest, card_table_element_layout);
-    size_t result = card_table_element_layout[seg_mapping_table_element + 1];
-    gc_heap::reduce_committed_bytes (&card_table_refcount(c_table), result, recorded_committed_bookkeeping_bucket, -1, true);
-}
-void gc_heap::get_card_table_element_sizes (uint8_t* start, uint8_t* end, size_t sizes[total_bookkeeping_elements])
-{
-    memset (sizes, 0, sizeof(size_t) * total_bookkeeping_elements);
-    sizes[card_table_element] = size_card_of (start, end);
-    sizes[brick_table_element] = size_brick_of (start, end);
-#ifdef CARD_BUNDLE
-    if (can_use_write_watch_for_card_table())
-    {
-        sizes[card_bundle_table_element] = size_card_bundle_of (start, end);
-    }
-#endif //CARD_BUNDLE
-#if defined(FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP) && defined (BACKGROUND_GC)
-    if (gc_can_use_concurrent)
-    {
-        sizes[software_write_watch_table_element] = SoftwareWriteWatch::GetTableByteSize(start, end);
-    }
-#endif //FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP && BACKGROUND_GC
-#ifdef USE_REGIONS
-    sizes[region_to_generation_table_element] = size_region_to_generation_table_of (start, end);
-#endif //USE_REGIONS
-    sizes[seg_mapping_table_element] = size_seg_mapping_table_of (start, end);
-#ifdef BACKGROUND_GC
-    if (gc_can_use_concurrent)
-    {
-        sizes[mark_array_element] = size_mark_array_of (start, end);
-    }
-#endif //BACKGROUND_GC
-}
-void gc_heap::get_card_table_element_layout (uint8_t* start, uint8_t* end, size_t layout[total_bookkeeping_elements + 1])
-{
-    size_t sizes[total_bookkeeping_elements];
-    get_card_table_element_sizes(start, end, sizes);
-    const size_t alignment[total_bookkeeping_elements + 1] =
-    {
-        sizeof (uint32_t), // card_table_element
-        sizeof (short),    // brick_table_element
-#ifdef CARD_BUNDLE
-        sizeof (uint32_t), // card_bundle_table_element
-#endif //CARD_BUNDLE
-#ifdef FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-        sizeof(size_t),    // software_write_watch_table_element
-#endif //FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-#ifdef USE_REGIONS
-        sizeof (uint8_t),  // region_to_generation_table_element
-#endif //USE_REGIONS
-        sizeof (uint8_t*), // seg_mapping_table_element
-#ifdef BACKGROUND_GC
-        OS_PAGE_SIZE,      // mark_array_element
-#endif //BACKGROUND_GC
-        OS_PAGE_SIZE       // total_bookkeeping_elements
-    };
-    layout[card_table_element] = ALIGN_UP(sizeof(card_table_info), alignment[card_table_element]);
-    for (int element = brick_table_element; element <= total_bookkeeping_elements; element++)
-    {
-        layout[element] = layout[element - 1] + sizes[element - 1];
-        if ((element != total_bookkeeping_elements) && (sizes[element] != 0))
-        {
-            layout[element] = ALIGN_UP(layout[element], alignment[element]);
-        }
-    }
-}
-#ifdef USE_REGIONS
-bool gc_heap::on_used_changed (uint8_t* new_used)
-{
-#if defined(WRITE_BARRIER_CHECK) && !defined (SERVER_GC)
-    if (GCConfig::GetHeapVerifyLevel() & GCConfig::HEAPVERIFY_BARRIERCHECK)
-    {
-        size_t shadow_covered = g_GCShadowEnd - g_GCShadow;
-        size_t used_heap_range = new_used - g_gc_lowest_address;
-        if (used_heap_range > shadow_covered)
-        {
-            size_t extra = used_heap_range - shadow_covered;
-            if (!GCToOSInterface::VirtualCommit (g_GCShadowEnd, extra))
-            {
-                _ASSERTE(!"Not enough memory to run HeapVerify level 2");
-                deleteGCShadow();
-            }
-            else
-            {
-                g_GCShadowEnd += extra;
-            }
-        }
-    }
-#endif //WRITE_BARRIER_CHECK && !SERVER_GC
-    if (new_used > bookkeeping_covered_committed)
-    {
-        bool speculative_commit_tried = false;
-#ifdef STRESS_REGIONS
-        if (gc_rand::get_rand(10) > 3)
-        {
-            dprintf (REGIONS_LOG, ("skipping speculative commit under stress regions"));
-            speculative_commit_tried = true;
-        }
-#endif
-        while (true)
-        {
-            uint8_t* new_bookkeeping_covered_committed = nullptr;
-            if (speculative_commit_tried)
-            {
-                new_bookkeeping_covered_committed = new_used;
-            }
-            else
-            {
-                uint64_t committed_size = (uint64_t)(bookkeeping_covered_committed - g_gc_lowest_address);
-                uint64_t total_size = (uint64_t)(g_gc_highest_address - g_gc_lowest_address);
-                assert (committed_size <= total_size);
-                assert (committed_size < (UINT64_MAX / 2));
-                uint64_t new_committed_size = min(committed_size * 2, total_size);
-                assert ((UINT64_MAX - new_committed_size) > (uint64_t)g_gc_lowest_address);
-                uint8_t* double_commit = g_gc_lowest_address + new_committed_size;
-                new_bookkeeping_covered_committed = max(double_commit, new_used);
-                dprintf (REGIONS_LOG, ("committed_size                           = %zd", committed_size));
-                dprintf (REGIONS_LOG, ("total_size                               = %zd", total_size));
-                dprintf (REGIONS_LOG, ("new_committed_size                       = %zd", new_committed_size));
-                dprintf (REGIONS_LOG, ("double_commit                            = %p", double_commit));
-            }
-            dprintf (REGIONS_LOG, ("bookkeeping_covered_committed     = %p", bookkeeping_covered_committed));
-            dprintf (REGIONS_LOG, ("new_bookkeeping_covered_committed = %p", new_bookkeeping_covered_committed));
-            if (inplace_commit_card_table (bookkeeping_covered_committed, new_bookkeeping_covered_committed))
-            {
-                bookkeeping_covered_committed = new_bookkeeping_covered_committed;
-                break;
-            }
-            else
-            {
-                if (new_bookkeeping_covered_committed == new_used)
-                {
-                    dprintf (REGIONS_LOG, ("The minimal commit for the GC bookkeeping data structure failed, giving up"));
-                    return false;
-                }
-                dprintf (REGIONS_LOG, ("The speculative commit for the GC bookkeeping data structure failed, retry for minimal commit"));
-                speculative_commit_tried = true;
-            }
-        }
-    }
-    return true;
-}
-bool gc_heap::get_card_table_commit_layout (uint8_t* from, uint8_t* to,
-                    uint8_t* commit_begins[total_bookkeeping_elements],
-                    size_t commit_sizes[total_bookkeeping_elements],
-                    size_t new_sizes[total_bookkeeping_elements])
-{
-    uint8_t* start = g_gc_lowest_address;
-    uint8_t* end = g_gc_highest_address;
-    bool initial_commit = (from == start);
-    bool additional_commit = !initial_commit && (to > from);
-    if (!initial_commit && !additional_commit)
-    {
-        return false;
-    }
-#ifdef _DEBUG
-    size_t offsets[total_bookkeeping_elements + 1];
-    get_card_table_element_layout(start, end, offsets);
-    dprintf (REGIONS_LOG, ("layout"));
-    for (int i = card_table_element; i <= total_bookkeeping_elements; i++)
-    {
-        assert (offsets[i] == card_table_element_layout[i]);
-        dprintf (REGIONS_LOG, ("%zd", card_table_element_layout[i]));
-    }
-#endif //_DEBUG
-    get_card_table_element_sizes (start, to, new_sizes);
-#ifdef _DEBUG
-    dprintf (REGIONS_LOG, ("new_sizes"));
-    for (int i = card_table_element; i < total_bookkeeping_elements; i++)
-    {
-        dprintf (REGIONS_LOG, ("%zd", new_sizes[i]));
-    }
-    if (additional_commit)
-    {
-        size_t current_sizes[total_bookkeeping_elements];
-        get_card_table_element_sizes (start, from, current_sizes);
-        dprintf (REGIONS_LOG, ("old_sizes"));
-        for (int i = card_table_element; i < total_bookkeeping_elements; i++)
-        {
-            assert (current_sizes[i] == bookkeeping_sizes[i]);
-            dprintf (REGIONS_LOG, ("%zd", bookkeeping_sizes[i]));
-        }
-    }
-#endif //_DEBUG
-    for (int i = card_table_element; i <= seg_mapping_table_element; i++)
-    {
-        uint8_t* required_begin = nullptr;
-        uint8_t* required_end = nullptr;
-        uint8_t* commit_begin = nullptr;
-        uint8_t* commit_end = nullptr;
-        if (initial_commit)
-        {
-            required_begin = bookkeeping_start + ((i == card_table_element) ? 0 : card_table_element_layout[i]);
-            required_end = bookkeeping_start + card_table_element_layout[i] + new_sizes[i];
-            commit_begin = align_lower_page(required_begin);
-        }
-        else
-        {
-            assert (additional_commit);
-            required_begin = bookkeeping_start + card_table_element_layout[i] + bookkeeping_sizes[i];
-            required_end = required_begin + new_sizes[i] - bookkeeping_sizes[i];
-            commit_begin = align_on_page(required_begin);
-        }
-        assert (required_begin <= required_end);
-        commit_end = align_on_page(required_end);
-        commit_end = min (commit_end, align_lower_page(bookkeeping_start + card_table_element_layout[i + 1]));
-        commit_begin = min (commit_begin, commit_end);
-        assert (commit_begin <= commit_end);
-        dprintf (REGIONS_LOG, ("required = [%p, %p), size = %zd", required_begin, required_end, required_end - required_begin));
-        dprintf (REGIONS_LOG, ("commit   = [%p, %p), size = %zd", commit_begin, commit_end, commit_end - commit_begin));
-        commit_begins[i] = commit_begin;
-        commit_sizes[i] = (size_t)(commit_end - commit_begin);
-    }
-    dprintf (REGIONS_LOG, ("---------------------------------------"));
-    return true;
-}
-bool gc_heap::inplace_commit_card_table (uint8_t* from, uint8_t* to)
-{
-    dprintf (REGIONS_LOG, ("inplace_commit_card_table(%p, %p), size = %zd", from, to, to - from));
-    uint8_t* start = g_gc_lowest_address;
-    uint8_t* end = g_gc_highest_address;
-    uint8_t* commit_begins[total_bookkeeping_elements];
-    size_t commit_sizes[total_bookkeeping_elements];
-    size_t new_sizes[total_bookkeeping_elements];
-    if (!get_card_table_commit_layout(from, to, commit_begins, commit_sizes, new_sizes))
-    {
-        return true;
-    }
-    int failed_commit = -1;
-    for (int i = card_table_element; i <= seg_mapping_table_element; i++)
-    {
-        bool succeed;
-        if (commit_sizes[i] > 0)
-        {
-            succeed = virtual_commit (commit_begins[i], commit_sizes[i], recorded_committed_bookkeeping_bucket);
-            if (!succeed)
-            {
-                failed_commit = i;
-                break;
-            }
-        }
-    }
-    if (failed_commit == -1)
-    {
-        for (int i = card_table_element; i < total_bookkeeping_elements; i++)
-        {
-            bookkeeping_sizes[i] = new_sizes[i];
-        }
-    }
-    else
-    {
-        for (int i = card_table_element; i < failed_commit; i++)
-        {
-            bool succeed;
-            if (commit_sizes[i] > 0)
-            {
-                succeed = virtual_decommit (commit_begins[i], commit_sizes[i], recorded_committed_bookkeeping_bucket);
-                assert (succeed);
-            }
-        }
-        return false;
-    }
-    return true;
-}
-#endif //USE_REGIONS
-uint32_t* gc_heap::make_card_table (uint8_t* start, uint8_t* end)
-{
-    assert (g_gc_lowest_address == start);
-    assert (g_gc_highest_address == end);
-    uint32_t virtual_reserve_flags = VirtualReserveFlags::None;
-#ifdef CARD_BUNDLE
-    if (can_use_write_watch_for_card_table())
-    {
-#ifndef FEATURE_MANUALLY_MANAGED_CARD_BUNDLES
-        virtual_reserve_flags |= VirtualReserveFlags::WriteWatch;
-#endif
-    }
-#endif //CARD_BUNDLE
-    get_card_table_element_layout(start, end, card_table_element_layout);
-    size_t alloc_size = card_table_element_layout[total_bookkeeping_elements];
-    uint8_t* mem = (uint8_t*)GCToOSInterface::VirtualReserve (alloc_size, 0, virtual_reserve_flags);
-    bookkeeping_start = mem;
-    if (!mem)
-        return 0;
-    dprintf (2, ("Init - Card table alloc for %zd bytes: [%zx, %zx[",
-                 alloc_size, (size_t)mem, (size_t)(mem+alloc_size)));
-#ifdef USE_REGIONS
-    if (!inplace_commit_card_table (g_gc_lowest_address, global_region_allocator.get_left_used_unsafe()))
-    {
-        dprintf (1, ("Card table commit failed"));
-        GCToOSInterface::VirtualRelease (mem, alloc_size);
-        return 0;
-    }
-    bookkeeping_covered_committed = global_region_allocator.get_left_used_unsafe();
-#else
-    size_t commit_size = card_table_element_layout[seg_mapping_table_element + 1];
-    if (!virtual_commit (mem, commit_size, recorded_committed_bookkeeping_bucket))
-    {
-        dprintf (1, ("Card table commit failed"));
-        GCToOSInterface::VirtualRelease (mem, alloc_size);
-        return 0;
-    }
-#endif //USE_REGIONS
-    uint32_t* ct = (uint32_t*)(mem + card_table_element_layout[card_table_element]);
-    card_table_refcount (ct) = 0;
-    card_table_lowest_address (ct) = start;
-    card_table_highest_address (ct) = end;
-    card_table_brick_table (ct) = (short*)(mem + card_table_element_layout[brick_table_element]);
-    card_table_size (ct) = alloc_size;
-    card_table_next (ct) = 0;
-#ifdef CARD_BUNDLE
-    card_table_card_bundle_table (ct) = (uint32_t*)(mem + card_table_element_layout[card_bundle_table_element]);
-#ifdef FEATURE_MANUALLY_MANAGED_CARD_BUNDLES
-    g_gc_card_bundle_table = translate_card_bundle_table(card_table_card_bundle_table(ct), g_gc_lowest_address);
-#endif
-#endif //CARD_BUNDLE
-#if defined(FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP) && defined (BACKGROUND_GC)
-    if (gc_can_use_concurrent)
-    {
-        SoftwareWriteWatch::InitializeUntranslatedTable(mem + card_table_element_layout[software_write_watch_table_element], start);
-    }
-#endif //FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP && BACKGROUND_GC
-#ifdef USE_REGIONS
-    map_region_to_generation = (region_info*)(mem + card_table_element_layout[region_to_generation_table_element]);
-    map_region_to_generation_skewed = map_region_to_generation - size_region_to_generation_table_of (0, g_gc_lowest_address);
-#endif //USE_REGIONS
-    seg_mapping_table = (seg_mapping*)(mem + card_table_element_layout[seg_mapping_table_element]);
-    seg_mapping_table = (seg_mapping*)((uint8_t*)seg_mapping_table -
-                                        size_seg_mapping_table_of (0, (align_lower_segment (g_gc_lowest_address))));
-#ifdef BACKGROUND_GC
-    if (gc_can_use_concurrent)
-        card_table_mark_array (ct) = (uint32_t*)(mem + card_table_element_layout[mark_array_element]);
-    else
-        card_table_mark_array (ct) = NULL;
-#endif //BACKGROUND_GC
-    return translate_card_table(ct);
-}
-void gc_heap::set_fgm_result (failure_get_memory f, size_t s, BOOL loh_p)
-{
-#ifdef MULTIPLE_HEAPS
-    for (int hn = 0; hn < gc_heap::n_heaps; hn++)
-    {
-        gc_heap* hp = gc_heap::g_heaps [hn];
-        hp->fgm_result.set_fgm (f, s, loh_p);
-    }
-#else //MULTIPLE_HEAPS
-    fgm_result.set_fgm (f, s, loh_p);
-#endif //MULTIPLE_HEAPS
-}
-#ifndef USE_REGIONS
-int gc_heap::grow_brick_card_tables (uint8_t* start,
-                                     uint8_t* end,
-                                     size_t size,
-                                     heap_segment* new_seg,
-                                     gc_heap* hp,
-                                     BOOL uoh_p)
-{
-    uint8_t* la = g_gc_lowest_address;
-    uint8_t* ha = g_gc_highest_address;
-    uint8_t* saved_g_lowest_address = min (start, g_gc_lowest_address);
-    uint8_t* saved_g_highest_address = max (end, g_gc_highest_address);
-    seg_mapping* new_seg_mapping_table = nullptr;
-#ifdef BACKGROUND_GC
-    size_t logging_ma_commit_size = size_mark_array_of (0, (uint8_t*)size);
-#endif //BACKGROUND_GC
-    if ((la != saved_g_lowest_address ) || (ha != saved_g_highest_address))
-    {
-        {
-            uint8_t* top = (uint8_t*)0 + Align (GCToOSInterface::GetVirtualMemoryMaxAddress());
-            if (top < saved_g_highest_address)
-            {
-                top = saved_g_highest_address;
-            }
-            size_t ps = ha-la;
-#ifdef HOST_64BIT
-            if (ps > (uint64_t)200*1024*1024*1024)
-                ps += (uint64_t)100*1024*1024*1024;
-            else
-#endif // HOST_64BIT
-                ps *= 2;
-            if (saved_g_lowest_address < g_gc_lowest_address)
-            {
-                if (ps > (size_t)g_gc_lowest_address)
-                    saved_g_lowest_address = (uint8_t*)(size_t)OS_PAGE_SIZE;
-                else
-                {
-                    assert (((size_t)g_gc_lowest_address - ps) >= OS_PAGE_SIZE);
-                    saved_g_lowest_address = min (saved_g_lowest_address, (g_gc_lowest_address - ps));
-                }
-            }
-            if (saved_g_highest_address > g_gc_highest_address)
-            {
-                saved_g_highest_address = max ((saved_g_lowest_address + ps), saved_g_highest_address);
-                if (saved_g_highest_address > top)
-                    saved_g_highest_address = top;
-            }
-        }
-        dprintf (GC_TABLE_LOG, ("Growing card table [%zx, %zx[",
-                                (size_t)saved_g_lowest_address,
-                                (size_t)saved_g_highest_address));
-        bool write_barrier_updated = false;
-        uint32_t virtual_reserve_flags = VirtualReserveFlags::None;
-        uint32_t* saved_g_card_table = g_gc_card_table;
-#ifdef FEATURE_MANUALLY_MANAGED_CARD_BUNDLES
-        uint32_t* saved_g_card_bundle_table = g_gc_card_bundle_table;
-#endif
-        get_card_table_element_layout(saved_g_lowest_address, saved_g_highest_address, card_table_element_layout);
-        size_t cb = 0;
-        uint32_t* ct = 0;
-        uint32_t* translated_ct = 0;
-#ifdef CARD_BUNDLE
-        if (can_use_write_watch_for_card_table())
-        {
-            cb = size_card_bundle_of (saved_g_lowest_address, saved_g_highest_address);
-#ifndef FEATURE_MANUALLY_MANAGED_CARD_BUNDLES
-            virtual_reserve_flags |= VirtualReserveFlags::WriteWatch;
-#endif
-        }
-#endif //CARD_BUNDLE
-        size_t alloc_size = card_table_element_layout[total_bookkeeping_elements];
-        uint8_t* mem = (uint8_t*)GCToOSInterface::VirtualReserve (alloc_size, 0, virtual_reserve_flags);
-        if (!mem)
-        {
-            set_fgm_result (fgm_grow_table, alloc_size, uoh_p);
-            goto fail;
-        }
-        dprintf (GC_TABLE_LOG, ("Table alloc for %zd bytes: [%zx, %zx[",
-                                 alloc_size, (size_t)mem, (size_t)((uint8_t*)mem+alloc_size)));
-        {
-            size_t commit_size = card_table_element_layout[seg_mapping_table_element + 1];
-            if (!virtual_commit (mem, commit_size, recorded_committed_bookkeeping_bucket))
-            {
-                dprintf (GC_TABLE_LOG, ("Table commit failed"));
-                set_fgm_result (fgm_commit_table, commit_size, uoh_p);
-                goto fail;
-            }
-        }
-        ct = (uint32_t*)(mem + card_table_element_layout[card_table_element]);
-        card_table_refcount (ct) = 0;
-        card_table_lowest_address (ct) = saved_g_lowest_address;
-        card_table_highest_address (ct) = saved_g_highest_address;
-        card_table_next (ct) = &g_gc_card_table[card_word (gcard_of (la))];
-/*
-        memclr ((uint8_t*)ct,
-                (((saved_g_highest_address - saved_g_lowest_address)*sizeof (uint32_t) /
-                  (card_size * card_word_width))
-                 + sizeof (uint32_t)));
-*/
-        card_table_brick_table (ct) = (short*)(mem + card_table_element_layout[brick_table_element]);
-#ifdef CARD_BUNDLE
-        card_table_card_bundle_table (ct) = (uint32_t*)(mem + card_table_element_layout[card_bundle_table_element]);
-        memset(card_table_card_bundle_table (ct), 0xFF, cb);
-#endif //CARD_BUNDLE
-        new_seg_mapping_table = (seg_mapping*)(mem + card_table_element_layout[seg_mapping_table_element]);
-        new_seg_mapping_table = (seg_mapping*)((uint8_t*)new_seg_mapping_table -
-                                            size_seg_mapping_table_of (0, (align_lower_segment (saved_g_lowest_address))));
-        memcpy(&new_seg_mapping_table[seg_mapping_word_of(g_gc_lowest_address)],
-            &seg_mapping_table[seg_mapping_word_of(g_gc_lowest_address)],
-            size_seg_mapping_table_of(g_gc_lowest_address, g_gc_highest_address));
-#ifdef BACKGROUND_GC
-        if(gc_can_use_concurrent)
-            card_table_mark_array (ct) = (uint32_t*)(mem + card_table_element_layout[mark_array_element]);
-        else
-            card_table_mark_array (ct) = NULL;
-#endif //BACKGROUND_GC
-        translated_ct = translate_card_table (ct);
-#ifdef BACKGROUND_GC
-        dprintf (GC_TABLE_LOG, ("card table: %zx(translated: %zx), seg map: %zx, mark array: %zx",
-            (size_t)ct, (size_t)translated_ct, (size_t)new_seg_mapping_table, (size_t)card_table_mark_array (ct)));
-        if (hp->is_bgc_in_progress())
-        {
-            dprintf (GC_TABLE_LOG, ("new low: %p, new high: %p, latest mark array is %p(translate: %p)",
-                                    saved_g_lowest_address, saved_g_highest_address,
-                                    card_table_mark_array (ct),
-                                    translate_mark_array (card_table_mark_array (ct))));
-            uint32_t* new_mark_array = (uint32_t*)((uint8_t*)card_table_mark_array (ct) - size_mark_array_of (0, saved_g_lowest_address));
-            if (!commit_new_mark_array_global (new_mark_array))
-            {
-                dprintf (GC_TABLE_LOG, ("failed to commit portions in the mark array for existing segments"));
-                set_fgm_result (fgm_commit_table, logging_ma_commit_size, uoh_p);
-                goto fail;
-            }
-            if (!commit_mark_array_new_seg (hp, new_seg, translated_ct, saved_g_lowest_address))
-            {
-                dprintf (GC_TABLE_LOG, ("failed to commit mark array for the new seg"));
-                set_fgm_result (fgm_commit_table, logging_ma_commit_size, uoh_p);
-                goto fail;
-            }
-        }
-        else
-        {
-            clear_commit_flag_global();
-        }
-#endif //BACKGROUND_GC
-#if defined(FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP) && defined(BACKGROUND_GC)
-        if (gc_can_use_concurrent)
-        {
-            bool is_runtime_suspended = GCToEEInterface::IsGCThread();
-            if (!is_runtime_suspended)
-            {
-                suspend_EE();
-            }
-            g_gc_card_table = translated_ct;
-#ifdef FEATURE_MANUALLY_MANAGED_CARD_BUNDLES
-            g_gc_card_bundle_table = translate_card_bundle_table(card_table_card_bundle_table(ct), saved_g_lowest_address);
-#endif
-            SoftwareWriteWatch::SetResizedUntranslatedTable(
-                mem + card_table_element_layout[software_write_watch_table_element],
-                saved_g_lowest_address,
-                saved_g_highest_address);
-            seg_mapping_table = new_seg_mapping_table;
-            g_gc_lowest_address = saved_g_lowest_address;
-            g_gc_highest_address = saved_g_highest_address;
-            stomp_write_barrier_resize(true, la != saved_g_lowest_address);
-            write_barrier_updated = true;
-            if (!is_runtime_suspended)
-            {
-                restart_EE();
-            }
-        }
-        else
-#endif //FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP && BACKGROUND_GC
-        {
-            g_gc_card_table = translated_ct;
-#ifdef FEATURE_MANUALLY_MANAGED_CARD_BUNDLES
-            g_gc_card_bundle_table = translate_card_bundle_table(card_table_card_bundle_table(ct), saved_g_lowest_address);
-#endif
-        }
-        if (!write_barrier_updated)
-        {
-            seg_mapping_table = new_seg_mapping_table;
-            GCToOSInterface::FlushProcessWriteBuffers();
-            g_gc_lowest_address = saved_g_lowest_address;
-            g_gc_highest_address = saved_g_highest_address;
-            stomp_write_barrier_resize(GCToEEInterface::IsGCThread(), la != saved_g_lowest_address);
-        }
-        return 0;
-fail:
-        if (mem)
-        {
-            assert(g_gc_card_table == saved_g_card_table);
-#ifdef FEATURE_MANUALLY_MANAGED_CARD_BUNDLES
-            assert(g_gc_card_bundle_table  == saved_g_card_bundle_table);
-#endif
-            if (!GCToOSInterface::VirtualRelease (mem, alloc_size))
-            {
-                dprintf (GC_TABLE_LOG, ("GCToOSInterface::VirtualRelease failed"));
-                assert (!"release failed");
-            }
-        }
-        return -1;
-    }
-    else
-    {
-#ifdef BACKGROUND_GC
-        if (hp->is_bgc_in_progress())
-        {
-            dprintf (GC_TABLE_LOG, ("in range new seg %p, mark_array is %p", new_seg, hp->mark_array));
-            if (!commit_mark_array_new_seg (hp, new_seg))
-            {
-                dprintf (GC_TABLE_LOG, ("failed to commit mark array for the new seg in range"));
-                set_fgm_result (fgm_commit_table, logging_ma_commit_size, uoh_p);
-                return -1;
-            }
-        }
-#endif //BACKGROUND_GC
-    }
-    return 0;
-}
-void gc_heap::copy_brick_card_range (uint8_t* la, uint32_t* old_card_table,
-                                     short* old_brick_table,
-                                     uint8_t* start, uint8_t* end)
-{
-    ptrdiff_t brick_offset = brick_of (start) - brick_of (la);
-    dprintf (2, ("copying tables for range [%zx %zx[", (size_t)start, (size_t)end));
-    short* brick_start = &brick_table [brick_of (start)];
-    if (old_brick_table)
-    {
-        memcpy (brick_start, &old_brick_table[brick_offset],
-                size_brick_of (start, end));
-    }
-    uint32_t* old_ct = &old_card_table[card_word (card_of (la))];
-#ifdef BACKGROUND_GC
-    if (gc_heap::background_running_p())
-    {
-        uint32_t* old_mark_array = card_table_mark_array (old_ct);
-        if ((card_table_highest_address (old_ct) >= start) &&
-            (card_table_lowest_address (old_ct) <= end))
-        {
-            if ((background_saved_highest_address >= start) &&
-                (background_saved_lowest_address <= end))
-            {
-                uint8_t* m_start = max (background_saved_lowest_address, start);
-                uint8_t* m_end = min (background_saved_highest_address, end);
-                memcpy (&mark_array[mark_word_of (m_start)],
-                        &old_mark_array[mark_word_of (m_start) - mark_word_of (la)],
-                        size_mark_array_of (m_start, m_end));
-            }
-        }
-        else
-        {
-            assert (old_brick_table == 0);
-        }
-    }
-#endif //BACKGROUND_GC
-    uint32_t* ct = card_table_next (&card_table[card_word (card_of(lowest_address))]);
-    assert (ct);
-    while (card_table_next (old_ct) != ct)
-    {
-        if ((card_table_highest_address (ct) >= end) &&
-            (card_table_lowest_address (ct) <= start))
-        {
-            size_t start_word = card_word (card_of (start));
-            uint32_t* dest = &card_table[start_word];
-            uint32_t* src = &((translate_card_table (ct))[start_word]);
-            ptrdiff_t count = count_card_of (start, end);
-            for (int x = 0; x < count; x++)
-            {
-                *dest |= *src;
-#ifdef FEATURE_MANUALLY_MANAGED_CARD_BUNDLES
-                if (*src != 0)
-                {
-                    card_bundle_set(cardw_card_bundle(start_word+x));
-                }
-#endif
-                dest++;
-                src++;
-            }
-        }
-        ct = card_table_next (ct);
-    }
-}
-void gc_heap::copy_brick_card_table()
-{
-    uint32_t* old_card_table = card_table;
-    short* old_brick_table = brick_table;
-    uint8_t* la = lowest_address;
-#ifdef _DEBUG
-    uint8_t* ha = highest_address;
-    assert (la == card_table_lowest_address (&old_card_table[card_word (card_of (la))]));
-    assert (ha == card_table_highest_address (&old_card_table[card_word (card_of (la))]));
-#endif //_DEBUG
-    /* todo: Need a global lock for this */
-    uint32_t* ct = &g_gc_card_table[card_word (gcard_of (g_gc_lowest_address))];
-    own_card_table (ct);
-    card_table = translate_card_table (ct);
-    bookkeeping_start = (uint8_t*)ct - sizeof(card_table_info);
-    card_table_size(ct) = card_table_element_layout[total_bookkeeping_elements];
-    /* End of global lock */
-    highest_address = card_table_highest_address (ct);
-    lowest_address = card_table_lowest_address (ct);
-    brick_table = card_table_brick_table (ct);
-#ifdef BACKGROUND_GC
-    if (gc_can_use_concurrent)
-    {
-        mark_array = translate_mark_array (card_table_mark_array (ct));
-        assert (mark_word_of (g_gc_highest_address) ==
-            mark_word_of (align_on_mark_word (g_gc_highest_address)));
-    }
-    else
-        mark_array = NULL;
-#endif //BACKGROUND_GC
-#ifdef CARD_BUNDLE
-    card_bundle_table = translate_card_bundle_table (card_table_card_bundle_table (ct), g_gc_lowest_address);
-    assert (&card_bundle_table [card_bundle_word (cardw_card_bundle (card_word (card_of (g_gc_lowest_address))))] ==
-            card_table_card_bundle_table (ct));
-    if (card_bundles_enabled())
-    {
-        card_bundles_set (cardw_card_bundle (card_word (card_of (lowest_address))),
-                          cardw_card_bundle (align_cardw_on_bundle (card_word (card_of (highest_address)))));
-    }
-#ifdef MULTIPLE_HEAPS
-    uint64_t th = (uint64_t)MH_TH_CARD_BUNDLE*gc_heap::n_heaps;
-#else
-    uint64_t th = (uint64_t)SH_TH_CARD_BUNDLE;
-#endif //MULTIPLE_HEAPS
-    if (reserved_memory >= th)
-    {
-        enable_card_bundles();
-    }
-#endif //CARD_BUNDLE
-    for (int i = get_start_generation_index(); i < total_generation_count; i++)
-    {
-        heap_segment* seg = generation_start_segment (generation_of (i));
-        while (seg)
-        {
-            if (heap_segment_read_only_p (seg) && !heap_segment_in_range_p (seg))
-            {
-                if ((heap_segment_reserved (seg) > lowest_address) &&
-                    (heap_segment_mem (seg) < highest_address))
-                {
-                    set_ro_segment_in_range (seg);
-                }
-            }
-            else
-            {
-                uint8_t* end = align_on_page (heap_segment_allocated (seg));
-                copy_brick_card_range (la, old_card_table,
-                    (i < uoh_start_generation) ? old_brick_table : NULL,
-                    align_lower_page (heap_segment_mem (seg)),
-                    end);
-            }
-            seg = heap_segment_next (seg);
-        }
-    }
-    release_card_table (&old_card_table[card_word (card_of(la))]);
-}
-void gc_heap::copy_brick_card_table_on_growth ()
-{
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < gc_heap::n_heaps; i++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[i];
-#else //MULTIPLE_HEAPS
-    {
-        gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-        if (g_gc_card_table != hp->card_table)
-        {
-            hp->copy_brick_card_table ();
-        }
-    }
-}
-#endif //!USE_REGIONS
-#ifdef FEATURE_BASICFREEZE
-BOOL gc_heap::insert_ro_segment (heap_segment* seg)
-{
-#ifdef FEATURE_EVENT_TRACE
-    if (!use_frozen_segments_p)
-        use_frozen_segments_p = true;
-#endif //FEATURE_EVENT_TRACE
-    enter_spin_lock (&gc_heap::gc_lock);
-    if (!gc_heap::seg_table->ensure_space_for_insert ()
-#ifdef BACKGROUND_GC
-        || (is_bgc_in_progress() && !commit_mark_array_new_seg(__this, seg))
-#endif //BACKGROUND_GC
-        )
-    {
-        leave_spin_lock(&gc_heap::gc_lock);
-        return FALSE;
-    }
-    generation* gen2 = generation_of (max_generation);
-    heap_segment* oldhead = generation_start_segment (gen2);
-    heap_segment_next (seg) = oldhead;
-    generation_start_segment (gen2) = seg;
-#ifdef USE_REGIONS
-    dprintf (REGIONS_LOG, ("setting gen2 start seg to %zx(%p)->%p",
-        (size_t)seg, heap_segment_mem (seg), heap_segment_mem (oldhead)));
-    if (generation_tail_ro_region (gen2) == 0)
-    {
-        dprintf (REGIONS_LOG, ("setting gen2 tail ro -> %p", heap_segment_mem (seg)));
-        generation_tail_ro_region (gen2) = seg;
-    }
-#endif //USE_REGIONS
-    seg_table->insert (heap_segment_mem(seg), (size_t)seg);
-    seg_mapping_table_add_ro_segment (seg);
-#ifdef USE_REGIONS
-    assert (!((heap_segment_reserved (seg) > lowest_address) &&
-        (heap_segment_mem (seg) < highest_address)));
-#else
-    if ((heap_segment_reserved (seg) > lowest_address) &&
-        (heap_segment_mem (seg) < highest_address))
-    {
-        set_ro_segment_in_range (seg);
-    }
-#endif //USE_REGIONS
-    FIRE_EVENT(GCCreateSegment_V1, heap_segment_mem(seg), (size_t)(heap_segment_reserved (seg) - heap_segment_mem(seg)), gc_etw_segment_read_only_heap);
-    leave_spin_lock (&gc_heap::gc_lock);
-    return TRUE;
-}
-void gc_heap::update_ro_segment (heap_segment* seg, uint8_t* allocated, uint8_t* committed)
-{
-    enter_spin_lock (&gc_heap::gc_lock);
-    assert (heap_segment_read_only_p (seg));
-    assert (allocated <= committed);
-    assert (committed <= heap_segment_reserved (seg));
-    heap_segment_allocated (seg) = allocated;
-    heap_segment_committed (seg) = committed;
-    leave_spin_lock (&gc_heap::gc_lock);
-}
-void gc_heap::remove_ro_segment (heap_segment* seg)
-{
-#ifdef BACKGROUND_GC
-    if (gc_can_use_concurrent)
-    {
-        if ((seg->flags & heap_segment_flags_ma_committed) || (seg->flags & heap_segment_flags_ma_pcommitted))
-        {
-            seg_clear_mark_array_bits_soh (seg);
-        }
-    }
-#endif //BACKGROUND_GC
-    enter_spin_lock (&gc_heap::gc_lock);
-    seg_table->remove (heap_segment_mem (seg));
-    seg_mapping_table_remove_ro_segment (seg);
-    generation* gen2 = generation_of (max_generation);
-#ifdef USE_REGIONS
-    if (generation_tail_ro_region (gen2) == seg)
-    {
-        generation_tail_ro_region (gen2) = 0;
-    }
-#endif //USE_REGIONS
-    heap_segment* curr_seg = generation_start_segment (gen2);
-    heap_segment* prev_seg = NULL;
-    while (curr_seg && curr_seg != seg)
-    {
-        prev_seg = curr_seg;
-        curr_seg = heap_segment_next (curr_seg);
-    }
-    assert (curr_seg == seg);
-    if (prev_seg)
-        heap_segment_next (prev_seg) = heap_segment_next (curr_seg);
-    else
-        generation_start_segment (gen2) = heap_segment_next (curr_seg);
-    leave_spin_lock (&gc_heap::gc_lock);
-}
-#endif //FEATURE_BASICFREEZE
-uint8_t** make_mark_list (size_t size)
-{
-    uint8_t** mark_list = new (nothrow) uint8_t* [size];
-    return mark_list;
-}
-#define swap(a,b){uint8_t* t; t = a; a = b; b = t;}
-void verify_qsort_array (uint8_t* *low, uint8_t* *high)
-{
-    uint8_t **i = 0;
-    for (i = low+1; i <= high; i++)
-    {
-        if (*i < *(i-1))
-        {
-            FATAL_GC_ERROR();
-        }
-    }
-}
-#ifndef USE_INTROSORT
-void qsort1( uint8_t* *low, uint8_t* *high, unsigned int depth)
-{
-    if (((low + 16) >= high) || (depth > 100))
-    {
-        uint8_t **i, **j;
-        for (i = low+1; i <= high; i++)
-        {
-            uint8_t* val = *i;
-            for (j=i;j >low && val<*(j-1);j--)
-            {
-                *j=*(j-1);
-            }
-            *j=val;
-        }
-    }
-    else
-    {
-        uint8_t *pivot, **left, **right;
-        if (*(low+((high-low)/2)) < *low)
-            swap (*(low+((high-low)/2)), *low);
-        if (*high < *low)
-            swap (*low, *high);
-        if (*high < *(low+((high-low)/2)))
-            swap (*(low+((high-low)/2)), *high);
-        swap (*(low+((high-low)/2)), *(high-1));
-        pivot =  *(high-1);
-        left = low; right = high-1;
-        while (1) {
-            while (*(--right) > pivot);
-            while (*(++left)  < pivot);
-            if (left < right)
-            {
-                swap(*left, *right);
-            }
-            else
-                break;
-        }
-        swap (*left, *(high-1));
-        qsort1(low, left-1, depth+1);
-        qsort1(left+1, high, depth+1);
-    }
-}
-#endif //USE_INTROSORT
-void rqsort1( uint8_t* *low, uint8_t* *high)
-{
-    if ((low + 16) >= high)
-    {
-        uint8_t **i, **j;
-        for (i = low+1; i <= high; i++)
-        {
-            uint8_t* val = *i;
-            for (j=i;j >low && val>*(j-1);j--)
-            {
-                *j=*(j-1);
-            }
-            *j=val;
-        }
-    }
-    else
-    {
-        uint8_t *pivot, **left, **right;
-        if (*(low+((high-low)/2)) > *low)
-            swap (*(low+((high-low)/2)), *low);
-        if (*high > *low)
-            swap (*low, *high);
-        if (*high > *(low+((high-low)/2)))
-            swap (*(low+((high-low)/2)), *high);
-        swap (*(low+((high-low)/2)), *(high-1));
-        pivot =  *(high-1);
-        left = low; right = high-1;
-        while (1) {
-            while (*(--right) < pivot);
-            while (*(++left)  > pivot);
-            if (left < right)
-            {
-                swap(*left, *right);
-            }
-            else
-                break;
-        }
-        swap (*left, *(high-1));
-        rqsort1(low, left-1);
-        rqsort1(left+1, high);
-    }
-}
-#if defined(USE_INTROSORT) || defined(USE_VXSORT)
-class introsort
-{
-private:
-    static const int size_threshold = 64;
-    static const int max_depth = 100;
-inline static void swap_elements(uint8_t** i,uint8_t** j)
-    {
-        uint8_t* t=*i;
-        *i=*j;
-        *j=t;
-    }
-public:
-    static void sort (uint8_t** begin, uint8_t** end, int ignored)
-    {
-        ignored = 0;
-        introsort_loop (begin, end, max_depth);
-        insertionsort (begin, end);
-    }
-private:
-    static void introsort_loop (uint8_t** lo, uint8_t** hi, int depth_limit)
-    {
-        while (hi-lo >= size_threshold)
-        {
-            if (depth_limit == 0)
-            {
-                heapsort (lo, hi);
-                return;
-            }
-            uint8_t** p=median_partition (lo, hi);
-            depth_limit=depth_limit-1;
-            introsort_loop (p, hi, depth_limit);
-            hi=p-1;
-        }
-    }
-    static uint8_t** median_partition (uint8_t** low, uint8_t** high)
-    {
-        uint8_t *pivot, **left, **right;
-        if (*(low+((high-low)/2)) < *low)
-            swap_elements ((low+((high-low)/2)), low);
-        if (*high < *low)
-            swap_elements (low, high);
-        if (*high < *(low+((high-low)/2)))
-            swap_elements ((low+((high-low)/2)), high);
-        swap_elements ((low+((high-low)/2)), (high-1));
-        pivot =  *(high-1);
-        left = low; right = high-1;
-        while (1) {
-            while (*(--right) > pivot);
-            while (*(++left)  < pivot);
-            if (left < right)
-            {
-                swap_elements(left, right);
-            }
-            else
-                break;
-        }
-        swap_elements (left, (high-1));
-        return left;
-    }
-    static void insertionsort (uint8_t** lo, uint8_t** hi)
-    {
-        for (uint8_t** i=lo+1; i <= hi; i++)
-        {
-            uint8_t** j = i;
-            uint8_t* t = *i;
-            while((j > lo) && (t <*(j-1)))
-            {
-                *j = *(j-1);
-                j--;
-            }
-            *j = t;
-        }
-    }
-    static void heapsort (uint8_t** lo, uint8_t** hi)
-    {
-        size_t n = hi - lo + 1;
-        for (size_t i=n / 2; i >= 1; i--)
-        {
-            downheap (i,n,lo);
-        }
-        for (size_t i = n; i > 1; i--)
-        {
-            swap_elements (lo, lo + i - 1);
-            downheap(1, i - 1,  lo);
-        }
-    }
-    static void downheap (size_t i, size_t n, uint8_t** lo)
-    {
-        uint8_t* d = *(lo + i - 1);
-        size_t child;
-        while (i <= n / 2)
-        {
-            child = 2*i;
-            if (child < n && *(lo + child - 1)<(*(lo + child)))
-            {
-                child++;
-            }
-            if (!(d<*(lo + child - 1)))
-            {
-                break;
-            }
-            *(lo + i - 1) = *(lo + child - 1);
-            i = child;
-        }
-        *(lo + i - 1) = d;
-    }
-};
-#endif //defined(USE_INTROSORT) || defined(USE_VXSORT)
-#ifdef USE_VXSORT
-static void do_vxsort (uint8_t** item_array, ptrdiff_t item_count, uint8_t* range_low, uint8_t* range_high)
-{
-    const ptrdiff_t AVX2_THRESHOLD_SIZE = 8 * 1024;
-    const ptrdiff_t AVX512F_THRESHOLD_SIZE = 128 * 1024;
-    if (item_count <= 1)
-        return;
-    if (IsSupportedInstructionSet (InstructionSet::AVX2) && (item_count > AVX2_THRESHOLD_SIZE))
-    {
-        dprintf(3, ("Sorting mark lists"));
-        if (IsSupportedInstructionSet (InstructionSet::AVX512F) && (item_count > AVX512F_THRESHOLD_SIZE))
-        {
-            do_vxsort_avx512 (item_array, &item_array[item_count - 1], range_low, range_high);
-        }
-        else
-        {
-            do_vxsort_avx2 (item_array, &item_array[item_count - 1], range_low, range_high);
-        }
-    }
-    else
-    {
-        dprintf (3, ("Sorting mark lists"));
-        introsort::sort (item_array, &item_array[item_count - 1], 0);
-    }
-#ifdef _DEBUG
-    for (ptrdiff_t i = 0; i < item_count - 1; i++)
-    {
-        assert (item_array[i] <= item_array[i + 1]);
-    }
-    assert ((range_low <= item_array[0]) && (item_array[item_count - 1] <= range_high));
-#endif
-}
-#endif //USE_VXSORT
-#ifdef MULTIPLE_HEAPS
-static size_t target_mark_count_for_heap (size_t total_mark_count, int heap_count, int heap_number)
-{
-    size_t average_mark_count = total_mark_count / heap_count;
-    size_t remaining_mark_count = total_mark_count - (average_mark_count * heap_count);
-    if (heap_number == (heap_count - 1))
-        return (average_mark_count + remaining_mark_count);
-    else
-        return average_mark_count;
-}
-NOINLINE
-uint8_t** gc_heap::equalize_mark_lists (size_t total_mark_list_size)
-{
-    size_t local_mark_count[MAX_SUPPORTED_CPUS];
-    size_t total_mark_count = 0;
-    for (int i = 0; i < n_heaps; i++)
-    {
-        gc_heap* hp = g_heaps[i];
-        size_t mark_count = hp->mark_list_index - hp->mark_list;
-        local_mark_count[i] = mark_count;
-        total_mark_count += mark_count;
-    }
-    assert(total_mark_count == total_mark_list_size);
-    size_t this_target_mark_count = target_mark_count_for_heap (total_mark_count, n_heaps, heap_number);
-    if (local_mark_count[heap_number] >= this_target_mark_count)
-        return (mark_list + this_target_mark_count);
-    int surplus_heap_index = 0;
-    for (int deficit_heap_index = 0; deficit_heap_index <= heap_number; deficit_heap_index++)
-    {
-        size_t deficit_target_mark_count = target_mark_count_for_heap (total_mark_count, n_heaps, deficit_heap_index);
-        if (local_mark_count[deficit_heap_index] >= deficit_target_mark_count)
-            continue;
-        while ((surplus_heap_index < n_heaps) && (local_mark_count[deficit_heap_index] < deficit_target_mark_count))
-        {
-            size_t deficit = deficit_target_mark_count - local_mark_count[deficit_heap_index];
-            size_t surplus_target_mark_count = target_mark_count_for_heap(total_mark_count, n_heaps, surplus_heap_index);
-            if (local_mark_count[surplus_heap_index] > surplus_target_mark_count)
-            {
-                size_t surplus = local_mark_count[surplus_heap_index] - surplus_target_mark_count;
-                size_t amount_to_transfer = min(deficit, surplus);
-                local_mark_count[surplus_heap_index] -= amount_to_transfer;
-                if (deficit_heap_index == heap_number)
-                {
-                    memcpy(&g_heaps[deficit_heap_index]->mark_list[local_mark_count[deficit_heap_index]],
-                           &g_heaps[surplus_heap_index]->mark_list[local_mark_count[surplus_heap_index]],
-                           (amount_to_transfer*sizeof(mark_list[0])));
-                }
-                local_mark_count[deficit_heap_index] += amount_to_transfer;
-            }
-            else
-            {
-                surplus_heap_index++;
-            }
-        }
-    }
-    return (mark_list + local_mark_count[heap_number]);
-}
-NOINLINE
-size_t gc_heap::sort_mark_list()
-{
-    if ((settings.condemned_generation >= max_generation)
-#ifdef USE_REGIONS
-      || (g_mark_list_piece == nullptr)
-#endif //USE_REGIONS
-        )
-    {
-        mark_list_index = mark_list_end + 1;
-        return 0;
-    }
-    if (mark_list_index > mark_list_end)
-    {
-        dprintf (2, ("h%d sort_mark_list overflow", heap_number));
-        mark_list_overflow = true;
-        return 0;
-    }
-    for (int i = 0; i < n_heaps; i++)
-    {
-        if (g_heaps[i]->mark_list_index > g_heaps[i]->mark_list_end)
-        {
-            mark_list_index = mark_list_end + 1;
-            dprintf (2, ("h%d sort_mark_list: detected overflow on heap %d", heap_number, i));
-            return 0;
-        }
-    }
-    size_t total_mark_list_size = 0;
-    size_t total_ephemeral_size = 0;
-    uint8_t* low = (uint8_t*)~0;
-    uint8_t* high = 0;
-    for (int i = 0; i < n_heaps; i++)
-    {
-        gc_heap* hp = g_heaps[i];
-        total_mark_list_size += (hp->mark_list_index - hp->mark_list);
-#ifdef USE_REGIONS
-        for (int gen_num = settings.condemned_generation; gen_num >= 0; gen_num--)
-        {
-            generation* gen = hp->generation_of (gen_num);
-            for (heap_segment* seg = generation_start_segment (gen); seg != nullptr; seg = heap_segment_next (seg))
-            {
-                size_t ephemeral_size = heap_segment_allocated (seg) - heap_segment_mem (seg);
-                total_ephemeral_size += ephemeral_size;
-                low = min (low, heap_segment_mem (seg));
-                high = max (high, heap_segment_allocated (seg));
-            }
-        }
-#else //USE_REGIONS
-        size_t ephemeral_size = heap_segment_allocated (hp->ephemeral_heap_segment) - hp->gc_low;
-        total_ephemeral_size += ephemeral_size;
-        low = min (low, hp->gc_low);
-        high = max (high, heap_segment_allocated (hp->ephemeral_heap_segment));
-#endif //USE_REGIONS
-    }
-    if (total_mark_list_size > (total_ephemeral_size / 256))
-    {
-        mark_list_index = mark_list_end + 1;
-        dprintf (2, ("h%d total mark list %zd is too large > (%zd / 256), don't use",
-            heap_number, total_mark_list_size, total_ephemeral_size));
-        mark_list_overflow = false;
-        return 0;
-    }
-    uint8_t **local_mark_list_index = equalize_mark_lists (total_mark_list_size);
-#ifdef USE_VXSORT
-    ptrdiff_t item_count = local_mark_list_index - mark_list;
-#if defined(_DEBUG) || defined(WRITE_SORT_DATA)
-    uint8_t** mark_list_copy = &g_mark_list_copy[heap_number * mark_list_size];
-    uint8_t** mark_list_copy_index = &mark_list_copy[item_count];
-    for (ptrdiff_t i = 0; i < item_count; i++)
-    {
-        uint8_t* item = mark_list[i];
-        assert ((low <= item) && (item < high));
-        mark_list_copy[i] = item;
-    }
-#endif // _DEBUG || WRITE_SORT_DATA
-    do_vxsort (mark_list, item_count, low, high);
-#ifdef WRITE_SORT_DATA
-    char file_name[256];
-    sprintf_s (file_name, ARRAY_SIZE(file_name), "sort_data_gc%d_heap%d", settings.gc_index, heap_number);
-    FILE* f;
-    errno_t err = fopen_s (&f, file_name, "wb");
-    if (err == 0)
-    {
-        size_t magic = 'SDAT';
-        if (fwrite (&magic, sizeof(magic), 1, f) != 1)
-            dprintf (3, ("fwrite failed\n"));
-        if (fwrite (&elapsed_cycles, sizeof(elapsed_cycles), 1, f) != 1)
-            dprintf (3, ("fwrite failed\n"));
-        if (fwrite (&low, sizeof(low), 1, f) != 1)
-            dprintf (3, ("fwrite failed\n"));
-        if (fwrite (&item_count, sizeof(item_count), 1, f) != 1)
-            dprintf (3, ("fwrite failed\n"));
-        if (fwrite (mark_list_copy, sizeof(mark_list_copy[0]), item_count, f) != item_count)
-            dprintf (3, ("fwrite failed\n"));
-        if (fwrite (&magic, sizeof(magic), 1, f) != 1)
-            dprintf (3, ("fwrite failed\n"));
-        if (fclose (f) != 0)
-            dprintf (3, ("fclose failed\n"));
-    }
-#endif
-#ifdef _DEBUG
-    if (mark_list_copy_index > mark_list_copy)
-    {
-        introsort::sort (mark_list_copy, mark_list_copy_index - 1, 0);
-    }
-    for (ptrdiff_t i = 0; i < item_count; i++)
-    {
-        uint8_t* item = mark_list[i];
-        assert (mark_list_copy[i] == item);
-    }
-#endif //_DEBUG
-#else //USE_VXSORT
-    dprintf (3, ("Sorting mark lists"));
-    if (local_mark_list_index > mark_list)
-    {
-        introsort::sort (mark_list, local_mark_list_index - 1, 0);
-    }
-#endif //USE_VXSORT
-    uint8_t** x = mark_list;
-#ifdef USE_REGIONS
-    assert (g_mark_list_piece_size >= region_count);
-    assert (g_mark_list_piece_total_size >= region_count*n_heaps);
-    for (size_t region_index = 0; region_index < region_count; region_index++)
-    {
-        mark_list_piece_start[region_index] = NULL;
-        mark_list_piece_end[region_index] = NULL;
-    }
-#define predicate(x) (((x) < local_mark_list_index) && (*(x) < region_limit))
-    while (x < local_mark_list_index)
-    {
-        heap_segment* region = get_region_info_for_address (*x);
-        assert ((heap_segment_mem (region) <= *x) && (*x < heap_segment_allocated (region)));
-        size_t region_index = get_basic_region_index_for_address (heap_segment_mem (region));
-        uint8_t* region_limit = heap_segment_allocated (region);
-        uint8_t*** mark_list_piece_start_ptr = &mark_list_piece_start[region_index];
-        uint8_t*** mark_list_piece_end_ptr = &mark_list_piece_end[region_index];
-#else // USE_REGIONS
-#define predicate(x) (((x) < local_mark_list_index) && (*(x) < heap->ephemeral_high))
-    int heap_num;
-    for (heap_num = 0; heap_num < n_heaps; heap_num++)
-    {
-        mark_list_piece_start[heap_num] = NULL;
-        mark_list_piece_end[heap_num] = NULL;
-    }
-    heap_num = -1;
-    while (x < local_mark_list_index)
-    {
-        gc_heap* heap;
-#ifdef _DEBUG
-        int last_heap_num = heap_num;
-#endif //_DEBUG
-        do
-        {
-            heap_num++;
-            if (heap_num >= n_heaps)
-                heap_num = 0;
-            assert(heap_num != last_heap_num); // we should always find the heap - infinite loop if not!
-            heap = g_heaps[heap_num];
-        }
-        while (!(*x >= heap->ephemeral_low && *x < heap->ephemeral_high));
-        uint8_t*** mark_list_piece_start_ptr = &mark_list_piece_start[heap_num];
-        uint8_t*** mark_list_piece_end_ptr = &mark_list_piece_end[heap_num];
-#endif // USE_REGIONS
-        *mark_list_piece_start_ptr = x;
-        if (predicate(x))
-        {
-            if (predicate(local_mark_list_index -1))
-            {
-                x = local_mark_list_index;
-                *mark_list_piece_end_ptr = x;
-                break;
-            }
-            unsigned inc = 1;
-            do
-            {
-                inc *= 2;
-                uint8_t** temp_x = x;
-                x += inc;
-                if (temp_x > x)
-                {
-                    break;
-                }
-            }
-            while (predicate(x));
-            x -= inc;
-            do
-            {
-                assert (predicate(x) && !(((x + inc) > x) && predicate(x + inc)));
-                inc /= 2;
-                if (((x + inc) > x) && predicate(x + inc))
-                {
-                    x += inc;
-                }
-            }
-            while (inc > 1);
-            assert(predicate(x) && !predicate(x + inc) && (inc == 1));
-            x += 1;
-        }
-        *mark_list_piece_end_ptr = x;
-    }
-#undef predicate
-    return total_mark_list_size;
-}
-void gc_heap::append_to_mark_list (uint8_t **start, uint8_t **end)
-{
-    size_t slots_needed = end - start;
-    size_t slots_available = mark_list_end + 1 - mark_list_index;
-    size_t slots_to_copy = min(slots_needed, slots_available);
-    memcpy(mark_list_index, start, slots_to_copy*sizeof(*start));
-    mark_list_index += slots_to_copy;
-    dprintf (3, ("h%d: appended %zd slots to mark_list\n", heap_number, slots_to_copy));
-}
-#ifdef _DEBUG
-#if !defined(_MSC_VER)
-#if !defined(__cdecl)
-#if defined(__i386__)
-#define __cdecl __attribute__((cdecl))
-#else
-#define __cdecl
-#endif
-#endif
-#endif
-static int __cdecl cmp_mark_list_item (const void* vkey, const void* vdatum)
-{
-    uint8_t** key = (uint8_t**)vkey;
-    uint8_t** datum = (uint8_t**)vdatum;
-    if (*key < *datum)
-        return -1;
-    else if (*key > *datum)
-        return 1;
-    else
-        return 0;
-}
-#endif // _DEBUG
-#ifdef USE_REGIONS
-uint8_t** gc_heap::get_region_mark_list (BOOL& use_mark_list, uint8_t* start, uint8_t* end, uint8_t*** mark_list_end_ptr)
-{
-    size_t region_number = get_basic_region_index_for_address (start);
-    size_t source_number = region_number;
-#else //USE_REGIONS
-void gc_heap::merge_mark_lists (size_t total_mark_list_size)
-{
-    if (total_mark_list_size == 0)
-    {
-        return;
-    }
-#ifdef _DEBUG
-    size_t this_mark_list_size = target_mark_count_for_heap (total_mark_list_size, n_heaps, heap_number);
-    for (uint8_t** p = mark_list + this_mark_list_size; p < mark_list_index; p++)
-    {
-        uint8_t* item = *p;
-        uint8_t** found_slot = nullptr;
-        for (int i = 0; i < n_heaps; i++)
-        {
-            uint8_t** heap_mark_list = &g_mark_list[i * mark_list_size];
-            size_t heap_mark_list_size = target_mark_count_for_heap (total_mark_list_size, n_heaps, i);
-            found_slot = (uint8_t**)bsearch (&item, heap_mark_list, heap_mark_list_size, sizeof(item), cmp_mark_list_item);
-            if (found_slot != nullptr)
-                break;
-        }
-        assert ((found_slot != nullptr) && (*found_slot == item));
-    }
-#endif
-    dprintf(3, ("merge_mark_lists: heap_number = %d  starts out with %zd entries",
-        heap_number, (mark_list_index - mark_list)));
-    int source_number = (size_t)heap_number;
-#endif //USE_REGIONS
-    uint8_t** source[MAX_SUPPORTED_CPUS];
-    uint8_t** source_end[MAX_SUPPORTED_CPUS];
-    int source_heap[MAX_SUPPORTED_CPUS];
-    int source_count = 0;
-    for (int i = 0; i < n_heaps; i++)
-    {
-        gc_heap* heap = g_heaps[i];
-        if (heap->mark_list_piece_start[source_number] < heap->mark_list_piece_end[source_number])
-        {
-            source[source_count] = heap->mark_list_piece_start[source_number];
-            source_end[source_count] = heap->mark_list_piece_end[source_number];
-            source_heap[source_count] = i;
-            if (source_count < MAX_SUPPORTED_CPUS)
-                source_count++;
-        }
-    }
-    dprintf(3, ("source_number = %zd  has %d sources\n", (size_t)source_number, source_count));
-#if defined(_DEBUG) || defined(TRACE_GC)
-    for (int j = 0; j < source_count; j++)
-    {
-        dprintf(3, ("source_number = %zd  ", (size_t)source_number));
-        dprintf(3, (" source from heap %zd = %zx .. %zx (%zd entries)",
-            (size_t)(source_heap[j]), (size_t)(source[j][0]),
-            (size_t)(source_end[j][-1]), (size_t)(source_end[j] - source[j])));
-        for (uint8_t **x = source[j]; x < source_end[j] - 1; x++)
-        {
-            if (x[0] > x[1])
-            {
-                dprintf(3, ("oops, mark_list from source %d for heap %zd isn't sorted\n", j,  (size_t)source_number));
-                assert (0);
-            }
-        }
-    }
-#endif //_DEBUG || TRACE_GC
-    mark_list = &g_mark_list_copy [heap_number*mark_list_size];
-    mark_list_index = mark_list;
-    mark_list_end = &mark_list [mark_list_size-1];
-    int piece_count = 0;
-    if (source_count == 0)
-    {
-        ; // nothing to do
-    }
-    else if (source_count == 1)
-    {
-        mark_list = source[0];
-        mark_list_index = source_end[0];
-        mark_list_end = mark_list_index;
-        piece_count++;
-    }
-    else
-    {
-        while (source_count > 1)
-        {
-            int lowest_source = 0;
-            uint8_t *lowest = *source[0];
-            uint8_t *second_lowest = *source[1];
-            for (int i = 1; i < source_count; i++)
-            {
-                if (lowest > *source[i])
-                {
-                    second_lowest = lowest;
-                    lowest = *source[i];
-                    lowest_source = i;
-                }
-                else if (second_lowest > *source[i])
-                {
-                    second_lowest = *source[i];
-                }
-            }
-            uint8_t **x;
-            if (source_end[lowest_source][-1] <= second_lowest)
-                x = source_end[lowest_source];
-            else
-            {
-                for (x = source[lowest_source]; x < source_end[lowest_source] && *x <= second_lowest; x++)
-                    ;
-            }
-            append_to_mark_list(source[lowest_source], x);
-#ifdef USE_REGIONS
-            if (mark_list_index > mark_list_end)
-            {
-                use_mark_list = false;
-                return nullptr;
-            }
-#endif //USE_REGIONS
-            piece_count++;
-            source[lowest_source] = x;
-            if (x >= source_end[lowest_source])
-            {
-                if (lowest_source < source_count-1)
-                {
-                    source[lowest_source] = source[source_count-1];
-                    source_end[lowest_source] = source_end[source_count-1];
-                }
-                source_count--;
-            }
-        }
-        append_to_mark_list(source[0], source_end[0]);
-#ifdef USE_REGIONS
-        if (mark_list_index > mark_list_end)
-        {
-            use_mark_list = false;
-            return nullptr;
-        }
-#endif //USE_REGIONS
-        piece_count++;
-    }
-#if defined(_DEBUG) || defined(TRACE_GC)
-    for (uint8_t **x = mark_list; x < mark_list_index - 1; x++)
-    {
-        if (x[0] > x[1])
-        {
-            dprintf(3, ("oops, mark_list for heap %d isn't sorted at the end of merge_mark_lists", heap_number));
-            assert (0);
-        }
-    }
-#endif //_DEBUG || TRACE_GC
-#ifdef USE_REGIONS
-    *mark_list_end_ptr = mark_list_index;
-    return mark_list;
-#endif // USE_REGIONS
-}
-#else
-#ifdef USE_REGIONS
-static uint8_t** binary_search (uint8_t** left, uint8_t** right, uint8_t* e)
-{
-    if (left == right)
-        return left;
-    assert (left < right);
-    uint8_t** a = left;
-    size_t l = 0;
-    size_t r = (size_t)(right - left);
-    while ((r - l) >= 2)
-    {
-        size_t m = l + (r - l) / 2;
-        assert ((l < m) && (m < r));
-        if (a[m] < e)
-        {
-            l = m;
-        }
-        else
-        {
-            r = m;
-        }
-    }
-    if (a[l] < e)
-        return a + l + 1;
-    else
-        return a + l;
-}
-uint8_t** gc_heap::get_region_mark_list (BOOL& use_mark_list, uint8_t* start, uint8_t* end, uint8_t*** mark_list_end_ptr)
-{
-    *mark_list_end_ptr = binary_search (mark_list, mark_list_index, end);
-    return binary_search (mark_list, *mark_list_end_ptr, start);
-}
-#endif //USE_REGIONS
-#endif //MULTIPLE_HEAPS
-void gc_heap::grow_mark_list ()
-{
-#ifdef USE_VXSORT
-#ifdef MULTIPLE_HEAPS
-    const size_t MAX_MARK_LIST_SIZE = IsSupportedInstructionSet (InstructionSet::AVX2) ?
-        (1000 * 1024) : (200 * 1024);
-#else //MULTIPLE_HEAPS
-    const size_t MAX_MARK_LIST_SIZE = IsSupportedInstructionSet (InstructionSet::AVX2) ?
-        (32 * 1024) : (16 * 1024);
-#endif //MULTIPLE_HEAPS
-#else //USE_VXSORT
-#ifdef MULTIPLE_HEAPS
-    const size_t MAX_MARK_LIST_SIZE = 200 * 1024;
-#else //MULTIPLE_HEAPS
-    const size_t MAX_MARK_LIST_SIZE = 16 * 1024;
-#endif //MULTIPLE_HEAPS
-#endif //USE_VXSORT
-    size_t new_mark_list_size = min (mark_list_size * 2, MAX_MARK_LIST_SIZE);
-    size_t new_mark_list_total_size = new_mark_list_size*n_heaps;
-    if (new_mark_list_total_size == g_mark_list_total_size)
-        return;
-#ifdef MULTIPLE_HEAPS
-    uint8_t** new_mark_list = make_mark_list (new_mark_list_total_size);
-    uint8_t** new_mark_list_copy = make_mark_list (new_mark_list_total_size);
-    if ((new_mark_list != nullptr) && (new_mark_list_copy != nullptr))
-    {
-        delete[] g_mark_list;
-        g_mark_list = new_mark_list;
-        delete[] g_mark_list_copy;
-        g_mark_list_copy = new_mark_list_copy;
-        mark_list_size = new_mark_list_size;
-        g_mark_list_total_size = new_mark_list_total_size;
-    }
-    else
-    {
-        delete[] new_mark_list;
-        delete[] new_mark_list_copy;
-    }
-#else //MULTIPLE_HEAPS
-    uint8_t** new_mark_list = make_mark_list (new_mark_list_size);
-    if (new_mark_list != nullptr)
-    {
-        delete[] mark_list;
-        g_mark_list = new_mark_list;
-        mark_list_size = new_mark_list_size;
-        g_mark_list_total_size = new_mark_list_size;
-    }
-#endif //MULTIPLE_HEAPS
-}
-#ifndef USE_REGIONS
-class seg_free_spaces
-{
-    struct seg_free_space
-    {
-        BOOL is_plug;
-        void* start;
-    };
-    struct free_space_bucket
-    {
-        seg_free_space* free_space;
-        ptrdiff_t count_add; // Assigned when we first construct the array.
-        ptrdiff_t count_fit; // How many items left when we are fitting plugs.
-    };
-    void move_bucket (int old_power2, int new_power2)
-    {
-        assert (old_power2 >= 0);
-        assert (old_power2 >= new_power2);
-        if (old_power2 == new_power2)
-        {
-            return;
-        }
-        seg_free_space* src_index = free_space_buckets[old_power2].free_space;
-        for (int i = old_power2; i > new_power2; i--)
-        {
-            seg_free_space** dest = &(free_space_buckets[i].free_space);
-            (*dest)++;
-            seg_free_space* dest_index = free_space_buckets[i - 1].free_space;
-            if (i > (new_power2 + 1))
-            {
-                seg_free_space temp = *src_index;
-                *src_index = *dest_index;
-                *dest_index = temp;
-            }
-            src_index = dest_index;
-        }
-        free_space_buckets[old_power2].count_fit--;
-        free_space_buckets[new_power2].count_fit++;
-    }
-#ifdef _DEBUG
-    void dump_free_space (seg_free_space* item)
-    {
-        uint8_t* addr = 0;
-        size_t len = 0;
-        if (item->is_plug)
-        {
-            mark* m = (mark*)(item->start);
-            len = pinned_len (m);
-            addr = pinned_plug (m) - len;
-        }
-        else
-        {
-            heap_segment* seg = (heap_segment*)(item->start);
-            addr = heap_segment_plan_allocated (seg);
-            len = heap_segment_committed (seg) - addr;
-        }
-        dprintf (SEG_REUSE_LOG_1, ("[%d]0x%p %zd", heap_num, addr, len));
-    }
-    void dump()
-    {
-        seg_free_space* item = NULL;
-        int i = 0;
-        dprintf (SEG_REUSE_LOG_1, ("[%d]----------------------------------\nnow the free spaces look like:", heap_num));
-        for (i = 0; i < (free_space_bucket_count - 1); i++)
-        {
-            dprintf (SEG_REUSE_LOG_1, ("[%d]Free spaces for 2^%d bucket:", heap_num, (base_power2 + i)));
-            dprintf (SEG_REUSE_LOG_1, ("[%d]%s %s", heap_num, "start", "len"));
-            item = free_space_buckets[i].free_space;
-            while (item < free_space_buckets[i + 1].free_space)
-            {
-                dump_free_space (item);
-                item++;
-            }
-            dprintf (SEG_REUSE_LOG_1, ("[%d]----------------------------------", heap_num));
-        }
-        dprintf (SEG_REUSE_LOG_1, ("[%d]Free spaces for 2^%d bucket:", heap_num, (base_power2 + i)));
-        dprintf (SEG_REUSE_LOG_1, ("[%d]%s %s", heap_num, "start", "len"));
-        item = free_space_buckets[i].free_space;
-        while (item <= &seg_free_space_array[free_space_item_count - 1])
-        {
-            dump_free_space (item);
-            item++;
-        }
-        dprintf (SEG_REUSE_LOG_1, ("[%d]----------------------------------", heap_num));
-    }
-#endif //_DEBUG
-    free_space_bucket* free_space_buckets;
-    seg_free_space* seg_free_space_array;
-    ptrdiff_t free_space_bucket_count;
-    ptrdiff_t free_space_item_count;
-    int base_power2;
-    int heap_num;
-#ifdef _DEBUG
-    BOOL has_end_of_seg;
-#endif //_DEBUG
-public:
-    seg_free_spaces (int h_number)
-    {
-        heap_num = h_number;
-    }
-    BOOL alloc ()
-    {
-        size_t total_prealloc_size =
-            MAX_NUM_BUCKETS * sizeof (free_space_bucket) +
-            MAX_NUM_FREE_SPACES * sizeof (seg_free_space);
-        free_space_buckets = (free_space_bucket*) new (nothrow) uint8_t[total_prealloc_size];
-        return (!!free_space_buckets);
-    }
-    void add_buckets (int base, size_t* ordered_free_spaces, int bucket_count, size_t item_count)
-    {
-        assert (free_space_buckets);
-        assert (item_count <= (size_t)MAX_PTR);
-        free_space_bucket_count = bucket_count;
-        free_space_item_count = item_count;
-        base_power2 = base;
-#ifdef _DEBUG
-        has_end_of_seg = FALSE;
-#endif //_DEBUG
-        ptrdiff_t total_item_count = 0;
-        ptrdiff_t i = 0;
-        seg_free_space_array = (seg_free_space*)(free_space_buckets + free_space_bucket_count);
-        for (i = 0; i < (ptrdiff_t)item_count; i++)
-        {
-            seg_free_space_array[i].start = 0;
-            seg_free_space_array[i].is_plug = FALSE;
-        }
-        for (i = 0; i < bucket_count; i++)
-        {
-            free_space_buckets[i].count_add = ordered_free_spaces[i];
-            free_space_buckets[i].count_fit = ordered_free_spaces[i];
-            free_space_buckets[i].free_space = &seg_free_space_array[total_item_count];
-            total_item_count += free_space_buckets[i].count_add;
-        }
-        assert (total_item_count == (ptrdiff_t)item_count);
-    }
-    void add (void* start, BOOL plug_p, BOOL first_p)
-    {
-        size_t size = (plug_p ?
-                       pinned_len ((mark*)start) :
-                       (heap_segment_committed ((heap_segment*)start) -
-                           heap_segment_plan_allocated ((heap_segment*)start)));
-        if (plug_p)
-        {
-            dprintf (SEG_REUSE_LOG_1, ("[%d]Adding a free space before plug: %zd", heap_num, size));
-        }
-        else
-        {
-            dprintf (SEG_REUSE_LOG_1, ("[%d]Adding a free space at end of seg: %zd", heap_num, size));
-#ifdef _DEBUG
-            has_end_of_seg = TRUE;
-#endif //_DEBUG
-        }
-        if (first_p)
-        {
-            size_t eph_gen_starts = gc_heap::eph_gen_starts_size;
-            size -= eph_gen_starts;
-            if (plug_p)
-            {
-                mark* m = (mark*)(start);
-                pinned_len (m) -= eph_gen_starts;
-            }
-            else
-            {
-                heap_segment* seg = (heap_segment*)start;
-                heap_segment_plan_allocated (seg) += eph_gen_starts;
-            }
-        }
-        int bucket_power2 = index_of_highest_set_bit (size);
-        if (bucket_power2 < base_power2)
-        {
-            return;
-        }
-        free_space_bucket* bucket = &free_space_buckets[bucket_power2 - base_power2];
-        seg_free_space* bucket_free_space = bucket->free_space;
-        assert (plug_p || (!plug_p && bucket->count_add));
-        if (bucket->count_add == 0)
-        {
-            dprintf (SEG_REUSE_LOG_1, ("[%d]Already have enough of 2^%d", heap_num, bucket_power2));
-            return;
-        }
-        ptrdiff_t index = bucket->count_add - 1;
-        dprintf (SEG_REUSE_LOG_1, ("[%d]Building free spaces: adding %p; len: %zd (2^%d)",
-                    heap_num,
-                    (plug_p ?
-                        (pinned_plug ((mark*)start) - pinned_len ((mark*)start)) :
-                        heap_segment_plan_allocated ((heap_segment*)start)),
-                    size,
-                    bucket_power2));
-        if (plug_p)
-        {
-            bucket_free_space[index].is_plug = TRUE;
-        }
-        bucket_free_space[index].start = start;
-        bucket->count_add--;
-    }
-#ifdef _DEBUG
-    void check()
-    {
-        ptrdiff_t i = 0;
-        int end_of_seg_count = 0;
-        for (i = 0; i < free_space_item_count; i++)
-        {
-            assert (seg_free_space_array[i].start);
-            if (!(seg_free_space_array[i].is_plug))
-            {
-                end_of_seg_count++;
-            }
-        }
-        if (has_end_of_seg)
-        {
-            assert (end_of_seg_count == 1);
-        }
-        else
-        {
-            assert (end_of_seg_count == 0);
-        }
-        for (i = 0; i < free_space_bucket_count; i++)
-        {
-            assert (free_space_buckets[i].count_add == 0);
-        }
-    }
-#endif //_DEBUG
-    uint8_t* fit (uint8_t* old_loc,
-               size_t plug_size
-               REQD_ALIGN_AND_OFFSET_DCL)
-    {
-        if (old_loc)
-        {
-#ifdef SHORT_PLUGS
-            assert (!is_plug_padded (old_loc));
-#endif //SHORT_PLUGS
-            assert (!node_realigned (old_loc));
-        }
-        size_t saved_plug_size = plug_size;
-#ifdef FEATURE_STRUCTALIGN
-        _ASSERTE(requiredAlignment == DATA_ALIGNMENT && false);
-#endif // FEATURE_STRUCTALIGN
-        size_t plug_size_to_fit = plug_size;
-#ifdef RESPECT_LARGE_ALIGNMENT
-        plug_size_to_fit += switch_alignment_size(FALSE);
-#endif //RESPECT_LARGE_ALIGNMENT
-        int plug_power2 = index_of_highest_set_bit (round_up_power2 (plug_size_to_fit + Align(min_obj_size)));
-        ptrdiff_t i;
-        uint8_t* new_address = 0;
-        if (plug_power2 < base_power2)
-        {
-            plug_power2 = base_power2;
-        }
-        int chosen_power2 = plug_power2 - base_power2;
-retry:
-        for (i = chosen_power2; i < free_space_bucket_count; i++)
-        {
-            if (free_space_buckets[i].count_fit != 0)
-            {
-                break;
-            }
-            chosen_power2++;
-        }
-        dprintf (SEG_REUSE_LOG_1, ("[%d]Fitting plug len %zd (2^%d) using 2^%d free space",
-            heap_num,
-            plug_size,
-            plug_power2,
-            (chosen_power2 + base_power2)));
-        assert (i < free_space_bucket_count);
-        seg_free_space* bucket_free_space = free_space_buckets[chosen_power2].free_space;
-        ptrdiff_t free_space_count = free_space_buckets[chosen_power2].count_fit;
-        size_t new_free_space_size = 0;
-        BOOL can_fit = FALSE;
-        size_t pad = 0;
-        for (i = 0; i < free_space_count; i++)
-        {
-            size_t free_space_size = 0;
-            pad = 0;
-            if (bucket_free_space[i].is_plug)
-            {
-                mark* m = (mark*)(bucket_free_space[i].start);
-                uint8_t* plug_free_space_start = pinned_plug (m) - pinned_len (m);
-                if (!((old_loc == 0) || same_large_alignment_p (old_loc, plug_free_space_start)))
-                {
-                    pad = switch_alignment_size (FALSE);
-                }
-                plug_size = saved_plug_size + pad;
-                free_space_size = pinned_len (m);
-                new_address = pinned_plug (m) - pinned_len (m);
-                if (free_space_size >= (plug_size + Align (min_obj_size)) ||
-                    free_space_size == plug_size)
-                {
-                    new_free_space_size = free_space_size - plug_size;
-                    pinned_len (m) = new_free_space_size;
-#ifdef SIMPLE_DPRINTF
-                    dprintf (SEG_REUSE_LOG_0, ("[%d]FP: 0x%p->0x%p(%zx)(%zx), [0x%p (2^%d) -> [0x%p (2^%d)",
-                                heap_num,
-                                old_loc,
-                                new_address,
-                                (plug_size - pad),
-                                pad,
-                                pinned_plug (m),
-                                index_of_highest_set_bit (free_space_size),
-                                (pinned_plug (m) - pinned_len (m)),
-                                index_of_highest_set_bit (new_free_space_size)));
-#endif //SIMPLE_DPRINTF
-                    if (pad != 0)
-                    {
-                        set_node_realigned (old_loc);
-                    }
-                    can_fit = TRUE;
-                }
-            }
-            else
-            {
-                heap_segment* seg = (heap_segment*)(bucket_free_space[i].start);
-                free_space_size = heap_segment_committed (seg) - heap_segment_plan_allocated (seg);
-                if (!((old_loc == 0) || same_large_alignment_p (old_loc, heap_segment_plan_allocated (seg))))
-                {
-                    pad = switch_alignment_size (FALSE);
-                }
-                plug_size = saved_plug_size + pad;
-                if (free_space_size >= (plug_size + Align (min_obj_size)) ||
-                    free_space_size == plug_size)
-                {
-                    new_address = heap_segment_plan_allocated (seg);
-                    new_free_space_size = free_space_size - plug_size;
-                    heap_segment_plan_allocated (seg) = new_address + plug_size;
-#ifdef SIMPLE_DPRINTF
-                    dprintf (SEG_REUSE_LOG_0, ("[%d]FS: 0x%p-> 0x%p(%zd) (2^%d) -> 0x%p (2^%d)",
-                                heap_num,
-                                old_loc,
-                                new_address,
-                                (plug_size - pad),
-                                index_of_highest_set_bit (free_space_size),
-                                heap_segment_plan_allocated (seg),
-                                index_of_highest_set_bit (new_free_space_size)));
-#endif //SIMPLE_DPRINTF
-                    if (pad != 0)
-                        set_node_realigned (old_loc);
-                    can_fit = TRUE;
-                }
-            }
-            if (can_fit)
-            {
-                break;
-            }
-        }
-        if (!can_fit)
-        {
-            assert (chosen_power2 == 0);
-            chosen_power2 = 1;
-            goto retry;
-        }
-        new_address += pad;
-        assert ((chosen_power2 && (i == 0)) ||
-                ((!chosen_power2) && (i < free_space_count)));
-        int new_bucket_power2 = index_of_highest_set_bit (new_free_space_size);
-        if (new_bucket_power2 < base_power2)
-        {
-            new_bucket_power2 = base_power2;
-        }
-        move_bucket (chosen_power2, new_bucket_power2 - base_power2);
-        return new_address;
-    }
-    void cleanup ()
-    {
-        if (free_space_buckets)
-        {
-            delete [] free_space_buckets;
-        }
-        if (seg_free_space_array)
-        {
-            delete [] seg_free_space_array;
-        }
-    }
-};
-#endif //!USE_REGIONS
-#define marked(i) header(i)->IsMarked()
-#define set_marked(i) header(i)->SetMarked()
-#define clear_marked(i) header(i)->ClearMarked()
-#define pinned(i) header(i)->IsPinned()
-#define set_pinned(i) header(i)->SetPinned()
-#define clear_pinned(i) header(i)->GetHeader()->ClrGCBit();
-inline size_t my_get_size (Object* ob)
-{
-    MethodTable* mT = header(ob)->GetMethodTable();
-    return (mT->GetBaseSize() +
-            (mT->HasComponentSize() ?
-             ((size_t)((CObjectHeader*)ob)->GetNumComponents() * mT->RawGetComponentSize()) : 0));
-}
-#define size(i) my_get_size (header(i))
-#define contain_pointers(i) header(i)->ContainsGCPointers()
-#ifdef COLLECTIBLE_CLASS
-#define contain_pointers_or_collectible(i) header(i)->ContainsGCPointersOrCollectible()
-#define get_class_object(i) GCToEEInterface::GetLoaderAllocatorObjectForGC((Object *)i)
-#define is_collectible(i) method_table(i)->Collectible()
-#else //COLLECTIBLE_CLASS
-#define contain_pointers_or_collectible(i) header(i)->ContainsGCPointers()
-#endif //COLLECTIBLE_CLASS
-#ifdef BACKGROUND_GC
-#ifdef FEATURE_BASICFREEZE
-inline
-void gc_heap::seg_clear_mark_array_bits_soh (heap_segment* seg)
-{
-    uint8_t* range_beg = 0;
-    uint8_t* range_end = 0;
-    if (bgc_mark_array_range (seg, FALSE, &range_beg, &range_end))
-    {
-        clear_mark_array (range_beg, align_on_mark_word (range_end));
-    }
-}
-inline
-void gc_heap::seg_set_mark_array_bits_soh (heap_segment* seg)
-{
-    uint8_t* range_beg = 0;
-    uint8_t* range_end = 0;
-    if (bgc_mark_array_range (seg, FALSE, &range_beg, &range_end))
-    {
-        size_t beg_word = mark_word_of (align_on_mark_word (range_beg));
-        size_t end_word = mark_word_of (align_on_mark_word (range_end));
-        uint8_t* op = range_beg;
-        while (op < mark_word_address (beg_word))
-        {
-            mark_array_set_marked (op);
-            op += mark_bit_pitch;
-        }
-        memset (&mark_array[beg_word], 0xFF, (end_word - beg_word)*sizeof (uint32_t));
-    }
-}
-#endif //FEATURE_BASICFREEZE
-void gc_heap::bgc_clear_batch_mark_array_bits (uint8_t* start, uint8_t* end)
-{
-    if ((start < background_saved_highest_address) &&
-        (end > background_saved_lowest_address))
-    {
-        start = max (start, background_saved_lowest_address);
-        end = min (end, background_saved_highest_address);
-        size_t start_mark_bit = mark_bit_of (start);
-        size_t end_mark_bit = mark_bit_of (end);
-        unsigned int startbit = mark_bit_bit (start_mark_bit);
-        unsigned int endbit = mark_bit_bit (end_mark_bit);
-        size_t startwrd = mark_bit_word (start_mark_bit);
-        size_t endwrd = mark_bit_word (end_mark_bit);
-        dprintf (3, ("Clearing all mark array bits between [%zx:%zx-[%zx:%zx",
-            (size_t)start, (size_t)start_mark_bit,
-            (size_t)end, (size_t)end_mark_bit));
-        unsigned int firstwrd = lowbits (~0, startbit);
-        unsigned int lastwrd = highbits (~0, endbit);
-        if (startwrd == endwrd)
-        {
-            if (startbit != endbit)
-            {
-                unsigned int wrd = firstwrd | lastwrd;
-                mark_array[startwrd] &= wrd;
-            }
-            else
-            {
-                assert (start == end);
-            }
-            return;
-        }
-        if (startbit)
-        {
-            mark_array[startwrd] &= firstwrd;
-            startwrd++;
-        }
-        for (size_t wrdtmp = startwrd; wrdtmp < endwrd; wrdtmp++)
-        {
-            mark_array[wrdtmp] = 0;
-        }
-        if (endbit)
-        {
-            mark_array[endwrd] &= lastwrd;
-        }
-    }
-}
-#endif //BACKGROUND_GC
-inline
-BOOL gc_heap::is_mark_set (uint8_t* o)
-{
-    return marked (o);
-}
-#if defined (_MSC_VER) && defined (TARGET_X86)
-#pragma optimize("y", on)        // Small critical routines, don't put in EBP frame
-#endif //_MSC_VER && TARGET_X86
-int gc_heap::object_gennum (uint8_t* o)
-{
-#ifdef USE_REGIONS
-    return get_region_gen_num (o);
-#else
-    if (in_range_for_segment (o, ephemeral_heap_segment) &&
-        (o >= generation_allocation_start (generation_of (max_generation - 1))))
-    {
-        for ( int i = 0; i < max_generation-1; i++)
-        {
-            if ((o >= generation_allocation_start (generation_of (i))))
-                return i;
-        }
-        return max_generation-1;
-    }
-    else
-    {
-        return max_generation;
-    }
-#endif //USE_REGIONS
-}
-int gc_heap::object_gennum_plan (uint8_t* o)
-{
-#ifdef USE_REGIONS
-    return get_region_plan_gen_num (o);
-#else
-    if (in_range_for_segment (o, ephemeral_heap_segment))
-    {
-        for (int i = 0; i < ephemeral_generation_count; i++)
-        {
-            uint8_t* plan_start = generation_plan_allocation_start (generation_of (i));
-            if (plan_start && (o >= plan_start))
-            {
-                return i;
-            }
-        }
-    }
-    return max_generation;
-#endif //USE_REGIONS
-}
-#if defined(_MSC_VER) && defined(TARGET_X86)
-#pragma optimize("", on)        // Go back to command line default optimizations
-#endif //_MSC_VER && TARGET_X86
-#ifdef USE_REGIONS
-void get_initial_region(int gen, int hn, uint8_t** region_start, uint8_t** region_end)
-{
-    *region_start = initial_regions[hn][gen][0];
-    *region_end = initial_regions[hn][gen][1];
-}
-bool gc_heap::initial_make_soh_regions (gc_heap* hp)
-{
-    uint8_t* region_start;
-    uint8_t* region_end;
-    uint32_t hn = 0;
-#ifdef MULTIPLE_HEAPS
-    hn = hp->heap_number;
-#endif //MULTIPLE_HEAPS
-    for (int i = max_generation; i >= 0; i--)
-    {
-        get_initial_region(i, hn, &region_start, &region_end);
-        size_t region_size = region_end - region_start;
-        heap_segment* current_region = make_heap_segment (region_start, region_size, hp, i);
-        if (current_region == nullptr)
-        {
-            return false;
-        }
-        uint8_t* gen_start = heap_segment_mem (current_region);
-        make_generation (i, current_region, gen_start);
-        if (i == 0)
-        {
-            ephemeral_heap_segment = current_region;
-            alloc_allocated = heap_segment_allocated (current_region);
-        }
-    }
-    for (int i = max_generation; i >= 0; i--)
-    {
-        dprintf (REGIONS_LOG, ("h%d gen%d alloc seg is %p, start seg is %p (%p-%p)",
-            heap_number, i, generation_allocation_segment (generation_of (i)),
-            generation_start_segment (generation_of (i)),
-            heap_segment_mem (generation_start_segment (generation_of (i))),
-            heap_segment_allocated (generation_start_segment (generation_of (i)))));
-    }
-    return true;
-}
-bool gc_heap::initial_make_uoh_regions (int gen, gc_heap* hp)
-{
-    uint8_t* region_start;
-    uint8_t* region_end;
-    uint32_t hn = 0;
-#ifdef MULTIPLE_HEAPS
-    hn = hp->heap_number;
-#endif //MULTIPLE_HEAPS
-    get_initial_region(gen, hn, &region_start, &region_end);
-    size_t region_size = region_end - region_start;
-    heap_segment* uoh_region = make_heap_segment (region_start, region_size, hp, gen);
-    if (uoh_region == nullptr)
-    {
-        return false;
-    }
-    uoh_region->flags |=
-        (gen == loh_generation) ? heap_segment_flags_loh : heap_segment_flags_poh;
-    uint8_t* gen_start = heap_segment_mem (uoh_region);
-    make_generation (gen, uoh_region, gen_start);
-    return true;
-}
-void gc_heap::clear_region_info (heap_segment* region)
-{
-    if (!heap_segment_uoh_p (region))
-    {
-        clear_brick_table (heap_segment_mem (region), heap_segment_reserved (region));
-    }
-    clear_card_for_addresses (get_region_start (region), heap_segment_reserved (region));
-#ifdef BACKGROUND_GC
-    ::record_changed_seg ((uint8_t*)region, heap_segment_reserved (region),
-                        settings.gc_index, current_bgc_state,
-                        seg_deleted);
-    bgc_verify_mark_array_cleared (region);
-#endif //BACKGROUND_GC
-}
-void gc_heap::return_free_region (heap_segment* region)
-{
-    gc_oh_num oh = heap_segment_oh (region);
-    dprintf(3, ("commit-accounting:  from %d to free [%p, %p) for heap %d", oh, get_region_start (region), heap_segment_committed (region), heap_number));
-    {
-        size_t committed = heap_segment_committed (region) - get_region_start (region);
-        if (committed > 0)
-        {
-            check_commit_cs.Enter();
-            assert (committed_by_oh[oh] >= committed);
-            committed_by_oh[oh] -= committed;
-            committed_by_oh[recorded_committed_free_bucket] += committed;
-#if defined(MULTIPLE_HEAPS) && defined(_DEBUG)
-            assert (committed_by_oh_per_heap[oh] >= committed);
-            committed_by_oh_per_heap[oh] -= committed;
-#endif // MULTIPLE_HEAPS && _DEBUG
-            check_commit_cs.Leave();
-        }
-    }
-    clear_region_info (region);
-    region_free_list::add_region_descending (region, free_regions);
-    uint8_t* region_start = get_region_start (region);
-    uint8_t* region_end = heap_segment_reserved (region);
-    int num_basic_regions = (int)((region_end - region_start) >> min_segment_size_shr);
-    dprintf (REGIONS_LOG, ("RETURNING region %p (%d basic regions) to free",
-        heap_segment_mem (region), num_basic_regions));
-    for (int i = 0; i < num_basic_regions; i++)
-    {
-        uint8_t* basic_region_start = region_start + ((size_t)i << min_segment_size_shr);
-        heap_segment* basic_region = get_region_info (basic_region_start);
-        heap_segment_allocated (basic_region) = 0;
-#ifdef MULTIPLE_HEAPS
-        heap_segment_heap (basic_region) = 0;
-#endif //MULTIPLE_HEAPS
-    }
-}
-heap_segment* gc_heap::get_free_region (int gen_number, size_t size)
-{
-    heap_segment* region = 0;
-    if (gen_number <= max_generation)
-    {
-        assert (size == 0);
-        region = free_regions[basic_free_region].unlink_region_front();
-    }
-    else
-    {
-        const size_t LARGE_REGION_SIZE = global_region_allocator.get_large_region_alignment();
-        assert (size >= LARGE_REGION_SIZE);
-        if (size == LARGE_REGION_SIZE)
-        {
-            region = free_regions[large_free_region].unlink_region_front();
-        }
-        else
-        {
-            region = free_regions[huge_free_region].unlink_smallest_region (size);
-            if (region == nullptr)
-            {
-                if (settings.pause_mode == pause_no_gc)
-                {
-                    assert (gc_lock.holding_thread != (Thread*)-1);
-                }
-                else
-                {
-                    ASSERT_HOLDING_SPIN_LOCK(&gc_lock);
-                }
-                region = global_free_huge_regions.unlink_smallest_region (size);
-            }
-        }
-    }
-    if (region)
-    {
-        uint8_t* region_start = get_region_start (region);
-        uint8_t* region_end = heap_segment_reserved (region);
-        init_heap_segment (region, __this, region_start,
-                           (region_end - region_start),
-                           gen_number, true);
-        gc_oh_num oh = gen_to_oh (gen_number);
-        dprintf(3, ("commit-accounting:  from free to %d [%p, %p) for heap %d", oh, get_region_start (region), heap_segment_committed (region), heap_number));
-        {
-            size_t committed = heap_segment_committed (region) - get_region_start (region);
-            if (committed > 0)
-            {
-                check_commit_cs.Enter();
-                committed_by_oh[oh] += committed;
-                assert (committed_by_oh[recorded_committed_free_bucket] >= committed);
-                committed_by_oh[recorded_committed_free_bucket] -= committed;
-#if defined(MULTIPLE_HEAPS) && defined(_DEBUG)
-                committed_by_oh_per_heap[oh] += committed;
-#endif // MULTIPLE_HEAPS && _DEBUG
-                check_commit_cs.Leave();
-            }
-        }
-        dprintf (REGIONS_LOG, ("h%d GFR get region %zx (%p-%p) for gen%d",
-            heap_number, (size_t)region,
-            region_start, region_end,
-            gen_number));
-        assert (heap_segment_allocated(region) == heap_segment_mem (region));
-    }
-    else
-    {
-        region = allocate_new_region (__this, gen_number, (gen_number > max_generation), size);
-    }
-    if (region)
-    {
-        if (!init_table_for_region (gen_number, region))
-        {
-            region = 0;
-        }
-    }
-    return region;
-}
-heap_segment* gc_heap::region_of (uint8_t* obj)
-{
-    size_t index = (size_t)obj >> gc_heap::min_segment_size_shr;
-    seg_mapping* entry = &seg_mapping_table[index];
-    return (heap_segment*)entry;
-}
-heap_segment* gc_heap::get_region_at_index (size_t index)
-{
-    index += (size_t)g_gc_lowest_address >> gc_heap::min_segment_size_shr;
-    return (heap_segment*)(&seg_mapping_table[index]);
-}
-void gc_heap::check_seg_gen_num (heap_segment* seg)
-{
-#ifdef _DEBUG
-    uint8_t* mem = heap_segment_mem (seg);
-    if ((mem < g_gc_lowest_address) || (mem >= g_gc_highest_address))
-    {
-        GCToOSInterface::DebugBreak();
-    }
-    int alloc_seg_gen_num = get_region_gen_num (mem);
-    int alloc_seg_plan_gen_num = get_region_plan_gen_num (mem);
-    dprintf (3, ("seg %p->%p, num %d, %d",
-        seg, mem, alloc_seg_gen_num, alloc_seg_plan_gen_num));
-#endif //_DEBUG
-}
-int gc_heap::get_region_gen_num (heap_segment* region)
-{
-    return heap_segment_gen_num (region);
-}
-int gc_heap::get_region_gen_num (uint8_t* obj)
-{
-    size_t skewed_basic_region_index = get_skewed_basic_region_index_for_address (obj);
-    int gen_num = map_region_to_generation_skewed[skewed_basic_region_index] & gc_heap::RI_GEN_MASK;
-    assert ((soh_gen0 <= gen_num) && (gen_num <= soh_gen2));
-    assert (gen_num == heap_segment_gen_num (region_of (obj)));
-    return gen_num;
-}
-int gc_heap::get_region_plan_gen_num (uint8_t* obj)
-{
-    size_t skewed_basic_region_index = get_skewed_basic_region_index_for_address (obj);
-    int plan_gen_num = map_region_to_generation_skewed[skewed_basic_region_index] >> gc_heap::RI_PLAN_GEN_SHR;
-    assert ((soh_gen0 <= plan_gen_num) && (plan_gen_num <= soh_gen2));
-    assert (plan_gen_num == heap_segment_plan_gen_num (region_of (obj)));
-    return plan_gen_num;
-}
-bool gc_heap::is_region_demoted (uint8_t* obj)
-{
-    size_t skewed_basic_region_index = get_skewed_basic_region_index_for_address (obj);
-    bool demoted_p = (map_region_to_generation_skewed[skewed_basic_region_index] & gc_heap::RI_DEMOTED) != 0;
-    assert (demoted_p == heap_segment_demoted_p (region_of (obj)));
-    return demoted_p;
-}
-static GCSpinLock write_barrier_spin_lock;
-inline
-void gc_heap::set_region_gen_num (heap_segment* region, int gen_num)
-{
-    assert (gen_num < (1 << (sizeof (uint8_t) * 8)));
-    assert (gen_num >= 0);
-    heap_segment_gen_num (region) = (uint8_t)gen_num;
-    uint8_t* region_start = get_region_start (region);
-    uint8_t* region_end = heap_segment_reserved (region);
-    size_t region_index_start = get_basic_region_index_for_address (region_start);
-    size_t region_index_end = get_basic_region_index_for_address (region_end);
-    region_info entry = (region_info)((gen_num << RI_PLAN_GEN_SHR) | gen_num);
-    for (size_t region_index = region_index_start; region_index < region_index_end; region_index++)
-    {
-        assert (gen_num <= max_generation);
-        map_region_to_generation[region_index] = entry;
-    }
-    if (gen_num <= soh_gen1)
-    {
-        if ((region_start < ephemeral_low) || (ephemeral_high < region_end))
-        {
-            while (true)
-            {
-                if (Interlocked::CompareExchange(&write_barrier_spin_lock.lock, 0, -1) < 0)
-                    break;
-                if ((ephemeral_low <= region_start) && (region_end <= ephemeral_high))
-                    return;
-                while (write_barrier_spin_lock.lock >= 0)
-                {
-                    YieldProcessor();           // indicate to the processor that we are spinning
-                }
-            }
-#ifdef _DEBUG
-            write_barrier_spin_lock.holding_thread = GCToEEInterface::GetThread();
-#endif //_DEBUG
-            if ((region_start < ephemeral_low) || (ephemeral_high < region_end))
-            {
-                uint8_t* new_ephemeral_low = min (region_start, (uint8_t*)ephemeral_low);
-                uint8_t* new_ephemeral_high = max (region_end, (uint8_t*)ephemeral_high);
-                dprintf (REGIONS_LOG, ("about to set ephemeral_low = %p ephemeral_high = %p", new_ephemeral_low, new_ephemeral_high));
-                stomp_write_barrier_ephemeral (new_ephemeral_low, new_ephemeral_high,
-                                               map_region_to_generation_skewed, (uint8_t)min_segment_size_shr);
-                if (ephemeral_low < new_ephemeral_low)
-                    GCToOSInterface::DebugBreak ();
-                if (new_ephemeral_high < ephemeral_high)
-                    GCToOSInterface::DebugBreak ();
-                ephemeral_low = new_ephemeral_low;
-                ephemeral_high = new_ephemeral_high;
-                dprintf (REGIONS_LOG, ("set ephemeral_low = %p ephemeral_high = %p", new_ephemeral_low, new_ephemeral_high));
-            }
-            else
-            {
-                dprintf (REGIONS_LOG, ("leaving lock - no need to update ephemeral range [%p,%p[ for region [%p,%p]", (uint8_t*)ephemeral_low, (uint8_t*)ephemeral_high, region_start, region_end));
-            }
-#ifdef _DEBUG
-            write_barrier_spin_lock.holding_thread = (Thread*)-1;
-#endif //_DEBUG
-            write_barrier_spin_lock.lock = -1;
-        }
-        else
-        {
-            dprintf (REGIONS_LOG, ("no need to update ephemeral range [%p,%p[ for region [%p,%p]", (uint8_t*)ephemeral_low, (uint8_t*)ephemeral_high, region_start, region_end));
-        }
-    }
-}
-inline
-void gc_heap::set_region_plan_gen_num (heap_segment* region, int plan_gen_num, bool replace_p)
-{
-    int gen_num = heap_segment_gen_num (region);
-    int supposed_plan_gen_num = get_plan_gen_num (gen_num);
-    dprintf (REGIONS_LOG, ("h%d setting plan gen on %p->%p(was gen%d) to %d(should be: %d) %s",
-        heap_number, region,
-        heap_segment_mem (region),
-        gen_num, plan_gen_num,
-        supposed_plan_gen_num,
-        ((plan_gen_num < supposed_plan_gen_num) ? "DEMOTED" : "ND")));
-    region_info region_info_bits_to_set = (region_info)(plan_gen_num << RI_PLAN_GEN_SHR);
-    if ((plan_gen_num < supposed_plan_gen_num) && (heap_segment_pinned_survived (region) != 0))
-    {
-        if (!settings.demotion)
-        {
-            settings.demotion = TRUE;
-        }
-        get_gc_data_per_heap()->set_mechanism_bit (gc_demotion_bit);
-        region->flags |= heap_segment_flags_demoted;
-        region_info_bits_to_set = (region_info)(region_info_bits_to_set | RI_DEMOTED);
-    }
-    else
-    {
-        region->flags &= ~heap_segment_flags_demoted;
-    }
-    if (replace_p)
-    {
-        int original_plan_gen_num = heap_segment_plan_gen_num (region);
-        planned_regions_per_gen[original_plan_gen_num]--;
-    }
-    planned_regions_per_gen[plan_gen_num]++;
-    dprintf (REGIONS_LOG, ("h%d g%d %zx(%zx) -> g%d (total %d region planned in g%d)",
-        heap_number, heap_segment_gen_num (region), (size_t)region, heap_segment_mem (region), plan_gen_num, planned_regions_per_gen[plan_gen_num], plan_gen_num));
-    heap_segment_plan_gen_num (region) = plan_gen_num;
-    uint8_t* region_start = get_region_start (region);
-    uint8_t* region_end = heap_segment_reserved (region);
-    size_t region_index_start = get_basic_region_index_for_address (region_start);
-    size_t region_index_end = get_basic_region_index_for_address (region_end);
-    for (size_t region_index = region_index_start; region_index < region_index_end; region_index++)
-    {
-        assert (plan_gen_num <= max_generation);
-        map_region_to_generation[region_index] = (region_info)(region_info_bits_to_set | (map_region_to_generation[region_index] & ~(RI_PLAN_GEN_MASK|RI_DEMOTED)));
-    }
-}
-inline
-void gc_heap::set_region_plan_gen_num_sip (heap_segment* region, int plan_gen_num)
-{
-    if (!heap_segment_swept_in_plan (region))
-    {
-        set_region_plan_gen_num (region, plan_gen_num);
-    }
-}
-void gc_heap::set_region_sweep_in_plan (heap_segment*region)
-{
-    heap_segment_swept_in_plan (region) = true;
-    assert (get_region_size (region) == global_region_allocator.get_region_alignment());
-    uint8_t* region_start = get_region_start (region);
-    size_t region_index = get_basic_region_index_for_address (region_start);
-    map_region_to_generation[region_index] = (region_info)(map_region_to_generation[region_index] | RI_SIP);
-}
-void gc_heap::clear_region_sweep_in_plan (heap_segment*region)
-{
-    heap_segment_swept_in_plan (region) = false;
-    assert (get_region_size (region) == global_region_allocator.get_region_alignment());
-    uint8_t* region_start = get_region_start (region);
-    size_t region_index = get_basic_region_index_for_address (region_start);
-    map_region_to_generation[region_index] = (region_info)(map_region_to_generation[region_index] & ~RI_SIP);
-}
-void gc_heap::clear_region_demoted (heap_segment* region)
-{
-    region->flags &= ~heap_segment_flags_demoted;
-    assert (get_region_size (region) == global_region_allocator.get_region_alignment());
-    uint8_t* region_start = get_region_start (region);
-    size_t region_index = get_basic_region_index_for_address (region_start);
-    map_region_to_generation[region_index] = (region_info)(map_region_to_generation[region_index] & ~RI_DEMOTED);
-}
-#endif //USE_REGIONS
-int gc_heap::get_plan_gen_num (int gen_number)
-{
-    return ((settings.promotion) ? min ((gen_number + 1), (int)max_generation) : gen_number);
-}
-uint8_t* gc_heap::get_uoh_start_object (heap_segment* region, generation* gen)
-{
-#ifdef USE_REGIONS
-    uint8_t* o = heap_segment_mem (region);
-#else
-    uint8_t* o = generation_allocation_start (gen);
-    assert(((CObjectHeader*)o)->IsFree());
-    size_t s = Align (size (o), get_alignment_constant (FALSE));
-    assert (s == AlignQword (min_obj_size));
-    o += s;
-#endif //USE_REGIONS
-    return o;
-}
-uint8_t* gc_heap::get_soh_start_object (heap_segment* region, generation* gen)
-{
-#ifdef USE_REGIONS
-    uint8_t* o             = heap_segment_mem (region);
-#else
-    uint8_t* o             = generation_allocation_start (gen);
-#endif //USE_REGIONS
-    return o;
-}
-size_t gc_heap::get_soh_start_obj_len (uint8_t* start_obj)
-{
-#ifdef USE_REGIONS
-    return 0;
-#else
-    return Align (size (start_obj));
-#endif //USE_REGIONS
-}
-void gc_heap::clear_gen1_cards()
-{
-#if defined(_DEBUG) && !defined(USE_REGIONS)
-    for (int x = 0; x <= max_generation; x++)
-    {
-        assert (generation_allocation_start (generation_of (x)));
-    }
-#endif //_DEBUG && !USE_REGIONS
-    if (!settings.demotion && settings.promotion)
-    {
-#ifdef USE_REGIONS
-        heap_segment* region = generation_start_segment (generation_of (1));
-        while (region)
-        {
-            clear_card_for_addresses (get_region_start (region), heap_segment_reserved (region));
-            region = heap_segment_next (region);
-        }
-#else //USE_REGIONS
-        clear_card_for_addresses (
-            generation_allocation_start (generation_of (1)),
-            generation_allocation_start (generation_of (0)));
-#endif //USE_REGIONS
-#ifdef _DEBUG
-        uint8_t* start = get_soh_start_object (ephemeral_heap_segment, youngest_generation);
-        assert (heap_segment_allocated (ephemeral_heap_segment) ==
-                (start + get_soh_start_obj_len (start)));
-#endif //_DEBUG
-    }
-}
-heap_segment* gc_heap::make_heap_segment (uint8_t* new_pages, size_t size, gc_heap* hp, int gen_num)
-{
-    gc_oh_num oh = gen_to_oh (gen_num);
-    size_t initial_commit = use_large_pages_p ? size : SEGMENT_INITIAL_COMMIT;
-    int h_number =
-#ifdef MULTIPLE_HEAPS
-        hp->heap_number;
-#else
-        0;
-#endif //MULTIPLE_HEAPS
-    if (!virtual_commit (new_pages, initial_commit, oh, h_number))
-    {
-        return 0;
-    }
-#ifdef USE_REGIONS
-    dprintf (REGIONS_LOG, ("Making region %p->%p(%zdmb)",
-        new_pages, (new_pages + size), (size / 1024 / 1024)));
-    heap_segment* new_segment = get_region_info (new_pages);
-    uint8_t* start = new_pages + sizeof (aligned_plug_and_gap);
-#else
-    heap_segment* new_segment = (heap_segment*)new_pages;
-    uint8_t* start = new_pages + segment_info_size;
-#endif //USE_REGIONS
-    heap_segment_mem (new_segment) = start;
-    heap_segment_used (new_segment) = start;
-    heap_segment_reserved (new_segment) = new_pages + size;
-    heap_segment_committed (new_segment) = new_pages + initial_commit;
-    init_heap_segment (new_segment, hp
-#ifdef USE_REGIONS
-                       , new_pages, size, gen_num
-#endif //USE_REGIONS
-                       );
-    dprintf (2, ("Creating heap segment %zx", (size_t)new_segment));
-    return new_segment;
-}
-void gc_heap::init_heap_segment (heap_segment* seg, gc_heap* hp
-#ifdef USE_REGIONS
-                                 , uint8_t* start, size_t size, int gen_num, bool existing_region_p
-#endif //USE_REGIONS
-    )
-{
-#ifndef USE_REGIONS
-    bool existing_region_p = false;
-#endif //!USE_REGIONS
-#ifdef BACKGROUND_GC
-    seg->flags = existing_region_p ? (seg->flags & heap_segment_flags_ma_committed) : 0;
-#else
-    seg->flags = 0;
-#endif
-    heap_segment_next (seg) = 0;
-    heap_segment_plan_allocated (seg) = heap_segment_mem (seg);
-    heap_segment_allocated (seg) = heap_segment_mem (seg);
-    heap_segment_saved_allocated (seg) = heap_segment_mem (seg);
-#if !defined(USE_REGIONS) || defined(MULTIPLE_HEAPS)
-    heap_segment_decommit_target (seg) = heap_segment_reserved (seg);
-#endif //!USE_REGIONS || MULTIPLE_HEAPS
-#ifdef BACKGROUND_GC
-    heap_segment_background_allocated (seg) = 0;
-    heap_segment_saved_bg_allocated (seg) = 0;
-#endif //BACKGROUND_GC
-#ifdef MULTIPLE_HEAPS
-    heap_segment_heap (seg) = hp;
-#endif //MULTIPLE_HEAPS
-#ifdef USE_REGIONS
-    int gen_num_for_region = min (gen_num, (int)max_generation);
-    set_region_gen_num (seg, gen_num_for_region);
-    heap_segment_plan_gen_num (seg) = gen_num_for_region;
-    heap_segment_swept_in_plan (seg) = false;
-#endif //USE_REGIONS
-#ifdef USE_REGIONS
-    int num_basic_regions = (int)(size >> min_segment_size_shr);
-    size_t basic_region_size = (size_t)1 << min_segment_size_shr;
-    dprintf (REGIONS_LOG, ("this region contains %d basic regions", num_basic_regions));
-    if (num_basic_regions > 1)
-    {
-        for (int i = 1; i < num_basic_regions; i++)
-        {
-            uint8_t* basic_region_start = start + (i * basic_region_size);
-            heap_segment* basic_region = get_region_info (basic_region_start);
-            heap_segment_allocated (basic_region) = (uint8_t*)(ptrdiff_t)-i;
-            dprintf (REGIONS_LOG, ("Initing basic region %p->%p(%zdmb) alloc to %p",
-                basic_region_start, (basic_region_start + basic_region_size),
-                (size_t)(basic_region_size / 1024 / 1024),
-                heap_segment_allocated (basic_region)));
-            heap_segment_gen_num (basic_region) = (uint8_t)gen_num_for_region;
-            heap_segment_plan_gen_num (basic_region) = gen_num_for_region;
-#ifdef MULTIPLE_HEAPS
-            heap_segment_heap (basic_region) = hp;
-#endif //MULTIPLE_HEAPS
-        }
-    }
-#endif //USE_REGIONS
-}
-void gc_heap::delete_heap_segment (heap_segment* seg, BOOL consider_hoarding)
-{
-    if (!heap_segment_uoh_p (seg))
-    {
-        clear_brick_table (heap_segment_mem (seg), heap_segment_reserved (seg));
-    }
-#ifdef USE_REGIONS
-    return_free_region (seg);
-#else // USE_REGIONS
-    if (consider_hoarding)
-    {
-        assert ((heap_segment_mem (seg) - (uint8_t*)seg) <= ptrdiff_t(2*OS_PAGE_SIZE));
-        size_t ss = (size_t) (heap_segment_reserved (seg) - (uint8_t*)seg);
-        if (ss <= INITIAL_ALLOC)
-        {
-            dprintf (2, ("Hoarding segment %zx", (size_t)seg));
-#ifdef BACKGROUND_GC
-            if (!heap_segment_decommitted_p (seg))
-#endif //BACKGROUND_GC
-            {
-                decommit_heap_segment (seg);
-            }
-            seg_mapping_table_remove_segment (seg);
-            heap_segment_next (seg) = segment_standby_list;
-            segment_standby_list = seg;
-            seg = 0;
-        }
-    }
-    if (seg != 0)
-    {
-        dprintf (2, ("h%d: del seg: [%zx, %zx[",
-                     heap_number, (size_t)seg,
-                     (size_t)(heap_segment_reserved (seg))));
-#ifdef BACKGROUND_GC
-        ::record_changed_seg ((uint8_t*)seg, heap_segment_reserved (seg),
-                            settings.gc_index, current_bgc_state,
-                            seg_deleted);
-        bgc_verify_mark_array_cleared (seg);
-        decommit_mark_array_by_seg (seg);
-#endif //BACKGROUND_GC
-        seg_mapping_table_remove_segment (seg);
-        release_segment (seg);
-    }
-#endif //USE_REGIONS
-}
-void gc_heap::reset_heap_segment_pages (heap_segment* seg)
-{
-    size_t page_start = align_on_page ((size_t)heap_segment_allocated (seg));
-    size_t size = (size_t)heap_segment_committed (seg) - page_start;
-    if (size != 0)
-        GCToOSInterface::VirtualReset((void*)page_start, size, false /* unlock */);
-}
-void gc_heap::decommit_heap_segment_pages (heap_segment* seg,
-                                           size_t extra_space)
-{
-    if (use_large_pages_p)
-        return;
-    uint8_t*  page_start = align_on_page (heap_segment_allocated(seg));
-    assert (heap_segment_committed (seg) >= page_start);
-    size_t size = heap_segment_committed (seg) - page_start;
-    extra_space = align_on_page (extra_space);
-    if (size >= max ((extra_space + 2*OS_PAGE_SIZE), MIN_DECOMMIT_SIZE))
-    {
-        page_start += max(extra_space, 32*OS_PAGE_SIZE);
-        decommit_heap_segment_pages_worker (seg, page_start);
-    }
-}
-size_t gc_heap::decommit_heap_segment_pages_worker (heap_segment* seg,
-                                                    uint8_t* new_committed)
-{
-    assert (!use_large_pages_p);
-    uint8_t* page_start = align_on_page (new_committed);
-    ptrdiff_t size = heap_segment_committed (seg) - page_start;
-    if (size > 0)
-    {
-        bool decommit_succeeded_p = virtual_decommit (page_start, (size_t)size, heap_segment_oh (seg), heap_number);
-        if (decommit_succeeded_p)
-        {
-            dprintf (3, ("Decommitting heap segment [%zx, %zx[(%zd)",
-                (size_t)page_start,
-                (size_t)(page_start + size),
-                size));
-            heap_segment_committed (seg) = page_start;
-            if (heap_segment_used (seg) > heap_segment_committed (seg))
-            {
-                heap_segment_used (seg) = heap_segment_committed (seg);
-            }
-        }
-        else
-        {
-            dprintf (3, ("Decommitting heap segment failed"));
-        }
-    }
-    return size;
-}
-void gc_heap::decommit_heap_segment (heap_segment* seg)
-{
-#ifdef USE_REGIONS
-    if (!dt_high_memory_load_p())
-    {
-        return;
-    }
-#endif
-    uint8_t*  page_start = align_on_page (heap_segment_mem (seg));
-    dprintf (3, ("Decommitting heap segment %zx(%p)", (size_t)seg, heap_segment_mem (seg)));
-#if defined(BACKGROUND_GC) && !defined(USE_REGIONS)
-    page_start += OS_PAGE_SIZE;
-#endif //BACKGROUND_GC && !USE_REGIONS
-    assert (heap_segment_committed (seg) >= page_start);
-    size_t size = heap_segment_committed (seg) - page_start;
-    bool decommit_succeeded_p = virtual_decommit (page_start, size, heap_segment_oh (seg), heap_number);
-    if (decommit_succeeded_p)
-    {
-        heap_segment_committed (seg) = page_start;
-        if (heap_segment_used (seg) > heap_segment_committed (seg))
-        {
-            heap_segment_used (seg) = heap_segment_committed (seg);
-        }
-    }
-}
-void gc_heap::clear_gen0_bricks()
-{
-    if (!gen0_bricks_cleared)
-    {
-        gen0_bricks_cleared = TRUE;
-#ifdef USE_REGIONS
-        heap_segment* gen0_region = generation_start_segment (generation_of (0));
-        while (gen0_region)
-        {
-            uint8_t* clear_start = heap_segment_mem (gen0_region);
-#else
-        heap_segment* gen0_region = ephemeral_heap_segment;
-        uint8_t* clear_start = generation_allocation_start (generation_of (0));
-        {
-#endif //USE_REGIONS
-            for (size_t b = brick_of (clear_start);
-                    b < brick_of (align_on_brick
-                                (heap_segment_allocated (gen0_region)));
-                    b++)
-            {
-                set_brick (b, -1);
-            }
-#ifdef USE_REGIONS
-            gen0_region = heap_segment_next (gen0_region);
-#endif //USE_REGIONS
-        }
-    }
-}
-void gc_heap::check_gen0_bricks()
-{
-    if (gen0_bricks_cleared)
-    {
-#ifdef USE_REGIONS
-        heap_segment* gen0_region = generation_start_segment (generation_of (0));
-        while (gen0_region)
-        {
-            uint8_t* start = heap_segment_mem (gen0_region);
-#else
-        heap_segment* gen0_region = ephemeral_heap_segment;
-        uint8_t* start = generation_allocation_start (generation_of (0));
-        {
-#endif //USE_REGIONS
-            size_t end_b = brick_of (heap_segment_allocated (gen0_region));
-            for (size_t b = brick_of (start); b < end_b; b++)
-            {
-                assert (brick_table[b] != 0);
-                if (brick_table[b] == 0)
-                {
-                    GCToOSInterface::DebugBreak();
-                }
-            }
-#ifdef USE_REGIONS
-            gen0_region = heap_segment_next (gen0_region);
-#endif //USE_REGIONS
-        }
-    }
-}
-#ifdef BACKGROUND_GC
-void gc_heap::rearrange_small_heap_segments()
-{
-    heap_segment* seg = freeable_soh_segment;
-    while (seg)
-    {
-        heap_segment* next_seg = heap_segment_next (seg);
-        delete_heap_segment (seg, FALSE);
-        seg = next_seg;
-    }
-    freeable_soh_segment = 0;
-}
-#endif //BACKGROUND_GC
-void gc_heap::rearrange_uoh_segments()
-{
-    dprintf (2, ("deleting empty large segments"));
-    heap_segment* seg = freeable_uoh_segment;
-    while (seg)
-    {
-        heap_segment* next_seg = heap_segment_next (seg);
-        delete_heap_segment (seg, GCConfig::GetRetainVM());
-        seg = next_seg;
-    }
-    freeable_uoh_segment = 0;
-}
-void gc_heap::delay_free_segments()
-{
-    rearrange_uoh_segments();
-#ifdef BACKGROUND_GC
-    background_delay_delete_uoh_segments();
-    if (!gc_heap::background_running_p())
-        rearrange_small_heap_segments();
-#endif //BACKGROUND_GC
-}
-#ifndef USE_REGIONS
-void gc_heap::rearrange_heap_segments(BOOL compacting)
-{
-    heap_segment* seg =
-        generation_start_segment (generation_of (max_generation));
-    heap_segment* prev_seg = 0;
-    heap_segment* next_seg = 0;
-    while (seg)
-    {
-        next_seg = heap_segment_next (seg);
-        if ((next_seg == 0) && (seg != ephemeral_heap_segment))
-        {
-            seg->next = ephemeral_heap_segment;
-            next_seg = heap_segment_next (seg);
-        }
-        if ((seg == ephemeral_heap_segment) && next_seg)
-        {
-            heap_segment_next (prev_seg) = next_seg;
-            heap_segment_next (seg) = 0;
-        }
-        else
-        {
-            uint8_t* end_segment = (compacting ?
-                                 heap_segment_plan_allocated (seg) :
-                                 heap_segment_allocated (seg));
-            if ((end_segment == heap_segment_mem (seg))&&
-                !heap_segment_read_only_p (seg))
-            {
-                assert (prev_seg);
-                assert (seg != ephemeral_heap_segment);
-                heap_segment_next (prev_seg) = next_seg;
-                delete_heap_segment (seg, GCConfig::GetRetainVM());
-                dprintf (2, ("Deleting heap segment %zx", (size_t)seg));
-            }
-            else
-            {
-                if (!heap_segment_read_only_p (seg))
-                {
-                    if (compacting)
-                    {
-                        heap_segment_allocated (seg) =
-                            heap_segment_plan_allocated (seg);
-                    }
-                    if (seg != ephemeral_heap_segment)
-                    {
-                        decommit_heap_segment_pages (seg, 0);
-                    }
-                }
-                prev_seg = seg;
-            }
-        }
-        seg = next_seg;
-    }
-}
-#endif //!USE_REGIONS
-#if defined(USE_REGIONS)
-static void remove_surplus_regions (region_free_list* free_list, region_free_list* surplus_list, size_t target_count)
-{
-    while (free_list->get_num_free_regions() > target_count)
-    {
-        heap_segment* region = free_list->unlink_region_front();
-        surplus_list->add_region_front (region);
-    }
-}
-static int64_t add_regions (region_free_list* free_list, region_free_list* surplus_list, size_t target_count)
-{
-    int64_t added_count = 0;
-    while (free_list->get_num_free_regions() < target_count)
-    {
-        if (surplus_list->get_num_free_regions() == 0)
-            break;
-        added_count++;
-        heap_segment* region = surplus_list->unlink_region_front();
-        free_list->add_region_front (region);
-    }
-    return added_count;
-}
-region_free_list::region_free_list() : num_free_regions (0),
-                                       size_free_regions (0),
-                                       size_committed_in_free_regions (0),
-                                       num_free_regions_added (0),
-                                       num_free_regions_removed (0),
-                                       head_free_region (nullptr),
-                                       tail_free_region (nullptr)
-{
-}
-void region_free_list::verify (bool empty_p)
-{
-#ifdef _DEBUG
-    assert ((num_free_regions == 0) == empty_p);
-    assert ((size_free_regions == 0) == empty_p);
-    assert ((size_committed_in_free_regions == 0) == empty_p);
-    assert ((head_free_region == nullptr) == empty_p);
-    assert ((tail_free_region == nullptr) == empty_p);
-    assert (num_free_regions == (num_free_regions_added - num_free_regions_removed));
-    if (!empty_p)
-    {
-        assert (heap_segment_next (tail_free_region) == nullptr);
-        assert (heap_segment_prev_free_region (head_free_region) == nullptr);
-        size_t actual_count = 0;
-        heap_segment* last_region = nullptr;
-        for (heap_segment* region = head_free_region; region != nullptr; region = heap_segment_next(region))
-        {
-            last_region = region;
-            actual_count++;
-        }
-        assert (num_free_regions == actual_count);
-        assert (last_region == tail_free_region);
-        heap_segment* first_region = nullptr;
-        for (heap_segment* region = tail_free_region; region != nullptr; region = heap_segment_prev_free_region(region))
-        {
-            first_region = region;
-            actual_count--;
-        }
-        assert (actual_count == 0);
-        assert (head_free_region == first_region);
-    }
-#endif
-}
-void region_free_list::reset()
-{
-    num_free_regions = 0;
-    size_free_regions = 0;
-    size_committed_in_free_regions = 0;
-    head_free_region = nullptr;
-    tail_free_region = nullptr;
-}
-inline
-void region_free_list::update_added_region_info (heap_segment* region)
-{
-    num_free_regions++;
-    num_free_regions_added++;
-    size_t region_size = get_region_size (region);
-    size_free_regions += region_size;
-    size_t region_committed_size = get_region_committed_size (region);
-    size_committed_in_free_regions += region_committed_size;
-    verify (false);
-}
-void region_free_list::add_region_front (heap_segment* region)
-{
-    assert (heap_segment_containing_free_list (region) == nullptr);
-    heap_segment_containing_free_list(region) = this;
-    if (head_free_region != nullptr)
-    {
-        heap_segment_prev_free_region(head_free_region) = region;
-        assert (tail_free_region != nullptr);
-    }
-    else
-    {
-        tail_free_region = region;
-    }
-    heap_segment_next (region) = head_free_region;
-    head_free_region = region;
-    heap_segment_prev_free_region (region) = nullptr;
-    update_added_region_info (region);
-}
-void region_free_list::add_region_in_descending_order (heap_segment* region_to_add)
-{
-    assert (heap_segment_containing_free_list (region_to_add) == nullptr);
-    heap_segment_containing_free_list (region_to_add) = this;
-    heap_segment_age_in_free (region_to_add) = 0;
-    heap_segment* prev_region = nullptr;
-    heap_segment* region = nullptr;
-    if (heap_segment_committed (region_to_add) == heap_segment_reserved (region_to_add))
-    {
-        region = head_free_region;
-    }
-    else
-    {
-        size_t region_to_add_committed = get_region_committed_size (region_to_add);
-        for (prev_region = tail_free_region; prev_region != nullptr; prev_region = heap_segment_prev_free_region (prev_region))
-        {
-            size_t prev_region_committed = get_region_committed_size (prev_region);
-            if (prev_region_committed >= region_to_add_committed)
-            {
-                break;
-            }
-            region = prev_region;
-        }
-    }
-    if (prev_region != nullptr)
-    {
-        heap_segment_next (prev_region) = region_to_add;
-    }
-    else
-    {
-        assert (region == head_free_region);
-        head_free_region = region_to_add;
-    }
-    heap_segment_prev_free_region (region_to_add) = prev_region;
-    heap_segment_next (region_to_add) = region;
-    if (region != nullptr)
-    {
-        heap_segment_prev_free_region (region) = region_to_add;
-    }
-    else
-    {
-        assert (prev_region == tail_free_region);
-        tail_free_region = region_to_add;
-    }
-    update_added_region_info (region_to_add);
-}
-heap_segment* region_free_list::unlink_region_front()
-{
-    heap_segment* region = head_free_region;
-    if (region != nullptr)
-    {
-        assert (heap_segment_containing_free_list (region) == this);
-        unlink_region (region);
-    }
-    return region;
-}
-void region_free_list::unlink_region (heap_segment* region)
-{
-    region_free_list* rfl = heap_segment_containing_free_list (region);
-    rfl->verify (false);
-    heap_segment* prev = heap_segment_prev_free_region (region);
-    heap_segment* next = heap_segment_next (region);
-    if (prev != nullptr)
-    {
-        assert (region != rfl->head_free_region);
-        assert (heap_segment_next (prev) == region);
-        heap_segment_next (prev) = next;
-    }
-    else
-    {
-        assert (region == rfl->head_free_region);
-        rfl->head_free_region = next;
-    }
-    if (next != nullptr)
-    {
-        assert (region != rfl->tail_free_region);
-        assert (heap_segment_prev_free_region (next) == region);
-        heap_segment_prev_free_region (next) = prev;
-    }
-    else
-    {
-        assert (region == rfl->tail_free_region);
-        rfl->tail_free_region = prev;
-    }
-    heap_segment_containing_free_list (region) = nullptr;
-    rfl->num_free_regions--;
-    rfl->num_free_regions_removed++;
-    size_t region_size = get_region_size (region);
-    assert (rfl->size_free_regions >= region_size);
-    rfl->size_free_regions -= region_size;
-    size_t region_committed_size = get_region_committed_size (region);
-    assert (rfl->size_committed_in_free_regions >= region_committed_size);
-    rfl->size_committed_in_free_regions -= region_committed_size;
-}
-free_region_kind region_free_list::get_region_kind (heap_segment* region)
-{
-    const size_t BASIC_REGION_SIZE = global_region_allocator.get_region_alignment();
-    const size_t LARGE_REGION_SIZE = global_region_allocator.get_large_region_alignment();
-    size_t region_size = get_region_size (region);
-    if (region_size == BASIC_REGION_SIZE)
-        return basic_free_region;
-    else if (region_size == LARGE_REGION_SIZE)
-        return large_free_region;
-    else
-    {
-        assert(region_size > LARGE_REGION_SIZE);
-        return huge_free_region;
-    }
-}
-heap_segment* region_free_list::unlink_smallest_region (size_t minimum_size)
-{
-    verify (num_free_regions == 0);
-    heap_segment* smallest_region = nullptr;
-    size_t smallest_size = (size_t)-1;
-    for (heap_segment* region = head_free_region; region != nullptr; region = heap_segment_next (region))
-    {
-        uint8_t* region_start = get_region_start(region);
-        uint8_t* region_end = heap_segment_reserved(region);
-        size_t region_size = get_region_size (region);
-        const size_t LARGE_REGION_SIZE = global_region_allocator.get_large_region_alignment();
-        assert (region_size >= LARGE_REGION_SIZE * 2);
-        if (region_size >= minimum_size)
-        {
-            if (smallest_size > region_size)
-            {
-                smallest_size = region_size;
-                smallest_region = region;
-            }
-            if (region_size == LARGE_REGION_SIZE * 2)
-            {
-                assert (region == smallest_region);
-                break;
-            }
-        }
-    }
-    if (smallest_region != nullptr)
-    {
-        unlink_region (smallest_region);
-        dprintf(REGIONS_LOG, ("get %p-%p-%p",
-            heap_segment_mem(smallest_region), heap_segment_committed(smallest_region), heap_segment_used(smallest_region)));
-    }
-    return smallest_region;
-}
-void region_free_list::transfer_regions (region_free_list* from)
-{
-    this->verify (this->num_free_regions == 0);
-    from->verify (from->num_free_regions == 0);
-    if (from->num_free_regions == 0)
-    {
-        return;
-    }
-    if (num_free_regions == 0)
-    {
-        head_free_region = from->head_free_region;
-        tail_free_region = from->tail_free_region;
-    }
-    else
-    {
-        heap_segment* this_tail = tail_free_region;
-        heap_segment* from_head = from->head_free_region;
-        heap_segment_next (this_tail) = from_head;
-        heap_segment_prev_free_region (from_head) = this_tail;
-        tail_free_region = from->tail_free_region;
-    }
-    for (heap_segment* region = from->head_free_region; region != nullptr; region = heap_segment_next (region))
-    {
-        heap_segment_containing_free_list (region) = this;
-    }
-    num_free_regions += from->num_free_regions;
-    num_free_regions_added += from->num_free_regions;
-    size_free_regions += from->size_free_regions;
-    size_committed_in_free_regions += from->size_committed_in_free_regions;
-    from->num_free_regions_removed += from->num_free_regions;
-    from->reset();
-    verify (false);
-}
-size_t region_free_list::get_num_free_regions()
-{
-#ifdef _DEBUG
-    verify (num_free_regions == 0);
-#endif //_DEBUG
-    return num_free_regions;
-}
-void region_free_list::add_region (heap_segment* region, region_free_list to_free_list[count_free_region_kinds])
-{
-    free_region_kind kind = get_region_kind (region);
-    to_free_list[kind].add_region_front (region);
-}
-void region_free_list::add_region_descending (heap_segment* region, region_free_list to_free_list[count_free_region_kinds])
-{
-    free_region_kind kind = get_region_kind (region);
-    to_free_list[kind].add_region_in_descending_order (region);
-}
-bool region_free_list::is_on_free_list (heap_segment* region, region_free_list free_list[count_free_region_kinds])
-{
-    region_free_list* rfl = heap_segment_containing_free_list (region);
-    free_region_kind kind = get_region_kind (region);
-    return rfl == &free_list[kind];
-}
-void region_free_list::age_free_regions()
-{
-    for (heap_segment* region = head_free_region; region != nullptr; region = heap_segment_next (region))
-    {
-        if (heap_segment_age_in_free (region) < MAX_AGE_IN_FREE)
-            heap_segment_age_in_free (region)++;
-    }
-}
-void region_free_list::age_free_regions (region_free_list free_lists[count_free_region_kinds])
-{
-    for (int kind = basic_free_region; kind < count_free_region_kinds; kind++)
-    {
-        free_lists[kind].age_free_regions();
-    }
-}
-void region_free_list::print (int hn, const char* msg, int* ages)
-{
-    dprintf (3, ("h%2d PRINTING-------------------------------", hn));
-    for (heap_segment* region = head_free_region; region != nullptr; region = heap_segment_next (region))
-    {
-        if (ages)
-        {
-            ages[heap_segment_age_in_free (region)]++;
-        }
-        dprintf (3, ("[%s] h%2d age %d region %p (%zd)%s",
-            msg, hn, (int)heap_segment_age_in_free (region),
-            heap_segment_mem (region), get_region_committed_size (region),
-            ((heap_segment_committed (region) == heap_segment_reserved (region)) ? "(FC)" : "")));
-    }
-    dprintf (3, ("h%2d PRINTING END-------------------------------", hn));
-}
-void region_free_list::print (region_free_list free_lists[count_free_region_kinds], int hn, const char* msg, int* ages)
-{
-    for (int kind = basic_free_region; kind < count_free_region_kinds; kind++)
-    {
-        free_lists[kind].print (hn, msg, ages);
-    }
-}
-static int compare_by_committed_and_age (heap_segment* l, heap_segment* r)
-{
-    size_t l_committed = get_region_committed_size (l);
-    size_t r_committed = get_region_committed_size (r);
-    if (l_committed > r_committed)
-        return -1;
-    else if (l_committed < r_committed)
-        return 1;
-    int l_age = heap_segment_age_in_free (l);
-    int r_age = heap_segment_age_in_free (r);
-    return (l_age - r_age);
-}
-static heap_segment* merge_sort_by_committed_and_age (heap_segment *head, size_t count)
-{
-    if (count <= 1)
-        return head;
-    size_t half = count / 2;
-    heap_segment* mid = nullptr;
-    size_t i = 0;
-    for (heap_segment *region = head; region != nullptr; region = heap_segment_next (region))
-    {
-        i++;
-        if (i == half)
-        {
-            mid = heap_segment_next (region);
-            heap_segment_next (region) = nullptr;
-            break;
-        }
-    }
-    head = merge_sort_by_committed_and_age (head, half);
-    mid = merge_sort_by_committed_and_age (mid, count - half);
-    heap_segment* new_head;
-    if (compare_by_committed_and_age (head, mid) <= 0)
-    {
-        new_head = head;
-        head = heap_segment_next (head);
-    }
-    else
-    {
-        new_head = mid;
-        mid = heap_segment_next (mid);
-    }
-    heap_segment* new_tail = new_head;
-    while ((head != nullptr) && (mid != nullptr))
-    {
-        heap_segment* region = nullptr;
-        if (compare_by_committed_and_age (head, mid) <= 0)
-        {
-            region = head;
-            head = heap_segment_next (head);
-        }
-        else
-        {
-            region = mid;
-            mid = heap_segment_next (mid);
-        }
-        heap_segment_next (new_tail) = region;
-        new_tail = region;
-    }
-    if (head != nullptr)
-    {
-        assert (mid == nullptr);
-        heap_segment_next (new_tail) = head;
-    }
-    else
-    {
-        heap_segment_next (new_tail) = mid;
-    }
-    return new_head;
-}
-void region_free_list::sort_by_committed_and_age()
-{
-    if (num_free_regions <= 1)
-        return;
-    heap_segment* new_head = merge_sort_by_committed_and_age (head_free_region, num_free_regions);
-    head_free_region = new_head;
-    heap_segment* prev = nullptr;
-    for (heap_segment* region = new_head; region != nullptr; region = heap_segment_next (region))
-    {
-        heap_segment_prev_free_region (region) = prev;
-        assert ((prev == nullptr) || (compare_by_committed_and_age (prev, region) <= 0));
-        prev = region;
-    }
-    tail_free_region = prev;
-}
-void gc_heap::age_free_regions (const char* msg)
-{
-    bool age_all_region_kinds = (settings.condemned_generation == max_generation);
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < n_heaps; i++)
-    {
-        gc_heap* hp = g_heaps[i];
-#else //MULTIPLE_HEAPS
-    {
-        gc_heap* hp = pGenGCHeap;
-        const int i = 0;
-#endif //MULTIPLE_HEAPS
-        if (age_all_region_kinds)
-        {
-            region_free_list::age_free_regions (hp->free_regions);
-            region_free_list::print (hp->free_regions, i, msg);
-        }
-        else
-        {
-            hp->free_regions[basic_free_region].age_free_regions();
-            hp->free_regions[basic_free_region].print (i, msg);
-        }
-    }
-}
-void gc_heap::distribute_free_regions()
-{
-    const int kind_count = large_free_region + 1;
-#ifdef MULTIPLE_HEAPS
-    BOOL joined_last_gc_before_oom = FALSE;
-    for (int i = 0; i < n_heaps; i++)
-    {
-        if (g_heaps[i]->last_gc_before_oom)
-        {
-            joined_last_gc_before_oom = TRUE;
-            break;
-        }
-    }
-#else
-    BOOL joined_last_gc_before_oom = last_gc_before_oom;
-#endif //MULTIPLE_HEAPS
-    if (settings.reason == reason_induced_aggressive)
-    {
-        global_regions_to_decommit[huge_free_region].transfer_regions (&global_free_huge_regions);
-#ifdef MULTIPLE_HEAPS
-        for (int i = 0; i < n_heaps; i++)
-        {
-            gc_heap* hp = g_heaps[i];
-#else //MULTIPLE_HEAPS
-        {
-            gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-            for (int kind = basic_free_region; kind < count_free_region_kinds; kind++)
-            {
-                global_regions_to_decommit[kind].transfer_regions (&hp->free_regions[kind]);
-            }
-        }
-        while (decommit_step(DECOMMIT_TIME_STEP_MILLISECONDS))
-        {
-        }
-#ifdef MULTIPLE_HEAPS
-        for (int i = 0; i < n_heaps; i++)
-        {
-            gc_heap* hp = g_heaps[i];
-            int hn = i;
-#else //MULTIPLE_HEAPS
-        {
-            gc_heap* hp = pGenGCHeap;
-            int hn  = 0;
-#endif //MULTIPLE_HEAPS
-            for (int i = 0; i < total_generation_count; i++)
-            {
-                generation* generation = hp->generation_of (i);
-                heap_segment* region = heap_segment_rw (generation_start_segment (generation));
-                while (region != nullptr)
-                {
-                    uint8_t* aligned_allocated = align_on_page (heap_segment_allocated (region));
-                    size_t end_space = heap_segment_committed (region) - aligned_allocated;
-                    if (end_space > 0)
-                    {
-                        virtual_decommit (aligned_allocated, end_space, gen_to_oh (i), hn);
-                        heap_segment_committed (region) = aligned_allocated;
-                        heap_segment_used (region) = min (heap_segment_used (region), heap_segment_committed (region));
-                        assert (heap_segment_committed (region) > heap_segment_mem (region));
-                    }
-                    region = heap_segment_next_rw (region);
-                }
-            }
-        }
-        return;
-    }
-    size_t total_num_free_regions[kind_count] = { 0, 0 };
-    size_t total_budget_in_region_units[kind_count] = { 0,  0 };
-    size_t num_decommit_regions_by_time = 0;
-    size_t size_decommit_regions_by_time = 0;
-    size_t heap_budget_in_region_units[MAX_SUPPORTED_CPUS][kind_count];
-    size_t min_heap_budget_in_region_units[MAX_SUPPORTED_CPUS];
-    size_t region_size[kind_count] = { global_region_allocator.get_region_alignment(), global_region_allocator.get_large_region_alignment() };
-    region_free_list surplus_regions[kind_count];
-    for (int kind = basic_free_region; kind < kind_count; kind++)
-    {
-        surplus_regions[kind].transfer_regions (&global_regions_to_decommit[kind]);
-    }
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < n_heaps; i++)
-    {
-        gc_heap* hp = g_heaps[i];
-#else //MULTIPLE_HEAPS
-    {
-        gc_heap* hp = pGenGCHeap;
-        const int i = 0;
-        const int n_heaps = 1;
-#endif //MULTIPLE_HEAPS
-        for (int kind = basic_free_region; kind < kind_count; kind++)
-        {
-            region_free_list& region_list = hp->free_regions[kind];
-            heap_segment* next_region = nullptr;
-            for (heap_segment* region = region_list.get_first_free_region(); region != nullptr; region = next_region)
-            {
-                next_region = heap_segment_next (region);
-                int age_in_free_to_decommit = min (max (AGE_IN_FREE_TO_DECOMMIT, n_heaps), MAX_AGE_IN_FREE);
-                if ((heap_segment_age_in_free (region) >= age_in_free_to_decommit) ||
-                    ((get_region_committed_size (region) == GC_PAGE_SIZE) && joined_last_gc_before_oom))
-                {
-                    num_decommit_regions_by_time++;
-                    size_decommit_regions_by_time += get_region_committed_size (region);
-                    dprintf (REGIONS_LOG, ("h%2d region %p age %2d, decommit",
-                        i, heap_segment_mem (region), heap_segment_age_in_free (region)));
-                    region_free_list::unlink_region (region);
-                    region_free_list::add_region (region, global_regions_to_decommit);
-                }
-            }
-            total_num_free_regions[kind] += region_list.get_num_free_regions();
-        }
-        global_free_huge_regions.transfer_regions (&hp->free_regions[huge_free_region]);
-        heap_budget_in_region_units[i][basic_free_region] = 0;
-        min_heap_budget_in_region_units[i] = 0;
-        heap_budget_in_region_units[i][large_free_region] = 0;
-    }
-    for (int gen = soh_gen0; gen < total_generation_count; gen++)
-    {
-        if ((gen <= soh_gen2) &&
-            total_budget_in_region_units[basic_free_region] >= (total_num_free_regions[basic_free_region] +
-                                                                surplus_regions[basic_free_region].get_num_free_regions()))
-        {
-            dprintf (REGIONS_LOG, ("out of free regions - skipping gen %d budget = %zd >= avail %zd",
-                gen,
-                total_budget_in_region_units[basic_free_region],
-                total_num_free_regions[basic_free_region] + surplus_regions[basic_free_region].get_num_free_regions()));
-            continue;
-        }
-#ifdef MULTIPLE_HEAPS
-        for (int i = 0; i < n_heaps; i++)
-        {
-            gc_heap* hp = g_heaps[i];
-#else //MULTIPLE_HEAPS
-        {
-            gc_heap* hp = pGenGCHeap;
-            const int i = 0;
-            const int n_heaps = 1;
-#endif //MULTIPLE_HEAPS
-            ptrdiff_t budget_gen = max (hp->estimate_gen_growth (gen), (ptrdiff_t)0);
-            int kind = gen >= loh_generation;
-            size_t budget_gen_in_region_units = (budget_gen + (region_size[kind] - 1)) / region_size[kind];
-            dprintf (REGIONS_LOG, ("h%2d gen %d has an estimated growth of %zd bytes (%zd regions)", i, gen, budget_gen, budget_gen_in_region_units));
-            if (gen <= soh_gen2)
-            {
-                min_heap_budget_in_region_units[i] = heap_budget_in_region_units[i][kind];
-            }
-            heap_budget_in_region_units[i][kind] += budget_gen_in_region_units;
-            total_budget_in_region_units[kind] += budget_gen_in_region_units;
-        }
-    }
-    dprintf (1, ("moved %2zd regions (%8zd) to decommit based on time", num_decommit_regions_by_time, size_decommit_regions_by_time));
-    global_free_huge_regions.transfer_regions (&global_regions_to_decommit[huge_free_region]);
-    size_t free_space_in_huge_regions = global_free_huge_regions.get_size_free_regions();
-    ptrdiff_t num_regions_to_decommit[kind_count];
-    int region_factor[kind_count] = { 1, LARGE_REGION_FACTOR };
-#ifdef TRACE_GC
-    const char* kind_name[count_free_region_kinds] = { "basic", "large", "huge"};
-#endif // TRACE_GC
-#ifndef MULTIPLE_HEAPS
-    const int n_heaps = 1;
-#endif //!MULTIPLE_HEAPS
-    size_t num_huge_region_units_to_consider[kind_count] = { 0, free_space_in_huge_regions / region_size[large_free_region] };
-    for (int kind = basic_free_region; kind < kind_count; kind++)
-    {
-        num_regions_to_decommit[kind] = surplus_regions[kind].get_num_free_regions();
-        dprintf(REGIONS_LOG, ("%zd %s free regions, %zd regions budget, %zd regions on decommit list, %zd huge regions to consider",
-            total_num_free_regions[kind],
-            kind_name[kind],
-            total_budget_in_region_units[kind],
-            num_regions_to_decommit[kind],
-            num_huge_region_units_to_consider[kind]));
-        total_num_free_regions[kind] += num_regions_to_decommit[kind];
-        ptrdiff_t balance = total_num_free_regions[kind] + num_huge_region_units_to_consider[kind] - total_budget_in_region_units[kind];
-        if (
-#ifdef BACKGROUND_GC
-            background_running_p() ||
-#endif
-            (balance < 0))
-        {
-            dprintf (REGIONS_LOG, ("distributing the %zd %s regions deficit", -balance, kind_name[kind]));
-#ifdef MULTIPLE_HEAPS
-            if (balance != 0)
-            {
-                ptrdiff_t curr_balance = 0;
-                ptrdiff_t rem_balance = 0;
-                for (int i = 0; i < n_heaps; i++)
-                {
-                    curr_balance += balance;
-                    ptrdiff_t adjustment_per_heap = curr_balance / n_heaps;
-                    curr_balance -= adjustment_per_heap * n_heaps;
-                    ptrdiff_t new_budget = (ptrdiff_t)heap_budget_in_region_units[i][kind] + adjustment_per_heap;
-                    ptrdiff_t min_budget = (kind == basic_free_region) ? (ptrdiff_t)min_heap_budget_in_region_units[i] : 0;
-                    dprintf (REGIONS_LOG, ("adjusting the budget for heap %d from %zd %s regions by %zd to %zd",
-                        i,
-                        heap_budget_in_region_units[i][kind],
-                        kind_name[kind],
-                        adjustment_per_heap,
-                        max (min_budget, new_budget)));
-                    heap_budget_in_region_units[i][kind] = max (min_budget, new_budget);
-                    rem_balance += new_budget - heap_budget_in_region_units[i][kind];
-                }
-                assert (rem_balance <= 0);
-                dprintf (REGIONS_LOG, ("remaining balance: %zd %s regions", rem_balance, kind_name[kind]));
-                while (rem_balance < 0)
-                {
-                    for (int i = 0; i < n_heaps; i++)
-                    {
-                        size_t min_budget = (kind == basic_free_region) ? min_heap_budget_in_region_units[i] : 0;
-                        if (heap_budget_in_region_units[i][kind] > min_budget)
-                        {
-                            dprintf (REGIONS_LOG, ("adjusting the budget for heap %d from %zd %s regions by %d to %zd",
-                                i,
-                                heap_budget_in_region_units[i][kind],
-                                kind_name[kind],
-                                -1,
-                                heap_budget_in_region_units[i][kind] - 1));
-                            heap_budget_in_region_units[i][kind] -= 1;
-                            rem_balance += 1;
-                            if (rem_balance == 0)
-                                break;
-                        }
-                    }
-                }
-            }
-#endif //MULTIPLE_HEAPS
-        }
-        else
-        {
-            num_regions_to_decommit[kind] = balance;
-            dprintf(REGIONS_LOG, ("distributing the %zd %s regions, removing %zd regions",
-                total_budget_in_region_units[kind],
-                kind_name[kind],
-                num_regions_to_decommit[kind]));
-            if (num_regions_to_decommit[kind] > 0)
-            {
-                size_t num_regions_to_decommit_before = global_regions_to_decommit[kind].get_num_free_regions();
-                global_region_allocator.move_highest_free_regions (num_regions_to_decommit[kind]*region_factor[kind],
-                                                                   kind == basic_free_region,
-                                                                   global_regions_to_decommit);
-                dprintf (REGIONS_LOG, ("Moved %zd %s regions to decommit list",
-                         global_regions_to_decommit[kind].get_num_free_regions(), kind_name[kind]));
-                if (kind == basic_free_region)
-                {
-                    assert (global_regions_to_decommit[kind].get_num_free_regions() ==
-                            num_regions_to_decommit_before + (size_t)num_regions_to_decommit[kind]);
-                }
-                else
-                {
-                    dprintf (REGIONS_LOG, ("Moved %zd %s regions to decommit list",
-                        global_regions_to_decommit[huge_free_region].get_num_free_regions(), kind_name[huge_free_region]));
-                }
-            }
-        }
-    }
-    for (int kind = basic_free_region; kind < kind_count; kind++)
-    {
-#ifdef MULTIPLE_HEAPS
-        for (int i = 0; i < n_heaps; i++)
-        {
-            gc_heap* hp = g_heaps[i];
-            if (hp->free_regions[kind].get_num_free_regions() > heap_budget_in_region_units[i][kind])
-            {
-                dprintf (REGIONS_LOG, ("removing %zd %s regions from heap %d with %zd regions, budget is %zd",
-                    hp->free_regions[kind].get_num_free_regions() - heap_budget_in_region_units[i][kind],
-                    kind_name[kind],
-                    i,
-                    hp->free_regions[kind].get_num_free_regions(),
-                    heap_budget_in_region_units[i][kind]));
-                remove_surplus_regions (&hp->free_regions[kind], &surplus_regions[kind], heap_budget_in_region_units[i][kind]);
-            }
-        }
-        for (int i = 0; i < n_heaps; i++)
-        {
-            gc_heap* hp = g_heaps[i];
-#else //MULTIPLE_HEAPS
-        {
-            gc_heap* hp = pGenGCHeap;
-            const int i = 0;
-#endif //MULTIPLE_HEAPS
-            if (hp->free_regions[kind].get_num_free_regions() < heap_budget_in_region_units[i][kind])
-            {
-                int64_t num_added_regions = add_regions (&hp->free_regions[kind], &surplus_regions[kind], heap_budget_in_region_units[i][kind]);
-                dprintf (REGIONS_LOG, ("added %zd %s regions to heap %d - now has %zd, budget is %zd",
-                    (size_t)num_added_regions,
-                    kind_name[kind],
-                    i,
-                    hp->free_regions[kind].get_num_free_regions(),
-                    heap_budget_in_region_units[i][kind]));
-            }
-            hp->free_regions[kind].sort_by_committed_and_age();
-        }
-        if (surplus_regions[kind].get_num_free_regions() > 0)
-        {
-            assert (!"should have exhausted the surplus_regions");
-            global_regions_to_decommit[kind].transfer_regions (&surplus_regions[kind]);
-        }
-    }
-#ifdef MULTIPLE_HEAPS
-    for (int kind = basic_free_region; kind < count_free_region_kinds; kind++)
-    {
-        if (global_regions_to_decommit[kind].get_num_free_regions() != 0)
-        {
-            gradual_decommit_in_progress_p = TRUE;
-            break;
-        }
-    }
-#else //MULTIPLE_HEAPS
-    dynamic_data* dd0 = dynamic_data_of (0);
-    size_t ephemeral_elapsed = (size_t)((dd_time_clock (dd0) - gc_last_ephemeral_decommit_time) / 1000);
-    if (ephemeral_elapsed >= DECOMMIT_TIME_STEP_MILLISECONDS)
-    {
-        gc_last_ephemeral_decommit_time = dd_time_clock (dd0);
-        size_t decommit_step_milliseconds = min (ephemeral_elapsed, (size_t)(10*1000));
-        decommit_step (decommit_step_milliseconds);
-    }
-    for (int kind = basic_free_region; kind < count_free_region_kinds; kind++)
-    {
-        if (global_regions_to_decommit[kind].get_num_free_regions() != 0)
-        {
-            free_regions[kind].transfer_regions (&global_regions_to_decommit[kind]);
-        }
-    }
-#endif //MULTIPLE_HEAPS
-}
-#endif //USE_REGIONS
-#ifdef WRITE_WATCH
-uint8_t* g_addresses [array_size+2]; // to get around the bug in GetWriteWatch
-#ifdef CARD_BUNDLE
-inline void gc_heap::verify_card_bundle_bits_set(size_t first_card_word, size_t last_card_word)
-{
-#ifdef _DEBUG
-    for (size_t x = cardw_card_bundle (first_card_word); x < cardw_card_bundle (last_card_word); x++)
-    {
-        if (!card_bundle_set_p (x))
-        {
-            assert (!"Card bundle not set");
-            dprintf (3, ("Card bundle %zx not set", x));
-        }
-    }
-#else
-    UNREFERENCED_PARAMETER(first_card_word);
-    UNREFERENCED_PARAMETER(last_card_word);
-#endif
-}
-inline void gc_heap::verify_card_bundles()
-{
-#ifdef _DEBUG
-    size_t lowest_card = card_word (card_of (lowest_address));
-#ifdef USE_REGIONS
-    size_t highest_card = card_word (card_of (global_region_allocator.get_left_used_unsafe()));
-#else
-    size_t highest_card = card_word (card_of (highest_address));
-#endif
-    size_t cardb = cardw_card_bundle (lowest_card);
-    size_t end_cardb = cardw_card_bundle (align_cardw_on_bundle (highest_card));
-    while (cardb < end_cardb)
-    {
-        uint32_t* card_word = &card_table[max(card_bundle_cardw (cardb), lowest_card)];
-        uint32_t* card_word_end = &card_table[min(card_bundle_cardw (cardb+1), highest_card)];
-        if (card_bundle_set_p (cardb) == 0)
-        {
-            while (card_word < card_word_end)
-            {
-                if (*card_word != 0)
-                {
-                    dprintf  (3, ("gc: %zd, Card word %zx for address %zx set, card_bundle %zx clear",
-                            dd_collection_count (dynamic_data_of (0)),
-                            (size_t)(card_word-&card_table[0]),
-                            (size_t)(card_address ((size_t)(card_word-&card_table[0]) * card_word_width)),
-                            cardb));
-                }
-                assert((*card_word)==0);
-                card_word++;
-            }
-        }
-        cardb++;
-    }
-#endif
-}
-void gc_heap::update_card_table_bundle()
-{
-    if (card_bundles_enabled())
-    {
-        uint8_t* base_address = (uint8_t*)(&card_table[card_word (card_of (lowest_address))]);
-#ifdef USE_REGIONS
-        uint8_t* high_address = (uint8_t*)(&card_table[card_word (card_of (global_region_allocator.get_left_used_unsafe()))]);
-#else
-        uint8_t* high_address = (uint8_t*)(&card_table[card_word (card_of (highest_address))]);
-#endif //USE_REGIONS
-        uint8_t* saved_base_address = base_address;
-        uintptr_t bcount = array_size;
-        size_t saved_region_size = align_on_page (high_address) - saved_base_address;
-        do
-        {
-            size_t region_size = align_on_page (high_address) - base_address;
-            dprintf (3,("Probing card table pages [%zx, %zx[",
-                (size_t)base_address, (size_t)(base_address + region_size)));
-            bool success = GCToOSInterface::GetWriteWatch(false /* resetState */,
-                                                          base_address,
-                                                          region_size,
-                                                          (void**)g_addresses,
-                                                          &bcount);
-            assert (success && "GetWriteWatch failed!");
-            dprintf (3,("Found %zd pages written", bcount));
-            for (unsigned i = 0; i < bcount; i++)
-            {
-                size_t bcardw = (uint32_t*)(max(g_addresses[i],base_address)) - &card_table[0];
-                size_t ecardw = (uint32_t*)(min(g_addresses[i]+OS_PAGE_SIZE, high_address)) - &card_table[0];
-                assert (bcardw >= card_word (card_of (g_gc_lowest_address)));
-                card_bundles_set (cardw_card_bundle (bcardw),
-                                  cardw_card_bundle (align_cardw_on_bundle (ecardw)));
-                dprintf (3,("Set Card bundle [%zx, %zx[",
-                    cardw_card_bundle (bcardw), cardw_card_bundle (align_cardw_on_bundle (ecardw))));
-                verify_card_bundle_bits_set(bcardw, ecardw);
-            }
-            if (bcount >= array_size)
-            {
-                base_address = g_addresses [array_size-1] + OS_PAGE_SIZE;
-                bcount = array_size;
-            }
-        } while ((bcount >= array_size) && (base_address < high_address));
-        GCToOSInterface::ResetWriteWatch (saved_base_address, saved_region_size);
-    }
-}
-#endif //CARD_BUNDLE
-#ifdef BACKGROUND_GC
-void gc_heap::reset_write_watch_for_gc_heap(void* base_address, size_t region_size)
-{
-#ifdef FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-    SoftwareWriteWatch::ClearDirty(base_address, region_size);
-#else // !FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-    GCToOSInterface::ResetWriteWatch(base_address, region_size);
-#endif // FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-}
-void gc_heap::get_write_watch_for_gc_heap(bool reset, void *base_address, size_t region_size,
-                                          void** dirty_pages, uintptr_t* dirty_page_count_ref,
-                                          bool is_runtime_suspended)
-{
-#ifdef FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-    SoftwareWriteWatch::GetDirty(base_address, region_size, dirty_pages, dirty_page_count_ref,
-                                 reset, is_runtime_suspended);
-#else // !FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-    UNREFERENCED_PARAMETER(is_runtime_suspended);
-    bool success = GCToOSInterface::GetWriteWatch(reset, base_address, region_size, dirty_pages,
-                                                  dirty_page_count_ref);
-    assert(success);
-#endif // FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-}
-const size_t ww_reset_quantum = 128*1024*1024;
-inline
-void gc_heap::switch_one_quantum()
-{
-    enable_preemptive ();
-    GCToOSInterface::Sleep (1);
-    disable_preemptive (true);
-}
-void gc_heap::reset_ww_by_chunk (uint8_t* start_address, size_t total_reset_size)
-{
-    size_t reset_size = 0;
-    size_t remaining_reset_size = 0;
-    size_t next_reset_size = 0;
-    while (reset_size != total_reset_size)
-    {
-        remaining_reset_size = total_reset_size - reset_size;
-        next_reset_size = ((remaining_reset_size >= ww_reset_quantum) ?
-            ww_reset_quantum : remaining_reset_size);
-        if (next_reset_size)
-        {
-            reset_write_watch_for_gc_heap(start_address, next_reset_size);
-            reset_size += next_reset_size;
-            switch_one_quantum();
-        }
-    }
-    assert (reset_size == total_reset_size);
-}
-void gc_heap::switch_on_reset (BOOL concurrent_p, size_t* current_total_reset_size, size_t last_reset_size)
-{
-    if (concurrent_p)
-    {
-        *current_total_reset_size += last_reset_size;
-        dprintf (2, ("reset %zd bytes so far", *current_total_reset_size));
-        if (*current_total_reset_size > ww_reset_quantum)
-        {
-            switch_one_quantum();
-            *current_total_reset_size = 0;
-        }
-    }
-}
-void gc_heap::reset_write_watch (BOOL concurrent_p)
-{
-#ifdef FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-    assert(!concurrent_p);
-#endif // FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-    dprintf (2, ("bgc lowest: %p, bgc highest: %p",
-        background_saved_lowest_address, background_saved_highest_address));
-    size_t reset_size = 0;
-    for (int i = get_start_generation_index(); i < total_generation_count; i++)
-    {
-        heap_segment* seg = heap_segment_rw (generation_start_segment (generation_of (i)));
-        while (seg)
-        {
-            uint8_t* base_address = align_lower_page (heap_segment_mem (seg));
-            base_address = max (base_address, background_saved_lowest_address);
-            uint8_t* high_address = ((seg == ephemeral_heap_segment) ?
-                alloc_allocated : heap_segment_allocated (seg));
-            high_address = min (high_address, background_saved_highest_address);
-            if (base_address < high_address)
-            {
-                size_t reset_size = 0;
-                size_t region_size = high_address - base_address;
-                dprintf (3, ("h%d, gen: %x, ww: [%zx(%zd)", heap_number, i, (size_t)base_address, region_size));
-                reset_write_watch_for_gc_heap(base_address, region_size);
-                switch_on_reset (concurrent_p, &reset_size, region_size);
-            }
-            seg = heap_segment_next_rw (seg);
-            concurrent_print_time_delta (i == max_generation ? "CRWW soh": "CRWW uoh");
-        }
-    }
-}
-#endif //BACKGROUND_GC
-#endif //WRITE_WATCH
-#ifdef BACKGROUND_GC
-void gc_heap::restart_vm()
-{
-    dprintf (3, ("Restarting EE"));
-    STRESS_LOG0(LF_GC, LL_INFO10000, "Concurrent GC: Restarting EE\n");
-    ee_proceed_event.Set();
-}
-inline
-void fire_alloc_wait_event (alloc_wait_reason awr, BOOL begin_p)
-{
-    if (awr != awr_ignored)
-    {
-        if (begin_p)
-        {
-            FIRE_EVENT(BGCAllocWaitBegin, awr);
-        }
-        else
-        {
-            FIRE_EVENT(BGCAllocWaitEnd, awr);
-        }
-    }
-}
-void gc_heap::fire_alloc_wait_event_begin (alloc_wait_reason awr)
-{
-    fire_alloc_wait_event (awr, TRUE);
-}
-void gc_heap::fire_alloc_wait_event_end (alloc_wait_reason awr)
-{
-    fire_alloc_wait_event (awr, FALSE);
-}
-#endif //BACKGROUND_GC
-void gc_heap::make_generation (int gen_num, heap_segment* seg, uint8_t* start)
-{
-    generation* gen = generation_of (gen_num);
-    gen->gen_num = gen_num;
-#ifndef USE_REGIONS
-    gen->allocation_start = start;
-    gen->plan_allocation_start = 0;
-#endif //USE_REGIONS
-    gen->allocation_context.alloc_ptr = 0;
-    gen->allocation_context.alloc_limit = 0;
-    gen->allocation_context.alloc_bytes = 0;
-    gen->allocation_context.alloc_bytes_uoh = 0;
-    gen->allocation_context_start_region = 0;
-    gen->start_segment = seg;
-#ifdef USE_REGIONS
-    dprintf (REGIONS_LOG, ("g%d start seg is %zx-%p", gen_num, (size_t)seg, heap_segment_mem (seg)));
-    gen->tail_region = seg;
-    gen->tail_ro_region = 0;
-#endif //USE_REGIONS
-    gen->allocation_segment = seg;
-    gen->free_list_space = 0;
-    gen->free_list_allocated = 0;
-    gen->end_seg_allocated = 0;
-    gen->condemned_allocated = 0;
-    gen->sweep_allocated = 0;
-    gen->free_obj_space = 0;
-    gen->allocation_size = 0;
-    gen->pinned_allocation_sweep_size = 0;
-    gen->pinned_allocation_compact_size = 0;
-    gen->allocate_end_seg_p = FALSE;
-    gen->free_list_allocator.clear();
-#ifdef DOUBLY_LINKED_FL
-    gen->set_bgc_mark_bit_p = FALSE;
-#endif //DOUBLY_LINKED_FL
-#ifdef FREE_USAGE_STATS
-    memset (gen->gen_free_spaces, 0, sizeof (gen->gen_free_spaces));
-    memset (gen->gen_current_pinned_free_spaces, 0, sizeof (gen->gen_current_pinned_free_spaces));
-    memset (gen->gen_plugs, 0, sizeof (gen->gen_plugs));
-#endif //FREE_USAGE_STATS
-}
-void gc_heap::adjust_ephemeral_limits ()
-{
-#ifndef USE_REGIONS
-    ephemeral_low = generation_allocation_start (generation_of (max_generation - 1));
-    ephemeral_high = heap_segment_reserved (ephemeral_heap_segment);
-    dprintf (3, ("new ephemeral low: %zx new ephemeral high: %zx",
-        (size_t)ephemeral_low, (size_t)ephemeral_high))
-#ifndef MULTIPLE_HEAPS
-    stomp_write_barrier_ephemeral(ephemeral_low, ephemeral_high);
-#endif // MULTIPLE_HEAPS
-#endif //USE_REGIONS
-}
-uint32_t adjust_heaps_hard_limit_worker (uint32_t nhp, size_t limit)
-{
-    if (!limit)
-        return nhp;
-    size_t aligned_limit =  align_on_segment_hard_limit (limit);
-    uint32_t nhp_oh = (uint32_t)(aligned_limit / min_segment_size_hard_limit);
-    nhp = min (nhp_oh, nhp);
-    return (max (nhp, 1u));
-}
-uint32_t gc_heap::adjust_heaps_hard_limit (uint32_t nhp)
-{
-#ifdef MULTIPLE_HEAPS
-    if (heap_hard_limit_oh[soh])
-    {
-        for (int i = 0; i < (total_oh_count - 1); i++)
-        {
-            nhp = adjust_heaps_hard_limit_worker (nhp, heap_hard_limit_oh[i]);
-        }
-    }
-    else if (heap_hard_limit)
-    {
-        nhp = adjust_heaps_hard_limit_worker (nhp, heap_hard_limit);
-    }
-#endif
-    return nhp;
-}
-size_t gc_heap::adjust_segment_size_hard_limit_va (size_t seg_size)
-{
-    return (use_large_pages_p ?
-            align_on_segment_hard_limit (seg_size) :
-            round_up_power2 (seg_size));
-}
-size_t gc_heap::adjust_segment_size_hard_limit (size_t limit, uint32_t nhp)
-{
-    if (!limit)
-    {
-        limit = min_segment_size_hard_limit;
-    }
-    size_t seg_size = align_on_segment_hard_limit (limit) / nhp;
-    return adjust_segment_size_hard_limit_va (seg_size);
-}
-#ifdef USE_REGIONS
-bool allocate_initial_regions(int number_of_heaps)
-{
-    initial_regions = new (nothrow) uint8_t*[number_of_heaps][total_generation_count][2];
-    if (initial_regions == nullptr)
-    {
-        return false;
-    }
-    for (int i = 0; i < number_of_heaps; i++)
-    {
-        bool succeed = global_region_allocator.allocate_large_region(
-            poh_generation,
-            &initial_regions[i][poh_generation][0],
-            &initial_regions[i][poh_generation][1], allocate_forward, 0, nullptr);
-        assert(succeed);
-    }
-    for (int i = 0; i < number_of_heaps; i++)
-    {
-        for (int gen_num = max_generation; gen_num >= 0; gen_num--)
-        {
-            bool succeed = global_region_allocator.allocate_basic_region(
-                gen_num,
-                &initial_regions[i][gen_num][0],
-                &initial_regions[i][gen_num][1], nullptr);
-            assert(succeed);
-        }
-    }
-    for (int i = 0; i < number_of_heaps; i++)
-    {
-        bool succeed = global_region_allocator.allocate_large_region(
-            loh_generation,
-            &initial_regions[i][loh_generation][0],
-            &initial_regions[i][loh_generation][1], allocate_forward, 0, nullptr);
-        assert(succeed);
-    }
-    return true;
-}
-#endif
-void
-gc_heap::suspend_EE ()
-{
-    dprintf (2, ("suspend_EE"));
-    GCToEEInterface::SuspendEE (SUSPEND_FOR_GC_PREP);
-}
-void
-gc_heap::restart_EE ()
-{
-    dprintf (2, ("restart_EE"));
-    GCToEEInterface::RestartEE (FALSE);
-}
-HRESULT gc_heap::initialize_gc (size_t soh_segment_size,
-                                size_t loh_segment_size,
-                                size_t poh_segment_size
-#ifdef MULTIPLE_HEAPS
-                                ,int number_of_heaps
-#endif //MULTIPLE_HEAPS
-)
-{
-#ifdef GC_CONFIG_DRIVEN
-    if (GCConfig::GetConfigLogEnabled())
-    {
-        gc_config_log = CreateLogFile(GCConfig::GetConfigLogFile(), true);
-        if (gc_config_log == NULL)
-        {
-            GCToEEInterface::LogErrorToHost("Cannot create log file");
-            return E_FAIL;
-        }
-        gc_config_log_buffer = new (nothrow) uint8_t [gc_config_log_buffer_size];
-        if (!gc_config_log_buffer)
-        {
-            fclose(gc_config_log);
-            return E_OUTOFMEMORY;
-        }
-        compact_ratio = static_cast<int>(GCConfig::GetCompactRatio());
-        cprintf (("%2s | %6s | %1s | %1s | %2s | %2s | %2s | %2s | %2s || %5s | %5s | %5s | %5s | %5s | %5s | %5s | %5s | %5s |",
-                "h#", // heap index
-                "GC", // GC index
-                "g", // generation
-                "C",  // compaction (empty means sweeping), 'M' means it was mandatory, 'W' means it was not
-                "EX", // heap expansion
-                "NF", // normal fit
-                "BF", // best fit (if it indicates neither NF nor BF it means it had to acquire a new seg.
-                "ML", // mark list
-                "DM", // demotion
-                "PreS", // short object before pinned plug
-                "PostS", // short object after pinned plug
-                "Merge", // merged pinned plugs
-                "Conv", // converted to pinned plug
-                "Pre", // plug before pinned plug but not after
-                "Post", // plug after pinned plug but not before
-                "PrPo", // plug both before and after pinned plug
-                "PreP", // pre short object padded
-                "PostP" // post short object padded
-                ));
-    }
-#endif //GC_CONFIG_DRIVEN
-    HRESULT hres = S_OK;
-    conserve_mem_setting = (int)GCConfig::GetGCConserveMem();
-#ifdef DYNAMIC_HEAP_COUNT
-    dynamic_adaptation_mode = (int)GCConfig::GetGCDynamicAdaptationMode();
-    if (GCConfig::GetHeapCount() != 0)
-    {
-        dynamic_adaptation_mode = 0;
-    }
-    if ((dynamic_adaptation_mode == dynamic_adaptation_to_application_sizes) && (conserve_mem_setting == 0))
-        conserve_mem_setting = 5;
-#ifdef STRESS_DYNAMIC_HEAP_COUNT
-    bgc_to_ngc2_ratio = (int)GCConfig::GetGCDBGCRatio();
-    dprintf (1, ("bgc_to_ngc2_ratio is %d", bgc_to_ngc2_ratio));
-#endif
-#endif //DYNAMIC_HEAP_COUNT
-    if (conserve_mem_setting < 0)
-        conserve_mem_setting = 0;
-    if (conserve_mem_setting > 9)
-        conserve_mem_setting = 9;
-    dprintf (1, ("conserve_mem_setting = %d", conserve_mem_setting));
-#ifdef WRITE_WATCH
-    hardware_write_watch_api_supported();
-#ifdef BACKGROUND_GC
-    if (can_use_write_watch_for_gc_heap() && GCConfig::GetConcurrentGC())
-    {
-        gc_can_use_concurrent = true;
-#ifndef FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-        virtual_alloc_hardware_write_watch = true;
-#endif // !FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-    }
-    else
-    {
-        gc_can_use_concurrent = false;
-    }
-    GCConfig::SetConcurrentGC(gc_can_use_concurrent);
-#else //BACKGROUND_GC
-    GCConfig::SetConcurrentGC(false);
-#endif //BACKGROUND_GC
-#endif //WRITE_WATCH
-#ifdef BACKGROUND_GC
-    segment_info_size = OS_PAGE_SIZE;
-#else
-    segment_info_size = Align (sizeof (heap_segment), get_alignment_constant (FALSE));
-#endif //BACKGROUND_GC
-    reserved_memory = 0;
-    size_t initial_heap_size = soh_segment_size + loh_segment_size + poh_segment_size;
-    uint16_t* heap_no_to_numa_node = nullptr;
-#ifdef MULTIPLE_HEAPS
-    reserved_memory_limit = initial_heap_size * number_of_heaps;
-    if (!heap_select::init(number_of_heaps))
-        return E_OUTOFMEMORY;
-    if (GCToOSInterface::CanEnableGCNumaAware())
-        heap_no_to_numa_node = heap_select::heap_no_to_numa_node;
-#else //MULTIPLE_HEAPS
-    reserved_memory_limit = initial_heap_size;
-    int number_of_heaps = 1;
-#endif //MULTIPLE_HEAPS
-    check_commit_cs.Initialize();
-#ifdef COMMITTED_BYTES_SHADOW
-    decommit_lock.Initialize();
-#endif //COMMITTED_BYTES_SHADOW
-#ifdef USE_REGIONS
-    if (regions_range)
-    {
-        size_t reserve_size = regions_range;
-        uint8_t* reserve_range = (uint8_t*)virtual_alloc (reserve_size, use_large_pages_p);
-        if (!reserve_range)
-            return E_OUTOFMEMORY;
-        if (!global_region_allocator.init (reserve_range, (reserve_range + reserve_size),
-                                           ((size_t)1 << min_segment_size_shr),
-                                           &g_gc_lowest_address, &g_gc_highest_address))
-            return E_OUTOFMEMORY;
-        if (!allocate_initial_regions(number_of_heaps))
-            return E_OUTOFMEMORY;
-    }
-    else
-    {
-        assert (!"cannot use regions without specifying the range!!!");
-        GCToEEInterface::LogErrorToHost("Cannot use regions without specifying the range (using DOTNET_GCRegionRange)");
-        return E_FAIL;
-    }
-#else //USE_REGIONS
-    bool separated_poh_p = use_large_pages_p &&
-                           heap_hard_limit_oh[soh] &&
-                           (GCConfig::GetGCHeapHardLimitPOH() == 0) &&
-                           (GCConfig::GetGCHeapHardLimitPOHPercent() == 0);
-    if (!reserve_initial_memory (soh_segment_size, loh_segment_size, poh_segment_size, number_of_heaps,
-                                 use_large_pages_p, separated_poh_p, heap_no_to_numa_node))
-        return E_OUTOFMEMORY;
-    if (use_large_pages_p)
-    {
-        if (heap_hard_limit_oh[soh])
-        {
-            heap_hard_limit_oh[soh] = soh_segment_size * number_of_heaps;
-            heap_hard_limit_oh[loh] = loh_segment_size * number_of_heaps;
-            heap_hard_limit_oh[poh] = poh_segment_size * number_of_heaps;
-            heap_hard_limit = heap_hard_limit_oh[soh] + heap_hard_limit_oh[loh] + heap_hard_limit_oh[poh];
-        }
-        else
-        {
-            assert (heap_hard_limit);
-            heap_hard_limit = (soh_segment_size + loh_segment_size + poh_segment_size) * number_of_heaps;
-        }
-    }
-#endif //USE_REGIONS
-#ifdef CARD_BUNDLE
-#ifdef MULTIPLE_HEAPS
-    uint64_t th = (uint64_t)MH_TH_CARD_BUNDLE*number_of_heaps;
-#else
-    uint64_t th = (uint64_t)SH_TH_CARD_BUNDLE;
-#endif //MULTIPLE_HEAPS
-    if (can_use_write_watch_for_card_table() && reserved_memory >= th)
-    {
-        settings.card_bundles = TRUE;
-    }
-    else
-    {
-        settings.card_bundles = FALSE;
-    }
-#endif //CARD_BUNDLE
-    settings.first_init();
-    int latency_level_from_config = static_cast<int>(GCConfig::GetLatencyLevel());
-    if (latency_level_from_config >= latency_level_first && latency_level_from_config <= latency_level_last)
-    {
-        gc_heap::latency_level = static_cast<gc_latency_level>(latency_level_from_config);
-    }
-    init_static_data();
-    g_gc_card_table = make_card_table (g_gc_lowest_address, g_gc_highest_address);
-    if (!g_gc_card_table)
-        return E_OUTOFMEMORY;
-    gc_started = FALSE;
-#ifdef MULTIPLE_HEAPS
-    g_heaps = new (nothrow) gc_heap* [number_of_heaps];
-    if (!g_heaps)
-        return E_OUTOFMEMORY;
-#ifdef _PREFAST_
-#pragma warning(push)
-#pragma warning(disable:22011) // Suppress PREFast warning about integer underflow/overflow
-#endif // _PREFAST_
-#if !defined(USE_REGIONS) || defined(_DEBUG)
-    g_promoted = new (nothrow) size_t [number_of_heaps*16];
-    if (!g_promoted)
-        return E_OUTOFMEMORY;
-#endif //!USE_REGIONS || _DEBUG
-#ifdef BACKGROUND_GC
-    g_bpromoted = new (nothrow) size_t [number_of_heaps*16];
-    if (!g_bpromoted)
-        return E_OUTOFMEMORY;
-#endif
-#ifdef MH_SC_MARK
-    g_mark_stack_busy = new (nothrow) int[(number_of_heaps+2)*HS_CACHE_LINE_SIZE/sizeof(int)];
-#endif //MH_SC_MARK
-#ifdef _PREFAST_
-#pragma warning(pop)
-#endif // _PREFAST_
-#ifdef MH_SC_MARK
-    if (!g_mark_stack_busy)
-        return E_OUTOFMEMORY;
-#endif //MH_SC_MARK
-    if (!create_thread_support (number_of_heaps))
-        return E_OUTOFMEMORY;
-#endif //MULTIPLE_HEAPS
-#ifdef MULTIPLE_HEAPS
-    yp_spin_count_unit = 32 * number_of_heaps;
-#else
-    yp_spin_count_unit = 32 * g_num_processors;
-#endif //MULTIPLE_HEAPS
-    int64_t spin_count_unit_from_config = GCConfig::GetGCSpinCountUnit();
-    gc_heap::spin_count_unit_config_p = (spin_count_unit_from_config > 0) && (spin_count_unit_from_config <= MAX_YP_SPIN_COUNT_UNIT);
-    if (gc_heap::spin_count_unit_config_p)
-    {
-        yp_spin_count_unit = static_cast<int32_t>(spin_count_unit_from_config);
-    }
-    original_spin_count_unit = yp_spin_count_unit;
-#if (defined(MULTIPLE_HEAPS) && defined(DYNAMIC_HEAP_COUNT))
-    if ((dynamic_adaptation_mode == dynamic_adaptation_to_application_sizes) && (!gc_heap::spin_count_unit_config_p))
-    {
-        yp_spin_count_unit = 10;
-    }
-#endif // MULTIPLE_HEAPS && DYNAMIC_HEAP_COUNT
-#if defined(__linux__)
-    GCToEEInterface::UpdateGCEventStatus(static_cast<int>(GCEventStatus::GetEnabledLevel(GCEventProvider_Default)),
-                                         static_cast<int>(GCEventStatus::GetEnabledKeywords(GCEventProvider_Default)),
-                                         static_cast<int>(GCEventStatus::GetEnabledLevel(GCEventProvider_Private)),
-                                         static_cast<int>(GCEventStatus::GetEnabledKeywords(GCEventProvider_Private)));
-#endif // __linux__
-#ifdef USE_VXSORT
-    InitSupportedInstructionSet ((int32_t)GCConfig::GetGCEnabledInstructionSets());
-#endif
-    if (!init_semi_shared())
-    {
-        GCToEEInterface::LogErrorToHost("PER_HEAP_ISOLATED data members initialization failed");
-        hres = E_FAIL;
-    }
-    return hres;
-}
-int
-gc_heap::init_semi_shared()
-{
-    int ret = 0;
-#ifdef BGC_SERVO_TUNING
-    uint32_t current_memory_load = 0;
-    uint32_t sweep_flr_goal = 0;
-    uint32_t sweep_flr_goal_loh = 0;
-#endif //BGC_SERVO_TUNING
-#ifndef USE_REGIONS
-    eph_gen_starts_size = (Align (min_obj_size)) * max_generation;
-#endif //!USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-    mark_list_size = min ((size_t)100*1024, max ((size_t)8192, soh_segment_size/(2*10*32)));
-#ifdef DYNAMIC_HEAP_COUNT
-    if (dynamic_adaptation_mode == dynamic_adaptation_to_application_sizes)
-    {
-        g_mark_list_total_size = mark_list_size;
-    }
-    else
-#endif //DYNAMIC_HEAP_COUNT
-    {
-        g_mark_list_total_size = mark_list_size*n_heaps;
-    }
-    g_mark_list = make_mark_list (g_mark_list_total_size);
-    min_balance_threshold = alloc_quantum_balance_units * CLR_SIZE * 2;
-    g_mark_list_copy = make_mark_list (g_mark_list_total_size);
-    if (!g_mark_list_copy)
-    {
-        goto cleanup;
-    }
-#else //MULTIPLE_HEAPS
-    mark_list_size = min((size_t)100*1024, max ((size_t)8192, soh_segment_size/(64*32)));
-    g_mark_list_total_size = mark_list_size;
-    g_mark_list = make_mark_list (mark_list_size);
-#endif //MULTIPLE_HEAPS
-    dprintf (3, ("mark_list_size: %zd", mark_list_size));
-    if (!g_mark_list)
-    {
-        goto cleanup;
-    }
-#ifdef MULTIPLE_HEAPS
-    max_decommit_step_size = ((DECOMMIT_SIZE_PER_MILLISECOND * DECOMMIT_TIME_STEP_MILLISECONDS) / n_heaps);
-    max_decommit_step_size = max (max_decommit_step_size, MIN_DECOMMIT_SIZE);
-#endif //MULTIPLE_HEAPS
-#ifdef FEATURE_BASICFREEZE
-    seg_table = sorted_table::make_sorted_table();
-    if (!seg_table)
-        goto cleanup;
-#endif //FEATURE_BASICFREEZE
-#ifndef USE_REGIONS
-    segment_standby_list = 0;
-#endif //USE_REGIONS
-    if (!full_gc_approach_event.CreateManualEventNoThrow(FALSE))
-    {
-        goto cleanup;
-    }
-    if (!full_gc_end_event.CreateManualEventNoThrow(FALSE))
-    {
-        goto cleanup;
-    }
-    fgn_loh_percent = 0;
-    full_gc_approach_event_set = false;
-    memset (full_gc_counts, 0, sizeof (full_gc_counts));
-#ifndef USE_REGIONS
-    should_expand_in_full_gc = FALSE;
-#endif //!USE_REGIONS
-#ifdef FEATURE_LOH_COMPACTION
-    loh_compaction_always_p = GCConfig::GetLOHCompactionMode() != 0;
-    loh_compaction_mode = loh_compaction_default;
-#endif //FEATURE_LOH_COMPACTION
-#ifdef BGC_SERVO_TUNING
-    memset (bgc_tuning::gen_calc, 0, sizeof (bgc_tuning::gen_calc));
-    memset (bgc_tuning::gen_stats, 0, sizeof (bgc_tuning::gen_stats));
-    memset (bgc_tuning::current_bgc_end_data, 0, sizeof (bgc_tuning::current_bgc_end_data));
-    bgc_tuning::enable_fl_tuning = (GCConfig::GetBGCFLTuningEnabled() != 0);
-    bgc_tuning::memory_load_goal = (uint32_t)GCConfig::GetBGCMemGoal();
-    bgc_tuning::memory_load_goal_slack = (uint32_t)GCConfig::GetBGCMemGoalSlack();
-    bgc_tuning::ml_kp = (double)GCConfig::GetBGCMLkp() / 1000.0;
-    bgc_tuning::ml_ki = (double)GCConfig::GetBGCMLki() / 1000.0;
-    bgc_tuning::ratio_correction_step = (double)GCConfig::GetBGCG2RatioStep() / 100.0;
-    bgc_tuning::above_goal_kp = (double)GCConfig::GetBGCFLkp() / 1000000.0;
-    bgc_tuning::enable_ki = (GCConfig::GetBGCFLEnableKi() != 0);
-    bgc_tuning::above_goal_ki = (double)GCConfig::GetBGCFLki() / 1000000.0;
-    bgc_tuning::enable_kd = (GCConfig::GetBGCFLEnableKd() != 0);
-    bgc_tuning::above_goal_kd = (double)GCConfig::GetBGCFLkd() / 100.0;
-    bgc_tuning::enable_smooth = (GCConfig::GetBGCFLEnableSmooth() != 0);
-    bgc_tuning::num_gen1s_smooth_factor = (double)GCConfig::GetBGCFLSmoothFactor() / 100.0;
-    bgc_tuning::enable_tbh = (GCConfig::GetBGCFLEnableTBH() != 0);
-    bgc_tuning::enable_ff = (GCConfig::GetBGCFLEnableFF() != 0);
-    bgc_tuning::above_goal_ff = (double)GCConfig::GetBGCFLff() / 100.0;
-    bgc_tuning::enable_gradual_d = (GCConfig::GetBGCFLGradualD() != 0);
-    sweep_flr_goal = (uint32_t)GCConfig::GetBGCFLSweepGoal();
-    sweep_flr_goal_loh = (uint32_t)GCConfig::GetBGCFLSweepGoalLOH();
-    bgc_tuning::gen_calc[0].sweep_flr_goal = ((sweep_flr_goal == 0) ? 20.0 : (double)sweep_flr_goal);
-    bgc_tuning::gen_calc[1].sweep_flr_goal = ((sweep_flr_goal_loh == 0) ? 20.0 : (double)sweep_flr_goal_loh);
-    bgc_tuning::available_memory_goal = (uint64_t)((double)gc_heap::total_physical_mem * (double)(100 - bgc_tuning::memory_load_goal) / 100);
-    get_memory_info (&current_memory_load);
-    dprintf (BGC_TUNING_LOG, ("BTL tuning %s!!!",
-        (bgc_tuning::enable_fl_tuning ? "enabled" : "disabled")));
-#ifdef SIMPLE_DPRINTF
-    dprintf (BGC_TUNING_LOG, ("BTL tuning parameters: mem goal: %d%%(%zd), +/-%d%%, gen2 correction factor: %.2f, sweep flr goal: %d%%, smooth factor: %.3f(%s), TBH: %s, FF: %.3f(%s), ml: kp %.5f, ki %.10f",
-        bgc_tuning::memory_load_goal,
-        bgc_tuning::available_memory_goal,
-        bgc_tuning::memory_load_goal_slack,
-        bgc_tuning::ratio_correction_step,
-        (int)bgc_tuning::gen_calc[0].sweep_flr_goal,
-        bgc_tuning::num_gen1s_smooth_factor,
-        (bgc_tuning::enable_smooth ? "enabled" : "disabled"),
-        (bgc_tuning::enable_tbh ? "enabled" : "disabled"),
-        bgc_tuning::above_goal_ff,
-        (bgc_tuning::enable_ff ? "enabled" : "disabled"),
-        bgc_tuning::ml_kp,
-        bgc_tuning::ml_ki));
-    dprintf (BGC_TUNING_LOG, ("BTL tuning parameters: kp: %.5f, ki: %.5f (%s), kd: %.3f (kd-%s, gd-%s), ff: %.3f",
-        bgc_tuning::above_goal_kp,
-        bgc_tuning::above_goal_ki,
-        (bgc_tuning::enable_ki ? "enabled" : "disabled"),
-        bgc_tuning::above_goal_kd,
-        (bgc_tuning::enable_kd ? "enabled" : "disabled"),
-        (bgc_tuning::enable_gradual_d ? "enabled" : "disabled"),
-        bgc_tuning::above_goal_ff));
-#endif //SIMPLE_DPRINTF
-    if (bgc_tuning::enable_fl_tuning && (current_memory_load < bgc_tuning::memory_load_goal))
-    {
-        uint32_t distance_to_goal = bgc_tuning::memory_load_goal - current_memory_load;
-        bgc_tuning::stepping_interval = max (distance_to_goal / 10, 1u);
-        bgc_tuning::last_stepping_mem_load = current_memory_load;
-        bgc_tuning::last_stepping_bgc_count = 0;
-        dprintf (BGC_TUNING_LOG, ("current ml: %d, %d to goal, interval: %d",
-            current_memory_load, distance_to_goal, bgc_tuning::stepping_interval));
-    }
-    else
-    {
-        dprintf (BGC_TUNING_LOG, ("current ml: %d, >= goal: %d, disable stepping",
-            current_memory_load, bgc_tuning::memory_load_goal));
-        bgc_tuning::use_stepping_trigger_p = false;
-    }
-#endif //BGC_SERVO_TUNING
-#ifdef BACKGROUND_GC
-    memset (ephemeral_fgc_counts, 0, sizeof (ephemeral_fgc_counts));
-    bgc_alloc_spin_count = static_cast<uint32_t>(GCConfig::GetBGCSpinCount());
-    bgc_alloc_spin = static_cast<uint32_t>(GCConfig::GetBGCSpin());
-    {
-        int number_bgc_threads = get_num_heaps();
-        if (!create_bgc_threads_support (number_bgc_threads))
-        {
-            goto cleanup;
-        }
-    }
-#endif //BACKGROUND_GC
-    memset (&current_no_gc_region_info, 0, sizeof (current_no_gc_region_info));
-#ifdef GC_CONFIG_DRIVEN
-    compact_or_sweep_gcs[0] = 0;
-    compact_or_sweep_gcs[1] = 0;
-#endif //GC_CONFIG_DRIVEN
-#if defined(SHORT_PLUGS) && !defined(USE_REGIONS)
-    short_plugs_pad_ratio = (double)DESIRED_PLUG_LENGTH / (double)(DESIRED_PLUG_LENGTH - Align (min_obj_size));
-#endif //SHORT_PLUGS && !USE_REGIONS
-    generation_skip_ratio_threshold = (int)GCConfig::GetGCLowSkipRatio();
-#ifdef FEATURE_EVENT_TRACE
-    gc_time_info = new (nothrow) uint64_t[max_compact_time_type];
-    if (!gc_time_info)
-    {
-        goto cleanup;
-    }
-#ifdef BACKGROUND_GC
-    bgc_time_info = new (nothrow) uint64_t[max_bgc_time_type];
-    if (!bgc_time_info)
-    {
-        goto cleanup;
-    }
-#endif //BACKGROUND_GC
-#ifdef FEATURE_LOH_COMPACTION
-    loh_compact_info = new (nothrow) etw_loh_compact_info [get_num_heaps()];
-    if (!loh_compact_info)
-    {
-        goto cleanup;
-    }
-#endif //FEATURE_LOH_COMPACTION
-#endif //FEATURE_EVENT_TRACE
-    reset_mm_p = TRUE;
-    ret = 1;
-cleanup:
-    if (!ret)
-    {
-        if (full_gc_approach_event.IsValid())
-        {
-            full_gc_approach_event.CloseEvent();
-        }
-        if (full_gc_end_event.IsValid())
-        {
-            full_gc_end_event.CloseEvent();
-        }
-    }
-    return ret;
-}
-gc_heap* gc_heap::make_gc_heap (
-#ifdef MULTIPLE_HEAPS
-                                GCHeap* vm_hp,
-                                int heap_number
-#endif //MULTIPLE_HEAPS
-                                )
-{
-    gc_heap* res = 0;
-#ifdef MULTIPLE_HEAPS
-    res = new (nothrow) gc_heap;
-    if (!res)
-        return 0;
-    res->vm_heap = vm_hp;
-    res->alloc_context_count = 0;
-#ifndef USE_REGIONS
-    res->mark_list_piece_start = new (nothrow) uint8_t**[n_heaps];
-    if (!res->mark_list_piece_start)
-        return 0;
-#ifdef _PREFAST_
-#pragma warning(push)
-#pragma warning(disable:22011) // Suppress PREFast warning about integer underflow/overflow
-#endif // _PREFAST_
-    res->mark_list_piece_end = new (nothrow) uint8_t**[n_heaps + 32]; // +32 is padding to reduce false sharing
-#ifdef _PREFAST_
-#pragma warning(pop)
-#endif // _PREFAST_
-    if (!res->mark_list_piece_end)
-        return 0;
-#endif //!USE_REGIONS
-#endif //MULTIPLE_HEAPS
-    if (res->init_gc_heap (
-#ifdef MULTIPLE_HEAPS
-        heap_number
-#else  //MULTIPLE_HEAPS
-        0
-#endif //MULTIPLE_HEAPS
-        )==0)
-    {
-        return 0;
-    }
-#ifdef MULTIPLE_HEAPS
-    return res;
-#else
-    return (gc_heap*)1;
-#endif //MULTIPLE_HEAPS
-}
-uint32_t
-gc_heap::wait_for_gc_done(int32_t timeOut)
-{
-    bool cooperative_mode = enable_preemptive ();
-    uint32_t dwWaitResult = NOERROR;
-    gc_heap* wait_heap = NULL;
-    while (gc_heap::gc_started)
-    {
-#ifdef MULTIPLE_HEAPS
-        wait_heap = GCHeap::GetHeap(heap_select::select_heap(NULL))->pGenGCHeap;
-        dprintf(2, ("waiting for the gc_done_event on heap %d", wait_heap->heap_number));
-#endif // MULTIPLE_HEAPS
-#ifdef _PREFAST_
-        PREFIX_ASSUME(wait_heap != NULL);
-#endif // _PREFAST_
-        dwWaitResult = wait_heap->gc_done_event.Wait(timeOut, FALSE);
-    }
-    disable_preemptive (cooperative_mode);
-    return dwWaitResult;
-}
-void
-gc_heap::set_gc_done()
-{
-    enter_gc_done_event_lock();
-    if (!gc_done_event_set)
-    {
-        gc_done_event_set = true;
-        dprintf (2, ("heap %d: setting gc_done_event", heap_number));
-        gc_done_event.Set();
-    }
-    exit_gc_done_event_lock();
-}
-void
-gc_heap::reset_gc_done()
-{
-    enter_gc_done_event_lock();
-    if (gc_done_event_set)
-    {
-        gc_done_event_set = false;
-        dprintf (2, ("heap %d: resetting gc_done_event", heap_number));
-        gc_done_event.Reset();
-    }
-    exit_gc_done_event_lock();
-}
-void
-gc_heap::enter_gc_done_event_lock()
-{
-    uint32_t dwSwitchCount = 0;
-retry:
-    if (Interlocked::CompareExchange(&gc_done_event_lock, 0, -1) >= 0)
-    {
-        while (gc_done_event_lock >= 0)
-        {
-            if  (g_num_processors > 1)
-            {
-                int spin_count = yp_spin_count_unit;
-                for (int j = 0; j < spin_count; j++)
-                {
-                    if  (gc_done_event_lock < 0)
-                        break;
-                    YieldProcessor();           // indicate to the processor that we are spinning
-                }
-                if  (gc_done_event_lock >= 0)
-                    GCToOSInterface::YieldThread(++dwSwitchCount);
-            }
-            else
-                GCToOSInterface::YieldThread(++dwSwitchCount);
-        }
-        goto retry;
-    }
-}
-void
-gc_heap::exit_gc_done_event_lock()
-{
-    gc_done_event_lock = -1;
-}
-#ifndef MULTIPLE_HEAPS
-#ifdef RECORD_LOH_STATE
-int gc_heap::loh_state_index = 0;
-gc_heap::loh_state_info gc_heap::last_loh_states[max_saved_loh_states];
-#endif //RECORD_LOH_STATE
-VOLATILE(int32_t) gc_heap::gc_done_event_lock;
-VOLATILE(bool) gc_heap::gc_done_event_set;
-GCEvent gc_heap::gc_done_event;
-#endif //!MULTIPLE_HEAPS
-VOLATILE(bool) gc_heap::internal_gc_done;
-void gc_heap::add_saved_spinlock_info (
-            bool loh_p,
-            msl_enter_state enter_state,
-            msl_take_state take_state,
-            enter_msl_status msl_status)
-{
-#ifdef SPINLOCK_HISTORY
-    if (!loh_p || (msl_status == msl_retry_different_heap))
-    {
-        return;
-    }
-    spinlock_info* current = &last_spinlock_info[spinlock_info_index];
-    current->enter_state = enter_state;
-    current->take_state = take_state;
-    current->current_uoh_alloc_state = current_uoh_alloc_state;
-    current->thread_id.SetToCurrentThread();
-    current->loh_p = loh_p;
-    dprintf (SPINLOCK_LOG, ("[%d]%s %s %s",
-        heap_number,
-        (loh_p ? "loh" : "soh"),
-        ((enter_state == me_acquire) ? "E" : "L"),
-        msl_take_state_str[take_state]));
-    spinlock_info_index++;
-    assert (spinlock_info_index <= max_saved_spinlock_info);
-    if (spinlock_info_index >= max_saved_spinlock_info)
-    {
-        spinlock_info_index = 0;
-    }
-#else
-    UNREFERENCED_PARAMETER(enter_state);
-    UNREFERENCED_PARAMETER(take_state);
-#endif //SPINLOCK_HISTORY
-}
-int
-gc_heap::init_gc_heap (int h_number)
-{
-#ifdef MULTIPLE_HEAPS
-#ifdef _DEBUG
-    memset (committed_by_oh_per_heap, 0, sizeof (committed_by_oh_per_heap));
-#endif //_DEBUG
-    g_heaps [h_number] = this;
-    time_bgc_last = 0;
-#ifdef SPINLOCK_HISTORY
-    spinlock_info_index = 0;
-    memset (last_spinlock_info, 0, sizeof(last_spinlock_info));
-#endif //SPINLOCK_HISTORY
-#ifndef USE_REGIONS
-    ephemeral_low = (uint8_t*)1;
-    ephemeral_high = MAX_PTR;
-#endif //!USE_REGIONS
-    gc_low = 0;
-    gc_high = 0;
-    ephemeral_heap_segment = 0;
-    oomhist_index_per_heap = 0;
-    freeable_uoh_segment = 0;
-    condemned_generation_num = 0;
-    blocking_collection = FALSE;
-    generation_skip_ratio = 100;
-#ifdef FEATURE_CARD_MARKING_STEALING
-    n_eph_soh = 0;
-    n_gen_soh = 0;
-    n_eph_loh = 0;
-    n_gen_loh = 0;
-#endif //FEATURE_CARD_MARKING_STEALING
-    mark_stack_tos = 0;
-    mark_stack_bos = 0;
-    mark_stack_array_length = 0;
-    mark_stack_array = 0;
-#if defined (_DEBUG) && defined (VERIFY_HEAP)
-    verify_pinned_queue_p = FALSE;
-#endif // _DEBUG && VERIFY_HEAP
-#ifdef FEATURE_LOH_COMPACTION
-    loh_pinned_queue_tos = 0;
-    loh_pinned_queue_bos = 0;
-    loh_pinned_queue_length = 0;
-    loh_pinned_queue_decay = LOH_PIN_DECAY;
-    loh_pinned_queue = 0;
-#endif //FEATURE_LOH_COMPACTION
-    min_overflow_address = MAX_PTR;
-    max_overflow_address = 0;
-    gen0_bricks_cleared = FALSE;
-    gen0_must_clear_bricks = 0;
-    allocation_quantum = CLR_SIZE;
-    more_space_lock_soh = gc_lock;
-    more_space_lock_uoh = gc_lock;
-    loh_alloc_since_cg = 0;
-#ifndef USE_REGIONS
-    new_heap_segment = NULL;
-    ro_segments_in_range = FALSE;
-#endif //!USE_REGIONS
-    gen0_allocated_after_gc_p = false;
-#ifdef RECORD_LOH_STATE
-    loh_state_index = 0;
-#endif //RECORD_LOH_STATE
-#ifdef USE_REGIONS
-    new_gen0_regions_in_plns = 0;
-    new_regions_in_prr = 0;
-    new_regions_in_threading = 0;
-    special_sweep_p = false;
-#endif //USE_REGIONS
-#endif //MULTIPLE_HEAPS
-#ifdef MULTIPLE_HEAPS
-    if (h_number > n_heaps)
-    {
-        assert (!"Number of heaps exceeded");
-        return 0;
-    }
-    heap_number = h_number;
-#endif //MULTIPLE_HEAPS
-    memset (etw_allocation_running_amount, 0, sizeof (etw_allocation_running_amount));
-    memset (allocated_since_last_gc, 0, sizeof (allocated_since_last_gc));
-    memset (&oom_info, 0, sizeof (oom_info));
-    memset (&fgm_result, 0, sizeof (fgm_result));
-    memset (oomhist_per_heap, 0, sizeof (oomhist_per_heap));
-    if (!gc_done_event.CreateManualEventNoThrow(FALSE))
-    {
-        return 0;
-    }
-    gc_done_event_lock = -1;
-    gc_done_event_set = false;
-#ifdef DYNAMIC_HEAP_COUNT
-    hchist_index_per_heap = 0;
-    memset (hchist_per_heap, 0, sizeof (hchist_per_heap));
-#ifdef BACKGROUND_GC
-    bgc_hchist_index_per_heap = 0;
-    memset (bgc_hchist_per_heap, 0, sizeof (bgc_hchist_per_heap));
-#endif //BACKGROUND_GC
-    if (h_number != 0)
-    {
-        if (!gc_idle_thread_event.CreateAutoEventNoThrow (FALSE))
-        {
-            return 0;
-        }
-#ifdef BACKGROUND_GC
-        if (!bgc_idle_thread_event.CreateAutoEventNoThrow (FALSE))
-        {
-            return 0;
-        }
-#endif //BACKGROUND_GC
-        dprintf (9999, ("creating idle events for h%d", h_number));
-    }
-#endif //DYNAMIC_HEAP_COUNT
-    if (!init_dynamic_data())
-    {
-        return 0;
-    }
-    uint32_t* ct = &g_gc_card_table [card_word (card_of (g_gc_lowest_address))];
-    own_card_table (ct);
-    card_table = translate_card_table (ct);
-    brick_table = card_table_brick_table (ct);
-    highest_address = card_table_highest_address (ct);
-    lowest_address = card_table_lowest_address (ct);
-#ifdef CARD_BUNDLE
-    card_bundle_table = translate_card_bundle_table (card_table_card_bundle_table (ct), g_gc_lowest_address);
-    assert (&card_bundle_table [card_bundle_word (cardw_card_bundle (card_word (card_of (g_gc_lowest_address))))] ==
-            card_table_card_bundle_table (ct));
-#endif //CARD_BUNDLE
-#ifdef BACKGROUND_GC
-    background_saved_highest_address = nullptr;
-    background_saved_lowest_address = nullptr;
-    if (gc_can_use_concurrent)
-        mark_array = translate_mark_array (card_table_mark_array (&g_gc_card_table[card_word (card_of (g_gc_lowest_address))]));
-    else
-        mark_array = NULL;
-#endif //BACKGROUND_GC
-#ifdef USE_REGIONS
-#ifdef STRESS_REGIONS
-    disable_preemptive (true);
-    pinning_handles_for_alloc = new (nothrow) (OBJECTHANDLE[PINNING_HANDLE_INITIAL_LENGTH]);
-    for (int i = 0; i < PINNING_HANDLE_INITIAL_LENGTH; i++)
-    {
-        pinning_handles_for_alloc[i] = g_gcGlobalHandleStore->CreateHandleOfType (0, HNDTYPE_PINNED);
-    }
-    enable_preemptive();
-    ph_index_per_heap = 0;
-    pinning_seg_interval = 2;
-    num_gen0_regions = 0;
-    sip_seg_interval = 2;
-    sip_seg_maxgen_interval = 3;
-    num_condemned_regions = 0;
-#endif //STRESS_REGIONS
-    end_gen0_region_space = 0;
-    end_gen0_region_committed_space = 0;
-    gen0_pinned_free_space = 0;
-    gen0_large_chunk_found = false;
-    if (!initial_make_soh_regions (__this) ||
-        !initial_make_uoh_regions (loh_generation, __this) ||
-        !initial_make_uoh_regions (poh_generation, __this))
-    {
-        return 0;
-    }
-#else //USE_REGIONS
-    heap_segment* seg = make_initial_segment (soh_gen0, h_number, __this);
-    if (!seg)
-        return 0;
-    FIRE_EVENT(GCCreateSegment_V1, heap_segment_mem(seg),
-                              (size_t)(heap_segment_reserved (seg) - heap_segment_mem(seg)),
-                              gc_etw_segment_small_object_heap);
-    seg_mapping_table_add_segment (seg, __this);
-#ifdef MULTIPLE_HEAPS
-    assert (heap_segment_heap (seg) == __this);
-#endif //MULTIPLE_HEAPS
-    uint8_t*  start = heap_segment_mem (seg);
-    for (int i = max_generation; i >= 0; i--)
-    {
-        make_generation (i, seg, start);
-        start += Align (min_obj_size);
-    }
-    heap_segment_allocated (seg) = start;
-    alloc_allocated = start;
-    heap_segment_used (seg) = start - plug_skew;
-    ephemeral_heap_segment = seg;
-    heap_segment* lseg = make_initial_segment(loh_generation, h_number, __this);
-    if (!lseg)
-        return 0;
-    lseg->flags |= heap_segment_flags_loh;
-    FIRE_EVENT(GCCreateSegment_V1, heap_segment_mem(lseg),
-                              (size_t)(heap_segment_reserved (lseg) - heap_segment_mem(lseg)),
-                              gc_etw_segment_large_object_heap);
-    heap_segment* pseg = make_initial_segment (poh_generation, h_number, __this);
-    if (!pseg)
-        return 0;
-    pseg->flags |= heap_segment_flags_poh;
-    FIRE_EVENT(GCCreateSegment_V1, heap_segment_mem(pseg),
-                              (size_t)(heap_segment_reserved (pseg) - heap_segment_mem(pseg)),
-                              gc_etw_segment_pinned_object_heap);
-    seg_mapping_table_add_segment (lseg, __this);
-    seg_mapping_table_add_segment (pseg, __this);
-    make_generation (loh_generation, lseg, heap_segment_mem (lseg));
-    make_generation (poh_generation, pseg, heap_segment_mem (pseg));
-    heap_segment_allocated (lseg) = heap_segment_mem (lseg) + Align (min_obj_size, get_alignment_constant (FALSE));
-    heap_segment_used (lseg) = heap_segment_allocated (lseg) - plug_skew;
-    heap_segment_allocated (pseg) = heap_segment_mem (pseg) + Align (min_obj_size, get_alignment_constant (FALSE));
-    heap_segment_used (pseg) = heap_segment_allocated (pseg) - plug_skew;
-    for (int gen_num = 0; gen_num < total_generation_count; gen_num++)
-    {
-        generation*  gen = generation_of (gen_num);
-        make_unused_array (generation_allocation_start (gen), Align (min_obj_size));
-    }
-#ifdef MULTIPLE_HEAPS
-    assert (heap_segment_heap (lseg) == __this);
-    assert (heap_segment_heap (pseg) == __this);
-#endif //MULTIPLE_HEAPS
-#endif //USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-    generation_alloc_context (generation_of (soh_gen0))->set_alloc_heap(vm_heap);
-    generation_alloc_context (generation_of (loh_generation))->set_alloc_heap(vm_heap);
-    generation_alloc_context (generation_of (poh_generation))->set_alloc_heap(vm_heap);
-#endif //MULTIPLE_HEAPS
-    generation_of (max_generation)->free_list_allocator = allocator(NUM_GEN2_ALIST, BASE_GEN2_ALIST_BITS, gen2_alloc_list, max_generation);
-    generation_of (loh_generation)->free_list_allocator = allocator(NUM_LOH_ALIST, BASE_LOH_ALIST_BITS, loh_alloc_list);
-    generation_of (poh_generation)->free_list_allocator = allocator(NUM_POH_ALIST, BASE_POH_ALIST_BITS, poh_alloc_list);
-    total_alloc_bytes_soh = 0;
-    total_alloc_bytes_uoh = 0;
-#ifdef MULTIPLE_HEAPS
-#ifdef STRESS_DYNAMIC_HEAP_COUNT
-    uoh_msl_before_gc_p = false;
-#endif //STRESS_DYNAMIC_HEAP_COUNT
-#else //MULTIPLE_HEAPS
-    allocation_running_amount = dd_min_size (dynamic_data_of (0));
-#endif //!MULTIPLE_HEAPS
-    fgn_maxgen_percent = 0;
-    fgn_last_alloc = dd_min_size (dynamic_data_of (0));
-    mark* arr = new (nothrow) (mark [MARK_STACK_INITIAL_LENGTH]);
-    if (!arr)
-        return 0;
-    make_mark_stack(arr);
-#ifdef BACKGROUND_GC
-    for (int i = uoh_start_generation; i < total_generation_count; i++)
-    {
-        uoh_a_no_bgc[i - uoh_start_generation] = 0;
-        uoh_a_bgc_marking[i - uoh_start_generation] = 0;
-        uoh_a_bgc_planning[i - uoh_start_generation] = 0;
-    }
-#ifdef BGC_SERVO_TUNING
-    bgc_maxgen_end_fl_size = 0;
-#endif //BGC_SERVO_TUNING
-    freeable_soh_segment = 0;
-    gchist_index_per_heap = 0;
-    if (gc_can_use_concurrent)
-    {
-        uint8_t** b_arr = new (nothrow) (uint8_t * [MARK_STACK_INITIAL_LENGTH]);
-        if (!b_arr)
-            return 0;
-        make_background_mark_stack(b_arr);
-    }
-#endif //BACKGROUND_GC
-#ifndef USE_REGIONS
-    ephemeral_low = generation_allocation_start(generation_of(max_generation - 1));
-    ephemeral_high = heap_segment_reserved(ephemeral_heap_segment);
-#endif //!USE_REGIONS
-    if (heap_number == 0)
-    {
-        stomp_write_barrier_initialize(
-#if defined(USE_REGIONS)
-            ephemeral_low, ephemeral_high,
-            map_region_to_generation_skewed, (uint8_t)min_segment_size_shr
-#elif defined(MULTIPLE_HEAPS)
-            reinterpret_cast<uint8_t*>(1), reinterpret_cast<uint8_t*>(~0)
-#else
-            ephemeral_low, ephemeral_high
-#endif //MULTIPLE_HEAPS || USE_REGIONS
-        );
-    }
-#ifdef MULTIPLE_HEAPS
-    if (!create_gc_thread ())
-        return 0;
-#endif //MULTIPLE_HEAPS
-#ifdef FEATURE_PREMORTEM_FINALIZATION
-    HRESULT hr = AllocateCFinalize(&finalize_queue);
-    if (FAILED(hr))
-        return 0;
-#endif // FEATURE_PREMORTEM_FINALIZATION
-#ifdef USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-    min_fl_list = 0;
-    num_fl_items_rethreaded_stage2 = 0;
-    free_list_space_per_heap = nullptr;
-#endif //MULTIPLE_HEAPS
-#else //USE_REGIONS
-    max_free_space_items = MAX_NUM_FREE_SPACES;
-    bestfit_seg = new (nothrow) seg_free_spaces (heap_number);
-    if (!bestfit_seg)
-    {
-        return 0;
-    }
-    if (!bestfit_seg->alloc())
-    {
-        return 0;
-    }
-#endif //USE_REGIONS
-    last_gc_before_oom = FALSE;
-    sufficient_gen0_space_p = FALSE;
-#ifdef MULTIPLE_HEAPS
-#ifdef HEAP_ANALYZE
-    heap_analyze_success = TRUE;
-    internal_root_array  = 0;
-    internal_root_array_index = 0;
-    internal_root_array_length = initial_internal_roots;
-    current_obj          = 0;
-    current_obj_size     = 0;
-#endif //HEAP_ANALYZE
-#endif // MULTIPLE_HEAPS
-#ifdef BACKGROUND_GC
-    bgc_thread_id.Clear();
-    if (!create_bgc_thread_support())
-    {
-        return 0;
-    }
-    bgc_alloc_lock = new (nothrow) exclusive_sync;
-    if (!bgc_alloc_lock)
-    {
-        return 0;
-    }
-    bgc_alloc_lock->init();
-    bgc_thread_running = 0;
-    bgc_thread = 0;
-    bgc_threads_timeout_cs.Initialize();
-    current_bgc_state = bgc_not_in_process;
-    background_soh_alloc_count = 0;
-    background_uoh_alloc_count = 0;
-    bgc_overflow_count = 0;
-    end_loh_size = dd_min_size (dynamic_data_of (loh_generation));
-    end_poh_size = dd_min_size (dynamic_data_of (poh_generation));
-    current_sweep_pos = 0;
-#ifdef DOUBLY_LINKED_FL
-    current_sweep_seg = 0;
-#endif //DOUBLY_LINKED_FL
-#endif //BACKGROUND_GC
-#ifdef GC_CONFIG_DRIVEN
-    memset(interesting_data_per_heap, 0, sizeof (interesting_data_per_heap));
-    memset(compact_reasons_per_heap, 0, sizeof (compact_reasons_per_heap));
-    memset(expand_mechanisms_per_heap, 0, sizeof (expand_mechanisms_per_heap));
-    memset(interesting_mechanism_bits_per_heap, 0, sizeof (interesting_mechanism_bits_per_heap));
-#endif //GC_CONFIG_DRIVEN
-    return 1;
-}
-void
-gc_heap::destroy_semi_shared()
-{
-    if (g_mark_list)
-        delete[] g_mark_list;
-#ifdef FEATURE_BASICFREEZE
-    seg_table->delete_sorted_table();
-    delete[] (char*)seg_table;
-#endif //FEATURE_BASICFREEZE
-}
-void
-gc_heap::self_destroy()
-{
-#ifdef BACKGROUND_GC
-    kill_gc_thread();
-#endif //BACKGROUND_GC
-    if (gc_done_event.IsValid())
-    {
-        gc_done_event.CloseEvent();
-    }
-    for (int i = get_start_generation_index(); i < total_generation_count; i++)
-    {
-        heap_segment* seg = heap_segment_rw (generation_start_segment (generation_of (i)));
-        PREFIX_ASSUME(seg != NULL);
-        while (seg)
-        {
-            heap_segment* next_seg = heap_segment_next_rw (seg);
-            delete_heap_segment (seg);
-            seg = next_seg;
-        }
-    }
-    release_card_table (card_table);
-    delete[] mark_stack_array;
-#ifdef FEATURE_PREMORTEM_FINALIZATION
-    if (finalize_queue)
-        delete finalize_queue;
-#endif // FEATURE_PREMORTEM_FINALIZATION
-}
-void
-gc_heap::destroy_gc_heap(gc_heap* heap)
-{
-    heap->self_destroy();
-    delete heap;
-}
-void gc_heap::shutdown_gc()
-{
-    destroy_semi_shared();
-#ifdef MULTIPLE_HEAPS
-    delete[] g_heaps;
-    destroy_thread_support();
-    n_heaps = 0;
-#endif //MULTIPLE_HEAPS
-    destroy_initial_memory();
-    GCToOSInterface::Shutdown();
-}
-inline
-BOOL gc_heap::size_fit_p (size_t size REQD_ALIGN_AND_OFFSET_DCL, uint8_t* alloc_pointer, uint8_t* alloc_limit,
-                          uint8_t* old_loc, int use_padding)
-{
-    BOOL already_padded = FALSE;
-#ifdef SHORT_PLUGS
-    if ((old_loc != 0) && (use_padding & USE_PADDING_FRONT))
-    {
-        alloc_pointer = alloc_pointer + Align (min_obj_size);
-        already_padded = TRUE;
-    }
-#endif //SHORT_PLUGS
-    if (!((old_loc == 0) || same_large_alignment_p (old_loc, alloc_pointer)))
-        size = size + switch_alignment_size (already_padded);
-#ifdef FEATURE_STRUCTALIGN
-    alloc_pointer = StructAlign(alloc_pointer, requiredAlignment, alignmentOffset);
-#endif // FEATURE_STRUCTALIGN
-    if (alloc_limit < alloc_pointer)
-    {
-        return FALSE;
-    }
-    if (old_loc != 0)
-    {
-        return (((size_t)(alloc_limit - alloc_pointer) >= (size + ((use_padding & USE_PADDING_TAIL)? Align(min_obj_size) : 0)))
-#ifdef SHORT_PLUGS
-                ||((!(use_padding & USE_PADDING_FRONT)) && ((alloc_pointer + size) == alloc_limit))
-#else //SHORT_PLUGS
-                ||((alloc_pointer + size) == alloc_limit)
-#endif //SHORT_PLUGS
-            );
-    }
-    else
-    {
-        assert (size == Align (min_obj_size));
-        return ((size_t)(alloc_limit - alloc_pointer) >= size);
-    }
-}
-inline
-BOOL gc_heap::a_size_fit_p (size_t size, uint8_t* alloc_pointer, uint8_t* alloc_limit,
-                            int align_const)
-{
-    if (alloc_limit < alloc_pointer)
-    {
-        return FALSE;
-    }
-    return ((size_t)(alloc_limit - alloc_pointer) >= (size + Align(min_obj_size, align_const)));
-}
-BOOL gc_heap::grow_heap_segment (heap_segment* seg, uint8_t* high_address, bool* hard_limit_exceeded_p)
-{
-    assert (high_address <= heap_segment_reserved (seg));
-    if (hard_limit_exceeded_p)
-        *hard_limit_exceeded_p = false;
-    if (align_on_page (high_address) > heap_segment_reserved (seg))
-        return FALSE;
-    if (high_address <= heap_segment_committed (seg))
-        return TRUE;
-    size_t c_size = align_on_page ((size_t)(high_address - heap_segment_committed (seg)));
-    c_size = max (c_size, commit_min_th);
-    c_size = min (c_size, (size_t)(heap_segment_reserved (seg) - heap_segment_committed (seg)));
-    if (c_size == 0)
-        return FALSE;
-    STRESS_LOG2(LF_GC, LL_INFO10000,
-                "Growing heap_segment: %zx high address: %zx\n",
-                (size_t)seg, (size_t)high_address);
-    bool ret = virtual_commit (heap_segment_committed (seg), c_size, heap_segment_oh (seg), heap_number, hard_limit_exceeded_p);
-    if (ret)
-    {
-        heap_segment_committed (seg) += c_size;
-        STRESS_LOG1(LF_GC, LL_INFO10000, "New commit: %zx\n",
-                    (size_t)heap_segment_committed (seg));
-        assert (heap_segment_committed (seg) <= heap_segment_reserved (seg));
-        assert (high_address <= heap_segment_committed (seg));
-#if defined(MULTIPLE_HEAPS) && !defined(USE_REGIONS)
-        assert (!gradual_decommit_in_progress_p ||
-                (seg != ephemeral_heap_segment) ||
-                (heap_segment_committed (seg) <= heap_segment_decommit_target (seg)));
-#endif //MULTIPLE_HEAPS && !USE_REGIONS
-    }
-    return !!ret;
-}
-inline
-int gc_heap::grow_heap_segment (heap_segment* seg, uint8_t* allocated, uint8_t* old_loc, size_t size,
-                                BOOL pad_front_p  REQD_ALIGN_AND_OFFSET_DCL)
-{
-    BOOL already_padded = FALSE;
-#ifdef SHORT_PLUGS
-    if ((old_loc != 0) && pad_front_p)
-    {
-        allocated = allocated + Align (min_obj_size);
-        already_padded = TRUE;
-    }
-#endif //SHORT_PLUGS
-    if (!((old_loc == 0) || same_large_alignment_p (old_loc, allocated)))
-        size += switch_alignment_size (already_padded);
-#ifdef FEATURE_STRUCTALIGN
-    size_t pad = ComputeStructAlignPad(allocated, requiredAlignment, alignmentOffset);
-    return grow_heap_segment (seg, allocated + pad + size);
-#else // FEATURE_STRUCTALIGN
-    return grow_heap_segment (seg, allocated + size);
-#endif // FEATURE_STRUCTALIGN
-}
-void gc_heap::thread_free_item_front (generation* gen, uint8_t* free_start, size_t free_size)
-{
-    make_unused_array (free_start, free_size);
-    generation_free_list_space (gen) += free_size;
-    generation_allocator(gen)->thread_item_front (free_start, free_size);
-    add_gen_free (gen->gen_num, free_size);
-    if (gen->gen_num == max_generation)
-    {
-        dprintf (2, ("AO h%d: gen2F+: %p(%zd)->%zd, FO: %zd",
-            heap_number, free_start, free_size,
-            generation_free_list_space (gen), generation_free_obj_space (gen)));
-    }
-}
-#ifdef DOUBLY_LINKED_FL
-void gc_heap::thread_item_front_added (generation* gen, uint8_t* free_start, size_t free_size)
-{
-    make_unused_array (free_start, free_size);
-    generation_free_list_space (gen) += free_size;
-    int bucket_index = generation_allocator(gen)->thread_item_front_added (free_start, free_size);
-    if (gen->gen_num == max_generation)
-    {
-        dprintf (2, ("AO [h%d] gen2FL+: %p(%zd)->%zd",
-            heap_number, free_start, free_size, generation_free_list_space (gen)));
-    }
-    add_gen_free (gen->gen_num, free_size);
-}
-#endif //DOUBLY_LINKED_FL
-void gc_heap::make_free_obj (generation* gen, uint8_t* free_start, size_t free_size)
-{
-    make_unused_array (free_start, free_size);
-    generation_free_obj_space (gen) += free_size;
-    if (gen->gen_num == max_generation)
-    {
-        dprintf (2, ("AO [h%d] gen2FO+: %p(%zd)->%zd",
-            heap_number, free_start, free_size, generation_free_obj_space (gen)));
-    }
-}
-void gc_heap::adjust_limit (uint8_t* start, size_t limit_size, generation* gen)
-{
-    dprintf (3, ("gc Expanding segment allocation"));
-    heap_segment* seg = generation_allocation_segment (gen);
-    if ((generation_allocation_limit (gen) != start) || (start != heap_segment_plan_allocated (seg)))
-    {
-        if (generation_allocation_limit (gen) == heap_segment_plan_allocated (seg))
-        {
-            assert (generation_allocation_pointer (gen) >= heap_segment_mem (seg));
-            assert (generation_allocation_pointer (gen) <= heap_segment_committed (seg));
-            heap_segment_plan_allocated (generation_allocation_segment (gen)) = generation_allocation_pointer (gen);
-        }
-        else
-        {
-            uint8_t*  hole = generation_allocation_pointer (gen);
-            size_t  size = (generation_allocation_limit (gen) - generation_allocation_pointer (gen));
-            if (size != 0)
-            {
-                dprintf (3, ("filling up hole: %p, size %zx", hole, size));
-                size_t allocated_size = generation_allocation_pointer (gen) - generation_allocation_context_start_region (gen);
-#ifdef DOUBLY_LINKED_FL
-                if (gen->gen_num == max_generation)
-                {
-                    if (allocated_size <= min_free_item_no_prev)
-                    {
-                        size_t* filler_free_obj_size_location = (size_t*)(generation_allocation_context_start_region (gen) +
-                                                                          min_free_item_no_prev);
-                        size_t filler_free_obj_size = 0;
-                        if (size >= (Align (min_free_list) + Align (min_obj_size)))
-                        {
-                            filler_free_obj_size = Align (min_obj_size);
-                            size_t fl_size = size - filler_free_obj_size;
-                            thread_item_front_added (gen, (hole + filler_free_obj_size), fl_size);
-                        }
-                        else
-                        {
-                            filler_free_obj_size = size;
-                        }
-                        generation_free_obj_space (gen) += filler_free_obj_size;
-                        *filler_free_obj_size_location = filler_free_obj_size;
-                        uint8_t* old_loc = generation_last_free_list_allocated (gen);
-                        uint8_t* saved_plug_and_gap = nullptr;
-                        if (saved_pinned_plug_index != INVALID_SAVED_PINNED_PLUG_INDEX)
-                        {
-                            saved_plug_and_gap = pinned_plug (pinned_plug_of (saved_pinned_plug_index)) - sizeof(plug_and_gap);
-                            dprintf (3333, ("[h%d] sppi: %zd mtos: %zd old_loc: %p pp: %p(%zd) offs: %zd",
-                                heap_number,
-                                saved_pinned_plug_index,
-                                mark_stack_tos,
-                                old_loc,
-                                pinned_plug (pinned_plug_of (saved_pinned_plug_index)),
-                                pinned_len (pinned_plug_of (saved_pinned_plug_index)),
-                                old_loc - saved_plug_and_gap));
-                        }
-                        size_t offset = old_loc - saved_plug_and_gap;
-                        if (offset < sizeof(gap_reloc_pair))
-                        {
-                            assert (offset <= sizeof(plug_and_gap) - min_obj_size);
-                            set_free_obj_in_compact_bit ((uint8_t*)(&pinned_plug_of (saved_pinned_plug_index)->saved_pre_plug_reloc) + offset);
-                        }
-                        else
-                        {
-#ifdef _DEBUG
-                            header(old_loc)->Validate();
-#endif //_DEBUG
-                            set_free_obj_in_compact_bit (old_loc);
-                        }
-                        dprintf (3333, ("[h%d] ac: %p->%p((%zd < %zd), Pset %p s->%zd", heap_number,
-                            generation_allocation_context_start_region (gen), generation_allocation_pointer (gen),
-                            allocated_size, min_free_item_no_prev, filler_free_obj_size_location, filler_free_obj_size));
-                    }
-                    else
-                    {
-                        if (size >= Align (min_free_list))
-                        {
-                            thread_item_front_added (gen, hole, size);
-                        }
-                        else
-                        {
-                            make_free_obj (gen, hole, size);
-                        }
-                    }
-                }
-                else
-#endif //DOUBLY_LINKED_FL
-                {
-                    if (size >= Align (min_free_list))
-                    {
-                        if (allocated_size < min_free_item_no_prev)
-                        {
-                            if (size >= (Align (min_free_list) + Align (min_obj_size)))
-                            {
-                                make_free_obj (gen, hole, min_obj_size);
-                                thread_free_item_front (gen, (hole + Align (min_obj_size)),
-                                    (size - Align (min_obj_size)));
-                            }
-                            else
-                            {
-                                dprintf (3, ("allocated size too small, can't put back rest on free list %zx",
-                                    allocated_size));
-                                make_free_obj (gen, hole, size);
-                            }
-                        }
-                        else
-                        {
-                            dprintf (3, ("threading hole in front of free list"));
-                            thread_free_item_front (gen, hole, size);
-                        }
-                    }
-                    else
-                    {
-                        make_free_obj (gen, hole, size);
-                    }
-                }
-            }
-        }
-        generation_allocation_pointer (gen) = start;
-        generation_allocation_context_start_region (gen) = start;
-    }
-    generation_allocation_limit (gen) = (start + limit_size);
-}
-void verify_mem_cleared (uint8_t* start, size_t size)
-{
-    if (!Aligned (size))
-    {
-        FATAL_GC_ERROR();
-    }
-    PTR_PTR curr_ptr = (PTR_PTR) start;
-    for (size_t i = 0; i < size / sizeof(PTR_PTR); i++)
-    {
-        if (*(curr_ptr++) != 0)
-        {
-            FATAL_GC_ERROR();
-        }
-    }
-}
-#if defined (VERIFY_HEAP) && defined (BACKGROUND_GC)
-void gc_heap::set_batch_mark_array_bits (uint8_t* start, uint8_t* end)
-{
-    size_t start_mark_bit = mark_bit_of (start);
-    size_t end_mark_bit = mark_bit_of (end);
-    unsigned int startbit = mark_bit_bit (start_mark_bit);
-    unsigned int endbit = mark_bit_bit (end_mark_bit);
-    size_t startwrd = mark_bit_word (start_mark_bit);
-    size_t endwrd = mark_bit_word (end_mark_bit);
-    dprintf (3, ("Setting all mark array bits between [%zx:%zx-[%zx:%zx",
-        (size_t)start, (size_t)start_mark_bit,
-        (size_t)end, (size_t)end_mark_bit));
-    unsigned int firstwrd = ~(lowbits (~0, startbit));
-    unsigned int lastwrd = ~(highbits (~0, endbit));
-    if (startwrd == endwrd)
-    {
-        unsigned int wrd = firstwrd & lastwrd;
-        mark_array[startwrd] |= wrd;
-        return;
-    }
-    if (startbit)
-    {
-        mark_array[startwrd] |= firstwrd;
-        startwrd++;
-    }
-    for (size_t wrdtmp = startwrd; wrdtmp < endwrd; wrdtmp++)
-    {
-        mark_array[wrdtmp] = ~(unsigned int)0;
-    }
-    if (endbit)
-    {
-        mark_array[endwrd] |= lastwrd;
-    }
-}
-void gc_heap::check_batch_mark_array_bits (uint8_t* start, uint8_t* end)
-{
-    size_t start_mark_bit = mark_bit_of (start);
-    size_t end_mark_bit = mark_bit_of (end);
-    unsigned int startbit = mark_bit_bit (start_mark_bit);
-    unsigned int endbit = mark_bit_bit (end_mark_bit);
-    size_t startwrd = mark_bit_word (start_mark_bit);
-    size_t endwrd = mark_bit_word (end_mark_bit);
-    unsigned int firstwrd = ~(lowbits (~0, startbit));
-    unsigned int lastwrd = ~(highbits (~0, endbit));
-    if (startwrd == endwrd)
-    {
-        unsigned int wrd = firstwrd & lastwrd;
-        if (mark_array[startwrd] & wrd)
-        {
-            dprintf  (1, ("The %x portion of mark bits at 0x%zx:0x%x(addr: 0x%p) were not cleared",
-                            wrd, startwrd,
-                            mark_array [startwrd], mark_word_address (startwrd)));
-            FATAL_GC_ERROR();
-        }
-        return;
-    }
-    if (startbit)
-    {
-        if (mark_array[startwrd] & firstwrd)
-        {
-            dprintf  (1, ("The %x portion of mark bits at 0x%zx:0x%x(addr: 0x%p) were not cleared",
-                            firstwrd, startwrd,
-                            mark_array [startwrd], mark_word_address (startwrd)));
-            FATAL_GC_ERROR();
-        }
-        startwrd++;
-    }
-    for (size_t wrdtmp = startwrd; wrdtmp < endwrd; wrdtmp++)
-    {
-        if (mark_array[wrdtmp])
-        {
-            dprintf  (1, ("The mark bits at 0x%zx:0x%x(addr: 0x%p) were not cleared",
-                            wrdtmp,
-                            mark_array [wrdtmp], mark_word_address (wrdtmp)));
-            FATAL_GC_ERROR();
-        }
-    }
-    if (endbit)
-    {
-        if (mark_array[endwrd] & lastwrd)
-        {
-            dprintf  (1, ("The %x portion of mark bits at 0x%x:0x%x(addr: 0x%p) were not cleared",
-                            lastwrd, lastwrd,
-                            mark_array [lastwrd], mark_word_address (lastwrd)));
-            FATAL_GC_ERROR();
-        }
-    }
-}
-#endif //VERIFY_HEAP && BACKGROUND_GC
-allocator::allocator (unsigned int num_b, int fbb, alloc_list* b, int gen)
-{
-    assert (num_b < MAX_BUCKET_COUNT);
-    num_buckets = num_b;
-    first_bucket_bits = fbb;
-    buckets = b;
-    gen_number = gen;
-}
-alloc_list& allocator::alloc_list_of (unsigned int bn)
-{
-    assert (bn < num_buckets);
-    if (bn == 0)
-        return first_bucket;
-    else
-        return buckets [bn-1];
-}
-size_t& allocator::alloc_list_damage_count_of (unsigned int bn)
-{
-    assert (bn < num_buckets);
-    if (bn == 0)
-        return first_bucket.alloc_list_damage_count();
-    else
-        return buckets [bn-1].alloc_list_damage_count();
-}
-void allocator::unlink_item (unsigned int bn, uint8_t* item, uint8_t* prev_item, BOOL use_undo_p)
-{
-    alloc_list* al = &alloc_list_of (bn);
-    uint8_t* next_item = free_list_slot(item);
-#ifdef DOUBLY_LINKED_FL
-    BOOL repair_list = !discard_if_no_fit_p ();
-#endif //DOUBLY_LINKED_FL
-    if (prev_item)
-    {
-        if (use_undo_p && (free_list_undo (prev_item) == UNDO_EMPTY))
-        {
-            assert (item == free_list_slot (prev_item));
-            free_list_undo (prev_item) = item;
-            alloc_list_damage_count_of (bn)++;
-        }
-        free_list_slot (prev_item) = next_item;
-    }
-    else
-    {
-        al->alloc_list_head() = next_item;
-    }
-    if (al->alloc_list_tail() == item)
-    {
-        al->alloc_list_tail() = prev_item;
-    }
-#ifdef DOUBLY_LINKED_FL
-    if (repair_list)
-    {
-        if (!use_undo_p)
-        {
-            free_list_prev (item) = PREV_EMPTY;
-        }
-    }
-    if (gen_number == max_generation)
-    {
-        dprintf (3, ("[g%2d, b%2d]UL: %p->%p->%p (h: %p, t: %p)",
-            gen_number, bn, free_list_prev (item), item, free_list_slot (item),
-            al->alloc_list_head(), al->alloc_list_tail()));
-        dprintf (3, ("[g%2d, b%2d]UL: exit, h->N: %p, h->P: %p, t->N: %p, t->P: %p",
-            gen_number, bn,
-            (al->alloc_list_head() ? free_list_slot (al->alloc_list_head()) : 0),
-            (al->alloc_list_head() ? free_list_prev (al->alloc_list_head()) : 0),
-            (al->alloc_list_tail() ? free_list_slot (al->alloc_list_tail()) : 0),
-            (al->alloc_list_tail() ? free_list_prev (al->alloc_list_tail()) : 0)));
-    }
-#endif //DOUBLY_LINKED_FL
-    if (al->alloc_list_head() == 0)
-    {
-        assert (al->alloc_list_tail() == 0);
-    }
-}
-#ifdef DOUBLY_LINKED_FL
-void allocator::unlink_item_no_undo (unsigned int bn, uint8_t* item)
-{
-    alloc_list* al = &alloc_list_of (bn);
-    uint8_t* next_item = free_list_slot (item);
-    uint8_t* prev_item = free_list_prev (item);
-#ifdef FL_VERIFICATION
-    {
-        uint8_t* start = al->alloc_list_head();
-        BOOL found_p = FALSE;
-        while (start)
-        {
-            if (start == item)
-            {
-                found_p = TRUE;
-                break;
-            }
-            start = free_list_slot (start);
-        }
-        if (!found_p)
-        {
-            dprintf (1, ("could not find %p in b%d!!!", item, a_l_number));
-            FATAL_GC_ERROR();
-        }
-    }
-#endif //FL_VERIFICATION
-    if (prev_item)
-    {
-        free_list_slot (prev_item) = next_item;
-    }
-    else
-    {
-        al->alloc_list_head() = next_item;
-    }
-    if (next_item)
-    {
-        free_list_prev (next_item) = prev_item;
-    }
-    if (al->alloc_list_tail() == item)
-    {
-        al->alloc_list_tail() = prev_item;
-    }
-    free_list_prev (item) = PREV_EMPTY;
-    if (gen_number == max_generation)
-    {
-        dprintf (3333, ("[g%2d, b%2d]ULN: %p->%p->%p (h: %p, t: %p)",
-            gen_number, bn, free_list_prev (item), item, free_list_slot (item),
-            al->alloc_list_head(), al->alloc_list_tail()));
-        dprintf (3333, ("[g%2d, b%2d]ULN: exit: h->N: %p, h->P: %p, t->N: %p, t->P: %p",
-            gen_number, bn,
-            (al->alloc_list_head() ? free_list_slot (al->alloc_list_head()) : 0),
-            (al->alloc_list_head() ? free_list_prev (al->alloc_list_head()) : 0),
-            (al->alloc_list_tail() ? free_list_slot (al->alloc_list_tail()) : 0),
-            (al->alloc_list_tail() ? free_list_prev (al->alloc_list_tail()) : 0)));
-    }
-}
-void allocator::unlink_item_no_undo (uint8_t* item, size_t size)
-{
-    unsigned int bn = first_suitable_bucket (size);
-    unlink_item_no_undo (bn, item);
-}
-void allocator::unlink_item_no_undo_added (unsigned int bn, uint8_t* item, uint8_t* previous_item)
-{
-    alloc_list* al = &alloc_list_of (bn);
-    uint8_t* next_item = free_list_slot (item);
-    uint8_t* prev_item = free_list_prev (item);
-    assert (prev_item == previous_item);
-    if (prev_item)
-    {
-        free_list_slot (prev_item) = next_item;
-    }
-    else
-    {
-        al->added_alloc_list_head() = next_item;
-    }
-    if (next_item)
-    {
-        free_list_prev (next_item) = prev_item;
-    }
-    if (al->added_alloc_list_tail() == item)
-    {
-        al->added_alloc_list_tail() = prev_item;
-    }
-    free_list_prev (item) = PREV_EMPTY;
-    if (gen_number == max_generation)
-    {
-        dprintf (3333, ("[g%2d, b%2d]ULNA: %p->%p->%p (h: %p, t: %p)",
-            gen_number, bn, free_list_prev (item), item, free_list_slot (item),
-            al->added_alloc_list_head(), al->added_alloc_list_tail()));
-        dprintf (3333, ("[g%2d, b%2d]ULNA: exit: h->N: %p, h->P: %p, t->N: %p, t->P: %p",
-            gen_number, bn,
-            (al->added_alloc_list_head() ? free_list_slot (al->added_alloc_list_head()) : 0),
-            (al->added_alloc_list_head() ? free_list_prev (al->added_alloc_list_head()) : 0),
-            (al->added_alloc_list_tail() ? free_list_slot (al->added_alloc_list_tail()) : 0),
-            (al->added_alloc_list_tail() ? free_list_prev (al->added_alloc_list_tail()) : 0)));
-    }
-}
-int allocator::thread_item_front_added (uint8_t* item, size_t size)
-{
-    unsigned int a_l_number = first_suitable_bucket (size);
-    alloc_list* al = &alloc_list_of (a_l_number);
-    free_list_slot (item) = al->added_alloc_list_head();
-    free_list_prev (item) = 0;
-    free_list_undo (item) = UNDO_EMPTY;
-    if (al->added_alloc_list_head() != 0)
-    {
-        free_list_prev (al->added_alloc_list_head()) = item;
-    }
-    al->added_alloc_list_head() = item;
-    if (al->added_alloc_list_tail() == 0)
-    {
-        al->added_alloc_list_tail() = item;
-    }
-    if (gen_number == max_generation)
-    {
-        dprintf (3333, ("[g%2d, b%2d]TFFA: exit: %p->%p->%p (h: %p, t: %p)",
-            gen_number, a_l_number,
-            free_list_prev (item), item, free_list_slot (item),
-            al->added_alloc_list_head(), al->added_alloc_list_tail()));
-        dprintf (3333, ("[g%2d, b%2d]TFFA: h->N: %p, h->P: %p, t->N: %p, t->P: %p",
-            gen_number, a_l_number,
-            (al->added_alloc_list_head() ? free_list_slot (al->added_alloc_list_head()) : 0),
-            (al->added_alloc_list_head() ? free_list_prev (al->added_alloc_list_head()) : 0),
-            (al->added_alloc_list_tail() ? free_list_slot (al->added_alloc_list_tail()) : 0),
-            (al->added_alloc_list_tail() ? free_list_prev (al->added_alloc_list_tail()) : 0)));
-    }
-    return a_l_number;
-}
-#endif //DOUBLY_LINKED_FL
-#ifdef DYNAMIC_HEAP_COUNT
-void allocator::count_items (gc_heap* this_hp, size_t* fl_items_count, size_t* fl_items_for_oh_count)
-{
-    uint64_t start_us = GetHighPrecisionTimeStamp();
-    uint64_t end_us = 0;
-    int align_const = get_alignment_constant (gen_number == max_generation);
-    size_t num_fl_items = 0;
-    size_t num_fl_items_for_oh = 0;
-    for (unsigned int i = 0; i < num_buckets; i++)
-    {
-        uint8_t* free_item = alloc_list_head_of (i);
-        while (free_item)
-        {
-            assert (((CObjectHeader*)free_item)->IsFree());
-            num_fl_items++;
-            heap_segment* region = gc_heap::region_of (free_item);
-            dprintf (3, ("b#%2d FL %Ix region %Ix heap %d -> %d",
-                i, free_item, (size_t)region, this_hp->heap_number, region->heap->heap_number));
-            if (region->heap != this_hp)
-            {
-                num_fl_items_for_oh++;
-            }
-            free_item = free_list_slot (free_item);
-        }
-    }
-    end_us = GetHighPrecisionTimeStamp();
-    dprintf (3, ("total - %Id items out of %Id items are from a different heap in %I64d us",
-        num_fl_items_for_oh, num_fl_items, (end_us - start_us)));
-    *fl_items_count = num_fl_items;
-    *fl_items_for_oh_count = num_fl_items_for_oh;
-}
-#ifdef DOUBLY_LINKED_FL
-void min_fl_list_info::thread_item (uint8_t* item)
-{
-    free_list_slot (item) = 0;
-    free_list_undo (item) = UNDO_EMPTY;
-    assert (item != head);
-    free_list_prev (item) = tail;
-    if (head == 0)
-    {
-        head = item;
-    }
-    else
-    {
-        assert ((free_list_slot(head) != 0) || (tail == head));
-        assert (item != tail);
-        assert (free_list_slot(tail) == 0);
-        free_list_slot (tail) = item;
-    }
-    tail = item;
-}
-#endif //DOUBLY_LINKED_FL
-void min_fl_list_info::thread_item_no_prev (uint8_t* item)
-{
-    free_list_slot (item) = 0;
-    free_list_undo (item) = UNDO_EMPTY;
-    assert (item != head);
-    if (head == 0)
-    {
-        head = item;
-    }
-    else
-    {
-        assert ((free_list_slot(head) != 0) || (tail == head));
-        assert (item != tail);
-        assert (free_list_slot(tail) == 0);
-        free_list_slot (tail) = item;
-    }
-    tail = item;
-}
-void allocator::rethread_items (size_t* num_total_fl_items, size_t* num_total_fl_items_rethreaded, gc_heap* current_heap,
-                                min_fl_list_info* min_fl_list, size_t *free_list_space_per_heap, int num_heaps)
-{
-    uint64_t start_us = GetHighPrecisionTimeStamp();
-    uint64_t end_us = 0;
-    int align_const = get_alignment_constant (gen_number == max_generation);
-    size_t num_fl_items = 0;
-    size_t num_fl_items_rethreaded = 0;
-    assert (num_buckets <= MAX_BUCKET_COUNT);
-    for (unsigned int i = 0; i < num_buckets; i++)
-    {
-        min_fl_list_info* current_bucket_min_fl_list = min_fl_list + (i * num_heaps);
-        uint8_t* free_item = alloc_list_head_of (i);
-        uint8_t* prev_item = nullptr;
-        while (free_item)
-        {
-            assert (((CObjectHeader*)free_item)->IsFree());
-            num_fl_items++;
-            heap_segment* region = gc_heap::region_of (free_item);
-            dprintf (3, ("b#%2d FL %Ix region %Ix heap %d -> %d",
-                i, free_item, (size_t)region, current_heap->heap_number, region->heap->heap_number));
-            if (region->heap != current_heap)
-            {
-                num_fl_items_rethreaded++;
-                size_t size_o = Align(size (free_item), align_const);
-                uint8_t* next_item = free_list_slot (free_item);
-                int hn = region->heap->heap_number;
-#ifdef DOUBLY_LINKED_FL
-                if (is_doubly_linked_p())
-                {
-                    unlink_item_no_undo (free_item, size_o);
-                    current_bucket_min_fl_list[hn].thread_item (free_item);
-                }
-                else
-#endif //DOUBLY_LINKED_FL
-                {
-                    unlink_item (i, free_item, prev_item, FALSE);
-                    current_bucket_min_fl_list[hn].thread_item_no_prev (free_item);
-                }
-                free_list_space_per_heap[hn] += size_o;
-                free_item = next_item;
-            }
-            else
-            {
-                prev_item = free_item;
-                free_item = free_list_slot (free_item);
-            }
-        }
-    }
-    end_us = GetHighPrecisionTimeStamp();
-    dprintf (8888, ("h%d total %Id items rethreaded out of %Id items in %I64d us (%I64dms)",
-        current_heap->heap_number, num_fl_items_rethreaded, num_fl_items, (end_us - start_us), ((end_us - start_us) / 1000)));
-    (*num_total_fl_items) += num_fl_items;
-    (*num_total_fl_items_rethreaded) += num_fl_items_rethreaded;
-}
-void allocator::merge_items (gc_heap* current_heap, int to_num_heaps, int from_num_heaps)
-{
-    int this_hn = current_heap->heap_number;
-    for (unsigned int i = 0; i < num_buckets; i++)
-    {
-        alloc_list* al = &alloc_list_of (i);
-        uint8_t*& head = al->alloc_list_head ();
-        uint8_t*& tail = al->alloc_list_tail ();
-        for (int other_hn = 0; other_hn < from_num_heaps; other_hn++)
-        {
-            min_fl_list_info* current_bucket_min_fl_list = gc_heap::g_heaps[other_hn]->min_fl_list + (i * to_num_heaps);
-            min_fl_list_info* current_heap_bucket_min_fl_list = &current_bucket_min_fl_list[this_hn];
-            uint8_t* head_other_heap = current_heap_bucket_min_fl_list->head;
-            if (head_other_heap)
-            {
-#ifdef DOUBLY_LINKED_FL
-                if (is_doubly_linked_p())
-                {
-                    free_list_prev (head_other_heap) = tail;
-                }
-#endif //DOUBLY_LINKED_FL
-                uint8_t* saved_head = head;
-                uint8_t* saved_tail = tail;
-                if (head)
-                {
-                    free_list_slot (tail) = head_other_heap;
-                }
-                else
-                {
-                    head = head_other_heap;
-                }
-                tail = current_heap_bucket_min_fl_list->tail;
-            }
-        }
-    }
-}
-#endif //DYNAMIC_HEAP_COUNT
-void allocator::clear()
-{
-    for (unsigned int i = 0; i < num_buckets; i++)
-    {
-        alloc_list_head_of (i) = 0;
-        alloc_list_tail_of (i) = 0;
-    }
-}
-void allocator::thread_item (uint8_t* item, size_t size)
-{
-    unsigned int a_l_number = first_suitable_bucket (size);
-    alloc_list* al = &alloc_list_of (a_l_number);
-    uint8_t*& head = al->alloc_list_head();
-    uint8_t*& tail = al->alloc_list_tail();
-    if (al->alloc_list_head() == 0)
-    {
-        assert (al->alloc_list_tail() == 0);
-    }
-    free_list_slot (item) = 0;
-    free_list_undo (item) = UNDO_EMPTY;
-    assert (item != head);
-#ifdef DOUBLY_LINKED_FL
-    if (gen_number == max_generation)
-    {
-        free_list_prev (item) = tail;
-    }
-#endif //DOUBLY_LINKED_FL
-    if (head == 0)
-    {
-        head = item;
-    }
-    else
-    {
-        assert ((free_list_slot(head) != 0) || (tail == head));
-        assert (item != tail);
-        assert (free_list_slot(tail) == 0);
-        free_list_slot (tail) = item;
-    }
-    tail = item;
-#ifdef DOUBLY_LINKED_FL
-    if (gen_number == max_generation)
-    {
-        dprintf (3333, ("[g%2d, b%2d]TFE: %p->%p->%p (h: %p, t: %p)",
-            gen_number, a_l_number,
-            free_list_prev (item), item, free_list_slot (item),
-            al->alloc_list_head(), al->alloc_list_tail()));
-        dprintf (3333, ("[g%2d, b%2d]TFE: exit: h->N: %p, h->P: %p, t->N: %p, t->P: %p",
-            gen_number, a_l_number,
-            (al->alloc_list_head() ? free_list_slot (al->alloc_list_head()) : 0),
-            (al->alloc_list_head() ? free_list_prev (al->alloc_list_head()) : 0),
-            (al->alloc_list_tail() ? free_list_slot (al->alloc_list_tail()) : 0),
-            (al->alloc_list_tail() ? free_list_prev (al->alloc_list_tail()) : 0)));
-    }
-#endif //DOUBLY_LINKED_FL
-}
-void allocator::thread_item_front (uint8_t* item, size_t size)
-{
-    unsigned int a_l_number = first_suitable_bucket (size);
-    alloc_list* al = &alloc_list_of (a_l_number);
-    if (al->alloc_list_head() == 0)
-    {
-        assert (al->alloc_list_tail() == 0);
-    }
-    free_list_slot (item) = al->alloc_list_head();
-    free_list_undo (item) = UNDO_EMPTY;
-    if (al->alloc_list_tail() == 0)
-    {
-        assert (al->alloc_list_head() == 0);
-        al->alloc_list_tail() = al->alloc_list_head();
-    }
-#ifdef DOUBLY_LINKED_FL
-    if (gen_number == max_generation)
-    {
-        if (al->alloc_list_head() != 0)
-        {
-            free_list_prev (al->alloc_list_head()) = item;
-        }
-    }
-#endif //DOUBLY_LINKED_FL
-    al->alloc_list_head() = item;
-    if (al->alloc_list_tail() == 0)
-    {
-        al->alloc_list_tail() = item;
-    }
-#ifdef DOUBLY_LINKED_FL
-    if (gen_number == max_generation)
-    {
-        free_list_prev (item) = 0;
-        dprintf (3333, ("[g%2d, b%2d]TFF: exit: %p->%p->%p (h: %p, t: %p)",
-            gen_number, a_l_number,
-            free_list_prev (item), item, free_list_slot (item),
-            al->alloc_list_head(), al->alloc_list_tail()));
-        dprintf (3333, ("[g%2d, b%2d]TFF: h->N: %p, h->P: %p, t->N: %p, t->P: %p",
-            gen_number, a_l_number,
-            (al->alloc_list_head() ? free_list_slot (al->alloc_list_head()) : 0),
-            (al->alloc_list_head() ? free_list_prev (al->alloc_list_head()) : 0),
-            (al->alloc_list_tail() ? free_list_slot (al->alloc_list_tail()) : 0),
-            (al->alloc_list_tail() ? free_list_prev (al->alloc_list_tail()) : 0)));
-    }
-#endif //DOUBLY_LINKED_FL
-}
-void allocator::copy_to_alloc_list (alloc_list* toalist)
-{
-    for (unsigned int i = 0; i < num_buckets; i++)
-    {
-        toalist [i] = alloc_list_of (i);
-#ifdef FL_VERIFICATION
-        size_t damage_count = alloc_list_damage_count_of (i);
-        assert (damage_count == 0);
-        uint8_t* free_item = alloc_list_head_of (i);
-        size_t count = 0;
-        while (free_item)
-        {
-            count++;
-            free_item = free_list_slot (free_item);
-        }
-        toalist[i].item_count = count;
-#endif //FL_VERIFICATION
-    }
-}
-void allocator::copy_from_alloc_list (alloc_list* fromalist)
-{
-    BOOL repair_list = !discard_if_no_fit_p ();
-#ifdef DOUBLY_LINKED_FL
-    BOOL bgc_repair_p = FALSE;
-    if (gen_number == max_generation)
-    {
-        bgc_repair_p = TRUE;
-        if (alloc_list_damage_count_of (0) != 0)
-        {
-            GCToOSInterface::DebugBreak();
-        }
-        uint8_t* b0_head = alloc_list_head_of (0);
-        if (b0_head)
-        {
-            free_list_prev (b0_head) = 0;
-        }
-        added_alloc_list_head_of (0) = 0;
-        added_alloc_list_tail_of (0) = 0;
-    }
-    unsigned int start_index = (bgc_repair_p ? 1 : 0);
-#else
-    unsigned int start_index = 0;
-#endif //DOUBLY_LINKED_FL
-    for (unsigned int i = start_index; i < num_buckets; i++)
-    {
-        size_t count = alloc_list_damage_count_of (i);
-        alloc_list_of (i) = fromalist [i];
-        assert (alloc_list_damage_count_of (i) == 0);
-        if (repair_list)
-        {
-            uint8_t* free_item = alloc_list_head_of (i);
-            while (free_item && count)
-            {
-                assert (((CObjectHeader*)free_item)->IsFree());
-                if ((free_list_undo (free_item) != UNDO_EMPTY))
-                {
-                    count--;
-                    free_list_slot (free_item) = free_list_undo (free_item);
-                    free_list_undo (free_item) = UNDO_EMPTY;
-                }
-                free_item = free_list_slot (free_item);
-            }
-#ifdef DOUBLY_LINKED_FL
-            if (bgc_repair_p)
-            {
-                added_alloc_list_head_of (i) = 0;
-                added_alloc_list_tail_of (i) = 0;
-            }
-#endif //DOUBLY_LINKED_FL
-#ifdef FL_VERIFICATION
-            free_item = alloc_list_head_of (i);
-            size_t item_count = 0;
-            while (free_item)
-            {
-                item_count++;
-                free_item = free_list_slot (free_item);
-            }
-            assert (item_count == alloc_list_of (i).item_count);
-#endif //FL_VERIFICATION
-        }
-#ifdef DEBUG
-        uint8_t* tail_item = alloc_list_tail_of (i);
-        assert ((tail_item == 0) || (free_list_slot (tail_item) == 0));
-#endif
-    }
-}
-void allocator::commit_alloc_list_changes()
-{
-    BOOL repair_list = !discard_if_no_fit_p ();
-#ifdef DOUBLY_LINKED_FL
-    BOOL bgc_repair_p = FALSE;
-    if (gen_number == max_generation)
-    {
-        bgc_repair_p = TRUE;
-    }
-#endif //DOUBLY_LINKED_FL
-    if (repair_list)
-    {
-        for (unsigned int i = 0; i < num_buckets; i++)
-        {
-            uint8_t* free_item = alloc_list_head_of (i);
-#ifdef DOUBLY_LINKED_FL
-            if (bgc_repair_p)
-            {
-                dprintf (3, ("C[b%2d] ENTRY: h: %p t: %p", i,
-                    alloc_list_head_of (i), alloc_list_tail_of (i)));
-            }
-            if (free_item && bgc_repair_p)
-            {
-                if (free_list_prev (free_item) != 0)
-                    free_list_prev (free_item) = 0;
-            }
-#endif //DOUBLY_LINKED_FL
-            size_t count = alloc_list_damage_count_of (i);
-            while (free_item && count)
-            {
-                assert (((CObjectHeader*)free_item)->IsFree());
-                if (free_list_undo (free_item) != UNDO_EMPTY)
-                {
-                    free_list_undo (free_item) = UNDO_EMPTY;
-#ifdef DOUBLY_LINKED_FL
-                    if (bgc_repair_p)
-                    {
-                        uint8_t* next_item = free_list_slot (free_item);
-                        if (next_item && (free_list_prev (next_item) != free_item))
-                            free_list_prev (next_item) = free_item;
-                    }
-#endif //DOUBLY_LINKED_FL
-                    count--;
-                }
-                free_item = free_list_slot (free_item);
-            }
-            alloc_list_damage_count_of (i) = 0;
-#ifdef DOUBLY_LINKED_FL
-            if (bgc_repair_p)
-            {
-                uint8_t* head = alloc_list_head_of (i);
-                uint8_t* tail_added = added_alloc_list_tail_of (i);
-                if (tail_added)
-                {
-                    assert (free_list_slot (tail_added) == 0);
-                    if (head)
-                    {
-                        free_list_slot (tail_added) = head;
-                        free_list_prev (head) = tail_added;
-                    }
-                }
-                uint8_t* head_added = added_alloc_list_head_of (i);
-                if (head_added)
-                {
-                    alloc_list_head_of (i) = head_added;
-                    uint8_t* final_head = alloc_list_head_of (i);
-                    if (alloc_list_tail_of (i) == 0)
-                    {
-                        alloc_list_tail_of (i) = tail_added;
-                    }
-                }
-                added_alloc_list_head_of (i) = 0;
-                added_alloc_list_tail_of (i) = 0;
-            }
-#endif //DOUBLY_LINKED_FL
-        }
-    }
-}
-#ifdef USE_REGIONS
-void allocator::thread_sip_fl (heap_segment* region)
-{
-    uint8_t* region_fl_head = region->free_list_head;
-    uint8_t* region_fl_tail = region->free_list_tail;
-    if (!region_fl_head)
-    {
-        assert (!region_fl_tail);
-        assert (region->free_list_size == 0);
-        return;
-    }
-    if (num_buckets == 1)
-    {
-        dprintf (REGIONS_LOG, ("threading gen%d region %p onto gen%d FL",
-            heap_segment_gen_num (region), heap_segment_mem (region), gen_number));
-        alloc_list* al = &alloc_list_of (0);
-        uint8_t*& head = al->alloc_list_head();
-        uint8_t*& tail = al->alloc_list_tail();
-        if (tail == 0)
-        {
-            assert (head == 0);
-            head = region_fl_head;
-        }
-        else
-        {
-            free_list_slot (tail) = region_fl_head;
-        }
-        tail = region_fl_tail;
-    }
-    else
-    {
-        dprintf (REGIONS_LOG, ("threading gen%d region %p onto gen%d bucketed FL",
-            heap_segment_gen_num (region), heap_segment_mem (region), gen_number));
-        uint8_t* region_fl_item = region_fl_head;
-        size_t total_free_size = 0;
-        while (region_fl_item)
-        {
-            uint8_t* next_fl_item = free_list_slot (region_fl_item);
-            size_t size_item = size (region_fl_item);
-            thread_item (region_fl_item, size_item);
-            total_free_size += size_item;
-            region_fl_item = next_fl_item;
-        }
-        assert (total_free_size == region->free_list_size);
-    }
-}
-#endif //USE_REGIONS
-#ifdef FEATURE_EVENT_TRACE
-uint16_t allocator::count_largest_items (etw_bucket_info* bucket_info,
-                                         size_t max_size,
-                                         size_t max_item_count,
-                                         size_t* recorded_fl_info_size)
-{
-    assert (gen_number == max_generation);
-    size_t size_counted_total = 0;
-    size_t items_counted_total = 0;
-    uint16_t bucket_info_index = 0;
-    for (int i = (num_buckets - 1); i >= 0; i--)
-    {
-        uint32_t items_counted = 0;
-        size_t size_counted = 0;
-        uint8_t* free_item = alloc_list_head_of ((unsigned int)i);
-        while (free_item)
-        {
-            assert (((CObjectHeader*)free_item)->IsFree());
-            size_t free_item_size = Align (size (free_item));
-            size_counted_total += free_item_size;
-            size_counted += free_item_size;
-            items_counted_total++;
-            items_counted++;
-            if ((size_counted_total > max_size) || (items_counted > max_item_count))
-            {
-                bucket_info[bucket_info_index++].set ((uint16_t)i, items_counted, size_counted);
-                *recorded_fl_info_size = size_counted_total;
-                return bucket_info_index;
-            }
-            free_item = free_list_slot (free_item);
-        }
-        if (items_counted)
-        {
-            bucket_info[bucket_info_index++].set ((uint16_t)i, items_counted, size_counted);
-        }
-    }
-    *recorded_fl_info_size = size_counted_total;
-    return bucket_info_index;
-}
-#endif //FEATURE_EVENT_TRACE
-void gc_heap::adjust_limit_clr (uint8_t* start, size_t limit_size, size_t size,
-                                alloc_context* acontext, uint32_t flags,
-                                heap_segment* seg, int align_const, int gen_number)
-{
-    bool uoh_p = (gen_number > 0);
-    GCSpinLock* msl = uoh_p ? &more_space_lock_uoh : &more_space_lock_soh;
-    uint64_t& total_alloc_bytes = uoh_p ? total_alloc_bytes_uoh : total_alloc_bytes_soh;
-    size_t aligned_min_obj_size = Align(min_obj_size, align_const);
-#ifdef USE_REGIONS
-    if (seg)
-    {
-        assert (heap_segment_used (seg) <= heap_segment_committed (seg));
-    }
-#endif //USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-    if (gen_number == 0)
-    {
-        if (!gen0_allocated_after_gc_p)
-        {
-            gen0_allocated_after_gc_p = true;
-        }
-    }
-#endif //MULTIPLE_HEAPS
-    dprintf (3, ("Expanding segment allocation [%zx, %zx[", (size_t)start,
-               (size_t)start + limit_size - aligned_min_obj_size));
-    if ((acontext->alloc_limit != start) &&
-        (acontext->alloc_limit + aligned_min_obj_size)!= start)
-    {
-        uint8_t*  hole = acontext->alloc_ptr;
-        if (hole != 0)
-        {
-            size_t  ac_size = (acontext->alloc_limit - acontext->alloc_ptr);
-            dprintf (3, ("filling up hole [%zx, %zx[", (size_t)hole, (size_t)hole + ac_size + aligned_min_obj_size));
-            acontext->alloc_bytes -= ac_size;
-            total_alloc_bytes -= ac_size;
-            size_t free_obj_size = ac_size + aligned_min_obj_size;
-            make_unused_array (hole, free_obj_size);
-            generation_free_obj_space (generation_of (gen_number)) += free_obj_size;
-        }
-        acontext->alloc_ptr = start;
-    }
-    else
-    {
-        if (gen_number == 0)
-        {
-#ifdef USE_REGIONS
-            if (acontext->alloc_ptr == 0)
-            {
-                acontext->alloc_ptr = start;
-            }
-            else
-#endif //USE_REGIONS
-            {
-                size_t pad_size = aligned_min_obj_size;
-                dprintf (3, ("contiguous ac: making min obj gap %p->%p(%zd)",
-                    acontext->alloc_ptr, (acontext->alloc_ptr + pad_size), pad_size));
-                make_unused_array (acontext->alloc_ptr, pad_size);
-                acontext->alloc_ptr += pad_size;
-            }
-        }
-    }
-    acontext->alloc_limit = (start + limit_size - aligned_min_obj_size);
-    size_t added_bytes = limit_size - ((gen_number <= max_generation) ? aligned_min_obj_size : 0);
-    acontext->alloc_bytes += added_bytes;
-    total_alloc_bytes     += added_bytes;
-    size_t etw_allocation_amount = 0;
-    bool fire_event_p = update_alloc_info (gen_number, added_bytes, &etw_allocation_amount);
-    uint8_t* saved_used = 0;
-    if (seg)
-    {
-        saved_used = heap_segment_used (seg);
-    }
-    if (seg == ephemeral_heap_segment)
-    {
-        if (heap_segment_used (seg) < (alloc_allocated - plug_skew))
-        {
-            heap_segment_used (seg) = alloc_allocated - plug_skew;
-            assert (heap_segment_mem (seg) <= heap_segment_used (seg));
-            assert (heap_segment_used (seg) <= heap_segment_reserved (seg));
-        }
-    }
-#ifdef BACKGROUND_GC
-    else if (seg)
-    {
-        uint8_t* old_allocated = heap_segment_allocated (seg) - plug_skew - limit_size;
-#ifdef FEATURE_LOH_COMPACTION
-        if (gen_number == loh_generation)
-        {
-            old_allocated -= Align (loh_padding_obj_size, align_const);
-        }
-#endif //FEATURE_LOH_COMPACTION
-        assert (heap_segment_used (seg) >= old_allocated);
-    }
-#endif //BACKGROUND_GC
-    uint8_t* clear_start = start - plug_skew;
-    uint8_t* clear_limit = start + limit_size - plug_skew;
-    if (flags & GC_ALLOC_ZEROING_OPTIONAL)
-    {
-        uint8_t* obj_start = acontext->alloc_ptr;
-        assert(start >= obj_start);
-        uint8_t* obj_end = obj_start + size - plug_skew;
-        assert(obj_end >= clear_start);
-        if(obj_start == start)
-        {
-            *(PTR_PTR)clear_start = 0;
-        }
-        dprintf(3, ("zeroing optional: skipping object at %p->%p(%zd)",
-            clear_start, obj_end, obj_end - clear_start));
-        clear_start = obj_end;
-    }
-    heap_segment* gen0_segment = ephemeral_heap_segment;
-#ifdef BACKGROUND_GC
-    {
-        if (uoh_p && gc_heap::background_running_p())
-        {
-            uint8_t* obj = acontext->alloc_ptr;
-            uint8_t* result = obj;
-            uint8_t* current_lowest_address = background_saved_lowest_address;
-            uint8_t* current_highest_address = background_saved_highest_address;
-            if (current_c_gc_state == c_gc_state_planning)
-            {
-                dprintf (3, ("Concurrent allocation of a large object %zx",
-                            (size_t)obj));
-                if ((result < current_highest_address) && (result >= current_lowest_address))
-                {
-#ifdef DOUBLY_LINKED_FL
-                    heap_segment* seg = seg_mapping_table_segment_of (result);
-                    uint8_t* background_allocated = heap_segment_background_allocated(seg);
-                    if (background_allocated != 0)
-#endif //DOUBLY_LINKED_FL
-                    {
-                        dprintf(3, ("Setting mark bit at address %zx",
-                            (size_t)(&mark_array[mark_word_of(result)])));
-                        mark_array_set_marked(result);
-                    }
-                }
-            }
-        }
-    }
-#endif //BACKGROUND_GC
-    if ((seg == 0) || (clear_limit <= heap_segment_used (seg)))
-    {
-        add_saved_spinlock_info (uoh_p, me_release, mt_clr_mem, msl_entered);
-        leave_spin_lock (msl);
-        if (clear_start < clear_limit)
-        {
-            dprintf(3, ("clearing memory at %p for %zd bytes", clear_start, clear_limit - clear_start));
-            memclr(clear_start, clear_limit - clear_start);
-        }
-    }
-    else
-    {
-        uint8_t* used = heap_segment_used (seg);
-        heap_segment_used (seg) = clear_limit;
-        add_saved_spinlock_info (uoh_p, me_release, mt_clr_mem, msl_entered);
-        leave_spin_lock (msl);
-        if (clear_start < used)
-        {
-            if (used != saved_used)
-            {
-                FATAL_GC_ERROR();
-            }
-            dprintf (2, ("clearing memory before used at %p for %zd bytes", clear_start, used - clear_start));
-            memclr (clear_start, used - clear_start);
-        }
-    }
-#ifdef FEATURE_EVENT_TRACE
-    if (fire_event_p)
-    {
-        fire_etw_allocation_event (etw_allocation_amount, gen_number, acontext->alloc_ptr, size);
-    }
-#endif //FEATURE_EVENT_TRACE
-    if (seg == gen0_segment ||
-       ((seg == nullptr) && (gen_number == 0) && (limit_size >= CLR_SIZE / 2)))
-    {
-        if (gen0_must_clear_bricks > 0)
-        {
-            size_t b = brick_of (acontext->alloc_ptr);
-            set_brick (b, acontext->alloc_ptr - brick_address (b));
-            b++;
-            dprintf (3, ("Allocation Clearing bricks [%zx, %zx[",
-                         b, brick_of (align_on_brick (start + limit_size))));
-            volatile short* x = &brick_table [b];
-            short* end_x = &brick_table [brick_of (align_on_brick (start + limit_size))];
-            for (;x < end_x;x++)
-                *x = -1;
-        }
-        else
-        {
-            gen0_bricks_cleared = FALSE;
-        }
-    }
-}
-size_t gc_heap::new_allocation_limit (size_t size, size_t physical_limit, int gen_number)
-{
-    dynamic_data* dd = dynamic_data_of (gen_number);
-    ptrdiff_t new_alloc = dd_new_allocation (dd);
-    assert (new_alloc == (ptrdiff_t)Align (new_alloc, get_alignment_constant (gen_number < uoh_start_generation)));
-    ptrdiff_t logical_limit = max (new_alloc, (ptrdiff_t)size);
-    size_t limit = min (logical_limit, (ptrdiff_t)physical_limit);
-    assert (limit == Align (limit, get_alignment_constant (gen_number <= max_generation)));
-    return limit;
-}
-size_t gc_heap::limit_from_size (size_t size, uint32_t flags, size_t physical_limit, int gen_number,
-                                 int align_const)
-{
-    size_t padded_size = size + Align (min_obj_size, align_const);
-    assert ((gen_number != 0) || (physical_limit >= padded_size));
-    size_t min_size_to_allocate = ((gen_number == 0 && !(flags & GC_ALLOC_ZEROING_OPTIONAL)) ? allocation_quantum : 0);
-    size_t desired_size_to_allocate  = max (padded_size, min_size_to_allocate);
-    size_t new_physical_limit = min (physical_limit, desired_size_to_allocate);
-    size_t new_limit = new_allocation_limit (padded_size,
-                                             new_physical_limit,
-                                             gen_number);
-    assert (new_limit >= (size + Align (min_obj_size, align_const)));
-    dprintf (3, ("h%d requested to allocate %zd bytes, actual size is %zd, phy limit: %zd",
-        heap_number, size, new_limit, physical_limit));
-    return new_limit;
-}
-void gc_heap::add_to_oom_history_per_heap()
-{
-    oom_history* current_hist = &oomhist_per_heap[oomhist_index_per_heap];
-    memcpy (current_hist, &oom_info, sizeof (oom_info));
-    oomhist_index_per_heap++;
-    if (oomhist_index_per_heap == max_oom_history_count)
-    {
-        oomhist_index_per_heap = 0;
-    }
-}
-void gc_heap::handle_oom (oom_reason reason, size_t alloc_size,
-                          uint8_t* allocated, uint8_t* reserved)
-{
-    if (reason == oom_budget)
-    {
-        alloc_size = dd_min_size (dynamic_data_of (0)) / 2;
-    }
-    if ((reason == oom_budget) && ((!fgm_result.loh_p) && (fgm_result.fgm != fgm_no_failure)))
-    {
-        reason = oom_low_mem;
-    }
-    oom_info.reason = reason;
-    oom_info.allocated = allocated;
-    oom_info.reserved = reserved;
-    oom_info.alloc_size = alloc_size;
-    oom_info.gc_index = settings.gc_index;
-    oom_info.fgm = fgm_result.fgm;
-    oom_info.size = fgm_result.size;
-    oom_info.available_pagefile_mb = fgm_result.available_pagefile_mb;
-    oom_info.loh_p = fgm_result.loh_p;
-    add_to_oom_history_per_heap();
-    fgm_result.fgm = fgm_no_failure;
-    if (GCConfig::GetBreakOnOOM())
-    {
-        GCToOSInterface::DebugBreak();
-    }
-}
-#ifdef BACKGROUND_GC
-BOOL gc_heap::background_allowed_p()
-{
-    return ( gc_can_use_concurrent && ((settings.pause_mode == pause_interactive) || (settings.pause_mode == pause_sustained_low_latency)) );
-}
-#endif //BACKGROUND_GC
-void gc_heap::check_for_full_gc (int gen_num, size_t size)
-{
-    BOOL should_notify = FALSE;
-    BOOL alloc_factor = TRUE;
-    int n_initial = gen_num;
-    BOOL local_blocking_collection = FALSE;
-    BOOL local_elevation_requested = FALSE;
-    int new_alloc_remain_percent = 0;
-    if (full_gc_approach_event_set)
-    {
-        return;
-    }
-    if (gen_num < max_generation)
-    {
-        gen_num = max_generation;
-    }
-    dynamic_data* dd_full = dynamic_data_of (gen_num);
-    ptrdiff_t new_alloc_remain = 0;
-    uint32_t pct = (gen_num >= uoh_start_generation) ? fgn_loh_percent : fgn_maxgen_percent;
-    for (int gen_index = 0; gen_index < total_generation_count; gen_index++)
-    {
-        dprintf (2, ("FGN: h#%d: gen%d: %zd(%zd)",
-                     heap_number, gen_index,
-                     dd_new_allocation (dynamic_data_of (gen_index)),
-                     dd_desired_allocation (dynamic_data_of (gen_index))));
-    }
-    if (n_initial == 0)
-    {
-        dprintf (2, ("FGN: gen0 last recorded alloc: %zd", fgn_last_alloc));
-        dynamic_data* dd_0 = dynamic_data_of (n_initial);
-        if (((fgn_last_alloc - dd_new_allocation (dd_0)) < fgn_check_quantum) &&
-            (dd_new_allocation (dd_0) >= 0))
-        {
-            return;
-        }
-        else
-        {
-            fgn_last_alloc = dd_new_allocation (dd_0);
-            dprintf (2, ("FGN: gen0 last recorded alloc is now: %zd", fgn_last_alloc));
-        }
-        size = 0;
-    }
-    int n = 0;
-    for (int i = 1; i <= max_generation; i++)
-    {
-            if (get_new_allocation (i) <= 0)
-            {
-                n = i;
-            }
-            else
-                break;
-    }
-    dprintf (2, ("FGN: h#%d: gen%d budget exceeded", heap_number, n));
-    if (gen_num == max_generation)
-    {
-        if (n < (max_generation - 1))
-        {
-            goto check_other_factors;
-        }
-    }
-    new_alloc_remain = dd_new_allocation (dd_full) - size;
-    new_alloc_remain_percent = (int)(((float)(new_alloc_remain) / (float)dd_desired_allocation (dd_full)) * 100);
-    dprintf (2, ("FGN: alloc threshold for gen%d is %d%%, current threshold is %d%%",
-                 gen_num, pct, new_alloc_remain_percent));
-    if (new_alloc_remain_percent <= (int)pct)
-    {
-#ifdef BACKGROUND_GC
-        if (background_allowed_p())
-        {
-            goto check_other_factors;
-        }
-#endif //BACKGROUND_GC
-        should_notify = TRUE;
-        goto done;
-    }
-check_other_factors:
-    dprintf (2, ("FGC: checking other factors"));
-    n = generation_to_condemn (n,
-                               &local_blocking_collection,
-                               &local_elevation_requested,
-                               TRUE);
-    if (local_elevation_requested && (n == max_generation))
-    {
-        if (settings.should_lock_elevation)
-        {
-            int local_elevation_locked_count = settings.elevation_locked_count + 1;
-            if (local_elevation_locked_count != 6)
-            {
-                dprintf (2, ("FGN: lock count is %d - Condemning max_generation-1",
-                    local_elevation_locked_count));
-                n = max_generation - 1;
-            }
-        }
-    }
-    dprintf (2, ("FGN: we estimate gen%d will be collected", n));
-#ifdef BACKGROUND_GC
-    if ((n == max_generation) &&
-        (gc_heap::background_running_p()))
-    {
-        n = max_generation - 1;
-        dprintf (2, ("FGN: bgc - 1 instead of 2"));
-    }
-    if ((n == max_generation) && !local_blocking_collection)
-    {
-        if (!background_allowed_p())
-        {
-            local_blocking_collection = TRUE;
-        }
-    }
-#endif //BACKGROUND_GC
-    dprintf (2, ("FGN: we estimate gen%d will be collected: %s",
-                       n,
-                       (local_blocking_collection ? "blocking" : "background")));
-    if ((n == max_generation) && local_blocking_collection)
-    {
-        alloc_factor = FALSE;
-        should_notify = TRUE;
-        goto done;
-    }
-done:
-    if (should_notify)
-    {
-        dprintf (2, ("FGN: gen%d detecting full GC approaching(%s) (GC#%zd) (%d%% left in gen%d)",
-                     n_initial,
-                     (alloc_factor ? "alloc" : "other"),
-                     dd_collection_count (dynamic_data_of (0)),
-                     new_alloc_remain_percent,
-                     gen_num));
-        send_full_gc_notification (n_initial, alloc_factor);
-    }
-}
-void gc_heap::send_full_gc_notification (int gen_num, BOOL due_to_alloc_p)
-{
-    if (!full_gc_approach_event_set)
-    {
-        assert (full_gc_approach_event.IsValid());
-        FIRE_EVENT(GCFullNotify_V1, gen_num, due_to_alloc_p);
-        full_gc_end_event.Reset();
-        full_gc_approach_event.Set();
-        full_gc_approach_event_set = true;
-    }
-}
-wait_full_gc_status gc_heap::full_gc_wait (GCEvent *event, int time_out_ms)
-{
-#ifdef MULTIPLE_HEAPS
-    gc_heap* hp = gc_heap::g_heaps[0];
-#else
-    gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-    if (hp->fgn_maxgen_percent == 0)
-    {
-        return wait_full_gc_na;
-    }
-    uint32_t wait_result = user_thread_wait(event, FALSE, time_out_ms);
-    if ((wait_result == WAIT_OBJECT_0) || (wait_result == WAIT_TIMEOUT))
-    {
-        if (hp->fgn_maxgen_percent == 0)
-        {
-            return wait_full_gc_cancelled;
-        }
-        if (wait_result == WAIT_OBJECT_0)
-        {
-#ifdef BACKGROUND_GC
-            if (fgn_last_gc_was_concurrent)
-            {
-                fgn_last_gc_was_concurrent = FALSE;
-                return wait_full_gc_na;
-            }
-            else
-#endif //BACKGROUND_GC
-            {
-                return wait_full_gc_success;
-            }
-        }
-        else
-        {
-            return wait_full_gc_timeout;
-        }
-    }
-    else
-    {
-        return wait_full_gc_failed;
-    }
-}
-size_t gc_heap::get_full_compact_gc_count()
-{
-    return full_gc_counts[gc_type_compacting];
-}
-inline
-BOOL gc_heap::short_on_end_of_seg (heap_segment* seg)
-{
-    uint8_t* allocated = heap_segment_allocated (seg);
-#ifdef USE_REGIONS
-    assert (end_gen0_region_space != uninitialized_end_gen0_region_space);
-    BOOL sufficient_p = sufficient_space_regions_for_allocation (end_gen0_region_space, end_space_after_gc());
-#else
-    BOOL sufficient_p = sufficient_space_end_seg (allocated,
-                                                  heap_segment_committed (seg),
-                                                  heap_segment_reserved (seg),
-                                                  end_space_after_gc());
-#endif //USE_REGIONS
-    if (!sufficient_p)
-    {
-        if (sufficient_gen0_space_p)
-        {
-            dprintf (GTC_LOG, ("gen0 has enough free space"));
-        }
-        sufficient_p = sufficient_gen0_space_p;
-    }
-    return !sufficient_p;
-}
-inline
-BOOL gc_heap::a_fit_free_list_p (int gen_number,
-                                 size_t size,
-                                 alloc_context* acontext,
-                                 uint32_t flags,
-                                 int align_const)
-{
-    BOOL can_fit = FALSE;
-    generation* gen = generation_of (gen_number);
-    allocator* gen_allocator = generation_allocator (gen);
-    for (unsigned int a_l_idx = gen_allocator->first_suitable_bucket(size); a_l_idx < gen_allocator->number_of_buckets(); a_l_idx++)
-    {
-        uint8_t* free_list = gen_allocator->alloc_list_head_of (a_l_idx);
-        uint8_t* prev_free_item = 0;
-        while (free_list != 0)
-        {
-            dprintf (3, ("considering free list %zx", (size_t)free_list));
-            size_t free_list_size = unused_array_size (free_list);
-            if ((size + Align (min_obj_size, align_const)) <= free_list_size)
-            {
-                dprintf (3, ("Found adequate unused area: [%zx, size: %zd",
-                                (size_t)free_list, free_list_size));
-                gen_allocator->unlink_item (a_l_idx, free_list, prev_free_item, FALSE);
-                size_t limit = limit_from_size (size, flags, free_list_size, gen_number, align_const);
-                dd_new_allocation (dynamic_data_of (gen_number)) -= limit;
-                uint8_t*  remain = (free_list + limit);
-                size_t remain_size = (free_list_size - limit);
-                if (remain_size >= Align(min_free_list, align_const))
-                {
-                    make_unused_array (remain, remain_size);
-                    gen_allocator->thread_item_front (remain, remain_size);
-                    assert (remain_size >= Align (min_obj_size, align_const));
-                }
-                else
-                {
-                    limit += remain_size;
-                }
-                generation_free_list_space (gen) -= limit;
-                assert ((ptrdiff_t)generation_free_list_space (gen) >= 0);
-                adjust_limit_clr (free_list, limit, size, acontext, flags, 0, align_const, gen_number);
-                can_fit = TRUE;
-                goto end;
-            }
-            else if (gen_allocator->discard_if_no_fit_p())
-            {
-                assert (prev_free_item == 0);
-                dprintf (3, ("couldn't use this free area, discarding"));
-                generation_free_obj_space (gen) += free_list_size;
-                gen_allocator->unlink_item (a_l_idx, free_list, prev_free_item, FALSE);
-                generation_free_list_space (gen) -= free_list_size;
-                assert ((ptrdiff_t)generation_free_list_space (gen) >= 0);
-            }
-            else
-            {
-                prev_free_item = free_list;
-            }
-            free_list = free_list_slot (free_list);
-        }
-    }
-end:
-    return can_fit;
-}
-#ifdef BACKGROUND_GC
-void gc_heap::bgc_uoh_alloc_clr (uint8_t* alloc_start,
-                                 size_t size,
-                                 alloc_context* acontext,
-                                 uint32_t flags,
-                                 int gen_number,
-                                 int align_const,
-                                 int lock_index,
-                                 BOOL check_used_p,
-                                 heap_segment* seg)
-{
-    make_unused_array (alloc_start, size);
-#ifdef DOUBLY_LINKED_FL
-    clear_prev_bit (alloc_start, size);
-#endif //DOUBLY_LINKED_FL
-    size_t size_of_array_base = sizeof(ArrayBase);
-    bgc_alloc_lock->uoh_alloc_done_with_index (lock_index);
-    size_t size_to_skip = size_of_array_base;
-    size_t size_to_clear = size - size_to_skip - plug_skew;
-    size_t saved_size_to_clear = size_to_clear;
-    if (check_used_p)
-    {
-        uint8_t* end = alloc_start + size - plug_skew;
-        uint8_t* used = heap_segment_used (seg);
-        if (used < end)
-        {
-            if ((alloc_start + size_to_skip) < used)
-            {
-                size_to_clear = used - (alloc_start + size_to_skip);
-            }
-            else
-            {
-                size_to_clear = 0;
-            }
-            dprintf (2, ("bgc uoh: setting used to %p", end));
-            heap_segment_used (seg) = end;
-        }
-        dprintf (2, ("bgc uoh: used: %p, alloc: %p, end of alloc: %p, clear %zd bytes",
-                     used, alloc_start, end, size_to_clear));
-    }
-    else
-    {
-        dprintf (2, ("bgc uoh: [%p-[%p(%zd)", alloc_start, alloc_start+size, size));
-    }
-#ifdef VERIFY_HEAP
-    if (GCConfig::GetHeapVerifyLevel() & GCConfig::HEAPVERIFY_GC)
-    {
-        if (size_to_clear < saved_size_to_clear)
-        {
-            size_to_clear = saved_size_to_clear;
-        }
-    }
-#endif //VERIFY_HEAP
-    size_t allocated_size = size - Align (min_obj_size, align_const);
-    total_alloc_bytes_uoh += allocated_size;
-    size_t etw_allocation_amount = 0;
-    bool fire_event_p = update_alloc_info (gen_number, allocated_size, &etw_allocation_amount);
-    dprintf (SPINLOCK_LOG, ("[%d]Lmsl to clear uoh obj", heap_number));
-    add_saved_spinlock_info (true, me_release, mt_clr_large_mem, msl_entered);
-    leave_spin_lock (&more_space_lock_uoh);
-#ifdef FEATURE_EVENT_TRACE
-    if (fire_event_p)
-    {
-        fire_etw_allocation_event (etw_allocation_amount, gen_number, alloc_start, size);
-    }
-#endif //FEATURE_EVENT_TRACE
-    ((void**) alloc_start)[-1] = 0;     //clear the sync block
-    if (!(flags & GC_ALLOC_ZEROING_OPTIONAL))
-    {
-        memclr(alloc_start + size_to_skip, size_to_clear);
-    }
-#ifdef MULTIPLE_HEAPS
-    assert (heap_of (alloc_start) == this);
-#endif // MULTIPLE_HEAPS
-    bgc_alloc_lock->uoh_alloc_set (alloc_start);
-    acontext->alloc_ptr = alloc_start;
-    acontext->alloc_limit = (alloc_start + size - Align (min_obj_size, align_const));
-    clear_unused_array(alloc_start, size);
-}
-#endif //BACKGROUND_GC
-BOOL gc_heap::a_fit_free_list_uoh_p (size_t size,
-                                       alloc_context* acontext,
-                                       uint32_t flags,
-                                       int align_const,
-                                       int gen_number)
-{
-    BOOL can_fit = FALSE;
-    generation* gen = generation_of (gen_number);
-    allocator* allocator = generation_allocator (gen);
-#ifdef FEATURE_LOH_COMPACTION
-    size_t loh_pad = (gen_number == loh_generation) ? Align (loh_padding_obj_size, align_const) : 0;
-#endif //FEATURE_LOH_COMPACTION
-#ifdef BACKGROUND_GC
-    int cookie = -1;
-#endif //BACKGROUND_GC
-    for (unsigned int a_l_idx = allocator->first_suitable_bucket(size); a_l_idx < allocator->number_of_buckets(); a_l_idx++)
-    {
-        uint8_t* free_list = allocator->alloc_list_head_of (a_l_idx);
-        uint8_t* prev_free_item = 0;
-        while (free_list != 0)
-        {
-            dprintf (3, ("considering free list %zx", (size_t)free_list));
-            size_t free_list_size = unused_array_size(free_list);
-            ptrdiff_t diff = free_list_size - size;
-#ifdef FEATURE_LOH_COMPACTION
-            diff -= loh_pad;
-#endif //FEATURE_LOH_COMPACTION
-            if ((diff == 0) || (diff >= (ptrdiff_t)Align (min_obj_size, align_const)))
-            {
-#ifdef BACKGROUND_GC
-#ifdef MULTIPLE_HEAPS
-                assert (heap_of (free_list) == this);
-#endif // MULTIPLE_HEAPS
-                cookie = bgc_alloc_lock->uoh_alloc_set (free_list);
-                bgc_track_uoh_alloc();
-#endif //BACKGROUND_GC
-                allocator->unlink_item (a_l_idx, free_list, prev_free_item, FALSE);
-                remove_gen_free (gen_number, free_list_size);
-                size_t limit = limit_from_size (size - Align(min_obj_size, align_const), flags, free_list_size,
-                                                gen_number, align_const);
-                dd_new_allocation (dynamic_data_of (gen_number)) -= limit;
-                size_t saved_free_list_size = free_list_size;
-#ifdef FEATURE_LOH_COMPACTION
-                if (loh_pad)
-                {
-                    make_unused_array (free_list, loh_pad);
-                    generation_free_obj_space (gen) += loh_pad;
-                    limit -= loh_pad;
-                    free_list += loh_pad;
-                    free_list_size -= loh_pad;
-                }
-#endif //FEATURE_LOH_COMPACTION
-                uint8_t*  remain = (free_list + limit);
-                size_t remain_size = (free_list_size - limit);
-                if (remain_size != 0)
-                {
-                    assert (remain_size >= Align (min_obj_size, align_const));
-                    make_unused_array (remain, remain_size);
-                }
-                if (remain_size >= Align(min_free_list, align_const))
-                {
-                    uoh_thread_gap_front (remain, remain_size, gen);
-                    add_gen_free (gen_number, remain_size);
-                    assert (remain_size >= Align (min_obj_size, align_const));
-                }
-                else
-                {
-                    generation_free_obj_space (gen) += remain_size;
-                }
-                generation_free_list_space (gen) -= saved_free_list_size;
-                assert ((ptrdiff_t)generation_free_list_space (gen) >= 0);
-                generation_free_list_allocated (gen) += limit;
-                dprintf (3, ("found fit on loh at %p", free_list));
-#ifdef BACKGROUND_GC
-                if (cookie != -1)
-                {
-                    bgc_uoh_alloc_clr (free_list, limit, acontext, flags, gen_number, align_const, cookie, FALSE, 0);
-                }
-                else
-#endif //BACKGROUND_GC
-                {
-                    adjust_limit_clr (free_list, limit, size, acontext, flags, 0, align_const, gen_number);
-                }
-                acontext->alloc_limit += Align (min_obj_size, align_const);
-                can_fit = TRUE;
-                goto exit;
-            }
-            prev_free_item = free_list;
-            free_list = free_list_slot (free_list);
-        }
-    }
-exit:
-    return can_fit;
-}
-BOOL gc_heap::a_fit_segment_end_p (int gen_number,
-                                   heap_segment* seg,
-                                   size_t size,
-                                   alloc_context* acontext,
-                                   uint32_t flags,
-                                   int align_const,
-                                   BOOL* commit_failed_p)
-{
-    *commit_failed_p = FALSE;
-    size_t limit = 0;
-    bool hard_limit_short_seg_end_p = false;
-#ifdef BACKGROUND_GC
-    int cookie = -1;
-#endif //BACKGROUND_GC
-    uint8_t*& allocated = ((gen_number == 0) ?
-                                    alloc_allocated :
-                                    heap_segment_allocated(seg));
-    size_t pad = Align (min_obj_size, align_const);
-#ifdef FEATURE_LOH_COMPACTION
-    size_t loh_pad = Align (loh_padding_obj_size, align_const);
-    if (gen_number == loh_generation)
-    {
-        pad += loh_pad;
-    }
-#endif //FEATURE_LOH_COMPACTION
-    uint8_t* end = heap_segment_committed (seg) - pad;
-    if (a_size_fit_p (size, allocated, end, align_const))
-    {
-        limit = limit_from_size (size,
-                                 flags,
-                                 (end - allocated),
-                                 gen_number, align_const);
-        goto found_fit;
-    }
-    end = heap_segment_reserved (seg) - pad;
-    if ((heap_segment_reserved (seg) != heap_segment_committed (seg)) && (a_size_fit_p (size, allocated, end, align_const)))
-    {
-        limit = limit_from_size (size,
-                                 flags,
-                                 (end - allocated),
-                                 gen_number, align_const);
-        if (grow_heap_segment (seg, (allocated + limit), &hard_limit_short_seg_end_p))
-        {
-            goto found_fit;
-        }
-        else
-        {
-#ifdef USE_REGIONS
-            *commit_failed_p = TRUE;
-#else
-            if (!hard_limit_short_seg_end_p)
-            {
-                dprintf (2, ("can't grow segment, doing a full gc"));
-                *commit_failed_p = TRUE;
-            }
-            else
-            {
-                assert (heap_hard_limit);
-            }
-#endif // USE_REGIONS
-        }
-    }
-    goto found_no_fit;
-found_fit:
-    dd_new_allocation (dynamic_data_of (gen_number)) -= limit;
-#ifdef BACKGROUND_GC
-    if (gen_number != 0)
-    {
-#ifdef MULTIPLE_HEAPS
-        assert (heap_of (allocated) == this);
-#endif // MULTIPLE_HEAPS
-        cookie = bgc_alloc_lock->uoh_alloc_set (allocated);
-        bgc_track_uoh_alloc();
-    }
-#endif //BACKGROUND_GC
-#ifdef FEATURE_LOH_COMPACTION
-    if (gen_number == loh_generation)
-    {
-        make_unused_array (allocated, loh_pad);
-        generation_free_obj_space (generation_of (gen_number)) += loh_pad;
-        allocated += loh_pad;
-        limit -= loh_pad;
-    }
-#endif //FEATURE_LOH_COMPACTION
-#if defined (VERIFY_HEAP) && defined (_DEBUG)
-    ((void**)allocated)[-1] = 0;    // clear the sync block
-    VOLATILE_MEMORY_BARRIER();
-#endif //VERIFY_HEAP && _DEBUG
-    uint8_t* old_alloc;
-    old_alloc = allocated;
-    dprintf (3, ("found fit at end of seg: %p", old_alloc));
-#ifdef BACKGROUND_GC
-    if (cookie != -1)
-    {
-        allocated += limit;
-        bgc_uoh_alloc_clr (old_alloc, limit, acontext, flags, gen_number, align_const, cookie, TRUE, seg);
-    }
-    else
-#endif //BACKGROUND_GC
-    {
-        if ((flags & GC_ALLOC_ZEROING_OPTIONAL) &&
-            ((allocated == acontext->alloc_limit) ||
-             (allocated == (acontext->alloc_limit + Align (min_obj_size, align_const)))))
-        {
-            assert(gen_number == 0);
-            assert(allocated > acontext->alloc_ptr);
-            size_t extra = allocated - acontext->alloc_ptr;
-            limit -= extra;
-            dynamic_data* dd = dynamic_data_of (0);
-            dd_new_allocation (dd) += extra;
-            limit += Align(min_obj_size, align_const);
-        }
-        allocated += limit;
-        adjust_limit_clr (old_alloc, limit, size, acontext, flags, seg, align_const, gen_number);
-    }
-    return TRUE;
-found_no_fit:
-    return FALSE;
-}
-BOOL gc_heap::uoh_a_fit_segment_end_p (int gen_number,
-                                       size_t size,
-                                       alloc_context* acontext,
-                                       uint32_t flags,
-                                       int align_const,
-                                       BOOL* commit_failed_p,
-                                       oom_reason* oom_r)
-{
-    *commit_failed_p = FALSE;
-    generation* gen = generation_of (gen_number);
-    heap_segment* seg = generation_allocation_segment (gen);
-    BOOL can_allocate_p = FALSE;
-    while (seg)
-    {
-#ifdef BACKGROUND_GC
-        if (seg->flags & heap_segment_flags_uoh_delete)
-        {
-            dprintf (3, ("h%d skipping seg %zx to be deleted", heap_number, (size_t)seg));
-        }
-        else
-#endif //BACKGROUND_GC
-        {
-            if (a_fit_segment_end_p (gen_number, seg, (size - Align (min_obj_size, align_const)),
-                                        acontext, flags, align_const, commit_failed_p))
-            {
-                acontext->alloc_limit += Align (min_obj_size, align_const);
-                can_allocate_p = TRUE;
-                break;
-            }
-            if (*commit_failed_p)
-            {
-                *oom_r = oom_cant_commit;
-                break;
-            }
-        }
-        seg = heap_segment_next_rw (seg);
-    }
-    if (can_allocate_p)
-    {
-        generation_end_seg_allocated (gen) += size;
-    }
-    return can_allocate_p;
-}
-#ifdef BACKGROUND_GC
-inline
-enter_msl_status gc_heap::wait_for_background (alloc_wait_reason awr, bool loh_p)
-{
-    GCSpinLock* msl = loh_p ? &more_space_lock_uoh : &more_space_lock_soh;
-    enter_msl_status msl_status = msl_entered;
-    dprintf (2, ("BGC is already in progress, waiting for it to finish"));
-    add_saved_spinlock_info (loh_p, me_release, mt_wait_bgc, msl_status);
-    leave_spin_lock (msl);
-    background_gc_wait (awr);
-    msl_status = enter_spin_lock_msl (msl);
-    add_saved_spinlock_info (loh_p, me_acquire, mt_wait_bgc, msl_status);
-    return msl_status;
-}
-bool gc_heap::wait_for_bgc_high_memory (alloc_wait_reason awr, bool loh_p, enter_msl_status* msl_status)
-{
-    bool wait_p = false;
-    if (gc_heap::background_running_p())
-    {
-        uint32_t memory_load;
-        get_memory_info (&memory_load);
-        if (memory_load >= m_high_memory_load_th)
-        {
-            wait_p = true;
-            dprintf (GTC_LOG, ("high mem - wait for BGC to finish, wait reason: %d", awr));
-            *msl_status = wait_for_background (awr, loh_p);
-        }
-    }
-    return wait_p;
-}
-#endif //BACKGROUND_GC
-BOOL gc_heap::trigger_ephemeral_gc (gc_reason gr, enter_msl_status* msl_status)
-{
-#ifdef BACKGROUND_GC
-    wait_for_bgc_high_memory (awr_loh_oos_bgc, false, msl_status);
-    if (*msl_status == msl_retry_different_heap) return FALSE;
-#endif //BACKGROUND_GC
-    BOOL did_full_compact_gc = FALSE;
-    dprintf (1, ("h%d triggering a gen1 GC", heap_number));
-    size_t last_full_compact_gc_count = get_full_compact_gc_count();
-    vm_heap->GarbageCollectGeneration(max_generation - 1, gr);
-#ifdef MULTIPLE_HEAPS
-    *msl_status = enter_spin_lock_msl (&more_space_lock_soh);
-    if (*msl_status == msl_retry_different_heap) return FALSE;
-    add_saved_spinlock_info (false, me_acquire, mt_t_eph_gc, *msl_status);
-#endif //MULTIPLE_HEAPS
-    size_t current_full_compact_gc_count = get_full_compact_gc_count();
-    if (current_full_compact_gc_count > last_full_compact_gc_count)
-    {
-        dprintf (2, ("attempted to trigger an ephemeral GC and got a full compacting GC"));
-        did_full_compact_gc = TRUE;
-    }
-    return did_full_compact_gc;
-}
-BOOL gc_heap::soh_try_fit (int gen_number,
-                           size_t size,
-                           alloc_context* acontext,
-                           uint32_t flags,
-                           int align_const,
-                           BOOL* commit_failed_p,
-                           BOOL* short_seg_end_p)
-{
-    BOOL can_allocate = TRUE;
-    if (short_seg_end_p)
-    {
-        *short_seg_end_p = FALSE;
-    }
-    can_allocate = a_fit_free_list_p (gen_number, size, acontext, flags, align_const);
-    if (!can_allocate)
-    {
-        if (short_seg_end_p)
-        {
-            *short_seg_end_p = short_on_end_of_seg (ephemeral_heap_segment);
-        }
-        if (!short_seg_end_p || !(*short_seg_end_p))
-        {
-#ifdef USE_REGIONS
-            while (ephemeral_heap_segment)
-#endif //USE_REGIONS
-            {
-                can_allocate = a_fit_segment_end_p (gen_number, ephemeral_heap_segment, size,
-                                                    acontext, flags, align_const, commit_failed_p);
-#ifdef USE_REGIONS
-                if (can_allocate)
-                {
-                    break;
-                }
-                dprintf (REGIONS_LOG, ("h%d fixing region %p end to alloc ptr: %p, alloc_allocated %p",
-                    heap_number, heap_segment_mem (ephemeral_heap_segment), acontext->alloc_ptr,
-                    alloc_allocated));
-                fix_allocation_context (acontext, TRUE, FALSE);
-                fix_youngest_allocation_area();
-                heap_segment* next_seg = heap_segment_next (ephemeral_heap_segment);
-                bool new_seg = false;
-                if (!next_seg)
-                {
-                    assert (ephemeral_heap_segment == generation_tail_region (generation_of (gen_number)));
-                    next_seg = get_new_region (gen_number);
-                    new_seg = true;
-                }
-                if (next_seg)
-                {
-                    dprintf (REGIONS_LOG, ("eph seg %p -> next %p",
-                        heap_segment_mem (ephemeral_heap_segment), heap_segment_mem (next_seg)));
-                    ephemeral_heap_segment = next_seg;
-                    if (new_seg)
-                    {
-                        GCToEEInterface::DiagAddNewRegion(
-                            heap_segment_gen_num (next_seg),
-                            heap_segment_mem (next_seg),
-                            heap_segment_allocated (next_seg),
-                            heap_segment_reserved (next_seg)
-                        );
-                    }
-                }
-                else
-                {
-                    *commit_failed_p = TRUE;
-                    dprintf (REGIONS_LOG, ("couldn't get a new ephemeral region"));
-                    return FALSE;
-                }
-                alloc_allocated = heap_segment_allocated (ephemeral_heap_segment);
-                dprintf (REGIONS_LOG, ("h%d alloc_allocated is now %p", heap_number, alloc_allocated));
-#endif //USE_REGIONS
-            }
-        }
-    }
-    return can_allocate;
-}
-allocation_state gc_heap::allocate_soh (int gen_number,
-                                          size_t size,
-                                          alloc_context* acontext,
-                                          uint32_t flags,
-                                          int align_const)
-{
-    enter_msl_status msl_status = msl_entered;
-#if defined (BACKGROUND_GC) && !defined (MULTIPLE_HEAPS)
-    if (gc_heap::background_running_p())
-    {
-        background_soh_alloc_count++;
-        if ((background_soh_alloc_count % bgc_alloc_spin_count) == 0)
-        {
-            add_saved_spinlock_info (false, me_release, mt_alloc_small, msl_status);
-            leave_spin_lock (&more_space_lock_soh);
-            bool cooperative_mode = enable_preemptive();
-            GCToOSInterface::Sleep (bgc_alloc_spin);
-            disable_preemptive (cooperative_mode);
-            msl_status = enter_spin_lock_msl (&more_space_lock_soh);
-            if (msl_status == msl_retry_different_heap) return a_state_retry_allocate;
-            add_saved_spinlock_info (false, me_acquire, mt_alloc_small, msl_status);
-        }
-        else
-        {
-        }
-    }
-#endif //BACKGROUND_GC && !MULTIPLE_HEAPS
-    gc_reason gr = reason_oos_soh;
-    oom_reason oom_r = oom_no_failure;
-    allocation_state soh_alloc_state = a_state_start;
-    while (1)
-    {
-        dprintf (3, ("[h%d]soh state is %s", heap_number, allocation_state_str[soh_alloc_state]));
-        switch (soh_alloc_state)
-        {
-            case a_state_can_allocate:
-            case a_state_cant_allocate:
-            {
-                goto exit;
-            }
-            case a_state_start:
-            {
-                soh_alloc_state = a_state_try_fit;
-                break;
-            }
-            case a_state_try_fit:
-            {
-                BOOL commit_failed_p = FALSE;
-                BOOL can_use_existing_p = FALSE;
-                can_use_existing_p = soh_try_fit (gen_number, size, acontext, flags,
-                                                  align_const, &commit_failed_p,
-                                                  NULL);
-                soh_alloc_state = (can_use_existing_p ?
-                                        a_state_can_allocate :
-                                        (commit_failed_p ?
-                                            a_state_trigger_full_compact_gc :
-                                            a_state_trigger_ephemeral_gc));
-                break;
-            }
-            case a_state_try_fit_after_bgc:
-            {
-                BOOL commit_failed_p = FALSE;
-                BOOL can_use_existing_p = FALSE;
-                BOOL short_seg_end_p = FALSE;
-                can_use_existing_p = soh_try_fit (gen_number, size, acontext, flags,
-                                                  align_const, &commit_failed_p,
-                                                  &short_seg_end_p);
-                soh_alloc_state = (can_use_existing_p ?
-                                        a_state_can_allocate :
-                                        (short_seg_end_p ?
-                                            a_state_trigger_2nd_ephemeral_gc :
-                                            a_state_trigger_full_compact_gc));
-                break;
-            }
-            case a_state_try_fit_after_cg:
-            {
-                BOOL commit_failed_p = FALSE;
-                BOOL can_use_existing_p = FALSE;
-                BOOL short_seg_end_p = FALSE;
-                can_use_existing_p = soh_try_fit (gen_number, size, acontext, flags,
-                                                  align_const, &commit_failed_p,
-                                                  &short_seg_end_p);
-                if (can_use_existing_p)
-                {
-                    soh_alloc_state = a_state_can_allocate;
-                }
-#ifdef MULTIPLE_HEAPS
-                else if (gen0_allocated_after_gc_p)
-                {
-                    soh_alloc_state = a_state_trigger_ephemeral_gc;
-                }
-#endif //MULTIPLE_HEAPS
-                else if (short_seg_end_p)
-                {
-                    soh_alloc_state = a_state_cant_allocate;
-                    oom_r = oom_budget;
-                }
-                else
-                {
-                    assert (commit_failed_p || heap_hard_limit);
-                    soh_alloc_state = a_state_cant_allocate;
-                    oom_r = oom_cant_commit;
-                }
-                break;
-            }
-            case a_state_check_and_wait_for_bgc:
-            {
-                BOOL bgc_in_progress_p = FALSE;
-                BOOL did_full_compacting_gc = FALSE;
-                bgc_in_progress_p = check_and_wait_for_bgc (awr_gen0_oos_bgc, &did_full_compacting_gc, false, &msl_status);
-                if (msl_status == msl_retry_different_heap) return a_state_retry_allocate;
-                soh_alloc_state = (did_full_compacting_gc ?
-                                        a_state_try_fit_after_cg :
-                                        a_state_try_fit_after_bgc);
-                break;
-            }
-            case a_state_trigger_ephemeral_gc:
-            {
-                BOOL commit_failed_p = FALSE;
-                BOOL can_use_existing_p = FALSE;
-                BOOL short_seg_end_p = FALSE;
-                BOOL bgc_in_progress_p = FALSE;
-                BOOL did_full_compacting_gc = FALSE;
-                did_full_compacting_gc = trigger_ephemeral_gc (gr, &msl_status);
-                if (msl_status == msl_retry_different_heap) return a_state_retry_allocate;
-                if (did_full_compacting_gc)
-                {
-                    soh_alloc_state = a_state_try_fit_after_cg;
-                }
-                else
-                {
-                    can_use_existing_p = soh_try_fit (gen_number, size, acontext, flags,
-                                                      align_const, &commit_failed_p,
-                                                      &short_seg_end_p);
-#ifdef BACKGROUND_GC
-                    bgc_in_progress_p = gc_heap::background_running_p();
-#endif //BACKGROUND_GC
-                    if (can_use_existing_p)
-                    {
-                        soh_alloc_state = a_state_can_allocate;
-                    }
-                    else
-                    {
-                        if (short_seg_end_p)
-                        {
-#ifndef USE_REGIONS
-                            if (should_expand_in_full_gc)
-                            {
-                                dprintf (2, ("gen1 GC wanted to expand!"));
-                                soh_alloc_state = a_state_trigger_full_compact_gc;
-                            }
-                            else
-#endif //!USE_REGIONS
-                            {
-                                soh_alloc_state = (bgc_in_progress_p ?
-                                                        a_state_check_and_wait_for_bgc :
-                                                        a_state_trigger_full_compact_gc);
-                            }
-                        }
-                        else if (commit_failed_p)
-                        {
-                            soh_alloc_state = a_state_trigger_full_compact_gc;
-                        }
-                        else
-                        {
-#ifdef MULTIPLE_HEAPS
-                            assert (gen0_allocated_after_gc_p);
-                            soh_alloc_state = a_state_trigger_ephemeral_gc;
-#else //MULTIPLE_HEAPS
-                            assert (!"shouldn't get here");
-#endif //MULTIPLE_HEAPS
-                        }
-                    }
-                }
-                break;
-            }
-            case a_state_trigger_2nd_ephemeral_gc:
-            {
-                BOOL commit_failed_p = FALSE;
-                BOOL can_use_existing_p = FALSE;
-                BOOL short_seg_end_p = FALSE;
-                BOOL did_full_compacting_gc = FALSE;
-                did_full_compacting_gc = trigger_ephemeral_gc (gr, &msl_status);
-                if (msl_status == msl_retry_different_heap) return a_state_retry_allocate;
-                if (did_full_compacting_gc)
-                {
-                    soh_alloc_state = a_state_try_fit_after_cg;
-                }
-                else
-                {
-                    can_use_existing_p = soh_try_fit (gen_number, size, acontext, flags,
-                                                      align_const, &commit_failed_p,
-                                                      &short_seg_end_p);
-                    if (short_seg_end_p || commit_failed_p)
-                    {
-                        soh_alloc_state = a_state_trigger_full_compact_gc;
-                    }
-                    else
-                    {
-                        assert (can_use_existing_p);
-                        soh_alloc_state = a_state_can_allocate;
-                    }
-                }
-                break;
-            }
-            case a_state_trigger_full_compact_gc:
-            {
-                if (fgn_maxgen_percent)
-                {
-                    dprintf (2, ("FGN: SOH doing last GC before we throw OOM"));
-                    send_full_gc_notification (max_generation, FALSE);
-                }
-                BOOL got_full_compacting_gc = FALSE;
-                got_full_compacting_gc = trigger_full_compact_gc (gr, &oom_r, false, &msl_status);
-                if (msl_status == msl_retry_different_heap) return a_state_retry_allocate;
-                soh_alloc_state = (got_full_compacting_gc ? a_state_try_fit_after_cg : a_state_cant_allocate);
-                break;
-            }
-            default:
-            {
-                assert (!"Invalid state!");
-                break;
-            }
-        }
-    }
-exit:
-    if (soh_alloc_state == a_state_cant_allocate)
-    {
-        assert (oom_r != oom_no_failure);
-        handle_oom (oom_r,
-                    size,
-                    heap_segment_allocated (ephemeral_heap_segment),
-                    heap_segment_reserved (ephemeral_heap_segment));
-        add_saved_spinlock_info (false, me_release, mt_alloc_small_cant, msl_entered);
-        leave_spin_lock (&more_space_lock_soh);
-    }
-    assert ((soh_alloc_state == a_state_can_allocate) ||
-            (soh_alloc_state == a_state_cant_allocate) ||
-            (soh_alloc_state == a_state_retry_allocate));
-    return soh_alloc_state;
-}
-#ifdef BACKGROUND_GC
-inline
-void gc_heap::bgc_track_uoh_alloc()
-{
-    if (current_c_gc_state == c_gc_state_planning)
-    {
-        Interlocked::Increment (&uoh_alloc_thread_count);
-        dprintf (3, ("h%d: inc lc: %d", heap_number, (int32_t)uoh_alloc_thread_count));
-    }
-}
-inline
-void gc_heap::bgc_untrack_uoh_alloc()
-{
-    if (current_c_gc_state == c_gc_state_planning)
-    {
-        Interlocked::Decrement (&uoh_alloc_thread_count);
-        dprintf (3, ("h%d: dec lc: %d", heap_number, (int32_t)uoh_alloc_thread_count));
-    }
-}
-int bgc_allocate_spin(size_t min_gc_size, size_t bgc_begin_size, size_t bgc_size_increased, size_t end_size)
-{
-    if ((bgc_begin_size + bgc_size_increased) < (min_gc_size * 10))
-    {
-        return 0;
-    }
-    if ((bgc_begin_size >= (2 * end_size)) || (bgc_size_increased >= bgc_begin_size))
-    {
-        if (bgc_begin_size >= (2 * end_size))
-        {
-            dprintf (3, ("alloc-ed too much before bgc started"));
-        }
-        else
-        {
-            dprintf (3, ("alloc-ed too much after bgc started"));
-        }
-        return -1;
-    }
-    else
-    {
-        return (int)(((float)bgc_size_increased / (float)bgc_begin_size) * 10);
-    }
-}
-int gc_heap::bgc_loh_allocate_spin()
-{
-    size_t min_gc_size = dd_min_size (dynamic_data_of (loh_generation));
-    size_t bgc_begin_size = bgc_begin_loh_size;
-    size_t bgc_size_increased = bgc_loh_size_increased;
-    size_t end_size = end_loh_size;
-    return bgc_allocate_spin(min_gc_size, bgc_begin_size, bgc_size_increased, end_size);
-}
-int gc_heap::bgc_poh_allocate_spin()
-{
-    size_t min_gc_size = dd_min_size (dynamic_data_of (poh_generation));
-    size_t bgc_begin_size = bgc_begin_poh_size;
-    size_t bgc_size_increased = bgc_poh_size_increased;
-    size_t end_size = end_poh_size;
-    return bgc_allocate_spin(min_gc_size, bgc_begin_size, bgc_size_increased, end_size);
-}
-#endif //BACKGROUND_GC
-size_t gc_heap::get_uoh_seg_size (size_t size)
-{
-    size_t default_seg_size =
-#ifdef USE_REGIONS
-        global_region_allocator.get_large_region_alignment();
-#else
-        min_uoh_segment_size;
-#endif //USE_REGIONS
-    size_t align_size =  default_seg_size;
-    int align_const = get_alignment_constant (FALSE);
-    size_t large_seg_size = align_on_page (
-        max (default_seg_size,
-            ((size + 2 * Align(min_obj_size, align_const) + OS_PAGE_SIZE +
-            align_size) / align_size * align_size)));
-    return large_seg_size;
-}
-BOOL gc_heap::uoh_get_new_seg (int gen_number,
-                               size_t size,
-                               BOOL* did_full_compact_gc,
-                               oom_reason* oom_r,
-                               enter_msl_status* msl_status)
-{
-    *did_full_compact_gc = FALSE;
-    size_t seg_size = get_uoh_seg_size (size);
-    heap_segment* new_seg = get_uoh_segment (gen_number, seg_size, did_full_compact_gc, msl_status);
-    if (*msl_status == msl_retry_different_heap) return FALSE;
-    if (new_seg && (gen_number == loh_generation))
-    {
-        loh_alloc_since_cg += seg_size;
-    }
-    else
-    {
-        *oom_r = oom_loh;
-    }
-    return (new_seg != 0);
-}
-BOOL gc_heap::retry_full_compact_gc (size_t size)
-{
-    size_t seg_size = get_uoh_seg_size (size);
-    if (loh_alloc_since_cg >= (2 * (uint64_t)seg_size))
-    {
-        return TRUE;
-    }
-#ifdef MULTIPLE_HEAPS
-    uint64_t total_alloc_size = 0;
-    for (int i = 0; i < n_heaps; i++)
-    {
-        total_alloc_size += g_heaps[i]->loh_alloc_since_cg;
-    }
-    if (total_alloc_size >= (2 * (uint64_t)seg_size))
-    {
-        return TRUE;
-    }
-#endif //MULTIPLE_HEAPS
-    return FALSE;
-}
-BOOL gc_heap::check_and_wait_for_bgc (alloc_wait_reason awr,
-                                      BOOL* did_full_compact_gc,
-                                      bool loh_p,
-                                      enter_msl_status* msl_status)
-{
-    BOOL bgc_in_progress = FALSE;
-    *did_full_compact_gc = FALSE;
-#ifdef BACKGROUND_GC
-    if (gc_heap::background_running_p())
-    {
-        bgc_in_progress = TRUE;
-        size_t last_full_compact_gc_count = get_full_compact_gc_count();
-        *msl_status = wait_for_background (awr, loh_p);
-        size_t current_full_compact_gc_count = get_full_compact_gc_count();
-        if (current_full_compact_gc_count > last_full_compact_gc_count)
-        {
-            *did_full_compact_gc = TRUE;
-        }
-    }
-#endif //BACKGROUND_GC
-    return bgc_in_progress;
-}
-BOOL gc_heap::uoh_try_fit (int gen_number,
-                           size_t size,
-                           alloc_context* acontext,
-                           uint32_t flags,
-                           int align_const,
-                           BOOL* commit_failed_p,
-                           oom_reason* oom_r)
-{
-    BOOL can_allocate = TRUE;
-    if (!a_fit_free_list_uoh_p (size, acontext, flags, align_const, gen_number))
-    {
-        can_allocate = uoh_a_fit_segment_end_p (gen_number, size,
-                                                acontext, flags, align_const,
-                                                commit_failed_p, oom_r);
-#ifdef BACKGROUND_GC
-        if (can_allocate && gc_heap::background_running_p())
-        {
-            if (gen_number == poh_generation)
-            {
-                bgc_poh_size_increased += size;
-            }
-            else
-            {
-                bgc_loh_size_increased += size;
-            }
-        }
-#endif //BACKGROUND_GC
-    }
-    return can_allocate;
-}
-BOOL gc_heap::trigger_full_compact_gc (gc_reason gr,
-                                       oom_reason* oom_r,
-                                       bool loh_p,
-                                       enter_msl_status* msl_status)
-{
-    BOOL did_full_compact_gc = FALSE;
-    size_t last_full_compact_gc_count = get_full_compact_gc_count();
-    if (!last_gc_before_oom)
-    {
-        last_gc_before_oom = TRUE;
-    }
-#ifdef BACKGROUND_GC
-    if (gc_heap::background_running_p())
-    {
-        *msl_status = wait_for_background (((gr == reason_oos_soh) ? awr_gen0_oos_bgc : awr_loh_oos_bgc), loh_p);
-        dprintf (2, ("waited for BGC - done"));
-        if (*msl_status == msl_retry_different_heap) return FALSE;
-    }
-#endif //BACKGROUND_GC
-    GCSpinLock* msl = loh_p ? &more_space_lock_uoh : &more_space_lock_soh;
-    size_t current_full_compact_gc_count = get_full_compact_gc_count();
-    if (current_full_compact_gc_count > last_full_compact_gc_count)
-    {
-        dprintf (3, ("a full compacting GC triggered while waiting for BGC (%zd->%zd)", last_full_compact_gc_count, current_full_compact_gc_count));
-        assert (current_full_compact_gc_count > last_full_compact_gc_count);
-        did_full_compact_gc = TRUE;
-        goto exit;
-    }
-    dprintf (3, ("h%d full GC", heap_number));
-    *msl_status = trigger_gc_for_alloc (max_generation, gr, msl, loh_p, mt_t_full_gc);
-    current_full_compact_gc_count = get_full_compact_gc_count();
-    if (current_full_compact_gc_count == last_full_compact_gc_count)
-    {
-        dprintf (2, ("attempted to trigger a full compacting GC but didn't get it"));
-        *oom_r = oom_unproductive_full_gc;
-    }
-    else
-    {
-        dprintf (3, ("h%d: T full compacting GC (%zd->%zd)",
-            heap_number,
-            last_full_compact_gc_count,
-            current_full_compact_gc_count));
-        assert (current_full_compact_gc_count > last_full_compact_gc_count);
-        did_full_compact_gc = TRUE;
-    }
-exit:
-    return did_full_compact_gc;
-}
-#ifdef RECORD_LOH_STATE
-void gc_heap::add_saved_loh_state (allocation_state loh_state_to_save, EEThreadId thread_id)
-{
-    if (loh_state_to_save != a_state_can_allocate)
-    {
-        last_loh_states[loh_state_index].alloc_state = loh_state_to_save;
-        last_loh_states[loh_state_index].gc_index = VolatileLoadWithoutBarrier (&settings.gc_index);
-        last_loh_states[loh_state_index].thread_id = thread_id;
-        loh_state_index++;
-        if (loh_state_index == max_saved_loh_states)
-        {
-            loh_state_index = 0;
-        }
-        assert (loh_state_index < max_saved_loh_states);
-    }
-}
-#endif //RECORD_LOH_STATE
-bool gc_heap::should_retry_other_heap (int gen_number, size_t size)
-{
-#ifdef MULTIPLE_HEAPS
-    if (heap_hard_limit)
-    {
-        size_t min_size = dd_min_size (g_heaps[0]->dynamic_data_of (gen_number));
-        size_t slack_space = max (commit_min_th, min_size);
-        bool retry_p = ((current_total_committed + size) < (heap_hard_limit - slack_space));
-        dprintf (1, ("%zd - %zd - total committed %zd - size %zd = %zd, %s",
-            heap_hard_limit, slack_space, current_total_committed, size,
-            (heap_hard_limit - slack_space - current_total_committed - size),
-            (retry_p ? "retry" : "no retry")));
-        return retry_p;
-    }
-    else
-#endif //MULTIPLE_HEAPS
-    {
-        return false;
-    }
-}
-#ifdef BACKGROUND_GC
-void gc_heap::bgc_record_uoh_allocation(int gen_number, size_t size)
-{
-    assert((gen_number >= uoh_start_generation) && (gen_number < total_generation_count));
-    if (gc_heap::background_running_p())
-    {
-        background_uoh_alloc_count++;
-        if (current_c_gc_state == c_gc_state_planning)
-        {
-            uoh_a_bgc_planning[gen_number - uoh_start_generation] += size;
-        }
-        else
-        {
-            uoh_a_bgc_marking[gen_number - uoh_start_generation] += size;
-        }
-    }
-    else
-    {
-        uoh_a_no_bgc[gen_number - uoh_start_generation] += size;
-    }
-}
-#endif //BACKGROUND_GC
-allocation_state gc_heap::allocate_uoh (int gen_number,
-                                          size_t size,
-                                          alloc_context* acontext,
-                                          uint32_t flags,
-                                          int align_const)
-{
-    enter_msl_status msl_status = msl_entered;
-    allocation_state uoh_alloc_state = a_state_start;
-#ifdef SPINLOCK_HISTORY
-    current_uoh_alloc_state = uoh_alloc_state;
-#endif //SPINLOCK_HISTORY
-#ifdef RECORD_LOH_STATE
-    EEThreadId current_thread_id;
-    current_thread_id.SetToCurrentThread ();
-#endif //RECORD_LOH_STATE
-#ifdef BACKGROUND_GC
-    bgc_record_uoh_allocation(gen_number, size);
-    if (gc_heap::background_running_p())
-    {
-        {
-            int spin_for_allocation = (gen_number == loh_generation) ?
-                bgc_loh_allocate_spin() :
-                bgc_poh_allocate_spin();
-            if (spin_for_allocation > 0)
-            {
-                add_saved_spinlock_info (true, me_release, mt_alloc_large, msl_status);
-                leave_spin_lock (&more_space_lock_uoh);
-                bool cooperative_mode = enable_preemptive();
-                GCToOSInterface::YieldThread (spin_for_allocation);
-                disable_preemptive (cooperative_mode);
-                msl_status = enter_spin_lock_msl (&more_space_lock_uoh);
-                if (msl_status == msl_retry_different_heap) return a_state_retry_allocate;
-                add_saved_spinlock_info (true, me_acquire, mt_alloc_large, msl_status);
-                dprintf (SPINLOCK_LOG, ("[%d]spin Emsl uoh", heap_number));
-            }
-            else if (spin_for_allocation < 0)
-            {
-                msl_status = wait_for_background (awr_uoh_alloc_during_bgc, true);
-                check_msl_status ("uoh a_state_acquire_seg", size);
-            }
-        }
-    }
-#endif //BACKGROUND_GC
-    gc_reason gr = reason_oos_loh;
-    generation* gen = generation_of (gen_number);
-    oom_reason oom_r = oom_no_failure;
-    size_t current_full_compact_gc_count = 0;
-    while (1)
-    {
-        dprintf (3, ("[h%d]loh state is %s", heap_number, allocation_state_str[uoh_alloc_state]));
-#ifdef SPINLOCK_HISTORY
-        current_uoh_alloc_state = uoh_alloc_state;
-#endif //SPINLOCK_HISTORY
-#ifdef RECORD_LOH_STATE
-        current_uoh_alloc_state = uoh_alloc_state;
-        add_saved_loh_state (uoh_alloc_state, current_thread_id);
-#endif //RECORD_LOH_STATE
-        switch (uoh_alloc_state)
-        {
-            case a_state_can_allocate:
-            case a_state_cant_allocate:
-            {
-                goto exit;
-            }
-            case a_state_start:
-            {
-                uoh_alloc_state = a_state_try_fit;
-                break;
-            }
-            case a_state_try_fit:
-            {
-                BOOL commit_failed_p = FALSE;
-                BOOL can_use_existing_p = FALSE;
-                can_use_existing_p = uoh_try_fit (gen_number, size, acontext, flags,
-                                                  align_const, &commit_failed_p, &oom_r);
-                uoh_alloc_state = (can_use_existing_p ?
-                                        a_state_can_allocate :
-                                        (commit_failed_p ?
-                                            a_state_trigger_full_compact_gc :
-                                            a_state_acquire_seg));
-                assert ((uoh_alloc_state == a_state_can_allocate) == (acontext->alloc_ptr != 0));
-                break;
-            }
-            case a_state_try_fit_new_seg:
-            {
-                BOOL commit_failed_p = FALSE;
-                BOOL can_use_existing_p = FALSE;
-                can_use_existing_p = uoh_try_fit (gen_number, size, acontext, flags,
-                                                  align_const, &commit_failed_p, &oom_r);
-                uoh_alloc_state = (can_use_existing_p ? a_state_can_allocate : a_state_try_fit);
-                assert ((uoh_alloc_state == a_state_can_allocate) == (acontext->alloc_ptr != 0));
-                break;
-            }
-            case a_state_try_fit_after_cg:
-            {
-                BOOL commit_failed_p = FALSE;
-                BOOL can_use_existing_p = FALSE;
-                can_use_existing_p = uoh_try_fit (gen_number, size, acontext, flags,
-                                                  align_const, &commit_failed_p, &oom_r);
-                uoh_alloc_state = (can_use_existing_p ?
-                                        a_state_can_allocate :
-                                        (commit_failed_p ?
-                                            a_state_cant_allocate :
-                                            a_state_acquire_seg_after_cg));
-                assert ((uoh_alloc_state == a_state_can_allocate) == (acontext->alloc_ptr != 0));
-                break;
-            }
-            case a_state_try_fit_after_bgc:
-            {
-                BOOL commit_failed_p = FALSE;
-                BOOL can_use_existing_p = FALSE;
-                can_use_existing_p = uoh_try_fit (gen_number, size, acontext, flags,
-                                                  align_const, &commit_failed_p, &oom_r);
-                uoh_alloc_state = (can_use_existing_p ?
-                                        a_state_can_allocate :
-                                        (commit_failed_p ?
-                                            a_state_trigger_full_compact_gc :
-                                            a_state_acquire_seg_after_bgc));
-                assert ((uoh_alloc_state == a_state_can_allocate) == (acontext->alloc_ptr != 0));
-                break;
-            }
-            case a_state_acquire_seg:
-            {
-                BOOL can_get_new_seg_p = FALSE;
-                BOOL did_full_compacting_gc = FALSE;
-                current_full_compact_gc_count = get_full_compact_gc_count();
-                can_get_new_seg_p = uoh_get_new_seg (gen_number, size, &did_full_compacting_gc, &oom_r, &msl_status);
-                check_msl_status ("uoh a_state_acquire_seg", size);
-                uoh_alloc_state = (can_get_new_seg_p ?
-                                        a_state_try_fit_new_seg :
-                                        (did_full_compacting_gc ?
-                                            a_state_check_retry_seg :
-                                            a_state_check_and_wait_for_bgc));
-                break;
-            }
-            case a_state_acquire_seg_after_cg:
-            {
-                BOOL can_get_new_seg_p = FALSE;
-                BOOL did_full_compacting_gc = FALSE;
-                current_full_compact_gc_count = get_full_compact_gc_count();
-                can_get_new_seg_p = uoh_get_new_seg (gen_number, size, &did_full_compacting_gc, &oom_r, &msl_status);
-                check_msl_status ("uoh a_state_acquire_seg_after_cg", size);
-                uoh_alloc_state = (can_get_new_seg_p ?
-                                        a_state_try_fit_after_cg :
-                                        a_state_check_retry_seg);
-                break;
-            }
-            case a_state_acquire_seg_after_bgc:
-            {
-                BOOL can_get_new_seg_p = FALSE;
-                BOOL did_full_compacting_gc = FALSE;
-                current_full_compact_gc_count = get_full_compact_gc_count();
-                can_get_new_seg_p = uoh_get_new_seg (gen_number, size, &did_full_compacting_gc, &oom_r, &msl_status);
-                check_msl_status ("uoh a_state_acquire_seg_after_bgc", size);
-                uoh_alloc_state = (can_get_new_seg_p ?
-                                        a_state_try_fit_new_seg :
-                                        (did_full_compacting_gc ?
-                                            a_state_check_retry_seg :
-                                            a_state_trigger_full_compact_gc));
-                assert ((uoh_alloc_state != a_state_cant_allocate) || (oom_r != oom_no_failure));
-                break;
-            }
-            case a_state_check_and_wait_for_bgc:
-            {
-                BOOL bgc_in_progress_p = FALSE;
-                BOOL did_full_compacting_gc = FALSE;
-                bgc_in_progress_p = check_and_wait_for_bgc (awr_loh_oos_bgc, &did_full_compacting_gc, true, &msl_status);
-                check_msl_status ("uoh a_state_check_and_wait_for_bgc", size);
-                uoh_alloc_state = (!bgc_in_progress_p ?
-                                        a_state_trigger_full_compact_gc :
-                                        (did_full_compacting_gc ?
-                                            a_state_try_fit_after_cg :
-                                            a_state_try_fit_after_bgc));
-                break;
-            }
-            case a_state_trigger_full_compact_gc:
-            {
-                if (fgn_maxgen_percent)
-                {
-                    dprintf (2, ("FGN: LOH doing last GC before we throw OOM"));
-                    send_full_gc_notification (max_generation, FALSE);
-                }
-                BOOL got_full_compacting_gc = FALSE;
-                got_full_compacting_gc = trigger_full_compact_gc (gr, &oom_r, true, &msl_status);
-                check_msl_status ("uoh a_state_trigger_full_compact_gc", size);
-                uoh_alloc_state = (got_full_compacting_gc ? a_state_try_fit_after_cg : a_state_cant_allocate);
-                assert ((uoh_alloc_state != a_state_cant_allocate) || (oom_r != oom_no_failure));
-                break;
-            }
-            case a_state_check_retry_seg:
-            {
-                BOOL should_retry_gc = retry_full_compact_gc (size);
-                BOOL should_retry_get_seg = FALSE;
-                if (!should_retry_gc)
-                {
-                    size_t last_full_compact_gc_count = current_full_compact_gc_count;
-                    current_full_compact_gc_count = get_full_compact_gc_count();
-                    if (current_full_compact_gc_count > last_full_compact_gc_count)
-                    {
-                        should_retry_get_seg = TRUE;
-                    }
-                }
-                uoh_alloc_state = (should_retry_gc ?
-                                        a_state_trigger_full_compact_gc :
-                                        (should_retry_get_seg ?
-                                            a_state_try_fit_after_cg :
-                                            a_state_cant_allocate));
-                assert ((uoh_alloc_state != a_state_cant_allocate) || (oom_r != oom_no_failure));
-                break;
-            }
-            default:
-            {
-                assert (!"Invalid state!");
-                break;
-            }
-        }
-    }
-exit:
-    if (uoh_alloc_state == a_state_cant_allocate)
-    {
-        assert (oom_r != oom_no_failure);
-        if ((oom_r != oom_cant_commit) && should_retry_other_heap (gen_number, size))
-        {
-            uoh_alloc_state = a_state_retry_allocate;
-        }
-        else
-        {
-            handle_oom (oom_r,
-                        size,
-                        0,
-                        0);
-        }
-        add_saved_spinlock_info (true, me_release, mt_alloc_large_cant, msl_entered);
-        leave_spin_lock (&more_space_lock_uoh);
-    }
-    assert ((uoh_alloc_state == a_state_can_allocate) ||
-            (uoh_alloc_state == a_state_cant_allocate) ||
-            (uoh_alloc_state == a_state_retry_allocate));
-    return uoh_alloc_state;
-}
-enter_msl_status gc_heap::trigger_gc_for_alloc (int gen_number, gc_reason gr,
-                                    GCSpinLock* msl, bool loh_p,
-                                    msl_take_state take_state)
-{
-    enter_msl_status msl_status = msl_entered;
-#ifdef BACKGROUND_GC
-    if (loh_p)
-    {
-#ifdef MULTIPLE_HEAPS
-#ifdef STRESS_DYNAMIC_HEAP_COUNT
-        uoh_msl_before_gc_p = true;
-#endif //STRESS_DYNAMIC_HEAP_COUNT
-        dprintf (5555, ("h%d uoh alloc before GC", heap_number));
-#endif //MULTIPLE_HEAPS
-        add_saved_spinlock_info (loh_p, me_release, take_state, msl_status);
-        leave_spin_lock (msl);
-    }
-#endif //BACKGROUND_GC
-#ifdef MULTIPLE_HEAPS
-    if (!loh_p)
-    {
-        add_saved_spinlock_info (loh_p, me_release, take_state, msl_status);
-        leave_spin_lock (msl);
-    }
-#endif //MULTIPLE_HEAPS
-    vm_heap->GarbageCollectGeneration (gen_number, gr);
-#ifdef MULTIPLE_HEAPS
-    if (!loh_p)
-    {
-        msl_status = enter_spin_lock_msl (msl);
-        add_saved_spinlock_info (loh_p, me_acquire, take_state, msl_status);
-    }
-#endif //MULTIPLE_HEAPS
-#ifdef BACKGROUND_GC
-    if (loh_p)
-    {
-        msl_status = enter_spin_lock_msl (msl);
-        add_saved_spinlock_info (loh_p, me_acquire, take_state, msl_status);
-    }
-#endif //BACKGROUND_GC
-    return msl_status;
-}
-inline
-bool gc_heap::update_alloc_info (int gen_number, size_t allocated_size, size_t* etw_allocation_amount)
-{
-    bool exceeded_p = false;
-    int oh_index = gen_to_oh (gen_number);
-    allocated_since_last_gc[oh_index] += allocated_size;
-    size_t& etw_allocated = etw_allocation_running_amount[oh_index];
-    etw_allocated += allocated_size;
-    if (etw_allocated > etw_allocation_tick)
-    {
-        *etw_allocation_amount = etw_allocated;
-        exceeded_p = true;
-        etw_allocated = 0;
-    }
-    return exceeded_p;
-}
-allocation_state gc_heap::try_allocate_more_space (alloc_context* acontext, size_t size,
-                                    uint32_t flags, int gen_number)
-{
-    enter_msl_status msl_status = msl_entered;
-    if (gc_heap::gc_started)
-    {
-        wait_for_gc_done();
-        return a_state_retry_allocate;
-    }
-    bool loh_p = (gen_number > 0);
-    GCSpinLock* msl = loh_p ? &more_space_lock_uoh : &more_space_lock_soh;
-#ifdef SYNCHRONIZATION_STATS
-    int64_t msl_acquire_start = GCToOSInterface::QueryPerformanceCounter();
-#endif //SYNCHRONIZATION_STATS
-    msl_status = enter_spin_lock_msl (msl);
-    check_msl_status ("TAMS", size);
-    add_saved_spinlock_info (loh_p, me_acquire, mt_try_alloc, msl_status);
-    dprintf (SPINLOCK_LOG, ("[%d]Emsl for alloc", heap_number));
-#ifdef SYNCHRONIZATION_STATS
-    int64_t msl_acquire = GCToOSInterface::QueryPerformanceCounter() - msl_acquire_start;
-    total_msl_acquire += msl_acquire;
-    num_msl_acquired++;
-    if (msl_acquire > 200)
-    {
-        num_high_msl_acquire++;
-    }
-    else
-    {
-        num_low_msl_acquire++;
-    }
-#endif //SYNCHRONIZATION_STATS
-    dprintf (3, ("requested to allocate %zd bytes on gen%d", size, gen_number));
-    int align_const = get_alignment_constant (gen_number <= max_generation);
-    if (fgn_maxgen_percent)
-    {
-        check_for_full_gc (gen_number, size);
-    }
-#ifdef BGC_SERVO_TUNING
-    if ((gen_number != 0) && bgc_tuning::should_trigger_bgc_loh())
-    {
-        msl_status = trigger_gc_for_alloc (max_generation, reason_bgc_tuning_loh, msl, loh_p, mt_try_servo_budget);
-        if (msl_status == msl_retry_different_heap) return a_state_retry_allocate;
-    }
-    else
-#endif //BGC_SERVO_TUNING
-    {
-        bool trigger_on_budget_loh_p =
-#ifdef BGC_SERVO_TUNING
-            !bgc_tuning::enable_fl_tuning;
-#else
-            true;
-#endif //BGC_SERVO_TUNING
-        bool check_budget_p = true;
-        if (gen_number != 0)
-        {
-            check_budget_p = trigger_on_budget_loh_p;
-        }
-        if (check_budget_p && !(new_allocation_allowed (gen_number)))
-        {
-            if (fgn_maxgen_percent && (gen_number == 0))
-            {
-                check_for_full_gc (gen_number, size);
-            }
-#ifdef BACKGROUND_GC
-            bool recheck_p = wait_for_bgc_high_memory (awr_gen0_alloc, loh_p, &msl_status);
-            if (msl_status == msl_retry_different_heap) return a_state_retry_allocate;
-#endif //BACKGROUND_GC
-#ifdef SYNCHRONIZATION_STATS
-            bad_suspension++;
-#endif //SYNCHRONIZATION_STATS
-            dprintf (2, ("h%d running out of budget on gen%d, gc", heap_number, gen_number));
-#ifdef BACKGROUND_GC
-            bool trigger_gc_p = true;
-            if (recheck_p)
-                trigger_gc_p = !(new_allocation_allowed (gen_number));
-            if (trigger_gc_p)
-#endif //BACKGROUND_GC
-            {
-                if (!settings.concurrent || (gen_number == 0))
-                {
-                    msl_status = trigger_gc_for_alloc (0, ((gen_number == 0) ? reason_alloc_soh : reason_alloc_loh),
-                                                       msl, loh_p, mt_try_budget);
-                    if (msl_status == msl_retry_different_heap) return a_state_retry_allocate;
-                }
-            }
-        }
-    }
-    allocation_state can_allocate = ((gen_number == 0) ?
-        allocate_soh (gen_number, size, acontext, flags, align_const) :
-        allocate_uoh (gen_number, size, acontext, flags, align_const));
-    return can_allocate;
-}
-#ifdef MULTIPLE_HEAPS
-void gc_heap::balance_heaps (alloc_context* acontext)
-{
-    if (acontext->get_alloc_count() < 4)
-    {
-        if (acontext->get_alloc_count() == 0)
-        {
-            int home_hp_num = heap_select::select_heap (acontext);
-            acontext->set_home_heap (GCHeap::GetHeap (home_hp_num));
-            gc_heap* hp = acontext->get_home_heap ()->pGenGCHeap;
-            acontext->set_alloc_heap (acontext->get_home_heap ());
-            hp->alloc_context_count++;
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-            uint16_t ideal_proc_no = 0;
-            GCToOSInterface::GetCurrentThreadIdealProc (&ideal_proc_no);
-            uint32_t proc_no = GCToOSInterface::GetCurrentProcessorNumber ();
-            add_to_hb_numa (proc_no, ideal_proc_no,
-                home_hp_num, false, true, false);
-            dprintf (HEAP_BALANCE_TEMP_LOG, ("TEMPafter GC: 1st alloc on p%3d, h%d, ip: %d",
-                proc_no, home_hp_num, ideal_proc_no));
-#endif //HEAP_BALANCE_INSTRUMENTATION
-        }
-    }
-    else
-    {
-        BOOL set_home_heap = FALSE;
-        gc_heap* home_hp = NULL;
-        int proc_hp_num = 0;
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-        bool alloc_count_p = true;
-        bool multiple_procs_p = false;
-        bool set_ideal_p = false;
-        uint32_t proc_no = GCToOSInterface::GetCurrentProcessorNumber ();
-        uint32_t last_proc_no = proc_no;
-#endif //HEAP_BALANCE_INSTRUMENTATION
-        if (heap_select::can_find_heap_fast ())
-        {
-            assert (acontext->get_home_heap () != NULL);
-            home_hp = acontext->get_home_heap ()->pGenGCHeap;
-            proc_hp_num = heap_select::select_heap (acontext);
-            if (home_hp != gc_heap::g_heaps[proc_hp_num])
-            {
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-                alloc_count_p = false;
-#endif //HEAP_BALANCE_INSTRUMENTATION
-                set_home_heap = TRUE;
-            }
-            else if ((acontext->get_alloc_count() & 15) == 0)
-                set_home_heap = TRUE;
-        }
-        else
-        {
-            if ((acontext->get_alloc_count() & 3) == 0)
-                set_home_heap = TRUE;
-        }
-        if (set_home_heap)
-        {
-            /*
-                        if (n_heaps > MAX_SUPPORTED_CPUS)
-                        {
-                            acontext->home_heap = GCHeap::GetHeap( heap_select::select_heap(acontext));
-                            acontext->alloc_heap = acontext->home_heap;
-                        }
-                        else
-            */
-            {
-                gc_heap* org_hp = acontext->get_alloc_heap ()->pGenGCHeap;
-                int org_hp_num = org_hp->heap_number;
-                int final_alloc_hp_num = org_hp_num;
-                dynamic_data* dd = org_hp->dynamic_data_of (0);
-                ptrdiff_t org_size = dd_new_allocation (dd);
-                ptrdiff_t total_size = (ptrdiff_t)dd_desired_allocation (dd);
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-                dprintf (HEAP_BALANCE_TEMP_LOG, ("TEMP[p%3d] ph h%3d, hh: %3d, ah: %3d (%dmb-%dmb), ac: %5d(%s)",
-                    proc_no, proc_hp_num, home_hp->heap_number,
-                    org_hp_num, (total_size / 1024 / 1024), (org_size / 1024 / 1024),
-                    acontext->get_alloc_count(),
-                    ((proc_hp_num == home_hp->heap_number) ? "AC" : "H")));
-#endif //HEAP_BALANCE_INSTRUMENTATION
-                int org_alloc_context_count;
-                int max_alloc_context_count;
-                gc_heap* max_hp;
-                int max_hp_num = 0;
-                ptrdiff_t max_size;
-                size_t local_delta = max (((size_t)org_size >> 6), min_gen0_balance_delta);
-                size_t delta = local_delta;
-                if (((size_t)org_size + 2 * delta) >= (size_t)total_size)
-                {
-                    acontext->inc_alloc_count();
-                    return;
-                }
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-                proc_no = GCToOSInterface::GetCurrentProcessorNumber ();
-                if (proc_no != last_proc_no)
-                {
-                    dprintf (HEAP_BALANCE_TEMP_LOG, ("TEMPSP: %d->%d", last_proc_no, proc_no));
-                    multiple_procs_p = true;
-                    last_proc_no = proc_no;
-                }
-                int new_home_hp_num = heap_select::proc_no_to_heap_no[proc_no];
-#else
-                int new_home_hp_num = heap_select::select_heap(acontext);
-#endif //HEAP_BALANCE_INSTRUMENTATION
-                gc_heap* new_home_hp = gc_heap::g_heaps[new_home_hp_num];
-                acontext->set_home_heap (new_home_hp->vm_heap);
-                int start, end, finish;
-                heap_select::get_heap_range_for_heap (new_home_hp_num, &start, &end);
-                finish = start + n_heaps;
-                do
-                {
-                    max_hp = org_hp;
-                    max_hp_num = org_hp_num;
-                    max_size = org_size + delta;
-                    org_alloc_context_count = org_hp->alloc_context_count;
-                    max_alloc_context_count = org_alloc_context_count;
-                    if (org_hp == new_home_hp)
-                        max_size = max_size + delta;
-                    if (max_alloc_context_count > 1)
-                        max_size /= max_alloc_context_count;
-                    if (org_hp != new_home_hp)
-                    {
-                        dd = new_home_hp->dynamic_data_of(0);
-                        ptrdiff_t size = dd_new_allocation(dd);
-                        size += delta * 2;
-                        int new_home_hp_alloc_context_count = new_home_hp->alloc_context_count;
-                        if (new_home_hp_alloc_context_count > 0)
-                            size /= (new_home_hp_alloc_context_count + 1);
-                        if (size > max_size)
-                        {
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-                            dprintf(HEAP_BALANCE_TEMP_LOG, ("TEMPorg h%d(%dmb), m h%d(%dmb)",
-                                org_hp_num, (max_size / 1024 / 1024),
-                                new_home_hp_num, (size / 1024 / 1024)));
-#endif //HEAP_BALANCE_INSTRUMENTATION
-                            max_hp = new_home_hp;
-                            max_size = size;
-                            max_hp_num = new_home_hp_num;
-                            max_alloc_context_count = new_home_hp_alloc_context_count;
-                        }
-                    }
-                    enum
-                    {
-                        LOCAL_NUMA_NODE,
-                        REMOTE_NUMA_NODE
-                    };
-                    for (int pass = LOCAL_NUMA_NODE; pass <= REMOTE_NUMA_NODE; pass++)
-                    {
-                        int count = end - start;
-                        int max_tries = min(count, 4);
-                        int heap_num = start + ((acontext->get_alloc_count() >> 2) + new_home_hp_num) % count;
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-                        dprintf(HEAP_BALANCE_TEMP_LOG, ("TEMP starting at h%d (home_heap_num = %d, alloc_count = %d)", heap_num, new_home_hp_num, acontext->get_alloc_count()));
-#endif //HEAP_BALANCE_INSTRUMENTATION
-                        for (int tries = max_tries; --tries >= 0; heap_num++)
-                        {
-                            if (heap_num >= end)
-                                heap_num -= count;
-                            while (heap_num >= n_heaps)
-                                heap_num -= n_heaps;
-                            assert (heap_num < n_heaps);
-                            gc_heap* hp = gc_heap::g_heaps[heap_num];
-                            dd = hp->dynamic_data_of(0);
-                            ptrdiff_t size = dd_new_allocation(dd);
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-                            dprintf(HEAP_BALANCE_TEMP_LOG, ("TEMP looking at h%d(%dmb)",
-                                heap_num, (size / 1024 / 1024)));
-#endif //HEAP_BALANCE_INSTRUMENTATION
-                            if (size <= max_size)
-                                continue;
-                            int hp_alloc_context_count = hp->alloc_context_count;
-                            if (hp_alloc_context_count > 0)
-                            {
-                                size /= (hp_alloc_context_count + 1);
-                            }
-                            if (size > max_size)
-                            {
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-                                dprintf(HEAP_BALANCE_TEMP_LOG, ("TEMPorg h%d(%dmb), m h%d(%dmb)",
-                                    org_hp_num, (max_size / 1024 / 1024),
-                                    hp->heap_number, (size / 1024 / 1024)));
-#endif //HEAP_BALANCE_INSTRUMENTATION
-                                max_hp = hp;
-                                max_size = size;
-                                max_hp_num = max_hp->heap_number;
-                                max_alloc_context_count = hp_alloc_context_count;
-                            }
-                        }
-                        if ((max_hp == org_hp) && (end < finish))
-                        {
-                            start = end; end = finish;
-                            delta = local_delta * 2; // Make it twice as hard to balance to remote nodes on NUMA.
-                        }
-                        else
-                        {
-                            break;
-                        }
-                    }
-                }
-                while (org_alloc_context_count != org_hp->alloc_context_count ||
-                       max_alloc_context_count != max_hp->alloc_context_count);
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-                uint16_t ideal_proc_no_before_set_ideal = 0;
-                GCToOSInterface::GetCurrentThreadIdealProc (&ideal_proc_no_before_set_ideal);
-#endif //HEAP_BALANCE_INSTRUMENTATION
-                if (max_hp != org_hp)
-                {
-                    final_alloc_hp_num = max_hp->heap_number;
-                    org_hp->alloc_context_count--;
-                    max_hp->alloc_context_count++;
-                    acontext->set_alloc_heap (GCHeap::GetHeap (final_alloc_hp_num));
-                    if (!gc_thread_no_affinitize_p)
-                    {
-                        uint16_t src_proc_no = heap_select::find_proc_no_from_heap_no (org_hp->heap_number);
-                        uint16_t dst_proc_no = heap_select::find_proc_no_from_heap_no (max_hp->heap_number);
-                        dprintf (HEAP_BALANCE_TEMP_LOG, ("TEMPSW! h%d(p%d)->h%d(p%d)",
-                            org_hp_num, src_proc_no, final_alloc_hp_num, dst_proc_no));
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-                        int current_proc_no_before_set_ideal = GCToOSInterface::GetCurrentProcessorNumber ();
-                        if ((uint16_t)current_proc_no_before_set_ideal != last_proc_no)
-                        {
-                            dprintf (HEAP_BALANCE_TEMP_LOG, ("TEMPSPa: %d->%d", last_proc_no, current_proc_no_before_set_ideal));
-                            multiple_procs_p = true;
-                        }
-#endif //HEAP_BALANCE_INSTRUMENTATION
-                        if (!GCToOSInterface::SetCurrentThreadIdealAffinity (src_proc_no, dst_proc_no))
-                        {
-                            dprintf (HEAP_BALANCE_TEMP_LOG, ("TEMPFailed to set the ideal processor for heap %d %d->%d",
-                                org_hp->heap_number, (int)src_proc_no, (int)dst_proc_no));
-                        }
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-                        else
-                        {
-                            set_ideal_p = true;
-                        }
-#endif //HEAP_BALANCE_INSTRUMENTATION
-                    }
-                }
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-                add_to_hb_numa (proc_no, ideal_proc_no_before_set_ideal,
-                    final_alloc_hp_num, multiple_procs_p, alloc_count_p, set_ideal_p);
-#endif //HEAP_BALANCE_INSTRUMENTATION
-            }
-        }
-    }
-    acontext->inc_alloc_count();
-}
-ptrdiff_t gc_heap::get_balance_heaps_uoh_effective_budget (int generation_num)
-{
-#ifndef USE_REGIONS
-    if (heap_hard_limit)
-    {
-        const ptrdiff_t free_list_space = generation_free_list_space (generation_of (generation_num));
-        heap_segment* seg = generation_start_segment (generation_of (generation_num));
-        assert (heap_segment_next (seg) == nullptr);
-        const ptrdiff_t allocated = heap_segment_allocated (seg) - seg->mem;
-        return free_list_space - allocated;
-    }
-    else
-#endif // !USE_REGIONS
-    {
-        return dd_new_allocation (dynamic_data_of (generation_num));
-    }
-}
-gc_heap* gc_heap::balance_heaps_uoh (alloc_context* acontext, size_t alloc_size, int generation_num)
-{
-    const int home_hp_num = heap_select::select_heap(acontext);
-    dprintf (3, ("[h%d] LA: %zd", home_hp_num, alloc_size));
-    gc_heap* home_hp = GCHeap::GetHeap(home_hp_num)->pGenGCHeap;
-    dynamic_data* dd = home_hp->dynamic_data_of (generation_num);
-    const ptrdiff_t home_hp_size = home_hp->get_balance_heaps_uoh_effective_budget (generation_num);
-    size_t delta = dd_min_size (dd) / 2;
-    int start, end;
-    heap_select::get_heap_range_for_heap(home_hp_num, &start, &end);
-    const int finish = start + n_heaps;
-try_again:
-    gc_heap* max_hp = home_hp;
-    ptrdiff_t max_size = home_hp_size + delta;
-    dprintf (3, ("home hp: %d, max size: %zd",
-        home_hp_num,
-        max_size));
-    for (int i = start; i < end; i++)
-    {
-        gc_heap* hp = GCHeap::GetHeap(i%n_heaps)->pGenGCHeap;
-        const ptrdiff_t size = hp->get_balance_heaps_uoh_effective_budget (generation_num);
-        dprintf (3, ("hp: %d, size: %zd", hp->heap_number, size));
-        if (size > max_size)
-        {
-            max_hp = hp;
-            max_size = size;
-            dprintf (3, ("max hp: %d, max size: %zd",
-                max_hp->heap_number,
-                max_size));
-        }
-    }
-    if ((max_hp == home_hp) && (end < finish))
-    {
-        start = end; end = finish;
-        delta = dd_min_size (dd) * 3 / 2; // Make it harder to balance to remote nodes on NUMA.
-        goto try_again;
-    }
-    if (max_hp != home_hp)
-    {
-        dprintf (3, ("uoh: %d(%zd)->%d(%zd)",
-            home_hp->heap_number, dd_new_allocation (home_hp->dynamic_data_of (generation_num)),
-            max_hp->heap_number, dd_new_allocation (max_hp->dynamic_data_of (generation_num))));
-    }
-    return max_hp;
-}
-gc_heap* gc_heap::balance_heaps_uoh_hard_limit_retry (alloc_context* acontext, size_t alloc_size, int generation_num)
-{
-    assert (heap_hard_limit);
-#ifdef USE_REGIONS
-    return balance_heaps_uoh (acontext, alloc_size, generation_num);
-#else //USE_REGIONS
-    const int home_heap = heap_select::select_heap(acontext);
-    dprintf (3, ("[h%d] balance_heaps_loh_hard_limit_retry alloc_size: %zd", home_heap, alloc_size));
-    int start, end;
-    heap_select::get_heap_range_for_heap (home_heap, &start, &end);
-    const int finish = start + n_heaps;
-    gc_heap* max_hp = nullptr;
-    size_t max_end_of_seg_space = alloc_size; // Must be more than this much, or return NULL
-try_again:
-    {
-        for (int i = start; i < end; i++)
-        {
-            gc_heap* hp = GCHeap::GetHeap (i%n_heaps)->pGenGCHeap;
-            heap_segment* seg = generation_start_segment (hp->generation_of (generation_num));
-            assert (heap_segment_next (seg) == nullptr);
-            const size_t end_of_seg_space = heap_segment_reserved (seg) - heap_segment_allocated (seg);
-            if (end_of_seg_space >= max_end_of_seg_space)
-            {
-                dprintf (3, ("Switching heaps in hard_limit_retry! To: [h%d], New end_of_seg_space: %zd", hp->heap_number, end_of_seg_space));
-                max_end_of_seg_space = end_of_seg_space;
-                max_hp = hp;
-            }
-        }
-    }
-    if ((max_hp == nullptr) && (end < finish))
-    {
-        start = end; end = finish;
-        goto try_again;
-    }
-    return max_hp;
-#endif //USE_REGIONS
-}
-#endif //MULTIPLE_HEAPS
-BOOL gc_heap::allocate_more_space(alloc_context* acontext, size_t size,
-                                   uint32_t flags, int alloc_generation_number)
-{
-    allocation_state status = a_state_start;
-    int retry_count = 0;
-    gc_heap* saved_alloc_heap = 0;
-    do
-    {
-#ifdef MULTIPLE_HEAPS
-        if (alloc_generation_number == 0)
-        {
-            balance_heaps (acontext);
-            status = acontext->get_alloc_heap ()->pGenGCHeap->try_allocate_more_space (acontext, size, flags, alloc_generation_number);
-        }
-        else
-        {
-            uint64_t start_us = GetHighPrecisionTimeStamp ();
-            gc_heap* alloc_heap;
-            if (heap_hard_limit && (status == a_state_retry_allocate))
-            {
-                alloc_heap = balance_heaps_uoh_hard_limit_retry (acontext, size, alloc_generation_number);
-                if (alloc_heap == nullptr || (retry_count++ == UOH_ALLOCATION_RETRY_MAX_COUNT))
-                {
-                    return false;
-                }
-            }
-            else
-            {
-                alloc_heap = balance_heaps_uoh (acontext, size, alloc_generation_number);
-                dprintf (3, ("uoh alloc %Id on h%d", size, alloc_heap->heap_number));
-                saved_alloc_heap = alloc_heap;
-            }
-            bool alloced_on_retry = (status == a_state_retry_allocate);
-            status = alloc_heap->try_allocate_more_space (acontext, size, flags, alloc_generation_number);
-            dprintf (3, ("UOH h%d %Id returned from TAMS, s %d", alloc_heap->heap_number, size, status));
-            uint64_t end_us = GetHighPrecisionTimeStamp ();
-            if (status == a_state_retry_allocate)
-            {
-                dprintf (5555, ("UOH h%d alloc %Id retry!", alloc_heap->heap_number, size));
-            }
-            else
-            {
-                if (alloced_on_retry)
-                {
-                    dprintf (5555, ("UOH h%d allocated %Id on retry (%I64dus)", alloc_heap->heap_number, size, (end_us - start_us)));
-                }
-            }
-        }
-#else
-        status = try_allocate_more_space (acontext, size, flags, alloc_generation_number);
-#endif //MULTIPLE_HEAPS
-    }
-    while (status == a_state_retry_allocate);
-    return (status == a_state_can_allocate);
-}
-inline
-CObjectHeader* gc_heap::allocate (size_t jsize, alloc_context* acontext, uint32_t flags)
-{
-    size_t size = Align (jsize);
-    assert (size >= Align (min_obj_size));
-    {
-    retry:
-        uint8_t*  result = acontext->alloc_ptr;
-        acontext->alloc_ptr+=size;
-        if (acontext->alloc_ptr <= acontext->alloc_limit)
-        {
-            CObjectHeader* obj = (CObjectHeader*)result;
-            assert (obj != 0);
-            return obj;
-        }
-        else
-        {
-            acontext->alloc_ptr -= size;
-#ifdef _MSC_VER
-#pragma inline_depth(0)
-#endif //_MSC_VER
-            if (! allocate_more_space (acontext, size, flags, 0))
-                return 0;
-#ifdef _MSC_VER
-#pragma inline_depth(20)
-#endif //_MSC_VER
-            goto retry;
-        }
-    }
-}
-void  gc_heap::leave_allocation_segment (generation* gen)
-{
-    adjust_limit (0, 0, gen);
-}
-void gc_heap::init_free_and_plug()
-{
-#ifdef FREE_USAGE_STATS
-    int i = (settings.concurrent ? max_generation : 0);
-    for (; i <= settings.condemned_generation; i++)
-    {
-        generation* gen = generation_of (i);
-#ifdef DOUBLY_LINKED_FL
-        print_free_and_plug ("BGC");
-#else
-        memset (gen->gen_free_spaces, 0, sizeof (gen->gen_free_spaces));
-#endif //DOUBLY_LINKED_FL
-        memset (gen->gen_plugs, 0, sizeof (gen->gen_plugs));
-        memset (gen->gen_current_pinned_free_spaces, 0, sizeof (gen->gen_current_pinned_free_spaces));
-    }
-    if (settings.condemned_generation != max_generation)
-    {
-        for (int i = (settings.condemned_generation + 1); i <= max_generation; i++)
-        {
-            generation* gen = generation_of (i);
-            memset (gen->gen_plugs, 0, sizeof (gen->gen_plugs));
-        }
-    }
-#endif //FREE_USAGE_STATS
-}
-void gc_heap::print_free_and_plug (const char* msg)
-{
-#ifdef FREE_USAGE_STATS
-    int older_gen = ((settings.condemned_generation == max_generation) ? max_generation : (settings.condemned_generation + 1));
-    for (int i = 0; i <= older_gen; i++)
-    {
-        generation* gen = generation_of (i);
-        for (int j = 0; j < NUM_GEN_POWER2; j++)
-        {
-            if ((gen->gen_free_spaces[j] != 0) || (gen->gen_plugs[j] != 0))
-            {
-                dprintf (2, ("[%s][h%d][%s#%d]gen%d: 2^%d: F: %zd, P: %zd",
-                    msg,
-                    heap_number,
-                    (settings.concurrent ? "BGC" : "GC"),
-                    settings.gc_index,
-                    i,
-                    (j + 9), gen->gen_free_spaces[j], gen->gen_plugs[j]));
-            }
-        }
-    }
-#else
-    UNREFERENCED_PARAMETER(msg);
-#endif //FREE_USAGE_STATS
-}
-int gc_heap::find_bucket (size_t size)
-{
-    size_t sz = BASE_GEN_SIZE;
-    int i = 0;
-    for (; i < (NUM_GEN_POWER2 - 1); i++)
-    {
-        if (size < sz)
-        {
-            break;
-        }
-        sz = sz * 2;
-    }
-    return i;
-}
-void gc_heap::add_gen_plug (int gen_number, size_t plug_size)
-{
-#ifdef FREE_USAGE_STATS
-    dprintf (3, ("adding plug size %zd to gen%d", plug_size, gen_number));
-    generation* gen = generation_of (gen_number);
-    size_t sz = BASE_GEN_SIZE;
-    int i = find_bucket (plug_size);
-    (gen->gen_plugs[i])++;
-#else
-    UNREFERENCED_PARAMETER(gen_number);
-    UNREFERENCED_PARAMETER(plug_size);
-#endif //FREE_USAGE_STATS
-}
-void gc_heap::add_item_to_current_pinned_free (int gen_number, size_t free_size)
-{
-#ifdef FREE_USAGE_STATS
-    generation* gen = generation_of (gen_number);
-    size_t sz = BASE_GEN_SIZE;
-    int i = find_bucket (free_size);
-    (gen->gen_current_pinned_free_spaces[i])++;
-    generation_pinned_free_obj_space (gen) += free_size;
-    dprintf (3, ("left pin free %zd(2^%d) to gen%d, total %zd bytes (%zd)",
-        free_size, (i + 10), gen_number,
-        generation_pinned_free_obj_space (gen),
-        gen->gen_current_pinned_free_spaces[i]));
-#else
-    UNREFERENCED_PARAMETER(gen_number);
-    UNREFERENCED_PARAMETER(free_size);
-#endif //FREE_USAGE_STATS
-}
-void gc_heap::add_gen_free (int gen_number, size_t free_size)
-{
-#ifdef FREE_USAGE_STATS
-    dprintf (3, ("adding free size %zd to gen%d", free_size, gen_number));
-    if (free_size < min_free_list)
-        return;
-    generation* gen = generation_of (gen_number);
-    size_t sz = BASE_GEN_SIZE;
-    int i = find_bucket (free_size);
-    (gen->gen_free_spaces[i])++;
-    if (gen_number == max_generation)
-    {
-        dprintf (3, ("Mb b%d: f+ %zd (%zd)",
-            i, free_size, gen->gen_free_spaces[i]));
-    }
-#else
-    UNREFERENCED_PARAMETER(gen_number);
-    UNREFERENCED_PARAMETER(free_size);
-#endif //FREE_USAGE_STATS
-}
-void gc_heap::remove_gen_free (int gen_number, size_t free_size)
-{
-#ifdef FREE_USAGE_STATS
-    dprintf (3, ("removing free %zd from gen%d", free_size, gen_number));
-    if (free_size < min_free_list)
-        return;
-    generation* gen = generation_of (gen_number);
-    size_t sz = BASE_GEN_SIZE;
-    int i = find_bucket (free_size);
-    (gen->gen_free_spaces[i])--;
-    if (gen_number == max_generation)
-    {
-        dprintf (3, ("Mb b%d: f- %zd (%zd)",
-            i, free_size, gen->gen_free_spaces[i]));
-    }
-#else
-    UNREFERENCED_PARAMETER(gen_number);
-    UNREFERENCED_PARAMETER(free_size);
-#endif //FREE_USAGE_STATS
-}
-#ifdef DOUBLY_LINKED_FL
-BOOL gc_heap::should_set_bgc_mark_bit (uint8_t* o)
-{
-    if (!current_sweep_seg)
-    {
-        assert (current_bgc_state == bgc_not_in_process);
-        return FALSE;
-    }
-    if (in_range_for_segment (o, current_sweep_seg))
-    {
-        if ((o >= current_sweep_pos) && (o < heap_segment_background_allocated (current_sweep_seg)))
-        {
-#ifndef USE_REGIONS
-            if (current_sweep_seg == saved_sweep_ephemeral_seg)
-            {
-                return (o < saved_sweep_ephemeral_start);
-            }
-            else
-#endif //!USE_REGIONS
-            {
-                return TRUE;
-            }
-        }
-        else
-            return FALSE;
-    }
-    else
-    {
-        if ((o >= background_saved_lowest_address) && (o < background_saved_highest_address))
-        {
-            heap_segment* seg = seg_mapping_table_segment_of (o);
-            uint8_t* background_allocated = heap_segment_background_allocated (seg);
-            if (background_allocated == 0)
-                return FALSE;
-            else if (o >= background_allocated)
-                return FALSE;
-            else
-                return (!heap_segment_swept_p (seg));
-        }
-        else
-            return FALSE;
-    }
-}
-#endif //DOUBLY_LINKED_FL
-uint8_t* gc_heap::allocate_in_older_generation (generation* gen, size_t size,
-                                                int from_gen_number,
-                                                uint8_t* old_loc REQD_ALIGN_AND_OFFSET_DCL)
-{
-    size = Align (size);
-    assert (size >= Align (min_obj_size));
-    assert (from_gen_number < max_generation);
-    assert (from_gen_number >= 0);
-    assert (generation_of (from_gen_number + 1) == gen);
-#ifdef DOUBLY_LINKED_FL
-    BOOL consider_bgc_mark_p        = FALSE;
-    BOOL check_current_sweep_p      = FALSE;
-    BOOL check_saved_sweep_p        = FALSE;
-    BOOL try_added_list_p       = (gen->gen_num == max_generation);
-    BOOL record_free_list_allocated_p = ((gen->gen_num == max_generation) &&
-                                         (current_c_gc_state == c_gc_state_planning));
-#endif //DOUBLY_LINKED_FL
-    allocator* gen_allocator = generation_allocator (gen);
-    BOOL discard_p = gen_allocator->discard_if_no_fit_p ();
-#ifdef SHORT_PLUGS
-    int pad_in_front = ((old_loc != 0) && ((from_gen_number+1) != max_generation)) ? USE_PADDING_FRONT : 0;
-#else //SHORT_PLUGS
-    int pad_in_front = 0;
-#endif //SHORT_PLUGS
-    size_t real_size = size + Align (min_obj_size);
-    if (pad_in_front)
-        real_size += Align (min_obj_size);
-#ifdef RESPECT_LARGE_ALIGNMENT
-    real_size += switch_alignment_size (pad_in_front);
-#endif //RESPECT_LARGE_ALIGNMENT
-    if (! (size_fit_p (size REQD_ALIGN_AND_OFFSET_ARG, generation_allocation_pointer (gen),
-                       generation_allocation_limit (gen), old_loc, USE_PADDING_TAIL | pad_in_front)))
-    {
-        for (unsigned int a_l_idx = gen_allocator->first_suitable_bucket(real_size * 2);
-             a_l_idx < gen_allocator->number_of_buckets(); a_l_idx++)
-        {
-            uint8_t* free_list = 0;
-            uint8_t* prev_free_item = 0;
-            BOOL use_undo_p = !discard_p;
-#ifdef DOUBLY_LINKED_FL
-            if (a_l_idx == 0)
-            {
-                use_undo_p = FALSE;
-            }
-            if (try_added_list_p)
-            {
-                free_list = gen_allocator->added_alloc_list_head_of (a_l_idx);
-                while (free_list != 0)
-                {
-                    dprintf (3, ("considering free list in added list%zx", (size_t)free_list));
-                    size_t free_list_size = unused_array_size (free_list);
-                    if (size_fit_p (size REQD_ALIGN_AND_OFFSET_ARG, free_list, (free_list + free_list_size),
-                                    old_loc, USE_PADDING_TAIL | pad_in_front))
-                    {
-                        dprintf (4, ("F:%zx-%zd",
-                                    (size_t)free_list, free_list_size));
-                        gen_allocator->unlink_item_no_undo_added (a_l_idx, free_list, prev_free_item);
-                        generation_free_list_space (gen) -= free_list_size;
-                        assert ((ptrdiff_t)generation_free_list_space (gen) >= 0);
-                        remove_gen_free (gen->gen_num, free_list_size);
-                        if (record_free_list_allocated_p)
-                        {
-                            generation_set_bgc_mark_bit_p (gen) = should_set_bgc_mark_bit (free_list);
-                            dprintf (3333, ("SFA: %p->%p(%d)", free_list, (free_list + free_list_size),
-                                (generation_set_bgc_mark_bit_p (gen) ? 1 : 0)));
-                        }
-                        adjust_limit (free_list, free_list_size, gen);
-                        generation_allocate_end_seg_p (gen) = FALSE;
-                        goto finished;
-                    }
-                    else if (a_l_idx == 0)
-                    {
-                        dprintf (3, ("couldn't use this free area, discarding"));
-                        generation_free_obj_space (gen) += free_list_size;
-                        gen_allocator->unlink_item_no_undo_added (a_l_idx, free_list, prev_free_item);
-                        generation_free_list_space (gen) -= free_list_size;
-                        assert ((ptrdiff_t)generation_free_list_space (gen) >= 0);
-                        remove_gen_free (gen->gen_num, free_list_size);
-                    }
-                    else
-                    {
-                        prev_free_item = free_list;
-                    }
-                    free_list = free_list_slot (free_list);
-                }
-            }
-#endif //DOUBLY_LINKED_FL
-            free_list = gen_allocator->alloc_list_head_of (a_l_idx);
-            prev_free_item = 0;
-            while (free_list != 0)
-            {
-                dprintf (3, ("considering free list %zx", (size_t)free_list));
-                size_t free_list_size = unused_array_size (free_list);
-                if (size_fit_p (size REQD_ALIGN_AND_OFFSET_ARG, free_list, (free_list + free_list_size),
-                                old_loc, USE_PADDING_TAIL | pad_in_front))
-                {
-                    dprintf (4, ("F:%zx-%zd",
-                                    (size_t)free_list, free_list_size));
-                    gen_allocator->unlink_item (a_l_idx, free_list, prev_free_item, use_undo_p);
-                    generation_free_list_space (gen) -= free_list_size;
-                    assert ((ptrdiff_t)generation_free_list_space (gen) >= 0);
-                    remove_gen_free (gen->gen_num, free_list_size);
-#ifdef DOUBLY_LINKED_FL
-                    if (!discard_p && !use_undo_p)
-                    {
-                        gen2_removed_no_undo += free_list_size;
-                        dprintf (3, ("h%d: remove with no undo %zd = %zd",
-                            heap_number, free_list_size, gen2_removed_no_undo));
-                    }
-                    if (record_free_list_allocated_p)
-                    {
-                        generation_set_bgc_mark_bit_p (gen) = should_set_bgc_mark_bit (free_list);
-                        dprintf (3333, ("SF: %p(%d)", free_list, (generation_set_bgc_mark_bit_p (gen) ? 1 : 0)));
-                    }
-#endif //DOUBLY_LINKED_FL
-                    adjust_limit (free_list, free_list_size, gen);
-                    generation_allocate_end_seg_p (gen) = FALSE;
-                    goto finished;
-                }
-                else if (discard_p || (a_l_idx == 0))
-                {
-                    dprintf (3, ("couldn't use this free area, discarding"));
-                    generation_free_obj_space (gen) += free_list_size;
-                    gen_allocator->unlink_item (a_l_idx, free_list, prev_free_item, FALSE);
-                    generation_free_list_space (gen) -= free_list_size;
-                    assert ((ptrdiff_t)generation_free_list_space (gen) >= 0);
-                    remove_gen_free (gen->gen_num, free_list_size);
-#ifdef DOUBLY_LINKED_FL
-                    if (!discard_p)
-                    {
-                        gen2_removed_no_undo += free_list_size;
-                        dprintf (3, ("h%d: b0 remove with no undo %zd = %zd",
-                            heap_number, free_list_size, gen2_removed_no_undo));
-                    }
-#endif //DOUBLY_LINKED_FL
-                }
-                else
-                {
-                    prev_free_item = free_list;
-                }
-                free_list = free_list_slot (free_list);
-            }
-        }
-#ifdef USE_REGIONS
-        heap_segment* seg = generation_allocation_segment (gen);
-        dprintf (3, ("end of seg, starting from alloc seg %p", heap_segment_mem (seg)));
-        assert (seg != ephemeral_heap_segment);
-        while (true)
-#else
-        heap_segment* seg = heap_segment_rw (generation_start_segment (gen));
-        if (seg != generation_allocation_segment (gen))
-        {
-            leave_allocation_segment (gen);
-            generation_allocation_segment (gen) = seg;
-        }
-        while (seg != ephemeral_heap_segment)
-#endif //USE_REGIONS
-        {
-            if (size_fit_p(size REQD_ALIGN_AND_OFFSET_ARG, heap_segment_plan_allocated (seg),
-                           heap_segment_committed (seg), old_loc, USE_PADDING_TAIL | pad_in_front))
-            {
-                adjust_limit (heap_segment_plan_allocated (seg),
-                              (heap_segment_committed (seg) - heap_segment_plan_allocated (seg)),
-                              gen);
-                generation_allocate_end_seg_p (gen) = TRUE;
-                heap_segment_plan_allocated (seg) =
-                    heap_segment_committed (seg);
-                dprintf (3, ("seg %p is used for end of seg alloc", heap_segment_mem (seg)));
-                goto finished;
-            }
-            else
-            {
-                if (size_fit_p (size REQD_ALIGN_AND_OFFSET_ARG, heap_segment_plan_allocated (seg),
-                                heap_segment_reserved (seg), old_loc, USE_PADDING_TAIL | pad_in_front) &&
-                    grow_heap_segment (seg, heap_segment_plan_allocated (seg), old_loc, size, pad_in_front REQD_ALIGN_AND_OFFSET_ARG))
-                {
-                    adjust_limit (heap_segment_plan_allocated (seg),
-                                  (heap_segment_committed (seg) - heap_segment_plan_allocated (seg)),
-                                  gen);
-                    generation_allocate_end_seg_p (gen) = TRUE;
-                    heap_segment_plan_allocated (seg) =
-                        heap_segment_committed (seg);
-                    dprintf (3, ("seg %p is used for end of seg alloc after grow, %p",
-                        heap_segment_mem (seg), heap_segment_committed (seg)));
-                    goto finished;
-                }
-                else
-                {
-                    leave_allocation_segment (gen);
-                    heap_segment*   next_seg = heap_segment_next_rw (seg);
-#ifdef USE_REGIONS
-                    assert (next_seg != ephemeral_heap_segment);
-#endif //USE_REGIONS
-                    if (next_seg)
-                    {
-                        generation_allocation_segment (gen) = next_seg;
-                        generation_allocation_pointer (gen) = heap_segment_mem (next_seg);
-                        generation_allocation_limit (gen) = generation_allocation_pointer (gen);
-                        dprintf (3, ("alloc region advanced to %p", heap_segment_mem (next_seg)));
-                    }
-                    else
-                    {
-                        size = 0;
-                        goto finished;
-                    }
-                }
-            }
-            seg = generation_allocation_segment (gen);
-        }
-        size = 0;
-        goto finished;
-    }
-finished:
-    if (0 == size)
-    {
-        return 0;
-    }
-    else
-    {
-        uint8_t*  result = generation_allocation_pointer (gen);
-        size_t pad = 0;
-#ifdef SHORT_PLUGS
-        if ((pad_in_front & USE_PADDING_FRONT) &&
-            (((generation_allocation_pointer (gen) - generation_allocation_context_start_region (gen))==0) ||
-             ((generation_allocation_pointer (gen) - generation_allocation_context_start_region (gen))>=DESIRED_PLUG_LENGTH)))
-        {
-            pad = Align (min_obj_size);
-            set_plug_padded (old_loc);
-        }
-#endif //SHORT_PLUGS
-#ifdef FEATURE_STRUCTALIGN
-        _ASSERTE(!old_loc || alignmentOffset != 0);
-        _ASSERTE(old_loc || requiredAlignment == DATA_ALIGNMENT);
-        if (old_loc != 0)
-        {
-            size_t pad1 = ComputeStructAlignPad(result+pad, requiredAlignment, alignmentOffset);
-            set_node_aligninfo (old_loc, requiredAlignment, pad1);
-            pad += pad1;
-        }
-#else // FEATURE_STRUCTALIGN
-        if (!((old_loc == 0) || same_large_alignment_p (old_loc, result+pad)))
-        {
-            pad += switch_alignment_size (pad != 0);
-            set_node_realigned (old_loc);
-            dprintf (3, ("Allocation realignment old_loc: %zx, new_loc:%zx",
-                         (size_t)old_loc, (size_t)(result+pad)));
-            assert (same_large_alignment_p (result + pad, old_loc));
-        }
-#endif // FEATURE_STRUCTALIGN
-        dprintf (3, ("Allocate %zd bytes", size));
-        if ((old_loc == 0) || (pad != 0))
-        {
-            generation_allocation_context_start_region (gen) = generation_allocation_pointer (gen);
-        }
-        generation_allocation_pointer (gen) += size + pad;
-        assert (generation_allocation_pointer (gen) <= generation_allocation_limit (gen));
-        generation_free_obj_space (gen) += pad;
-        if (generation_allocate_end_seg_p (gen))
-        {
-            generation_end_seg_allocated (gen) += size;
-        }
-        else
-        {
-#ifdef DOUBLY_LINKED_FL
-            if (generation_set_bgc_mark_bit_p (gen))
-            {
-                dprintf (2, ("IOM: %p(->%p(%zd) (%zx-%zx)", old_loc, result, pad,
-                        (size_t)(&mark_array [mark_word_of (result)]),
-                        (size_t)(mark_array [mark_word_of (result)])));
-                set_plug_bgc_mark_bit (old_loc);
-            }
-            generation_last_free_list_allocated (gen) = old_loc;
-#endif //DOUBLY_LINKED_FL
-            generation_free_list_allocated (gen) += size;
-        }
-        generation_allocation_size (gen) += size;
-        dprintf (3, ("aio: ptr: %p, limit: %p, sr: %p",
-            generation_allocation_pointer (gen), generation_allocation_limit (gen),
-            generation_allocation_context_start_region (gen)));
-        return (result + pad);
-    }
-}
-#ifndef USE_REGIONS
-void gc_heap::repair_allocation_in_expanded_heap (generation* consing_gen)
-{
-    int  gen_number = max_generation - 1;
-    while (gen_number>= 0)
-    {
-        generation* gen = generation_of (gen_number);
-        if (0 == generation_plan_allocation_start (gen))
-        {
-            realloc_plan_generation_start (gen, consing_gen);
-            assert (generation_plan_allocation_start (gen));
-        }
-        gen_number--;
-    }
-    size_t  size = (generation_allocation_limit (consing_gen) - generation_allocation_pointer (consing_gen));
-    heap_segment* seg = generation_allocation_segment (consing_gen);
-    if (generation_allocation_limit (consing_gen) == heap_segment_plan_allocated (seg))
-    {
-        if (size != 0)
-        {
-            heap_segment_plan_allocated (seg) = generation_allocation_pointer (consing_gen);
-        }
-    }
-    else
-    {
-        assert (settings.condemned_generation == max_generation);
-        uint8_t* first_address = generation_allocation_limit (consing_gen);
-        size_t mi = 0;
-        mark* m = 0;
-        while (mi != mark_stack_tos)
-        {
-            m = pinned_plug_of (mi);
-            if ((pinned_plug (m) == first_address))
-                break;
-            else
-                mi++;
-        }
-        assert (mi != mark_stack_tos);
-        pinned_len (m) = size;
-    }
-}
-uint8_t* gc_heap::allocate_in_expanded_heap (generation* gen,
-                                          size_t size,
-                                          BOOL& adjacentp,
-                                          uint8_t* old_loc,
-#ifdef SHORT_PLUGS
-                                          BOOL set_padding_on_saved_p,
-                                          mark* pinned_plug_entry,
-#endif //SHORT_PLUGS
-                                          BOOL consider_bestfit,
-                                          int active_new_gen_number
-                                          REQD_ALIGN_AND_OFFSET_DCL)
-{
-    dprintf (3, ("aie: P: %p, size: %zx", old_loc, size));
-    size = Align (size);
-    assert (size >= Align (min_obj_size));
-#ifdef SHORT_PLUGS
-    int pad_in_front = ((old_loc != 0) && (active_new_gen_number != max_generation)) ? USE_PADDING_FRONT : 0;
-#else //SHORT_PLUGS
-    int pad_in_front = 0;
-#endif //SHORT_PLUGS
-    if (consider_bestfit && use_bestfit)
-    {
-        assert (bestfit_seg);
-        dprintf (SEG_REUSE_LOG_1, ("reallocating 0x%p in expanded heap, size: %zd",
-                    old_loc, size));
-        return bestfit_seg->fit (old_loc,
-                                 size REQD_ALIGN_AND_OFFSET_ARG);
-    }
-    heap_segment* seg = generation_allocation_segment (gen);
-    if (! (size_fit_p (size REQD_ALIGN_AND_OFFSET_ARG, generation_allocation_pointer (gen),
-                       generation_allocation_limit (gen), old_loc,
-                       ((generation_allocation_limit (gen) !=
-                          heap_segment_plan_allocated (seg))? USE_PADDING_TAIL : 0) | pad_in_front)))
-    {
-        dprintf (3, ("aie: can't fit: ptr: %p, limit: %p", generation_allocation_pointer (gen),
-            generation_allocation_limit (gen)));
-        adjacentp = FALSE;
-        uint8_t* first_address = (generation_allocation_limit (gen) ?
-                               generation_allocation_limit (gen) :
-                               heap_segment_mem (seg));
-        assert (in_range_for_segment (first_address, seg));
-        uint8_t* end_address   = heap_segment_reserved (seg);
-        dprintf (3, ("aie: first_addr: %p, gen alloc limit: %p, end_address: %p",
-            first_address, generation_allocation_limit (gen), end_address));
-        size_t mi = 0;
-        mark* m = 0;
-        if (heap_segment_allocated (seg) != heap_segment_mem (seg))
-        {
-            assert (settings.condemned_generation == max_generation);
-            while (mi != mark_stack_tos)
-            {
-                m = pinned_plug_of (mi);
-                if ((pinned_plug (m) >= first_address) && (pinned_plug (m) < end_address))
-                {
-                    dprintf (3, ("aie: found pin: %p", pinned_plug (m)));
-                    break;
-                }
-                else
-                    mi++;
-            }
-            if (mi != mark_stack_tos)
-            {
-                size_t  hsize = (generation_allocation_limit (gen) - generation_allocation_pointer (gen));
-                {
-                    dprintf(3,("gc filling up hole"));
-                    ptrdiff_t mi1 = (ptrdiff_t)mi;
-                    while ((mi1 >= 0) &&
-                           (pinned_plug (pinned_plug_of(mi1)) != generation_allocation_limit (gen)))
-                    {
-                        dprintf (3, ("aie: checking pin %p", pinned_plug (pinned_plug_of(mi1))));
-                        mi1--;
-                    }
-                    if (mi1 >= 0)
-                    {
-                        size_t saved_pinned_len = pinned_len (pinned_plug_of(mi1));
-                        pinned_len (pinned_plug_of(mi1)) = hsize;
-                        dprintf (3, ("changing %p len %zx->%zx",
-                            pinned_plug (pinned_plug_of(mi1)),
-                            saved_pinned_len, pinned_len (pinned_plug_of(mi1))));
-                    }
-                }
-            }
-        }
-        else
-        {
-            assert (generation_allocation_limit (gen) ==
-                    generation_allocation_pointer (gen));
-            mi = mark_stack_tos;
-        }
-        while ((mi != mark_stack_tos) && in_range_for_segment (pinned_plug (m), seg))
-        {
-            size_t len = pinned_len (m);
-            uint8_t*  free_list = (pinned_plug (m) - len);
-            dprintf (3, ("aie: testing free item: %p->%p(%zx)",
-                free_list, (free_list + len), len));
-            if (size_fit_p (size REQD_ALIGN_AND_OFFSET_ARG, free_list, (free_list + len), old_loc, USE_PADDING_TAIL | pad_in_front))
-            {
-                dprintf (3, ("aie: Found adequate unused area: %zx, size: %zd",
-                            (size_t)free_list, len));
-                {
-                    generation_allocation_pointer (gen) = free_list;
-                    generation_allocation_context_start_region (gen) = generation_allocation_pointer (gen);
-                    generation_allocation_limit (gen) = (free_list + len);
-                }
-                goto allocate_in_free;
-            }
-            mi++;
-            m = pinned_plug_of (mi);
-        }
-        generation_allocation_pointer (gen) = heap_segment_plan_allocated (seg);
-        generation_allocation_context_start_region (gen) = generation_allocation_pointer (gen);
-        heap_segment_plan_allocated (seg) = heap_segment_committed (seg);
-        generation_allocation_limit (gen) = heap_segment_plan_allocated (seg);
-        dprintf (3, ("aie: switching to end of seg: %p->%p(%zx)",
-            generation_allocation_pointer (gen), generation_allocation_limit (gen),
-            (generation_allocation_limit (gen) - generation_allocation_pointer (gen))));
-        if (!size_fit_p (size REQD_ALIGN_AND_OFFSET_ARG, generation_allocation_pointer (gen),
-                         generation_allocation_limit (gen), old_loc, USE_PADDING_TAIL | pad_in_front))
-        {
-            dprintf (3, ("aie: ptr: %p, limit: %p, can't alloc", generation_allocation_pointer (gen),
-                generation_allocation_limit (gen)));
-            assert (!"Can't allocate if no free space");
-            return 0;
-        }
-    }
-    else
-    {
-        adjacentp = TRUE;
-    }
-allocate_in_free:
-    {
-        uint8_t*  result = generation_allocation_pointer (gen);
-        size_t pad = 0;
-#ifdef SHORT_PLUGS
-        if ((pad_in_front & USE_PADDING_FRONT) &&
-            (((generation_allocation_pointer (gen) - generation_allocation_context_start_region (gen))==0) ||
-             ((generation_allocation_pointer (gen) - generation_allocation_context_start_region (gen))>=DESIRED_PLUG_LENGTH)))
-        {
-            pad = Align (min_obj_size);
-            set_padding_in_expand (old_loc, set_padding_on_saved_p, pinned_plug_entry);
-        }
-#endif //SHORT_PLUGS
-#ifdef FEATURE_STRUCTALIGN
-        _ASSERTE(!old_loc || alignmentOffset != 0);
-        _ASSERTE(old_loc || requiredAlignment == DATA_ALIGNMENT);
-        if (old_loc != 0)
-        {
-            size_t pad1 = ComputeStructAlignPad(result+pad, requiredAlignment, alignmentOffset);
-            set_node_aligninfo (old_loc, requiredAlignment, pad1);
-            pad += pad1;
-            adjacentp = FALSE;
-        }
-#else // FEATURE_STRUCTALIGN
-        if (!((old_loc == 0) || same_large_alignment_p (old_loc, result+pad)))
-        {
-            pad += switch_alignment_size (pad != 0);
-            set_node_realigned (old_loc);
-            dprintf (3, ("Allocation realignment old_loc: %zx, new_loc:%zx",
-                         (size_t)old_loc, (size_t)(result+pad)));
-            assert (same_large_alignment_p (result + pad, old_loc));
-            adjacentp = FALSE;
-        }
-#endif // FEATURE_STRUCTALIGN
-        if ((old_loc == 0) || (pad != 0))
-        {
-            generation_allocation_context_start_region (gen) = generation_allocation_pointer (gen);
-        }
-        generation_allocation_pointer (gen) += size + pad;
-        assert (generation_allocation_pointer (gen) <= generation_allocation_limit (gen));
-        dprintf (3, ("Allocated in expanded heap %zx:%zd", (size_t)(result+pad), size));
-        dprintf (3, ("aie: ptr: %p, limit: %p, sr: %p",
-            generation_allocation_pointer (gen), generation_allocation_limit (gen),
-            generation_allocation_context_start_region (gen)));
-        return result + pad;
-    }
-}
-generation*  gc_heap::ensure_ephemeral_heap_segment (generation* consing_gen)
-{
-    heap_segment* seg = generation_allocation_segment (consing_gen);
-    if (seg != ephemeral_heap_segment)
-    {
-        assert (generation_allocation_pointer (consing_gen)>= heap_segment_mem (seg));
-        assert (generation_allocation_pointer (consing_gen)<= heap_segment_committed (seg));
-        heap_segment_plan_allocated (seg) = generation_allocation_pointer (consing_gen);
-        generation* new_consing_gen = generation_of (max_generation - 1);
-        generation_allocation_pointer (new_consing_gen) =
-                heap_segment_mem (ephemeral_heap_segment);
-        generation_allocation_limit (new_consing_gen) =
-            generation_allocation_pointer (new_consing_gen);
-        generation_allocation_context_start_region (new_consing_gen) =
-            generation_allocation_pointer (new_consing_gen);
-        generation_allocation_segment (new_consing_gen) = ephemeral_heap_segment;
-        return new_consing_gen;
-    }
-    else
-        return consing_gen;
-}
-#endif //!USE_REGIONS
-inline
-void gc_heap::init_alloc_info (generation* gen, heap_segment* seg)
-{
-    generation_allocation_segment (gen) = seg;
-    generation_allocation_pointer (gen) = heap_segment_mem (seg);
-    generation_allocation_limit (gen) = generation_allocation_pointer (gen);
-    generation_allocation_context_start_region (gen) = generation_allocation_pointer (gen);
-}
-inline
-heap_segment* gc_heap::get_next_alloc_seg (generation* gen)
-{
-#ifdef USE_REGIONS
-    heap_segment* saved_region = generation_allocation_segment (gen);
-    int gen_num = heap_segment_gen_num (saved_region);
-    heap_segment* region = saved_region;
-    while (1)
-    {
-        region = heap_segment_non_sip (region);
-        if (region)
-        {
-            break;
-        }
-        else
-        {
-            if (gen_num > 0)
-            {
-                gen_num--;
-                region = generation_start_segment (generation_of (gen_num));
-                dprintf (REGIONS_LOG, ("h%d next alloc region: switching to next gen%d start %zx(%p)",
-                    heap_number, heap_segment_gen_num (region), (size_t)region,
-                    heap_segment_mem (region)));
-            }
-            else
-            {
-                assert (!"ran out regions when getting the next alloc seg!");
-            }
-        }
-    }
-    if (region != saved_region)
-    {
-        dprintf (REGIONS_LOG, ("init allocate region for gen%d to %p(%d)",
-            gen->gen_num, heap_segment_mem (region), heap_segment_gen_num (region)));
-        init_alloc_info (gen, region);
-    }
-    return region;
-#else
-    return generation_allocation_segment (gen);
-#endif //USE_REGIONS
-}
-uint8_t* gc_heap::allocate_in_condemned_generations (generation* gen,
-                                                  size_t size,
-                                                  int from_gen_number,
-#ifdef SHORT_PLUGS
-                                                  BOOL* convert_to_pinned_p,
-                                                  uint8_t* next_pinned_plug,
-                                                  heap_segment* current_seg,
-#endif //SHORT_PLUGS
-                                                  uint8_t* old_loc
-                                                  REQD_ALIGN_AND_OFFSET_DCL)
-{
-#ifndef USE_REGIONS
-    if (settings.promotion)
-    {
-        assert (generation_plan_allocation_start (youngest_generation) == 0);
-    }
-#endif //!USE_REGIONS
-    size = Align (size);
-    assert (size >= Align (min_obj_size));
-    int to_gen_number = from_gen_number;
-    if (from_gen_number != (int)max_generation)
-    {
-        to_gen_number = from_gen_number + (settings.promotion ? 1 : 0);
-    }
-    dprintf (3, ("aic gen%d: s: %zd, ac: %p-%p", gen->gen_num, size,
-            generation_allocation_pointer (gen), generation_allocation_limit (gen)));
-#ifdef SHORT_PLUGS
-    int pad_in_front = ((old_loc != 0) && (to_gen_number != max_generation)) ? USE_PADDING_FRONT : 0;
-#else //SHORT_PLUGS
-    int pad_in_front = 0;
-#endif //SHORT_PLUGS
-    if ((from_gen_number != -1) && (from_gen_number != (int)max_generation) && settings.promotion)
-    {
-        generation_condemned_allocated (generation_of (from_gen_number + (settings.promotion ? 1 : 0))) += size;
-        generation_allocation_size (generation_of (from_gen_number + (settings.promotion ? 1 : 0))) += size;
-    }
-retry:
-    {
-        heap_segment* seg = get_next_alloc_seg (gen);
-        if (! (size_fit_p (size REQD_ALIGN_AND_OFFSET_ARG, generation_allocation_pointer (gen),
-                           generation_allocation_limit (gen), old_loc,
-                           ((generation_allocation_limit (gen) != heap_segment_plan_allocated (seg))?USE_PADDING_TAIL:0)|pad_in_front)))
-        {
-            if ((! (pinned_plug_que_empty_p()) &&
-                 (generation_allocation_limit (gen) ==
-                  pinned_plug (oldest_pin()))))
-            {
-                size_t entry = deque_pinned_plug();
-                mark* pinned_plug_entry = pinned_plug_of (entry);
-                size_t len = pinned_len (pinned_plug_entry);
-                uint8_t* plug = pinned_plug (pinned_plug_entry);
-                set_new_pin_info (pinned_plug_entry, generation_allocation_pointer (gen));
-#ifdef USE_REGIONS
-                if (to_gen_number == 0)
-                {
-                    update_planned_gen0_free_space (pinned_len (pinned_plug_entry), plug);
-                    dprintf (REGIONS_LOG, ("aic: not promotion, gen0 added free space %zd at %p",
-                                    pinned_len (pinned_plug_entry), plug));
-                }
-#endif //USE_REGIONS
-#ifdef FREE_USAGE_STATS
-                generation_allocated_in_pinned_free (gen) += generation_allocated_since_last_pin (gen);
-                dprintf (3, ("allocated %zd so far within pin %zx, total->%zd",
-                    generation_allocated_since_last_pin (gen),
-                    plug,
-                    generation_allocated_in_pinned_free (gen)));
-                generation_allocated_since_last_pin (gen) = 0;
-                add_item_to_current_pinned_free (gen->gen_num, pinned_len (pinned_plug_of (entry)));
-#endif //FREE_USAGE_STATS
-                dprintf (3, ("mark stack bos: %zd, tos: %zd, aic: p %p len: %zx->%zx",
-                    mark_stack_bos, mark_stack_tos, plug, len, pinned_len (pinned_plug_of (entry))));
-                assert(mark_stack_array[entry].len == 0 ||
-                       mark_stack_array[entry].len >= Align(min_obj_size));
-                generation_allocation_pointer (gen) = plug + len;
-                generation_allocation_context_start_region (gen) = generation_allocation_pointer (gen);
-                generation_allocation_limit (gen) = heap_segment_plan_allocated (seg);
-                set_allocator_next_pin (gen);
-                int frgn = object_gennum (plug);
-                if ((frgn != (int)max_generation) && settings.promotion)
-                {
-                    generation_pinned_allocation_sweep_size (generation_of (frgn + 1)) += len;
-#ifdef USE_REGIONS
-                    int togn = (in_range_for_segment (plug, seg) ? to_gen_number : object_gennum_plan (plug));
-#else
-                    int togn = object_gennum_plan (plug);
-#endif //USE_REGIONS
-                    if (frgn < togn)
-                    {
-                        generation_pinned_allocation_compact_size (generation_of (togn)) += len;
-                    }
-                }
-                goto retry;
-            }
-            if (generation_allocation_limit (gen) != heap_segment_plan_allocated (seg))
-            {
-                generation_allocation_limit (gen) = heap_segment_plan_allocated (seg);
-                dprintf (3, ("changed limit to plan alloc: %p", generation_allocation_limit (gen)));
-            }
-            else
-            {
-                if (heap_segment_plan_allocated (seg) != heap_segment_committed (seg))
-                {
-                    heap_segment_plan_allocated (seg) = heap_segment_committed (seg);
-                    generation_allocation_limit (gen) = heap_segment_plan_allocated (seg);
-                    dprintf (3, ("changed limit to commit: %p", generation_allocation_limit (gen)));
-                }
-                else
-                {
-#if !defined(RESPECT_LARGE_ALIGNMENT) && !defined(USE_REGIONS)
-                    assert (gen != youngest_generation);
-#endif //!RESPECT_LARGE_ALIGNMENT && !USE_REGIONS
-                    if (size_fit_p (size REQD_ALIGN_AND_OFFSET_ARG, generation_allocation_pointer (gen),
-                                    heap_segment_reserved (seg), old_loc, USE_PADDING_TAIL | pad_in_front) &&
-                        (grow_heap_segment (seg, generation_allocation_pointer (gen), old_loc,
-                                            size, pad_in_front REQD_ALIGN_AND_OFFSET_ARG)))
-                    {
-                        dprintf (3, ("Expanded segment allocation by committing more memory"));
-                        heap_segment_plan_allocated (seg) = heap_segment_committed (seg);
-                        generation_allocation_limit (gen) = heap_segment_plan_allocated (seg);
-                    }
-                    else
-                    {
-                        heap_segment*   next_seg = heap_segment_next (seg);
-                        dprintf (REGIONS_LOG, ("aic next: %p(%p,%p) -> %p(%p,%p)",
-                            heap_segment_mem (seg), heap_segment_allocated (seg), heap_segment_plan_allocated (seg),
-                            (next_seg ? heap_segment_mem (next_seg) : 0),
-                            (next_seg ? heap_segment_allocated (next_seg) : 0),
-                            (next_seg ? heap_segment_plan_allocated (next_seg) : 0)));
-                        assert (generation_allocation_pointer (gen)>=
-                                heap_segment_mem (seg));
-                        if (!pinned_plug_que_empty_p() &&
-                            ((pinned_plug (oldest_pin()) < heap_segment_allocated (seg)) &&
-                             (pinned_plug (oldest_pin()) >= generation_allocation_pointer (gen))))
-                        {
-                            LOG((LF_GC, LL_INFO10, "remaining pinned plug %zx while leaving segment on allocation",
-                                         pinned_plug (oldest_pin())));
-                            FATAL_GC_ERROR();
-                        }
-                        assert (generation_allocation_pointer (gen)>=
-                                heap_segment_mem (seg));
-                        assert (generation_allocation_pointer (gen)<=
-                                heap_segment_committed (seg));
-                        heap_segment_plan_allocated (seg) = generation_allocation_pointer (gen);
-#ifdef USE_REGIONS
-                        set_region_plan_gen_num (seg, to_gen_number);
-                        if ((next_seg == 0) && (heap_segment_gen_num (seg) > 0))
-                        {
-                            next_seg = generation_start_segment (generation_of (heap_segment_gen_num (seg) - 1));
-                            dprintf (REGIONS_LOG, ("h%d aic: switching to next gen%d start %zx(%p)",
-                                heap_number, heap_segment_gen_num (next_seg), (size_t)next_seg,
-                                heap_segment_mem (next_seg)));
-                        }
-#endif //USE_REGIONS
-                        if (next_seg)
-                        {
-                            init_alloc_info (gen, next_seg);
-                        }
-                        else
-                        {
-#ifdef USE_REGIONS
-                            assert (!"should not happen for regions!");
-#else
-                            return 0; //should only happen during allocation of generation 0 gap
-#endif //USE_REGIONS
-                        }
-                    }
-                }
-            }
-            set_allocator_next_pin (gen);
-            goto retry;
-        }
-    }
-    {
-        assert (generation_allocation_pointer (gen)>=
-                heap_segment_mem (generation_allocation_segment (gen)));
-        uint8_t* result = generation_allocation_pointer (gen);
-        size_t pad = 0;
-#ifdef SHORT_PLUGS
-        if ((pad_in_front & USE_PADDING_FRONT) &&
-            (((generation_allocation_pointer (gen) - generation_allocation_context_start_region (gen))==0) ||
-             ((generation_allocation_pointer (gen) - generation_allocation_context_start_region (gen))>=DESIRED_PLUG_LENGTH)))
-        {
-            ptrdiff_t dist = old_loc - result;
-            if (dist == 0)
-            {
-                dprintf (3, ("old alloc: %p, same as new alloc, not padding", old_loc));
-                pad = 0;
-            }
-            else
-            {
-                if ((dist > 0) && (dist < (ptrdiff_t)Align (min_obj_size)))
-                {
-                    dprintf (1, ("old alloc: %p, only %zd bytes > new alloc! Shouldn't happen", old_loc, dist));
-                    FATAL_GC_ERROR();
-                }
-                pad = Align (min_obj_size);
-                set_plug_padded (old_loc);
-            }
-        }
-#endif //SHORT_PLUGS
-#ifdef FEATURE_STRUCTALIGN
-        _ASSERTE(!old_loc || alignmentOffset != 0);
-        _ASSERTE(old_loc || requiredAlignment == DATA_ALIGNMENT);
-        if ((old_loc != 0))
-        {
-            size_t pad1 = ComputeStructAlignPad(result+pad, requiredAlignment, alignmentOffset);
-            set_node_aligninfo (old_loc, requiredAlignment, pad1);
-            pad += pad1;
-        }
-#else // FEATURE_STRUCTALIGN
-        if (!((old_loc == 0) || same_large_alignment_p (old_loc, result+pad)))
-        {
-            pad += switch_alignment_size (pad != 0);
-            set_node_realigned(old_loc);
-            dprintf (3, ("Allocation realignment old_loc: %zx, new_loc:%zx",
-                         (size_t)old_loc, (size_t)(result+pad)));
-            assert (same_large_alignment_p (result + pad, old_loc));
-        }
-#endif // FEATURE_STRUCTALIGN
-#ifdef SHORT_PLUGS
-        if ((next_pinned_plug != 0) && (pad != 0) && (generation_allocation_segment (gen) == current_seg))
-        {
-            assert (old_loc != 0);
-            ptrdiff_t dist_to_next_pin = (ptrdiff_t)(next_pinned_plug - (generation_allocation_pointer (gen) + size + pad));
-            assert (dist_to_next_pin >= 0);
-            if ((dist_to_next_pin >= 0) && (dist_to_next_pin < (ptrdiff_t)Align (min_obj_size)))
-            {
-                dprintf (3, ("%p->(%p,%p),%p(%zx)(%zx),NP->PP",
-                    old_loc,
-                    generation_allocation_pointer (gen),
-                    generation_allocation_limit (gen),
-                    next_pinned_plug,
-                    size,
-                    dist_to_next_pin));
-                clear_plug_padded (old_loc);
-                pad = 0;
-                *convert_to_pinned_p = TRUE;
-                record_interesting_data_point (idp_converted_pin);
-                return 0;
-            }
-        }
-#endif //SHORT_PLUGS
-        if ((old_loc == 0) || (pad != 0))
-        {
-            generation_allocation_context_start_region (gen) = generation_allocation_pointer (gen);
-        }
-        generation_allocation_pointer (gen) += size + pad;
-        assert (generation_allocation_pointer (gen) <= generation_allocation_limit (gen));
-        if ((pad > 0) && (to_gen_number >= 0))
-        {
-            generation_free_obj_space (generation_of (to_gen_number)) += pad;
-        }
-#ifdef FREE_USAGE_STATS
-        generation_allocated_since_last_pin (gen) += size;
-#endif //FREE_USAGE_STATS
-        dprintf (3, ("aic: old: %p ptr: %p, limit: %p, sr: %p, res: %p, pad: %zd",
-            old_loc,
-            generation_allocation_pointer (gen), generation_allocation_limit (gen),
-            generation_allocation_context_start_region (gen),
-            result, (size_t)pad));
-        assert (result + pad);
-        return result + pad;
-    }
-}
-int gc_heap::joined_generation_to_condemn (BOOL should_evaluate_elevation,
-                                           int initial_gen,
-                                           int current_gen,
-                                           BOOL* blocking_collection_p
-                                           STRESS_HEAP_ARG(int n_original))
-{
-    gc_data_global.gen_to_condemn_reasons.init();
-#ifdef BGC_SERVO_TUNING
-    if (settings.entry_memory_load == 0)
-    {
-        uint32_t current_memory_load = 0;
-        uint64_t current_available_physical = 0;
-        get_memory_info (&current_memory_load, &current_available_physical);
-        settings.entry_memory_load = current_memory_load;
-        settings.entry_available_physical_mem = current_available_physical;
-    }
-#endif //BGC_SERVO_TUNING
-    int n = current_gen;
-#ifdef MULTIPLE_HEAPS
-    BOOL joined_last_gc_before_oom = FALSE;
-    for (int i = 0; i < n_heaps; i++)
-    {
-        if (g_heaps[i]->last_gc_before_oom)
-        {
-            dprintf (GTC_LOG, ("h%d is setting blocking to TRUE", i));
-            joined_last_gc_before_oom = TRUE;
-            break;
-        }
-    }
-#else
-    BOOL joined_last_gc_before_oom = last_gc_before_oom;
-#endif //MULTIPLE_HEAPS
-    if (joined_last_gc_before_oom && settings.pause_mode != pause_low_latency)
-    {
-        assert (*blocking_collection_p);
-    }
-    if (should_evaluate_elevation && (n == max_generation))
-    {
-        dprintf (GTC_LOG, ("lock: %d(%d)",
-            (settings.should_lock_elevation ? 1 : 0),
-            settings.elevation_locked_count));
-        if (settings.should_lock_elevation)
-        {
-            settings.elevation_locked_count++;
-            if (settings.elevation_locked_count == 6)
-            {
-                settings.elevation_locked_count = 0;
-            }
-            else
-            {
-                n = max_generation - 1;
-                gc_data_global.gen_to_condemn_reasons.set_condition(gen_joined_avoid_unproductive);
-                settings.elevation_reduced = TRUE;
-            }
-        }
-        else
-        {
-            settings.elevation_locked_count = 0;
-        }
-    }
-    else
-    {
-        settings.should_lock_elevation = FALSE;
-        settings.elevation_locked_count = 0;
-    }
-    if (provisional_mode_triggered && (n == max_generation))
-    {
-        if ((initial_gen == max_generation) || (settings.reason == reason_alloc_loh))
-        {
-            dprintf (GTC_LOG, ("full GC induced, not reducing gen"));
-            if (initial_gen == max_generation)
-            {
-                gc_data_global.gen_to_condemn_reasons.set_condition(gen_joined_pm_induced_fullgc_p);
-            }
-            else
-            {
-                gc_data_global.gen_to_condemn_reasons.set_condition(gen_joined_pm_alloc_loh);
-            }
-            *blocking_collection_p = TRUE;
-        }
-        else if (
-#ifndef USE_REGIONS
-                 should_expand_in_full_gc ||
-#endif //!USE_REGIONS
-                 joined_last_gc_before_oom)
-        {
-            dprintf (GTC_LOG, ("need full blocking GCs to expand heap or avoid OOM, not reducing gen"));
-            assert (*blocking_collection_p);
-        }
-        else
-        {
-            dprintf (GTC_LOG, ("reducing gen in PM: %d->%d->%d", initial_gen, n, (max_generation - 1)));
-            gc_data_global.gen_to_condemn_reasons.set_condition(gen_joined_gen1_in_pm);
-            n = max_generation - 1;
-        }
-    }
-#ifndef USE_REGIONS
-    if (should_expand_in_full_gc)
-    {
-        should_expand_in_full_gc = FALSE;
-    }
-#endif //!USE_REGIONS
-    if (heap_hard_limit)
-    {
-        dprintf (GTC_LOG, ("committed %zd is %d%% of limit %zd",
-            current_total_committed, (int)((float)current_total_committed * 100.0 / (float)heap_hard_limit),
-            heap_hard_limit));
-        bool full_compact_gc_p = false;
-        if (joined_last_gc_before_oom)
-        {
-            gc_data_global.gen_to_condemn_reasons.set_condition(gen_joined_limit_before_oom);
-            full_compact_gc_p = true;
-        }
-        else if ((current_total_committed * 10) >= (heap_hard_limit * 9))
-        {
-            size_t loh_frag = get_total_gen_fragmentation (loh_generation);
-            if ((loh_frag * 8) >= heap_hard_limit)
-            {
-                dprintf (GTC_LOG, ("loh frag: %zd > 1/8 of limit %zd", loh_frag, (heap_hard_limit / 8)));
-                gc_data_global.gen_to_condemn_reasons.set_condition(gen_joined_limit_loh_frag);
-                full_compact_gc_p = true;
-            }
-            else
-            {
-                size_t est_loh_reclaim = get_total_gen_estimated_reclaim (loh_generation);
-                if ((est_loh_reclaim * 8) >= heap_hard_limit)
-                {
-                    gc_data_global.gen_to_condemn_reasons.set_condition(gen_joined_limit_loh_reclaim);
-                    full_compact_gc_p = true;
-                }
-                dprintf (GTC_LOG, ("loh est reclaim: %zd, 1/8 of limit %zd", est_loh_reclaim, (heap_hard_limit / 8)));
-            }
-        }
-        if (full_compact_gc_p)
-        {
-            n = max_generation;
-            *blocking_collection_p = TRUE;
-            settings.loh_compaction = TRUE;
-            dprintf (GTC_LOG, ("compacting LOH due to hard limit"));
-        }
-    }
-    if ((conserve_mem_setting != 0) && (n == max_generation))
-    {
-        float frag_limit = 1.0f - conserve_mem_setting / 10.0f;
-        size_t loh_size = get_total_gen_size (loh_generation);
-        size_t gen2_size = get_total_gen_size (max_generation);
-        float loh_frag_ratio = 0.0f;
-        float combined_frag_ratio = 0.0f;
-        if (loh_size != 0)
-        {
-            size_t loh_frag  = get_total_gen_fragmentation (loh_generation);
-            size_t gen2_frag = get_total_gen_fragmentation (max_generation);
-            loh_frag_ratio = (float)loh_frag / (float)loh_size;
-            combined_frag_ratio = (float)(gen2_frag + loh_frag) / (float)(gen2_size + loh_size);
-        }
-        if (combined_frag_ratio > frag_limit)
-        {
-            dprintf (GTC_LOG, ("combined frag: %f > limit %f, loh frag: %f", combined_frag_ratio, frag_limit, loh_frag_ratio));
-            gc_data_global.gen_to_condemn_reasons.set_condition (gen_max_high_frag_p);
-            n = max_generation;
-            *blocking_collection_p = TRUE;
-            if (loh_frag_ratio > frag_limit)
-            {
-                settings.loh_compaction = TRUE;
-                dprintf (GTC_LOG, ("compacting LOH due to GCConserveMem setting"));
-            }
-        }
-    }
-    if (settings.reason == reason_induced_aggressive)
-    {
-        gc_data_global.gen_to_condemn_reasons.set_condition (gen_joined_aggressive);
-        settings.loh_compaction = TRUE;
-    }
-#ifdef BGC_SERVO_TUNING
-    if (bgc_tuning::should_trigger_ngc2())
-    {
-        gc_data_global.gen_to_condemn_reasons.set_condition(gen_joined_servo_ngc);
-        n = max_generation;
-        *blocking_collection_p = TRUE;
-    }
-    if ((n < max_generation) && !gc_heap::background_running_p() &&
-        bgc_tuning::stepping_trigger (settings.entry_memory_load, get_current_gc_index (max_generation)))
-    {
-        gc_data_global.gen_to_condemn_reasons.set_condition(gen_joined_servo_initial);
-        n = max_generation;
-        saved_bgc_tuning_reason = reason_bgc_stepping;
-    }
-    if ((n < max_generation) && bgc_tuning::should_trigger_bgc())
-    {
-        gc_data_global.gen_to_condemn_reasons.set_condition(gen_joined_servo_bgc);
-        n = max_generation;
-    }
-    if (n == (max_generation - 1))
-    {
-        if (bgc_tuning::should_delay_alloc (max_generation))
-        {
-            gc_data_global.gen_to_condemn_reasons.set_condition(gen_joined_servo_postpone);
-            n -= 1;
-        }
-    }
-#endif //BGC_SERVO_TUNING
-    if ((n == max_generation) && (*blocking_collection_p == FALSE))
-    {
-        settings.should_lock_elevation = FALSE;
-        settings.elevation_locked_count = 0;
-        dprintf (GTC_LOG, ("doing bgc, reset elevation"));
-    }
-#ifdef STRESS_HEAP
-#ifdef BACKGROUND_GC
-    if (n_original != max_generation &&
-        g_pConfig->GetGCStressLevel() && gc_can_use_concurrent)
-    {
-#ifndef FEATURE_NATIVEAOT
-        if (*blocking_collection_p)
-        {
-            GCStressPolicy::GlobalDisable();
-        }
-        else
-#endif // !FEATURE_NATIVEAOT
-        {
-            gc_data_global.gen_to_condemn_reasons.set_condition(gen_joined_stress);
-            n = max_generation;
-        }
-    }
-#endif //BACKGROUND_GC
-#endif //STRESS_HEAP
-#ifdef BACKGROUND_GC
-#ifdef DYNAMIC_HEAP_COUNT
-    if (trigger_bgc_for_rethreading_p)
-    {
-        if (background_running_p())
-        {
-            if (n != 0)
-            {
-                n = 0;
-            }
-        }
-        else
-        {
-            dprintf (6666, ("was going to be g%d %s GC, HC change request this GC to be a BGC unless it's an NGC2",
-                n, (*blocking_collection_p ? "blocking" : "non blocking")));
-            if (!((n == max_generation) && *blocking_collection_p))
-            {
-                n = max_generation;
-#ifdef STRESS_DYNAMIC_HEAP_COUNT
-                if (bgc_to_ngc2_ratio)
-                {
-                    int r = (int)gc_rand::get_rand ((bgc_to_ngc2_ratio + 1) * 10);
-                    dprintf (6666, ("%d - making this full GC %s", r, ((r < 10) ? "NGC2" : "BGC")));
-                    if (r < 10)
-                    {
-                        *blocking_collection_p = TRUE;
-                    }
-                }
-#endif //STRESS_DYNAMIC_HEAP_COUNT
-            }
-        }
-    }
-    else
-#endif //DYNAMIC_HEAP_COUNT
-    if ((n == max_generation) && background_running_p())
-    {
-        n = max_generation - 1;
-        dprintf (GTC_LOG, ("bgc in progress - 1 instead of 2"));
-    }
-#endif //BACKGROUND_GC
-#ifdef DYNAMIC_HEAP_COUNT
-    if (trigger_initial_gen2_p)
-    {
-#ifdef BACKGROUND_GC
-        assert (!trigger_bgc_for_rethreading_p);
-        assert (!background_running_p());
-#endif //BACKGROUND_GC
-        if (n != max_generation)
-        {
-            n = max_generation;
-            *blocking_collection_p = FALSE;
-            dprintf (6666, ("doing the 1st gen2 GC requested by DATAS"));
-        }
-        trigger_initial_gen2_p = false;
-    }
-#endif //DYNAMIC_HEAP_COUNT
-    return n;
-}
-inline
-size_t get_survived_size (gc_history_per_heap* hist)
-{
-    size_t surv_size = 0;
-    gc_generation_data* gen_data;
-    for (int gen_number = 0; gen_number < total_generation_count; gen_number++)
-    {
-        gen_data = &(hist->gen_data[gen_number]);
-        surv_size += (gen_data->size_after -
-                      gen_data->free_list_space_after -
-                      gen_data->free_obj_space_after);
-    }
-    return surv_size;
-}
-size_t gc_heap::get_total_survived_size()
-{
-    size_t total_surv_size = 0;
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < gc_heap::n_heaps; i++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[i];
-        gc_history_per_heap* current_gc_data_per_heap = hp->get_gc_data_per_heap();
-        total_surv_size += get_survived_size (current_gc_data_per_heap);
-    }
-#else
-    gc_history_per_heap* current_gc_data_per_heap = get_gc_data_per_heap();
-    total_surv_size = get_survived_size (current_gc_data_per_heap);
-#endif //MULTIPLE_HEAPS
-    return total_surv_size;
-}
-void gc_heap::get_total_allocated_since_last_gc (size_t* oh_allocated)
-{
-    memset (oh_allocated, 0, (total_oh_count * sizeof (size_t)));
-    size_t total_allocated_size = 0;
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < gc_heap::n_heaps; i++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[i];
-#else //MULTIPLE_HEAPS
-    {
-        gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-        for (int oh_idx = 0; oh_idx < total_oh_count; oh_idx++)
-        {
-            oh_allocated[oh_idx] += hp->allocated_since_last_gc[oh_idx];
-            hp->allocated_since_last_gc[oh_idx] = 0;
-        }
-    }
-}
-size_t gc_heap::get_current_allocated()
-{
-    dynamic_data* dd = dynamic_data_of (0);
-    size_t current_alloc = dd_desired_allocation (dd) - dd_new_allocation (dd);
-    for (int i = uoh_start_generation; i < total_generation_count; i++)
-    {
-        dynamic_data* dd = dynamic_data_of (i);
-        current_alloc += dd_desired_allocation (dd) - dd_new_allocation (dd);
-    }
-    return current_alloc;
-}
-size_t gc_heap::get_total_allocated()
-{
-    size_t total_current_allocated = 0;
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < gc_heap::n_heaps; i++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[i];
-        total_current_allocated += hp->get_current_allocated();
-    }
-#else
-    total_current_allocated = get_current_allocated();
-#endif //MULTIPLE_HEAPS
-    return total_current_allocated;
-}
-size_t gc_heap::get_total_promoted()
-{
-    size_t total_promoted_size = 0;
-    int highest_gen = ((settings.condemned_generation == max_generation) ?
-                       (total_generation_count - 1) : settings.condemned_generation);
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < gc_heap::n_heaps; i++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[i];
-#else //MULTIPLE_HEAPS
-    {
-        gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-        for (int gen_number = 0; gen_number <= highest_gen; gen_number++)
-        {
-            total_promoted_size += dd_promoted_size (hp->dynamic_data_of (gen_number));
-        }
-    }
-    return total_promoted_size;
-}
-#ifdef BGC_SERVO_TUNING
-size_t gc_heap::get_total_generation_size (int gen_number)
-{
-    size_t total_generation_size = 0;
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < gc_heap::n_heaps; i++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[i];
-#else //MULTIPLE_HEAPS
-    {
-        gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-        total_generation_size += hp->generation_size (gen_number);
-    }
-    return total_generation_size;
-}
-size_t gc_heap::get_total_servo_alloc (int gen_number)
-{
-    size_t total_alloc = 0;
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < gc_heap::n_heaps; i++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[i];
-#else //MULTIPLE_HEAPS
-    {
-        gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-        generation* gen = hp->generation_of (gen_number);
-        total_alloc += generation_free_list_allocated (gen);
-        total_alloc += generation_end_seg_allocated (gen);
-        total_alloc += generation_condemned_allocated (gen);
-        total_alloc += generation_sweep_allocated (gen);
-    }
-    return total_alloc;
-}
-size_t gc_heap::get_total_bgc_promoted()
-{
-    size_t total_bgc_promoted = 0;
-#ifdef MULTIPLE_HEAPS
-    int num_heaps = gc_heap::n_heaps;
-#else //MULTIPLE_HEAPS
-    int num_heaps = 1;
-#endif //MULTIPLE_HEAPS
-    for (int i = 0; i < num_heaps; i++)
-    {
-        total_bgc_promoted += bpromoted_bytes (i);
-    }
-    return total_bgc_promoted;
-}
-size_t gc_heap::get_total_surv_size (int gen_number)
-{
-    size_t total_surv_size = 0;
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < gc_heap::n_heaps; i++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[i];
-#else //MULTIPLE_HEAPS
-    {
-        gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-        total_surv_size += dd_current_size (hp->dynamic_data_of (gen_number));
-    }
-    return total_surv_size;
-}
-size_t gc_heap::get_total_begin_data_size (int gen_number)
-{
-    size_t total_begin_data_size = 0;
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < gc_heap::n_heaps; i++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[i];
-#else //MULTIPLE_HEAPS
-    {
-        gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-        total_begin_data_size += dd_begin_data_size (hp->dynamic_data_of (gen_number));
-    }
-    return total_begin_data_size;
-}
-size_t gc_heap::get_total_generation_fl_size (int gen_number)
-{
-    size_t total_generation_fl_size = 0;
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < gc_heap::n_heaps; i++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[i];
-#else //MULTIPLE_HEAPS
-    {
-        gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-        total_generation_fl_size += generation_free_list_space (hp->generation_of (gen_number));
-    }
-    return total_generation_fl_size;
-}
-size_t gc_heap::get_current_gc_index (int gen_number)
-{
-#ifdef MULTIPLE_HEAPS
-    gc_heap* hp = gc_heap::g_heaps[0];
-    return dd_collection_count (hp->dynamic_data_of (gen_number));
-#else
-    return dd_collection_count (dynamic_data_of (gen_number));
-#endif //MULTIPLE_HEAPS
-}
-#endif //BGC_SERVO_TUNING
-size_t gc_heap::current_generation_size (int gen_number)
-{
-    dynamic_data* dd = dynamic_data_of (gen_number);
-    size_t gen_size = (dd_current_size (dd) + dd_desired_allocation (dd)
-                        - dd_new_allocation (dd));
-    return gen_size;
-}
-#ifdef USE_REGIONS
-bool gc_heap::try_get_new_free_region()
-{
-    heap_segment* region = 0;
-    if (free_regions[basic_free_region].get_num_free_regions() > 0)
-    {
-        dprintf (REGIONS_LOG, ("h%d has %zd free regions %p", heap_number, free_regions[basic_free_region].get_num_free_regions(),
-            heap_segment_mem (free_regions[basic_free_region].get_first_free_region())));
-        return true;
-    }
-    else
-    {
-        region = allocate_new_region (__this, 0, false);
-        if (region)
-        {
-            if (init_table_for_region (0, region))
-            {
-                return_free_region (region);
-                dprintf (REGIONS_LOG, ("h%d got a new empty region %p", heap_number, region));
-            }
-            else
-            {
-                region = 0;
-            }
-        }
-    }
-    return (region != 0);
-}
-bool gc_heap::init_table_for_region (int gen_number, heap_segment* region)
-{
-#ifdef BACKGROUND_GC
-    dprintf (GC_TABLE_LOG, ("new seg %Ix, mark_array is %Ix",
-        heap_segment_mem (region), mark_array));
-    if (((region->flags & heap_segment_flags_ma_committed) == 0) &&
-        !commit_mark_array_new_seg (__this, region))
-    {
-        dprintf (GC_TABLE_LOG, ("failed to commit mark array for the new region %Ix-%Ix",
-            get_region_start (region), heap_segment_reserved (region)));
-        decommit_region (region, gen_to_oh (gen_number), heap_number);
-        return false;
-    }
-    if ((region->flags & heap_segment_flags_ma_committed) != 0)
-    {
-        bgc_verify_mark_array_cleared (region, true);
-    }
-#endif //BACKGROUND_GC
-    if (gen_number <= max_generation)
-    {
-        size_t first_brick = brick_of (heap_segment_mem (region));
-        set_brick (first_brick, -1);
-    }
-    else
-    {
-        assert (brick_table[brick_of (heap_segment_mem (region))] == 0);
-    }
-    return true;
-}
-#endif //USE_REGIONS
-inline
-size_t gc_heap::generation_allocator_efficiency_percent (generation* inst)
-{
-#ifdef DYNAMIC_HEAP_COUNT
-    if (dynamic_adaptation_mode == dynamic_adaptation_to_application_sizes)
-    {
-        uint64_t total_plan_allocated = generation_total_plan_allocated (inst);
-        uint64_t condemned_allocated = generation_condemned_allocated (inst);
-        return ((total_plan_allocated == 0) ? 0 : (100 * (total_plan_allocated - condemned_allocated) / total_plan_allocated));
-    }
-    else
-#endif //DYNAMIC_HEAP_COUNT
-    {
-        uint64_t free_obj_space = generation_free_obj_space (inst);
-        uint64_t free_list_allocated = generation_free_list_allocated (inst);
-        if ((free_list_allocated + free_obj_space) == 0)
-            return 0;
-        return (size_t)((100 * free_list_allocated) / (free_list_allocated + free_obj_space));
-    }
-}
-inline
-size_t gc_heap::generation_unusable_fragmentation (generation* inst, int hn)
-{
-#ifdef DYNAMIC_HEAP_COUNT
-    if (dynamic_adaptation_mode == dynamic_adaptation_to_application_sizes)
-    {
-        uint64_t total_plan_allocated = generation_total_plan_allocated (inst);
-        uint64_t condemned_allocated = generation_condemned_allocated (inst);
-        uint64_t unusable_frag = 0;
-        size_t fo_space = (((ptrdiff_t)generation_free_obj_space (inst) < 0) ? 0 : generation_free_obj_space (inst));
-        if (total_plan_allocated != 0)
-        {
-            unusable_frag = fo_space + (condemned_allocated * generation_free_list_space (inst) / total_plan_allocated);
-        }
-        dprintf (3, ("h%d g%d FLa: %Id, ESa: %Id, Ca: %Id | FO: %Id, FL %Id, fl effi %.3f, unusable fl is %Id",
-            hn, inst->gen_num,
-            generation_free_list_allocated (inst), generation_end_seg_allocated (inst), (size_t)condemned_allocated,
-            fo_space, generation_free_list_space (inst),
-            ((total_plan_allocated == 0) ? 1.0 : ((float)(total_plan_allocated - condemned_allocated) / (float)total_plan_allocated)),
-            (size_t)unusable_frag));
-        return (size_t)unusable_frag;
-    }
-    else
-#endif //DYNAMIC_HEAP_COUNT
-    {
-        uint64_t free_obj_space = generation_free_obj_space (inst);
-        uint64_t free_list_allocated = generation_free_list_allocated (inst);
-        uint64_t free_list_space = generation_free_list_space (inst);
-        if ((free_list_allocated + free_obj_space) == 0)
-            return 0;
-        return (size_t)(free_obj_space + (free_obj_space * free_list_space) / (free_list_allocated + free_obj_space));
-    }
-}
-#ifdef _PREFAST_
-#pragma warning(push)
-#pragma warning(disable:6326) // "Potential comparison of a constant with another constant" is intentional in this function.
-#endif //_PREFAST_
-/*
-    This is called by when we are actually doing a GC, or when we are just checking whether
-    we would do a full blocking GC, in which case check_only_p is TRUE.
-    The difference between calling this with check_only_p TRUE and FALSE is that when it's
-    TRUE:
-            settings.reason is ignored
-            budgets are not checked (since they are checked before this is called)
-            it doesn't change anything non local like generation_skip_ratio
-*/
-int gc_heap::generation_to_condemn (int n_initial,
-                                    BOOL* blocking_collection_p,
-                                    BOOL* elevation_requested_p,
-                                    BOOL check_only_p)
-{
-    gc_mechanisms temp_settings = settings;
-    gen_to_condemn_tuning temp_condemn_reasons;
-    gc_mechanisms* local_settings = (check_only_p ? &temp_settings : &settings);
-    gen_to_condemn_tuning* local_condemn_reasons = (check_only_p ? &temp_condemn_reasons : &gen_to_condemn_reasons);
-    if (!check_only_p)
-    {
-        if ((local_settings->reason == reason_oos_soh) || (local_settings->reason == reason_oos_loh))
-        {
-            assert (n_initial >= 1);
-        }
-        assert (settings.reason != reason_empty);
-    }
-    local_condemn_reasons->init();
-    int n = n_initial;
-    int n_alloc = n;
-    if (heap_number == 0)
-    {
-        dprintf (6666, ("init: %d(%d)", n_initial, settings.reason));
-    }
-    int i = 0;
-    int temp_gen = 0;
-    BOOL low_memory_detected = g_low_memory_status;
-    uint32_t memory_load = 0;
-    uint64_t available_physical = 0;
-    uint64_t available_page_file = 0;
-    BOOL check_memory = FALSE;
-    BOOL high_fragmentation  = FALSE;
-    BOOL v_high_memory_load  = FALSE;
-    BOOL high_memory_load    = FALSE;
-    BOOL low_ephemeral_space = FALSE;
-    BOOL evaluate_elevation  = TRUE;
-    *elevation_requested_p   = FALSE;
-    *blocking_collection_p   = FALSE;
-    BOOL check_max_gen_alloc = TRUE;
-#ifdef STRESS_HEAP
-    int orig_gen = n;
-#endif //STRESS_HEAP
-    if (!check_only_p)
-    {
-        dd_fragmentation (dynamic_data_of (0)) =
-            generation_free_list_space (youngest_generation) +
-            generation_free_obj_space (youngest_generation);
-        for (int i = uoh_start_generation; i < total_generation_count; i++)
-        {
-            dd_fragmentation (dynamic_data_of (i)) =
-                generation_free_list_space (generation_of (i)) +
-                generation_free_obj_space (generation_of (i));
-        }
-        for (i = 0; i < total_generation_count; i++)
-        {
-            dynamic_data* dd = dynamic_data_of (i);
-            if ((dd_new_allocation (dd) < 0) && (i >= 2))
-            {
-                dprintf (6666, ("h%d: g%d: l: %zd (%zd)",
-                    heap_number, i,
-                    dd_new_allocation (dd),
-                    dd_desired_allocation (dd)));
-            }
-            dd_gc_new_allocation (dd) = dd_new_allocation (dd);
-        }
-        local_condemn_reasons->set_gen (gen_initial, n);
-        temp_gen = n;
-#ifdef BACKGROUND_GC
-        if (gc_heap::background_running_p()
-#ifdef BGC_SERVO_TUNING
-            || bgc_tuning::fl_tuning_triggered
-            || (bgc_tuning::enable_fl_tuning && bgc_tuning::use_stepping_trigger_p)
-#endif //BGC_SERVO_TUNING
-            )
-        {
-            check_max_gen_alloc = FALSE;
-        }
-#endif //BACKGROUND_GC
-        if (check_max_gen_alloc)
-        {
-            for (int i = uoh_start_generation; i < total_generation_count; i++)
-            {
-                if (get_new_allocation (i) <= 0)
-                {
-                    n = max_generation;
-                    local_condemn_reasons->set_gen (gen_alloc_budget, n);
-                    dprintf (BGC_TUNING_LOG, ("BTL[GTC]: trigger based on gen%d b: %zd",
-                             (i),
-                             get_new_allocation (i)));
-                    break;
-                }
-            }
-        }
-        for (i = n+1; i <= (check_max_gen_alloc ? max_generation : (max_generation - 1)); i++)
-        {
-            if (get_new_allocation (i) <= 0)
-            {
-                n = i;
-                if (n == max_generation)
-                {
-                    dprintf (BGC_TUNING_LOG, ("BTL[GTC]: trigger based on gen2 b: %zd",
-                            get_new_allocation (max_generation)));
-                }
-            }
-            else
-                break;
-        }
-    }
-    if (n > temp_gen)
-    {
-        local_condemn_reasons->set_gen (gen_alloc_budget, n);
-    }
-    if (n > 0)
-    {
-        dprintf (6666, ("h%d: g%d budget", heap_number, ((get_new_allocation (loh_generation) <= 0) ? 3 : n)));
-    }
-    n_alloc = n;
-#if defined(BACKGROUND_GC) && !defined(MULTIPLE_HEAPS)
-    int n_time_max = max_generation;
-    if (!check_only_p)
-    {
-        if (!check_max_gen_alloc)
-        {
-            n_time_max = max_generation - 1;
-        }
-    }
-    if ((local_settings->pause_mode == pause_interactive) ||
-        (local_settings->pause_mode == pause_sustained_low_latency))
-    {
-        dynamic_data* dd0 = dynamic_data_of (0);
-        uint64_t now = GetHighPrecisionTimeStamp();
-        temp_gen = n;
-        for (i = (temp_gen+1); i <= n_time_max; i++)
-        {
-            dynamic_data* dd = dynamic_data_of (i);
-            if ((now > dd_time_clock(dd) + dd_time_clock_interval(dd)) &&
-                (dd_gc_clock (dd0) > (dd_gc_clock (dd) + dd_gc_clock_interval(dd))) &&
-                ((n < max_generation) || ((dd_current_size (dd) < dd_max_size (dd0)))))
-            {
-                n = min (i, n_time_max);
-                dprintf (GTC_LOG, ("time %d", n));
-            }
-        }
-        if (n > temp_gen)
-        {
-            local_condemn_reasons->set_gen (gen_time_tuning, n);
-            if (n == max_generation)
-            {
-                dprintf (BGC_TUNING_LOG, ("BTL[GTC]: trigger based on time"));
-            }
-        }
-    }
-    if (n != n_alloc)
-    {
-        dprintf (GTC_LOG, ("Condemning %d based on time tuning and fragmentation", n));
-    }
-#endif //BACKGROUND_GC && !MULTIPLE_HEAPS
-    if (n < (max_generation - 1))
-    {
-        dprintf (6666, ("h%d: skip %d", heap_number, generation_skip_ratio));
-        if (dt_low_card_table_efficiency_p (tuning_deciding_condemned_gen))
-        {
-            n = max (n, max_generation - 1);
-            local_settings->promotion = TRUE;
-            dprintf (2, ("h%d: skip %d, c %d",
-                        heap_number, generation_skip_ratio, n));
-            local_condemn_reasons->set_condition (gen_low_card_p);
-        }
-    }
-    if (!check_only_p)
-    {
-        generation_skip_ratio = 100;
-    }
-    if (dt_low_ephemeral_space_p (check_only_p ?
-                                  tuning_deciding_full_gc :
-                                  tuning_deciding_condemned_gen))
-    {
-        low_ephemeral_space = TRUE;
-        n = max (n, max_generation - 1);
-        local_condemn_reasons->set_condition (gen_low_ephemeral_p);
-        dprintf (GTC_LOG, ("h%d: low eph", heap_number));
-        if (!provisional_mode_triggered)
-        {
-#ifdef BACKGROUND_GC
-            if (!gc_can_use_concurrent || (generation_free_list_space (generation_of (max_generation)) == 0))
-#endif //BACKGROUND_GC
-            {
-                if (dt_high_frag_p (tuning_deciding_condemned_gen,
-                                    max_generation - 1,
-                                    TRUE))
-                {
-                    high_fragmentation = TRUE;
-                    local_condemn_reasons->set_condition (gen_max_high_frag_e_p);
-                    dprintf (6666, ("heap%d: gen1 frag", heap_number));
-                }
-            }
-        }
-    }
-#ifdef USE_REGIONS
-    if (!check_only_p)
-    {
-        if (!try_get_new_free_region())
-        {
-            dprintf (GTC_LOG, ("can't get an empty region -> full compacting"));
-            last_gc_before_oom = TRUE;
-        }
-    }
-#endif //USE_REGIONS
-    temp_gen = n;
-    for (i = n+1; i < max_generation; i++)
-    {
-        if (dt_high_frag_p (tuning_deciding_condemned_gen, i))
-        {
-            dprintf (6666, ("h%d g%d too frag", heap_number, i));
-            n = i;
-        }
-        else
-            break;
-    }
-    if (low_ephemeral_space)
-    {
-        local_settings->promotion = TRUE;
-    }
-    if (n > temp_gen)
-    {
-        local_condemn_reasons->set_condition (gen_eph_high_frag_p);
-    }
-    if (!check_only_p)
-    {
-        if (settings.pause_mode == pause_low_latency)
-        {
-            if (!is_induced (settings.reason))
-            {
-                n = min (n, max_generation - 1);
-                dprintf (GTC_LOG, ("low latency mode is enabled, condemning %d", n));
-                evaluate_elevation = FALSE;
-                goto exit;
-            }
-        }
-    }
-    check_memory = (check_only_p ?
-                    (n >= 0) :
-                    ((n >= 1) || low_memory_detected));
-    if (check_memory)
-    {
-        get_memory_info (&memory_load, &available_physical, &available_page_file);
-        if (heap_number == 0)
-        {
-            dprintf (GTC_LOG, ("ml: %d", memory_load));
-        }
-#ifdef USE_REGIONS
-        uint32_t va_memory_load = global_region_allocator.get_va_memory_load();
-        if (heap_number == 0)
-        {
-            dprintf (GTC_LOG, ("h%d ML %d, va ML %d", heap_number, memory_load, va_memory_load));
-        }
-        memory_load = max (memory_load, va_memory_load);
-#endif //USE_REGIONS
-        local_settings->entry_available_physical_mem = available_physical;
-        local_settings->entry_memory_load = memory_load;
-        if (memory_load >= high_memory_load_th || low_memory_detected)
-        {
-#ifdef SIMPLE_DPRINTF
-            if (heap_number == 0)
-            {
-                dprintf (GTC_LOG, ("tp: %zd, ap: %zd", total_physical_mem, available_physical));
-            }
-#endif //SIMPLE_DPRINTF
-            high_memory_load = TRUE;
-            if (memory_load >= v_high_memory_load_th || low_memory_detected)
-            {
-                if (!high_fragmentation)
-                {
-                    high_fragmentation = dt_estimate_reclaim_space_p (tuning_deciding_condemned_gen, max_generation);
-                }
-                v_high_memory_load = TRUE;
-            }
-            else
-            {
-                if (!high_fragmentation)
-                {
-                    high_fragmentation = dt_estimate_high_frag_p (tuning_deciding_condemned_gen, max_generation, available_physical);
-                }
-            }
-            if (high_fragmentation)
-            {
-                dprintf (6666, ("h%d high frag true!! mem load %d", heap_number, memory_load));
-                if (high_memory_load)
-                {
-                    local_condemn_reasons->set_condition (gen_max_high_frag_m_p);
-                }
-                else if (v_high_memory_load)
-                {
-                    local_condemn_reasons->set_condition (gen_max_high_frag_vm_p);
-                }
-            }
-        }
-    }
-    dprintf (GTC_LOG, ("h%d: le: %d, hm: %d, vm: %d, f: %d",
-                 heap_number, low_ephemeral_space, high_memory_load, v_high_memory_load,
-                 high_fragmentation));
-#ifndef USE_REGIONS
-    if (should_expand_in_full_gc)
-    {
-        dprintf (GTC_LOG, ("h%d: expand_in_full - BLOCK", heap_number));
-        *blocking_collection_p = TRUE;
-        evaluate_elevation = FALSE;
-        n = max_generation;
-        local_condemn_reasons->set_condition (gen_expand_fullgc_p);
-    }
-#endif //!USE_REGIONS
-    if (last_gc_before_oom)
-    {
-        dprintf (GTC_LOG, ("h%d: alloc full - BLOCK", heap_number));
-        n = max_generation;
-        *blocking_collection_p = TRUE;
-        if ((local_settings->reason == reason_oos_loh) ||
-            (local_settings->reason == reason_alloc_loh))
-        {
-            evaluate_elevation = FALSE;
-        }
-        local_condemn_reasons->set_condition (gen_before_oom);
-    }
-    if (!check_only_p)
-    {
-        if (is_induced_blocking (settings.reason) &&
-            n_initial == max_generation
-            IN_STRESS_HEAP( && !settings.stress_induced ))
-        {
-            if (heap_number == 0)
-            {
-                dprintf (GTC_LOG, ("induced - BLOCK"));
-            }
-            *blocking_collection_p = TRUE;
-            local_condemn_reasons->set_condition (gen_induced_fullgc_p);
-            evaluate_elevation = FALSE;
-        }
-        if (settings.reason == reason_induced_noforce)
-        {
-            local_condemn_reasons->set_condition (gen_induced_noforce_p);
-            evaluate_elevation = FALSE;
-        }
-    }
-    if (!provisional_mode_triggered && evaluate_elevation && (low_ephemeral_space || high_memory_load || v_high_memory_load))
-    {
-        *elevation_requested_p = TRUE;
-#ifdef HOST_64BIT
-        if (high_memory_load || v_high_memory_load)
-        {
-            dynamic_data* dd_max = dynamic_data_of (max_generation);
-            if (((float)dd_new_allocation (dd_max) / (float)dd_desired_allocation (dd_max)) < 0.9)
-            {
-                dprintf (GTC_LOG, ("%zd left in gen2 alloc (%zd)",
-                    dd_new_allocation (dd_max), dd_desired_allocation (dd_max)));
-                n = max_generation;
-                local_condemn_reasons->set_condition (gen_almost_max_alloc);
-            }
-        }
-        if (n <= max_generation)
-#endif // HOST_64BIT
-        {
-            if (high_fragmentation)
-            {
-                n = max_generation;
-                dprintf (GTC_LOG, ("h%d: f full", heap_number));
-#ifdef BACKGROUND_GC
-                if (high_memory_load || v_high_memory_load)
-                {
-                    dprintf (GTC_LOG, ("h%d: bgc - BLOCK", heap_number));
-                    *blocking_collection_p = TRUE;
-                }
-#else
-                if (v_high_memory_load)
-                {
-                    dprintf (GTC_LOG, ("h%d: - BLOCK", heap_number));
-                    *blocking_collection_p = TRUE;
-                }
-#endif //BACKGROUND_GC
-            }
-            else
-            {
-                n = max (n, max_generation - 1);
-                dprintf (GTC_LOG, ("h%d: nf c %d", heap_number, n));
-            }
-        }
-    }
-    if (!provisional_mode_triggered && (n == (max_generation - 1)) && (n_alloc < (max_generation -1)))
-    {
-#ifdef BGC_SERVO_TUNING
-        if (!bgc_tuning::enable_fl_tuning)
-#endif //BGC_SERVO_TUNING
-        {
-            dprintf (GTC_LOG, ("h%d: budget %d, check 2",
-                        heap_number, n_alloc));
-            if (get_new_allocation (max_generation) <= 0)
-            {
-                dprintf (GTC_LOG, ("h%d: budget alloc", heap_number));
-                n = max_generation;
-                local_condemn_reasons->set_condition (gen_max_gen1);
-            }
-        }
-    }
-    if (!provisional_mode_triggered
-#ifdef BGC_SERVO_TUNING
-        && !bgc_tuning::enable_fl_tuning
-#endif //BGC_SERVO_TUNING
-        && (n == max_generation))
-    {
-        if (dt_high_frag_p (tuning_deciding_condemned_gen, n))
-        {
-            dprintf (6666, ("h%d: g%d too frag", heap_number, n));
-            local_condemn_reasons->set_condition (gen_max_high_frag_p);
-            if (local_settings->pause_mode != pause_sustained_low_latency)
-            {
-                *blocking_collection_p = TRUE;
-            }
-        }
-    }
-#ifdef BACKGROUND_GC
-    if ((n == max_generation) && !(*blocking_collection_p))
-    {
-        if (heap_number == 0)
-        {
-            BOOL bgc_heap_too_small = TRUE;
-            size_t gen2size = 0;
-            size_t gen3size = 0;
-#ifdef MULTIPLE_HEAPS
-            for (int i = 0; i < n_heaps; i++)
-            {
-                if (((g_heaps[i]->current_generation_size (max_generation)) > bgc_min_per_heap) ||
-                    ((g_heaps[i]->current_generation_size (loh_generation)) > bgc_min_per_heap) ||
-                    ((g_heaps[i]->current_generation_size (poh_generation)) > bgc_min_per_heap))
-                {
-                    bgc_heap_too_small = FALSE;
-                    break;
-                }
-            }
-#else //MULTIPLE_HEAPS
-            if ((current_generation_size (max_generation) > bgc_min_per_heap) ||
-                (current_generation_size (loh_generation) > bgc_min_per_heap) ||
-                (current_generation_size (poh_generation) > bgc_min_per_heap))
-            {
-                bgc_heap_too_small = FALSE;
-            }
-#endif //MULTIPLE_HEAPS
-            if (bgc_heap_too_small)
-            {
-                dprintf (GTC_LOG, ("gen2 and gen3 too small"));
-#ifdef STRESS_HEAP
-                if (!settings.stress_induced)
-#endif //STRESS_HEAP
-                {
-                    *blocking_collection_p = TRUE;
-                }
-                local_condemn_reasons->set_condition (gen_gen2_too_small);
-            }
-        }
-    }
-#endif //BACKGROUND_GC
-exit:
-    if (!check_only_p)
-    {
-#ifdef STRESS_HEAP
-#ifdef BACKGROUND_GC
-        if (orig_gen != max_generation &&
-            g_pConfig->GetGCStressLevel() && gc_can_use_concurrent)
-        {
-            *elevation_requested_p = FALSE;
-        }
-#endif //BACKGROUND_GC
-#endif //STRESS_HEAP
-        if (check_memory)
-        {
-            fgm_result.available_pagefile_mb = (size_t)(available_page_file / (1024 * 1024));
-        }
-        local_condemn_reasons->set_gen (gen_final_per_heap, n);
-        get_gc_data_per_heap()->gen_to_condemn_reasons.init (local_condemn_reasons);
-#ifdef DT_LOG
-        local_condemn_reasons->print (heap_number);
-#endif //DT_LOG
-        if ((local_settings->reason == reason_oos_soh) ||
-            (local_settings->reason == reason_oos_loh))
-        {
-            assert (n >= 1);
-        }
-    }
-    return n;
-}
-#ifdef _PREFAST_
-#pragma warning(pop)
-#endif //_PREFAST_
-inline
-size_t gc_heap::min_reclaim_fragmentation_threshold (uint32_t num_heaps)
-{
-    size_t min_mem_based_on_available =
-        (500 - (settings.entry_memory_load - high_memory_load_th) * 40) * 1024 * 1024 / num_heaps;
-    size_t ten_percent_size = (size_t)((float)generation_size (max_generation) * 0.10);
-    uint64_t three_percent_mem = mem_one_percent * 3 / num_heaps;
-#ifdef SIMPLE_DPRINTF
-    dprintf (GTC_LOG, ("min av: %zd, 10%% gen2: %zd, 3%% mem: %zd",
-        min_mem_based_on_available, ten_percent_size, three_percent_mem));
-#endif //SIMPLE_DPRINTF
-    return (size_t)(min ((uint64_t)min_mem_based_on_available, min ((uint64_t)ten_percent_size, three_percent_mem)));
-}
-inline
-uint64_t gc_heap::min_high_fragmentation_threshold(uint64_t available_mem, uint32_t num_heaps)
-{
-    return min (available_mem, (uint64_t)(256*1024*1024)) / num_heaps;
-}
-enum {
-CORINFO_EXCEPTION_GC = 0xE0004743 // 'GC'
-};
-#ifdef BACKGROUND_GC
-void gc_heap::init_background_gc ()
-{
-    generation* gen = generation_of (max_generation);
-    generation_allocation_pointer (gen)= 0;
-    generation_allocation_limit (gen) = 0;
-    generation_allocation_segment (gen) = heap_segment_rw (generation_start_segment (gen));
-    PREFIX_ASSUME(generation_allocation_segment(gen) != NULL);
-#ifdef DOUBLY_LINKED_FL
-    generation_set_bgc_mark_bit_p (gen) = FALSE;
-#endif //DOUBLY_LINKED_FL
-#ifndef USE_REGIONS
-    for (heap_segment* seg = generation_allocation_segment (gen); seg != ephemeral_heap_segment;
-        seg = heap_segment_next_rw (seg))
-    {
-        heap_segment_plan_allocated (seg) = heap_segment_allocated (seg);
-    }
-#endif //!USE_REGIONS
-    if (heap_number == 0)
-    {
-        dprintf (2, ("heap%d: bgc lowest: %p, highest: %p",
-            heap_number,
-            background_saved_lowest_address,
-            background_saved_highest_address));
-    }
-}
-#endif //BACKGROUND_GC
-inline
-void fire_drain_mark_list_event (size_t mark_list_objects)
-{
-    FIRE_EVENT(BGCDrainMark, mark_list_objects);
-}
-inline
-void fire_revisit_event (size_t dirtied_pages,
-                         size_t marked_objects,
-                         BOOL large_objects_p)
-{
-    FIRE_EVENT(BGCRevisit, dirtied_pages, marked_objects, large_objects_p);
-}
-inline
-void fire_overflow_event (uint8_t* overflow_min,
-                          uint8_t* overflow_max,
-                          size_t marked_objects,
-                          int gen_number)
-{
-    FIRE_EVENT(BGCOverflow_V1, (uint64_t)overflow_min, (uint64_t)overflow_max, marked_objects, gen_number == loh_generation, gen_number);
-}
-void gc_heap::concurrent_print_time_delta (const char* msg)
-{
-#ifdef TRACE_GC
-    uint64_t current_time = GetHighPrecisionTimeStamp();
-    size_t elapsed_time_ms = (size_t)((current_time - time_bgc_last) / 1000);
-    time_bgc_last = current_time;
-    dprintf (2, ("h%d: %s T %zd ms", heap_number, msg, elapsed_time_ms));
-#else
-    UNREFERENCED_PARAMETER(msg);
-#endif //TRACE_GC
-}
-void gc_heap::free_list_info (int gen_num, const char* msg)
-{
-#if defined (BACKGROUND_GC) && defined (TRACE_GC)
-    dprintf (3, ("h%d: %s", heap_number, msg));
-    for (int i = 0; i < total_generation_count; i++)
-    {
-        generation* gen = generation_of (i);
-        if ((generation_allocation_size (gen) == 0) &&
-            (generation_free_list_space (gen) == 0) &&
-            (generation_free_obj_space (gen) == 0))
-        {
-        }
-        else
-        {
-            dprintf (3, ("h%d: g%d: a-%zd, fl-%zd, fo-%zd",
-                heap_number, i,
-                generation_allocation_size (gen),
-                generation_free_list_space (gen),
-                generation_free_obj_space (gen)));
-        }
-    }
-#else
-    UNREFERENCED_PARAMETER(gen_num);
-    UNREFERENCED_PARAMETER(msg);
-#endif // BACKGROUND_GC && TRACE_GC
-}
-void gc_heap::update_collection_counts_for_no_gc()
-{
-    assert (settings.pause_mode == pause_no_gc);
-    settings.condemned_generation = max_generation;
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < n_heaps; i++)
-        g_heaps[i]->update_collection_counts();
-#else //MULTIPLE_HEAPS
-    update_collection_counts();
-#endif //MULTIPLE_HEAPS
-    full_gc_counts[gc_type_blocking]++;
-}
-BOOL gc_heap::should_proceed_with_gc()
-{
-    if (gc_heap::settings.pause_mode == pause_no_gc)
-    {
-        if (current_no_gc_region_info.started)
-        {
-            if (current_no_gc_region_info.soh_withheld_budget != 0)
-            {
-                dprintf(1, ("[no_gc_callback] allocation budget exhausted with withheld, time to trigger callback\n"));
-#ifdef MULTIPLE_HEAPS
-                for (int i = 0; i < gc_heap::n_heaps; i++)
-                {
-                    gc_heap* hp = gc_heap::g_heaps [i];
-#else
-                {
-                    gc_heap* hp = pGenGCHeap;
-#endif
-                    dd_new_allocation (hp->dynamic_data_of (soh_gen0)) += current_no_gc_region_info.soh_withheld_budget;
-                    dd_new_allocation (hp->dynamic_data_of (loh_generation)) += current_no_gc_region_info.loh_withheld_budget;
-                }
-                current_no_gc_region_info.soh_withheld_budget = 0;
-                current_no_gc_region_info.loh_withheld_budget = 0;
-                schedule_no_gc_callback (false);
-                current_no_gc_region_info.callback = nullptr;
-                return FALSE;
-            }
-            else
-            {
-                dprintf(1, ("[no_gc_callback] GC triggered while in no_gc mode. Exiting no_gc mode.\n"));
-                restore_data_for_no_gc();
-                if (current_no_gc_region_info.callback != nullptr)
-                {
-                    dprintf (1, ("[no_gc_callback] detaching callback on exit"));
-                    schedule_no_gc_callback (true);
-                }
-                memset (&current_no_gc_region_info, 0, sizeof (current_no_gc_region_info));
-            }
-        }
-        else
-            return should_proceed_for_no_gc();
-    }
-    return TRUE;
-}
-void gc_heap::update_end_gc_time_per_heap()
-{
-    for (int gen_number = 0; gen_number <= settings.condemned_generation; gen_number++)
-    {
-        dynamic_data* dd = dynamic_data_of (gen_number);
-        if (heap_number == 0)
-        {
-            dprintf (3, ("prev gen%d GC end time: prev start %I64d + prev gc elapsed %Id = %I64d",
-                gen_number, dd_previous_time_clock (dd), dd_gc_elapsed_time (dd), (dd_previous_time_clock (dd) + dd_gc_elapsed_time (dd))));
-        }
-        dd_gc_elapsed_time (dd) = (size_t)(end_gc_time - dd_time_clock (dd));
-        if (heap_number == 0)
-        {
-            dprintf (3, ("updated NGC%d %Id elapsed time to %I64d - %I64d = %I64d", gen_number, dd_gc_clock (dd), end_gc_time, dd_time_clock (dd), dd_gc_elapsed_time (dd)));
-        }
-    }
-}
-void gc_heap::update_end_ngc_time()
-{
-    end_gc_time = GetHighPrecisionTimeStamp();
-    last_alloc_reset_suspended_end_time = end_gc_time;
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-    last_gc_end_time_us = end_gc_time;
-    dprintf (HEAP_BALANCE_LOG, ("[GC#%zd-%zd-%zd]", settings.gc_index,
-        (last_gc_end_time_us - dd_time_clock (dynamic_data_of (0))),
-        dd_time_clock (dynamic_data_of (0))));
-#endif //HEAP_BALANCE_INSTRUMENTATION
-}
-size_t gc_heap::exponential_smoothing (int gen, size_t collection_count, size_t desired_per_heap)
-{
-    size_t smoothing = min((size_t)3, collection_count);
-    size_t desired_total = desired_per_heap * n_heaps;
-    size_t new_smoothed_desired_total = desired_total / smoothing + ((smoothed_desired_total[gen] / smoothing) * (smoothing - 1));
-    smoothed_desired_total[gen] = new_smoothed_desired_total;
-    size_t new_smoothed_desired_per_heap = new_smoothed_desired_total / n_heaps;
-#ifdef MULTIPLE_HEAPS
-    gc_heap* hp = g_heaps[0];
-#else //MULTIPLE_HEAPS
-    gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-    dynamic_data* dd = hp->dynamic_data_of (gen);
-    new_smoothed_desired_per_heap = max (new_smoothed_desired_per_heap, dd_min_size (dd));
-    new_smoothed_desired_per_heap = Align (new_smoothed_desired_per_heap, get_alignment_constant (gen <= soh_gen2));
-    dprintf (2, ("new smoothed_desired_per_heap for gen %d = %zd, desired_per_heap = %zd", gen, new_smoothed_desired_per_heap, desired_per_heap));
-    return new_smoothed_desired_per_heap;
-}
-void gc_heap::gc1()
-{
-#ifdef BACKGROUND_GC
-    assert (settings.concurrent == (uint32_t)(bgc_thread_id.IsCurrentThread()));
-#endif //BACKGROUND_GC
-    verify_soh_segment_list();
-    int n = settings.condemned_generation;
-    if (settings.reason == reason_pm_full_gc)
-    {
-        assert (n == max_generation);
-        init_records();
-        gen_to_condemn_tuning* local_condemn_reasons = &(get_gc_data_per_heap()->gen_to_condemn_reasons);
-        local_condemn_reasons->init();
-        local_condemn_reasons->set_gen (gen_initial, n);
-        local_condemn_reasons->set_gen (gen_final_per_heap, n);
-    }
-    update_collection_counts ();
-#ifdef BACKGROUND_GC
-    bgc_alloc_lock->check();
-#endif //BACKGROUND_GC
-    free_list_info (max_generation, "beginning");
-    vm_heap->GcCondemnedGeneration = settings.condemned_generation;
-    assert (g_gc_card_table == card_table);
-#ifdef FEATURE_MANUALLY_MANAGED_CARD_BUNDLES
-    assert (g_gc_card_bundle_table == card_bundle_table);
-#endif
-    {
-#ifndef USE_REGIONS
-        if (n == max_generation)
-        {
-            gc_low = lowest_address;
-            gc_high = highest_address;
-        }
-        else
-        {
-            gc_low = generation_allocation_start (generation_of (n));
-            gc_high = heap_segment_reserved (ephemeral_heap_segment);
-        }
-#endif //USE_REGIONS
-#ifdef BACKGROUND_GC
-        if (settings.concurrent)
-        {
-#ifdef TRACE_GC
-            time_bgc_last = GetHighPrecisionTimeStamp();
-#endif //TRACE_GC
-            FIRE_EVENT(BGCBegin);
-            concurrent_print_time_delta ("BGC");
-            concurrent_print_time_delta ("RW");
-            background_mark_phase();
-            free_list_info (max_generation, "after mark phase");
-            background_sweep();
-            free_list_info (max_generation, "after sweep phase");
-        }
-        else
-#endif //BACKGROUND_GC
-        {
-            mark_phase (n);
-            check_gen0_bricks();
-            GCScan::GcRuntimeStructuresValid (FALSE);
-            plan_phase (n);
-            GCScan::GcRuntimeStructuresValid (TRUE);
-            check_gen0_bricks();
-        }
-    }
-    for (int gen_number = 0; gen_number <= min ((int)max_generation,n+1); gen_number++)
-    {
-        generation* gn = generation_of (gen_number);
-        if (settings.compaction)
-        {
-            generation_allocation_size (generation_of (gen_number)) += generation_pinned_allocation_compact_size (gn);
-        }
-        else
-        {
-            generation_allocation_size (generation_of (gen_number)) += generation_pinned_allocation_sweep_size (gn);
-        }
-        generation_pinned_allocation_sweep_size (gn) = 0;
-        generation_pinned_allocation_compact_size (gn) = 0;
-    }
-#ifdef BACKGROUND_GC
-    if (settings.concurrent)
-    {
-        dynamic_data* dd = dynamic_data_of (n);
-        end_gc_time = GetHighPrecisionTimeStamp();
-        size_t time_since_last_gen2 = 0;
-#ifdef DYNAMIC_HEAP_COUNT
-        if ((heap_number == 0) && (dynamic_adaptation_mode == dynamic_adaptation_to_application_sizes))
-        {
-            time_since_last_gen2 = (size_t)(end_gc_time - (dd_previous_time_clock (dd) + dd_gc_elapsed_time (dd)));
-            dprintf (6666, ("BGC %Id end %I64d - (prev gen2 start %I64d + elapsed %Id = %I64d) = time inbewteen gen2 %Id",
-                dd_gc_clock (dd), end_gc_time, dd_previous_time_clock (dd), dd_gc_elapsed_time (dd), (dd_previous_time_clock (dd) + dd_gc_elapsed_time (dd)), time_since_last_gen2));
-        }
-#endif //DYNAMIC_HEAP_COUNT
-        dd_gc_elapsed_time (dd) = (size_t)(end_gc_time - dd_time_clock (dd));
-#ifdef DYNAMIC_HEAP_COUNT
-        if ((heap_number == 0) && (dynamic_adaptation_mode == dynamic_adaptation_to_application_sizes))
-        {
-            dprintf (6666, ("updating BGC %Id elapsed time to %I64d - %I64d = %I64d", dd_gc_clock (dd), end_gc_time, dd_time_clock (dd), dd_gc_elapsed_time (dd)));
-            float bgc_percent = (float)dd_gc_elapsed_time (dd) * 100.0f / (float)time_since_last_gen2;
-            dynamic_heap_count_data_t::gen2_sample& g2_sample = dynamic_heap_count_data.gen2_samples[dynamic_heap_count_data.gen2_sample_index];
-            g2_sample.gc_index = VolatileLoadWithoutBarrier (&(settings.gc_index));
-            g2_sample.gc_duration = dd_gc_elapsed_time (dd);
-            g2_sample.gc_percent = bgc_percent;
-            dprintf (6666, ("gen2 sample %d elapsed %Id * 100 / time inbetween gen2 %Id = %.3f",
-                dynamic_heap_count_data.gen2_sample_index, dd_gc_elapsed_time (dd), time_since_last_gen2, bgc_percent));
-            dynamic_heap_count_data.gen2_sample_index = (dynamic_heap_count_data.gen2_sample_index + 1) % dynamic_heap_count_data_t::sample_size;
-            (dynamic_heap_count_data.current_gen2_samples_count)++;
-            gc_index_full_gc_end = dd_gc_clock (dynamic_data_of (0));
-            calculate_new_heap_count ();
-        }
-#endif //DYNAMIC_HEAP_COUNT
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-        if (heap_number == 0)
-        {
-            last_gc_end_time_us = end_gc_time;
-            dprintf (HEAP_BALANCE_LOG, ("[GC#%zd-%zd-BGC]", settings.gc_index, dd_gc_elapsed_time (dd)));
-        }
-#endif //HEAP_BALANCE_INSTRUMENTATION
-        free_list_info (max_generation, "after computing new dynamic data");
-        gc_history_per_heap* current_gc_data_per_heap = get_gc_data_per_heap();
-        for (int gen_number = 0; gen_number < max_generation; gen_number++)
-        {
-            dprintf (2, ("end of BGC: gen%d new_alloc: %zd",
-                         gen_number, dd_desired_allocation (dynamic_data_of (gen_number))));
-            current_gc_data_per_heap->gen_data[gen_number].size_after = generation_size (gen_number);
-            current_gc_data_per_heap->gen_data[gen_number].free_list_space_after = generation_free_list_space (generation_of (gen_number));
-            current_gc_data_per_heap->gen_data[gen_number].free_obj_space_after = generation_free_obj_space (generation_of (gen_number));
-        }
-    }
-    else
-#endif //BACKGROUND_GC
-    {
-        free_list_info (max_generation, "end");
-        for (int gen_number = 0; gen_number <= n; gen_number++)
-        {
-            compute_new_dynamic_data (gen_number);
-        }
-        if (n != max_generation)
-        {
-            for (int gen_number = (n + 1); gen_number < total_generation_count; gen_number++)
-            {
-                get_gc_data_per_heap()->gen_data[gen_number].size_after = generation_size (gen_number);
-                get_gc_data_per_heap()->gen_data[gen_number].free_list_space_after = generation_free_list_space (generation_of (gen_number));
-                get_gc_data_per_heap()->gen_data[gen_number].free_obj_space_after = generation_free_obj_space (generation_of (gen_number));
-            }
-        }
-        get_gc_data_per_heap()->maxgen_size_info.running_free_list_efficiency = (uint32_t)(generation_allocator_efficiency_percent (generation_of (max_generation)));
-        free_list_info (max_generation, "after computing new dynamic data");
-    }
-    if (n < max_generation)
-    {
-        int highest_gen_number =
-#ifdef USE_REGIONS
-            max_generation;
-#else //USE_REGIONS
-            1 + n;
-#endif //USE_REGIONS
-        for (int older_gen_idx = (1 + n); older_gen_idx <= highest_gen_number; older_gen_idx++)
-        {
-            compute_in (older_gen_idx);
-            dynamic_data* dd = dynamic_data_of (older_gen_idx);
-            size_t new_fragmentation = generation_free_list_space (generation_of (older_gen_idx)) +
-                                       generation_free_obj_space (generation_of (older_gen_idx));
-#ifdef BACKGROUND_GC
-            if ((older_gen_idx != max_generation) || (current_c_gc_state != c_gc_state_planning))
-#endif //BACKGROUND_GC
-            {
-                if (settings.promotion)
-                {
-                    dd_fragmentation (dd) = new_fragmentation;
-                }
-                else
-                {
-                }
-            }
-        }
-    }
-#ifdef BACKGROUND_GC
-    if (!settings.concurrent)
-#endif //BACKGROUND_GC
-    {
-#ifndef FEATURE_NATIVEAOT
-        assert(GCToEEInterface::IsGCThread());
-#endif // FEATURE_NATIVEAOT
-        adjust_ephemeral_limits();
-    }
-#if defined(BACKGROUND_GC) && !defined(USE_REGIONS)
-    assert (ephemeral_low == generation_allocation_start (generation_of ( max_generation -1)));
-    assert (ephemeral_high == heap_segment_reserved (ephemeral_heap_segment));
-#endif //BACKGROUND_GC && !USE_REGIONS
-    if (fgn_maxgen_percent)
-    {
-        if (settings.condemned_generation == (max_generation - 1))
-        {
-            check_for_full_gc (max_generation - 1, 0);
-        }
-        else if (settings.condemned_generation == max_generation)
-        {
-            if (full_gc_approach_event_set
-#ifdef MULTIPLE_HEAPS
-                && (heap_number == 0)
-#endif //MULTIPLE_HEAPS
-                )
-            {
-                dprintf (2, ("FGN-GC: setting gen2 end event"));
-                full_gc_approach_event.Reset();
-#ifdef BACKGROUND_GC
-                fgn_last_gc_was_concurrent = settings.concurrent ? TRUE : FALSE;
-#endif //BACKGROUND_GC
-                full_gc_end_event.Set();
-                full_gc_approach_event_set = false;
-            }
-        }
-    }
-#ifdef BACKGROUND_GC
-    if (!settings.concurrent)
-#endif //BACKGROUND_GC
-    {
-        if (alloc_contexts_used >= 1)
-        {
-            allocation_quantum = Align (min ((size_t)CLR_SIZE,
-                                            (size_t)max ((size_t)1024, get_new_allocation (0) / (2 * alloc_contexts_used))),
-                                            get_alignment_constant(FALSE));
-            dprintf (3, ("New allocation quantum: %zd(0x%zx)", allocation_quantum, allocation_quantum));
-        }
-    }
-#ifdef USE_REGIONS
-    if (end_gen0_region_space == uninitialized_end_gen0_region_space)
-    {
-        end_gen0_region_space = get_gen0_end_space (memory_type_reserved);
-    }
-#endif //USE_REGIONS
-    descr_generations ("END");
-    verify_soh_segment_list();
-#ifdef BACKGROUND_GC
-    if (gc_can_use_concurrent)
-    {
-        check_bgc_mark_stack_length();
-    }
-    assert (settings.concurrent == (uint32_t)(bgc_thread_id.IsCurrentThread()));
-#endif //BACKGROUND_GC
-#if defined(VERIFY_HEAP) || (defined (FEATURE_EVENT_TRACE) && defined(BACKGROUND_GC))
-    if (FALSE
-#ifdef VERIFY_HEAP
-        || (GCConfig::GetHeapVerifyLevel() & GCConfig::HEAPVERIFY_GC)
-#endif
-#if defined(FEATURE_EVENT_TRACE) && defined(BACKGROUND_GC)
-        || (bgc_heap_walk_for_etw_p && settings.concurrent)
-#endif
-        )
-    {
-#ifdef BACKGROUND_GC
-        bool cooperative_mode = true;
-        if (settings.concurrent)
-        {
-            cooperative_mode = enable_preemptive ();
-#ifdef MULTIPLE_HEAPS
-            bgc_t_join.join(this, gc_join_suspend_ee_verify);
-            if (bgc_t_join.joined())
-            {
-                bgc_threads_sync_event.Reset();
-                dprintf(2, ("Joining BGC threads to suspend EE for verify heap"));
-                bgc_t_join.restart();
-            }
-            if (heap_number == 0)
-            {
-                enter_gc_lock_for_verify_heap();
-                suspend_EE();
-                bgc_threads_sync_event.Set();
-            }
-            else
-            {
-                bgc_threads_sync_event.Wait(INFINITE, FALSE);
-                dprintf (2, ("bgc_threads_sync_event is signalled"));
-            }
-#else //MULTIPLE_HEAPS
-            enter_gc_lock_for_verify_heap();
-            suspend_EE();
-#endif //MULTIPLE_HEAPS
-            fix_allocation_contexts (FALSE);
-        }
-#endif //BACKGROUND_GC
-#ifdef BACKGROUND_GC
-        assert (settings.concurrent == (uint32_t)(bgc_thread_id.IsCurrentThread()));
-#ifdef FEATURE_EVENT_TRACE
-        if (bgc_heap_walk_for_etw_p && settings.concurrent)
-        {
-            GCToEEInterface::DiagWalkBGCSurvivors(__this);
-#ifdef MULTIPLE_HEAPS
-            bgc_t_join.join(this, gc_join_after_profiler_heap_walk);
-            if (bgc_t_join.joined())
-            {
-                bgc_t_join.restart();
-            }
-#endif // MULTIPLE_HEAPS
-        }
-#endif // FEATURE_EVENT_TRACE
-#endif //BACKGROUND_GC
-#ifdef VERIFY_HEAP
-        if (GCConfig::GetHeapVerifyLevel() & GCConfig::HEAPVERIFY_GC)
-            verify_heap (FALSE);
-#endif // VERIFY_HEAP
-#ifdef BACKGROUND_GC
-        if (settings.concurrent)
-        {
-            repair_allocation_contexts (TRUE);
-#ifdef MULTIPLE_HEAPS
-            bgc_t_join.join(this, gc_join_restart_ee_verify);
-            if (bgc_t_join.joined())
-            {
-                bgc_threads_sync_event.Reset();
-                dprintf(2, ("Joining BGC threads to restart EE after verify heap"));
-                bgc_t_join.restart();
-            }
-            if (heap_number == 0)
-            {
-                restart_EE();
-                leave_gc_lock_for_verify_heap();
-                bgc_threads_sync_event.Set();
-            }
-            else
-            {
-                bgc_threads_sync_event.Wait(INFINITE, FALSE);
-                dprintf (2, ("bgc_threads_sync_event is signalled"));
-            }
-#else //MULTIPLE_HEAPS
-            restart_EE();
-            leave_gc_lock_for_verify_heap();
-#endif //MULTIPLE_HEAPS
-            disable_preemptive (cooperative_mode);
-        }
-#endif //BACKGROUND_GC
-    }
-#endif //VERIFY_HEAP || (FEATURE_EVENT_TRACE && BACKGROUND_GC)
-#ifdef MULTIPLE_HEAPS
-    if (!settings.concurrent)
-    {
-        gc_t_join.join(this, gc_join_done);
-        if (gc_t_join.joined ())
-        {
-            gc_heap::internal_gc_done = false;
-            int limit = settings.condemned_generation;
-            if (limit == max_generation)
-            {
-                limit = total_generation_count-1;
-            }
-            for (int gen = 0; gen <= limit; gen++)
-            {
-                size_t total_desired = 0;
-                size_t total_already_consumed = 0;
-                for (int i = 0; i < gc_heap::n_heaps; i++)
-                {
-                    gc_heap* hp = gc_heap::g_heaps[i];
-                    dynamic_data* dd = hp->dynamic_data_of (gen);
-                    size_t temp_total_desired = total_desired + dd_desired_allocation (dd);
-                    if (temp_total_desired < total_desired)
-                    {
-                        total_desired = (size_t)MAX_PTR;
-                        break;
-                    }
-                    total_desired = temp_total_desired;
-                    assert ((ptrdiff_t)dd_desired_allocation (dd) >= dd_new_allocation (dd));
-                    size_t already_consumed = dd_desired_allocation (dd) - dd_new_allocation (dd);
-                    size_t temp_total_already_consumed = total_already_consumed + already_consumed;
-                    assert (temp_total_already_consumed >= total_already_consumed);
-                    total_already_consumed = temp_total_already_consumed;
-                }
-                size_t desired_per_heap = Align (total_desired/gc_heap::n_heaps, get_alignment_constant (gen <= max_generation));
-                size_t already_consumed_per_heap = total_already_consumed / gc_heap::n_heaps;
-                if (gen == 0)
-                {
-                    size_t desired_per_heap_before_smoothing = desired_per_heap;
-                    desired_per_heap = exponential_smoothing (gen, dd_collection_count (dynamic_data_of(gen)), desired_per_heap);
-                    size_t desired_per_heap_after_smoothing = desired_per_heap;
-                    if (!heap_hard_limit
-#ifdef DYNAMIC_HEAP_COUNT
-                        && (dynamic_adaptation_mode != dynamic_adaptation_to_application_sizes)
-#endif //DYNAMIC_HEAP_COUNT
-                        )
-                    {
-                        gc_heap* hp = gc_heap::g_heaps[0];
-                        dynamic_data* dd = hp->dynamic_data_of (gen);
-                        size_t min_gc_size = dd_min_size(dd);
-                        if ((min_gc_size <= GCToOSInterface::GetCacheSizePerLogicalCpu(TRUE)) &&
-                            desired_per_heap <= 2*min_gc_size)
-                        {
-                            desired_per_heap = min_gc_size;
-                        }
-                    }
-#ifdef HOST_64BIT
-                    size_t desired_per_heap_before_trim = desired_per_heap;
-                    desired_per_heap = joined_youngest_desired (desired_per_heap);
-                    dprintf (6666, ("final gen0 bcs: total desired: %Id (%.3fmb/heap), before smooth %zd -> after smooth %zd -> after joined %zd",
-                        total_desired, ((double)(total_desired / n_heaps)/ 1000.0 / 1000.0),
-                        desired_per_heap_before_smoothing, desired_per_heap_after_smoothing, desired_per_heap));
-#endif // HOST_64BIT
-                    gc_data_global.final_youngest_desired = desired_per_heap;
-                }
-#if 1 //subsumed by the linear allocation model
-                if (gen >= uoh_start_generation)
-                {
-                    desired_per_heap = exponential_smoothing (gen, dd_collection_count (dynamic_data_of (max_generation)), desired_per_heap);
-                }
-#endif //0
-                for (int i = 0; i < gc_heap::n_heaps; i++)
-                {
-                    gc_heap* hp = gc_heap::g_heaps[i];
-                    dynamic_data* dd = hp->dynamic_data_of (gen);
-                    dd_desired_allocation (dd) = desired_per_heap;
-                    dd_gc_new_allocation (dd) = desired_per_heap;
-#ifdef USE_REGIONS
-                    dd_new_allocation (dd) = desired_per_heap - already_consumed_per_heap;
-#else //USE_REGIONS
-                    dd_new_allocation (dd) = desired_per_heap;
-#endif //USE_REGIONS
-                    if (gen == 0)
-                    {
-                        hp->fgn_last_alloc = desired_per_heap;
-                    }
-                }
-            }
-#ifdef FEATURE_LOH_COMPACTION
-            BOOL all_heaps_compacted_p = TRUE;
-#endif //FEATURE_LOH_COMPACTION
-            int max_gen0_must_clear_bricks = 0;
-            for (int i = 0; i < gc_heap::n_heaps; i++)
-            {
-                gc_heap* hp = gc_heap::g_heaps[i];
-                hp->rearrange_uoh_segments();
-#ifdef FEATURE_LOH_COMPACTION
-                all_heaps_compacted_p &= hp->loh_compacted_p;
-#endif //FEATURE_LOH_COMPACTION
-                max_gen0_must_clear_bricks = max(max_gen0_must_clear_bricks, hp->gen0_must_clear_bricks);
-            }
-            verify_committed_bytes_per_heap ();
-#ifdef USE_REGIONS
-            initGCShadow();
-            verify_region_to_generation_map ();
-            compute_gc_and_ephemeral_range (settings.condemned_generation, true);
-            stomp_write_barrier_ephemeral (ephemeral_low, ephemeral_high,
-                                           map_region_to_generation_skewed, (uint8_t)min_segment_size_shr);
-#endif //USE_REGIONS
-#ifdef FEATURE_LOH_COMPACTION
-            check_loh_compact_mode (all_heaps_compacted_p);
-#endif //FEATURE_LOH_COMPACTION
-            if (max_gen0_must_clear_bricks > 0)
-            {
-                for (int i = 0; i < gc_heap::n_heaps; i++)
-                {
-                    gc_heap* hp = gc_heap::g_heaps[i];
-                    hp->gen0_must_clear_bricks = max_gen0_must_clear_bricks;
-                }
-            }
-#ifdef DYNAMIC_HEAP_COUNT
-            if (dynamic_adaptation_mode == dynamic_adaptation_to_application_sizes)
-            {
-                update_total_soh_stable_size();
-                if ((settings.condemned_generation == max_generation) && trigger_bgc_for_rethreading_p)
-                {
-                    trigger_bgc_for_rethreading_p = false;
-                }
-                process_datas_sample();
-            }
-#endif //DYNAMIC_HEAP_COUNT
-            for (int i = 0; i < gc_heap::n_heaps; i++)
-            {
-                gc_heap* hp = gc_heap::g_heaps[i];
-                hp->decommit_ephemeral_segment_pages();
-                hp->descr_generations ("END");
-            }
-            fire_pevents();
-#ifdef USE_REGIONS
-            distribute_free_regions();
-            age_free_regions ("END");
-#endif //USE_REGIONS
-            update_end_ngc_time();
-            pm_full_gc_init_or_clear();
-            gc_t_join.restart();
-        }
-        update_end_gc_time_per_heap();
-        add_to_history_per_heap();
-        alloc_context_count = 0;
-        heap_select::mark_heap (heap_number);
-    }
-#else //MULTIPLE_HEAPS
-    gc_data_global.final_youngest_desired =
-        dd_desired_allocation (dynamic_data_of (0));
-#ifdef FEATURE_LOH_COMPACTION
-    check_loh_compact_mode (loh_compacted_p);
-#endif //FEATURE_LOH_COMPACTION
-#ifndef USE_REGIONS
-    decommit_ephemeral_segment_pages();
-#endif
-    fire_pevents();
-    if (!(settings.concurrent))
-    {
-        rearrange_uoh_segments();
-        verify_committed_bytes_per_heap ();
-#ifdef USE_REGIONS
-        initGCShadow();
-        verify_region_to_generation_map ();
-        compute_gc_and_ephemeral_range (settings.condemned_generation, true);
-        stomp_write_barrier_ephemeral (ephemeral_low, ephemeral_high,
-                                        map_region_to_generation_skewed, (uint8_t)min_segment_size_shr);
-        distribute_free_regions();
-        age_free_regions ("END");
-#endif //USE_REGIONS
-        update_end_ngc_time();
-        update_end_gc_time_per_heap();
-        add_to_history_per_heap();
-        do_post_gc();
-    }
-    pm_full_gc_init_or_clear();
-#ifdef BACKGROUND_GC
-    recover_bgc_settings();
-#endif //BACKGROUND_GC
-#endif //MULTIPLE_HEAPS
-#ifdef USE_REGIONS
-    if (!(settings.concurrent) && (settings.condemned_generation == max_generation))
-    {
-        last_gc_before_oom = FALSE;
-    }
-#endif //USE_REGIONS
-}
-#ifdef DYNAMIC_HEAP_COUNT
-size_t gc_heap::get_total_soh_stable_size()
-{
-    if (current_total_soh_stable_size)
-    {
-        return current_total_soh_stable_size;
-    }
-    else
-    {
-        size_t total_stable_size = 0;
-        for (int i = 0; i < gc_heap::n_heaps; i++)
-        {
-            gc_heap* hp = g_heaps[i];
-            total_stable_size += hp->generation_size (max_generation - 1) / 2;
-        }
-        if (!total_stable_size)
-        {
-            total_stable_size = dd_min_size (g_heaps[0]->dynamic_data_of (max_generation - 1));
-        }
-        return total_stable_size;
-    }
-}
-void gc_heap::update_total_soh_stable_size()
-{
-    if ((dynamic_adaptation_mode == dynamic_adaptation_to_application_sizes) && (settings.condemned_generation == max_generation))
-    {
-        current_total_soh_stable_size = 0;
-        for (int i = 0; i < gc_heap::n_heaps; i++)
-        {
-            gc_heap* hp = g_heaps[i];
-            dynamic_data* dd = hp->dynamic_data_of (max_generation);
-            current_total_soh_stable_size += dd_current_size (dd) + dd_desired_allocation (dd);
-            dprintf (2, ("current size is %.3fmb, budget %.3fmb, total -> %.3fmb", mb (dd_current_size (dd)), mb (dd_desired_allocation (dd)), mb (current_total_soh_stable_size)));
-        }
-    }
-}
-void gc_heap::assign_new_budget (int gen_number, size_t desired_per_heap)
-{
-    for (int i = 0; i < gc_heap::n_heaps; i++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[i];
-        dynamic_data* dd = hp->dynamic_data_of (gen_number);
-        dd_desired_allocation (dd) = desired_per_heap;
-        dd_gc_new_allocation (dd) = desired_per_heap;
-        dd_new_allocation (dd) = desired_per_heap;
-        if (gen_number == 0)
-        {
-            hp->fgn_last_alloc = desired_per_heap;
-        }
-    }
-    gc_data_global.final_youngest_desired = desired_per_heap;
-}
-bool gc_heap::prepare_rethread_fl_items()
-{
-    if (!min_fl_list)
-    {
-        min_fl_list = new (nothrow) min_fl_list_info [MAX_BUCKET_COUNT * n_max_heaps];
-        if (min_fl_list == nullptr)
-            return false;
-    }
-    if (!free_list_space_per_heap)
-    {
-        free_list_space_per_heap = new (nothrow) size_t[n_max_heaps];
-        if (free_list_space_per_heap == nullptr)
-            return false;
-    }
-    return true;
-}
-void gc_heap::rethread_fl_items(int gen_idx)
-{
-    uint32_t min_fl_list_size = sizeof (min_fl_list_info) * (MAX_BUCKET_COUNT * n_max_heaps);
-    memset (min_fl_list, 0, min_fl_list_size);
-    memset (free_list_space_per_heap, 0, sizeof(free_list_space_per_heap[0])*n_max_heaps);
-    size_t num_fl_items = 0;
-    size_t num_fl_items_rethreaded = 0;
-    allocator* gen_allocator = generation_allocator (generation_of (gen_idx));
-    gen_allocator->rethread_items (&num_fl_items, &num_fl_items_rethreaded, this, min_fl_list, free_list_space_per_heap, n_heaps);
-    num_fl_items_rethreaded_stage2 = num_fl_items_rethreaded;
-}
-void gc_heap::merge_fl_from_other_heaps (int gen_idx, int to_n_heaps, int from_n_heaps)
-{
-#ifdef _DEBUG
-    uint64_t start_us = GetHighPrecisionTimeStamp ();
-    size_t total_num_fl_items_rethreaded_stage2 = 0;
-    for (int hn = 0; hn < to_n_heaps; hn++)
-    {
-        gc_heap* hp = g_heaps[hn];
-        total_num_fl_items_rethreaded_stage2 += hp->num_fl_items_rethreaded_stage2;
-        min_fl_list_info* current_heap_min_fl_list = hp->min_fl_list;
-        allocator* gen_allocator = generation_allocator (hp->generation_of (gen_idx));
-        int num_buckets = gen_allocator->number_of_buckets();
-        for (int i = 0; i < num_buckets; i++)
-        {
-            min_fl_list_info* current_bucket_min_fl_list = current_heap_min_fl_list + (i * to_n_heaps);
-            for (int other_hn = 0; other_hn < from_n_heaps; other_hn++)
-            {
-                min_fl_list_info* min_fl_other_heap = &current_bucket_min_fl_list[other_hn];
-                if (min_fl_other_heap->head)
-                {
-                    if (other_hn == hn)
-                    {
-                        dprintf (8888, ("h%d has fl items for itself on the temp list?!", hn));
-                        GCToOSInterface::DebugBreak ();
-                    }
-                }
-            }
-        }
-    }
-    uint64_t elapsed = GetHighPrecisionTimeStamp () - start_us;
-    dprintf (8888, ("rethreaded %Id items, merging took %I64dus (%I64dms)",
-        total_num_fl_items_rethreaded_stage2, elapsed, (elapsed / 1000)));
-#endif //_DEBUG
-    for (int hn = 0; hn < to_n_heaps; hn++)
-    {
-        gc_heap* hp = g_heaps[hn];
-        generation* gen = hp->generation_of (gen_idx);
-        dynamic_data* dd = hp->dynamic_data_of (gen_idx);
-        allocator* gen_allocator = generation_allocator (gen);
-        gen_allocator->merge_items (hp, to_n_heaps, from_n_heaps);
-        size_t free_list_space_decrease = 0;
-        if (hn < from_n_heaps)
-        {
-            assert (hp->free_list_space_per_heap[hn] == 0);
-            for (int to_hn = 0; to_hn < to_n_heaps; to_hn++)
-            {
-                free_list_space_decrease += hp->free_list_space_per_heap[to_hn];
-            }
-        }
-        dprintf (8888, ("heap %d gen %d %zd total free list space, %zd moved to other heaps",
-            hn,
-            gen_idx,
-            generation_free_list_space (gen),
-            free_list_space_decrease));
-        assert (free_list_space_decrease <= generation_free_list_space (gen));
-        generation_free_list_space (gen) -= free_list_space_decrease;
-        if (gen_idx != max_generation)
-        {
-            assert (free_list_space_decrease <= dd_fragmentation (dd));
-        }
-        size_t free_list_space_increase = 0;
-        for (int from_hn = 0; from_hn < from_n_heaps; from_hn++)
-        {
-            gc_heap* from_hp = g_heaps[from_hn];
-            free_list_space_increase += from_hp->free_list_space_per_heap[hn];
-        }
-        dprintf (8888, ("heap %d gen %d %zd free list space moved from other heaps", hn, gen_idx, free_list_space_increase));
-        generation_free_list_space (gen) += free_list_space_increase;
-    }
-#ifdef _DEBUG
-    size_t total_fl_items_count = 0;
-    size_t total_fl_items_for_oh_count = 0;
-    for (int hn = 0; hn < to_n_heaps; hn++)
-    {
-        gc_heap* hp = g_heaps[hn];
-        allocator* gen_allocator = generation_allocator (hp->generation_of (gen_idx));
-        size_t fl_items_count = 0;
-        size_t fl_items_for_oh_count = 0;
-        gen_allocator->count_items (hp, &fl_items_count, &fl_items_for_oh_count);
-        total_fl_items_count += fl_items_count;
-        total_fl_items_for_oh_count += fl_items_for_oh_count;
-    }
-    dprintf (8888, ("total %Id fl items, %Id are for other heaps",
-        total_fl_items_count, total_fl_items_for_oh_count));
-    if (total_fl_items_for_oh_count)
-    {
-        GCToOSInterface::DebugBreak ();
-    }
-#endif //_DEBUG
-}
-#endif //DYNAMIC_HEAP_COUNT
-void gc_heap::save_data_for_no_gc()
-{
-    current_no_gc_region_info.saved_pause_mode = settings.pause_mode;
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < n_heaps; i++)
-    {
-        current_no_gc_region_info.saved_gen0_min_size = dd_min_size (g_heaps[i]->dynamic_data_of (0));
-        dd_min_size (g_heaps[i]->dynamic_data_of (0)) = min_balance_threshold;
-        current_no_gc_region_info.saved_gen3_min_size = dd_min_size (g_heaps[i]->dynamic_data_of (loh_generation));
-        dd_min_size (g_heaps[i]->dynamic_data_of (loh_generation)) = 0;
-    }
-#endif //MULTIPLE_HEAPS
-}
-void gc_heap::restore_data_for_no_gc()
-{
-    gc_heap::settings.pause_mode = current_no_gc_region_info.saved_pause_mode;
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < n_heaps; i++)
-    {
-        dd_min_size (g_heaps[i]->dynamic_data_of (0)) = current_no_gc_region_info.saved_gen0_min_size;
-        dd_min_size (g_heaps[i]->dynamic_data_of (loh_generation)) = current_no_gc_region_info.saved_gen3_min_size;
-    }
-#endif //MULTIPLE_HEAPS
-}
-start_no_gc_region_status gc_heap::prepare_for_no_gc_region (uint64_t total_size,
-                                                             BOOL loh_size_known,
-                                                             uint64_t loh_size,
-                                                             BOOL disallow_full_blocking)
-{
-    if (current_no_gc_region_info.started)
-    {
-        return start_no_gc_in_progress;
-    }
-    start_no_gc_region_status status = start_no_gc_success;
-    save_data_for_no_gc();
-    settings.pause_mode = pause_no_gc;
-    current_no_gc_region_info.start_status = start_no_gc_success;
-    uint64_t allocation_no_gc_loh = 0;
-    uint64_t allocation_no_gc_soh = 0;
-    assert(total_size != 0);
-    if (loh_size_known)
-    {
-        assert(loh_size != 0);
-        assert(loh_size <= total_size);
-        allocation_no_gc_loh = loh_size;
-        allocation_no_gc_soh = total_size - loh_size;
-    }
-    else
-    {
-        allocation_no_gc_soh = total_size;
-        allocation_no_gc_loh = total_size;
-    }
-    int soh_align_const = get_alignment_constant (TRUE);
-#ifdef USE_REGIONS
-    size_t max_soh_allocated = SIZE_T_MAX;
-#else
-    size_t max_soh_allocated = soh_segment_size - segment_info_size - eph_gen_starts_size;
-#endif
-    size_t size_per_heap = 0;
-    const double scale_factor = 1.05;
-    int num_heaps = get_num_heaps();
-    uint64_t total_allowed_soh_allocation = (uint64_t)max_soh_allocated * num_heaps;
-    assert(total_allowed_soh_allocation <= SIZE_T_MAX);
-    uint64_t total_allowed_loh_allocation = SIZE_T_MAX;
-    uint64_t total_allowed_soh_alloc_scaled = allocation_no_gc_soh > 0 ? static_cast<uint64_t>(total_allowed_soh_allocation / scale_factor) : 0;
-    uint64_t total_allowed_loh_alloc_scaled = allocation_no_gc_loh > 0 ? static_cast<uint64_t>(total_allowed_loh_allocation / scale_factor) : 0;
-    if (allocation_no_gc_soh > total_allowed_soh_alloc_scaled ||
-        allocation_no_gc_loh > total_allowed_loh_alloc_scaled)
-    {
-        status = start_no_gc_too_large;
-        goto done;
-    }
-    if (allocation_no_gc_soh > 0)
-    {
-        allocation_no_gc_soh = static_cast<uint64_t>(allocation_no_gc_soh * scale_factor);
-        allocation_no_gc_soh = min (allocation_no_gc_soh, total_allowed_soh_alloc_scaled);
-    }
-    if (allocation_no_gc_loh > 0)
-    {
-        allocation_no_gc_loh = static_cast<uint64_t>(allocation_no_gc_loh * scale_factor);
-        allocation_no_gc_loh = min (allocation_no_gc_loh, total_allowed_loh_alloc_scaled);
-    }
-    if (disallow_full_blocking)
-        current_no_gc_region_info.minimal_gc_p = TRUE;
-    if (allocation_no_gc_soh != 0)
-    {
-        current_no_gc_region_info.soh_allocation_size = (size_t)allocation_no_gc_soh;
-        size_per_heap = current_no_gc_region_info.soh_allocation_size;
-#ifdef MULTIPLE_HEAPS
-        size_per_heap /= n_heaps;
-        for (int i = 0; i < n_heaps; i++)
-        {
-            g_heaps[i]->soh_allocation_no_gc = min (Align ((size_per_heap + min_balance_threshold), soh_align_const), max_soh_allocated);
-        }
-#else //MULTIPLE_HEAPS
-        soh_allocation_no_gc = min (Align (size_per_heap, soh_align_const), max_soh_allocated);
-#endif //MULTIPLE_HEAPS
-    }
-    if (allocation_no_gc_loh != 0)
-    {
-        current_no_gc_region_info.loh_allocation_size = (size_t)allocation_no_gc_loh;
-        size_per_heap = current_no_gc_region_info.loh_allocation_size;
-#ifdef MULTIPLE_HEAPS
-        size_per_heap /= n_heaps;
-        for (int i = 0; i < n_heaps; i++)
-            g_heaps[i]->loh_allocation_no_gc = Align (size_per_heap, get_alignment_constant (FALSE));
-#else //MULTIPLE_HEAPS
-        loh_allocation_no_gc = Align (size_per_heap, get_alignment_constant (FALSE));
-#endif //MULTIPLE_HEAPS
-    }
-done:
-    if (status != start_no_gc_success)
-        restore_data_for_no_gc();
-    return status;
-}
-void gc_heap::handle_failure_for_no_gc()
-{
-    gc_heap::restore_data_for_no_gc();
-    memset (&current_no_gc_region_info, 0, sizeof (current_no_gc_region_info));
-}
-start_no_gc_region_status gc_heap::get_start_no_gc_region_status()
-{
-    return current_no_gc_region_info.start_status;
-}
-void gc_heap::record_gcs_during_no_gc()
-{
-    if (current_no_gc_region_info.started)
-    {
-        current_no_gc_region_info.num_gcs++;
-        if (is_induced (settings.reason))
-            current_no_gc_region_info.num_gcs_induced++;
-    }
-}
-BOOL gc_heap::find_loh_free_for_no_gc()
-{
-    allocator* loh_allocator = generation_allocator (generation_of (loh_generation));
-    size_t size = loh_allocation_no_gc;
-    for (unsigned int a_l_idx = loh_allocator->first_suitable_bucket(size); a_l_idx < loh_allocator->number_of_buckets(); a_l_idx++)
-    {
-        uint8_t* free_list = loh_allocator->alloc_list_head_of (a_l_idx);
-        while (free_list)
-        {
-            size_t free_list_size = unused_array_size(free_list);
-            if (free_list_size > size)
-            {
-                dprintf (3, ("free item %zx(%zd) for no gc", (size_t)free_list, free_list_size));
-                return TRUE;
-            }
-            free_list = free_list_slot (free_list);
-        }
-    }
-    return FALSE;
-}
-BOOL gc_heap::find_loh_space_for_no_gc()
-{
-    saved_loh_segment_no_gc = 0;
-    if (find_loh_free_for_no_gc())
-        return TRUE;
-    heap_segment* seg = generation_allocation_segment (generation_of (loh_generation));
-    while (seg)
-    {
-        size_t remaining = heap_segment_reserved (seg) - heap_segment_allocated (seg);
-        if (remaining >= loh_allocation_no_gc)
-        {
-            saved_loh_segment_no_gc = seg;
-            break;
-        }
-        seg = heap_segment_next (seg);
-    }
-    if (!saved_loh_segment_no_gc && current_no_gc_region_info.minimal_gc_p)
-    {
-        saved_loh_segment_no_gc = get_segment_for_uoh (loh_generation, get_uoh_seg_size (loh_allocation_no_gc)
-#ifdef MULTIPLE_HEAPS
-                                                      , this
-#endif //MULTIPLE_HEAPS
-                                                      );
-    }
-    return (saved_loh_segment_no_gc != 0);
-}
-BOOL gc_heap::loh_allocated_for_no_gc()
-{
-    if (!saved_loh_segment_no_gc)
-        return FALSE;
-    heap_segment* seg = generation_allocation_segment (generation_of (loh_generation));
-    do
-    {
-        if (seg == saved_loh_segment_no_gc)
-        {
-            return FALSE;
-        }
-        seg = heap_segment_next (seg);
-    } while (seg);
-    return TRUE;
-}
-BOOL gc_heap::commit_loh_for_no_gc (heap_segment* seg)
-{
-    uint8_t* end_committed = heap_segment_allocated (seg) + loh_allocation_no_gc;
-    assert (end_committed <= heap_segment_reserved (seg));
-    return (grow_heap_segment (seg, end_committed));
-}
-void gc_heap::thread_no_gc_loh_segments()
-{
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < n_heaps; i++)
-    {
-        gc_heap* hp = g_heaps[i];
-        if (hp->loh_allocated_for_no_gc())
-        {
-            hp->thread_uoh_segment (loh_generation, hp->saved_loh_segment_no_gc);
-            hp->saved_loh_segment_no_gc = 0;
-        }
-    }
-#else //MULTIPLE_HEAPS
-    if (loh_allocated_for_no_gc())
-    {
-        thread_uoh_segment (loh_generation, saved_loh_segment_no_gc);
-        saved_loh_segment_no_gc = 0;
-    }
-#endif //MULTIPLE_HEAPS
-}
-void gc_heap::set_loh_allocations_for_no_gc()
-{
-    if (current_no_gc_region_info.loh_allocation_size != 0)
-    {
-        dynamic_data* dd = dynamic_data_of (loh_generation);
-        dd_new_allocation (dd) = loh_allocation_no_gc;
-        dd_gc_new_allocation (dd) = dd_new_allocation (dd);
-    }
-}
-void gc_heap::set_soh_allocations_for_no_gc()
-{
-    if (current_no_gc_region_info.soh_allocation_size != 0)
-    {
-        dynamic_data* dd = dynamic_data_of (0);
-        dd_new_allocation (dd) = soh_allocation_no_gc;
-        dd_gc_new_allocation (dd) = dd_new_allocation (dd);
-#ifdef MULTIPLE_HEAPS
-        alloc_context_count = 0;
-#endif //MULTIPLE_HEAPS
-    }
-}
-void gc_heap::set_allocations_for_no_gc()
-{
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < n_heaps; i++)
-    {
-        gc_heap* hp = g_heaps[i];
-        hp->set_loh_allocations_for_no_gc();
-        hp->set_soh_allocations_for_no_gc();
-    }
-#else //MULTIPLE_HEAPS
-    set_loh_allocations_for_no_gc();
-    set_soh_allocations_for_no_gc();
-#endif //MULTIPLE_HEAPS
-}
-BOOL gc_heap::should_proceed_for_no_gc()
-{
-    BOOL gc_requested = FALSE;
-    BOOL loh_full_gc_requested = FALSE;
-    BOOL soh_full_gc_requested = FALSE;
-    BOOL no_gc_requested = FALSE;
-    BOOL get_new_loh_segments = FALSE;
-#ifdef MULTIPLE_HEAPS
-    gradual_decommit_in_progress_p = FALSE;
-#endif //MULTIPLE_HEAPS
-    gc_heap* hp = nullptr;
-    if (current_no_gc_region_info.soh_allocation_size)
-    {
-#ifdef USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-        for (int i = 0; i < n_heaps; i++)
-        {
-            hp = g_heaps[i];
-#else
-        {
-            hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-            if (!hp->extend_soh_for_no_gc())
-            {
-                soh_full_gc_requested = TRUE;
-#ifdef MULTIPLE_HEAPS
-                break;
-#endif //MULTIPLE_HEAPS
-            }
-        }
-#else //USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-        for (int i = 0; i < n_heaps; i++)
-        {
-            hp = g_heaps[i];
-#else //MULTIPLE_HEAPS
-        {
-            hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-            size_t reserved_space = heap_segment_reserved (hp->ephemeral_heap_segment) - hp->alloc_allocated;
-            if (reserved_space < hp->soh_allocation_no_gc)
-            {
-                gc_requested = TRUE;
-#ifdef MULTIPLE_HEAPS
-                break;
-#endif //MULTIPLE_HEAPS
-            }
-        }
-        if (!gc_requested)
-        {
-#ifdef MULTIPLE_HEAPS
-            for (int i = 0; i < n_heaps; i++)
-            {
-                hp = g_heaps[i];
-#else //MULTIPLE_HEAPS
-            {
-                hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-                if (!(hp->grow_heap_segment (hp->ephemeral_heap_segment, (hp->alloc_allocated + hp->soh_allocation_no_gc))))
-                {
-                    soh_full_gc_requested = TRUE;
-#ifdef MULTIPLE_HEAPS
-                    break;
-#endif //MULTIPLE_HEAPS
-                }
-            }
-        }
-#endif //USE_REGIONS
-    }
-    if (!current_no_gc_region_info.minimal_gc_p && gc_requested)
-    {
-        soh_full_gc_requested = TRUE;
-    }
-    no_gc_requested = !(soh_full_gc_requested || gc_requested);
-    if (soh_full_gc_requested && current_no_gc_region_info.minimal_gc_p)
-    {
-        current_no_gc_region_info.start_status = start_no_gc_no_memory;
-        goto done;
-    }
-    if (!soh_full_gc_requested && current_no_gc_region_info.loh_allocation_size)
-    {
-#ifdef MULTIPLE_HEAPS
-        for (int i = 0; i < n_heaps; i++)
-        {
-            gc_heap* hp = g_heaps[i];
-            if (!hp->find_loh_space_for_no_gc())
-            {
-                loh_full_gc_requested = TRUE;
-                break;
-            }
-        }
-#else //MULTIPLE_HEAPS
-        if (!find_loh_space_for_no_gc())
-            loh_full_gc_requested = TRUE;
-#endif //MULTIPLE_HEAPS
-        if (!loh_full_gc_requested)
-        {
-#ifdef MULTIPLE_HEAPS
-            for (int i = 0; i < n_heaps; i++)
-            {
-                gc_heap* hp = g_heaps[i];
-                if (hp->saved_loh_segment_no_gc &&!hp->commit_loh_for_no_gc (hp->saved_loh_segment_no_gc))
-                {
-                    loh_full_gc_requested = TRUE;
-                    break;
-                }
-            }
-#else //MULTIPLE_HEAPS
-            if (saved_loh_segment_no_gc && !commit_loh_for_no_gc (saved_loh_segment_no_gc))
-                loh_full_gc_requested = TRUE;
-#endif //MULTIPLE_HEAPS
-        }
-    }
-    if (loh_full_gc_requested || soh_full_gc_requested)
-    {
-        if (current_no_gc_region_info.minimal_gc_p)
-            current_no_gc_region_info.start_status = start_no_gc_no_memory;
-    }
-    no_gc_requested = !(loh_full_gc_requested || soh_full_gc_requested || gc_requested);
-    if (current_no_gc_region_info.start_status == start_no_gc_success)
-    {
-        if (no_gc_requested)
-            set_allocations_for_no_gc();
-    }
-done:
-    if ((current_no_gc_region_info.start_status == start_no_gc_success) && !no_gc_requested)
-        return TRUE;
-    else
-    {
-        current_no_gc_region_info.started = TRUE;
-        return FALSE;
-    }
-}
-end_no_gc_region_status gc_heap::end_no_gc_region()
-{
-    dprintf (1, ("end no gc called"));
-    end_no_gc_region_status status = end_no_gc_success;
-    if (!(current_no_gc_region_info.started))
-        status = end_no_gc_not_in_progress;
-    if (current_no_gc_region_info.num_gcs_induced)
-        status = end_no_gc_induced;
-    else if (current_no_gc_region_info.num_gcs)
-        status = end_no_gc_alloc_exceeded;
-    if (settings.pause_mode == pause_no_gc)
-    {
-        restore_data_for_no_gc();
-        if (current_no_gc_region_info.callback != nullptr)
-        {
-            dprintf (1, ("[no_gc_callback] detaching callback on exit"));
-            schedule_no_gc_callback (true);
-        }
-    }
-    memset (&current_no_gc_region_info, 0, sizeof (current_no_gc_region_info));
-    return status;
-}
-void gc_heap::schedule_no_gc_callback (bool abandoned)
-{
-    current_no_gc_region_info.callback->abandoned = abandoned;
-    if (!current_no_gc_region_info.callback->scheduled)
-    {
-        current_no_gc_region_info.callback->scheduled = true;
-        schedule_finalizer_work(current_no_gc_region_info.callback);
-    }
-}
-void gc_heap::schedule_finalizer_work (FinalizerWorkItem* callback)
-{
-    FinalizerWorkItem* prev;
-    do
-    {
-        prev = finalizer_work;
-        callback->next = prev;
-    }
-    while (Interlocked::CompareExchangePointer (&finalizer_work, callback, prev) != prev);
-    if (prev == nullptr)
-    {
-        GCToEEInterface::EnableFinalization(true);
-    }
-}
-void gc_heap::update_collection_counts ()
-{
-    dynamic_data* dd0 = dynamic_data_of (0);
-    dd_gc_clock (dd0) += 1;
-    uint64_t now = GetHighPrecisionTimeStamp();
-    for (int i = 0; i <= settings.condemned_generation;i++)
-    {
-        dynamic_data* dd = dynamic_data_of (i);
-        dd_collection_count (dd)++;
-        if (i == max_generation)
-        {
-            dd_collection_count (dynamic_data_of (loh_generation))++;
-            dd_collection_count(dynamic_data_of(poh_generation))++;
-        }
-        dd_gc_clock (dd) = dd_gc_clock (dd0);
-        dd_previous_time_clock (dd) = dd_time_clock (dd);
-        dd_time_clock (dd) = now;
-    }
-}
-#ifdef USE_REGIONS
-bool gc_heap::extend_soh_for_no_gc()
-{
-    size_t required = soh_allocation_no_gc;
-    heap_segment* region = ephemeral_heap_segment;
-    while (true)
-    {
-        uint8_t* allocated = (region == ephemeral_heap_segment) ?
-                             alloc_allocated :
-                             heap_segment_allocated (region);
-        size_t available = heap_segment_reserved (region) - allocated;
-        size_t commit = min (available, required);
-        if (grow_heap_segment (region, allocated + commit))
-        {
-            required -= commit;
-            if (required == 0)
-            {
-                break;
-            }
-            region = heap_segment_next (region);
-            if (region == nullptr)
-            {
-                region = get_new_region (0);
-                if (region == nullptr)
-                {
-                    break;
-                }
-                else
-                {
-                    GCToEEInterface::DiagAddNewRegion(
-                            0,
-                            heap_segment_mem (region),
-                            heap_segment_allocated (region),
-                            heap_segment_reserved (region)
-                        );
-                }
-            }
-        }
-        else
-        {
-            break;
-        }
-    }
-    return (required == 0);
-}
-#else
-BOOL gc_heap::expand_soh_with_minimal_gc()
-{
-    if ((size_t)(heap_segment_reserved (ephemeral_heap_segment) - heap_segment_allocated (ephemeral_heap_segment)) >= soh_allocation_no_gc)
-        return TRUE;
-    heap_segment* new_seg = soh_get_segment_to_expand();
-    if (new_seg)
-    {
-        if (g_gc_card_table != card_table)
-            copy_brick_card_table();
-        settings.promotion = TRUE;
-        settings.demotion = FALSE;
-        ephemeral_promotion = TRUE;
-        int condemned_gen_number = max_generation - 1;
-        int align_const = get_alignment_constant (TRUE);
-        for (int i = 0; i <= condemned_gen_number; i++)
-        {
-            generation* gen = generation_of (i);
-            saved_ephemeral_plan_start[i] = generation_allocation_start (gen);
-            saved_ephemeral_plan_start_size[i] = Align (size (generation_allocation_start (gen)), align_const);
-        }
-        for (size_t b = brick_of (generation_allocation_start (generation_of (0)));
-             b < brick_of (align_on_brick (heap_segment_allocated (ephemeral_heap_segment)));
-             b++)
-        {
-            set_brick (b, -1);
-        }
-        size_t ephemeral_size = (heap_segment_allocated (ephemeral_heap_segment) -
-                                generation_allocation_start (generation_of (max_generation - 1)));
-        heap_segment_next (ephemeral_heap_segment) = new_seg;
-        ephemeral_heap_segment = new_seg;
-        uint8_t*  start = heap_segment_mem (ephemeral_heap_segment);
-        for (int i = condemned_gen_number; i >= 0; i--)
-        {
-            size_t gen_start_size = Align (min_obj_size);
-            make_generation (i, ephemeral_heap_segment, start);
-            generation* gen = generation_of (i);
-            generation_plan_allocation_start (gen) = start;
-            generation_plan_allocation_start_size (gen) = gen_start_size;
-            start += gen_start_size;
-        }
-        heap_segment_used (ephemeral_heap_segment) = start - plug_skew;
-        heap_segment_plan_allocated (ephemeral_heap_segment) = start;
-        fix_generation_bounds (condemned_gen_number, generation_of (0));
-        dd_gc_new_allocation (dynamic_data_of (max_generation)) -= ephemeral_size;
-        dd_new_allocation (dynamic_data_of (max_generation)) = dd_gc_new_allocation (dynamic_data_of (max_generation));
-        adjust_ephemeral_limits();
-        return TRUE;
-    }
-    else
-    {
-        return FALSE;
-    }
-}
-#endif //USE_REGIONS
-void gc_heap::check_and_set_no_gc_oom()
-{
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < n_heaps; i++)
-    {
-        gc_heap* hp = g_heaps[i];
-        if (hp->no_gc_oom_p)
-        {
-            current_no_gc_region_info.start_status = start_no_gc_no_memory;
-            hp->no_gc_oom_p = false;
-        }
-    }
-#else
-    if (no_gc_oom_p)
-    {
-        current_no_gc_region_info.start_status = start_no_gc_no_memory;
-        no_gc_oom_p = false;
-    }
-#endif //MULTIPLE_HEAPS
-}
-void gc_heap::allocate_for_no_gc_after_gc()
-{
-    if (current_no_gc_region_info.minimal_gc_p)
-        repair_allocation_contexts (TRUE);
-    no_gc_oom_p = false;
-    if (current_no_gc_region_info.start_status != start_no_gc_no_memory)
-    {
-        if (current_no_gc_region_info.soh_allocation_size != 0)
-        {
-#ifdef USE_REGIONS
-            no_gc_oom_p = !extend_soh_for_no_gc();
-#else
-            if (((size_t)(heap_segment_reserved (ephemeral_heap_segment) - heap_segment_allocated (ephemeral_heap_segment)) < soh_allocation_no_gc) ||
-                (!grow_heap_segment (ephemeral_heap_segment, (heap_segment_allocated (ephemeral_heap_segment) + soh_allocation_no_gc))))
-            {
-                no_gc_oom_p = true;
-            }
-#endif //USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-            gc_t_join.join(this, gc_join_after_commit_soh_no_gc);
-            if (gc_t_join.joined())
-#endif //MULTIPLE_HEAPS
-            {
-                check_and_set_no_gc_oom();
-#ifdef MULTIPLE_HEAPS
-                gc_t_join.restart();
-#endif //MULTIPLE_HEAPS
-            }
-        }
-        if ((current_no_gc_region_info.start_status == start_no_gc_success) &&
-            !(current_no_gc_region_info.minimal_gc_p) &&
-            (current_no_gc_region_info.loh_allocation_size != 0))
-        {
-            gc_policy = policy_compact;
-            saved_loh_segment_no_gc = 0;
-            if (!find_loh_free_for_no_gc())
-            {
-                heap_segment* seg = generation_allocation_segment (generation_of (loh_generation));
-                BOOL found_seg_p = FALSE;
-                while (seg)
-                {
-                    if ((size_t)(heap_segment_reserved (seg) - heap_segment_allocated (seg)) >= loh_allocation_no_gc)
-                    {
-                        found_seg_p = TRUE;
-                        if (!commit_loh_for_no_gc (seg))
-                        {
-                            no_gc_oom_p = true;
-                            break;
-                        }
-                    }
-                    seg = heap_segment_next (seg);
-                }
-                if (!found_seg_p)
-                    gc_policy = policy_expand;
-            }
-#ifdef MULTIPLE_HEAPS
-            gc_t_join.join(this, gc_join_expand_loh_no_gc);
-            if (gc_t_join.joined())
-            {
-                check_and_set_no_gc_oom();
-                if (current_no_gc_region_info.start_status == start_no_gc_success)
-                {
-                    for (int i = 0; i < n_heaps; i++)
-                    {
-                        gc_heap* hp = g_heaps[i];
-                        if (hp->gc_policy == policy_expand)
-                        {
-                            hp->saved_loh_segment_no_gc = get_segment_for_uoh (loh_generation, get_uoh_seg_size (loh_allocation_no_gc), hp);
-                            if (!(hp->saved_loh_segment_no_gc))
-                            {
-                                current_no_gc_region_info.start_status = start_no_gc_no_memory;
-                                break;
-                            }
-                        }
-                    }
-                }
-                gc_t_join.restart();
-            }
-#else //MULTIPLE_HEAPS
-            check_and_set_no_gc_oom();
-            if ((current_no_gc_region_info.start_status == start_no_gc_success) && (gc_policy == policy_expand))
-            {
-                saved_loh_segment_no_gc = get_segment_for_uoh (loh_generation, get_uoh_seg_size (loh_allocation_no_gc));
-                if (!saved_loh_segment_no_gc)
-                    current_no_gc_region_info.start_status = start_no_gc_no_memory;
-            }
-#endif //MULTIPLE_HEAPS
-            if ((current_no_gc_region_info.start_status == start_no_gc_success) && saved_loh_segment_no_gc)
-            {
-                if (!commit_loh_for_no_gc (saved_loh_segment_no_gc))
-                {
-                    no_gc_oom_p = true;
-                }
-            }
-        }
-    }
-#ifdef MULTIPLE_HEAPS
-    gc_t_join.join(this, gc_join_final_no_gc);
-    if (gc_t_join.joined())
-#endif //MULTIPLE_HEAPS
-    {
-        check_and_set_no_gc_oom();
-        if (current_no_gc_region_info.start_status == start_no_gc_success)
-        {
-            set_allocations_for_no_gc();
-            current_no_gc_region_info.started = TRUE;
-        }
-#ifdef MULTIPLE_HEAPS
-        gc_t_join.restart();
-#endif //MULTIPLE_HEAPS
-    }
-}
-void gc_heap::init_records()
-{
-    memset (&gc_data_per_heap, 0, sizeof (gc_data_per_heap));
-    gc_data_per_heap.heap_index = heap_number;
-    if (heap_number == 0)
-        memset (&gc_data_global, 0, sizeof (gc_data_global));
-#ifdef GC_CONFIG_DRIVEN
-    memset (interesting_data_per_gc, 0, sizeof (interesting_data_per_gc));
-#endif //GC_CONFIG_DRIVEN
-    memset (&fgm_result, 0, sizeof (fgm_result));
-    for (int i = 0; i < total_generation_count; i++)
-    {
-        gc_data_per_heap.gen_data[i].size_before = generation_size (i);
-        generation* gen = generation_of (i);
-        gc_data_per_heap.gen_data[i].free_list_space_before = generation_free_list_space (gen);
-        gc_data_per_heap.gen_data[i].free_obj_space_before = generation_free_obj_space (gen);
-    }
-#ifdef USE_REGIONS
-    end_gen0_region_space = uninitialized_end_gen0_region_space;
-    end_gen0_region_committed_space = 0;
-    gen0_pinned_free_space = 0;
-    gen0_large_chunk_found = false;
-    num_regions_freed_in_sweep = 0;
-#endif //USE_REGIONS
-    sufficient_gen0_space_p = FALSE;
-#ifdef MULTIPLE_HEAPS
-    gen0_allocated_after_gc_p = false;
-#endif //MULTIPLE_HEAPS
-#if defined (_DEBUG) && defined (VERIFY_HEAP)
-    verify_pinned_queue_p = FALSE;
-#endif // _DEBUG && VERIFY_HEAP
-}
-void gc_heap::pm_full_gc_init_or_clear()
-{
-    if (settings.condemned_generation == (max_generation - 1))
-    {
-        if (pm_trigger_full_gc)
-        {
-#ifdef MULTIPLE_HEAPS
-            do_post_gc();
-#endif //MULTIPLE_HEAPS
-            dprintf (GTC_LOG, ("init for PM triggered full GC"));
-            uint32_t saved_entry_memory_load = settings.entry_memory_load;
-            settings.init_mechanisms();
-            settings.reason = reason_pm_full_gc;
-            settings.condemned_generation = max_generation;
-            settings.entry_memory_load = saved_entry_memory_load;
-            assert (settings.entry_memory_load > 0);
-            settings.gc_index += 1;
-            do_pre_gc();
-        }
-    }
-    else if (settings.reason == reason_pm_full_gc)
-    {
-        assert (settings.condemned_generation == max_generation);
-        assert (pm_trigger_full_gc);
-        pm_trigger_full_gc = false;
-        dprintf (GTC_LOG, ("PM triggered full GC done"));
-    }
-}
-void gc_heap::garbage_collect_pm_full_gc()
-{
-    assert (settings.condemned_generation == max_generation);
-    assert (settings.reason == reason_pm_full_gc);
-    assert (!settings.concurrent);
-    gc1();
-}
-void gc_heap::garbage_collect (int n)
-{
-    gc_pause_mode saved_settings_pause_mode = settings.pause_mode;
-    alloc_contexts_used = 0;
-    fix_allocation_contexts (TRUE);
-#ifdef MULTIPLE_HEAPS
-#ifdef JOIN_STATS
-    gc_t_join.start_ts(this);
-#endif //JOIN_STATS
-    check_gen0_bricks();
-    clear_gen0_bricks();
-#endif //MULTIPLE_HEAPS
-    if ((settings.pause_mode == pause_no_gc) && current_no_gc_region_info.minimal_gc_p)
-    {
-#ifdef MULTIPLE_HEAPS
-        gc_t_join.join(this, gc_join_minimal_gc);
-        if (gc_t_join.joined())
-#endif //MULTIPLE_HEAPS
-        {
-#ifndef USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-            for (int i = 0; i < n_heaps; i++)
-            {
-                if (!(g_heaps[i]->expand_soh_with_minimal_gc()))
-                    current_no_gc_region_info.start_status = start_no_gc_no_memory;
-            }
-#else
-            if (!expand_soh_with_minimal_gc())
-                current_no_gc_region_info.start_status = start_no_gc_no_memory;
-#endif //MULTIPLE_HEAPS
-#endif //!USE_REGIONS
-            update_collection_counts_for_no_gc();
-#ifdef MULTIPLE_HEAPS
-            gc_start_event.Reset();
-            gc_t_join.restart();
-#endif //MULTIPLE_HEAPS
-        }
-        goto done;
-    }
-    init_records();
-    settings.reason = gc_trigger_reason;
-    num_pinned_objects = 0;
-#ifdef STRESS_HEAP
-    if (settings.reason == reason_gcstress)
-    {
-        settings.reason = reason_induced;
-        settings.stress_induced = TRUE;
-    }
-#endif // STRESS_HEAP
-#ifdef MULTIPLE_HEAPS
-#ifdef STRESS_DYNAMIC_HEAP_COUNT
-    Interlocked::Increment (&heaps_in_this_gc);
-#endif //STRESS_DYNAMIC_HEAP_COUNT
-    dprintf (3, ("Joining for max generation to condemn"));
-    condemned_generation_num = generation_to_condemn (n,
-                                                      &blocking_collection,
-                                                      &elevation_requested,
-                                                      FALSE);
-    gc_t_join.join(this, gc_join_generation_determined);
-    if (gc_t_join.joined())
-#endif //MULTIPLE_HEAPS
-    {
-#ifdef FEATURE_BASICFREEZE
-        seg_table->delete_old_slots();
-#endif //FEATURE_BASICFREEZE
-#ifndef USE_REGIONS
-        copy_brick_card_table_on_growth ();
-#endif //!USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-#ifdef STRESS_DYNAMIC_HEAP_COUNT
-        dprintf (9999, ("%d heaps, join sees %d, actually joined %d, %d idle threads (%d)",
-            n_heaps, gc_t_join.get_num_threads (), heaps_in_this_gc,
-            VolatileLoadWithoutBarrier(&dynamic_heap_count_data.idle_thread_count), (n_max_heaps - n_heaps)));
-        if (heaps_in_this_gc != n_heaps)
-        {
-            dprintf (9999, ("should have %d heaps but actually have %d!!", n_heaps, heaps_in_this_gc));
-            GCToOSInterface::DebugBreak ();
-        }
-        heaps_in_this_gc = 0;
-#endif //STRESS_DYNAMIC_HEAP_COUNT
-        for (int i = 0; i < n_heaps; i++)
-        {
-            gc_heap* hp = g_heaps[i];
-            hp->delay_free_segments();
-        }
-#else //MULTIPLE_HEAPS
-        delay_free_segments();
-#endif //MULTIPLE_HEAPS
-        BOOL should_evaluate_elevation = TRUE;
-        BOOL should_do_blocking_collection = FALSE;
-#ifdef MULTIPLE_HEAPS
-        int gen_max = condemned_generation_num;
-        for (int i = 0; i < n_heaps; i++)
-        {
-            if (gen_max < g_heaps[i]->condemned_generation_num)
-                gen_max = g_heaps[i]->condemned_generation_num;
-            if (should_evaluate_elevation && !(g_heaps[i]->elevation_requested))
-                should_evaluate_elevation = FALSE;
-            if ((!should_do_blocking_collection) && (g_heaps[i]->blocking_collection))
-                should_do_blocking_collection = TRUE;
-        }
-        settings.condemned_generation = gen_max;
-#else //MULTIPLE_HEAPS
-        settings.condemned_generation = generation_to_condemn (n,
-                                                            &blocking_collection,
-                                                            &elevation_requested,
-                                                            FALSE);
-        should_evaluate_elevation = elevation_requested;
-        should_do_blocking_collection = blocking_collection;
-#endif //MULTIPLE_HEAPS
-        settings.condemned_generation = joined_generation_to_condemn (
-                                            should_evaluate_elevation,
-                                            n,
-                                            settings.condemned_generation,
-                                            &should_do_blocking_collection
-                                            STRESS_HEAP_ARG(n)
-                                            );
-        STRESS_LOG1(LF_GCROOTS|LF_GC|LF_GCALLOC, LL_INFO10,
-                "condemned generation num: %d\n", settings.condemned_generation);
-        record_gcs_during_no_gc();
-        if (settings.condemned_generation > 1)
-            settings.promotion = TRUE;
-#ifdef HEAP_ANALYZE
-        if (GCToEEInterface::AnalyzeSurvivorsRequested(settings.condemned_generation))
-        {
-            heap_analyze_enabled = TRUE;
-        }
-#endif // HEAP_ANALYZE
-        GCToEEInterface::DiagGCStart(settings.condemned_generation, is_induced (settings.reason));
-#ifdef BACKGROUND_GC
-        if ((settings.condemned_generation == max_generation) &&
-            (should_do_blocking_collection == FALSE) &&
-            gc_can_use_concurrent &&
-            !temp_disable_concurrent_p &&
-            ((settings.pause_mode == pause_interactive) || (settings.pause_mode == pause_sustained_low_latency)))
-        {
-            keep_bgc_threads_p = TRUE;
-            c_write (settings.concurrent, TRUE);
-            memset (&bgc_data_global, 0, sizeof(bgc_data_global));
-            memcpy (&bgc_data_global, &gc_data_global, sizeof(gc_data_global));
-        }
-#endif //BACKGROUND_GC
-        settings.gc_index = (uint32_t)dd_collection_count (dynamic_data_of (0)) + 1;
-#ifdef MULTIPLE_HEAPS
-        hb_log_balance_activities();
-        hb_log_new_allocation();
-#endif //MULTIPLE_HEAPS
-        GCToEEInterface::GcStartWork (settings.condemned_generation,
-                                max_generation);
-        do_pre_gc();
-#ifdef MULTIPLE_HEAPS
-        dprintf (9999, ("in GC, resetting gc_start"));
-        gc_start_event.Reset();
-        dprintf(3, ("Starting all gc threads for gc"));
-        gc_t_join.restart();
-#endif //MULTIPLE_HEAPS
-    }
-    descr_generations ("BEGIN");
-#if defined(TRACE_GC) && defined(USE_REGIONS)
-    if (heap_number == 0)
-    {
-#ifdef MULTIPLE_HEAPS
-        for (int i = 0; i < n_heaps; i++)
-        {
-            gc_heap *hp = g_heaps[i];
-#else //MULTIPLE_HEAPS
-        {
-            gc_heap* hp = pGenGCHeap;
-            const int i = 0;
-#endif //MULTIPLE_HEAPS
-            if (settings.condemned_generation == max_generation)
-            {
-                region_free_list::print(hp->free_regions, i, "BEGIN");
-            }
-            else
-            {
-                hp->free_regions[basic_free_region].print (i, "BEGIN");
-            }
-        }
-    }
-#endif // TRACE_GC && USE_REGIONS
-#ifdef VERIFY_HEAP
-    if ((GCConfig::GetHeapVerifyLevel() & GCConfig::HEAPVERIFY_GC) &&
-       !(GCConfig::GetHeapVerifyLevel() & GCConfig::HEAPVERIFY_POST_GC_ONLY))
-    {
-        verify_heap (TRUE);
-    }
-    if (GCConfig::GetHeapVerifyLevel() & GCConfig::HEAPVERIFY_BARRIERCHECK)
-        checkGCWriteBarrier();
-#endif // VERIFY_HEAP
-#ifdef BACKGROUND_GC
-    if (settings.concurrent)
-    {
-        assert (settings.condemned_generation == max_generation);
-        settings.compaction = FALSE;
-        saved_bgc_settings = settings;
-#ifdef MULTIPLE_HEAPS
-        if (heap_number == 0)
-        {
-#ifdef DYNAMIC_HEAP_COUNT
-            size_t current_gc_index = VolatileLoadWithoutBarrier (&settings.gc_index);
-            if (!bgc_init_gc_index)
-            {
-                assert (!bgc_init_n_heaps);
-                bgc_init_gc_index = current_gc_index;
-                bgc_init_n_heaps = (short)n_heaps;
-            }
-            size_t saved_bgc_th_count_created = bgc_th_count_created;
-            size_t saved_bgc_th_count_created_th_existed = bgc_th_count_created_th_existed;
-            size_t saved_bgc_th_count_creation_failed = bgc_th_count_creation_failed;
-#endif //DYNAMIC_HEAP_COUNT
-            int total_bgc_threads_running = 0;
-            for (int i = 0; i < n_heaps; i++)
-            {
-                gc_heap* hp = g_heaps[i];
-                if (prepare_bgc_thread (hp))
-                {
-                    assert (hp->bgc_thread_running);
-                    if (!hp->bgc_thread_running)
-                    {
-                        dprintf (6666, ("h%d prepare succeeded but running is still false!", i));
-                        GCToOSInterface::DebugBreak();
-                    }
-                    total_bgc_threads_running++;
-                }
-                else
-                {
-                    break;
-                }
-            }
-#ifdef DYNAMIC_HEAP_COUNT
-            total_bgc_threads = max (total_bgc_threads, total_bgc_threads_running);
-            if (total_bgc_threads_running != n_heaps)
-            {
-                dprintf (6666, ("wanted to have %d BGC threads but only have %d", n_heaps, total_bgc_threads_running));
-            }
-            add_to_bgc_th_creation_history (current_gc_index,
-                (bgc_th_count_created - saved_bgc_th_count_created),
-                (bgc_th_count_created_th_existed - saved_bgc_th_count_created_th_existed),
-                (bgc_th_count_creation_failed - saved_bgc_th_count_creation_failed));
-#endif //DYNAMIC_HEAP_COUNT
-            dprintf (2, ("setting bgc_threads_sync_event"));
-            bgc_threads_sync_event.Set();
-        }
-        else
-        {
-            bgc_threads_sync_event.Wait(INFINITE, FALSE);
-            dprintf (2, ("bgc_threads_sync_event is signalled"));
-        }
-#else
-        prepare_bgc_thread(0);
-#endif //MULTIPLE_HEAPS
-#ifdef MULTIPLE_HEAPS
-        gc_t_join.join(this, gc_join_start_bgc);
-        if (gc_t_join.joined())
-#endif //MULTIPLE_HEAPS
-        {
-            do_concurrent_p = TRUE;
-            do_ephemeral_gc_p = FALSE;
-#ifdef MULTIPLE_HEAPS
-            dprintf(2, ("Joined to perform a background GC"));
-            for (int i = 0; i < n_heaps; i++)
-            {
-                gc_heap* hp = g_heaps[i];
-                if (!(hp->bgc_thread_running))
-                {
-                    assert (!(hp->bgc_thread));
-                }
-                if (!(hp->bgc_thread_running && hp->bgc_thread && hp->commit_mark_array_bgc_init()))
-                {
-                    do_concurrent_p = FALSE;
-                    break;
-                }
-                else
-                {
-                    hp->background_saved_lowest_address = hp->lowest_address;
-                    hp->background_saved_highest_address = hp->highest_address;
-                }
-            }
-#else
-            do_concurrent_p = (!!bgc_thread && commit_mark_array_bgc_init());
-            if (do_concurrent_p)
-            {
-                background_saved_lowest_address = lowest_address;
-                background_saved_highest_address = highest_address;
-            }
-#endif //MULTIPLE_HEAPS
-#ifdef DYNAMIC_HEAP_COUNT
-            dprintf (6666, ("last BGC saw %d heaps and %d total threads, currently %d heaps and %d total threads, %s BGC",
-                last_bgc_n_heaps, last_total_bgc_threads, n_heaps, total_bgc_threads, (do_concurrent_p ? "doing" : "not doing")));
-#endif //DYNAMIC_HEAP_COUNT
-            if (do_concurrent_p)
-            {
-#ifdef DYNAMIC_HEAP_COUNT
-                int diff = n_heaps - last_bgc_n_heaps;
-                if (diff > 0)
-                {
-                    int saved_idle_bgc_thread_count = dynamic_heap_count_data.idle_bgc_thread_count;
-                    int max_idle_event_count = min (n_heaps, last_total_bgc_threads);
-                    int idle_events_to_set = max_idle_event_count - last_bgc_n_heaps;
-                    if (idle_events_to_set > 0)
-                    {
-                        Interlocked::ExchangeAdd (&dynamic_heap_count_data.idle_bgc_thread_count, -idle_events_to_set);
-                        dprintf (6666, ("%d BGC threads exist, setting %d idle events for h%d-h%d, total idle %d -> %d",
-                            total_bgc_threads, idle_events_to_set, last_bgc_n_heaps, (last_bgc_n_heaps + idle_events_to_set - 1),
-                            saved_idle_bgc_thread_count, VolatileLoadWithoutBarrier (&dynamic_heap_count_data.idle_bgc_thread_count)));
-                        for (int heap_idx = last_bgc_n_heaps; heap_idx < max_idle_event_count; heap_idx++)
-                        {
-                            g_heaps[heap_idx]->bgc_idle_thread_event.Set();
-                        }
-                    }
-                }
-                last_bgc_n_heaps = n_heaps;
-                last_total_bgc_threads = total_bgc_threads;
-#endif //DYNAMIC_HEAP_COUNT
-#ifdef FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-                SoftwareWriteWatch::EnableForGCHeap();
-#endif //FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-#ifdef MULTIPLE_HEAPS
-                for (int i = 0; i < n_heaps; i++)
-                    g_heaps[i]->current_bgc_state = bgc_initialized;
-#else
-                current_bgc_state = bgc_initialized;
-#endif //MULTIPLE_HEAPS
-                int gen = check_for_ephemeral_alloc();
-                dont_restart_ee_p = TRUE;
-                if (gen == -1)
-                {
-#ifdef MULTIPLE_HEAPS
-                    for (int i = 0; i < n_heaps; i++)
-                    {
-                        generation_allocation_pointer (g_heaps[i]->generation_of (0)) =  0;
-                        generation_allocation_limit (g_heaps[i]->generation_of (0)) = 0;
-                    }
-#else
-                    generation_allocation_pointer (youngest_generation) =  0;
-                    generation_allocation_limit (youngest_generation) = 0;
-#endif //MULTIPLE_HEAPS
-                }
-                else
-                {
-                    do_ephemeral_gc_p = TRUE;
-                    settings.init_mechanisms();
-                    settings.condemned_generation = gen;
-#ifdef DYNAMIC_HEAP_COUNT
-                    if (trigger_bgc_for_rethreading_p)
-                    {
-                        settings.condemned_generation = 0;
-                    }
-#endif //DYNAMIC_HEAP_COUNT
-                    settings.gc_index = (size_t)dd_collection_count (dynamic_data_of (0)) + 2;
-                    do_pre_gc();
-                    dprintf (GTC_LOG, ("doing gen%d before doing a bgc", gen));
-                }
-                if (!do_ephemeral_gc_p)
-                {
-                    do_background_gc();
-                }
-            }
-            else
-            {
-                settings.compaction = TRUE;
-                c_write (settings.concurrent, FALSE);
-            }
-#ifdef MULTIPLE_HEAPS
-            gc_t_join.restart();
-#endif //MULTIPLE_HEAPS
-        }
-        if (do_concurrent_p)
-        {
-            memset (&bgc_data_per_heap, 0, sizeof (bgc_data_per_heap));
-            memcpy (&bgc_data_per_heap, &gc_data_per_heap, sizeof(gc_data_per_heap));
-            if (do_ephemeral_gc_p)
-            {
-                dprintf (2, ("GC threads running, doing gen%d GC", settings.condemned_generation));
-                gen_to_condemn_reasons.init();
-                gen_to_condemn_reasons.set_condition (gen_before_bgc);
-                gc_data_per_heap.gen_to_condemn_reasons.init (&gen_to_condemn_reasons);
-                gc1();
-#ifdef MULTIPLE_HEAPS
-                gc_t_join.join(this, gc_join_bgc_after_ephemeral);
-                if (gc_t_join.joined())
-#endif //MULTIPLE_HEAPS
-                {
-#ifdef MULTIPLE_HEAPS
-                    do_post_gc();
-#endif //MULTIPLE_HEAPS
-                    settings = saved_bgc_settings;
-                    assert (settings.concurrent);
-                    do_background_gc();
-#ifdef MULTIPLE_HEAPS
-                    gc_t_join.restart();
-#endif //MULTIPLE_HEAPS
-                }
-            }
-        }
-        else
-        {
-            dprintf (2, ("couldn't create BGC threads, reverting to doing a blocking GC"));
-            gc1();
-        }
-    }
-    else
-#endif //BACKGROUND_GC
-    {
-        gc1();
-    }
-#ifndef MULTIPLE_HEAPS
-    allocation_running_time = GCToOSInterface::GetLowPrecisionTimeStamp();
-    allocation_running_amount = dd_new_allocation (dynamic_data_of (0));
-    fgn_last_alloc = dd_new_allocation (dynamic_data_of (0));
-#endif //MULTIPLE_HEAPS
-done:
-    if (saved_settings_pause_mode == pause_no_gc)
-        allocate_for_no_gc_after_gc();
-}
-#define mark_stack_empty_p() (mark_stack_base == mark_stack_tos)
-inline
-size_t gc_heap::get_promoted_bytes()
-{
-#ifdef USE_REGIONS
-    if (!survived_per_region)
-    {
-        dprintf (REGIONS_LOG, ("no space to store promoted bytes"));
-        return 0;
-    }
-    dprintf (3, ("h%d getting surv", heap_number));
-    size_t promoted = 0;
-    for (size_t i = 0; i < region_count; i++)
-    {
-        if (survived_per_region[i] > 0)
-        {
-            heap_segment* region = get_region_at_index (i);
-            dprintf (REGIONS_LOG, ("h%d region[%zd] %p(g%d)(%s) surv: %zd(%p)",
-                heap_number, i,
-                heap_segment_mem (region),
-                heap_segment_gen_num (region),
-                (heap_segment_loh_p (region) ? "LOH" : (heap_segment_poh_p (region) ? "POH" :"SOH")),
-                survived_per_region[i],
-                &survived_per_region[i]));
-            promoted += survived_per_region[i];
-        }
-    }
-#ifdef _DEBUG
-    dprintf (REGIONS_LOG, ("h%d global recorded %zd, regions recorded %zd",
-        heap_number, promoted_bytes (heap_number), promoted));
-    assert (promoted_bytes (heap_number) == promoted);
-#endif //_DEBUG
-    return promoted;
-#else //USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-    return g_promoted [heap_number*16];
-#else //MULTIPLE_HEAPS
-    return g_promoted;
-#endif //MULTIPLE_HEAPS
-#endif //USE_REGIONS
-}
-#ifdef USE_REGIONS
-void gc_heap::sync_promoted_bytes()
-{
-    int condemned_gen_number = settings.condemned_generation;
-    int highest_gen_number = ((condemned_gen_number == max_generation) ?
-                              (total_generation_count - 1) : settings.condemned_generation);
-    int stop_gen_idx = get_stop_generation_index (condemned_gen_number);
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < n_heaps; i++)
-    {
-        gc_heap* hp = g_heaps[i];
-#else //MULTIPLE_HEAPS
-    {
-        gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-        for (int gen_idx = highest_gen_number; gen_idx >= stop_gen_idx; gen_idx--)
-        {
-            generation* condemned_gen = hp->generation_of (gen_idx);
-            heap_segment* current_region = heap_segment_rw (generation_start_segment (condemned_gen));
-            while (current_region)
-            {
-                size_t region_index = get_basic_region_index_for_address (heap_segment_mem (current_region));
-#ifdef MULTIPLE_HEAPS
-                size_t total_surv = 0;
-                size_t total_old_card_surv = 0;
-                for (int hp_idx = 0; hp_idx < n_heaps; hp_idx++)
-                {
-                    total_surv += g_heaps[hp_idx]->survived_per_region[region_index];
-                    total_old_card_surv += g_heaps[hp_idx]->old_card_survived_per_region[region_index];
-                }
-                heap_segment_survived (current_region) = total_surv;
-                heap_segment_old_card_survived (current_region) = (int)total_old_card_surv;
-#else
-                heap_segment_survived (current_region) = survived_per_region[region_index];
-                heap_segment_old_card_survived (current_region) =
-                    (int)(old_card_survived_per_region[region_index]);
-#endif //MULTIPLE_HEAPS
-                dprintf (REGIONS_LOG, ("region #%zd %p surv %zd, old card surv %d",
-                    region_index,
-                    heap_segment_mem (current_region),
-                    heap_segment_survived (current_region),
-                    heap_segment_old_card_survived (current_region)));
-                current_region = heap_segment_next (current_region);
-            }
-        }
-    }
-}
-#ifdef MULTIPLE_HEAPS
-void gc_heap::set_heap_for_contained_basic_regions (heap_segment* region, gc_heap* hp)
-{
-    uint8_t* region_start = get_region_start (region);
-    uint8_t* region_end = heap_segment_reserved (region);
-    int num_basic_regions = (int)((region_end - region_start) >> min_segment_size_shr);
-    for (int i = 0; i < num_basic_regions; i++)
-    {
-        uint8_t* basic_region_start = region_start + ((size_t)i << min_segment_size_shr);
-        heap_segment* basic_region = get_region_info (basic_region_start);
-        heap_segment_heap (basic_region) = hp;
-    }
-}
-heap_segment* gc_heap::unlink_first_rw_region (int gen_idx)
-{
-    generation* gen = generation_of (gen_idx);
-    heap_segment* prev_region = generation_tail_ro_region (gen);
-    heap_segment* region = nullptr;
-    if (prev_region)
-    {
-        assert (heap_segment_read_only_p (prev_region));
-        region = heap_segment_next (prev_region);
-        assert (region != nullptr);
-        if (heap_segment_next (region) == nullptr)
-        {
-            assert (region == generation_tail_region (gen));
-            return nullptr;
-        }
-        heap_segment_next (prev_region) = heap_segment_next (region);
-    }
-    else
-    {
-        region = generation_start_segment (gen);
-        assert (region != nullptr);
-        if (heap_segment_next (region) == nullptr)
-        {
-            assert (region == generation_tail_region (gen));
-            return nullptr;
-        }
-        generation_start_segment (gen) = heap_segment_next (region);
-    }
-    assert (region != generation_tail_region (gen));
-    assert (!heap_segment_read_only_p (region));
-    dprintf (REGIONS_LOG, ("unlink_first_rw_region on heap: %d gen: %d region: %p", heap_number, gen_idx, heap_segment_mem (region)));
-    int oh = heap_segment_oh (region);
-    dprintf(3, ("commit-accounting:  from %d to temp [%p, %p) for heap %d", oh, get_region_start (region), heap_segment_committed (region), this->heap_number));
-#ifdef _DEBUG
-    size_t committed = heap_segment_committed (region) - get_region_start (region);
-    if (committed > 0)
-    {
-        assert (this->committed_by_oh_per_heap[oh] >= committed);
-        this->committed_by_oh_per_heap[oh] -= committed;
-    }
-#endif //_DEBUG
-    set_heap_for_contained_basic_regions (region, nullptr);
-    return region;
-}
-void gc_heap::thread_rw_region_front (int gen_idx, heap_segment* region)
-{
-    generation* gen = generation_of (gen_idx);
-    assert (!heap_segment_read_only_p (region));
-    heap_segment* prev_region = generation_tail_ro_region (gen);
-    if (prev_region)
-    {
-        heap_segment_next (region) = heap_segment_next (prev_region);
-        heap_segment_next (prev_region) = region;
-    }
-    else
-    {
-        heap_segment_next (region) = generation_start_segment (gen);
-        generation_start_segment (gen) = region;
-    }
-    if (heap_segment_next (region) == nullptr)
-    {
-        generation_tail_region (gen) = region;
-    }
-    dprintf (REGIONS_LOG, ("thread_rw_region_front on heap: %d gen: %d region: %p", heap_number, gen_idx, heap_segment_mem (region)));
-    int oh = heap_segment_oh (region);
-    dprintf(3, ("commit-accounting:  from temp to %d [%p, %p) for heap %d", oh, get_region_start (region), heap_segment_committed (region), this->heap_number));
-#ifdef _DEBUG
-    size_t committed = heap_segment_committed (region) - get_region_start (region);
-    assert (heap_segment_heap (region) == nullptr);
-    this->committed_by_oh_per_heap[oh] += committed;
-#endif //_DEBUG
-    set_heap_for_contained_basic_regions (region, this);
-}
-#endif // MULTIPLE_HEAPS
-void gc_heap::equalize_promoted_bytes(int condemned_gen_number)
-{
-#ifdef MULTIPLE_HEAPS
-    int highest_gen_number = ((condemned_gen_number == max_generation) ?
-        (total_generation_count - 1) : condemned_gen_number);
-    int stop_gen_idx = get_stop_generation_index (condemned_gen_number);
-    for (int gen_idx = highest_gen_number; gen_idx >= stop_gen_idx; gen_idx--)
-    {
-        size_t total_surv = 0;
-        size_t max_surv_per_heap = 0;
-        size_t surv_per_heap[MAX_SUPPORTED_CPUS];
-        for (int i = 0; i < n_heaps; i++)
-        {
-            surv_per_heap[i] = 0;
-            gc_heap* hp = g_heaps[i];
-            generation* condemned_gen = hp->generation_of (gen_idx);
-            heap_segment* current_region = heap_segment_rw (generation_start_segment (condemned_gen));
-            while (current_region)
-            {
-                total_surv += heap_segment_survived (current_region);
-                surv_per_heap[i] += heap_segment_survived (current_region);
-                current_region = heap_segment_next (current_region);
-            }
-            max_surv_per_heap = max (max_surv_per_heap, surv_per_heap[i]);
-            dprintf (REGIONS_LOG, ("gen: %d heap %d surv: %zd", gen_idx, i, surv_per_heap[i]));
-        }
-        size_t avg_surv_per_heap = (total_surv + n_heaps - 1) / n_heaps;
-        if (avg_surv_per_heap != 0)
-        {
-            dprintf (REGIONS_LOG, ("before equalize: gen: %d avg surv: %zd max_surv: %zd imbalance: %zd", gen_idx, avg_surv_per_heap, max_surv_per_heap, max_surv_per_heap*100/avg_surv_per_heap));
-        }
-        heap_segment* surplus_regions = nullptr;
-        size_t max_deficit = 0;
-        size_t max_survived = 0;
-        for (int i = 0; i < n_heaps; i++)
-        {
-            while (surv_per_heap[i] > avg_surv_per_heap)
-            {
-                heap_segment* region = g_heaps[i]->unlink_first_rw_region (gen_idx);
-                if (region == nullptr)
-                {
-                    break;
-                }
-                assert (surv_per_heap[i] >= heap_segment_survived (region));
-                dprintf (REGIONS_LOG, ("heap: %d surv: %zd - %zd = %zd",
-                    i,
-                    surv_per_heap[i],
-                    heap_segment_survived (region),
-                    surv_per_heap[i] - heap_segment_survived (region)));
-                surv_per_heap[i] -= heap_segment_survived (region);
-                heap_segment_next (region) = surplus_regions;
-                surplus_regions = region;
-                max_survived = max (max_survived, heap_segment_survived (region));
-            }
-            if (surv_per_heap[i] < avg_surv_per_heap)
-            {
-                size_t deficit = avg_surv_per_heap - surv_per_heap[i];
-                max_deficit = max (max_deficit, deficit);
-            }
-        }
-        for (int i = 0; i < n_heaps; i++)
-        {
-            gc_heap* hp = g_heaps[i];
-            generation* gen = hp->generation_of (gen_idx);
-            if (heap_segment_rw (generation_start_segment (gen)) == nullptr)
-            {
-                heap_segment* start_region = surplus_regions;
-                if (start_region != nullptr)
-                {
-                    surplus_regions = heap_segment_next (start_region);
-                }
-                else
-                {
-                    for (int j = 0; j < n_heaps; j++)
-                    {
-                        start_region = g_heaps[j]->unlink_first_rw_region (gen_idx);
-                        if (start_region != nullptr)
-                        {
-                            surv_per_heap[j] -= heap_segment_survived (start_region);
-                            size_t deficit = avg_surv_per_heap - surv_per_heap[j];
-                            max_deficit = max (max_deficit, deficit);
-                            break;
-                        }
-                    }
-                }
-                assert (start_region);
-                dprintf (3, ("making sure heap %d gen %d has at least one region by adding region %zx", start_region));
-                heap_segment_next (start_region) = nullptr;
-                assert (heap_segment_heap (start_region) == nullptr && hp != nullptr);
-                int oh = heap_segment_oh (start_region);
-                size_t committed = heap_segment_committed (start_region) - get_region_start (start_region);
-                dprintf(3, ("commit-accounting:  from temp to %d [%p, %p) for heap %d", oh, get_region_start (start_region), heap_segment_committed (start_region), hp->heap_number));
-#ifdef _DEBUG
-                g_heaps[hp->heap_number]->committed_by_oh_per_heap[oh] += committed;
-#endif //_DEBUG
-                set_heap_for_contained_basic_regions (start_region, hp);
-                max_survived = max (max_survived, heap_segment_survived (start_region));
-                hp->thread_start_region (gen, start_region);
-                surv_per_heap[i] += heap_segment_survived (start_region);
-            }
-        }
-        const int NUM_SIZE_CLASSES = 16;
-        heap_segment* surplus_regions_by_size_class[NUM_SIZE_CLASSES];
-        memset (surplus_regions_by_size_class, 0, sizeof(surplus_regions_by_size_class));
-        double survived_scale_factor = ((double)NUM_SIZE_CLASSES) / (max_survived + 1);
-        heap_segment* next_region;
-        for (heap_segment* region = surplus_regions; region != nullptr; region = next_region)
-        {
-            size_t size_class = (size_t)(heap_segment_survived (region)*survived_scale_factor);
-            assert ((0 <= size_class) && (size_class < NUM_SIZE_CLASSES));
-            next_region = heap_segment_next (region);
-            heap_segment_next (region) = surplus_regions_by_size_class[size_class];
-            surplus_regions_by_size_class[size_class] = region;
-        }
-        int next_heap_in_size_class[MAX_SUPPORTED_CPUS];
-        int heaps_by_deficit_size_class[NUM_SIZE_CLASSES];
-        for (int i = 0; i < NUM_SIZE_CLASSES; i++)
-        {
-            heaps_by_deficit_size_class[i] = -1;
-        }
-        double deficit_scale_factor = ((double)NUM_SIZE_CLASSES) / (max_deficit + 1);
-        for (int i = 0; i < n_heaps; i++)
-        {
-            if (avg_surv_per_heap > surv_per_heap[i])
-            {
-                size_t deficit = avg_surv_per_heap - surv_per_heap[i];
-                int size_class = (int)(deficit*deficit_scale_factor);
-                assert ((0 <= size_class) && (size_class < NUM_SIZE_CLASSES));
-                next_heap_in_size_class[i] = heaps_by_deficit_size_class[size_class];
-                heaps_by_deficit_size_class[size_class] = i;
-            }
-        }
-        int region_size_class = NUM_SIZE_CLASSES - 1;
-        int heap_size_class = NUM_SIZE_CLASSES - 1;
-        while (region_size_class >= 0)
-        {
-            heap_segment* region = surplus_regions_by_size_class[region_size_class];
-            if (region == nullptr)
-            {
-                region_size_class--;
-                continue;
-            }
-            int heap_num;
-            while (true)
-            {
-                if (heap_size_class < 0)
-                {
-                    heap_num = 0;
-                    break;
-                }
-                heap_num = heaps_by_deficit_size_class[heap_size_class];
-                if (heap_num >= 0)
-                {
-                    break;
-                }
-                heap_size_class--;
-            }
-            surplus_regions_by_size_class[region_size_class] = heap_segment_next (region);
-            g_heaps[heap_num]->thread_rw_region_front (gen_idx, region);
-            dprintf (REGIONS_LOG, ("heap: %d surv: %zd + %zd = %zd",
-                heap_num,
-                surv_per_heap[heap_num],
-                heap_segment_survived (region),
-                surv_per_heap[heap_num] + heap_segment_survived (region)));
-            surv_per_heap[heap_num] += heap_segment_survived (region);
-            if (heap_size_class < 0)
-            {
-                continue;
-            }
-            if (surv_per_heap[heap_num] >= avg_surv_per_heap)
-            {
-                heaps_by_deficit_size_class[heap_size_class] = next_heap_in_size_class[heap_num];
-                continue;
-            }
-            size_t new_deficit = avg_surv_per_heap - surv_per_heap[heap_num];
-            int new_heap_size_class = (int)(new_deficit*deficit_scale_factor);
-            if (new_heap_size_class != heap_size_class)
-            {
-                assert (new_heap_size_class < heap_size_class);
-                assert ((0 <= new_heap_size_class) && (new_heap_size_class < NUM_SIZE_CLASSES));
-                heaps_by_deficit_size_class[heap_size_class] = next_heap_in_size_class[heap_num];
-                next_heap_in_size_class[heap_num] = heaps_by_deficit_size_class[new_heap_size_class];
-                heaps_by_deficit_size_class[new_heap_size_class] = heap_num;
-            }
-        }
-        for (int i = 0; i < n_heaps; i++)
-        {
-            gc_heap* hp = g_heaps[i];
-            hp->verify_regions (gen_idx, true, true);
-        }
-#ifdef TRACE_GC
-        max_surv_per_heap = 0;
-        for (int i = 0; i < n_heaps; i++)
-        {
-            max_surv_per_heap = max (max_surv_per_heap, surv_per_heap[i]);
-        }
-        if (avg_surv_per_heap != 0)
-        {
-            dprintf (REGIONS_LOG, ("after equalize: gen: %d avg surv: %zd max_surv: %zd imbalance: %zd", gen_idx, avg_surv_per_heap, max_surv_per_heap, max_surv_per_heap*100/avg_surv_per_heap));
-        }
-#endif // TRACE_GC
-    }
-#endif //MULTIPLE_HEAPS
-}
-#ifdef DYNAMIC_HEAP_COUNT
-#define DECOMMISSIONED_VALUE 0xdec0dec0dec0dec0
-static const size_t DECOMMISSIONED_SIZE_T = DECOMMISSIONED_VALUE;
-static const ptrdiff_t DECOMMISSIONED_PTRDIFF_T = (ptrdiff_t)DECOMMISSIONED_VALUE;
-static const ptrdiff_t DECOMMISSIONED_UINT64_T = (uint64_t)DECOMMISSIONED_VALUE;
-static uint8_t* const DECOMMISSIONED_UINT8_T_P = (uint8_t*)DECOMMISSIONED_VALUE;
-static uint8_t** const DECOMMISSIONED_UINT8_T_PP = (uint8_t**)DECOMMISSIONED_VALUE;
-static PTR_heap_segment const DECOMMISSIONED_REGION_P = (PTR_heap_segment)DECOMMISSIONED_VALUE;
-static mark* const DECOMMISSIONED_MARK_P = (mark*)DECOMMISSIONED_VALUE;
-static const BOOL DECOMMISSIONED_BOOL = 0xdec0dec0;
-static const BOOL DECOMMISSIONED_INT = (int)0xdec0dec0;
-static const float DECOMMISSIONED_FLOAT = (float)DECOMMISSIONED_VALUE;
-static const ptrdiff_t UNINITIALIZED_VALUE  = 0xbaadbaadbaadbaad;
-void gc_heap::check_decommissioned_heap()
-{
-    assert (generation_skip_ratio               == DECOMMISSIONED_INT);
-    assert (gen0_must_clear_bricks              == DECOMMISSIONED_INT);
-    assert (freeable_uoh_segment                == DECOMMISSIONED_REGION_P);
-#ifdef BACKGROUND_GC
-    assert (freeable_soh_segment                == DECOMMISSIONED_REGION_P);
-#endif //BACKGROUND_GC
-#ifdef FEATURE_LOH_COMPACTION
-    assert (loh_pinned_queue_length             == DECOMMISSIONED_SIZE_T);
-    assert (loh_pinned_queue_decay              == DECOMMISSIONED_INT);
-    assert (loh_pinned_queue                    == DECOMMISSIONED_MARK_P);
-#endif //FEATURE_LOH_COMPACTION
-    assert (gen0_bricks_cleared                 == DECOMMISSIONED_BOOL);
-    assert (alloc_allocated                     == DECOMMISSIONED_UINT8_T_P);
-    assert (ephemeral_heap_segment              == DECOMMISSIONED_REGION_P);
-#ifdef USE_REGIONS
-#endif //USE_REGIONS
-    assert (more_space_lock_soh.lock            == lock_decommissioned);
-    assert (more_space_lock_uoh.lock            == lock_decommissioned);
-    assert (soh_allocation_no_gc                == DECOMMISSIONED_SIZE_T);
-    assert (loh_allocation_no_gc                == DECOMMISSIONED_SIZE_T);
-    for (int gen_idx = 0; gen_idx < total_generation_count; gen_idx++)
-    {
-        generation* gen = generation_of (gen_idx);
-        assert (generation_start_segment                   (gen) == DECOMMISSIONED_REGION_P);
-        assert (generation_allocation_segment              (gen) == DECOMMISSIONED_REGION_P);
-        assert (generation_tail_region                     (gen) == DECOMMISSIONED_REGION_P);
-        assert (generation_tail_ro_region                  (gen) == DECOMMISSIONED_REGION_P);
-        assert (generation_allocation_context_start_region (gen) == DECOMMISSIONED_UINT8_T_P);
-        assert (generation_free_list_allocated             (gen) == DECOMMISSIONED_SIZE_T);
-        assert (generation_end_seg_allocated               (gen) == DECOMMISSIONED_SIZE_T);
-        assert (generation_allocate_end_seg_p              (gen) == DECOMMISSIONED_BOOL);
-        assert (generation_condemned_allocated             (gen) == DECOMMISSIONED_SIZE_T);
-        assert (generation_sweep_allocated                 (gen) == DECOMMISSIONED_SIZE_T);
-        assert (generation_free_list_space                 (gen) == DECOMMISSIONED_SIZE_T);
-        assert (generation_free_obj_space                  (gen) == DECOMMISSIONED_SIZE_T);
-        assert (generation_allocation_size                 (gen) == DECOMMISSIONED_SIZE_T);
-        assert (generation_pinned_allocation_compact_size  (gen) == DECOMMISSIONED_SIZE_T);
-        assert (generation_pinned_allocation_sweep_size    (gen) == DECOMMISSIONED_SIZE_T);
-        assert (gen->gen_num                                     == DECOMMISSIONED_INT);
-#ifdef DOUBLY_LINKED_FL
-        assert (generation_set_bgc_mark_bit_p              (gen) == DECOMMISSIONED_BOOL);
-        assert (generation_last_free_list_allocated        (gen) == DECOMMISSIONED_UINT8_T_P);
-#endif //DOUBLY_LINKED_FL
-        dynamic_data* dd = dynamic_data_of (gen_idx);
-        assert (dd_new_allocation                  (dd) == DECOMMISSIONED_PTRDIFF_T);
-        assert (dd_gc_new_allocation               (dd) == DECOMMISSIONED_PTRDIFF_T);
-        assert (dd_surv                     (dd) == (float)DECOMMISSIONED_VALUE);
-        assert (dd_desired_allocation              (dd) == DECOMMISSIONED_SIZE_T);
-        assert (dd_begin_data_size                 (dd) == DECOMMISSIONED_SIZE_T);
-        assert (dd_survived_size                   (dd) == DECOMMISSIONED_SIZE_T);
-        assert (dd_pinned_survived_size            (dd) == DECOMMISSIONED_SIZE_T);
-        assert (dd_artificial_pinned_survived_size (dd) == DECOMMISSIONED_SIZE_T);
-        assert (dd_added_pinned_size               (dd) == DECOMMISSIONED_SIZE_T);
-#ifdef SHORT_PLUGS
-        assert (dd_padding_size                    (dd) == DECOMMISSIONED_SIZE_T);
-#endif //SHORT_PLUGS
-#if defined (RESPECT_LARGE_ALIGNMENT) || defined (FEATURE_STRUCTALIGN)
-        assert (dd_num_npinned_plugs               (dd) == DECOMMISSIONED_SIZE_T);
-#endif //RESPECT_LARGE_ALIGNMENT || FEATURE_STRUCTALIGN
-        assert (dd_current_size                    (dd) == DECOMMISSIONED_SIZE_T);
-        assert (dd_collection_count                (dd) == DECOMMISSIONED_SIZE_T);
-        assert (dd_promoted_size                   (dd) == DECOMMISSIONED_SIZE_T);
-        assert (dd_freach_previous_promotion       (dd) == DECOMMISSIONED_SIZE_T);
-        assert (dd_fragmentation                   (dd) == DECOMMISSIONED_SIZE_T);
-        assert (dd_gc_clock                        (dd) == DECOMMISSIONED_SIZE_T);
-        assert (dd_time_clock                      (dd) == DECOMMISSIONED_SIZE_T);
-        assert (dd_previous_time_clock             (dd) == DECOMMISSIONED_SIZE_T);
-        assert (dd_gc_elapsed_time                 (dd) == DECOMMISSIONED_SIZE_T);
-    }
-}
-void gc_heap::decommission_heap()
-{
-    set_gc_done();
-    generation_skip_ratio               = DECOMMISSIONED_INT;
-    gen0_must_clear_bricks              = DECOMMISSIONED_INT;
-    freeable_uoh_segment                = DECOMMISSIONED_REGION_P;
-    memset ((void *)gen2_alloc_list, DECOMMISSIONED_INT, sizeof(gen2_alloc_list[0])*(NUM_GEN2_ALIST - 1));
-#ifdef BACKGROUND_GC
-    freeable_soh_segment                = DECOMMISSIONED_REGION_P;
-#endif //BACKGROUND_GC
-#ifdef FEATURE_LOH_COMPACTION
-    loh_pinned_queue_length             = DECOMMISSIONED_SIZE_T;
-    loh_pinned_queue_decay              = DECOMMISSIONED_INT;
-    loh_pinned_queue                    = DECOMMISSIONED_MARK_P;
-#endif //FEATURE_LOH_COMPACTION
-    gen0_bricks_cleared                 = DECOMMISSIONED_BOOL;
-    memset ((void *)loh_alloc_list, DECOMMISSIONED_INT, sizeof(loh_alloc_list));
-    memset ((void *)poh_alloc_list, DECOMMISSIONED_INT, sizeof(poh_alloc_list));
-    alloc_allocated                     = DECOMMISSIONED_UINT8_T_P;
-    ephemeral_heap_segment              = DECOMMISSIONED_REGION_P;
-#ifdef USE_REGIONS
-    memset ((void *)free_regions, DECOMMISSIONED_INT, sizeof(free_regions));
-#endif //USE_REGIONS
-    assert (more_space_lock_soh.lock    == lock_free);
-    more_space_lock_soh.lock            = lock_decommissioned;
-    assert (more_space_lock_uoh.lock    == lock_free);
-    more_space_lock_uoh.lock            = lock_decommissioned;
-    soh_allocation_no_gc                = DECOMMISSIONED_SIZE_T;
-    loh_allocation_no_gc                = DECOMMISSIONED_SIZE_T;
-    for (int gen_idx = 0; gen_idx < total_generation_count; gen_idx++)
-    {
-        generation* gen = generation_of (gen_idx);
-        generation_allocator (gen)->clear();
-        memset (generation_alloc_context           (gen),  DECOMMISSIONED_INT, sizeof(alloc_context));
-        generation_start_segment                   (gen) = DECOMMISSIONED_REGION_P;
-        generation_allocation_segment              (gen) = DECOMMISSIONED_REGION_P;
-        generation_allocation_context_start_region (gen) = DECOMMISSIONED_UINT8_T_P;
-        generation_tail_region                     (gen) = DECOMMISSIONED_REGION_P;
-        generation_tail_ro_region                  (gen) = DECOMMISSIONED_REGION_P;
-        generation_free_list_allocated             (gen) = DECOMMISSIONED_SIZE_T;
-        generation_end_seg_allocated               (gen) = DECOMMISSIONED_SIZE_T;
-        generation_allocate_end_seg_p              (gen) = DECOMMISSIONED_BOOL;
-        generation_condemned_allocated             (gen) = DECOMMISSIONED_SIZE_T;
-        generation_sweep_allocated                 (gen) = DECOMMISSIONED_SIZE_T;
-        generation_free_list_space                 (gen) = DECOMMISSIONED_SIZE_T;
-        generation_free_obj_space                  (gen) = DECOMMISSIONED_SIZE_T;
-        generation_allocation_size                 (gen) = DECOMMISSIONED_SIZE_T;
-        generation_pinned_allocation_compact_size  (gen) = DECOMMISSIONED_SIZE_T;
-        generation_pinned_allocation_sweep_size    (gen) = DECOMMISSIONED_SIZE_T;
-        gen->gen_num                                     = DECOMMISSIONED_INT;
-#ifdef DOUBLY_LINKED_FL
-        generation_set_bgc_mark_bit_p              (gen) = DECOMMISSIONED_BOOL;
-        generation_last_free_list_allocated        (gen) = DECOMMISSIONED_UINT8_T_P;
-#endif //DOUBLY_LINKED_FL
-        dynamic_data* dd = dynamic_data_of (gen_idx);
-        dd_new_allocation                  (dd) = DECOMMISSIONED_SIZE_T;
-        dd_gc_new_allocation               (dd) = DECOMMISSIONED_PTRDIFF_T;
-        dd_surv                     (dd) = (float)DECOMMISSIONED_VALUE;
-        dd_desired_allocation              (dd) = DECOMMISSIONED_SIZE_T;
-        dd_begin_data_size                 (dd) = DECOMMISSIONED_SIZE_T;
-        dd_survived_size                   (dd) = DECOMMISSIONED_SIZE_T;
-        dd_pinned_survived_size            (dd) = DECOMMISSIONED_SIZE_T;
-        dd_artificial_pinned_survived_size (dd) = DECOMMISSIONED_SIZE_T;
-        dd_added_pinned_size               (dd) = DECOMMISSIONED_SIZE_T;
-#ifdef SHORT_PLUGS
-        dd_padding_size                    (dd) = DECOMMISSIONED_SIZE_T;
-#endif //SHORT_PLUGS
-#if defined (RESPECT_LARGE_ALIGNMENT) || defined (FEATURE_STRUCTALIGN)
-        dd_num_npinned_plugs               (dd) = DECOMMISSIONED_SIZE_T;
-#endif //RESPECT_LARGE_ALIGNMENT || FEATURE_STRUCTALIGN
-        dd_current_size                    (dd) = DECOMMISSIONED_SIZE_T;
-        dd_collection_count                (dd) = DECOMMISSIONED_SIZE_T;
-        dd_promoted_size                   (dd) = DECOMMISSIONED_SIZE_T;
-        dd_freach_previous_promotion       (dd) = DECOMMISSIONED_SIZE_T;
-        dd_fragmentation                   (dd) = DECOMMISSIONED_SIZE_T;
-        dd_gc_clock                        (dd) = DECOMMISSIONED_SIZE_T;
-        dd_time_clock                      (dd) = DECOMMISSIONED_SIZE_T;
-        dd_previous_time_clock             (dd) = DECOMMISSIONED_SIZE_T;
-        dd_gc_elapsed_time                 (dd) = DECOMMISSIONED_SIZE_T;
-    }
-}
-void gc_heap::recommission_heap()
-{
-    generation_skip_ratio               = 100;
-    gen0_must_clear_bricks              = 0;
-    freeable_uoh_segment                = nullptr;
-    memset ((void *)gen2_alloc_list, 0, sizeof(gen2_alloc_list));
-#ifdef BACKGROUND_GC
-    freeable_soh_segment                = nullptr;
-#endif //BACKGROUND_GC
-#ifdef FEATURE_LOH_COMPACTION
-    loh_pinned_queue_length             = 0;
-    loh_pinned_queue_decay              = 0;
-    loh_pinned_queue                    = 0;
-#endif //FEATURE_LOH_COMPACTION
-    gen0_bricks_cleared                 = FALSE;
-    memset ((void *)loh_alloc_list, 0, sizeof(loh_alloc_list));
-    memset ((void *)poh_alloc_list, 0, sizeof(poh_alloc_list));
-    alloc_allocated                     = 0;
-    ephemeral_heap_segment              = nullptr;
-    for (int kind = 0; kind < count_free_region_kinds; kind++)
-    {
-        free_regions[kind].reset();
-    }
-    more_space_lock_soh.lock            = lock_free;
-    more_space_lock_uoh.lock            = lock_free;
-    soh_allocation_no_gc                = 0;
-    loh_allocation_no_gc                = 0;
-#ifdef BACKGROUND_GC
-    bgc_alloc_lock->init();
-#endif //BACKGROUND_GC
-    gc_heap* heap0 = g_heaps[0];
-    for (int gen_idx = 0; gen_idx < total_generation_count; gen_idx++)
-    {
-        generation* gen = generation_of (gen_idx);
-        generation_allocator (gen)->clear();
-        memset (generation_alloc_context           (gen), 0, sizeof(alloc_context));
-        generation_start_segment                   (gen) = nullptr;
-        generation_tail_ro_region                  (gen) = nullptr;
-        generation_tail_region                     (gen) = nullptr;
-        generation_allocation_segment              (gen) = nullptr;
-        generation_allocation_context_start_region (gen) = nullptr;
-        generation_free_list_allocated             (gen) = 0;
-        generation_end_seg_allocated               (gen) = 0;
-        generation_allocate_end_seg_p              (gen) = 0;
-        generation_condemned_allocated             (gen) = 0;
-        generation_sweep_allocated                 (gen) = 0;
-        generation_free_list_space                 (gen) = 0;
-        generation_free_obj_space                  (gen) = 0;
-        generation_allocation_size                 (gen) = 0;
-        generation_pinned_allocation_compact_size  (gen) = 0;
-        generation_pinned_allocation_sweep_size    (gen) = 0;
-        gen->gen_num                                     = gen_idx;
-#ifdef DOUBLY_LINKED_FL
-        generation_set_bgc_mark_bit_p              (gen) = FALSE;
-        generation_last_free_list_allocated        (gen) = nullptr;
-#endif //DOUBLY_LINKED_FL
-        dynamic_data* dd = dynamic_data_of (gen_idx);
-        dynamic_data* heap0_dd = heap0->dynamic_data_of (gen_idx);
-        dd_time_clock     (dd) = dd_time_clock (heap0_dd);
-        dd_collection_count (dd) = dd_collection_count (heap0_dd);
-        dd_promoted_size                   (dd) = 0;
-        dd_fragmentation                   (dd) = 0;
-        dd_gc_clock                        (dd) = dd_gc_clock (heap0_dd);
-        dd_new_allocation                  (dd) = UNINITIALIZED_VALUE;
-        dd_desired_allocation              (dd) = UNINITIALIZED_VALUE;
-        dd_gc_new_allocation               (dd) = UNINITIALIZED_VALUE;
-        dd_surv                     (dd) = (float)UNINITIALIZED_VALUE;
-        dd_begin_data_size                 (dd) = UNINITIALIZED_VALUE;
-        dd_survived_size                   (dd) = UNINITIALIZED_VALUE;
-        dd_pinned_survived_size            (dd) = UNINITIALIZED_VALUE;
-        dd_artificial_pinned_survived_size (dd) = UNINITIALIZED_VALUE;
-        dd_added_pinned_size               (dd) = UNINITIALIZED_VALUE;
-#ifdef SHORT_PLUGS
-        dd_padding_size                    (dd) = UNINITIALIZED_VALUE;
-#endif //SHORT_PLUGS
-#if defined (RESPECT_LARGE_ALIGNMENT) || defined (FEATURE_STRUCTALIGN)
-        dd_num_npinned_plugs               (dd) = UNINITIALIZED_VALUE;
-#endif //RESPECT_LARGE_ALIGNMENT || FEATURE_STRUCTALIGN
-        dd_current_size                    (dd) = UNINITIALIZED_VALUE;
-        dd_freach_previous_promotion       (dd) = UNINITIALIZED_VALUE;
-        dd_previous_time_clock             (dd) = UNINITIALIZED_VALUE;
-        dd_gc_elapsed_time                 (dd) = UNINITIALIZED_VALUE;
-    }
-#ifdef SPINLOCK_HISTORY
-    spinlock_info_index = 0;
-    current_uoh_alloc_state = (allocation_state)-1;
-#endif //SPINLOCK_HISTORY
-#ifdef RECORD_LOH_STATE
-    loh_state_index = 0;
-#endif //RECORD_LOH_STATE
-}
-float median_of_3 (float a, float b, float c)
-{
-#define compare_and_swap(i, j)          \
-        {                               \
-            if (i < j)                  \
-            {                           \
-                float t = i;            \
-                          i = j;        \
-                              j = t;    \
-            }                           \
-        }
-    compare_and_swap (b, a);
-    compare_and_swap (c, a);
-    compare_and_swap (c, b);
-#undef compare_and_swap
-    return b;
-}
-float log_with_base (float x, float base)
-{
-    assert (x > base);
-    return (float)(log(x) / log(base));
-}
-float mean (float* arr, int size)
-{
-    float sum = 0.0;
-    for (int i = 0; i < size; i++)
-    {
-        sum += arr[i];
-    }
-    return (sum / size);
-}
-int max_times_to_print_tcp = 0;
-float gc_heap::dynamic_heap_count_data_t::slope (float* y, int n, float* avg)
-{
-    assert (n > 0);
-    if (n == 1)
-    {
-        dprintf (6666, ("only 1 tcp: %.3f, no slope", y[0]));
-        *avg = y[0];
-        return 0.0;
-    }
-    int sum_x = 0;
-    for (int i = 0; i < n; i++)
-    {
-        sum_x += i;
-        if (max_times_to_print_tcp >= 0)
-        {
-            dprintf (6666, ("%.3f, ", y[i]));
-        }
-    }
-    float avg_x = (float)sum_x / n;
-    float avg_y = mean (y, n);
-    *avg = avg_y;
-    float numerator = 0.0;
-    float denominator = 0.0;
-    for (int i = 0; i < n; ++i)
-    {
-        numerator += ((float)i - avg_x) * (y[i] - avg_y);
-        denominator += ((float)i - avg_x) * (i - avg_x);
-    }
-    max_times_to_print_tcp--;
-    return (numerator / denominator);
-}
-void gc_heap::calculate_new_heap_count ()
-{
-    assert (dynamic_adaptation_mode == dynamic_adaptation_to_application_sizes);
-    dprintf (6666, ("current num of samples %Id (g2: %Id) prev processed %Id (g2: %Id), last full GC happened at index %Id",
-        dynamic_heap_count_data.current_samples_count, dynamic_heap_count_data.current_gen2_samples_count,
-        dynamic_heap_count_data.processed_samples_count, dynamic_heap_count_data.processed_gen2_samples_count, gc_index_full_gc_end));
-    if ((dynamic_heap_count_data.current_samples_count < (dynamic_heap_count_data.processed_samples_count + dynamic_heap_count_data_t::sample_size)) &&
-        (dynamic_heap_count_data.current_gen2_samples_count < (dynamic_heap_count_data.processed_gen2_samples_count + dynamic_heap_count_data_t::sample_size)))
-    {
-        dprintf (6666, ("not enough GCs, skipping"));
-        return;
-    }
-    bool process_eph_samples_p = (dynamic_heap_count_data.current_samples_count >= (dynamic_heap_count_data.processed_samples_count + dynamic_heap_count_data_t::sample_size));
-    bool process_gen2_samples_p = (dynamic_heap_count_data.current_gen2_samples_count >= (dynamic_heap_count_data.processed_gen2_samples_count + dynamic_heap_count_data_t::sample_size));
-    size_t current_gc_index = VolatileLoadWithoutBarrier (&settings.gc_index);
-    float median_gen2_tcp = 0.0f;
-    if (dynamic_heap_count_data.current_gen2_samples_count >= (dynamic_heap_count_data.processed_gen2_samples_count + dynamic_heap_count_data_t::sample_size))
-    {
-        median_gen2_tcp = dynamic_heap_count_data.get_median_gen2_gc_percent ();
-    }
-    float throughput_cost_percents[dynamic_heap_count_data_t::sample_size];
-    if (process_eph_samples_p)
-    {
-        for (int i = 0; i < dynamic_heap_count_data_t::sample_size; i++)
-        {
-            dynamic_heap_count_data_t::sample& sample = dynamic_heap_count_data.samples[i];
-            assert (sample.elapsed_between_gcs > 0);
-            throughput_cost_percents[i] = (sample.elapsed_between_gcs ? (((float)sample.msl_wait_time / n_heaps + sample.gc_pause_time) * 100.0f / (float)sample.elapsed_between_gcs) : 0.0f);
-            assert (throughput_cost_percents[i] >= 0.0);
-            if (throughput_cost_percents[i] > 100.0)
-                throughput_cost_percents[i] = 100.0;
-            dprintf (6666, ("sample %d in GC#%Id msl %I64d / %d + pause %I64d / elapsed %I64d = tcp: %.3f, surv %zd, gc speed %zd/ms", i,
-                sample.gc_index, sample.msl_wait_time, n_heaps, sample.gc_pause_time, sample.elapsed_between_gcs, throughput_cost_percents[i],
-                sample.gc_survived_size, (sample.gc_pause_time ? (sample.gc_survived_size * 1000 / sample.gc_pause_time) : 0)));
-        }
-    }
-    float median_throughput_cost_percent = median_of_3 (throughput_cost_percents[0], throughput_cost_percents[1], throughput_cost_percents[2]);
-    float avg_throughput_cost_percent = (float)((throughput_cost_percents[0] + throughput_cost_percents[1] + throughput_cost_percents[2]) / 3.0);
-    float min_tcp = throughput_cost_percents[0];
-    size_t min_survived = dynamic_heap_count_data.samples[0].gc_survived_size;
-    uint64_t min_pause = dynamic_heap_count_data.samples[0].gc_pause_time;
-    for (int i = 1; i < dynamic_heap_count_data_t::sample_size; i++)
-    {
-        min_tcp = min (throughput_cost_percents[i], min_tcp);
-        min_survived = min (dynamic_heap_count_data.samples[i].gc_survived_size, min_survived);
-        min_pause = min (dynamic_heap_count_data.samples[i].gc_pause_time, min_pause);
-    }
-    dprintf (6666, ("checking if samples are stable %Id %Id %Id, min tcp %.3f, min pause %I64d",
-        dynamic_heap_count_data.samples[0].gc_survived_size, dynamic_heap_count_data.samples[1].gc_survived_size, dynamic_heap_count_data.samples[2].gc_survived_size,
-        min_tcp, min_pause));
-    bool survived_stable_p = true;
-    if (min_survived > 0)
-    {
-        for (int i = 0; i < dynamic_heap_count_data_t::sample_size; i++)
-        {
-            dynamic_heap_count_data_t::sample& sample = dynamic_heap_count_data.samples[i];
-            float diff = (float)(sample.gc_survived_size - min_survived) / (float)min_survived;
-            dprintf (6666, ("sample %d diff from min is %Id -> %.3f", i, (sample.gc_survived_size - min_survived), diff));
-            if (diff >= 0.15)
-            {
-                survived_stable_p = false;
-            }
-        }
-    }
-    if (survived_stable_p)
-    {
-        dprintf (6666, ("survived is stable, so we pick min tcp %.3f", min_tcp));
-        median_throughput_cost_percent = min_tcp;
-    }
-    dprintf (6666, ("median tcp: %.3f, avg tcp: %.3f, gen2 tcp %.3f(%.3f, %.3f, %.3f)",
-        median_throughput_cost_percent, avg_throughput_cost_percent, median_gen2_tcp,
-        dynamic_heap_count_data.gen2_samples[0].gc_percent, dynamic_heap_count_data.gen2_samples[1].gc_percent, dynamic_heap_count_data.gen2_samples[2].gc_percent));
-    int extra_heaps = (n_max_heaps >= 16) + (n_max_heaps >= 64);
-    int actual_n_max_heaps = n_max_heaps - extra_heaps;
-#ifdef STRESS_DYNAMIC_HEAP_COUNT
-    int new_n_heaps = (int)gc_rand::get_rand (n_max_heaps - 1) + 1;
-    if ((new_n_heaps < n_heaps) && (dynamic_heap_count_data.lowest_heap_with_msl_uoh != -1))
-    {
-        new_n_heaps = min (dynamic_heap_count_data.lowest_heap_with_msl_uoh, new_n_heaps);
-        new_n_heaps = max (new_n_heaps, 1);
-    }
-    dprintf (6666, ("stress %d -> %d", n_heaps, new_n_heaps));
-#else //STRESS_DYNAMIC_HEAP_COUNT
-    int new_n_heaps = n_heaps;
-    float target_tcp = dynamic_heap_count_data.target_tcp;
-    float target_gen2_tcp = dynamic_heap_count_data.target_gen2_tcp;
-    if (process_eph_samples_p)
-    {
-        dynamic_heap_count_data.add_to_recorded_tcp (median_throughput_cost_percent);
-        float tcp_to_consider = 0.0f;
-        int agg_factor = 0;
-        size_t total_soh_stable_size = 0;
-        int max_heap_count_datas = 0;
-        int min_heap_count_datas = 0;
-        dynamic_heap_count_data_t::adjust_metric adj_metric = dynamic_heap_count_data_t::adjust_metric::not_adjusted;
-        dynamic_heap_count_data_t::decide_change_condition change_decision = (dynamic_heap_count_data_t::decide_change_condition)0;
-        int recorded_tcp_count = 0;
-        float recorded_tcp_slope = 0.0f;
-        size_t num_gcs_since_last_change = 0;
-        float current_around_target_accumulation = 0.0f;
-        dynamic_heap_count_data_t::decide_adjustment_reason adj_reason = (dynamic_heap_count_data_t::decide_adjustment_reason)0;
-        int hc_change_freq_factor = 0;
-        dynamic_heap_count_data_t::hc_change_freq_reason hc_freq_reason = (dynamic_heap_count_data_t::hc_change_freq_reason)0;
-        if (dynamic_heap_count_data.should_change (median_throughput_cost_percent, &tcp_to_consider, current_gc_index,
-                                                   &change_decision, &recorded_tcp_count, &recorded_tcp_slope, &num_gcs_since_last_change, &current_around_target_accumulation))
-        {
-            total_soh_stable_size = get_total_soh_stable_size();
-            size_t total_bcd = dynamic_heap_count_data.compute_total_gen0_budget (total_soh_stable_size);
-            max_heap_count_datas = (int)(total_bcd / dynamic_heap_count_data.min_gen0_new_allocation);
-            min_heap_count_datas = (int)(total_bcd / dynamic_heap_count_data.max_gen0_new_allocation);
-            int max_heap_count_growth_step = dynamic_heap_count_data.get_max_growth (n_heaps);
-            int max_heap_count_growth_datas = max_heap_count_datas - n_heaps;
-            if (max_heap_count_growth_datas < 0)
-            {
-                max_heap_count_growth_datas = 0;
-            }
-            int max_heap_count_growth_core = actual_n_max_heaps - n_heaps;
-            int max_heap_count_growth = min (max_heap_count_growth_step, min (max_heap_count_growth_datas, max_heap_count_growth_core));
-            float distance = tcp_to_consider - target_tcp;
-            dprintf (6666, ("median tcp %.3f, recent tcp %.3f - target %.1f = %.3f", median_throughput_cost_percent, tcp_to_consider, target_tcp, distance));
-            float diff_pct = distance / target_tcp;
-            float hc_change_factor = (float)((diff_pct > 0.0) ? 1.5 : 3.0);
-            float change_float = diff_pct / hc_change_factor * (float)n_heaps;
-            float change_float_rounded = (float)round(change_float);
-            int change_int = (int)change_float_rounded;
-            dprintf (6666, ("diff pct %.3f / %.1f * %d = %d (%.3f), max hc allowed by datas %d | by core %d, max growth per step %d, max growth by datas %d | by core %d",
-                diff_pct, hc_change_factor, n_heaps, change_int, ((float)change_int / n_heaps), max_heap_count_datas, actual_n_max_heaps,
-                max_heap_count_growth_step, max_heap_count_growth_datas, max_heap_count_growth_core));
-            if (change_int > 0)
-            {
-                if (!max_heap_count_growth_datas && !(dynamic_heap_count_data.current_gen2_samples_count))
-                {
-                    trigger_initial_gen2_p = true;
-                    dprintf (6666, ("we want to grow but DATAS is limiting, trigger a gen2 right away"));
-#ifdef BACKGROUND_GC
-                    if (is_bgc_in_progress())
-                    {
-                        trigger_initial_gen2_p = false;
-                    }
-#endif //BACKGROUND_GC
-                }
-                agg_factor = dynamic_heap_count_data.get_aggressiveness (change_int);
-                if (agg_factor > 1)
-                {
-                    change_int *= agg_factor;
-                    dprintf (6666, ("agg factor is %d, change by %d heaps", agg_factor, change_int));
-                }
-            }
-            if (change_int)
-            {
-                adj_metric = dynamic_heap_count_data.should_change_hc (max_heap_count_datas, min_heap_count_datas,
-                                                                       max_heap_count_growth, change_int, current_gc_index,
-                                                                       &adj_reason, &hc_change_freq_factor, &hc_freq_reason);
-                if (adj_metric != dynamic_heap_count_data_t::adjust_metric::adjust_hc)
-                {
-                    change_int = 0;
-                }
-                if (adj_metric != dynamic_heap_count_data_t::adjust_metric::not_adjusted)
-                {
-                    if (adj_metric == dynamic_heap_count_data_t::adjust_metric::adjust_hc)
-                    {
-                        new_n_heaps = n_heaps + change_int;
-                    }
-                    dynamic_heap_count_data.record_adjustment (adj_metric, distance, change_int, current_gc_index);
-                }
-            }
-            dynamic_heap_count_data.reset_accumulation();
-            dprintf (6666, ("changing HC or budget %d -> %d at GC#%Id", n_heaps, new_n_heaps, current_gc_index));
-            dprintf (6666, ("total max gen %.3fmb, total bcd %.3fmb, diff %% %.3f-> +%d hc (%%%.3f)",
-                mb (total_soh_stable_size), mb (total_bcd), diff_pct, change_int, (change_int * 100.0 / n_heaps)));
-        }
-        GCEventFireSizeAdaptationTuning_V1 (
-            (uint16_t)new_n_heaps,
-            (uint16_t)max_heap_count_datas,
-            (uint16_t)min_heap_count_datas,
-            (uint64_t)current_gc_index,
-            (uint64_t)total_soh_stable_size,
-            (float)median_throughput_cost_percent,
-            (float)tcp_to_consider,
-            (float)current_around_target_accumulation,
-            (uint16_t)recorded_tcp_count,
-            (float)recorded_tcp_slope,
-            (uint32_t)num_gcs_since_last_change,
-            (uint8_t)agg_factor,
-            (uint16_t)change_decision,
-            (uint16_t)adj_reason,
-            (uint16_t)hc_change_freq_factor,
-            (uint16_t)hc_freq_reason,
-            (uint8_t)adj_metric);
-    }
-    size_t num_gen2s_since_last_change = 0;
-    if ((new_n_heaps == n_heaps) && !process_eph_samples_p && process_gen2_samples_p)
-    {
-        num_gen2s_since_last_change = dynamic_heap_count_data.current_gen2_samples_count - dynamic_heap_count_data.gen2_last_changed_sample_count;
-        if ((dynamic_heap_count_data.current_samples_count / dynamic_heap_count_data.current_gen2_samples_count) < 10)
-        {
-            int step_up = (n_heaps + 1) / 2;
-            int max_growth = max ((n_max_heaps / 4), (1 + (actual_n_max_heaps > 3)));
-            step_up = min (step_up, (actual_n_max_heaps - n_heaps));
-            int step_down = (n_heaps + 1) / 3;
-            if (median_gen2_tcp > target_gen2_tcp)
-            {
-                new_n_heaps += step_up;
-                new_n_heaps = min (new_n_heaps, actual_n_max_heaps);
-                dprintf (6666, ("[CHP2-0] gen2 tcp: %.3f, inc by %d + %d = %d", median_gen2_tcp, step_up, n_heaps, new_n_heaps));
-                if ((new_n_heaps < actual_n_max_heaps) && dynamic_heap_count_data.is_close_to_max (new_n_heaps, actual_n_max_heaps))
-                {
-                    dprintf (6666, ("[CHP2-1] %d is close to max heaps %d, grow to max", new_n_heaps, actual_n_max_heaps));
-                    new_n_heaps = actual_n_max_heaps;
-                }
-            }
-            else if ((median_gen2_tcp < (target_gen2_tcp / 2)) && (num_gen2s_since_last_change > 30))
-            {
-                new_n_heaps -= step_down;
-                dprintf (6666, ("[CHP3-0] last gen2 sample count when changed: %Id, gen2 tcp: %.3f, dec by %d, %d -> %d",
-                    dynamic_heap_count_data.gen2_last_changed_sample_count, median_gen2_tcp, step_down, n_heaps, new_n_heaps));
-            }
-            if (new_n_heaps != n_heaps)
-            {
-                dynamic_heap_count_data.gen2_last_changed_sample_count = dynamic_heap_count_data.current_gen2_samples_count;
-            }
-        }
-    }
-    assert (new_n_heaps >= 1);
-    assert (new_n_heaps <= actual_n_max_heaps);
-    if (process_eph_samples_p)
-    {
-        dprintf (6666, ("processed eph samples, updating processed %Id -> %Id", dynamic_heap_count_data.processed_samples_count, dynamic_heap_count_data.current_samples_count));
-        dynamic_heap_count_data.processed_samples_count = dynamic_heap_count_data.current_samples_count;
-    }
-    if (process_gen2_samples_p)
-    {
-        dynamic_heap_count_data_t::gen2_sample* gen2_samples = dynamic_heap_count_data.gen2_samples;
-        GCEventFireSizeAdaptationFullGCTuning_V1 (
-            (uint16_t)dynamic_heap_count_data.new_n_heaps,
-            (uint64_t)current_gc_index,
-            (float)median_gen2_tcp,
-            (uint32_t)num_gen2s_since_last_change,
-            (uint32_t)(current_gc_index - gen2_samples[0].gc_index),
-            (float)gen2_samples[0].gc_percent,
-            (uint32_t)(current_gc_index - gen2_samples[1].gc_index),
-            (float)gen2_samples[1].gc_percent,
-            (uint32_t)(current_gc_index - gen2_samples[2].gc_index),
-            (float)gen2_samples[2].gc_percent);
-        dprintf (6666, ("processed gen2 samples, updating processed %Id -> %Id", dynamic_heap_count_data.processed_gen2_samples_count, dynamic_heap_count_data.current_gen2_samples_count));
-        dynamic_heap_count_data.processed_gen2_samples_count = dynamic_heap_count_data.current_gen2_samples_count;
-    }
-#endif //STRESS_DYNAMIC_HEAP_COUNT
-    if (new_n_heaps != n_heaps)
-    {
-        dprintf (6666, ("GC#%Id should change! %d->%d (%s)",
-            VolatileLoadWithoutBarrier (&settings.gc_index), n_heaps, new_n_heaps, ((n_heaps < new_n_heaps) ? "INC" : "DEC")));
-        dynamic_heap_count_data.heap_count_to_change_to = new_n_heaps;
-        dynamic_heap_count_data.should_change_heap_count = true;
-    }
-}
-void gc_heap::check_heap_count ()
-{
-    dynamic_heap_count_data.new_n_heaps = dynamic_heap_count_data.heap_count_to_change_to;
-    assert (dynamic_heap_count_data.new_n_heaps != n_heaps);
-    if (dynamic_heap_count_data.new_n_heaps != n_heaps)
-    {
-        dprintf (9999, ("h0 suspending EE in check"));
-        GCToEEInterface::SuspendEE(SUSPEND_FOR_GC_PREP);
-        dprintf (9999, ("h0 suspended EE in check"));
-#ifdef BACKGROUND_GC
-        if (gc_heap::background_running_p())
-        {
-            add_to_hc_history (hc_record_check_cancelled_bgc);
-            hc_change_cancelled_count_bgc++;
-            dynamic_heap_count_data.new_n_heaps = n_heaps;
-            dprintf (6666, ("can't change heap count! BGC in progress"));
-        }
-#endif //BACKGROUND_GC
-    }
-    if (dynamic_heap_count_data.new_n_heaps != n_heaps)
-    {
-        dprintf (6666, ("prep to change from %d to %d at GC#%Id", n_heaps, dynamic_heap_count_data.new_n_heaps, VolatileLoadWithoutBarrier (&settings.gc_index)));
-        if (!prepare_to_change_heap_count (dynamic_heap_count_data.new_n_heaps))
-        {
-            add_to_hc_history (hc_record_check_cancelled_prep);
-            hc_change_cancelled_count_prep++;
-            dynamic_heap_count_data.new_n_heaps = n_heaps;
-        }
-    }
-    if (dynamic_heap_count_data.new_n_heaps == n_heaps)
-    {
-        dynamic_heap_count_data.processed_samples_count = dynamic_heap_count_data.current_samples_count;
-        dynamic_heap_count_data.processed_gen2_samples_count = dynamic_heap_count_data.current_gen2_samples_count;
-        dynamic_heap_count_data.should_change_heap_count = false;
-        dprintf (6666, ("heap count stays the same %d, no work to do, set processed sample count to %Id",
-            dynamic_heap_count_data.new_n_heaps, dynamic_heap_count_data.current_samples_count));
-        GCToEEInterface::RestartEE(TRUE);
-        return;
-    }
-    int new_n_heaps = dynamic_heap_count_data.new_n_heaps;
-    assert (!(dynamic_heap_count_data.init_only_p));
-    {
-        dprintf (9999, ("changing join hp %d->%d", n_heaps, new_n_heaps));
-        int max_threads_to_wake = max (n_heaps, new_n_heaps);
-        gc_t_join.update_n_threads (max_threads_to_wake);
-        assert (dynamic_heap_count_data.new_n_heaps != n_heaps);
-        if (n_heaps < new_n_heaps)
-        {
-            int saved_idle_thread_count = dynamic_heap_count_data.idle_thread_count;
-            Interlocked::ExchangeAdd (&dynamic_heap_count_data.idle_thread_count, (n_heaps - new_n_heaps));
-            dprintf (9999, ("GC thread %d setting idle events for h%d-h%d, total idle %d -> %d", heap_number, n_heaps, (new_n_heaps - 1),
-                saved_idle_thread_count, VolatileLoadWithoutBarrier (&dynamic_heap_count_data.idle_thread_count)));
-            for (int heap_idx = n_heaps; heap_idx < new_n_heaps; heap_idx++)
-            {
-                g_heaps[heap_idx]->gc_idle_thread_event.Set();
-            }
-        }
-        gc_start_event.Set();
-    }
-    int old_n_heaps = n_heaps;
-    change_heap_count (dynamic_heap_count_data.new_n_heaps);
-    GCToEEInterface::RestartEE(TRUE);
-    dprintf (9999, ("h0 restarted EE"));
-    dprintf (6666, ("h0 finished changing, set should change to false!\n"));
-    dynamic_heap_count_data.should_change_heap_count = false;
-}
-bool gc_heap::prepare_to_change_heap_count (int new_n_heaps)
-{
-    dprintf (9999, ("trying to change heap count %d -> %d", n_heaps, new_n_heaps));
-    int old_n_heaps = n_heaps;
-    for (int i = 0; i < old_n_heaps; i++)
-    {
-        gc_heap* hp = g_heaps[i];
-        if (!hp->prepare_rethread_fl_items())
-        {
-            return false;
-        }
-    }
-    if (new_n_heaps < old_n_heaps)
-    {
-        int to_heap_number = 0;
-        for (int i = new_n_heaps; i < old_n_heaps; i++)
-        {
-            gc_heap* from_hp = g_heaps[i];
-            gc_heap* to_hp = g_heaps[to_heap_number];
-            if (!to_hp->finalize_queue->MergeFinalizationData (from_hp->finalize_queue))
-            {
-                dprintf (3, ("failed to merge finalization from heap %d into heap %d", i, to_heap_number));
-                return false;
-            }
-            to_heap_number = (to_heap_number + 1) % new_n_heaps;
-        }
-    }
-    for (int i = 0; i < old_n_heaps; i++)
-    {
-        gc_heap* hp = g_heaps[i];
-        hp->delay_free_segments ();
-    }
-    ptrdiff_t region_count_in_gen[total_generation_count];
-    for (int gen_idx = 0; gen_idx < total_generation_count; gen_idx++)
-    {
-        region_count_in_gen[gen_idx] = 0;
-    }
-    if (old_n_heaps < new_n_heaps)
-    {
-        for (int i = 0; i < old_n_heaps; i++)
-        {
-            gc_heap* hp = g_heaps[i];
-            for (int gen_idx = 0; gen_idx < total_generation_count; gen_idx++)
-            {
-                generation* gen = hp->generation_of (gen_idx);
-                for (heap_segment* region = heap_segment_rw (generation_start_segment (gen));
-                     region != nullptr;
-                     region = heap_segment_next (region))
-                {
-                    region_count_in_gen[gen_idx]++;
-                }
-            }
-        }
-        bool success = true;
-        for (int gen_idx = 0; gen_idx < total_generation_count; gen_idx++)
-        {
-            const size_t size = gen_idx > soh_gen2 ? global_region_allocator.get_large_region_alignment() : 0;
-            while (region_count_in_gen[gen_idx] < new_n_heaps)
-            {
-                int kind = gen_idx > soh_gen2 ? large_free_region : basic_free_region;
-                bool found_free_regions = false;
-                for (int i = 0; i < old_n_heaps; i++)
-                {
-                    gc_heap* hp = g_heaps[i];
-                    if (hp->free_regions[kind].get_num_free_regions() > 0)
-                    {
-                        heap_segment* region = hp->get_new_region (gen_idx, size);
-                        assert (region != nullptr);
-                        region_count_in_gen[gen_idx]++;
-                        found_free_regions = true;
-                        if (region_count_in_gen[gen_idx] == new_n_heaps)
-                            break;
-                    }
-                }
-                if (!found_free_regions)
-                {
-                    break;
-                }
-            }
-            while (region_count_in_gen[gen_idx] < new_n_heaps)
-            {
-                if (g_heaps[0]->get_new_region (gen_idx, size) == nullptr)
-                {
-                    success = false;
-                    break;
-                }
-                region_count_in_gen[gen_idx]++;
-            }
-            if (!success)
-            {
-                return false;
-            }
-        }
-    }
-    return true;
-}
-bool gc_heap::change_heap_count (int new_n_heaps)
-{
-    uint64_t start_time = 0;
-    dprintf (9999, ("BEG heap%d changing %d->%d", heap_number, n_heaps, new_n_heaps));
-    int old_n_heaps = n_heaps;
-    bool init_only_p = dynamic_heap_count_data.init_only_p;
-    {
-        gc_t_join.join (this, gc_join_merge_temp_fl);
-        if (gc_t_join.joined ())
-        {
-#ifdef BACKGROUND_GC
-            bgc_t_join.update_n_threads (new_n_heaps);
-#endif //BACKGROUND_GC
-            dynamic_heap_count_data.init_only_p = false;
-            dprintf (9999, ("in change h%d resetting gc_start, update bgc join to %d heaps", heap_number, new_n_heaps));
-            gc_start_event.Reset();
-            gc_t_join.restart ();
-        }
-    }
-    assert (dynamic_heap_count_data.new_n_heaps != old_n_heaps);
-    if (heap_number == 0)
-    {
-        start_time = GetHighPrecisionTimeStamp ();
-        int from_heap_number = 0;
-        for (int i = old_n_heaps; i < new_n_heaps; i++)
-        {
-            gc_heap* to_hp = g_heaps[i];
-            gc_heap* from_hp = g_heaps[from_heap_number];
-            if (!from_hp->finalize_queue->SplitFinalizationData (to_hp->finalize_queue))
-            {
-                dprintf (3, ("failed to split finalization data between heaps %d and %d", from_heap_number, i));
-            }
-            from_heap_number = (from_heap_number + 1) % old_n_heaps;
-        }
-        BOOL unified_gen0_bricks_cleared = TRUE;
-        for (int i = 0; i < old_n_heaps; i++)
-        {
-            gc_heap* hp = g_heaps[i];
-            if (!init_only_p)
-            {
-                hp->fix_allocation_contexts (TRUE);
-            }
-            if (unified_gen0_bricks_cleared && (hp->gen0_bricks_cleared == FALSE))
-            {
-                unified_gen0_bricks_cleared = FALSE;
-            }
-            for (int gen_idx = 0; gen_idx < total_generation_count; gen_idx++)
-            {
-                generation* gen = hp->generation_of (gen_idx);
-                for (heap_segment* region = heap_segment_rw (generation_start_segment (gen));
-                     region != nullptr;
-                     region = heap_segment_next (region))
-                {
-                    heap_segment_survived (region) = heap_segment_allocated (region) - heap_segment_mem (region);
-                }
-            }
-        }
-        if (old_n_heaps < new_n_heaps)
-        {
-            for (int i = old_n_heaps; i < new_n_heaps; i++)
-            {
-                gc_heap* hp = g_heaps[i];
-                hp->check_decommissioned_heap();
-                hp->recommission_heap();
-            }
-        }
-        if (new_n_heaps < old_n_heaps)
-        {
-            assert (new_n_heaps > 0);
-            for (int gen_idx = 0; gen_idx < total_generation_count; gen_idx++)
-            {
-                for (int i = new_n_heaps; i < old_n_heaps; i++)
-                {
-                    gc_heap* hp = g_heaps[i];
-                    int dest_heap_number = i % new_n_heaps;
-                    gc_heap* hpd = g_heaps[dest_heap_number];
-                    generation* hpd_gen = hpd->generation_of (gen_idx);
-                    generation* gen = hp->generation_of (gen_idx);
-                    heap_segment* start_region = generation_start_segment (gen);
-                    heap_segment* tail_ro_region = generation_tail_ro_region (gen);
-                    heap_segment* tail_region = generation_tail_region (gen);
-                    for (heap_segment* region = start_region; region != nullptr; region = heap_segment_next(region))
-                    {
-                        assert ((hp != nullptr) && (hpd != nullptr) && (hp != hpd));
-                        int oh = heap_segment_oh (region);
-                        size_t committed = heap_segment_committed (region) - get_region_start (region);
-                        if (committed > 0)
-                        {
-                            dprintf(3, ("commit-accounting:  from %d to %d [%p, %p) for heap %d to heap %d", oh, oh, get_region_start (region), heap_segment_committed (region), i, dest_heap_number));
-#ifdef _DEBUG
-                            assert (hp->committed_by_oh_per_heap[oh] >= committed);
-                            hp->committed_by_oh_per_heap[oh] -= committed;
-                            hpd->committed_by_oh_per_heap[oh] += committed;
-#endif // _DEBUG
-                        }
-                        set_heap_for_contained_basic_regions (region, hpd);
-                    }
-                    if (tail_ro_region != nullptr)
-                    {
-                        heap_segment* start_rw_region = heap_segment_next (tail_ro_region);
-                        heap_segment* hpd_tail_ro_region = generation_tail_ro_region (hpd_gen);
-                        if (hpd_tail_ro_region != nullptr)
-                        {
-                            heap_segment_next (tail_ro_region) = heap_segment_next (hpd_tail_ro_region);
-                            heap_segment_next (hpd_tail_ro_region) = start_region;
-                        }
-                        else
-                        {
-                            heap_segment_next (tail_ro_region) = generation_start_segment (hpd_gen);
-                            generation_start_segment (hpd_gen) = start_region;
-                        }
-                        generation_tail_ro_region (hpd_gen) = tail_ro_region;
-                        start_region = start_rw_region;
-                    }
-                    heap_segment* hpd_tail_region = generation_tail_region (hpd_gen);
-                    heap_segment_next (hpd_tail_region) = start_region;
-                    generation_tail_region (hpd_gen) = tail_region;
-                    generation_start_segment (gen) = nullptr;
-                    generation_tail_ro_region (gen) = nullptr;
-                    generation_tail_region (gen) = nullptr;
-                }
-            }
-        }
-        for (int i = new_n_heaps; i < old_n_heaps; i++)
-        {
-            gc_heap* hp = g_heaps[i];
-            int dest_heap_number = i % new_n_heaps;
-            gc_heap* hpd = g_heaps[dest_heap_number];
-            for (int kind = 0; kind < count_free_region_kinds; kind++)
-            {
-                hpd->free_regions[kind].transfer_regions(&hp->free_regions[kind]);
-            }
-        }
-        dprintf (9999, ("h%d changing %d->%d", heap_number, n_heaps, new_n_heaps));
-        n_heaps = new_n_heaps;
-        equalize_promoted_bytes (max_generation);
-        for (int i = 0; i < new_n_heaps; i++)
-        {
-            gc_heap* hp = g_heaps[i];
-            hp->gen0_bricks_cleared = unified_gen0_bricks_cleared;
-            generation* gen0 = hp->generation_of (0);
-            if ((hp->ephemeral_heap_segment == nullptr) ||
-                (heap_segment_heap (hp->ephemeral_heap_segment) != hp))
-            {
-                hp->ephemeral_heap_segment = heap_segment_rw (generation_start_segment (gen0));
-                hp->alloc_allocated = heap_segment_allocated (hp->ephemeral_heap_segment);
-            }
-            for (int gen_idx = 0; gen_idx < total_generation_count; gen_idx++)
-            {
-                generation* gen = hp->generation_of (gen_idx);
-                heap_segment *allocation_region = generation_allocation_segment (gen);
-                if ((allocation_region == nullptr) ||
-                    (heap_segment_heap (allocation_region) != hp))
-                {
-                    generation_allocation_segment (gen) = heap_segment_rw (generation_start_segment (gen));
-                }
-                generation_free_obj_space (gen) = 0;
-            }
-        }
-    }
-    dprintf (3, ("individual heap%d changing %d->%d", heap_number, n_heaps, new_n_heaps));
-    if (!init_only_p)
-    {
-        gc_t_join.join (this, gc_join_merge_temp_fl);
-        if (gc_t_join.joined ())
-        {
-#ifdef BACKGROUND_GC
-            trigger_bgc_for_rethreading_p = true;
-#endif //BACKGROUND_GC
-            gc_t_join.restart ();
-        }
-        for (int gen_idx = 0; gen_idx < total_generation_count; gen_idx++)
-        {
-            bool do_rethreading = true;
-#ifdef BACKGROUND_GC
-            if (trigger_bgc_for_rethreading_p && (gen_idx == max_generation))
-            {
-                do_rethreading = false;
-            }
-#endif //BACKGROUND_GC
-            if (do_rethreading)
-            {
-                if (heap_number < old_n_heaps)
-                {
-                    dprintf (3, ("h%d calling per heap work!", heap_number));
-                    rethread_fl_items (gen_idx);
-                }
-                gc_t_join.join (this, gc_join_merge_temp_fl);
-                if (gc_t_join.joined ())
-                {
-                    merge_fl_from_other_heaps (gen_idx, new_n_heaps, old_n_heaps);
-                    gc_t_join.restart ();
-                }
-            }
-        }
-#ifdef BACKGROUND_GC
-        bgc_alloc_lock->check();
-#endif //BACKGROUND_GC
-    }
-    if (heap_number == 0)
-    {
-        ptrdiff_t new_alloc_per_heap[total_generation_count];
-        size_t desired_alloc_per_heap[total_generation_count];
-        for (int gen_idx = 0; gen_idx < total_generation_count; gen_idx++)
-        {
-            ptrdiff_t total_new_alloc = 0;
-            size_t total_desired_alloc = 0;
-            for (int i = 0; i < old_n_heaps; i++)
-            {
-                gc_heap* hp = g_heaps[i];
-                dynamic_data* dd = hp->dynamic_data_of (gen_idx);
-                total_new_alloc += dd_new_allocation (dd);
-                total_desired_alloc += dd_desired_allocation (dd);
-            }
-            int max_n_heaps = max (old_n_heaps, new_n_heaps);
-            new_alloc_per_heap[gen_idx] = Align (total_new_alloc / max_n_heaps, get_alignment_constant (gen_idx <= max_generation));
-            desired_alloc_per_heap[gen_idx] = Align (total_desired_alloc / max_n_heaps, get_alignment_constant (gen_idx <= max_generation));
-            size_t allocated_in_budget = total_desired_alloc - total_new_alloc;
-            dprintf (6666, ("g%d: total budget %zd (%zd / heap), left in budget: %zd (%zd / heap), (allocated %Id, %.3f%%), min %zd",
-                gen_idx, total_desired_alloc, desired_alloc_per_heap[gen_idx],
-                total_new_alloc, new_alloc_per_heap[gen_idx],
-                allocated_in_budget, ((double)allocated_in_budget * 100.0 / (double)total_desired_alloc),
-                dd_min_size (g_heaps[0]->dynamic_data_of (gen_idx))));
-        }
-        for (int i = 0; i < new_n_heaps; i++)
-        {
-            gc_heap* hp = g_heaps[i];
-            for (int gen_idx = 0; gen_idx < total_generation_count; gen_idx++)
-            {
-                dynamic_data* dd = hp->dynamic_data_of (gen_idx);
-                dd_new_allocation (dd) = new_alloc_per_heap[gen_idx];
-                dd_desired_allocation (dd) = max (desired_alloc_per_heap[gen_idx], dd_min_size (dd));
-                generation* gen = hp->generation_of (gen_idx);
-                size_t gen_size = hp->generation_size (gen_idx);
-                dd_fragmentation (dd) = generation_free_list_space (gen);
-                if (gen_idx == max_generation)
-                {
-                    dd_current_size (dd) = 0;
-                }
-                else
-                {
-                    assert (gen_size >= dd_fragmentation (dd));
-                    dd_current_size (dd) = gen_size - dd_fragmentation (dd);
-                }
-                dprintf (3, ("h%d g%d: budget: %zd, left in budget: %zd, generation_size: %zd fragmentation: %zd current_size: %zd",
-                    i,
-                    gen_idx,
-                    desired_alloc_per_heap[gen_idx],
-                    new_alloc_per_heap[gen_idx],
-                    gen_size,
-                    dd_fragmentation (dd),
-                    dd_current_size (dd)));
-            }
-        }
-        for (int i = n_heaps; i < old_n_heaps; i++)
-        {
-            gc_heap* hp = g_heaps[i];
-            hp->decommission_heap();
-        }
-        if (!init_only_p)
-        {
-            fix_allocation_contexts_heaps();
-        }
-        dynamic_heap_count_data.last_n_heaps = old_n_heaps;
-    }
-    if (new_n_heaps < old_n_heaps)
-    {
-        gc_t_join.join (this, gc_join_merge_temp_fl);
-        if (gc_t_join.joined ())
-        {
-            dprintf (9999, ("now changing the join heap count to the smaller one %d", new_n_heaps));
-            gc_t_join.update_n_threads (new_n_heaps);
-            gc_t_join.restart ();
-        }
-    }
-    if (heap_number == 0)
-    {
-        add_to_hc_history (hc_record_change_done);
-        change_heap_count_time = GetHighPrecisionTimeStamp() - start_time;
-        total_change_heap_count_time += change_heap_count_time;
-        total_change_heap_count++;
-        dprintf (6666, ("changing HC took %I64dus", change_heap_count_time));
-    }
-    return true;
-}
-void gc_heap::get_msl_wait_time (size_t* soh_msl_wait_time, size_t* uoh_msl_wait_time)
-{
-    assert (dynamic_adaptation_mode == dynamic_adaptation_to_application_sizes);
-    *soh_msl_wait_time = 0;
-    *uoh_msl_wait_time = 0;
-    for (int i = 0; i < n_heaps; i++)
-    {
-        gc_heap* hp = g_heaps[i];
-        soh_msl_wait_time += hp->more_space_lock_soh.msl_wait_time;
-        hp->more_space_lock_soh.msl_wait_time = 0;
-        uoh_msl_wait_time += hp->more_space_lock_uoh.msl_wait_time;
-        hp->more_space_lock_uoh.msl_wait_time = 0;
-    }
-}
-void gc_heap::process_datas_sample()
-{
-    before_distribute_free_regions_time = GetHighPrecisionTimeStamp();
-    dynamic_data* dd0 = g_heaps[0]->dynamic_data_of (0);
-    uint64_t gc_pause_time = before_distribute_free_regions_time - dd_time_clock (dd0);
-    size_t desired_per_heap = dd_desired_allocation (dd0);
-    if (settings.gc_index > 1)
-    {
-        size_t gc_index = VolatileLoadWithoutBarrier (&settings.gc_index);
-        dynamic_heap_count_data_t::sample& sample = dynamic_heap_count_data.samples[dynamic_heap_count_data.sample_index];
-        sample.elapsed_between_gcs = before_distribute_free_regions_time - last_suspended_end_time;
-        sample.gc_pause_time = gc_pause_time;
-        size_t soh_msl_wait_time, uoh_msl_wait_time;
-        get_msl_wait_time (&soh_msl_wait_time, &uoh_msl_wait_time);
-        sample.msl_wait_time = soh_msl_wait_time + uoh_msl_wait_time;
-        sample.gc_index = gc_index;
-        sample.gc_survived_size = get_total_promoted();
-        size_t desired_per_heap_datas = desired_per_heap;
-        float tcp = (sample.elapsed_between_gcs ?
-            (((float)sample.msl_wait_time / n_heaps + sample.gc_pause_time) * 100.0f / (float)sample.elapsed_between_gcs) : 0.0f);
-        size_t total_soh_stable_size = get_total_soh_stable_size();
-        desired_per_heap_datas = dynamic_heap_count_data.compute_gen0_budget_per_heap (total_soh_stable_size, tcp, desired_per_heap);
-        dprintf (6666, ("gen0 new_alloc %Id (%.3fmb), from datas: %Id (%.3fmb)",
-            desired_per_heap, mb (desired_per_heap), desired_per_heap_datas, mb (desired_per_heap_datas)));
-        dprintf (6666, ("budget DATAS %Id, previous %Id", desired_per_heap_datas, desired_per_heap));
-        sample.gen0_budget_per_heap = (int)desired_per_heap_datas;
-        if (desired_per_heap_datas != desired_per_heap)
-        {
-            dprintf (6666, ("adjusted budget for DATAS, assigning to all heaps"));
-            assign_new_budget (0, desired_per_heap_datas);
-        }
-        dprintf (6666, ("sample#%d: %d heaps, this GC end %I64d - last sus end %I64d = %I64d, this GC pause %.3fms, msl wait %I64dus, tcp %.3f, surv %zd, gc speed %.3fmb/ms (%.3fkb/ms/heap)",
-            dynamic_heap_count_data.sample_index, n_heaps, before_distribute_free_regions_time, last_suspended_end_time, sample.elapsed_between_gcs,
-            (sample.gc_pause_time / 1000.0), sample.msl_wait_time, tcp, sample.gc_survived_size,
-            (sample.gc_pause_time ? (sample.gc_survived_size / 1000.0 / sample.gc_pause_time) : 0),
-            (sample.gc_pause_time ? ((float)sample.gc_survived_size / sample.gc_pause_time / n_heaps) : 0)));
-        GCEventFireSizeAdaptationSample_V1 (
-            (uint64_t)gc_index,
-            (uint32_t)sample.elapsed_between_gcs,
-            (uint32_t)sample.gc_pause_time,
-            (uint32_t)soh_msl_wait_time, (uint32_t)uoh_msl_wait_time,
-            (uint64_t)total_soh_stable_size, (uint32_t)sample.gen0_budget_per_heap);
-        dynamic_heap_count_data.sample_index = (dynamic_heap_count_data.sample_index + 1) % dynamic_heap_count_data_t::sample_size;
-        (dynamic_heap_count_data.current_samples_count)++;
-        if (settings.condemned_generation == max_generation)
-        {
-            gc_index_full_gc_end = dd_gc_clock (dd0);
-            dynamic_heap_count_data_t::gen2_sample& last_g2_sample = dynamic_heap_count_data.get_last_gen2_sample();
-            uint64_t prev_gen2_end_time = dd_previous_time_clock (g_heaps[0]->dynamic_data_of (max_generation)) + last_g2_sample.gc_duration;
-            size_t elapsed_between_gen2_gcs = before_distribute_free_regions_time - prev_gen2_end_time;
-            size_t gen2_elapsed_time = sample.gc_pause_time;
-            dynamic_heap_count_data_t::gen2_sample& g2_sample = dynamic_heap_count_data.get_current_gen2_sample();
-            g2_sample.gc_index = VolatileLoadWithoutBarrier (&(settings.gc_index));
-            g2_sample.gc_duration = gen2_elapsed_time;
-            g2_sample.gc_percent = (float)gen2_elapsed_time * 100.0f / elapsed_between_gen2_gcs;
-            (dynamic_heap_count_data.current_gen2_samples_count)++;
-            dprintf (6666, ("gen2 sample#%d: this GC end %I64d - last gen2 end %I64d = %I64d, GC elapsed %I64d, percent %.3f",
-                dynamic_heap_count_data.gen2_sample_index, before_distribute_free_regions_time, prev_gen2_end_time, elapsed_between_gen2_gcs, gen2_elapsed_time, g2_sample.gc_percent));
-            dynamic_heap_count_data.gen2_sample_index = (dynamic_heap_count_data.gen2_sample_index + 1) % dynamic_heap_count_data_t::sample_size;
-        }
-        calculate_new_heap_count ();
-    }
-    else
-    {
-        size_t min_desired = dd_min_size (dd0);
-        if (min_desired != desired_per_heap)
-        {
-            dprintf (6666, ("use the min budget for DATAS, assigning to all heaps"));
-            assign_new_budget (0, min_desired);
-        }
-    }
-    last_suspended_end_time = before_distribute_free_regions_time;
-}
-void gc_heap::add_to_hc_history_worker (hc_history* hist, int* current_index, hc_record_stage stage, const char* msg)
-{
-    dprintf (6666, ("h%d ADDING %s HC hist to entry #%d, stage %d, gc index %Id, last %d, n %d, new %d",
-        heap_number, msg, *current_index, (int)stage, VolatileLoadWithoutBarrier (&settings.gc_index),
-        dynamic_heap_count_data.last_n_heaps, n_heaps, dynamic_heap_count_data.new_n_heaps));
-    hc_history* current_hist = &hist[*current_index];
-    current_hist->gc_index = VolatileLoadWithoutBarrier (&settings.gc_index);
-    current_hist->stage = (short)stage;
-    current_hist->last_n_heaps = (short)dynamic_heap_count_data.last_n_heaps;
-    current_hist->n_heaps = (short)n_heaps;
-    current_hist->new_n_heaps = (short)dynamic_heap_count_data.new_n_heaps;
-    current_hist->idle_thread_count = (short)dynamic_heap_count_data.idle_thread_count;
-    current_hist->gc_t_join_n_threads = (short)gc_t_join.get_num_threads();
-    current_hist->gc_t_join_join_lock = (short)gc_t_join.get_join_lock();
-    current_hist->gc_t_join_joined_p = (bool)gc_t_join.joined();
-#ifdef BACKGROUND_GC
-    current_hist->bgc_t_join_n_threads = (short)bgc_t_join.get_num_threads();
-    current_hist->bgc_t_join_join_lock = (short)bgc_t_join.get_join_lock();
-    current_hist->bgc_t_join_joined_p = (bool)bgc_t_join.joined();
-    current_hist->concurrent_p = (bool)settings.concurrent;
-    current_hist->bgc_thread_running = (bool)bgc_thread_running;
-#if defined(TARGET_AMD64) && defined(TARGET_WINDOWS) && !defined(_DEBUG) && !defined(FEATURE_NATIVEAOT)
-    if (GCConfig::GetGCLogBGCThreadId())
-    {
-        int bgc_thread_os_id = 0;
-        if (bgc_thread)
-        {
-            bgc_thread_os_id = (int)(*(size_t*)((uint8_t*)bgc_thread + 0x130));
-        }
-        current_hist->bgc_thread_os_id = bgc_thread_os_id;
-    }
-#endif //TARGET_AMD64 && TARGET_WINDOWS && !_DEBUG && !FEATURE_NATIVEAOT
-#endif //BACKGROUND_GC
-    *current_index  = (*current_index + 1) % max_hc_history_count;
-}
-void gc_heap::add_to_hc_history (hc_record_stage stage)
-{
-    add_to_hc_history_worker (hchist_per_heap, &hchist_index_per_heap, stage, "GC");
-}
-void gc_heap::add_to_bgc_hc_history (hc_record_stage stage)
-{
-    add_to_hc_history_worker (bgc_hchist_per_heap, &bgc_hchist_index_per_heap, stage, "BGC");
-}
-#endif //DYNAMIC_HEAP_COUNT
-#endif //USE_REGIONS
-#if !defined(USE_REGIONS) || defined(_DEBUG)
-inline
-void gc_heap::init_promoted_bytes()
-{
-#ifdef MULTIPLE_HEAPS
-    g_promoted [heap_number*16] = 0;
-#else //MULTIPLE_HEAPS
-    g_promoted = 0;
-#endif //MULTIPLE_HEAPS
-}
-size_t& gc_heap::promoted_bytes (int thread)
-{
-#ifdef MULTIPLE_HEAPS
-    return g_promoted [thread*16];
-#else //MULTIPLE_HEAPS
-    UNREFERENCED_PARAMETER(thread);
-    return g_promoted;
-#endif //MULTIPLE_HEAPS
-}
-#endif //!USE_REGIONS || _DEBUG
-inline
-void gc_heap::add_to_promoted_bytes (uint8_t* object, int thread)
-{
-    size_t obj_size = size (object);
-    add_to_promoted_bytes (object, obj_size, thread);
-}
-inline
-void gc_heap::add_to_promoted_bytes (uint8_t* object, size_t obj_size, int thread)
-{
-    assert (thread == heap_number);
-#ifdef USE_REGIONS
-    if (survived_per_region)
-    {
-        survived_per_region[get_basic_region_index_for_address (object)] += obj_size;
-    }
-#endif //USE_REGIONS
-#if !defined(USE_REGIONS) || defined(_DEBUG)
-#ifdef MULTIPLE_HEAPS
-    g_promoted [heap_number*16] += obj_size;
-#else //MULTIPLE_HEAPS
-    g_promoted += obj_size;
-#endif //MULTIPLE_HEAPS
-#endif //!USE_REGIONS || _DEBUG
-#ifdef _DEBUG
-#endif //_DEBUG
-}
-heap_segment* gc_heap::find_segment (uint8_t* interior, BOOL small_segment_only_p)
-{
-    heap_segment* seg = seg_mapping_table_segment_of (interior);
-    if (seg)
-    {
-        if (small_segment_only_p && heap_segment_uoh_p (seg))
-            return 0;
-    }
-    return seg;
-}
-#if !defined(_DEBUG) && !defined(__GNUC__)
-inline // This causes link errors if global optimization is off
-#endif //!_DEBUG && !__GNUC__
-gc_heap* gc_heap::heap_of (uint8_t* o)
-{
-#ifdef MULTIPLE_HEAPS
-    if (o == 0)
-        return g_heaps [0];
-    gc_heap* hp = seg_mapping_table_heap_of (o);
-    return (hp ? hp : g_heaps[0]);
-#else //MULTIPLE_HEAPS
-    UNREFERENCED_PARAMETER(o);
-    return __this;
-#endif //MULTIPLE_HEAPS
-}
-inline
-gc_heap* gc_heap::heap_of_gc (uint8_t* o)
-{
-#ifdef MULTIPLE_HEAPS
-    if (o == 0)
-        return g_heaps [0];
-    gc_heap* hp = seg_mapping_table_heap_of_gc (o);
-    return (hp ? hp : g_heaps[0]);
-#else //MULTIPLE_HEAPS
-    UNREFERENCED_PARAMETER(o);
-    return __this;
-#endif //MULTIPLE_HEAPS
-}
-uint8_t* gc_heap::find_object (uint8_t* interior)
-{
-    assert (interior != 0);
-    if (!gen0_bricks_cleared)
-    {
-#ifdef MULTIPLE_HEAPS
-        assert (!"Should have already been done in server GC");
-#endif //MULTIPLE_HEAPS
-        clear_gen0_bricks();
-    }
-    gen0_must_clear_bricks = FFIND_DECAY;
-    int brick_entry = get_brick_entry(brick_of (interior));
-    if (brick_entry == 0)
-    {
-        heap_segment* seg = find_segment (interior, FALSE);
-        if (seg)
-        {
-#ifdef FEATURE_CONSERVATIVE_GC
-            if (interior >= heap_segment_allocated(seg))
-                return 0;
-#endif
-            int align_const = get_alignment_constant (heap_segment_read_only_p (seg)
-#ifdef FEATURE_CONSERVATIVE_GC
-                                                       || (GCConfig::GetConservativeGC() && !heap_segment_uoh_p (seg))
-#endif
-                                                      );
-            assert (interior < heap_segment_allocated (seg));
-            uint8_t* o = heap_segment_mem (seg);
-            while (o < heap_segment_allocated (seg))
-            {
-                uint8_t* next_o = o + Align (size (o), align_const);
-                assert (next_o > o);
-                if ((o <= interior) && (interior < next_o))
-                    return o;
-                o = next_o;
-            }
-            return 0;
-        }
-        else
-        {
-            return 0;
-        }
-    }
-    else
-    {
-        heap_segment* seg = find_segment (interior, TRUE);
-        if (seg)
-        {
-#ifdef FEATURE_CONSERVATIVE_GC
-            if (interior >= heap_segment_allocated (seg))
-                return 0;
-#else
-            assert (interior < heap_segment_allocated (seg));
-#endif
-            uint8_t* o = find_first_object (interior, heap_segment_mem (seg));
-            return o;
-        }
-        else
-            return 0;
-    }
-}
-#ifdef MULTIPLE_HEAPS
-#ifdef GC_CONFIG_DRIVEN
-#define m_boundary(o) {if (mark_list_index <= mark_list_end) {*mark_list_index = o;mark_list_index++;} else {mark_list_index++;}}
-#else //GC_CONFIG_DRIVEN
-#define m_boundary(o) {if (mark_list_index <= mark_list_end) {*mark_list_index = o;mark_list_index++;}}
-#endif //GC_CONFIG_DRIVEN
-#define m_boundary_fullgc(o) {}
-#else //MULTIPLE_HEAPS
-#ifdef GC_CONFIG_DRIVEN
-#define m_boundary(o) {if (mark_list_index <= mark_list_end) {*mark_list_index = o;mark_list_index++;} else {mark_list_index++;} if (slow > o) slow = o; if (shigh < o) shigh = o;}
-#else
-#define m_boundary(o) {if (mark_list_index <= mark_list_end) {*mark_list_index = o;mark_list_index++;}if (slow > o) slow = o; if (shigh < o) shigh = o;}
-#endif //GC_CONFIG_DRIVEN
-#define m_boundary_fullgc(o) {if (slow > o) slow = o; if (shigh < o) shigh = o;}
-#endif //MULTIPLE_HEAPS
-inline
-BOOL gc_heap::gc_mark1 (uint8_t* o)
-{
-    BOOL marked = !marked (o);
-    set_marked (o);
-    dprintf (3, ("*%zx*, newly marked: %d", (size_t)o, marked));
-#if defined(USE_REGIONS) && defined(_DEBUG)
-    heap_segment* seg = seg_mapping_table_segment_of (o);
-    if (o > heap_segment_allocated (seg))
-    {
-        dprintf (REGIONS_LOG, ("%p is in seg %zx(%p) but beyond alloc %p!!",
-            o, (size_t)seg, heap_segment_mem (seg), heap_segment_allocated (seg)));
-        GCToOSInterface::DebugBreak();
-    }
-#endif //USE_REGIONS && _DEBUG
-    return marked;
-}
-#ifdef USE_REGIONS
-inline bool is_in_heap_range (uint8_t* o)
-{
-#ifdef FEATURE_BASICFREEZE
-    assert (((g_gc_lowest_address <= o) && (o < g_gc_highest_address)) ||
-        (o == nullptr) || (ro_segment_lookup (o) != nullptr));
-    return ((g_gc_lowest_address <= o) && (o < g_gc_highest_address));
-#else //FEATURE_BASICFREEZE
-    assert ((o == nullptr) || (g_gc_lowest_address <= o) && (o < g_gc_highest_address));
-    return (o != nullptr);
-#endif //FEATURE_BASICFREEZE
-}
-inline bool gc_heap::is_in_gc_range (uint8_t* o)
-{
-#ifdef FEATURE_BASICFREEZE
-    assert (((g_gc_lowest_address <= o) && (o < g_gc_highest_address)) ||
-        (o == nullptr) || (ro_segment_lookup (o) != nullptr));
-#else //FEATURE_BASICFREEZE
-    assert ((o == nullptr) || (g_gc_lowest_address <= o) && (o < g_gc_highest_address));
-#endif //FEATURE_BASICFREEZE
-    return ((gc_low <= o) && (o < gc_high));
-}
-#endif //USE_REGIONS
-inline
-BOOL gc_heap::gc_mark (uint8_t* o, uint8_t* low, uint8_t* high, int condemned_gen)
-{
-#ifdef USE_REGIONS
-    if ((o >= low) && (o < high))
-    {
-        if (condemned_gen != max_generation && get_region_gen_num (o) > condemned_gen)
-        {
-            return FALSE;
-        }
-        BOOL already_marked = marked (o);
-        if (already_marked)
-        {
-            return FALSE;
-        }
-        set_marked (o);
-        return TRUE;
-    }
-    return FALSE;
-#else //USE_REGIONS
-    assert (condemned_gen == -1);
-    BOOL marked = FALSE;
-    if ((o >= low) && (o < high))
-        marked = gc_mark1 (o);
-#ifdef MULTIPLE_HEAPS
-    else if (o)
-    {
-        gc_heap* hp = heap_of_gc (o);
-        assert (hp);
-        if ((o >= hp->gc_low) && (o < hp->gc_high))
-            marked = gc_mark1 (o);
-    }
-#ifdef SNOOP_STATS
-    snoop_stat.objects_checked_count++;
-    if (marked)
-    {
-        snoop_stat.objects_marked_count++;
-    }
-    if (!o)
-    {
-        snoop_stat.zero_ref_count++;
-    }
-#endif //SNOOP_STATS
-#endif //MULTIPLE_HEAPS
-    return marked;
-#endif //USE_REGIONS
-}
-#ifdef BACKGROUND_GC
-inline
-BOOL gc_heap::background_marked (uint8_t* o)
-{
-    return mark_array_marked (o);
-}
-inline
-BOOL gc_heap::background_mark1 (uint8_t* o)
-{
-    BOOL to_mark = !mark_array_marked (o);
-    dprintf (3, ("b*%zx*b(%d)", (size_t)o, (to_mark ? 1 : 0)));
-    if (to_mark)
-    {
-        mark_array_set_marked (o);
-        dprintf (4, ("n*%zx*n", (size_t)o));
-        return TRUE;
-    }
-    else
-        return FALSE;
-}
-inline
-BOOL gc_heap::background_mark (uint8_t* o, uint8_t* low, uint8_t* high)
-{
-    BOOL marked = FALSE;
-    if ((o >= low) && (o < high))
-        marked = background_mark1 (o);
-#ifdef MULTIPLE_HEAPS
-    else if (o)
-    {
-        gc_heap* hp = heap_of (o);
-        assert (hp);
-        if ((o >= hp->background_saved_lowest_address) && (o < hp->background_saved_highest_address))
-            marked = background_mark1 (o);
-    }
-#endif //MULTIPLE_HEAPS
-    return marked;
-}
-#endif //BACKGROUND_GC
-#define new_start() {if (ppstop <= start) {break;} else {parm = start}}
-#define ignore_start 0
-#define use_start 1
-#define go_through_object(mt,o,size,parm,start,start_useful,limit,exp)      \
-{                                                                           \
-    CGCDesc* map = CGCDesc::GetCGCDescFromMT((MethodTable*)(mt));           \
-    CGCDescSeries* cur = map->GetHighestSeries();                           \
-    ptrdiff_t cnt = (ptrdiff_t) map->GetNumSeries();                        \
-                                                                            \
-    if (cnt >= 0)                                                           \
-    {                                                                       \
-        CGCDescSeries* last = map->GetLowestSeries();                       \
-        uint8_t** parm = 0;                                                 \
-        do                                                                  \
-        {                                                                   \
-            assert (parm <= (uint8_t**)((o) + cur->GetSeriesOffset()));     \
-            parm = (uint8_t**)((o) + cur->GetSeriesOffset());               \
-            uint8_t** ppstop =                                              \
-                (uint8_t**)((uint8_t*)parm + cur->GetSeriesSize() + (size));\
-            if (!start_useful || (uint8_t*)ppstop > (start))                \
-            {                                                               \
-                if (start_useful && (uint8_t*)parm < (start)) parm = (uint8_t**)(start);\
-                while (parm < ppstop)                                       \
-                {                                                           \
-                   {exp}                                                    \
-                   parm++;                                                  \
-                }                                                           \
-            }                                                               \
-            cur--;                                                          \
-                                                                            \
-        } while (cur >= last);                                              \
-    }                                                                       \
-    else                                                                    \
-    {                                                                       \
-        /* Handle the repeating case - array of valuetypes */               \
-        uint8_t** parm = (uint8_t**)((o) + cur->startoffset);               \
-        if (start_useful && start > (uint8_t*)parm)                         \
-        {                                                                   \
-            ptrdiff_t cs = mt->RawGetComponentSize();                         \
-            parm = (uint8_t**)((uint8_t*)parm + (((start) - (uint8_t*)parm)/cs)*cs); \
-        }                                                                   \
-        while ((uint8_t*)parm < ((o)+(size)-plug_skew))                     \
-        {                                                                   \
-            for (ptrdiff_t __i = 0; __i > cnt; __i--)                         \
-            {                                                               \
-                HALF_SIZE_T skip =  (cur->val_serie + __i)->skip;           \
-                HALF_SIZE_T nptrs = (cur->val_serie + __i)->nptrs;          \
-                uint8_t** ppstop = parm + nptrs;                            \
-                if (!start_useful || (uint8_t*)ppstop > (start))            \
-                {                                                           \
-                    if (start_useful && (uint8_t*)parm < (start)) parm = (uint8_t**)(start);      \
-                    do                                                      \
-                    {                                                       \
-                       {exp}                                                \
-                       parm++;                                              \
-                    } while (parm < ppstop);                                \
-                }                                                           \
-                parm = (uint8_t**)((uint8_t*)ppstop + skip);                \
-            }                                                               \
-        }                                                                   \
-    }                                                                       \
-}
-#define go_through_object_nostart(mt,o,size,parm,exp) {go_through_object(mt,o,size,parm,o,ignore_start,(o + size),exp); }
-#ifndef COLLECTIBLE_CLASS
-#define go_through_object_cl(mt,o,size,parm,exp)                            \
-{                                                                           \
-    if (header(o)->ContainsGCPointers())                                      \
-    {                                                                       \
-        go_through_object_nostart(mt,o,size,parm,exp);                      \
-    }                                                                       \
-}
-#else //COLLECTIBLE_CLASS
-#define go_through_object_cl(mt,o,size,parm,exp)                            \
-{                                                                           \
-    if (header(o)->Collectible())                                           \
-    {                                                                       \
-        uint8_t* class_obj = get_class_object (o);                             \
-        uint8_t** parm = &class_obj;                                           \
-        do {exp} while (false);                                             \
-    }                                                                       \
-    if (header(o)->ContainsGCPointers())                                      \
-    {                                                                       \
-        go_through_object_nostart(mt,o,size,parm,exp);                      \
-    }                                                                       \
-}
-#endif //COLLECTIBLE_CLASS
-void gc_heap::enque_pinned_plug (uint8_t* plug,
-                                 BOOL save_pre_plug_info_p,
-                                 uint8_t* last_object_in_last_plug)
-{
-    if (mark_stack_array_length <= mark_stack_tos)
-    {
-        if (!grow_mark_stack (mark_stack_array, mark_stack_array_length, MARK_STACK_INITIAL_LENGTH))
-        {
-            GCToEEInterface::HandleFatalError((unsigned int)CORINFO_EXCEPTION_GC);
-        }
-    }
-    dprintf (3, ("enqueuing P #%zd(%p): %p. oldest: %zd, LO: %p, pre: %d",
-        mark_stack_tos, &mark_stack_array[mark_stack_tos], plug, mark_stack_bos, last_object_in_last_plug, (save_pre_plug_info_p ? 1 : 0)));
-    mark& m = mark_stack_array[mark_stack_tos];
-    m.first = plug;
-    m.saved_pre_p = save_pre_plug_info_p;
-    if (save_pre_plug_info_p)
-    {
-        size_t special_bits = clear_special_bits (last_object_in_last_plug);
-        memcpy (&(m.saved_pre_plug), &(((plug_and_gap*)plug)[-1]), sizeof (gap_reloc_pair));
-        set_special_bits (last_object_in_last_plug, special_bits);
-        memcpy (&(m.saved_pre_plug_reloc), &(((plug_and_gap*)plug)[-1]), sizeof (gap_reloc_pair));
-        size_t last_obj_size = plug - last_object_in_last_plug;
-        if (last_obj_size < min_pre_pin_obj_size)
-        {
-            record_interesting_data_point (idp_pre_short);
-#ifdef SHORT_PLUGS
-            if (is_plug_padded (last_object_in_last_plug))
-                record_interesting_data_point (idp_pre_short_padded);
-#endif //SHORT_PLUGS
-            dprintf (3, ("encountered a short object %p right before pinned plug %p!",
-                         last_object_in_last_plug, plug));
-            m.set_pre_short();
-#ifdef COLLECTIBLE_CLASS
-            if (is_collectible (last_object_in_last_plug))
-            {
-                m.set_pre_short_collectible();
-            }
-#endif //COLLECTIBLE_CLASS
-            if (contain_pointers (last_object_in_last_plug))
-            {
-                dprintf (3, ("short object: %p(%zx)", last_object_in_last_plug, last_obj_size));
-                go_through_object_nostart (method_table(last_object_in_last_plug), last_object_in_last_plug, last_obj_size, pval,
-                    {
-                        size_t gap_offset = (((size_t)pval - (size_t)(plug - sizeof (gap_reloc_pair) - plug_skew))) / sizeof (uint8_t*);
-                        dprintf (3, ("member: %p->%p, %zd ptrs from beginning of gap", (uint8_t*)pval, *pval, gap_offset));
-                        m.set_pre_short_bit (gap_offset);
-                    }
-                );
-            }
-        }
-    }
-    m.saved_post_p = FALSE;
-}
-void gc_heap::save_post_plug_info (uint8_t* last_pinned_plug, uint8_t* last_object_in_last_plug, uint8_t* post_plug)
-{
-#ifndef _DEBUG
-    UNREFERENCED_PARAMETER(last_pinned_plug);
-#endif //_DEBUG
-    mark& m = mark_stack_array[mark_stack_tos - 1];
-    assert (last_pinned_plug == m.first);
-    m.saved_post_plug_info_start = (uint8_t*)&(((plug_and_gap*)post_plug)[-1]);
-    size_t special_bits = clear_special_bits (last_object_in_last_plug);
-    memcpy (&(m.saved_post_plug), m.saved_post_plug_info_start, sizeof (gap_reloc_pair));
-    set_special_bits (last_object_in_last_plug, special_bits);
-    memcpy (&(m.saved_post_plug_reloc), m.saved_post_plug_info_start, sizeof (gap_reloc_pair));
-    m.saved_post_p = TRUE;
-#ifdef _DEBUG
-    m.saved_post_plug_debug.gap = 1;
-#endif //_DEBUG
-    dprintf (3, ("PP %p has NP %p right after", last_pinned_plug, post_plug));
-    size_t last_obj_size = post_plug - last_object_in_last_plug;
-    if (last_obj_size < min_pre_pin_obj_size)
-    {
-        dprintf (3, ("PP %p last obj %p is too short", last_pinned_plug, last_object_in_last_plug));
-        record_interesting_data_point (idp_post_short);
-#ifdef SHORT_PLUGS
-        if (is_plug_padded (last_object_in_last_plug))
-            record_interesting_data_point (idp_post_short_padded);
-#endif //SHORT_PLUGS
-        m.set_post_short();
-#if defined (_DEBUG) && defined (VERIFY_HEAP)
-        verify_pinned_queue_p = TRUE;
-#endif // _DEBUG && VERIFY_HEAP
-#ifdef COLLECTIBLE_CLASS
-        if (is_collectible (last_object_in_last_plug))
-        {
-            m.set_post_short_collectible();
-        }
-#endif //COLLECTIBLE_CLASS
-        if (contain_pointers (last_object_in_last_plug))
-        {
-            dprintf (3, ("short object: %p(%zx)", last_object_in_last_plug, last_obj_size));
-            go_through_object_nostart (method_table(last_object_in_last_plug), last_object_in_last_plug, last_obj_size, pval,
-                {
-                    size_t gap_offset = (((size_t)pval - (size_t)(post_plug - sizeof (gap_reloc_pair) - plug_skew))) / sizeof (uint8_t*);
-                    dprintf (3, ("member: %p->%p, %zd ptrs from beginning of gap", (uint8_t*)pval, *pval, gap_offset));
-                    m.set_post_short_bit (gap_offset);
-                }
-            );
-        }
-    }
-}
-#if defined(TARGET_AMD64) || defined(TARGET_X86) || defined(TARGET_ARM64) || defined(TARGET_RISCV64)
-#define PREFETCH
-#endif
-#ifdef PREFETCH
-inline void Prefetch(void* addr)
-{
-#ifdef TARGET_WINDOWS
-#if defined(TARGET_AMD64) || defined(TARGET_X86)
-#ifndef _MM_HINT_T0
-#define _MM_HINT_T0 1
-#endif
-    _mm_prefetch((const char*)addr, _MM_HINT_T0);
-#elif defined(TARGET_ARM64)
-    __prefetch((const char*)addr);
-#endif //defined(TARGET_AMD64) || defined(TARGET_X86)
-#elif defined(TARGET_UNIX)
-    __builtin_prefetch(addr);
-#else //!(TARGET_WINDOWS || TARGET_UNIX)
-    UNREFERENCED_PARAMETER(addr);
-#endif //TARGET_WINDOWS
-}
-#else //PREFETCH
-inline void Prefetch (void* addr)
-{
-    UNREFERENCED_PARAMETER(addr);
-}
-#endif //PREFETCH
-#ifdef MH_SC_MARK
-inline
-VOLATILE(uint8_t*)& gc_heap::ref_mark_stack (gc_heap* hp, int index)
-{
-    return ((VOLATILE(uint8_t*)*)(hp->mark_stack_array))[index];
-}
-#endif //MH_SC_MARK
-#define stolen 2
-#define partial 1
-#define partial_object 3
-inline
-uint8_t* ref_from_slot (uint8_t* r)
-{
-    return (uint8_t*)((size_t)r & ~(stolen | partial));
-}
-inline
-BOOL stolen_p (uint8_t* r)
-{
-    return (((size_t)r&2) && !((size_t)r&1));
-}
-inline
-BOOL ready_p (uint8_t* r)
-{
-    return ((size_t)r != 1);
-}
-inline
-BOOL partial_p (uint8_t* r)
-{
-    return (((size_t)r&1) && !((size_t)r&2));
-}
-inline
-BOOL straight_ref_p (uint8_t* r)
-{
-    return (!stolen_p (r) && !partial_p (r));
-}
-inline
-BOOL partial_object_p (uint8_t* r)
-{
-    return (((size_t)r & partial_object) == partial_object);
-}
-inline
-BOOL ref_p (uint8_t* r)
-{
-    return (straight_ref_p (r) || partial_object_p (r));
-}
-mark_queue_t::mark_queue_t()
-#ifdef MARK_PHASE_PREFETCH
-    : curr_slot_index(0)
-#endif //MARK_PHASE_PREFETCH
-{
-#ifdef MARK_PHASE_PREFETCH
-    for (size_t i = 0; i < slot_count; i++)
-    {
-        slot_table[i] = nullptr;
-    }
-#endif //MARK_PHASE_PREFETCH
-}
-FORCEINLINE
-uint8_t *mark_queue_t::queue_mark(uint8_t *o)
-{
-#ifdef MARK_PHASE_PREFETCH
-    Prefetch (o);
-    size_t slot_index = curr_slot_index;
-    uint8_t* old_o = slot_table[slot_index];
-    slot_table[slot_index] = o;
-    curr_slot_index = (slot_index + 1) % slot_count;
-    if (old_o == nullptr)
-        return nullptr;
-#else //MARK_PHASE_PREFETCH
-    uint8_t* old_o = o;
-#endif //MARK_PHASE_PREFETCH
-    BOOL already_marked = marked (old_o);
-    if (already_marked)
-    {
-        return nullptr;
-    }
-    set_marked (old_o);
-    return old_o;
-}
-FORCEINLINE
-uint8_t *mark_queue_t::queue_mark(uint8_t *o, int condemned_gen)
-{
-#ifdef USE_REGIONS
-    if (!is_in_heap_range (o))
-    {
-        return nullptr;
-    }
-    if ((condemned_gen != max_generation) && (gc_heap::get_region_gen_num (o) > condemned_gen))
-    {
-        return nullptr;
-    }
-    return queue_mark(o);
-#else //USE_REGIONS
-    assert (condemned_gen == -1);
-#ifdef MULTIPLE_HEAPS
-    if (o)
-    {
-        gc_heap* hp = gc_heap::heap_of_gc (o);
-        assert (hp);
-        if ((o >= hp->gc_low) && (o < hp->gc_high))
-            return queue_mark (o);
-    }
-#else //MULTIPLE_HEAPS
-    if ((o >= gc_heap::gc_low) && (o < gc_heap::gc_high))
-        return queue_mark (o);
-#endif //MULTIPLE_HEAPS
-    return nullptr;
-#endif //USE_REGIONS
-}
-uint8_t* mark_queue_t::get_next_marked()
-{
-#ifdef MARK_PHASE_PREFETCH
-    size_t slot_index = curr_slot_index;
-    size_t empty_slot_count = 0;
-    while (empty_slot_count < slot_count)
-    {
-        uint8_t* o = slot_table[slot_index];
-        slot_table[slot_index] = nullptr;
-        slot_index = (slot_index + 1) % slot_count;
-        if (o != nullptr)
-        {
-            BOOL already_marked = marked (o);
-            if (!already_marked)
-            {
-                set_marked (o);
-                curr_slot_index = slot_index;
-                return o;
-            }
-        }
-        empty_slot_count++;
-    }
-#endif //MARK_PHASE_PREFETCH
-    return nullptr;
-}
-void mark_queue_t::verify_empty()
-{
-#ifdef MARK_PHASE_PREFETCH
-    for (size_t slot_index = 0; slot_index < slot_count; slot_index++)
-    {
-        assert(slot_table[slot_index] == nullptr);
-    }
-#endif //MARK_PHASE_PREFETCH
-}
-void gc_heap::mark_object_simple1 (uint8_t* oo, uint8_t* start THREAD_NUMBER_DCL)
-{
-    SERVER_SC_MARK_VOLATILE(uint8_t*)* mark_stack_tos = (SERVER_SC_MARK_VOLATILE(uint8_t*)*)mark_stack_array;
-    SERVER_SC_MARK_VOLATILE(uint8_t*)* mark_stack_limit = (SERVER_SC_MARK_VOLATILE(uint8_t*)*)&mark_stack_array[mark_stack_array_length];
-    SERVER_SC_MARK_VOLATILE(uint8_t*)* mark_stack_base = mark_stack_tos;
-#ifdef SORT_MARK_STACK
-    SERVER_SC_MARK_VOLATILE(uint8_t*)* sorted_tos = mark_stack_base;
-#endif //SORT_MARK_STACK
-    BOOL  full_p = (settings.condemned_generation == max_generation);
-    int condemned_gen =
-#ifdef USE_REGIONS
-        settings.condemned_generation;
-#else
-        -1;
-#endif //USE_REGIONS
-    assert ((start >= oo) && (start < oo+size(oo)));
-#ifndef MH_SC_MARK
-    *mark_stack_tos = oo;
-#endif //!MH_SC_MARK
-    while (1)
-    {
-#ifdef MULTIPLE_HEAPS
-#else  //MULTIPLE_HEAPS
-        const int thread = 0;
-#endif //MULTIPLE_HEAPS
-        if (oo && ((size_t)oo != 4))
-        {
-            size_t s = 0;
-            if (stolen_p (oo))
-            {
-                --mark_stack_tos;
-                goto next_level;
-            }
-            else if (!partial_p (oo) && ((s = size (oo)) < (partial_size_th*sizeof (uint8_t*))))
-            {
-                BOOL overflow_p = FALSE;
-                if (mark_stack_tos + (s) /sizeof (uint8_t*) >= (mark_stack_limit  - 1))
-                {
-                    size_t num_components = ((method_table(oo))->HasComponentSize() ? ((CObjectHeader*)oo)->GetNumComponents() : 0);
-                    if (mark_stack_tos + CGCDesc::GetNumPointers(method_table(oo), s, num_components) >= (mark_stack_limit - 1))
-                    {
-                        overflow_p = TRUE;
-                    }
-                }
-                if (overflow_p == FALSE)
-                {
-                    dprintf(3,("pushing mark for %zx ", (size_t)oo));
-                    go_through_object_cl (method_table(oo), oo, s, ppslot,
-                                          {
-                                              uint8_t* o = mark_queue.queue_mark(*ppslot, condemned_gen);
-                                              if (o != nullptr)
-                                              {
-                                                  if (full_p)
-                                                  {
-                                                      m_boundary_fullgc (o);
-                                                  }
-                                                  else
-                                                  {
-                                                      m_boundary (o);
-                                                  }
-                                                  add_to_promoted_bytes (o, thread);
-                                                  if (contain_pointers_or_collectible (o))
-                                                  {
-                                                      *(mark_stack_tos++) = o;
-                                                  }
-                                              }
-                                          }
-                        );
-                }
-                else
-                {
-                    dprintf(3,("mark stack overflow for object %zx ", (size_t)oo));
-                    min_overflow_address = min (min_overflow_address, oo);
-                    max_overflow_address = max (max_overflow_address, oo);
-                }
-            }
-            else
-            {
-                if (partial_p (oo))
-                {
-                    start = ref_from_slot (oo);
-                    oo = ref_from_slot (*(--mark_stack_tos));
-                    dprintf (4, ("oo: %zx, start: %zx\n", (size_t)oo, (size_t)start));
-                    assert ((oo < start) && (start < (oo + size (oo))));
-                }
-#ifdef COLLECTIBLE_CLASS
-                else
-                {
-                    if (is_collectible (oo))
-                    {
-                        uint8_t* class_obj = get_class_object (oo);
-                        if (gc_mark (class_obj, gc_low, gc_high, condemned_gen))
-                        {
-                            if (full_p)
-                            {
-                                m_boundary_fullgc (class_obj);
-                            }
-                            else
-                            {
-                                m_boundary (class_obj);
-                            }
-                            add_to_promoted_bytes (class_obj, thread);
-                            *(mark_stack_tos++) = class_obj;
-                            *mark_stack_tos = oo;
-                        }
-                    }
-                    if (!contain_pointers (oo))
-                    {
-                        goto next_level;
-                    }
-                }
-#endif //COLLECTIBLE_CLASS
-                s = size (oo);
-                BOOL overflow_p = FALSE;
-                if (mark_stack_tos + (num_partial_refs + 2)  >= mark_stack_limit)
-                {
-                    overflow_p = TRUE;
-                }
-                if (overflow_p == FALSE)
-                {
-                    dprintf(3,("pushing mark for %zx ", (size_t)oo));
-                    SERVER_SC_MARK_VOLATILE(uint8_t*)* place = ++mark_stack_tos;
-                    mark_stack_tos++;
-#ifdef MH_SC_MARK
-                    *(place-1) = 0;
-                    *(place) = (uint8_t*)partial;
-#endif //MH_SC_MARK
-                    int i = num_partial_refs;
-                    uint8_t* ref_to_continue = 0;
-                    go_through_object (method_table(oo), oo, s, ppslot,
-                                       start, use_start, (oo + s),
-                                       {
-                                           uint8_t* o = mark_queue.queue_mark(*ppslot, condemned_gen);
-                                           if (o != nullptr)
-                                           {
-                                                if (full_p)
-                                                {
-                                                    m_boundary_fullgc (o);
-                                                }
-                                                else
-                                                {
-                                                    m_boundary (o);
-                                                }
-                                                add_to_promoted_bytes (o, thread);
-                                                if (contain_pointers_or_collectible (o))
-                                                {
-                                                    *(mark_stack_tos++) = o;
-                                                    if (--i == 0)
-                                                    {
-                                                        ref_to_continue = (uint8_t*)((size_t)(ppslot+1) | partial);
-                                                        goto more_to_do;
-                                                    }
-                                                }
-                                           }
-                                       }
-                        );
-                    assert (ref_to_continue == 0);
-#ifdef MH_SC_MARK
-                    assert ((*(place-1)) == (uint8_t*)0);
-#else //MH_SC_MARK
-                    *(place-1) = 0;
-#endif //MH_SC_MARK
-                    *place = 0;
-more_to_do:
-                    if (ref_to_continue)
-                    {
-#ifdef MH_SC_MARK
-                        assert ((*(place-1)) == (uint8_t*)0);
-                        *(place-1) = (uint8_t*)((size_t)oo | partial_object);
-                        assert (((*place) == (uint8_t*)1) || ((*place) == (uint8_t*)2));
-#endif //MH_SC_MARK
-                        *place = ref_to_continue;
-                    }
-                }
-                else
-                {
-                    dprintf(3,("mark stack overflow for object %zx ", (size_t)oo));
-                    min_overflow_address = min (min_overflow_address, oo);
-                    max_overflow_address = max (max_overflow_address, oo);
-                }
-            }
-#ifdef SORT_MARK_STACK
-            if (mark_stack_tos > sorted_tos + mark_stack_array_length/8)
-            {
-                rqsort1 (sorted_tos, mark_stack_tos-1);
-                sorted_tos = mark_stack_tos-1;
-            }
-#endif //SORT_MARK_STACK
-        }
-    next_level:
-        if (!(mark_stack_empty_p()))
-        {
-            oo = *(--mark_stack_tos);
-            start = oo;
-#ifdef SORT_MARK_STACK
-            sorted_tos = min ((size_t)sorted_tos, (size_t)mark_stack_tos);
-#endif //SORT_MARK_STACK
-        }
-        else
-            break;
-    }
-}
-#ifdef MH_SC_MARK
-BOOL same_numa_node_p (int hn1, int hn2)
-{
-    return (heap_select::find_numa_node_from_heap_no (hn1) == heap_select::find_numa_node_from_heap_no (hn2));
-}
-int find_next_buddy_heap (int this_heap_number, int current_buddy, int n_heaps)
-{
-    int hn = (current_buddy+1)%n_heaps;
-    while (hn != current_buddy)
-    {
-        if ((this_heap_number != hn) && (same_numa_node_p (this_heap_number, hn)))
-            return hn;
-        hn = (hn+1)%n_heaps;
-    }
-    return current_buddy;
-}
-void
-gc_heap::mark_steal()
-{
-    mark_stack_busy() = 0;
-    for (int i = 0; i < max_snoop_level; i++)
-    {
-        ((VOLATILE(uint8_t*)*)(mark_stack_array))[i] = 0;
-    }
-    int thpn = find_next_buddy_heap (heap_number, heap_number, n_heaps);
-#ifdef SNOOP_STATS
-        dprintf (SNOOP_LOG, ("(GC%d)heap%d: start snooping %d", settings.gc_index, heap_number, (heap_number+1)%n_heaps));
-        uint64_t begin_tick = GCToOSInterface::GetLowPrecisionTimeStamp();
-#endif //SNOOP_STATS
-    int idle_loop_count = 0;
-    int first_not_ready_level = 0;
-    while (1)
-    {
-        gc_heap* hp = g_heaps [thpn];
-        int level = first_not_ready_level;
-        first_not_ready_level = 0;
-        while (check_next_mark_stack (hp) && (level < (max_snoop_level-1)))
-        {
-            idle_loop_count = 0;
-#ifdef SNOOP_STATS
-            snoop_stat.busy_count++;
-            dprintf (SNOOP_LOG, ("heap%d: looking at next heap level %d stack contents: %zx",
-                                 heap_number, level, (int)((uint8_t**)(hp->mark_stack_array))[level]));
-#endif //SNOOP_STATS
-            uint8_t* o = ref_mark_stack (hp, level);
-            uint8_t* start = o;
-            if (ref_p (o))
-            {
-                mark_stack_busy() = 1;
-                BOOL success = TRUE;
-                uint8_t* next = (ref_mark_stack (hp, level+1));
-                if (ref_p (next))
-                {
-                    if (((size_t)o > 4) && !partial_object_p (o))
-                    {
-                        success = (Interlocked::CompareExchangePointer (&ref_mark_stack (hp, level), (uint8_t*)4, o)==o);
-#ifdef SNOOP_STATS
-                        snoop_stat.interlocked_count++;
-                        if (success)
-                            snoop_stat.normal_count++;
-#endif //SNOOP_STATS
-                    }
-                    else
-                    {
-                        level++;
-#ifdef SNOOP_STATS
-                        snoop_stat.stolen_or_pm_count++;
-#endif //SNOOP_STATS
-                        success = FALSE;
-                    }
-                }
-                else if (stolen_p (next))
-                {
-                    success = FALSE;
-                    level+=2;
-#ifdef SNOOP_STATS
-                    snoop_stat.stolen_entry_count++;
-#endif //SNOOP_STATS
-                }
-                else
-                {
-                    assert (partial_p (next));
-                    start = ref_from_slot (next);
-                    o = ref_from_slot (ref_mark_stack (hp, level));
-                    if (o && start)
-                    {
-                        success = (Interlocked::CompareExchangePointer (&ref_mark_stack (hp, level+1),
-                                                                        (uint8_t*)stolen, next) == next);
-#ifdef SNOOP_STATS
-                        snoop_stat.interlocked_count++;
-                        if (success)
-                        {
-                            snoop_stat.partial_mark_parent_count++;
-                        }
-#endif //SNOOP_STATS
-                    }
-                    else
-                    {
-                        success = FALSE;
-                        if (first_not_ready_level == 0)
-                        {
-                            first_not_ready_level = level;
-                        }
-                        level+=2;
-#ifdef SNOOP_STATS
-                        snoop_stat.pm_not_ready_count++;
-#endif //SNOOP_STATS
-                    }
-                }
-                if (success)
-                {
-#ifdef SNOOP_STATS
-                    dprintf (SNOOP_LOG, ("heap%d: marking %zx from %d [%d] tl:%dms",
-                            heap_number, (size_t)o, (heap_number+1)%n_heaps, level,
-                            (GCToOSInterface::GetLowPrecisionTimeStamp()-begin_tick)));
-                    uint64_t start_tick = GCToOSInterface::GetLowPrecisionTimeStamp();
-#endif //SNOOP_STATS
-                    mark_object_simple1 (o, start, heap_number);
-#ifdef SNOOP_STATS
-                    dprintf (SNOOP_LOG, ("heap%d: done marking %zx from %d [%d] %dms tl:%dms",
-                            heap_number, (size_t)o, (heap_number+1)%n_heaps, level,
-                            (GCToOSInterface::GetLowPrecisionTimeStamp()-start_tick),(GCToOSInterface::GetLowPrecisionTimeStamp()-begin_tick)));
-#endif //SNOOP_STATS
-                    mark_stack_busy() = 0;
-                    for (int i = 0; i < max_snoop_level; i++)
-                    {
-                        if (((uint8_t**)mark_stack_array)[i] != 0)
-                        {
-                            ((VOLATILE(uint8_t*)*)(mark_stack_array))[i] = 0;
-#ifdef SNOOP_STATS
-                            snoop_stat.stack_bottom_clear_count++;
-#endif //SNOOP_STATS
-                        }
-                    }
-                    level = 0;
-                }
-                mark_stack_busy() = 0;
-            }
-            else
-            {
-                level++;
-            }
-        }
-        if ((first_not_ready_level != 0) && hp->mark_stack_busy())
-        {
-            continue;
-        }
-        if (!hp->mark_stack_busy())
-        {
-            first_not_ready_level = 0;
-            idle_loop_count++;
-            if ((idle_loop_count % (6) )==1)
-            {
-#ifdef SNOOP_STATS
-                snoop_stat.switch_to_thread_count++;
-#endif //SNOOP_STATS
-                GCToOSInterface::Sleep(1);
-            }
-            int free_count = 1;
-#ifdef SNOOP_STATS
-            snoop_stat.stack_idle_count++;
-#endif //SNOOP_STATS
-            for (int hpn = (heap_number+1)%n_heaps; hpn != heap_number;)
-            {
-                if (!((g_heaps [hpn])->mark_stack_busy()))
-                {
-                    free_count++;
-#ifdef SNOOP_STATS
-                dprintf (SNOOP_LOG, ("heap%d: %d idle", heap_number, free_count));
-#endif //SNOOP_STATS
-                }
-                else if (same_numa_node_p (hpn, heap_number) || ((idle_loop_count%1000))==999)
-                {
-                    thpn = hpn;
-                    break;
-                }
-                hpn = (hpn+1)%n_heaps;
-                YieldProcessor();
-            }
-            if (free_count == n_heaps)
-            {
-                break;
-            }
-        }
-    }
-}
-inline
-BOOL gc_heap::check_next_mark_stack (gc_heap* next_heap)
-{
-#ifdef SNOOP_STATS
-    snoop_stat.check_level_count++;
-#endif //SNOOP_STATS
-    return (next_heap->mark_stack_busy()>=1);
-}
-#endif //MH_SC_MARK
-#ifdef SNOOP_STATS
-void gc_heap::print_snoop_stat()
-{
-    dprintf (1234, ("%4s | %8s | %8s | %8s | %8s | %8s | %8s | %8s",
-        "heap", "check", "zero", "mark", "stole", "pstack", "nstack", "nonsk"));
-    dprintf (1234, ("%4d | %8d | %8d | %8d | %8d | %8d | %8d | %8d",
-        snoop_stat.heap_index,
-        snoop_stat.objects_checked_count,
-        snoop_stat.zero_ref_count,
-        snoop_stat.objects_marked_count,
-        snoop_stat.stolen_stack_count,
-        snoop_stat.partial_stack_count,
-        snoop_stat.normal_stack_count,
-        snoop_stat.non_stack_count));
-    dprintf (1234, ("%4s | %8s | %8s | %8s | %8s | %8s | %8s | %8s | %8s | %8s",
-        "heap", "level", "busy", "xchg", "pmparent", "s_pm", "stolen", "nready", "clear"));
-    dprintf (1234, ("%4d | %8d | %8d | %8d | %8d | %8d | %8d | %8d | %8d | %8d\n",
-        snoop_stat.heap_index,
-        snoop_stat.check_level_count,
-        snoop_stat.busy_count,
-        snoop_stat.interlocked_count,
-        snoop_stat.partial_mark_parent_count,
-        snoop_stat.stolen_or_pm_count,
-        snoop_stat.stolen_entry_count,
-        snoop_stat.pm_not_ready_count,
-        snoop_stat.normal_count,
-        snoop_stat.stack_bottom_clear_count));
-    printf ("\n%4s | %8s | %8s | %8s | %8s | %8s\n",
-        "heap", "check", "zero", "mark", "idle", "switch");
-    printf ("%4d | %8d | %8d | %8d | %8d | %8d\n",
-        snoop_stat.heap_index,
-        snoop_stat.objects_checked_count,
-        snoop_stat.zero_ref_count,
-        snoop_stat.objects_marked_count,
-        snoop_stat.stack_idle_count,
-        snoop_stat.switch_to_thread_count);
-    printf ("%4s | %8s | %8s | %8s | %8s | %8s | %8s | %8s | %8s | %8s\n",
-        "heap", "level", "busy", "xchg", "pmparent", "s_pm", "stolen", "nready", "normal", "clear");
-    printf ("%4d | %8d | %8d | %8d | %8d | %8d | %8d | %8d | %8d | %8d\n",
-        snoop_stat.heap_index,
-        snoop_stat.check_level_count,
-        snoop_stat.busy_count,
-        snoop_stat.interlocked_count,
-        snoop_stat.partial_mark_parent_count,
-        snoop_stat.stolen_or_pm_count,
-        snoop_stat.stolen_entry_count,
-        snoop_stat.pm_not_ready_count,
-        snoop_stat.normal_count,
-        snoop_stat.stack_bottom_clear_count);
-}
-#endif //SNOOP_STATS
-#ifdef HEAP_ANALYZE
-void
-gc_heap::ha_mark_object_simple (uint8_t** po THREAD_NUMBER_DCL)
-{
-    if (!internal_root_array)
-    {
-        internal_root_array = new (nothrow) uint8_t* [internal_root_array_length];
-        if (!internal_root_array)
-        {
-            heap_analyze_success = FALSE;
-        }
-    }
-    if (heap_analyze_success && (internal_root_array_length <= internal_root_array_index))
-    {
-        size_t new_size = 2*internal_root_array_length;
-        uint64_t available_physical = 0;
-        get_memory_info (NULL, &available_physical);
-        if (new_size > (size_t)(available_physical / 10))
-        {
-            heap_analyze_success = FALSE;
-        }
-        else
-        {
-            uint8_t** tmp = new (nothrow) uint8_t* [new_size];
-            if (tmp)
-            {
-                memcpy (tmp, internal_root_array,
-                        internal_root_array_length*sizeof (uint8_t*));
-                delete[] internal_root_array;
-                internal_root_array = tmp;
-                internal_root_array_length = new_size;
-            }
-            else
-            {
-                heap_analyze_success = FALSE;
-            }
-        }
-    }
-    if (heap_analyze_success)
-    {
-        PREFIX_ASSUME(internal_root_array_index < internal_root_array_length);
-        uint8_t* ref = (uint8_t*)po;
-        if (!current_obj ||
-            !((ref >= current_obj) && (ref < (current_obj + current_obj_size))))
-        {
-            gc_heap* hp = gc_heap::heap_of (ref);
-            current_obj = hp->find_object (ref);
-            current_obj_size = size (current_obj);
-            internal_root_array[internal_root_array_index] = current_obj;
-            internal_root_array_index++;
-        }
-    }
-    mark_object_simple (po THREAD_NUMBER_ARG);
-}
-#endif //HEAP_ANALYZE
-void
-gc_heap::mark_object_simple (uint8_t** po THREAD_NUMBER_DCL)
-{
-    int condemned_gen =
-#ifdef USE_REGIONS
-        settings.condemned_generation;
-#else
-        -1;
-#endif //USE_REGIONS
-    uint8_t* o = *po;
-#ifndef MULTIPLE_HEAPS
-    const int thread = 0;
-#endif //MULTIPLE_HEAPS
-    {
-#ifdef SNOOP_STATS
-        snoop_stat.objects_checked_count++;
-#endif //SNOOP_STATS
-        o = mark_queue.queue_mark (o);
-        if (o != nullptr)
-        {
-            m_boundary (o);
-            size_t s = size (o);
-            add_to_promoted_bytes (o, s, thread);
-            {
-                go_through_object_cl (method_table(o), o, s, poo,
-                                        {
-                                            uint8_t* oo = mark_queue.queue_mark(*poo, condemned_gen);
-                                            if (oo != nullptr)
-                                            {
-                                                m_boundary (oo);
-                                                add_to_promoted_bytes (oo, thread);
-                                                if (contain_pointers_or_collectible (oo))
-                                                    mark_object_simple1 (oo, oo THREAD_NUMBER_ARG);
-                                            }
-                                        }
-                    );
-            }
-        }
-    }
-}
-inline
-void gc_heap::mark_object (uint8_t* o THREAD_NUMBER_DCL)
-{
-#ifdef USE_REGIONS
-    if (is_in_gc_range (o) && is_in_condemned_gc (o))
-    {
-        mark_object_simple (&o THREAD_NUMBER_ARG);
-    }
-#else //USE_REGIONS
-    if ((o >= gc_low) && (o < gc_high))
-        mark_object_simple (&o THREAD_NUMBER_ARG);
-#ifdef MULTIPLE_HEAPS
-    else if (o)
-    {
-        gc_heap* hp = heap_of (o);
-        assert (hp);
-        if ((o >= hp->gc_low) && (o < hp->gc_high))
-            mark_object_simple (&o THREAD_NUMBER_ARG);
-    }
-#endif //MULTIPLE_HEAPS
-#endif //USE_REGIONS
-}
-void gc_heap::drain_mark_queue ()
-{
-    int condemned_gen =
-#ifdef USE_REGIONS
-        settings.condemned_generation;
-#else
-        -1;
-#endif //USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-    THREAD_FROM_HEAP;
-#else
-    const int thread = 0;
-#endif //MULTIPLE_HEAPS
-    uint8_t* o;
-    while ((o = mark_queue.get_next_marked()) != nullptr)
-    {
-        m_boundary (o);
-        size_t s = size (o);
-        add_to_promoted_bytes (o, s, thread);
-        if (contain_pointers_or_collectible (o))
-        {
-            go_through_object_cl (method_table(o), o, s, poo,
-                                    {
-                                        uint8_t* oo = mark_queue.queue_mark(*poo, condemned_gen);
-                                        if (oo != nullptr)
-                                        {
-                                            m_boundary (oo);
-                                            add_to_promoted_bytes (oo, thread);
-                                            if (contain_pointers_or_collectible (oo))
-                                                mark_object_simple1 (oo, oo THREAD_NUMBER_ARG);
-                                        }
-                                    }
-                );
-        }
-    }
-}
-#ifdef BACKGROUND_GC
-#ifdef USE_REGIONS
-void gc_heap::set_background_overflow_p (uint8_t* oo)
-{
-    heap_segment* overflow_region = get_region_info_for_address (oo);
-    overflow_region->flags |= heap_segment_flags_overflow;
-    dprintf (3,("setting overflow flag for region %p", heap_segment_mem (overflow_region)));
-    background_overflow_p = TRUE;
-}
-#endif //USE_REGIONS
-void gc_heap::background_mark_simple1 (uint8_t* oo THREAD_NUMBER_DCL)
-{
-    uint8_t** mark_stack_limit = &background_mark_stack_array[background_mark_stack_array_length];
-#ifdef SORT_MARK_STACK
-    uint8_t** sorted_tos = background_mark_stack_array;
-#endif //SORT_MARK_STACK
-    background_mark_stack_tos = background_mark_stack_array;
-    while (1)
-    {
-#ifdef MULTIPLE_HEAPS
-#else  //MULTIPLE_HEAPS
-        const int thread = 0;
-#endif //MULTIPLE_HEAPS
-        if (oo)
-        {
-            size_t s = 0;
-            if ((((size_t)oo & 1) == 0) && ((s = size (oo)) < (partial_size_th*sizeof (uint8_t*))))
-            {
-                BOOL overflow_p = FALSE;
-                if (background_mark_stack_tos + (s) /sizeof (uint8_t*) >= (mark_stack_limit - 1))
-                {
-                    size_t num_components = ((method_table(oo))->HasComponentSize() ? ((CObjectHeader*)oo)->GetNumComponents() : 0);
-                    size_t num_pointers = CGCDesc::GetNumPointers(method_table(oo), s, num_components);
-                    if (background_mark_stack_tos + num_pointers >= (mark_stack_limit - 1))
-                    {
-                        dprintf (2, ("h%d: %zd left, obj (mt: %p) %zd ptrs",
-                            heap_number,
-                            (size_t)(mark_stack_limit - 1 - background_mark_stack_tos),
-                            method_table(oo),
-                            num_pointers));
-                        bgc_overflow_count++;
-                        overflow_p = TRUE;
-                    }
-                }
-                if (overflow_p == FALSE)
-                {
-                    dprintf(3,("pushing mark for %zx ", (size_t)oo));
-                    go_through_object_cl (method_table(oo), oo, s, ppslot,
-                    {
-                        uint8_t* o = *ppslot;
-                        Prefetch(o);
-                        if (background_mark (o,
-                                             background_saved_lowest_address,
-                                             background_saved_highest_address))
-                        {
-                            size_t obj_size = size (o);
-                            bpromoted_bytes (thread) += obj_size;
-                            if (contain_pointers_or_collectible (o))
-                            {
-                                *(background_mark_stack_tos++) = o;
-                            }
-                        }
-                    }
-                        );
-                }
-                else
-                {
-                    dprintf (3,("background mark stack overflow for object %zx ", (size_t)oo));
-#ifdef USE_REGIONS
-                    set_background_overflow_p (oo);
-#else //USE_REGIONS
-                    background_min_overflow_address = min (background_min_overflow_address, oo);
-                    background_max_overflow_address = max (background_max_overflow_address, oo);
-#endif //USE_REGIONS
-                }
-            }
-            else
-            {
-                uint8_t* start = oo;
-                if ((size_t)oo & 1)
-                {
-                    oo = (uint8_t*)((size_t)oo & ~1);
-                    start = *(--background_mark_stack_tos);
-                    dprintf (4, ("oo: %zx, start: %zx\n", (size_t)oo, (size_t)start));
-                }
-#ifdef COLLECTIBLE_CLASS
-                else
-                {
-                    if (is_collectible (oo))
-                    {
-                        uint8_t* class_obj = get_class_object (oo);
-                        if (background_mark (class_obj,
-                                            background_saved_lowest_address,
-                                            background_saved_highest_address))
-                        {
-                            size_t obj_size = size (class_obj);
-                            bpromoted_bytes (thread) += obj_size;
-                            *(background_mark_stack_tos++) = class_obj;
-                        }
-                    }
-                    if (!contain_pointers (oo))
-                    {
-                        goto next_level;
-                    }
-                }
-#endif //COLLECTIBLE_CLASS
-                s = size (oo);
-                BOOL overflow_p = FALSE;
-                if (background_mark_stack_tos + (num_partial_refs + 2)  >= mark_stack_limit)
-                {
-                    size_t num_components = ((method_table(oo))->HasComponentSize() ? ((CObjectHeader*)oo)->GetNumComponents() : 0);
-                    size_t num_pointers = CGCDesc::GetNumPointers(method_table(oo), s, num_components);
-                    dprintf (2, ("h%d: PM: %zd left, obj %p (mt: %p) start: %p, total: %zd",
-                        heap_number,
-                        (size_t)(mark_stack_limit - background_mark_stack_tos),
-                        oo,
-                        method_table(oo),
-                        start,
-                        num_pointers));
-                    bgc_overflow_count++;
-                    overflow_p = TRUE;
-                }
-                if (overflow_p == FALSE)
-                {
-                    dprintf(3,("pushing mark for %zx ", (size_t)oo));
-                    uint8_t** place = background_mark_stack_tos++;
-                    *(place) = start;
-                    *(background_mark_stack_tos++) = (uint8_t*)((size_t)oo | 1);
-                    int num_pushed_refs = num_partial_refs;
-                    int num_processed_refs = num_pushed_refs * 16;
-                    go_through_object (method_table(oo), oo, s, ppslot,
-                                       start, use_start, (oo + s),
-                    {
-                        uint8_t* o = *ppslot;
-                        Prefetch(o);
-                        if (background_mark (o,
-                                            background_saved_lowest_address,
-                                            background_saved_highest_address))
-                        {
-                            size_t obj_size = size (o);
-                            bpromoted_bytes (thread) += obj_size;
-                            if (contain_pointers_or_collectible (o))
-                            {
-                                *(background_mark_stack_tos++) = o;
-                                if (--num_pushed_refs == 0)
-                                {
-                                    *place = (uint8_t*)(ppslot+1);
-                                    goto more_to_do;
-                                }
-                            }
-                        }
-                        if (--num_processed_refs == 0)
-                        {
-                            *place = (uint8_t*)(ppslot + 1);
-                            goto more_to_do;
-                        }
-                        }
-                        );
-                    *place = 0;
-                    *(place+1) = 0;
-                more_to_do:;
-                }
-                else
-                {
-                    dprintf (3,("background mark stack overflow for object %zx ", (size_t)oo));
-#ifdef USE_REGIONS
-                    set_background_overflow_p (oo);
-#else //USE_REGIONS
-                    background_min_overflow_address = min (background_min_overflow_address, oo);
-                    background_max_overflow_address = max (background_max_overflow_address, oo);
-#endif //USE_REGIONS
-                }
-            }
-        }
-#ifdef SORT_MARK_STACK
-        if (background_mark_stack_tos > sorted_tos + mark_stack_array_length/8)
-        {
-            rqsort1 (sorted_tos, background_mark_stack_tos-1);
-            sorted_tos = background_mark_stack_tos-1;
-        }
-#endif //SORT_MARK_STACK
-#ifdef COLLECTIBLE_CLASS
-next_level:
-#endif // COLLECTIBLE_CLASS
-        allow_fgc();
-        if (!(background_mark_stack_tos == background_mark_stack_array))
-        {
-            oo = *(--background_mark_stack_tos);
-#ifdef SORT_MARK_STACK
-            sorted_tos = (uint8_t**)min ((size_t)sorted_tos, (size_t)background_mark_stack_tos);
-#endif //SORT_MARK_STACK
-        }
-        else
-            break;
-    }
-    assert (background_mark_stack_tos == background_mark_stack_array);
-}
-void
-gc_heap::background_mark_simple (uint8_t* o THREAD_NUMBER_DCL)
-{
-#ifdef MULTIPLE_HEAPS
-#else  //MULTIPLE_HEAPS
-    const int thread = 0;
-#endif //MULTIPLE_HEAPS
-    {
-        dprintf (3, ("bmarking %p", o));
-        if (background_mark1 (o))
-        {
-            size_t s = size (o);
-            bpromoted_bytes (thread) += s;
-            if (contain_pointers_or_collectible (o))
-            {
-                background_mark_simple1 (o THREAD_NUMBER_ARG);
-            }
-        }
-        allow_fgc();
-    }
-}
-inline
-uint8_t* gc_heap::background_mark_object (uint8_t* o THREAD_NUMBER_DCL)
-{
-    if ((o >= background_saved_lowest_address) && (o < background_saved_highest_address))
-    {
-        background_mark_simple (o THREAD_NUMBER_ARG);
-    }
-    else
-    {
-        if (o)
-        {
-            dprintf (3, ("or-%p", o));
-        }
-    }
-    return o;
-}
-void gc_heap::background_promote (Object** ppObject, ScanContext* sc, uint32_t flags)
-{
-    UNREFERENCED_PARAMETER(sc);
-    assert (settings.concurrent);
-    THREAD_NUMBER_FROM_CONTEXT;
-#ifndef MULTIPLE_HEAPS
-    const int thread = 0;
-#endif //!MULTIPLE_HEAPS
-    uint8_t* o = (uint8_t*)*ppObject;
-    if (!is_in_find_object_range (o))
-    {
-        return;
-    }
-#ifdef DEBUG_DestroyedHandleValue
-    if (o == (uint8_t*)DEBUG_DestroyedHandleValue)
-        return;
-#endif //DEBUG_DestroyedHandleValue
-    HEAP_FROM_THREAD;
-    gc_heap* hp = gc_heap::heap_of (o);
-    if ((o < hp->background_saved_lowest_address) || (o >= hp->background_saved_highest_address))
-    {
-        return;
-    }
-    if (flags & GC_CALL_INTERIOR)
-    {
-        o = hp->find_object (o);
-        if (o == 0)
-            return;
-    }
-#ifdef FEATURE_CONSERVATIVE_GC
-    if (GCConfig::GetConservativeGC() && ((CObjectHeader*)o)->IsFree())
-    {
-        return;
-    }
-#endif //FEATURE_CONSERVATIVE_GC
-#ifdef _DEBUG
-    ((CObjectHeader*)o)->Validate();
-#endif //_DEBUG
-    STRESS_LOG3(LF_GC|LF_GCROOTS, LL_INFO1000000, "    GCHeap::Promote: Promote GC Root *%p = %p MT = %pT", ppObject, o, o ? ((Object*) o)->GetGCSafeMethodTable() : NULL);
-    hpt->background_mark_simple (o THREAD_NUMBER_ARG);
-}
-void
-gc_heap::scan_background_roots (promote_func* fn, int hn, ScanContext *pSC)
-{
-    ScanContext sc;
-    if (pSC == 0)
-        pSC = &sc;
-    pSC->thread_number = hn;
-    pSC->thread_count = n_heaps;
-    BOOL relocate_p = (fn == &GCHeap::Relocate);
-    dprintf (3, ("Scanning background mark list"));
-    size_t mark_list_finger = 0;
-    while (mark_list_finger < c_mark_list_index)
-    {
-        uint8_t** o = &c_mark_list [mark_list_finger];
-        if (!relocate_p)
-        {
-            size_t s = size (*o);
-            assert (Align (s) >= Align (min_obj_size));
-            dprintf(3,("background root %zx", (size_t)*o));
-        }
-        (*fn) ((Object**)o, pSC, 0);
-        mark_list_finger++;
-    }
-    dprintf (3, ("Scanning background mark stack"));
-    uint8_t** finger = background_mark_stack_array;
-    while (finger < background_mark_stack_tos)
-    {
-        if ((finger + 1) < background_mark_stack_tos)
-        {
-            uint8_t* parent_obj = *(finger + 1);
-            if ((size_t)parent_obj & 1)
-            {
-                uint8_t* place = *finger;
-                size_t place_offset = 0;
-                uint8_t* real_parent_obj = (uint8_t*)((size_t)parent_obj & ~1);
-                if (relocate_p)
-                {
-                    *(finger + 1) = real_parent_obj;
-                    place_offset = place - real_parent_obj;
-                    dprintf(3,("relocating background root %zx", (size_t)real_parent_obj));
-                    (*fn) ((Object**)(finger + 1), pSC, 0);
-                    real_parent_obj = *(finger + 1);
-                    *finger = real_parent_obj + place_offset;
-                    *(finger + 1) = (uint8_t*)((size_t)real_parent_obj | 1);
-                    dprintf(3,("roots changed to %p, %p", *finger, *(finger + 1)));
-                }
-                else
-                {
-                    uint8_t** temp = &real_parent_obj;
-                    dprintf(3,("marking background root %zx", (size_t)real_parent_obj));
-                    (*fn) ((Object**)temp, pSC, 0);
-                }
-                finger += 2;
-                continue;
-            }
-        }
-        dprintf(3,("background root %zx", (size_t)*finger));
-        (*fn) ((Object**)finger, pSC, 0);
-        finger++;
-    }
-}
-void gc_heap::grow_bgc_mark_stack (size_t new_size)
-{
-    if ((background_mark_stack_array_length < new_size) &&
-        ((new_size - background_mark_stack_array_length) > (background_mark_stack_array_length / 2)))
-    {
-        dprintf (2, ("h%d: ov grow to %zd", heap_number, new_size));
-        uint8_t** tmp = new (nothrow) uint8_t* [new_size];
-        if (tmp)
-        {
-            delete [] background_mark_stack_array;
-            background_mark_stack_array = tmp;
-            background_mark_stack_array_length = new_size;
-            background_mark_stack_tos = background_mark_stack_array;
-        }
-    }
-}
-void gc_heap::check_bgc_mark_stack_length()
-{
-    if ((settings.condemned_generation < (max_generation - 1)) || gc_heap::background_running_p())
-        return;
-    size_t total_heap_size = get_total_heap_size();
-    if (total_heap_size < ((size_t)4*1024*1024*1024))
-        return;
-#ifdef MULTIPLE_HEAPS
-    int total_heaps = n_heaps;
-#else
-    int total_heaps = 1;
-#endif //MULTIPLE_HEAPS
-    size_t size_based_on_heap = total_heap_size / (size_t)(100 * 100 * total_heaps * sizeof (uint8_t*));
-    size_t new_size = max (background_mark_stack_array_length, size_based_on_heap);
-    grow_bgc_mark_stack (new_size);
-}
-uint8_t* gc_heap::background_seg_end (heap_segment* seg, BOOL concurrent_p)
-{
-#ifndef USE_REGIONS
-    if (concurrent_p && (seg == saved_overflow_ephemeral_seg))
-    {
-        return background_min_soh_overflow_address;
-    }
-    else
-#endif //!USE_REGIONS
-    {
-        return heap_segment_allocated (seg);
-    }
-}
-uint8_t* gc_heap::background_first_overflow (uint8_t* min_add,
-                                          heap_segment* seg,
-                                          BOOL concurrent_p,
-                                          BOOL small_object_p)
-{
-#ifdef USE_REGIONS
-        return heap_segment_mem (seg);
-#else
-    uint8_t* o = 0;
-    if (small_object_p)
-    {
-        if (in_range_for_segment (min_add, seg))
-        {
-            if (min_add >= heap_segment_allocated (seg))
-            {
-                return min_add;
-            }
-            else
-            {
-                if (concurrent_p &&
-                    ((seg == saved_overflow_ephemeral_seg) && (min_add >= background_min_soh_overflow_address)))
-                {
-                    return background_min_soh_overflow_address;
-                }
-                else
-                {
-                    o = find_first_object (min_add, heap_segment_mem (seg));
-                    return o;
-                }
-            }
-        }
-    }
-    o = max (heap_segment_mem (seg), min_add);
-    return o;
-#endif //USE_REGIONS
-}
-void gc_heap::background_process_mark_overflow_internal (uint8_t* min_add, uint8_t* max_add,
-                                                         BOOL concurrent_p)
-{
-    if (concurrent_p)
-    {
-        current_bgc_state = bgc_overflow_soh;
-    }
-    size_t total_marked_objects = 0;
-#ifdef MULTIPLE_HEAPS
-    int thread = heap_number;
-#endif //MULTIPLE_HEAPS
-    int start_gen_idx = get_start_generation_index();
-#ifdef USE_REGIONS
-    if (concurrent_p)
-        start_gen_idx = max_generation;
-#endif //USE_REGIONS
-    exclusive_sync* loh_alloc_lock = 0;
-#ifndef USE_REGIONS
-    dprintf (2,("Processing Mark overflow [%zx %zx]", (size_t)min_add, (size_t)max_add));
-#endif
-#ifdef MULTIPLE_HEAPS
-    int h_start = (concurrent_p ? heap_number : 0);
-    int h_end = (concurrent_p ? (heap_number + 1) : n_heaps);
-    for (int hi = h_start; hi < h_end; hi++)
-    {
-        gc_heap*  hp = (concurrent_p ? this : g_heaps [(heap_number + hi) % n_heaps]);
-#else
-    {
-        gc_heap*  hp = 0;
-#endif //MULTIPLE_HEAPS
-        BOOL small_object_segments = TRUE;
-        loh_alloc_lock = hp->bgc_alloc_lock;
-        for (int i = start_gen_idx; i < total_generation_count; i++)
-        {
-            int align_const = get_alignment_constant (small_object_segments);
-            generation* gen = hp->generation_of (i);
-            heap_segment* seg = heap_segment_in_range (generation_start_segment (gen));
-            PREFIX_ASSUME(seg != NULL);
-            uint8_t* current_min_add = min_add;
-            uint8_t* current_max_add = max_add;
-            while (seg)
-            {
-#ifdef USE_REGIONS
-                if (heap_segment_overflow_p (seg))
-                {
-                    seg->flags &= ~heap_segment_flags_overflow;
-                    current_min_add = heap_segment_mem (seg);
-                    current_max_add = heap_segment_allocated (seg);
-                    dprintf (2,("Processing Mark overflow [%zx %zx]", (size_t)current_min_add, (size_t)current_max_add));
-                }
-                else
-                {
-                    current_min_add = current_max_add = 0;
-                }
-#endif //USE_REGIONS
-                uint8_t* o = hp->background_first_overflow (current_min_add, seg, concurrent_p, small_object_segments);
-                while ((o < hp->background_seg_end (seg, concurrent_p)) && (o <= current_max_add))
-                {
-                    dprintf (3, ("considering %zx", (size_t)o));
-                    size_t s;
-                    if (concurrent_p && !small_object_segments)
-                    {
-                        loh_alloc_lock->bgc_mark_set (o);
-                        if (((CObjectHeader*)o)->IsFree())
-                        {
-                            s = unused_array_size (o);
-                        }
-                        else
-                        {
-                            s = size (o);
-                        }
-                    }
-                    else
-                    {
-                        s = size (o);
-                    }
-                    if (background_object_marked (o, FALSE) && contain_pointers_or_collectible (o))
-                    {
-                        total_marked_objects++;
-                        go_through_object_cl (method_table(o), o, s, poo,
-                                              uint8_t* oo = *poo;
-                                              background_mark_object (oo THREAD_NUMBER_ARG);
-                                             );
-                    }
-                    if (concurrent_p && !small_object_segments)
-                    {
-                        loh_alloc_lock->bgc_mark_done ();
-                    }
-                    o = o + Align (s, align_const);
-                    if (concurrent_p)
-                    {
-                        allow_fgc();
-                    }
-                }
-#ifdef USE_REGIONS
-                if (current_max_add != 0)
-#endif //USE_REGIONS
-                {
-                    dprintf (2, ("went through overflow objects in segment %p (%d) (so far %zd marked)",
-                        heap_segment_mem (seg), (small_object_segments ? 0 : 1), total_marked_objects));
-                }
-#ifndef USE_REGIONS
-                if (concurrent_p && (seg == hp->saved_overflow_ephemeral_seg))
-                {
-                    break;
-                }
-#endif //!USE_REGIONS
-                seg = heap_segment_next_in_range (seg);
-            }
-            if (concurrent_p)
-            {
-                current_bgc_state = bgc_overflow_uoh;
-            }
-            dprintf (2, ("h%d: SOH: ov-mo: %zd", heap_number, total_marked_objects));
-            fire_overflow_event (min_add, max_add, total_marked_objects, i);
-            if (i >= soh_gen2)
-            {
-                concurrent_print_time_delta (concurrent_p ? "Cov SOH" : "Nov SOH");
-                small_object_segments = FALSE;
-            }
-            total_marked_objects = 0;
-        }
-    }
-}
-BOOL gc_heap::background_process_mark_overflow (BOOL concurrent_p)
-{
-    BOOL grow_mark_array_p = TRUE;
-    if (concurrent_p)
-    {
-        assert (!processed_eph_overflow_p);
-#ifndef USE_REGIONS
-        if ((background_max_overflow_address != 0) &&
-            (background_min_overflow_address != MAX_PTR))
-        {
-            saved_overflow_ephemeral_seg = ephemeral_heap_segment;
-            background_max_soh_overflow_address = heap_segment_reserved (saved_overflow_ephemeral_seg);
-            background_min_soh_overflow_address = generation_allocation_start (generation_of (max_generation - 1));
-        }
-#endif //!USE_REGIONS
-    }
-    else
-    {
-#ifndef USE_REGIONS
-        assert ((saved_overflow_ephemeral_seg == 0) ||
-                ((background_max_soh_overflow_address != 0) &&
-                 (background_min_soh_overflow_address != MAX_PTR)));
-#endif //!USE_REGIONS
-        if (!processed_eph_overflow_p)
-        {
-#ifdef USE_REGIONS
-            if (!background_overflow_p)
-#else
-            if ((background_max_overflow_address == 0) && (background_min_overflow_address == MAX_PTR))
-#endif //USE_REGIONS
-            {
-                dprintf (2, ("final processing mark overflow - no more overflow since last time"));
-                grow_mark_array_p = FALSE;
-            }
-#ifdef USE_REGIONS
-            background_overflow_p = TRUE;
-#else
-            background_min_overflow_address = min (background_min_overflow_address,
-                                                background_min_soh_overflow_address);
-            background_max_overflow_address = max (background_max_overflow_address,
-                                                background_max_soh_overflow_address);
-#endif //!USE_REGIONS
-            processed_eph_overflow_p = TRUE;
-        }
-    }
-    BOOL  overflow_p = FALSE;
-recheck:
-#ifdef USE_REGIONS
-    if (background_overflow_p)
-#else
-    if ((! ((background_max_overflow_address == 0)) ||
-         ! ((background_min_overflow_address == MAX_PTR))))
-#endif
-    {
-        overflow_p = TRUE;
-        if (grow_mark_array_p)
-        {
-            size_t new_size = max ((size_t)MARK_STACK_INITIAL_LENGTH, 2*background_mark_stack_array_length);
-            if ((new_size * sizeof(mark)) > 100*1024)
-            {
-                size_t new_max_size = (get_total_heap_size() / 10) / sizeof(mark);
-                new_size = min(new_max_size, new_size);
-            }
-            grow_bgc_mark_stack (new_size);
-        }
-        else
-        {
-            grow_mark_array_p = TRUE;
-        }
-#ifdef USE_REGIONS
-        uint8_t*  min_add = 0;
-        uint8_t*  max_add = 0;
-        background_overflow_p = FALSE;
-#else
-        uint8_t*  min_add = background_min_overflow_address;
-        uint8_t*  max_add = background_max_overflow_address;
-        background_max_overflow_address = 0;
-        background_min_overflow_address = MAX_PTR;
-#endif
-        background_process_mark_overflow_internal (min_add, max_add, concurrent_p);
-        if (!concurrent_p)
-        {
-            goto recheck;
-        }
-    }
-    return overflow_p;
-}
-#endif //BACKGROUND_GC
-inline
-void gc_heap::mark_through_object (uint8_t* oo, BOOL mark_class_object_p THREAD_NUMBER_DCL)
-{
-#ifndef COLLECTIBLE_CLASS
-    UNREFERENCED_PARAMETER(mark_class_object_p);
-    BOOL to_mark_class_object = FALSE;
-#else //COLLECTIBLE_CLASS
-    BOOL to_mark_class_object = (mark_class_object_p && (is_collectible(oo)));
-#endif //COLLECTIBLE_CLASS
-    if (contain_pointers (oo) || to_mark_class_object)
-    {
-        dprintf(3,( "Marking through %zx", (size_t)oo));
-        size_t s = size (oo);
-#ifdef COLLECTIBLE_CLASS
-        if (to_mark_class_object)
-        {
-            uint8_t* class_obj = get_class_object (oo);
-            mark_object (class_obj THREAD_NUMBER_ARG);
-        }
-#endif //COLLECTIBLE_CLASS
-        if (contain_pointers (oo))
-        {
-            go_through_object_nostart (method_table(oo), oo, s, po,
-                                uint8_t* o = *po;
-                                mark_object (o THREAD_NUMBER_ARG);
-                                );
-        }
-    }
-}
-size_t gc_heap::get_total_heap_size()
-{
-    size_t total_heap_size = 0;
-#ifdef MULTIPLE_HEAPS
-    int hn = 0;
-    for (hn = 0; hn < gc_heap::n_heaps; hn++)
-    {
-        gc_heap* hp2 = gc_heap::g_heaps [hn];
-        for (int i = max_generation; i < total_generation_count; i++)
-        {
-            total_heap_size += hp2->generation_sizes (hp2->generation_of (i));
-        }
-    }
-#else
-    for (int i = max_generation; i < total_generation_count; i++)
-    {
-        total_heap_size += generation_sizes (generation_of (i));
-    }
-#endif //MULTIPLE_HEAPS
-    return total_heap_size;
-}
-size_t gc_heap::get_total_fragmentation()
-{
-    size_t total_fragmentation = 0;
-#ifdef MULTIPLE_HEAPS
-    for (int hn = 0; hn < gc_heap::n_heaps; hn++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[hn];
-#else //MULTIPLE_HEAPS
-    {
-        gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-        for (int i = 0; i < total_generation_count; i++)
-        {
-            generation* gen = hp->generation_of (i);
-            total_fragmentation += (generation_free_list_space (gen) + generation_free_obj_space (gen));
-        }
-    }
-    return total_fragmentation;
-}
-size_t gc_heap::get_total_gen_fragmentation (int gen_number)
-{
-    size_t total_fragmentation = 0;
-#ifdef MULTIPLE_HEAPS
-    for (int hn = 0; hn < gc_heap::n_heaps; hn++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[hn];
-#else //MULTIPLE_HEAPS
-    {
-        gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-        generation* gen = hp->generation_of (gen_number);
-        total_fragmentation += (generation_free_list_space (gen) + generation_free_obj_space (gen));
-    }
-    return total_fragmentation;
-}
-#ifdef USE_REGIONS
-int gc_heap::get_total_new_gen0_regions_in_plns ()
-{
-    int total_new_gen0_regions_in_plns = 0;
-#ifdef MULTIPLE_HEAPS
-    for (int hn = 0; hn < gc_heap::n_heaps; hn++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[hn];
-#else //MULTIPLE_HEAPS
-    {
-        gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-        total_new_gen0_regions_in_plns += hp->new_gen0_regions_in_plns;
-    }
-    return total_new_gen0_regions_in_plns;
-}
-int gc_heap::get_total_new_regions_in_prr ()
-{
-    int total_new_regions_in_prr = 0;
-#ifdef MULTIPLE_HEAPS
-    for (int hn = 0; hn < gc_heap::n_heaps; hn++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[hn];
-#else //MULTIPLE_HEAPS
-        {
-            gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-            total_new_regions_in_prr += hp->new_regions_in_prr;
-        }
-        return total_new_regions_in_prr;
-}
-int gc_heap::get_total_new_regions_in_threading ()
-{
-    int total_new_regions_in_threading = 0;
-#ifdef MULTIPLE_HEAPS
-    for (int hn = 0; hn < gc_heap::n_heaps; hn++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[hn];
-#else //MULTIPLE_HEAPS
-    {
-        gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-        total_new_regions_in_threading += hp->new_regions_in_threading;
-    }
-    return total_new_regions_in_threading;
-}
-#endif //USE_REGIONS
-size_t gc_heap::get_total_gen_estimated_reclaim (int gen_number)
-{
-    size_t total_estimated_reclaim = 0;
-#ifdef MULTIPLE_HEAPS
-    for (int hn = 0; hn < gc_heap::n_heaps; hn++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[hn];
-#else //MULTIPLE_HEAPS
-    {
-        gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-        total_estimated_reclaim += hp->estimated_reclaim (gen_number);
-    }
-    return total_estimated_reclaim;
-}
-size_t gc_heap::get_total_gen_size (int gen_number)
-{
-#ifdef MULTIPLE_HEAPS
-    size_t size = 0;
-    for (int hn = 0; hn < gc_heap::n_heaps; hn++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[hn];
-        size += hp->generation_size (gen_number);
-    }
-#else
-    size_t size = generation_size (gen_number);
-#endif //MULTIPLE_HEAPS
-    return size;
-}
-size_t gc_heap::committed_size()
-{
-    size_t total_committed = 0;
-    const size_t kB = 1024;
-    for (int i = get_start_generation_index(); i < total_generation_count; i++)
-    {
-        generation* gen = generation_of (i);
-        heap_segment* seg = heap_segment_rw (generation_start_segment (gen));
-        size_t gen_committed = 0;
-        size_t gen_allocated = 0;
-        while (seg)
-        {
-            uint8_t* start =
-#ifdef USE_REGIONS
-                get_region_start (seg);
-#else
-                (uint8_t*)seg;
-#endif //USE_REGIONS
-            gen_committed += heap_segment_committed (seg) - start;
-            gen_allocated += heap_segment_allocated (seg) - start;
-            seg = heap_segment_next (seg);
-        }
-        dprintf (3, ("h%d committed in gen%d %zdkB, allocated %zdkB, committed-allocated %zdkB", heap_number, i, gen_committed/kB, gen_allocated/kB, (gen_committed - gen_allocated)/kB));
-        total_committed += gen_committed;
-    }
-#ifdef USE_REGIONS
-    size_t committed_in_free = 0;
-    for (int kind = basic_free_region; kind < count_free_region_kinds; kind++)
-    {
-        committed_in_free += free_regions[kind].get_size_committed_in_free();
-    }
-    dprintf (3, ("h%d committed in free %zdkB", heap_number, committed_in_free/kB));
-    total_committed += committed_in_free;
-#endif //USE_REGIONS
-    return total_committed;
-}
-size_t gc_heap::get_total_committed_size()
-{
-    size_t total_committed = 0;
-#ifdef MULTIPLE_HEAPS
-    int hn = 0;
-    for (hn = 0; hn < gc_heap::n_heaps; hn++)
-    {
-        gc_heap* hp = gc_heap::g_heaps [hn];
-        total_committed += hp->committed_size();
-    }
-#else
-    total_committed = committed_size();
-#endif //MULTIPLE_HEAPS
-    return total_committed;
-}
-size_t gc_heap::uoh_committed_size (int gen_number, size_t* allocated)
-{
-    generation* gen = generation_of (gen_number);
-    heap_segment* seg = heap_segment_rw (generation_start_segment (gen));
-    size_t total_committed = 0;
-    size_t total_allocated = 0;
-    while (seg)
-    {
-        uint8_t* start =
-#ifdef USE_REGIONS
-            get_region_start (seg);
-#else
-            (uint8_t*)seg;
-#endif //USE_REGIONS
-        total_committed += heap_segment_committed (seg) - start;
-        total_allocated += heap_segment_allocated (seg) - start;
-        seg = heap_segment_next (seg);
-    }
-    *allocated = total_allocated;
-    return total_committed;
-}
-void gc_heap::get_memory_info (uint32_t* memory_load,
-                               uint64_t* available_physical,
-                               uint64_t* available_page_file)
-{
-    GCToOSInterface::GetMemoryStatus(is_restricted_physical_mem ? total_physical_mem  : 0,  memory_load, available_physical, available_page_file);
-}
-BOOL gc_heap::process_mark_overflow(int condemned_gen_number)
-{
-    size_t last_promoted_bytes = get_promoted_bytes();
-    BOOL  overflow_p = FALSE;
-recheck:
-    drain_mark_queue();
-    if ((! (max_overflow_address == 0) ||
-         ! (min_overflow_address == MAX_PTR)))
-    {
-        overflow_p = TRUE;
-        size_t new_size =
-            max ((size_t)MARK_STACK_INITIAL_LENGTH, 2*mark_stack_array_length);
-        if ((new_size * sizeof(mark)) > 100*1024)
-        {
-            size_t new_max_size = (get_total_heap_size() / 10) / sizeof(mark);
-            new_size = min(new_max_size, new_size);
-        }
-        if ((mark_stack_array_length < new_size) &&
-            ((new_size - mark_stack_array_length) > (mark_stack_array_length / 2)))
-        {
-            mark* tmp = new (nothrow) mark [new_size];
-            if (tmp)
-            {
-                delete[] mark_stack_array;
-                mark_stack_array = tmp;
-                mark_stack_array_length = new_size;
-            }
-        }
-        uint8_t*  min_add = min_overflow_address;
-        uint8_t*  max_add = max_overflow_address;
-        max_overflow_address = 0;
-        min_overflow_address = MAX_PTR;
-        process_mark_overflow_internal (condemned_gen_number, min_add, max_add);
-        goto recheck;
-    }
-    size_t current_promoted_bytes = get_promoted_bytes();
-    if (current_promoted_bytes != last_promoted_bytes)
-        fire_mark_event (ETW::GC_ROOT_OVERFLOW, current_promoted_bytes, last_promoted_bytes);
-    return overflow_p;
-}
-void gc_heap::process_mark_overflow_internal (int condemned_gen_number,
-                                              uint8_t* min_add, uint8_t* max_add)
-{
-#ifdef MULTIPLE_HEAPS
-    int thread = heap_number;
-#endif //MULTIPLE_HEAPS
-    BOOL  full_p = (condemned_gen_number == max_generation);
-    dprintf(3,("Processing Mark overflow [%zx %zx]", (size_t)min_add, (size_t)max_add));
-    size_t obj_count = 0;
-#ifdef MULTIPLE_HEAPS
-    for (int hi = 0; hi < n_heaps; hi++)
-    {
-        gc_heap*  hp = g_heaps [(heap_number + hi) % n_heaps];
-#else
-    {
-        gc_heap*  hp = 0;
-#endif //MULTIPLE_HEAPS
-        int gen_limit = full_p ? total_generation_count : condemned_gen_number + 1;
-        for (int i = get_stop_generation_index (condemned_gen_number); i < gen_limit; i++)
-        {
-            generation* gen = hp->generation_of (i);
-            heap_segment* seg = heap_segment_in_range (generation_start_segment (gen));
-            int align_const = get_alignment_constant (i < uoh_start_generation);
-            PREFIX_ASSUME(seg != NULL);
-            while (seg)
-            {
-                uint8_t*  o = max (heap_segment_mem (seg), min_add);
-                uint8_t*  end = heap_segment_allocated (seg);
-                while ((o < end) && (o <= max_add))
-                {
-                    assert ((min_add <= o) && (max_add >= o));
-                    dprintf (3, ("considering %zx", (size_t)o));
-                    if (marked (o))
-                    {
-                        mark_through_object (o, TRUE THREAD_NUMBER_ARG);
-                        obj_count++;
-                    }
-                    o = o + Align (size (o), align_const);
-                }
-                seg = heap_segment_next_in_range (seg);
-            }
-        }
-#ifndef MULTIPLE_HEAPS
-        assert (obj_count > 0);
-#endif //MULTIPLE_HEAPS
-    }
-}
-#ifdef MULTIPLE_HEAPS
-static VOLATILE(BOOL) s_fUnpromotedHandles = FALSE;
-static VOLATILE(BOOL) s_fUnscannedPromotions = FALSE;
-static VOLATILE(BOOL) s_fScanRequired;
-void gc_heap::scan_dependent_handles (int condemned_gen_number, ScanContext *sc, BOOL initial_scan_p)
-{
-    s_fUnscannedPromotions = TRUE;
-    while (true)
-    {
-        if (GCScan::GcDhUnpromotedHandlesExist(sc))
-            s_fUnpromotedHandles = TRUE;
-        drain_mark_queue();
-        gc_t_join.join(this, gc_join_scan_dependent_handles);
-        if (gc_t_join.joined())
-        {
-            s_fScanRequired = s_fUnscannedPromotions && s_fUnpromotedHandles;
-            s_fUnscannedPromotions = FALSE;
-            s_fUnpromotedHandles = FALSE;
-            if (!s_fScanRequired)
-            {
-                if (!initial_scan_p)
-                {
-                    uint8_t* all_heaps_max = 0;
-                    uint8_t* all_heaps_min = MAX_PTR;
-                    int i;
-                    for (i = 0; i < n_heaps; i++)
-                    {
-                        if (all_heaps_max < g_heaps[i]->max_overflow_address)
-                            all_heaps_max = g_heaps[i]->max_overflow_address;
-                        if (all_heaps_min > g_heaps[i]->min_overflow_address)
-                            all_heaps_min = g_heaps[i]->min_overflow_address;
-                    }
-                    for (i = 0; i < n_heaps; i++)
-                    {
-                        g_heaps[i]->max_overflow_address = all_heaps_max;
-                        g_heaps[i]->min_overflow_address = all_heaps_min;
-                    }
-                }
-            }
-            dprintf(3, ("Starting all gc thread mark stack overflow processing"));
-            gc_t_join.restart();
-        }
-        if (process_mark_overflow(condemned_gen_number))
-            s_fUnscannedPromotions = TRUE;
-        if (!s_fScanRequired)
-            break;
-        gc_t_join.join(this, gc_join_rescan_dependent_handles);
-        if (gc_t_join.joined())
-        {
-            dprintf(3, ("Starting all gc thread for dependent handle promotion"));
-            gc_t_join.restart();
-        }
-        if (GCScan::GcDhUnpromotedHandlesExist(sc))
-            if (GCScan::GcDhReScan(sc))
-                s_fUnscannedPromotions = TRUE;
-    }
-}
-#else //MULTIPLE_HEAPS
-void gc_heap::scan_dependent_handles (int condemned_gen_number, ScanContext *sc, BOOL initial_scan_p)
-{
-    UNREFERENCED_PARAMETER(initial_scan_p);
-    bool fUnscannedPromotions = true;
-    while (GCScan::GcDhUnpromotedHandlesExist(sc) && fUnscannedPromotions)
-    {
-        fUnscannedPromotions = false;
-        if (process_mark_overflow(condemned_gen_number))
-            fUnscannedPromotions = true;
-        mark_queue.verify_empty();
-        if (GCScan::GcDhReScan(sc))
-            fUnscannedPromotions = true;
-    }
-    process_mark_overflow(condemned_gen_number);
-}
-#endif //MULTIPLE_HEAPS
-size_t gc_heap::get_generation_start_size (int gen_number)
-{
-#ifdef USE_REGIONS
-    return 0;
-#else
-    return Align (size (generation_allocation_start (generation_of (gen_number))),
-                  get_alignment_constant (gen_number <= max_generation));
-#endif //!USE_REGIONS
-}
-inline
-int gc_heap::get_num_heaps()
-{
-#ifdef MULTIPLE_HEAPS
-    return n_heaps;
-#else
-    return 1;
-#endif //MULTIPLE_HEAPS
-}
-BOOL gc_heap::decide_on_promotion_surv (size_t threshold)
-{
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < gc_heap::n_heaps; i++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[i];
-#else //MULTIPLE_HEAPS
-    {
-        gc_heap* hp = pGenGCHeap;
-        int i = 0;
-#endif //MULTIPLE_HEAPS
-        dynamic_data* dd = hp->dynamic_data_of (min ((int)(settings.condemned_generation + 1), (int)max_generation));
-        size_t older_gen_size = dd_current_size (dd) + (dd_desired_allocation (dd) - dd_new_allocation (dd));
-        size_t promoted = hp->total_promoted_bytes;
-        dprintf (6666, ("h%d promotion threshold: %zd, promoted bytes: %zd size n+1: %zd -> %s",
-            i, threshold, promoted, older_gen_size,
-            (((threshold > (older_gen_size)) || (promoted > threshold)) ? "promote" : "don't promote")));
-        if ((threshold > (older_gen_size)) || (promoted > threshold))
-        {
-            return TRUE;
-        }
-    }
-    return FALSE;
-}
-inline
-void gc_heap::fire_mark_event (int root_type, size_t& current_promoted_bytes, size_t& last_promoted_bytes)
-{
-#ifdef FEATURE_EVENT_TRACE
-    if (informational_event_enabled_p)
-    {
-        current_promoted_bytes = get_promoted_bytes();
-        size_t root_promoted = current_promoted_bytes - last_promoted_bytes;
-        dprintf (3, ("h%d marked root %s: %zd (%zd - %zd)",
-            heap_number, str_root_kinds[root_type], root_promoted,
-            current_promoted_bytes, last_promoted_bytes));
-        FIRE_EVENT(GCMarkWithType, heap_number, root_type, root_promoted);
-        last_promoted_bytes = current_promoted_bytes;
-    }
-#endif // FEATURE_EVENT_TRACE
-}
-#ifdef FEATURE_EVENT_TRACE
-inline
-void gc_heap::record_mark_time (uint64_t& mark_time,
-                                uint64_t& current_mark_time,
-                                uint64_t& last_mark_time)
-{
-    if (informational_event_enabled_p)
-    {
-        current_mark_time = GetHighPrecisionTimeStamp();
-        mark_time = limit_time_to_uint32 (current_mark_time - last_mark_time);
-        dprintf (3, ("%zd - %zd = %zd",
-            current_mark_time, last_mark_time, (current_mark_time - last_mark_time)));
-        last_mark_time = current_mark_time;
-    }
-}
-#endif // FEATURE_EVENT_TRACE
-#ifdef USE_REGIONS
-void gc_heap::verify_region_to_generation_map()
-{
-#ifdef _DEBUG
-    uint8_t* local_ephemeral_low = MAX_PTR;
-    uint8_t* local_ephemeral_high = nullptr;
-    for (int gen_number = soh_gen0; gen_number < total_generation_count; gen_number++)
-    {
-#ifdef MULTIPLE_HEAPS
-        for (int i = 0; i < n_heaps; i++)
-        {
-            gc_heap* hp = g_heaps[i];
-#else //MULTIPLE_HEAPS
-        {
-            gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-            generation *gen = hp->generation_of (gen_number);
-            for (heap_segment *region = generation_start_segment (gen); region != nullptr; region = heap_segment_next (region))
-            {
-                if (heap_segment_read_only_p (region))
-                {
-                    continue;
-                }
-                size_t region_index_start = get_basic_region_index_for_address (get_region_start (region));
-                size_t region_index_end = get_basic_region_index_for_address (heap_segment_reserved (region));
-                int gen_num = min (gen_number, (int)soh_gen2);
-                assert (gen_num == heap_segment_gen_num (region));
-                int plan_gen_num = heap_segment_plan_gen_num (region);
-                bool is_demoted = (region->flags & heap_segment_flags_demoted) != 0;
-                bool is_sweep_in_plan = heap_segment_swept_in_plan (region);
-                for (size_t region_index = region_index_start; region_index < region_index_end; region_index++)
-                {
-                    region_info region_info_bits = map_region_to_generation[region_index];
-                    assert ((region_info_bits & RI_GEN_MASK) == gen_num);
-                    assert ((region_info_bits >> RI_PLAN_GEN_SHR) == plan_gen_num);
-                    assert (((region_info_bits & RI_SIP) != 0) == is_sweep_in_plan);
-                    assert (((region_info_bits & RI_DEMOTED) != 0) == is_demoted);
-                }
-            }
-        }
-    }
-#endif //_DEBUG
-}
-void gc_heap::compute_gc_and_ephemeral_range (int condemned_gen_number, bool end_of_gc_p)
-{
-    ephemeral_low = MAX_PTR;
-    ephemeral_high = nullptr;
-    gc_low = MAX_PTR;
-    gc_high = nullptr;
-    if (condemned_gen_number >= soh_gen2 || end_of_gc_p)
-    {
-        gc_low = g_gc_lowest_address;
-        gc_high = g_gc_highest_address;
-    }
-    if (end_of_gc_p)
-    {
-#if 1
-        ephemeral_low = g_gc_lowest_address;
-#else
-        uint8_t* addr = g_gc_lowest_address;
-        while (true)
-        {
-            heap_segment* region = get_region_info (addr);
-            if (is_free_region (region))
-                break;
-            if (heap_segment_gen_num (region) <= soh_gen1)
-                break;
-            addr += ((size_t)1) << min_segment_size_shr;
-        }
-        ephemeral_low = addr;
-#endif
-        ephemeral_high = g_gc_highest_address;
-    }
-    else
-    {
-        for (int gen_number = soh_gen0; gen_number <= soh_gen1; gen_number++)
-        {
-#ifdef MULTIPLE_HEAPS
-            for (int i = 0; i < n_heaps; i++)
-            {
-                gc_heap* hp = g_heaps[i];
-#else //MULTIPLE_HEAPS
-            {
-                gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-                generation *gen = hp->generation_of (gen_number);
-                for (heap_segment *region = generation_start_segment (gen); region != nullptr; region = heap_segment_next (region))
-                {
-                    ephemeral_low = min ((uint8_t*)ephemeral_low, get_region_start (region));
-                    ephemeral_high = max ((uint8_t*)ephemeral_high, heap_segment_reserved (region));
-                    if (gen_number <= condemned_gen_number)
-                    {
-                        gc_low = min (gc_low, get_region_start (region));
-                        gc_high = max (gc_high, heap_segment_reserved (region));
-                    }
-                }
-            }
-        }
-    }
-    dprintf (2, ("ephemeral_low = %p, ephemeral_high = %p, gc_low = %p, gc_high = %p", (uint8_t*)ephemeral_low, (uint8_t*)ephemeral_high, gc_low, gc_high));
-}
-#endif //USE_REGIONS
-void gc_heap::mark_phase (int condemned_gen_number)
-{
-    assert (settings.concurrent == FALSE);
-    ScanContext sc;
-    sc.thread_number = heap_number;
-    sc.thread_count = n_heaps;
-    sc.promotion = TRUE;
-    sc.concurrent = FALSE;
-    dprintf (2, (ThreadStressLog::gcStartMarkMsg(), heap_number, condemned_gen_number));
-    BOOL  full_p = (condemned_gen_number == max_generation);
-    int gen_to_init = condemned_gen_number;
-    if (condemned_gen_number == max_generation)
-    {
-        gen_to_init = total_generation_count - 1;
-    }
-    for (int gen_idx = 0; gen_idx <= gen_to_init; gen_idx++)
-    {
-        dynamic_data* dd = dynamic_data_of (gen_idx);
-        dd_begin_data_size (dd) = generation_size (gen_idx) -
-                                   dd_fragmentation (dd) -
-#ifdef USE_REGIONS
-                                   0;
-#else
-                                   get_generation_start_size (gen_idx);
-#endif //USE_REGIONS
-        dprintf (2, ("begin data size for gen%d is %zd", gen_idx, dd_begin_data_size (dd)));
-        dd_survived_size (dd) = 0;
-        dd_pinned_survived_size (dd) = 0;
-        dd_artificial_pinned_survived_size (dd) = 0;
-        dd_added_pinned_size (dd) = 0;
-#ifdef SHORT_PLUGS
-        dd_padding_size (dd) = 0;
-#endif //SHORT_PLUGS
-#if defined (RESPECT_LARGE_ALIGNMENT) || defined (FEATURE_STRUCTALIGN)
-        dd_num_npinned_plugs (dd) = 0;
-#endif //RESPECT_LARGE_ALIGNMENT || FEATURE_STRUCTALIGN
-    }
-    if (gen0_must_clear_bricks > 0)
-        gen0_must_clear_bricks--;
-    size_t last_promoted_bytes = 0;
-    size_t current_promoted_bytes = 0;
-#if !defined(USE_REGIONS) || defined(_DEBUG)
-    init_promoted_bytes();
-#endif //!USE_REGIONS || _DEBUG
-    reset_mark_stack();
-#ifdef SNOOP_STATS
-    memset (&snoop_stat, 0, sizeof(snoop_stat));
-    snoop_stat.heap_index = heap_number;
-#endif //SNOOP_STATS
-#ifdef MH_SC_MARK
-    if (full_p)
-    {
-        for (int i = 0; i < max_snoop_level; i++)
-        {
-            ((uint8_t**)(mark_stack_array))[i] = 0;
-        }
-        mark_stack_busy() = 1;
-    }
-#endif //MH_SC_MARK
-    static uint32_t num_sizedrefs = 0;
-#ifdef MH_SC_MARK
-    static BOOL do_mark_steal_p = FALSE;
-#endif //MH_SC_MARK
-#ifdef FEATURE_CARD_MARKING_STEALING
-    reset_card_marking_enumerators();
-#endif // FEATURE_CARD_MARKING_STEALING
-#ifdef STRESS_REGIONS
-    heap_segment* gen0_region = generation_start_segment (generation_of (0));
-    while (gen0_region)
-    {
-        size_t gen0_region_size = heap_segment_allocated (gen0_region) - heap_segment_mem (gen0_region);
-        if (gen0_region_size > 0)
-        {
-            if ((num_gen0_regions % pinning_seg_interval) == 0)
-            {
-                dprintf (REGIONS_LOG, ("h%d potentially creating pinning in region %zx",
-                    heap_number, heap_segment_mem (gen0_region)));
-                int align_const = get_alignment_constant (TRUE);
-                uint8_t* boundary = heap_segment_mem (gen0_region);
-                uint8_t* obj_to_pin = boundary;
-                int num_pinned_objs = 0;
-                while (obj_to_pin < heap_segment_allocated (gen0_region))
-                {
-                    if (obj_to_pin >= boundary && !((CObjectHeader*)obj_to_pin)->IsFree())
-                    {
-                        pin_by_gc (obj_to_pin);
-                        num_pinned_objs++;
-                        if (num_pinned_objs >= 2)
-                            break;
-                        boundary += (gen0_region_size / 2) + 1;
-                    }
-                    obj_to_pin += Align (size (obj_to_pin), align_const);
-                }
-            }
-        }
-        num_gen0_regions++;
-        gen0_region = heap_segment_next (gen0_region);
-    }
-#endif //STRESS_REGIONS
-#ifdef FEATURE_EVENT_TRACE
-    static uint64_t current_mark_time = 0;
-    static uint64_t last_mark_time = 0;
-#endif //FEATURE_EVENT_TRACE
-#ifdef USE_REGIONS
-    special_sweep_p = false;
-#endif //USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-    gc_t_join.join(this, gc_join_begin_mark_phase);
-    if (gc_t_join.joined())
-#endif //MULTIPLE_HEAPS
-    {
-        maxgen_size_inc_p = false;
-#ifdef USE_REGIONS
-        region_count = global_region_allocator.get_used_region_count();
-        grow_mark_list_piece();
-        verify_region_to_generation_map();
-        compute_gc_and_ephemeral_range (condemned_gen_number, false);
-#endif //USE_REGIONS
-        GCToEEInterface::BeforeGcScanRoots(condemned_gen_number, /* is_bgc */ false, /* is_concurrent */ false);
-        num_sizedrefs = GCToEEInterface::GetTotalNumSizedRefHandles();
-#ifdef FEATURE_EVENT_TRACE
-        informational_event_enabled_p = EVENT_ENABLED (GCMarkWithType);
-        if (informational_event_enabled_p)
-        {
-            last_mark_time = GetHighPrecisionTimeStamp();
-            gc_time_info[time_mark_sizedref] = 0;
-        }
-#endif //FEATURE_EVENT_TRACE
-#ifdef MULTIPLE_HEAPS
-#ifdef MH_SC_MARK
-        if (full_p)
-        {
-            size_t total_heap_size = get_total_heap_size();
-            if (total_heap_size > (100 * 1024 * 1024))
-            {
-                do_mark_steal_p = TRUE;
-            }
-            else
-            {
-                do_mark_steal_p = FALSE;
-            }
-        }
-        else
-        {
-            do_mark_steal_p = FALSE;
-        }
-#endif //MH_SC_MARK
-        gc_t_join.restart();
-#endif //MULTIPLE_HEAPS
-    }
-    {
-        assert (g_mark_list);
-#ifdef MULTIPLE_HEAPS
-        mark_list_size = g_mark_list_total_size / n_heaps;
-        mark_list = &g_mark_list [heap_number*mark_list_size];
-#else
-        mark_list = g_mark_list;
-#endif //MULTIPLE_HEAPS
-        if (condemned_gen_number < max_generation)
-            mark_list_end = &mark_list [mark_list_size-1];
-        else
-            mark_list_end = &mark_list [0];
-        mark_list_index = &mark_list [0];
-#ifdef USE_REGIONS
-        if (g_mark_list_piece != nullptr)
-        {
-#ifdef MULTIPLE_HEAPS
-            mark_list_piece_start = &g_mark_list_piece[heap_number * 2 * g_mark_list_piece_size];
-            mark_list_piece_end = &mark_list_piece_start[g_mark_list_piece_size];
-#endif //MULTIPLE_HEAPS
-            survived_per_region = (size_t*)&g_mark_list_piece[heap_number * 2 * g_mark_list_piece_size];
-            old_card_survived_per_region = (size_t*)&survived_per_region[g_mark_list_piece_size];
-            size_t region_info_to_clear = region_count * sizeof (size_t);
-            memset (survived_per_region, 0, region_info_to_clear);
-            memset (old_card_survived_per_region, 0, region_info_to_clear);
-        }
-        else
-        {
-#ifdef MULTIPLE_HEAPS
-            mark_list_piece_start = nullptr;
-            mark_list_piece_end = nullptr;
-            mark_list_end = &mark_list[0];
-#endif //MULTIPLE_HEAPS
-            survived_per_region = nullptr;
-            old_card_survived_per_region = nullptr;
-        }
-#endif // USE_REGIONS && MULTIPLE_HEAPS
-#ifndef MULTIPLE_HEAPS
-        shigh = (uint8_t*) 0;
-        slow  = MAX_PTR;
-#endif //MULTIPLE_HEAPS
-        if ((condemned_gen_number == max_generation) && (num_sizedrefs > 0))
-        {
-            GCScan::GcScanSizedRefs(GCHeap::Promote, condemned_gen_number, max_generation, &sc);
-            drain_mark_queue();
-            fire_mark_event (ETW::GC_ROOT_SIZEDREF, current_promoted_bytes, last_promoted_bytes);
-#ifdef MULTIPLE_HEAPS
-            gc_t_join.join(this, gc_join_scan_sizedref_done);
-            if (gc_t_join.joined())
-#endif //MULTIPLE_HEAPS
-            {
-#ifdef FEATURE_EVENT_TRACE
-                record_mark_time (gc_time_info[time_mark_sizedref], current_mark_time, last_mark_time);
-#endif //FEATURE_EVENT_TRACE
-#ifdef MULTIPLE_HEAPS
-                dprintf(3, ("Done with marking all sized refs. Starting all gc thread for marking other strong roots"));
-                gc_t_join.restart();
-#endif //MULTIPLE_HEAPS
-            }
-        }
-#if defined(FEATURE_BASICFREEZE) && !defined(USE_REGIONS)
-        if (ro_segments_in_range)
-        {
-            dprintf(3,("Marking in range ro segments"));
-            mark_ro_segments();
-        }
-#endif //FEATURE_BASICFREEZE && !USE_REGIONS
-        dprintf(3,("Marking Roots"));
-        GCScan::GcScanRoots(GCHeap::Promote,
-                                condemned_gen_number, max_generation,
-                                &sc);
-        drain_mark_queue();
-        fire_mark_event (ETW::GC_ROOT_STACK, current_promoted_bytes, last_promoted_bytes);
-#ifdef BACKGROUND_GC
-        if (gc_heap::background_running_p())
-        {
-            scan_background_roots (GCHeap::Promote, heap_number, &sc);
-            drain_mark_queue();
-            fire_mark_event (ETW::GC_ROOT_BGC, current_promoted_bytes, last_promoted_bytes);
-        }
-#endif //BACKGROUND_GC
-#ifdef FEATURE_PREMORTEM_FINALIZATION
-        dprintf(3, ("Marking finalization data"));
-        finalize_queue->GcScanRoots(GCHeap::Promote, heap_number, 0);
-        drain_mark_queue();
-        fire_mark_event (ETW::GC_ROOT_FQ, current_promoted_bytes, last_promoted_bytes);
-#endif // FEATURE_PREMORTEM_FINALIZATION
-        dprintf(3,("Marking handle table"));
-        GCScan::GcScanHandles(GCHeap::Promote,
-                                    condemned_gen_number, max_generation,
-                                    &sc);
-        drain_mark_queue();
-        fire_mark_event (ETW::GC_ROOT_HANDLES, current_promoted_bytes, last_promoted_bytes);
-        if (!full_p)
-        {
-#ifdef USE_REGIONS
-            save_current_survived();
-#endif //USE_REGIONS
-#ifdef FEATURE_CARD_MARKING_STEALING
-            n_eph_soh = 0;
-            n_gen_soh = 0;
-            n_eph_loh = 0;
-            n_gen_loh = 0;
-#endif //FEATURE_CARD_MARKING_STEALING
-#ifdef CARD_BUNDLE
-#ifdef MULTIPLE_HEAPS
-            if (gc_t_join.r_join(this, gc_r_join_update_card_bundle))
-            {
-#endif //MULTIPLE_HEAPS
-#ifndef FEATURE_MANUALLY_MANAGED_CARD_BUNDLES
-                update_card_table_bundle();
-#endif
-                if (card_bundles_enabled())
-                {
-                    verify_card_bundles();
-                }
-#ifdef MULTIPLE_HEAPS
-                gc_t_join.r_restart();
-            }
-#endif //MULTIPLE_HEAPS
-#endif //CARD_BUNDLE
-            card_fn mark_object_fn = &gc_heap::mark_object_simple;
-#ifdef HEAP_ANALYZE
-            heap_analyze_success = TRUE;
-            if (heap_analyze_enabled)
-            {
-                internal_root_array_index = 0;
-                current_obj = 0;
-                current_obj_size = 0;
-                mark_object_fn = &gc_heap::ha_mark_object_simple;
-            }
-#endif //HEAP_ANALYZE
-#if defined(MULTIPLE_HEAPS) && defined(FEATURE_CARD_MARKING_STEALING)
-            if (!card_mark_done_soh)
-#endif // MULTIPLE_HEAPS && FEATURE_CARD_MARKING_STEALING
-            {
-                dprintf (3, ("Marking cross generation pointers on heap %d", heap_number));
-                mark_through_cards_for_segments(mark_object_fn, FALSE THIS_ARG);
-#if defined(MULTIPLE_HEAPS) && defined(FEATURE_CARD_MARKING_STEALING)
-                card_mark_done_soh = true;
-#endif // MULTIPLE_HEAPS && FEATURE_CARD_MARKING_STEALING
-            }
-#if defined(MULTIPLE_HEAPS) && defined(FEATURE_CARD_MARKING_STEALING)
-            if (!card_mark_done_uoh)
-#endif // MULTIPLE_HEAPS && FEATURE_CARD_MARKING_STEALING
-            {
-                dprintf (3, ("Marking cross generation pointers for uoh objects on heap %d", heap_number));
-                for (int i = uoh_start_generation; i < total_generation_count; i++)
-                {
-#ifndef ALLOW_REFERENCES_IN_POH
-                    if (i != poh_generation)
-#endif //ALLOW_REFERENCES_IN_POH
-                        mark_through_cards_for_uoh_objects(mark_object_fn, i, FALSE THIS_ARG);
-                }
-#if defined(MULTIPLE_HEAPS) && defined(FEATURE_CARD_MARKING_STEALING)
-                card_mark_done_uoh = true;
-#endif // MULTIPLE_HEAPS && FEATURE_CARD_MARKING_STEALING
-            }
-#if defined(MULTIPLE_HEAPS) && defined(FEATURE_CARD_MARKING_STEALING)
-            for (int i = 0; i < gc_heap::n_heaps; i++)
-            {
-                int heap_number_to_look_at = (i + heap_number) % gc_heap::n_heaps;
-                gc_heap* hp = gc_heap::g_heaps[heap_number_to_look_at];
-                if (!hp->card_mark_done_soh)
-                {
-                    dprintf(3, ("Marking cross generation pointers on heap %d", hp->heap_number));
-                    hp->mark_through_cards_for_segments(mark_object_fn, FALSE THIS_ARG);
-                    hp->card_mark_done_soh = true;
-                }
-                if (!hp->card_mark_done_uoh)
-                {
-                    dprintf(3, ("Marking cross generation pointers for large objects on heap %d", hp->heap_number));
-                    for (int i = uoh_start_generation; i < total_generation_count; i++)
-                    {
-#ifndef ALLOW_REFERENCES_IN_POH
-                        if (i != poh_generation)
-#endif //ALLOW_REFERENCES_IN_POH
-                            hp->mark_through_cards_for_uoh_objects(mark_object_fn, i, FALSE THIS_ARG);
-                    }
-                    hp->card_mark_done_uoh = true;
-                }
-            }
-#endif // MULTIPLE_HEAPS && FEATURE_CARD_MARKING_STEALING
-#ifdef USE_REGIONS
-            update_old_card_survived();
-#endif //USE_REGIONS
-            drain_mark_queue();
-            fire_mark_event (ETW::GC_ROOT_OLDER, current_promoted_bytes, last_promoted_bytes);
-        }
-    }
-#ifdef MH_SC_MARK
-    if (do_mark_steal_p)
-    {
-        mark_steal();
-        drain_mark_queue();
-        fire_mark_event (ETW::GC_ROOT_STEAL, current_promoted_bytes, last_promoted_bytes);
-    }
-#endif //MH_SC_MARK
-    GCScan::GcDhInitialScan(GCHeap::Promote, condemned_gen_number, max_generation, &sc);
-    scan_dependent_handles(condemned_gen_number, &sc, true);
-    mark_queue.verify_empty();
-    fire_mark_event (ETW::GC_ROOT_DH_HANDLES, current_promoted_bytes, last_promoted_bytes);
-#ifdef MULTIPLE_HEAPS
-    dprintf(3, ("Joining for short weak handle scan"));
-    gc_t_join.join(this, gc_join_null_dead_short_weak);
-    if (gc_t_join.joined())
-#endif //MULTIPLE_HEAPS
-    {
-#ifdef FEATURE_EVENT_TRACE
-        record_mark_time (gc_time_info[time_mark_roots], current_mark_time, last_mark_time);
-#endif //FEATURE_EVENT_TRACE
-        uint64_t promoted_bytes_global = 0;
-#ifdef HEAP_ANALYZE
-        heap_analyze_enabled = FALSE;
-#ifdef MULTIPLE_HEAPS
-        for (int i = 0; i < n_heaps; i++)
-        {
-            promoted_bytes_global += g_heaps[i]->get_promoted_bytes();
-        }
-#else
-        promoted_bytes_global = get_promoted_bytes();
-#endif //MULTIPLE_HEAPS
-        GCToEEInterface::AnalyzeSurvivorsFinished (settings.gc_index, condemned_gen_number, promoted_bytes_global, GCHeap::ReportGenerationBounds);
-#endif // HEAP_ANALYZE
-        GCToEEInterface::AfterGcScanRoots (condemned_gen_number, max_generation, &sc);
-#ifdef MULTIPLE_HEAPS
-        if (!full_p)
-        {
-            gc_t_join.r_init();
-        }
-        dprintf(3, ("Starting all gc thread for short weak handle scan"));
-        gc_t_join.restart();
-#endif //MULTIPLE_HEAPS
-    }
-#ifdef FEATURE_CARD_MARKING_STEALING
-    reset_card_marking_enumerators();
-    if (!full_p)
-    {
-        int generation_skip_ratio_soh = ((n_eph_soh > MIN_SOH_CROSS_GEN_REFS) ?
-                                         (int)(((float)n_gen_soh / (float)n_eph_soh) * 100) : 100);
-        int generation_skip_ratio_loh = ((n_eph_loh > MIN_LOH_CROSS_GEN_REFS) ?
-                                         (int)(((float)n_gen_loh / (float)n_eph_loh) * 100) : 100);
-        generation_skip_ratio = min (generation_skip_ratio_soh, generation_skip_ratio_loh);
-#ifdef SIMPLE_DPRINTF
-        dprintf (6666, ("h%d skip ratio soh: %d (n_gen_soh: %Id, n_eph_soh: %Id), loh: %d (n_gen_loh: %Id, n_eph_loh: %Id), size 0: %Id-%Id, 1: %Id-%Id, 2: %Id-%Id, 3: %Id-%Id",
-            heap_number,
-            generation_skip_ratio_soh, VolatileLoadWithoutBarrier (&n_gen_soh), VolatileLoadWithoutBarrier (&n_eph_soh),
-            generation_skip_ratio_loh, VolatileLoadWithoutBarrier (&n_gen_loh), VolatileLoadWithoutBarrier (&n_eph_loh),
-            generation_size (0), dd_fragmentation (dynamic_data_of (0)),
-            generation_size (1), dd_fragmentation (dynamic_data_of (1)),
-            generation_size (2), dd_fragmentation (dynamic_data_of (2)),
-            generation_size (3), dd_fragmentation (dynamic_data_of (3))));
-#endif //SIMPLE_DPRINTF
-    }
-#endif // FEATURE_CARD_MARKING_STEALING
-    GCScan::GcShortWeakPtrScan (condemned_gen_number, max_generation,&sc);
-#ifdef MULTIPLE_HEAPS
-    dprintf(3, ("Joining for finalization"));
-    gc_t_join.join(this, gc_join_scan_finalization);
-    if (gc_t_join.joined())
-    {
-#endif //MULTIPLE_HEAPS
-#ifdef FEATURE_EVENT_TRACE
-        record_mark_time (gc_time_info[time_mark_short_weak], current_mark_time, last_mark_time);
-#endif //FEATURE_EVENT_TRACE
-#ifdef MULTIPLE_HEAPS
-        dprintf(3, ("Starting all gc thread for Finalization"));
-        gc_t_join.restart();
-    }
-#endif //MULTIPLE_HEAPS
-    size_t promoted_bytes_live = get_promoted_bytes();
-#ifdef FEATURE_PREMORTEM_FINALIZATION
-    dprintf (3, ("Finalize marking"));
-    finalize_queue->ScanForFinalization (GCHeap::Promote, condemned_gen_number, __this);
-    drain_mark_queue();
-    fire_mark_event (ETW::GC_ROOT_NEW_FQ, current_promoted_bytes, last_promoted_bytes);
-    GCToEEInterface::DiagWalkFReachableObjects(__this);
-    scan_dependent_handles(condemned_gen_number, &sc, false);
-    mark_queue.verify_empty();
-    fire_mark_event (ETW::GC_ROOT_DH_HANDLES, current_promoted_bytes, last_promoted_bytes);
-#endif //FEATURE_PREMORTEM_FINALIZATION
-    total_promoted_bytes = get_promoted_bytes();
-#ifdef MULTIPLE_HEAPS
-    static VOLATILE(int32_t) syncblock_scan_p;
-    dprintf(3, ("Joining for weak pointer deletion"));
-    gc_t_join.join(this, gc_join_null_dead_long_weak);
-    if (gc_t_join.joined())
-    {
-        dprintf(3, ("Starting all gc thread for weak pointer deletion"));
-#endif //MULTIPLE_HEAPS
-#ifdef FEATURE_EVENT_TRACE
-        record_mark_time (gc_time_info[time_mark_scan_finalization], current_mark_time, last_mark_time);
-#endif //FEATURE_EVENT_TRACE
-#ifdef USE_REGIONS
-        sync_promoted_bytes();
-        equalize_promoted_bytes(settings.condemned_generation);
-#endif //USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-        syncblock_scan_p = 0;
-        gc_t_join.restart();
-    }
-#endif //MULTIPLE_HEAPS
-    GCScan::GcWeakPtrScan (condemned_gen_number, max_generation, &sc);
-#ifdef MULTIPLE_HEAPS
-    size_t total_mark_list_size = sort_mark_list();
-    if ((syncblock_scan_p == 0) && (Interlocked::Increment(&syncblock_scan_p) == 1))
-#endif //MULTIPLE_HEAPS
-    {
-        GCScan::GcWeakPtrScanBySingleThread(condemned_gen_number, max_generation, &sc);
-    }
-#ifdef MULTIPLE_HEAPS
-    dprintf (3, ("Joining for sync block cache entry scanning"));
-    gc_t_join.join(this, gc_join_null_dead_syncblk);
-    if (gc_t_join.joined())
-#endif //MULTIPLE_HEAPS
-    {
-#ifdef FEATURE_EVENT_TRACE
-        record_mark_time (gc_time_info[time_mark_long_weak], current_mark_time, last_mark_time);
-        gc_time_info[time_plan] = last_mark_time;
-#endif //FEATURE_EVENT_TRACE
-        if (!settings.promotion)
-        {
-            size_t m = 0;
-            for (int n = 0; n <= condemned_gen_number;n++)
-            {
-#ifdef MULTIPLE_HEAPS
-                m +=  (size_t)(dd_min_size (dynamic_data_of (n))*(n+1)*0.1);
-#else
-                m +=  (size_t)(dd_min_size (dynamic_data_of (n))*(n+1)*0.06);
-#endif //MULTIPLE_HEAPS
-            }
-            settings.promotion = decide_on_promotion_surv (m);
-        }
-#ifdef MULTIPLE_HEAPS
-#ifdef SNOOP_STATS
-        if (do_mark_steal_p)
-        {
-            size_t objects_checked_count = 0;
-            size_t zero_ref_count = 0;
-            size_t objects_marked_count = 0;
-            size_t check_level_count = 0;
-            size_t busy_count = 0;
-            size_t interlocked_count = 0;
-            size_t partial_mark_parent_count = 0;
-            size_t stolen_or_pm_count = 0;
-            size_t stolen_entry_count = 0;
-            size_t pm_not_ready_count = 0;
-            size_t normal_count = 0;
-            size_t stack_bottom_clear_count = 0;
-            for (int i = 0; i < n_heaps; i++)
-            {
-                gc_heap* hp = g_heaps[i];
-                hp->print_snoop_stat();
-                objects_checked_count += hp->snoop_stat.objects_checked_count;
-                zero_ref_count += hp->snoop_stat.zero_ref_count;
-                objects_marked_count += hp->snoop_stat.objects_marked_count;
-                check_level_count += hp->snoop_stat.check_level_count;
-                busy_count += hp->snoop_stat.busy_count;
-                interlocked_count += hp->snoop_stat.interlocked_count;
-                partial_mark_parent_count += hp->snoop_stat.partial_mark_parent_count;
-                stolen_or_pm_count += hp->snoop_stat.stolen_or_pm_count;
-                stolen_entry_count += hp->snoop_stat.stolen_entry_count;
-                pm_not_ready_count += hp->snoop_stat.pm_not_ready_count;
-                normal_count += hp->snoop_stat.normal_count;
-                stack_bottom_clear_count += hp->snoop_stat.stack_bottom_clear_count;
-            }
-            fflush (stdout);
-            printf ("-------total stats-------\n");
-            printf ("%8s | %8s | %8s | %8s | %8s | %8s | %8s | %8s | %8s | %8s | %8s | %8s\n",
-                "checked", "zero", "marked", "level", "busy", "xchg", "pmparent", "s_pm", "stolen", "nready", "normal", "clear");
-            printf ("%8d | %8d | %8d | %8d | %8d | %8d | %8d | %8d | %8d | %8d | %8d | %8d\n",
-                objects_checked_count,
-                zero_ref_count,
-                objects_marked_count,
-                check_level_count,
-                busy_count,
-                interlocked_count,
-                partial_mark_parent_count,
-                stolen_or_pm_count,
-                stolen_entry_count,
-                pm_not_ready_count,
-                normal_count,
-                stack_bottom_clear_count);
-        }
-#endif //SNOOP_STATS
-        dprintf(3, ("Starting all threads for end of mark phase"));
-        gc_t_join.restart();
-#endif //MULTIPLE_HEAPS
-    }
-#if defined(MULTIPLE_HEAPS) && !defined(USE_REGIONS)
-    merge_mark_lists (total_mark_list_size);
-#endif //MULTIPLE_HEAPS && !USE_REGIONS
-    finalization_promoted_bytes = total_promoted_bytes - promoted_bytes_live;
-    mark_queue.verify_empty();
-    dprintf(2,("---- End of mark phase ----"));
-}
-inline
-void gc_heap::pin_object (uint8_t* o, uint8_t** ppObject)
-{
-    dprintf (3, ("Pinning %zx->%zx", (size_t)ppObject, (size_t)o));
-    set_pinned (o);
-#ifdef FEATURE_EVENT_TRACE
-    if(EVENT_ENABLED(PinObjectAtGCTime))
-    {
-        fire_etw_pin_object_event(o, ppObject);
-    }
-#endif // FEATURE_EVENT_TRACE
-    num_pinned_objects++;
-}
-size_t gc_heap::get_total_pinned_objects()
-{
-#ifdef MULTIPLE_HEAPS
-    size_t total_num_pinned_objects = 0;
-    for (int i = 0; i < gc_heap::n_heaps; i++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[i];
-        total_num_pinned_objects += hp->num_pinned_objects;
-    }
-    return total_num_pinned_objects;
-#else //MULTIPLE_HEAPS
-    return num_pinned_objects;
-#endif //MULTIPLE_HEAPS
-}
-void gc_heap::reinit_pinned_objects()
-{
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < gc_heap::n_heaps; i++)
-    {
-        gc_heap::g_heaps[i]->num_pinned_objects = 0;
-    }
-#else //MULTIPLE_HEAPS
-    num_pinned_objects = 0;
-#endif //MULTIPLE_HEAPS
-}
-void gc_heap::reset_mark_stack ()
-{
-    reset_pinned_queue();
-    max_overflow_address = 0;
-    min_overflow_address = MAX_PTR;
-}
-#ifdef FEATURE_STRUCTALIGN
-#if defined (TARGET_AMD64)
-#define brick_bits (12)
-#else
-#define brick_bits (11)
-#endif //TARGET_AMD64
-C_ASSERT(brick_size == (1 << brick_bits));
-#define child_bits (brick_bits + 1 - LOG2_PTRSIZE)
-#define pad_bits (sizeof(short) * 8 - child_bits)
-#define child_from_short(w) (((signed short)(w) / (1 << (pad_bits - LOG2_PTRSIZE))) & ~((1 << LOG2_PTRSIZE) - 1))
-#define pad_mask ((1 << pad_bits) - 1)
-#define pad_from_short(w) ((size_t)(w) & pad_mask)
-#else // FEATURE_STRUCTALIGN
-#define child_from_short(w) (w)
-#endif // FEATURE_STRUCTALIGN
-inline
-short node_left_child(uint8_t* node)
-{
-    return child_from_short(((plug_and_pair*)node)[-1].m_pair.left);
-}
-inline
-void set_node_left_child(uint8_t* node, ptrdiff_t val)
-{
-    assert (val > -(ptrdiff_t)brick_size);
-    assert (val < (ptrdiff_t)brick_size);
-    assert (Aligned (val));
-#ifdef FEATURE_STRUCTALIGN
-    size_t pad = pad_from_short(((plug_and_pair*)node)[-1].m_pair.left);
-    ((plug_and_pair*)node)[-1].m_pair.left = ((short)val << (pad_bits - LOG2_PTRSIZE)) | (short)pad;
-#else // FEATURE_STRUCTALIGN
-    ((plug_and_pair*)node)[-1].m_pair.left = (short)val;
-#endif // FEATURE_STRUCTALIGN
-    assert (node_left_child (node) == val);
-}
-inline
-short node_right_child(uint8_t* node)
-{
-    return child_from_short(((plug_and_pair*)node)[-1].m_pair.right);
-}
-inline
-void set_node_right_child(uint8_t* node, ptrdiff_t val)
-{
-    assert (val > -(ptrdiff_t)brick_size);
-    assert (val < (ptrdiff_t)brick_size);
-    assert (Aligned (val));
-#ifdef FEATURE_STRUCTALIGN
-    size_t pad = pad_from_short(((plug_and_pair*)node)[-1].m_pair.right);
-    ((plug_and_pair*)node)[-1].m_pair.right = ((short)val << (pad_bits - LOG2_PTRSIZE)) | (short)pad;
-#else // FEATURE_STRUCTALIGN
-    ((plug_and_pair*)node)[-1].m_pair.right = (short)val;
-#endif // FEATURE_STRUCTALIGN
-    assert (node_right_child (node) == val);
-}
-#ifdef FEATURE_STRUCTALIGN
-void node_aligninfo (uint8_t* node, int& requiredAlignment, ptrdiff_t& pad)
-{
-    short left = ((plug_and_pair*)node)[-1].m_pair.left;
-    short right = ((plug_and_pair*)node)[-1].m_pair.right;
-    ptrdiff_t pad_shifted = (pad_from_short(left) << pad_bits) | pad_from_short(right);
-    ptrdiff_t aligninfo = pad_shifted * DATA_ALIGNMENT;
-    ptrdiff_t x = aligninfo;
-    x |= x >> 8;
-    x |= x >> 4;
-    x |= x >> 2;
-    x |= x >> 1;
-    requiredAlignment = (int)(x ^ (x >> 1));
-    pad = aligninfo - requiredAlignment;
-    pad += AdjustmentForMinPadSize(pad, requiredAlignment);
-}
-inline
-ptrdiff_t node_alignpad (uint8_t* node)
-{
-    int requiredAlignment;
-    ptrdiff_t alignpad;
-    node_aligninfo (node, requiredAlignment, alignpad);
-    return alignpad;
-}
-void clear_node_aligninfo (uint8_t* node)
-{
-    ((plug_and_pair*)node)[-1].m_pair.left &= ~0 << pad_bits;
-    ((plug_and_pair*)node)[-1].m_pair.right &= ~0 << pad_bits;
-}
-void set_node_aligninfo (uint8_t* node, int requiredAlignment, ptrdiff_t pad)
-{
-    ptrdiff_t aligninfo = (size_t)requiredAlignment + (pad & (requiredAlignment-1));
-    assert (Aligned (aligninfo));
-    ptrdiff_t aligninfo_shifted = aligninfo / DATA_ALIGNMENT;
-    assert (aligninfo_shifted < (1 << (pad_bits + pad_bits)));
-    ptrdiff_t hi = aligninfo_shifted >> pad_bits;
-    assert (pad_from_short(((plug_and_gap*)node)[-1].m_pair.left) == 0);
-    ((plug_and_pair*)node)[-1].m_pair.left |= hi;
-    ptrdiff_t lo = aligninfo_shifted & pad_mask;
-    assert (pad_from_short(((plug_and_gap*)node)[-1].m_pair.right) == 0);
-    ((plug_and_pair*)node)[-1].m_pair.right |= lo;
-#ifdef _DEBUG
-    int requiredAlignment2;
-    ptrdiff_t pad2;
-    node_aligninfo (node, requiredAlignment2, pad2);
-    assert (requiredAlignment == requiredAlignment2);
-    assert (pad == pad2);
-#endif // _DEBUG
-}
-#endif // FEATURE_STRUCTALIGN
-inline
-void loh_set_node_relocation_distance(uint8_t* node, ptrdiff_t val)
-{
-    ptrdiff_t* place = &(((loh_obj_and_pad*)node)[-1].reloc);
-    *place = val;
-}
-inline
-ptrdiff_t loh_node_relocation_distance(uint8_t* node)
-{
-    return (((loh_obj_and_pad*)node)[-1].reloc);
-}
-inline
-ptrdiff_t node_relocation_distance (uint8_t* node)
-{
-    return (((plug_and_reloc*)(node))[-1].reloc & ~3);
-}
-inline
-void set_node_relocation_distance(uint8_t* node, ptrdiff_t val)
-{
-    assert (val == (val & ~3));
-    ptrdiff_t* place = &(((plug_and_reloc*)node)[-1].reloc);
-    *place &= 1;
-    *place |= val;
-}
-#define node_left_p(node) (((plug_and_reloc*)(node))[-1].reloc & 2)
-#define set_node_left(node) ((plug_and_reloc*)(node))[-1].reloc |= 2;
-#ifndef FEATURE_STRUCTALIGN
-void set_node_realigned(uint8_t* node)
-{
-    ((plug_and_reloc*)(node))[-1].reloc |= 1;
-}
-void clear_node_realigned(uint8_t* node)
-{
-#ifdef RESPECT_LARGE_ALIGNMENT
-    ((plug_and_reloc*)(node))[-1].reloc &= ~1;
-#else
-    UNREFERENCED_PARAMETER(node);
-#endif //RESPECT_LARGE_ALIGNMENT
-}
-#endif // FEATURE_STRUCTALIGN
-inline
-size_t  node_gap_size (uint8_t* node)
-{
-    return ((plug_and_gap *)node)[-1].gap;
-}
-void set_gap_size (uint8_t* node, size_t size)
-{
-    assert (Aligned (size));
-    ((plug_and_gap *)node)[-1].reloc = 0;
-    ((plug_and_gap *)node)[-1].lr =0;
-    ((plug_and_gap *)node)[-1].gap = size;
-    assert ((size == 0 )||(size >= sizeof(plug_and_reloc)));
-}
-uint8_t* gc_heap::insert_node (uint8_t* new_node, size_t sequence_number,
-                   uint8_t* tree, uint8_t* last_node)
-{
-    dprintf (3, ("IN: %zx(%zx), T: %zx(%zx), L: %zx(%zx) [%zx]",
-                 (size_t)new_node, brick_of(new_node),
-                 (size_t)tree, brick_of(tree),
-                 (size_t)last_node, brick_of(last_node),
-                 sequence_number));
-    if (power_of_two_p (sequence_number))
-    {
-        set_node_left_child (new_node, (tree - new_node));
-        dprintf (3, ("NT: %zx, LC->%zx", (size_t)new_node, (tree - new_node)));
-        tree = new_node;
-    }
-    else
-    {
-        if (oddp (sequence_number))
-        {
-            set_node_right_child (last_node, (new_node - last_node));
-            dprintf (3, ("%p RC->%zx", last_node, (new_node - last_node)));
-        }
-        else
-        {
-            uint8_t*  earlier_node = tree;
-            size_t imax = logcount(sequence_number) - 2;
-            for (size_t i = 0; i != imax; i++)
-            {
-                earlier_node = earlier_node + node_right_child (earlier_node);
-            }
-            int tmp_offset = node_right_child (earlier_node);
-            assert (tmp_offset); // should never be empty
-            set_node_left_child (new_node, ((earlier_node + tmp_offset ) - new_node));
-            set_node_right_child (earlier_node, (new_node - earlier_node));
-            dprintf (3, ("%p LC->%zx, %p RC->%zx",
-                new_node, ((earlier_node + tmp_offset ) - new_node),
-                earlier_node, (new_node - earlier_node)));
-        }
-    }
-    return tree;
-}
-size_t gc_heap::update_brick_table (uint8_t* tree, size_t current_brick,
-                                    uint8_t* x, uint8_t* plug_end)
-{
-    dprintf (3, ("tree: %p, current b: %zx, x: %p, plug_end: %p",
-        tree, current_brick, x, plug_end));
-    if (tree != NULL)
-    {
-        dprintf (3, ("b- %zx->%zx pointing to tree %p",
-            current_brick, (size_t)(tree - brick_address (current_brick)), tree));
-        set_brick (current_brick, (tree - brick_address (current_brick)));
-    }
-    else
-    {
-        dprintf (3, ("b- %zx->-1", current_brick));
-        set_brick (current_brick, -1);
-    }
-    size_t  b = 1 + current_brick;
-    ptrdiff_t  offset = 0;
-    size_t last_br = brick_of (plug_end-1);
-    current_brick = brick_of (x-1);
-    dprintf (3, ("ubt: %zx->%zx]->%zx]", b, last_br, current_brick));
-    while (b <= current_brick)
-    {
-        if (b <= last_br)
-        {
-            set_brick (b, --offset);
-        }
-        else
-        {
-            set_brick (b,-1);
-        }
-        b++;
-    }
-    return brick_of (x);
-}
-#ifndef USE_REGIONS
-void gc_heap::plan_generation_start (generation* gen, generation* consing_gen, uint8_t* next_plug_to_allocate)
-{
-#ifdef HOST_64BIT
-    if (gen == youngest_generation)
-    {
-        heap_segment* seg = ephemeral_heap_segment;
-        size_t mark_stack_large_bos = mark_stack_bos;
-        size_t large_plug_pos = 0;
-        while (mark_stack_large_bos < mark_stack_tos)
-        {
-            if (mark_stack_array[mark_stack_large_bos].len > demotion_plug_len_th)
-            {
-                while (mark_stack_bos <= mark_stack_large_bos)
-                {
-                    size_t entry = deque_pinned_plug();
-                    size_t len = pinned_len (pinned_plug_of (entry));
-                    uint8_t* plug = pinned_plug (pinned_plug_of(entry));
-                    if (len > demotion_plug_len_th)
-                    {
-                        dprintf (2, ("ps(%d): S %p (%zd)(%p)", gen->gen_num, plug, len, (plug+len)));
-                    }
-                    pinned_len (pinned_plug_of (entry)) = plug - generation_allocation_pointer (consing_gen);
-                    assert(mark_stack_array[entry].len == 0 ||
-                            mark_stack_array[entry].len >= Align(min_obj_size));
-                    generation_allocation_pointer (consing_gen) = plug + len;
-                    generation_allocation_limit (consing_gen) = heap_segment_plan_allocated (seg);
-                    set_allocator_next_pin (consing_gen);
-                }
-            }
-            mark_stack_large_bos++;
-        }
-    }
-#endif // HOST_64BIT
-    generation_plan_allocation_start (gen) =
-        allocate_in_condemned_generations (consing_gen, Align (min_obj_size), -1);
-    generation_plan_allocation_start_size (gen) = Align (min_obj_size);
-    size_t allocation_left = (size_t)(generation_allocation_limit (consing_gen) - generation_allocation_pointer (consing_gen));
-    if (next_plug_to_allocate)
-    {
-        size_t dist_to_next_plug = (size_t)(next_plug_to_allocate - generation_allocation_pointer (consing_gen));
-        if (allocation_left > dist_to_next_plug)
-        {
-            allocation_left = dist_to_next_plug;
-        }
-    }
-    if (allocation_left < Align (min_obj_size))
-    {
-        generation_plan_allocation_start_size (gen) += allocation_left;
-        generation_allocation_pointer (consing_gen) += allocation_left;
-    }
-    dprintf (2, ("plan alloc gen%d(%p) start at %zx (ptr: %p, limit: %p, next: %p)", gen->gen_num,
-        generation_plan_allocation_start (gen),
-        generation_plan_allocation_start_size (gen),
-        generation_allocation_pointer (consing_gen), generation_allocation_limit (consing_gen),
-        next_plug_to_allocate));
-}
-void gc_heap::realloc_plan_generation_start (generation* gen, generation* consing_gen)
-{
-    BOOL adjacentp = FALSE;
-    generation_plan_allocation_start (gen) =
-        allocate_in_expanded_heap (consing_gen, Align(min_obj_size), adjacentp, 0,
-#ifdef SHORT_PLUGS
-                                   FALSE, NULL,
-#endif //SHORT_PLUGS
-                                   FALSE, -1 REQD_ALIGN_AND_OFFSET_ARG);
-    generation_plan_allocation_start_size (gen) = Align (min_obj_size);
-    size_t allocation_left = (size_t)(generation_allocation_limit (consing_gen) - generation_allocation_pointer (consing_gen));
-    if ((allocation_left < Align (min_obj_size)) &&
-         (generation_allocation_limit (consing_gen)!=heap_segment_plan_allocated (generation_allocation_segment (consing_gen))))
-    {
-        generation_plan_allocation_start_size (gen) += allocation_left;
-        generation_allocation_pointer (consing_gen) += allocation_left;
-    }
-    dprintf (1, ("plan re-alloc gen%d start at %p (ptr: %p, limit: %p)", gen->gen_num,
-        generation_plan_allocation_start (consing_gen),
-        generation_allocation_pointer (consing_gen),
-        generation_allocation_limit (consing_gen)));
-}
-void gc_heap::plan_generation_starts (generation*& consing_gen)
-{
-    int  gen_number = settings.condemned_generation;
-    while (gen_number >= 0)
-    {
-        if (gen_number < max_generation)
-        {
-            consing_gen = ensure_ephemeral_heap_segment (consing_gen);
-        }
-        generation* gen = generation_of (gen_number);
-        if (0 == generation_plan_allocation_start (gen))
-        {
-            plan_generation_start (gen, consing_gen, 0);
-            assert (generation_plan_allocation_start (gen));
-        }
-        gen_number--;
-    }
-    heap_segment_plan_allocated (ephemeral_heap_segment) =
-        generation_allocation_pointer (consing_gen);
-}
-void gc_heap::advance_pins_for_demotion (generation* gen)
-{
-    uint8_t* original_youngest_start = generation_allocation_start (youngest_generation);
-    heap_segment* seg = ephemeral_heap_segment;
-    if ((!(pinned_plug_que_empty_p())))
-    {
-        size_t gen1_pinned_promoted = generation_pinned_allocation_compact_size (generation_of (max_generation));
-        size_t gen1_pins_left = dd_pinned_survived_size (dynamic_data_of (max_generation - 1)) - gen1_pinned_promoted;
-        size_t total_space_to_skip = last_gen1_pin_end - generation_allocation_pointer (gen);
-        float pin_frag_ratio = (float)gen1_pins_left / (float)total_space_to_skip;
-        float pin_surv_ratio = (float)gen1_pins_left / (float)(dd_survived_size (dynamic_data_of (max_generation - 1)));
-        if ((pin_frag_ratio > 0.15) && (pin_surv_ratio > 0.30))
-        {
-            while (!pinned_plug_que_empty_p() &&
-                    (pinned_plug (oldest_pin()) < original_youngest_start))
-            {
-                size_t entry = deque_pinned_plug();
-                size_t len = pinned_len (pinned_plug_of (entry));
-                uint8_t* plug = pinned_plug (pinned_plug_of(entry));
-                pinned_len (pinned_plug_of (entry)) = plug - generation_allocation_pointer (gen);
-                assert(mark_stack_array[entry].len == 0 ||
-                        mark_stack_array[entry].len >= Align(min_obj_size));
-                generation_allocation_pointer (gen) = plug + len;
-                generation_allocation_limit (gen) = heap_segment_plan_allocated (seg);
-                set_allocator_next_pin (gen);
-                int frgn = object_gennum (plug);
-                if ((frgn != (int)max_generation) && settings.promotion)
-                {
-                    int togn = object_gennum_plan (plug);
-                    generation_pinned_allocation_sweep_size ((generation_of (frgn +1))) += len;
-                    if (frgn < togn)
-                    {
-                        generation_pinned_allocation_compact_size (generation_of (togn)) += len;
-                    }
-                }
-                dprintf (2, ("skipping gap %zu, pin %p (%zd)",
-                    pinned_len (pinned_plug_of (entry)), plug, len));
-            }
-        }
-        dprintf (2, ("ad_p_d: PL: %zd, SL: %zd, pfr: %d, psr: %d",
-            gen1_pins_left, total_space_to_skip, (int)(pin_frag_ratio*100), (int)(pin_surv_ratio*100)));
-    }
-}
-void gc_heap::process_ephemeral_boundaries (uint8_t* x,
-                                            int& active_new_gen_number,
-                                            int& active_old_gen_number,
-                                            generation*& consing_gen,
-                                            BOOL& allocate_in_condemned)
-{
-retry:
-    if ((active_old_gen_number > 0) &&
-        (x >= generation_allocation_start (generation_of (active_old_gen_number - 1))))
-    {
-        dprintf (2, ("crossing gen%d, x is %p", active_old_gen_number - 1, x));
-        if (!pinned_plug_que_empty_p())
-        {
-            dprintf (2, ("oldest pin: %p(%zd)",
-                pinned_plug (oldest_pin()),
-                (x - pinned_plug (oldest_pin()))));
-        }
-        if (active_old_gen_number <= (settings.promotion ? (max_generation - 1) : max_generation))
-        {
-            active_new_gen_number--;
-        }
-        active_old_gen_number--;
-        assert ((!settings.promotion) || (active_new_gen_number>0));
-        if (active_new_gen_number == (max_generation - 1))
-        {
-#ifdef FREE_USAGE_STATS
-            if (settings.condemned_generation == max_generation)
-            {
-                generation* gen_2 = generation_of (max_generation);
-                generation* gen_1 = generation_of (max_generation - 1);
-                size_t total_num_pinned_free_spaces_left = 0;
-                for (int j = 0; j < NUM_GEN_POWER2; j++)
-                {
-                    dprintf (1, ("[h%d][#%zd]2^%d: current: %zd, S: 2: %zd, 1: %zd(%zd)",
-                        heap_number,
-                        settings.gc_index,
-                        (j + 10),
-                        gen_2->gen_current_pinned_free_spaces[j],
-                        gen_2->gen_plugs[j], gen_1->gen_plugs[j],
-                        (gen_2->gen_plugs[j] + gen_1->gen_plugs[j])));
-                    total_num_pinned_free_spaces_left += gen_2->gen_current_pinned_free_spaces[j];
-                }
-                float pinned_free_list_efficiency = 0;
-                size_t total_pinned_free_space = generation_allocated_in_pinned_free (gen_2) + generation_pinned_free_obj_space (gen_2);
-                if (total_pinned_free_space != 0)
-                {
-                    pinned_free_list_efficiency = (float)(generation_allocated_in_pinned_free (gen_2)) / (float)total_pinned_free_space;
-                }
-                dprintf (1, ("[h%d] gen2 allocated %zd bytes with %zd bytes pinned free spaces (effi: %d%%), %zd (%zd) left",
-                            heap_number,
-                            generation_allocated_in_pinned_free (gen_2),
-                            total_pinned_free_space,
-                            (int)(pinned_free_list_efficiency * 100),
-                            generation_pinned_free_obj_space (gen_2),
-                            total_num_pinned_free_spaces_left));
-            }
-#endif //FREE_USAGE_STATS
-            while (!pinned_plug_que_empty_p() &&
-                   (!in_range_for_segment ((pinned_plug (oldest_pin())), ephemeral_heap_segment)))
-            {
-                size_t  entry = deque_pinned_plug();
-                mark*  m = pinned_plug_of (entry);
-                uint8_t*  plug = pinned_plug (m);
-                size_t  len = pinned_len (m);
-                heap_segment* nseg = heap_segment_in_range (generation_allocation_segment (consing_gen));
-                PREFIX_ASSUME(nseg != NULL);
-                while (!((plug >= generation_allocation_pointer (consing_gen))&&
-                        (plug < heap_segment_allocated (nseg))))
-                {
-                    assert (generation_allocation_pointer (consing_gen)>=
-                            heap_segment_mem (nseg));
-                    assert (generation_allocation_pointer (consing_gen)<=
-                            heap_segment_committed (nseg));
-                    heap_segment_plan_allocated (nseg) =
-                        generation_allocation_pointer (consing_gen);
-                    nseg = heap_segment_next_rw (nseg);
-                    generation_allocation_segment (consing_gen) = nseg;
-                    generation_allocation_pointer (consing_gen) =
-                        heap_segment_mem (nseg);
-                }
-                set_new_pin_info (m, generation_allocation_pointer (consing_gen));
-                assert(pinned_len(m) == 0 || pinned_len(m) >= Align(min_obj_size));
-                generation_allocation_pointer (consing_gen) = plug + len;
-                generation_allocation_limit (consing_gen) =
-                    generation_allocation_pointer (consing_gen);
-            }
-            allocate_in_condemned = TRUE;
-            consing_gen = ensure_ephemeral_heap_segment (consing_gen);
-        }
-        if (active_new_gen_number != max_generation)
-        {
-            if (active_new_gen_number == (max_generation - 1))
-            {
-                maxgen_pinned_compact_before_advance = generation_pinned_allocation_compact_size (generation_of (max_generation));
-                if (!demote_gen1_p)
-                    advance_pins_for_demotion (consing_gen);
-            }
-            plan_generation_start (generation_of (active_new_gen_number), consing_gen, x);
-            dprintf (2, ("process eph: allocated gen%d start at %p",
-                active_new_gen_number,
-                generation_plan_allocation_start (generation_of (active_new_gen_number))));
-            if ((demotion_low == MAX_PTR) && !pinned_plug_que_empty_p())
-            {
-                uint8_t* pplug = pinned_plug (oldest_pin());
-                if (object_gennum (pplug) > 0)
-                {
-                    demotion_low = pplug;
-                    dprintf (3, ("process eph: dlow->%p", demotion_low));
-                }
-            }
-            assert (generation_plan_allocation_start (generation_of (active_new_gen_number)));
-        }
-        goto retry;
-    }
-}
-#endif //!USE_REGIONS
-#ifdef FEATURE_BASICFREEZE
-inline
-void gc_heap::seg_set_mark_bits (heap_segment* seg)
-{
-    uint8_t* o = heap_segment_mem (seg);
-    while (o < heap_segment_allocated (seg))
-    {
-        set_marked (o);
-        o = o + Align (size(o));
-    }
-}
-inline
-void gc_heap::seg_clear_mark_bits (heap_segment* seg)
-{
-    uint8_t* o = heap_segment_mem (seg);
-    while (o < heap_segment_allocated (seg))
-    {
-        if (marked (o))
-        {
-            clear_marked (o);
-        }
-        o = o + Align (size (o));
-    }
-}
-void gc_heap::mark_ro_segments()
-{
-#ifndef USE_REGIONS
-    if ((settings.condemned_generation == max_generation) && ro_segments_in_range)
-    {
-        heap_segment* seg = generation_start_segment (generation_of (max_generation));
-        while (seg)
-        {
-            if (!heap_segment_read_only_p (seg))
-                break;
-            if (heap_segment_in_range_p (seg))
-            {
-#ifdef BACKGROUND_GC
-                if (settings.concurrent)
-                {
-                    seg_set_mark_array_bits_soh (seg);
-                }
-                else
-#endif //BACKGROUND_GC
-                {
-                    seg_set_mark_bits (seg);
-                }
-            }
-            seg = heap_segment_next (seg);
-        }
-    }
-#endif //!USE_REGIONS
-}
-void gc_heap::sweep_ro_segments()
-{
-#ifndef USE_REGIONS
-    if ((settings.condemned_generation == max_generation) && ro_segments_in_range)
-    {
-        heap_segment* seg = generation_start_segment (generation_of (max_generation));;
-        while (seg)
-        {
-            if (!heap_segment_read_only_p (seg))
-                break;
-            if (heap_segment_in_range_p (seg))
-            {
-#ifdef BACKGROUND_GC
-                if (settings.concurrent)
-                {
-                    seg_clear_mark_array_bits_soh (seg);
-                }
-                else
-#endif //BACKGROUND_GC
-                {
-                    seg_clear_mark_bits (seg);
-                }
-            }
-            seg = heap_segment_next (seg);
-        }
-    }
-#endif //!USE_REGIONS
-}
-#endif // FEATURE_BASICFREEZE
-#ifdef FEATURE_LOH_COMPACTION
-inline
-BOOL gc_heap::loh_pinned_plug_que_empty_p()
-{
-    return (loh_pinned_queue_bos == loh_pinned_queue_tos);
-}
-void gc_heap::loh_set_allocator_next_pin()
-{
-    if (!(loh_pinned_plug_que_empty_p()))
-    {
-        mark*  oldest_entry = loh_oldest_pin();
-        uint8_t* plug = pinned_plug (oldest_entry);
-        generation* gen = large_object_generation;
-        if ((plug >= generation_allocation_pointer (gen)) &&
-            (plug <  generation_allocation_limit (gen)))
-        {
-            generation_allocation_limit (gen) = pinned_plug (oldest_entry);
-        }
-        else
-            assert (!((plug < generation_allocation_pointer (gen)) &&
-                      (plug >= heap_segment_mem (generation_allocation_segment (gen)))));
-    }
-}
-size_t gc_heap::loh_deque_pinned_plug ()
-{
-    size_t m = loh_pinned_queue_bos;
-    loh_pinned_queue_bos++;
-    return m;
-}
-inline
-mark* gc_heap::loh_pinned_plug_of (size_t bos)
-{
-    return &loh_pinned_queue[bos];
-}
-inline
-mark* gc_heap::loh_oldest_pin()
-{
-    return loh_pinned_plug_of (loh_pinned_queue_bos);
-}
-BOOL gc_heap::loh_enque_pinned_plug (uint8_t* plug, size_t len)
-{
-    assert(len >= Align(min_obj_size, get_alignment_constant (FALSE)));
-    if (loh_pinned_queue_length <= loh_pinned_queue_tos)
-    {
-        if (!grow_mark_stack (loh_pinned_queue, loh_pinned_queue_length, LOH_PIN_QUEUE_LENGTH))
-        {
-            return FALSE;
-        }
-    }
-    dprintf (3, (" P: %p(%zd)", plug, len));
-    mark& m = loh_pinned_queue[loh_pinned_queue_tos];
-    m.first = plug;
-    m.len = len;
-    loh_pinned_queue_tos++;
-    loh_set_allocator_next_pin();
-    return TRUE;
-}
-inline
-BOOL gc_heap::loh_size_fit_p (size_t size, uint8_t* alloc_pointer, uint8_t* alloc_limit, bool end_p)
-{
-    dprintf (1235, ("trying to fit %zd(%zd) between %p and %p (%zd)",
-        size,
-        (2* AlignQword (loh_padding_obj_size) +  size),
-        alloc_pointer,
-        alloc_limit,
-        (alloc_limit - alloc_pointer)));
-    size_t pad = 1 + (end_p ? 0 : 1);
-    pad *= AlignQword (loh_padding_obj_size);
-    return ((alloc_pointer + pad + size) <= alloc_limit);
-}
-uint8_t* gc_heap::loh_allocate_in_condemned (size_t size)
-{
-    generation* gen = large_object_generation;
-    dprintf (1235, ("E: p:%p, l:%p, s: %zd",
-        generation_allocation_pointer (gen),
-        generation_allocation_limit (gen),
-        size));
-retry:
-    {
-        heap_segment* seg = generation_allocation_segment (gen);
-        if (!(loh_size_fit_p (size, generation_allocation_pointer (gen), generation_allocation_limit (gen),
-                              (generation_allocation_limit (gen) == heap_segment_plan_allocated (seg)))))
-        {
-            if ((!(loh_pinned_plug_que_empty_p()) &&
-                 (generation_allocation_limit (gen) ==
-                  pinned_plug (loh_oldest_pin()))))
-            {
-                mark* m = loh_pinned_plug_of (loh_deque_pinned_plug());
-                size_t len = pinned_len (m);
-                uint8_t* plug = pinned_plug (m);
-                dprintf (1235, ("AIC: %p->%p(%zd)", generation_allocation_pointer (gen), plug, plug - generation_allocation_pointer (gen)));
-                pinned_len (m) = plug - generation_allocation_pointer (gen);
-                generation_allocation_pointer (gen) = plug + len;
-                generation_allocation_limit (gen) = heap_segment_plan_allocated (seg);
-                loh_set_allocator_next_pin();
-                dprintf (1235, ("s: p: %p, l: %p (%zd)",
-                    generation_allocation_pointer (gen),
-                    generation_allocation_limit (gen),
-                    (generation_allocation_limit (gen) - generation_allocation_pointer (gen))));
-                goto retry;
-            }
-            if (generation_allocation_limit (gen) != heap_segment_plan_allocated (seg))
-            {
-                generation_allocation_limit (gen) = heap_segment_plan_allocated (seg);
-                dprintf (1235, ("l->pa(%p)", generation_allocation_limit (gen)));
-            }
-            else
-            {
-                if (heap_segment_plan_allocated (seg) != heap_segment_committed (seg))
-                {
-                    heap_segment_plan_allocated (seg) = heap_segment_committed (seg);
-                    generation_allocation_limit (gen) = heap_segment_plan_allocated (seg);
-                    dprintf (1235, ("l->c(%p)", generation_allocation_limit (gen)));
-                }
-                else
-                {
-                    if (loh_size_fit_p (size, generation_allocation_pointer (gen), heap_segment_reserved (seg), true) &&
-                        (grow_heap_segment (seg, (generation_allocation_pointer (gen) + size + AlignQword (loh_padding_obj_size)))))
-                    {
-                        dprintf (1235, ("growing seg from %p to %p\n", heap_segment_committed (seg),
-                                         (generation_allocation_pointer (gen) + size)));
-                        heap_segment_plan_allocated (seg) = heap_segment_committed (seg);
-                        generation_allocation_limit (gen) = heap_segment_plan_allocated (seg);
-                        dprintf (1235, ("g: p: %p, l: %p (%zd)",
-                            generation_allocation_pointer (gen),
-                            generation_allocation_limit (gen),
-                            (generation_allocation_limit (gen) - generation_allocation_pointer (gen))));
-                    }
-                    else
-                    {
-                        heap_segment* next_seg = heap_segment_next (seg);
-                        assert (generation_allocation_pointer (gen)>=
-                                heap_segment_mem (seg));
-                        if (!loh_pinned_plug_que_empty_p() &&
-                            ((pinned_plug (loh_oldest_pin()) <
-                              heap_segment_allocated (seg)) &&
-                             (pinned_plug (loh_oldest_pin()) >=
-                              generation_allocation_pointer (gen))))
-                        {
-                            LOG((LF_GC, LL_INFO10, "remaining pinned plug %zx while leaving segment on allocation",
-                                         pinned_plug (loh_oldest_pin())));
-                            dprintf (1, ("queue empty: %d", loh_pinned_plug_que_empty_p()));
-                            FATAL_GC_ERROR();
-                        }
-                        assert (generation_allocation_pointer (gen)>=
-                                heap_segment_mem (seg));
-                        assert (generation_allocation_pointer (gen)<=
-                                heap_segment_committed (seg));
-                        heap_segment_plan_allocated (seg) = generation_allocation_pointer (gen);
-                        if (next_seg)
-                        {
-                            generation_allocation_segment (gen) = next_seg;
-                            generation_allocation_pointer (gen) = heap_segment_mem (next_seg);
-                            generation_allocation_limit (gen) = generation_allocation_pointer (gen);
-                            dprintf (1235, ("n: p: %p, l: %p (%zd)",
-                                generation_allocation_pointer (gen),
-                                generation_allocation_limit (gen),
-                                (generation_allocation_limit (gen) - generation_allocation_pointer (gen))));
-                        }
-                        else
-                        {
-                            dprintf (1, ("We ran out of space compacting, shouldn't happen"));
-                            FATAL_GC_ERROR();
-                        }
-                    }
-                }
-            }
-            loh_set_allocator_next_pin();
-            dprintf (1235, ("r: p: %p, l: %p (%zd)",
-                generation_allocation_pointer (gen),
-                generation_allocation_limit (gen),
-                (generation_allocation_limit (gen) - generation_allocation_pointer (gen))));
-            goto retry;
-        }
-    }
-    {
-        assert (generation_allocation_pointer (gen)>=
-                heap_segment_mem (generation_allocation_segment (gen)));
-        uint8_t* result = generation_allocation_pointer (gen);
-        size_t loh_pad = AlignQword (loh_padding_obj_size);
-        generation_allocation_pointer (gen) += size + loh_pad;
-        assert (generation_allocation_pointer (gen) <= generation_allocation_limit (gen));
-        dprintf (1235, ("p: %p, l: %p (%zd)",
-            generation_allocation_pointer (gen),
-            generation_allocation_limit (gen),
-            (generation_allocation_limit (gen) - generation_allocation_pointer (gen))));
-        assert (result + loh_pad);
-        return result + loh_pad;
-    }
-}
-BOOL gc_heap::loh_compaction_requested()
-{
-    return (loh_compaction_always_p || (loh_compaction_mode != loh_compaction_default));
-}
-inline
-void gc_heap::check_loh_compact_mode (BOOL all_heaps_compacted_p)
-{
-    if (settings.loh_compaction && (loh_compaction_mode == loh_compaction_once))
-    {
-        if (all_heaps_compacted_p)
-        {
-            loh_compaction_mode = loh_compaction_default;
-        }
-    }
-}
-BOOL gc_heap::plan_loh()
-{
-#ifdef FEATURE_EVENT_TRACE
-    uint64_t start_time = 0, end_time;
-    if (informational_event_enabled_p)
-    {
-        memset (loh_compact_info, 0, (sizeof (etw_loh_compact_info) * get_num_heaps()));
-        start_time = GetHighPrecisionTimeStamp();
-    }
-#endif //FEATURE_EVENT_TRACE
-    if (!loh_pinned_queue)
-    {
-        loh_pinned_queue = new (nothrow) (mark [LOH_PIN_QUEUE_LENGTH]);
-        if (!loh_pinned_queue)
-        {
-            dprintf (1, ("Cannot allocate the LOH pinned queue (%zd bytes), no compaction",
-                         LOH_PIN_QUEUE_LENGTH * sizeof (mark)));
-            return FALSE;
-        }
-        loh_pinned_queue_length = LOH_PIN_QUEUE_LENGTH;
-    }
-    loh_pinned_queue_decay = LOH_PIN_DECAY;
-    loh_pinned_queue_tos = 0;
-    loh_pinned_queue_bos = 0;
-    generation* gen        = large_object_generation;
-    heap_segment* start_seg = heap_segment_rw (generation_start_segment (gen));
-    PREFIX_ASSUME(start_seg != NULL);
-    heap_segment* seg      = start_seg;
-    uint8_t* o             = get_uoh_start_object (seg, gen);
-    dprintf (1235, ("before GC LOH size: %zd, free list: %zd, free obj: %zd\n",
-        generation_size (loh_generation),
-        generation_free_list_space (gen),
-        generation_free_obj_space (gen)));
-    while (seg)
-    {
-        heap_segment_plan_allocated (seg) = heap_segment_mem (seg);
-        seg = heap_segment_next (seg);
-    }
-    seg = start_seg;
-    heap_segment_plan_allocated (seg) = o;
-    generation_allocation_pointer (gen) = o;
-    generation_allocation_limit (gen) = generation_allocation_pointer (gen);
-    generation_allocation_segment (gen) = start_seg;
-    uint8_t* free_space_start = o;
-    uint8_t* free_space_end = o;
-    uint8_t* new_address = 0;
-    while (1)
-    {
-        if (o >= heap_segment_allocated (seg))
-        {
-            seg = heap_segment_next (seg);
-            if (seg == 0)
-            {
-                break;
-            }
-            o = heap_segment_mem (seg);
-        }
-        if (marked (o))
-        {
-            free_space_end = o;
-            size_t size = AlignQword (size (o));
-            dprintf (1235, ("%p(%zd) M", o, size));
-            if (pinned (o))
-            {
-                if (!loh_enque_pinned_plug (o, size))
-                {
-                    return FALSE;
-                }
-                new_address = o;
-            }
-            else
-            {
-                new_address = loh_allocate_in_condemned (size);
-            }
-            loh_set_node_relocation_distance (o, (new_address - o));
-            dprintf (1235, ("lobj %p-%p -> %p-%p (%zd)", o, (o + size), new_address, (new_address + size), (new_address - o)));
-            o = o + size;
-            free_space_start = o;
-            if (o < heap_segment_allocated (seg))
-            {
-                assert (!marked (o));
-            }
-        }
-        else
-        {
-            while (o < heap_segment_allocated (seg) && !marked (o))
-            {
-                dprintf (1235, ("%p(%zd) F (%d)", o, AlignQword (size (o)), ((method_table (o) == g_gc_pFreeObjectMethodTable) ? 1 : 0)));
-                o = o + AlignQword (size (o));
-            }
-        }
-    }
-    while (!loh_pinned_plug_que_empty_p())
-    {
-        mark* m = loh_pinned_plug_of (loh_deque_pinned_plug());
-        size_t len = pinned_len (m);
-        uint8_t* plug = pinned_plug (m);
-        heap_segment* nseg = heap_segment_rw (generation_allocation_segment (gen));
-        while ((plug < generation_allocation_pointer (gen)) ||
-               (plug >= heap_segment_allocated (nseg)))
-        {
-            assert ((plug < heap_segment_mem (nseg)) ||
-                    (plug > heap_segment_reserved (nseg)));
-            assert (generation_allocation_pointer (gen)>=
-                    heap_segment_mem (nseg));
-            assert (generation_allocation_pointer (gen)<=
-                    heap_segment_committed (nseg));
-            heap_segment_plan_allocated (nseg) =
-                generation_allocation_pointer (gen);
-            nseg = heap_segment_next_rw (nseg);
-            generation_allocation_segment (gen) = nseg;
-            generation_allocation_pointer (gen) =
-                heap_segment_mem (nseg);
-        }
-        dprintf (1235, ("SP: %p->%p(%zd)", generation_allocation_pointer (gen), plug, plug - generation_allocation_pointer (gen)));
-        pinned_len (m) = plug - generation_allocation_pointer (gen);
-        generation_allocation_pointer (gen) = plug + len;
-    }
-    heap_segment_plan_allocated (generation_allocation_segment (gen)) = generation_allocation_pointer (gen);
-    generation_allocation_pointer (gen) = 0;
-    generation_allocation_limit (gen) = 0;
-#ifdef FEATURE_EVENT_TRACE
-    if (informational_event_enabled_p)
-    {
-        end_time = GetHighPrecisionTimeStamp();
-        loh_compact_info[heap_number].time_plan = limit_time_to_uint32 (end_time - start_time);
-    }
-#endif //FEATURE_EVENT_TRACE
-    return TRUE;
-}
-void gc_heap::compact_loh()
-{
-    assert (loh_compaction_requested() || heap_hard_limit || conserve_mem_setting || (settings.reason == reason_induced_aggressive));
-#ifdef FEATURE_EVENT_TRACE
-    uint64_t start_time = 0, end_time;
-    if (informational_event_enabled_p)
-    {
-        start_time = GetHighPrecisionTimeStamp();
-    }
-#endif //FEATURE_EVENT_TRACE
-    generation* gen        = large_object_generation;
-    heap_segment* start_seg = heap_segment_rw (generation_start_segment (gen));
-    PREFIX_ASSUME(start_seg != NULL);
-    heap_segment* seg      = start_seg;
-    heap_segment* prev_seg = 0;
-    uint8_t* o             = get_uoh_start_object (seg, gen);
-    uint8_t* free_space_start = o;
-    uint8_t* free_space_end = o;
-    generation_allocator (gen)->clear();
-    generation_free_list_space (gen) = 0;
-    generation_free_obj_space (gen) = 0;
-    loh_pinned_queue_bos = 0;
-    while (1)
-    {
-        if (o >= heap_segment_allocated (seg))
-        {
-            heap_segment* next_seg = heap_segment_next (seg);
-            if ((heap_segment_plan_allocated (seg) == heap_segment_mem (seg)) &&
-                (seg != start_seg) && !heap_segment_read_only_p (seg))
-            {
-                dprintf (3, ("Preparing empty large segment %zx", (size_t)seg));
-                assert (prev_seg);
-                heap_segment_next (prev_seg) = next_seg;
-                heap_segment_next (seg) = freeable_uoh_segment;
-                freeable_uoh_segment = seg;
-#ifdef USE_REGIONS
-                update_start_tail_regions (gen, seg, prev_seg, next_seg);
-#endif //USE_REGIONS
-            }
-            else
-            {
-                if (!heap_segment_read_only_p (seg))
-                {
-                    if (heap_segment_plan_allocated (seg) > heap_segment_allocated (seg))
-                    {
-                        if ((heap_segment_plan_allocated (seg) - plug_skew)  > heap_segment_used (seg))
-                        {
-                            heap_segment_used (seg) = heap_segment_plan_allocated (seg) - plug_skew;
-                        }
-                    }
-                    heap_segment_allocated (seg) = heap_segment_plan_allocated (seg);
-                    dprintf (3, ("Trimming seg to %p[", heap_segment_allocated (seg)));
-                    decommit_heap_segment_pages (seg, 0);
-                    dprintf (1236, ("CLOH: seg: %p, alloc: %p, used: %p, committed: %p",
-                        seg,
-                        heap_segment_allocated (seg),
-                        heap_segment_used (seg),
-                        heap_segment_committed (seg)));
-                    dprintf (1236, ("CLOH: used is set to %p", heap_segment_used (seg)));
-                }
-                prev_seg = seg;
-            }
-            seg = next_seg;
-            if (seg == 0)
-                break;
-            else
-            {
-                o = heap_segment_mem (seg);
-            }
-        }
-        if (marked (o))
-        {
-            free_space_end = o;
-            size_t size = AlignQword (size (o));
-            size_t loh_pad;
-            uint8_t* reloc = o;
-            clear_marked (o);
-            if (pinned (o))
-            {
-                mark* m = loh_pinned_plug_of (loh_deque_pinned_plug());
-                uint8_t* plug = pinned_plug (m);
-                assert (plug == o);
-                loh_pad = pinned_len (m);
-                clear_pinned (o);
-            }
-            else
-            {
-                loh_pad = AlignQword (loh_padding_obj_size);
-                reloc += loh_node_relocation_distance (o);
-                gcmemcopy (reloc, o, size, TRUE);
-            }
-            thread_gap ((reloc - loh_pad), loh_pad, gen);
-            o = o + size;
-            free_space_start = o;
-            if (o < heap_segment_allocated (seg))
-            {
-                assert (!marked (o));
-            }
-        }
-        else
-        {
-            while (o < heap_segment_allocated (seg) && !marked (o))
-            {
-                o = o + AlignQword (size (o));
-            }
-        }
-    }
-#ifdef FEATURE_EVENT_TRACE
-    if (informational_event_enabled_p)
-    {
-        end_time = GetHighPrecisionTimeStamp();
-        loh_compact_info[heap_number].time_compact = limit_time_to_uint32 (end_time - start_time);
-    }
-#endif //FEATURE_EVENT_TRACE
-    assert (loh_pinned_plug_que_empty_p());
-    dprintf (1235, ("after GC LOH size: %zd, free list: %zd, free obj: %zd\n\n",
-        generation_size (loh_generation),
-        generation_free_list_space (gen),
-        generation_free_obj_space (gen)));
-}
-#ifdef FEATURE_EVENT_TRACE
-inline
-void gc_heap::loh_reloc_survivor_helper (uint8_t** pval, size_t& total_refs, size_t& zero_refs)
-{
-    uint8_t* val = *pval;
-    if (!val)
-        zero_refs++;
-    total_refs++;
-    reloc_survivor_helper (pval);
-}
-#endif //FEATURE_EVENT_TRACE
-void gc_heap::relocate_in_loh_compact()
-{
-    generation* gen        = large_object_generation;
-    heap_segment* seg      = heap_segment_rw (generation_start_segment (gen));
-    uint8_t* o              = get_uoh_start_object (seg, gen);
-#ifdef FEATURE_EVENT_TRACE
-    size_t total_refs = 0;
-    size_t zero_refs = 0;
-    uint64_t start_time = 0, end_time;
-    if (informational_event_enabled_p)
-    {
-        start_time = GetHighPrecisionTimeStamp();
-    }
-#endif //FEATURE_EVENT_TRACE
-    while (1)
-    {
-        if (o >= heap_segment_allocated (seg))
-        {
-            seg = heap_segment_next (seg);
-            if (seg == 0)
-            {
-                break;
-            }
-            o = heap_segment_mem (seg);
-        }
-        if (marked (o))
-        {
-            size_t size = AlignQword (size (o));
-            check_class_object_demotion (o);
-            if (contain_pointers (o))
-            {
-#ifdef FEATURE_EVENT_TRACE
-                if (informational_event_enabled_p)
-                {
-                    go_through_object_nostart (method_table (o), o, size(o), pval,
-                    {
-                        loh_reloc_survivor_helper (pval, total_refs, zero_refs);
-                    });
-                }
-                else
-#endif //FEATURE_EVENT_TRACE
-                {
-                    go_through_object_nostart (method_table (o), o, size(o), pval,
-                    {
-                        reloc_survivor_helper (pval);
-                    });
-                }
-            }
-            o = o + size;
-            if (o < heap_segment_allocated (seg))
-            {
-                assert (!marked (o));
-            }
-        }
-        else
-        {
-            while (o < heap_segment_allocated (seg) && !marked (o))
-            {
-                o = o + AlignQword (size (o));
-            }
-        }
-    }
-#ifdef FEATURE_EVENT_TRACE
-    if (informational_event_enabled_p)
-    {
-        end_time = GetHighPrecisionTimeStamp();
-        loh_compact_info[heap_number].time_relocate = limit_time_to_uint32 (end_time - start_time);
-        loh_compact_info[heap_number].total_refs = total_refs;
-        loh_compact_info[heap_number].zero_refs = zero_refs;
-    }
-#endif //FEATURE_EVENT_TRACE
-    dprintf (1235, ("after GC LOH size: %zd, free list: %zd, free obj: %zd\n\n",
-        generation_size (loh_generation),
-        generation_free_list_space (gen),
-        generation_free_obj_space (gen)));
-}
-void gc_heap::walk_relocation_for_loh (void* profiling_context, record_surv_fn fn)
-{
-    generation* gen        = large_object_generation;
-    heap_segment* seg      = heap_segment_rw (generation_start_segment (gen));
-    uint8_t* o             = get_uoh_start_object (seg, gen);
-    while (1)
-    {
-        if (o >= heap_segment_allocated (seg))
-        {
-            seg = heap_segment_next (seg);
-            if (seg == 0)
-            {
-                break;
-            }
-            o = heap_segment_mem (seg);
-        }
-        if (marked (o))
-        {
-            size_t size = AlignQword (size (o));
-            ptrdiff_t reloc = loh_node_relocation_distance (o);
-            STRESS_LOG_PLUG_MOVE(o, (o + size), -reloc);
-            fn (o, (o + size), reloc, profiling_context, !!settings.compaction, false);
-            o = o + size;
-            if (o < heap_segment_allocated (seg))
-            {
-                assert (!marked (o));
-            }
-        }
-        else
-        {
-            while (o < heap_segment_allocated (seg) && !marked (o))
-            {
-                o = o + AlignQword (size (o));
-            }
-        }
-    }
-}
-BOOL gc_heap::loh_object_p (uint8_t* o)
-{
-#ifdef MULTIPLE_HEAPS
-    gc_heap* hp = gc_heap::g_heaps [0];
-    int brick_entry = hp->brick_table[hp->brick_of (o)];
-#else //MULTIPLE_HEAPS
-    int brick_entry = brick_table[brick_of (o)];
-#endif //MULTIPLE_HEAPS
-    return (brick_entry == 0);
-}
-#endif //FEATURE_LOH_COMPACTION
-void gc_heap::convert_to_pinned_plug (BOOL& last_npinned_plug_p,
-                                      BOOL& last_pinned_plug_p,
-                                      BOOL& pinned_plug_p,
-                                      size_t ps,
-                                      size_t& artificial_pinned_size)
-{
-    last_npinned_plug_p = FALSE;
-    last_pinned_plug_p = TRUE;
-    pinned_plug_p = TRUE;
-    artificial_pinned_size = ps;
-}
-void gc_heap::store_plug_gap_info (uint8_t* plug_start,
-                                   uint8_t* plug_end,
-                                   BOOL& last_npinned_plug_p,
-                                   BOOL& last_pinned_plug_p,
-                                   uint8_t*& last_pinned_plug,
-                                   BOOL& pinned_plug_p,
-                                   uint8_t* last_object_in_last_plug,
-                                   BOOL& merge_with_last_pin_p,
-                                   size_t last_plug_len)
-{
-    UNREFERENCED_PARAMETER(last_plug_len);
-    if (!last_npinned_plug_p && !last_pinned_plug_p)
-    {
-        dprintf (3, ("Free: %zx", (plug_start - plug_end)));
-        assert ((plug_start == plug_end) || ((size_t)(plug_start - plug_end) >= Align (min_obj_size)));
-        set_gap_size (plug_start, plug_start - plug_end);
-    }
-    if (pinned (plug_start))
-    {
-        BOOL save_pre_plug_info_p = FALSE;
-        if (last_npinned_plug_p || last_pinned_plug_p)
-        {
-            save_pre_plug_info_p = TRUE;
-        }
-        pinned_plug_p = TRUE;
-        last_npinned_plug_p = FALSE;
-        if (last_pinned_plug_p)
-        {
-            dprintf (3, ("last plug %p was also pinned, should merge", last_pinned_plug));
-            merge_with_last_pin_p = TRUE;
-        }
-        else
-        {
-            last_pinned_plug_p = TRUE;
-            last_pinned_plug = plug_start;
-            enque_pinned_plug (last_pinned_plug, save_pre_plug_info_p, last_object_in_last_plug);
-            if (save_pre_plug_info_p)
-            {
-#ifdef DOUBLY_LINKED_FL
-                if (last_object_in_last_plug == generation_last_free_list_allocated(generation_of(max_generation)))
-                {
-                    saved_pinned_plug_index = mark_stack_tos;
-                }
-#endif //DOUBLY_LINKED_FL
-                set_gap_size (plug_start, sizeof (gap_reloc_pair));
-            }
-        }
-    }
-    else
-    {
-        if (last_pinned_plug_p)
-        {
-            save_post_plug_info (last_pinned_plug, last_object_in_last_plug, plug_start);
-            set_gap_size (plug_start, sizeof (gap_reloc_pair));
-            verify_pins_with_post_plug_info("after saving post plug info");
-        }
-        last_npinned_plug_p = TRUE;
-        last_pinned_plug_p = FALSE;
-    }
-}
-void gc_heap::record_interesting_data_point (interesting_data_point idp)
-{
-#ifdef GC_CONFIG_DRIVEN
-    (interesting_data_per_gc[idp])++;
-#else
-    UNREFERENCED_PARAMETER(idp);
-#endif //GC_CONFIG_DRIVEN
-}
-#ifdef USE_REGIONS
-void gc_heap::skip_pins_in_alloc_region (generation* consing_gen, int plan_gen_num)
-{
-    heap_segment* alloc_region = generation_allocation_segment (consing_gen);
-    while (!pinned_plug_que_empty_p())
-    {
-        uint8_t* oldest_plug = pinned_plug (oldest_pin());
-        if ((oldest_plug >= generation_allocation_pointer (consing_gen)) &&
-            (oldest_plug < heap_segment_allocated (alloc_region)))
-        {
-            mark* m =       pinned_plug_of (deque_pinned_plug());
-            uint8_t* plug = pinned_plug (m);
-            size_t len =    pinned_len (m);
-            set_new_pin_info (m, generation_allocation_pointer (consing_gen));
-            dprintf (REGIONS_LOG, ("pin %p b: %zx->%zx", plug, brick_of (plug),
-                (size_t)(brick_table[brick_of (plug)])));
-            generation_allocation_pointer (consing_gen) = plug + len;
-        }
-        else
-        {
-            break;
-        }
-    }
-    dprintf (REGIONS_LOG, ("finished with alloc region %p, (%s) plan gen -> %d",
-        heap_segment_mem (alloc_region),
-        (heap_segment_swept_in_plan (alloc_region) ? "SIP" : "non SIP"),
-        (heap_segment_swept_in_plan (alloc_region) ?
-            heap_segment_plan_gen_num (alloc_region) : plan_gen_num)));
-    set_region_plan_gen_num_sip (alloc_region, plan_gen_num);
-    heap_segment_plan_allocated (alloc_region) = generation_allocation_pointer (consing_gen);
-}
-void gc_heap::decide_on_demotion_pin_surv (heap_segment* region, int* no_pinned_surv_region_count)
-{
-    int new_gen_num = 0;
-    int pinned_surv = heap_segment_pinned_survived (region);
-    if (pinned_surv == 0)
-    {
-        (*no_pinned_surv_region_count)++;
-        dprintf (REGIONS_LOG, ("region %Ix will be empty", heap_segment_mem (region)));
-    }
-    size_t basic_region_size = (size_t)1 << min_segment_size_shr;
-    int pinned_ratio = (int)(((double)pinned_surv * 100.0) / (double)basic_region_size);
-    dprintf (REGIONS_LOG, ("h%d g%d region %Ix(%Ix) ps: %d (%d) (%s)", heap_number,
-        heap_segment_gen_num (region), (size_t)region, heap_segment_mem (region), pinned_surv, pinned_ratio,
-        ((pinned_ratio >= demotion_pinned_ratio_th) ? "ND" : "D")));
-    if (pinned_ratio >= demotion_pinned_ratio_th)
-    {
-        if (settings.promotion)
-        {
-            new_gen_num = get_plan_gen_num (heap_segment_gen_num (region));
-        }
-    }
-    set_region_plan_gen_num (region, new_gen_num);
-}
-void gc_heap::process_last_np_surv_region (generation* consing_gen,
-                                           int current_plan_gen_num,
-                                           int next_plan_gen_num)
-{
-    heap_segment* alloc_region = generation_allocation_segment (consing_gen);
-    uint8_t* consing_gen_alloc_ptr = generation_allocation_pointer (consing_gen);
-    assert ((consing_gen_alloc_ptr >= heap_segment_mem (alloc_region)) &&
-            (consing_gen_alloc_ptr <= heap_segment_reserved (alloc_region)));
-    dprintf (REGIONS_LOG, ("h%d PLN: (%s) plan gen%d->%d, consing alloc region: %p, ptr: %p (%Id) (consing gen: %d)",
-        heap_number, (settings.promotion ? "promotion" : "no promotion"), current_plan_gen_num, next_plan_gen_num,
-        heap_segment_mem (alloc_region),
-        generation_allocation_pointer (consing_gen),
-        (generation_allocation_pointer (consing_gen) - heap_segment_mem (alloc_region)),
-        consing_gen->gen_num));
-    if (current_plan_gen_num != next_plan_gen_num)
-    {
-        if (generation_allocation_pointer (consing_gen) == heap_segment_mem (alloc_region))
-        {
-            dprintf (REGIONS_LOG, ("h%d alloc region %p unused, using it to plan %d",
-                heap_number, heap_segment_mem (alloc_region), next_plan_gen_num));
-            return;
-        }
-        skip_pins_in_alloc_region (consing_gen, current_plan_gen_num);
-        heap_segment* next_region = heap_segment_next_non_sip (alloc_region);
-        if (!next_region)
-        {
-            int gen_num = heap_segment_gen_num (alloc_region);
-            if (gen_num > 0)
-            {
-                next_region = generation_start_segment (generation_of (gen_num - 1));
-                dprintf (REGIONS_LOG, ("h%d consing switching to next gen%d seg %p",
-                    heap_number, heap_segment_gen_num (next_region), heap_segment_mem (next_region)));
-            }
-            else
-            {
-                if (settings.promotion)
-                {
-                    assert (next_plan_gen_num == 0);
-                    next_region = get_new_region (0);
-                    if (next_region)
-                    {
-                        dprintf (REGIONS_LOG, ("h%d getting a new region for gen0 plan start seg to %p",
-                            heap_number, heap_segment_mem (next_region)));
-                        regions_per_gen[0]++;
-                        new_gen0_regions_in_plns++;
-                    }
-                    else
-                    {
-                        dprintf (REGIONS_LOG, ("h%d couldn't get a region to plan gen0, special sweep on",
-                            heap_number));
-                        special_sweep_p = true;
-                    }
-                }
-                else
-                {
-                    assert (!"ran out of regions for non promotion case??");
-                }
-            }
-        }
-        else
-        {
-            dprintf (REGIONS_LOG, ("h%d consing switching to next seg %p in gen%d to alloc in",
-                heap_number, heap_segment_mem (next_region), heap_segment_gen_num (next_region)));
-        }
-        if (next_region)
-        {
-            init_alloc_info (consing_gen, next_region);
-            dprintf (REGIONS_LOG, ("h%d consing(%d) alloc seg: %p(%p, %p), ptr: %p, planning gen%d",
-                heap_number, consing_gen->gen_num,
-                heap_segment_mem (generation_allocation_segment (consing_gen)),
-                heap_segment_allocated (generation_allocation_segment (consing_gen)),
-                heap_segment_plan_allocated (generation_allocation_segment (consing_gen)),
-                generation_allocation_pointer (consing_gen), next_plan_gen_num));
-        }
-        else
-        {
-            assert (special_sweep_p);
-        }
-    }
-}
-void gc_heap::process_remaining_regions (int current_plan_gen_num, generation* consing_gen)
-{
-    assert ((current_plan_gen_num == 0) || (!settings.promotion && (current_plan_gen_num == -1)));
-    if (special_sweep_p)
-    {
-        assert (pinned_plug_que_empty_p());
-    }
-    dprintf (REGIONS_LOG, ("h%d PRR: (%s) plan %d: consing alloc seg: %p, ptr: %p",
-        heap_number, (settings.promotion ? "promotion" : "no promotion"), current_plan_gen_num,
-        heap_segment_mem (generation_allocation_segment (consing_gen)),
-        generation_allocation_pointer (consing_gen)));
-    if (current_plan_gen_num == -1)
-    {
-        assert (!settings.promotion);
-        current_plan_gen_num = 0;
-        heap_segment* alloc_region = generation_allocation_segment (consing_gen);
-        if (generation_allocation_pointer (consing_gen) > heap_segment_mem (alloc_region))
-        {
-            skip_pins_in_alloc_region (consing_gen, current_plan_gen_num);
-            heap_segment* next_region = heap_segment_next_non_sip (alloc_region);
-            if ((next_region == 0) && (heap_segment_gen_num (alloc_region) > 0))
-            {
-                next_region = generation_start_segment (generation_of (heap_segment_gen_num (alloc_region) - 1));
-            }
-            if (next_region)
-            {
-                init_alloc_info (consing_gen, next_region);
-            }
-            else
-            {
-                assert (pinned_plug_que_empty_p ());
-                if (!pinned_plug_que_empty_p ())
-                {
-                    dprintf (REGIONS_LOG, ("we still have a pin at %Ix but no more regions!?", pinned_plug (oldest_pin ())));
-                    GCToOSInterface::DebugBreak ();
-                }
-                generation_allocation_segment (consing_gen) = 0;
-                generation_allocation_pointer (consing_gen) = 0;
-                generation_allocation_limit (consing_gen) = 0;
-            }
-        }
-    }
-    dprintf (REGIONS_LOG, ("h%d regions in g2: %d, g1: %d, g0: %d, before processing remaining regions",
-        heap_number, planned_regions_per_gen[2], planned_regions_per_gen[1], planned_regions_per_gen[0]));
-    dprintf (REGIONS_LOG, ("h%d g2: surv %Id(p: %Id, %.2f%%), g1: surv %Id(p: %Id, %.2f%%), g0: surv %Id(p: %Id, %.2f%%)",
-        heap_number,
-        dd_survived_size (dynamic_data_of (2)), dd_pinned_survived_size (dynamic_data_of (2)),
-        (dd_survived_size (dynamic_data_of (2)) ? ((double)dd_pinned_survived_size (dynamic_data_of (2)) * 100.0 / (double)dd_survived_size (dynamic_data_of (2))) : 0),
-        dd_survived_size (dynamic_data_of (1)), dd_pinned_survived_size (dynamic_data_of (1)),
-        (dd_survived_size (dynamic_data_of (2)) ? ((double)dd_pinned_survived_size (dynamic_data_of (1)) * 100.0 / (double)dd_survived_size (dynamic_data_of (1))) : 0),
-        dd_survived_size (dynamic_data_of (0)), dd_pinned_survived_size (dynamic_data_of (0)),
-        (dd_survived_size (dynamic_data_of (2)) ? ((double)dd_pinned_survived_size (dynamic_data_of (0)) * 100.0 / (double)dd_survived_size (dynamic_data_of (0))) : 0)));
-    int to_be_empty_regions = 0;
-    while (!pinned_plug_que_empty_p())
-    {
-        uint8_t* oldest_plug = pinned_plug (oldest_pin());
-        heap_segment* nseg = heap_segment_rw (generation_allocation_segment (consing_gen));
-        dprintf (3, ("h%d oldest pin: %p, consing alloc %p, ptr %p, limit %p",
-            heap_number, oldest_plug, heap_segment_mem (nseg),
-            generation_allocation_pointer (consing_gen),
-            generation_allocation_limit (consing_gen)));
-        while ((oldest_plug < generation_allocation_pointer (consing_gen)) ||
-               (oldest_plug >= heap_segment_allocated (nseg)))
-        {
-            assert ((oldest_plug < heap_segment_mem (nseg)) ||
-                    (oldest_plug > heap_segment_reserved (nseg)));
-            assert (generation_allocation_pointer (consing_gen)>=
-                    heap_segment_mem (nseg));
-            assert (generation_allocation_pointer (consing_gen)<=
-                    heap_segment_committed (nseg));
-            dprintf (3, ("h%d PRR: in loop, seg %p pa %p -> alloc ptr %p, plan gen %d->%d",
-                heap_number, heap_segment_mem (nseg),
-                heap_segment_plan_allocated (nseg),
-                generation_allocation_pointer (consing_gen),
-                heap_segment_plan_gen_num (nseg),
-                current_plan_gen_num));
-            assert (!heap_segment_swept_in_plan (nseg));
-            heap_segment_plan_allocated (nseg) = generation_allocation_pointer (consing_gen);
-            decide_on_demotion_pin_surv (nseg, &to_be_empty_regions);
-            heap_segment* next_seg = heap_segment_next_non_sip (nseg);
-            if ((next_seg == 0) && (heap_segment_gen_num (nseg) > 0))
-            {
-                next_seg = generation_start_segment (generation_of (heap_segment_gen_num (nseg) - 1));
-                dprintf (3, ("h%d PRR: switching to next gen%d start %zx",
-                    heap_number, heap_segment_gen_num (next_seg), (size_t)next_seg));
-            }
-            assert (next_seg != 0);
-            nseg = next_seg;
-            generation_allocation_segment (consing_gen) = nseg;
-            generation_allocation_pointer (consing_gen) = heap_segment_mem (nseg);
-        }
-        mark* m = pinned_plug_of (deque_pinned_plug());
-        uint8_t* plug = pinned_plug (m);
-        size_t len = pinned_len (m);
-        set_new_pin_info (m, generation_allocation_pointer (consing_gen));
-        size_t free_size = pinned_len (m);
-        update_planned_gen0_free_space (free_size, plug);
-        dprintf (2, ("h%d plug %p-%p(%zu), free space before %p-%p(%zu)",
-            heap_number, plug, (plug + len), len,
-            generation_allocation_pointer (consing_gen), plug, free_size));
-        generation_allocation_pointer (consing_gen) = plug + len;
-        generation_allocation_limit (consing_gen) =
-            generation_allocation_pointer (consing_gen);
-    }
-    heap_segment* current_region = generation_allocation_segment (consing_gen);
-    if (special_sweep_p)
-    {
-        assert ((current_region == 0) || (heap_segment_next_rw (current_region) == 0));
-        return;
-    }
-    dprintf (REGIONS_LOG, ("after going through the rest of regions - regions in g2: %d, g1: %d, g0: %d, to be empty %d now",
-        planned_regions_per_gen[2], planned_regions_per_gen[1], planned_regions_per_gen[0], to_be_empty_regions));
-    current_region = heap_segment_non_sip (current_region);
-    dprintf (REGIONS_LOG, ("now current region is %p", (current_region ? heap_segment_mem (current_region) : 0)));
-    if (current_region)
-    {
-        decide_on_demotion_pin_surv (current_region, &to_be_empty_regions);
-        if (!heap_segment_swept_in_plan (current_region))
-        {
-            heap_segment_plan_allocated (current_region) = generation_allocation_pointer (consing_gen);
-            dprintf (REGIONS_LOG, ("h%d setting alloc seg %p plan alloc to %p",
-                heap_number, heap_segment_mem (current_region),
-                heap_segment_plan_allocated (current_region)));
-        }
-        dprintf (REGIONS_LOG, ("before going through the rest of empty regions - regions in g2: %d, g1: %d, g0: %d, to be empty %d now",
-            planned_regions_per_gen[2], planned_regions_per_gen[1], planned_regions_per_gen[0], to_be_empty_regions));
-        heap_segment* region_no_pins = heap_segment_next (current_region);
-        int region_no_pins_gen_num = heap_segment_gen_num (current_region);
-        do
-        {
-            region_no_pins = heap_segment_non_sip (region_no_pins);
-            if (region_no_pins)
-            {
-                set_region_plan_gen_num (region_no_pins, current_plan_gen_num);
-                to_be_empty_regions++;
-                heap_segment_plan_allocated (region_no_pins) = heap_segment_mem (region_no_pins);
-                dprintf (REGIONS_LOG, ("h%d setting empty seg %p(no pins) plan gen to 0, plan alloc to %p",
-                    heap_number, heap_segment_mem (region_no_pins),
-                    heap_segment_plan_allocated (region_no_pins)));
-                region_no_pins = heap_segment_next (region_no_pins);
-            }
-            if (!region_no_pins)
-            {
-                if (region_no_pins_gen_num > 0)
-                {
-                    region_no_pins_gen_num--;
-                    region_no_pins = generation_start_segment (generation_of (region_no_pins_gen_num));
-                }
-                else
-                    break;
-            }
-        } while (region_no_pins);
-    }
-    if (to_be_empty_regions)
-    {
-        if (planned_regions_per_gen[0] == 0)
-        {
-            dprintf (REGIONS_LOG, ("we didn't seem to find any gen to plan gen0 yet we have empty regions?!"));
-        }
-        assert (planned_regions_per_gen[0]);
-    }
-    int saved_planned_regions_per_gen[max_generation + 1];
-    memcpy (saved_planned_regions_per_gen, planned_regions_per_gen, sizeof (saved_planned_regions_per_gen));
-    assert (saved_planned_regions_per_gen[0] >= to_be_empty_regions);
-    saved_planned_regions_per_gen[0] -= to_be_empty_regions;
-    int plan_regions_needed = 0;
-    for (int gen_idx = settings.condemned_generation; gen_idx >= 0; gen_idx--)
-    {
-        if (saved_planned_regions_per_gen[gen_idx] == 0)
-        {
-            dprintf (REGIONS_LOG, ("g%d has 0 planned regions!!!", gen_idx));
-            plan_regions_needed++;
-        }
-    }
-    dprintf (1, ("we still need %d regions, %d will be empty", plan_regions_needed, to_be_empty_regions));
-    if (plan_regions_needed > to_be_empty_regions)
-    {
-        dprintf (REGIONS_LOG, ("h%d %d regions will be empty but we still need %d regions!!", heap_number, to_be_empty_regions, plan_regions_needed));
-        plan_regions_needed -= to_be_empty_regions;
-        while (plan_regions_needed && get_new_region (0))
-        {
-            new_regions_in_prr++;
-            plan_regions_needed--;
-        }
-        if (plan_regions_needed > 0)
-        {
-            dprintf (REGIONS_LOG, ("h%d %d regions short for having at least one region per gen, special sweep on",
-                heap_number));
-            special_sweep_p = true;
-        }
-    }
-#ifdef _DEBUG
-    {
-        dprintf (REGIONS_LOG, ("regions in g2: %d[%d], g1: %d[%d], g0: %d[%d]",
-            planned_regions_per_gen[2], regions_per_gen[2],
-            planned_regions_per_gen[1], regions_per_gen[1],
-            planned_regions_per_gen[0], regions_per_gen[0]));
-        int total_regions = 0;
-        int total_planned_regions = 0;
-        for (int i = max_generation; i >= 0; i--)
-        {
-            total_regions += regions_per_gen[i];
-            total_planned_regions += planned_regions_per_gen[i];
-        }
-        if (total_regions != total_planned_regions)
-        {
-            dprintf (REGIONS_LOG, ("planned %d regions, saw %d total",
-                total_planned_regions, total_regions));
-        }
-    }
-#endif //_DEBUG
-}
-void gc_heap::grow_mark_list_piece()
-{
-    if (g_mark_list_piece_total_size < region_count * 2 * get_num_heaps())
-    {
-        delete[] g_mark_list_piece;
-        size_t alloc_count = max ((g_mark_list_piece_size * 2), region_count);
-        g_mark_list_piece = new (nothrow) uint8_t * *[alloc_count * 2 * get_num_heaps()];
-        if (g_mark_list_piece != nullptr)
-        {
-            g_mark_list_piece_size = alloc_count;
-        }
-        else
-        {
-            g_mark_list_piece_size = 0;
-        }
-        g_mark_list_piece_total_size = g_mark_list_piece_size * 2 * get_num_heaps();
-    }
-    g_mark_list_piece_size = g_mark_list_piece_total_size / (2 * get_num_heaps());
-}
-void gc_heap::save_current_survived()
-{
-    if (!survived_per_region) return;
-    size_t region_info_to_copy = region_count * sizeof (size_t);
-    memcpy (old_card_survived_per_region, survived_per_region, region_info_to_copy);
-#ifdef _DEBUG
-    for (size_t region_index = 0; region_index < region_count; region_index++)
-    {
-        if (survived_per_region[region_index] != 0)
-        {
-            dprintf (REGIONS_LOG, ("region#[%3zd]: %zd", region_index, survived_per_region[region_index]));
-        }
-    }
-    dprintf (REGIONS_LOG, ("global reported %zd", promoted_bytes (heap_number)));
-#endif //_DEBUG
-}
-void gc_heap::update_old_card_survived()
-{
-    if (!survived_per_region) return;
-    for (size_t region_index = 0; region_index < region_count; region_index++)
-    {
-        old_card_survived_per_region[region_index] = survived_per_region[region_index] -
-                                                     old_card_survived_per_region[region_index];
-        if (survived_per_region[region_index] != 0)
-        {
-            dprintf (REGIONS_LOG, ("region#[%3zd]: %zd (card: %zd)",
-                region_index, survived_per_region[region_index], old_card_survived_per_region[region_index]));
-        }
-    }
-}
-void gc_heap::update_planned_gen0_free_space (size_t free_size, uint8_t* plug)
-{
-    gen0_pinned_free_space += free_size;
-    if (!gen0_large_chunk_found)
-    {
-        gen0_large_chunk_found = (free_size >= END_SPACE_AFTER_GC_FL);
-        if (gen0_large_chunk_found)
-        {
-            dprintf (3, ("h%d found large pin free space: %zd at %p",
-                heap_number, free_size, plug));
-        }
-    }
-}
-void gc_heap::get_gen0_end_plan_space()
-{
-    end_gen0_region_space = 0;
-    for (int gen_idx = settings.condemned_generation; gen_idx >= 0; gen_idx--)
-    {
-        generation* gen = generation_of (gen_idx);
-        heap_segment* region = heap_segment_rw (generation_start_segment (gen));
-        while (region)
-        {
-            if (heap_segment_plan_gen_num (region) == 0)
-            {
-                size_t end_plan_space = heap_segment_reserved (region) - heap_segment_plan_allocated (region);
-                if (!gen0_large_chunk_found)
-                {
-                    gen0_large_chunk_found = (end_plan_space >= END_SPACE_AFTER_GC_FL);
-                    if (gen0_large_chunk_found)
-                    {
-                        dprintf (REGIONS_LOG, ("h%d found large end space: %zd in region %p",
-                            heap_number, end_plan_space, heap_segment_mem (region)));
-                    }
-                }
-                dprintf (REGIONS_LOG, ("h%d found end space: %zd in region %p, total %zd->%zd",
-                    heap_number, end_plan_space, heap_segment_mem (region), end_gen0_region_space,
-                    (end_gen0_region_space + end_plan_space)));
-                end_gen0_region_space += end_plan_space;
-            }
-            region = heap_segment_next (region);
-        }
-    }
-}
-size_t gc_heap::get_gen0_end_space(memory_type type)
-{
-    size_t end_space = 0;
-    heap_segment* seg = generation_start_segment (generation_of (0));
-    while (seg)
-    {
-        uint8_t* allocated = heap_segment_allocated (seg);
-        uint8_t* end = (type == memory_type_reserved) ? heap_segment_reserved (seg) : heap_segment_committed (seg);
-        end_space += end - allocated;
-        dprintf (REGIONS_LOG, ("h%d gen0 seg %p, end %p-%p=%zx, end_space->%zd",
-            heap_number, heap_segment_mem (seg),
-            end, allocated,
-            (end - allocated),
-            end_space));
-        seg = heap_segment_next (seg);
-    }
-    return end_space;
-}
-#endif //USE_REGIONS
-inline
-uint8_t* gc_heap::find_next_marked (uint8_t* x, uint8_t* end,
-                                    BOOL use_mark_list,
-                                    uint8_t**& mark_list_next,
-                                    uint8_t** mark_list_index)
-{
-    if (use_mark_list)
-    {
-        uint8_t* old_x = x;
-        while ((mark_list_next < mark_list_index) &&
-            (*mark_list_next <= x))
-        {
-            mark_list_next++;
-        }
-        x = end;
-        if ((mark_list_next < mark_list_index)
-#ifdef MULTIPLE_HEAPS
-            && (*mark_list_next < end) //for multiple segments
-#endif //MULTIPLE_HEAPS
-            )
-        x = *mark_list_next;
-#ifdef BACKGROUND_GC
-        if (current_c_gc_state == c_gc_state_marking)
-        {
-            assert(gc_heap::background_running_p());
-            bgc_clear_batch_mark_array_bits (old_x, x);
-        }
-#endif //BACKGROUND_GC
-    }
-    else
-    {
-        uint8_t* xl = x;
-#ifdef BACKGROUND_GC
-        if (current_c_gc_state == c_gc_state_marking)
-        {
-            assert (gc_heap::background_running_p());
-            while ((xl < end) && !marked (xl))
-            {
-                dprintf (4, ("-%zx-", (size_t)xl));
-                assert ((size (xl) > 0));
-                background_object_marked (xl, TRUE);
-                xl = xl + Align (size (xl));
-                Prefetch (xl);
-            }
-        }
-        else
-#endif //BACKGROUND_GC
-        {
-            while ((xl < end) && !marked (xl))
-            {
-                dprintf (4, ("-%zx-", (size_t)xl));
-                assert ((size (xl) > 0));
-                xl = xl + Align (size (xl));
-                Prefetch (xl);
-            }
-        }
-        assert (xl <= end);
-        x = xl;
-    }
-    return x;
-}
-#ifdef FEATURE_EVENT_TRACE
-void gc_heap::init_bucket_info()
-{
-    memset (bucket_info, 0, sizeof (bucket_info));
-}
-void gc_heap::add_plug_in_condemned_info (generation* gen, size_t plug_size)
-{
-    uint32_t bucket_index = generation_allocator (gen)->first_suitable_bucket (plug_size);
-    (bucket_info[bucket_index].count)++;
-    bucket_info[bucket_index].size += plug_size;
-}
-#endif //FEATURE_EVENT_TRACE
-inline void save_allocated(heap_segment* seg)
-{
-#ifndef MULTIPLE_HEAPS
-    if (!heap_segment_saved_allocated(seg))
-#endif // !MULTIPLE_HEAPS
-    {
-        heap_segment_saved_allocated (seg) = heap_segment_allocated (seg);
-    }
-}
-#ifdef _PREFAST_
-#pragma warning(push)
-#pragma warning(disable:21000) // Suppress PREFast warning about overly large function
-#endif //_PREFAST_
-void gc_heap::plan_phase (int condemned_gen_number)
-{
-    size_t old_gen2_allocated = 0;
-    size_t old_gen2_size = 0;
-    if (condemned_gen_number == (max_generation - 1))
-    {
-        old_gen2_allocated = generation_free_list_allocated (generation_of (max_generation));
-        old_gen2_size = generation_size (max_generation);
-    }
-    assert (settings.concurrent == FALSE);
-    dprintf (2,(ThreadStressLog::gcStartPlanMsg(), heap_number,
-                condemned_gen_number, settings.promotion ? 1 : 0));
-    generation*  condemned_gen1 = generation_of (condemned_gen_number);
-    BOOL use_mark_list = FALSE;
-#ifdef GC_CONFIG_DRIVEN
-    dprintf (3, ("total number of marked objects: %zd (%zd)",
-                 (mark_list_index - &mark_list[0]), (mark_list_end - &mark_list[0])));
-    if (mark_list_index >= (mark_list_end + 1))
-    {
-        mark_list_index = mark_list_end + 1;
-#ifndef MULTIPLE_HEAPS // in Server GC, we check for mark list overflow in sort_mark_list
-        mark_list_overflow = true;
-#endif
-    }
-#else //GC_CONFIG_DRIVEN
-    dprintf (3, ("mark_list length: %zd",
-                 (mark_list_index - &mark_list[0])));
-#endif //GC_CONFIG_DRIVEN
-    if ((condemned_gen_number < max_generation) &&
-        (mark_list_index <= mark_list_end))
-    {
-#ifndef MULTIPLE_HEAPS
-#ifdef USE_VXSORT
-        do_vxsort (mark_list, mark_list_index - mark_list, slow, shigh);
-#else //USE_VXSORT
-        _sort (&mark_list[0], mark_list_index - 1, 0);
-#endif //USE_VXSORT
-        dprintf (3, ("using mark list at GC #%zd", (size_t)settings.gc_index));
-#endif //!MULTIPLE_HEAPS
-        use_mark_list = TRUE;
-        get_gc_data_per_heap()->set_mechanism_bit(gc_mark_list_bit);
-    }
-    else
-    {
-        dprintf (3, ("mark_list not used"));
-    }
-#ifdef FEATURE_BASICFREEZE
-    sweep_ro_segments();
-#endif //FEATURE_BASICFREEZE
-#ifndef MULTIPLE_HEAPS
-    int condemned_gen_index = get_stop_generation_index (condemned_gen_number);
-    for (; condemned_gen_index <= condemned_gen_number; condemned_gen_index++)
-    {
-        generation* current_gen = generation_of (condemned_gen_index);
-        if (shigh != (uint8_t*)0)
-        {
-            heap_segment* seg = heap_segment_rw (generation_start_segment (current_gen));
-            PREFIX_ASSUME(seg != NULL);
-            heap_segment* fseg = seg;
-            do
-            {
-                heap_segment_saved_allocated(seg) = 0;
-                if (in_range_for_segment (slow, seg))
-                {
-                    uint8_t* start_unmarked = 0;
-#ifdef USE_REGIONS
-                    start_unmarked = heap_segment_mem (seg);
-#else //USE_REGIONS
-                    if (seg == fseg)
-                    {
-                        uint8_t* o = generation_allocation_start (current_gen);
-                        o += get_soh_start_obj_len (o);
-                        if (slow > o)
-                        {
-                            start_unmarked = o;
-                            assert ((slow - o) >= (int)Align (min_obj_size));
-                        }
-                    }
-                    else
-                    {
-                        assert (condemned_gen_number == max_generation);
-                        start_unmarked = heap_segment_mem (seg);
-                    }
-#endif //USE_REGIONS
-                    if (start_unmarked)
-                    {
-                        size_t unmarked_size = slow - start_unmarked;
-                        if (unmarked_size > 0)
-                        {
-#ifdef BACKGROUND_GC
-                            if (current_c_gc_state == c_gc_state_marking)
-                            {
-                                bgc_clear_batch_mark_array_bits (start_unmarked, slow);
-                            }
-#endif //BACKGROUND_GC
-                            make_unused_array (start_unmarked, unmarked_size);
-                        }
-                    }
-                }
-                if (in_range_for_segment (shigh, seg))
-                {
-#ifdef BACKGROUND_GC
-                    if (current_c_gc_state == c_gc_state_marking)
-                    {
-                        bgc_clear_batch_mark_array_bits ((shigh + Align (size (shigh))), heap_segment_allocated (seg));
-                    }
-#endif //BACKGROUND_GC
-                    save_allocated(seg);
-                    heap_segment_allocated (seg) = shigh + Align (size (shigh));
-                }
-                if (!((heap_segment_reserved (seg) >= slow) &&
-                    (heap_segment_mem (seg) <= shigh)))
-                {
-#ifdef BACKGROUND_GC
-                    if (current_c_gc_state == c_gc_state_marking)
-                    {
-#ifdef USE_REGIONS
-                        bgc_clear_batch_mark_array_bits (heap_segment_mem (seg), heap_segment_allocated (seg));
-#else //USE_REGIONS
-                        assert (!"cannot happen with segments");
-#endif //USE_REGIONS
-                    }
-#endif //BACKGROUND_GC
-                    save_allocated(seg);
-                    heap_segment_allocated (seg) =  heap_segment_mem (seg);
-                }
-                seg = heap_segment_next_rw (seg);
-            } while (seg);
-        }
-        else
-        {
-            heap_segment* seg = heap_segment_rw (generation_start_segment (current_gen));
-            PREFIX_ASSUME(seg != NULL);
-            heap_segment* sseg = seg;
-            do
-            {
-                heap_segment_saved_allocated(seg) = 0;
-                uint8_t* start_unmarked = heap_segment_mem (seg);
-#ifndef USE_REGIONS
-                if (seg == sseg)
-                {
-                    uint8_t* o = generation_allocation_start (current_gen);
-                    o += get_soh_start_obj_len (o);
-                    start_unmarked = o;
-                }
-#endif //!USE_REGIONS
-#ifdef BACKGROUND_GC
-                if (current_c_gc_state == c_gc_state_marking)
-                {
-                    bgc_clear_batch_mark_array_bits (start_unmarked, heap_segment_allocated (seg));
-                }
-#endif //BACKGROUND_GC
-                save_allocated(seg);
-                heap_segment_allocated (seg) = start_unmarked;
-                seg = heap_segment_next_rw (seg);
-            } while (seg);
-        }
-    }
-#endif //MULTIPLE_HEAPS
-    heap_segment*  seg1 = heap_segment_rw (generation_start_segment (condemned_gen1));
-    PREFIX_ASSUME(seg1 != NULL);
-    uint8_t*  end = heap_segment_allocated (seg1);
-    uint8_t*  first_condemned_address = get_soh_start_object (seg1, condemned_gen1);
-    uint8_t*  x = first_condemned_address;
-#ifdef USE_REGIONS
-    memset (regions_per_gen, 0, sizeof (regions_per_gen));
-    memset (planned_regions_per_gen, 0, sizeof (planned_regions_per_gen));
-    memset (sip_maxgen_regions_per_gen, 0, sizeof (sip_maxgen_regions_per_gen));
-    memset (reserved_free_regions_sip, 0, sizeof (reserved_free_regions_sip));
-    int pinned_survived_region = 0;
-    uint8_t** mark_list_index = nullptr;
-    uint8_t** mark_list_next = nullptr;
-    if (use_mark_list)
-        mark_list_next = get_region_mark_list (use_mark_list, x, end, &mark_list_index);
-#else // USE_REGIONS
-    assert (!marked (x));
-    uint8_t** mark_list_next = &mark_list[0];
-#endif //USE_REGIONS
-    uint8_t*  plug_end = x;
-    uint8_t*  tree = 0;
-    size_t  sequence_number = 0;
-    uint8_t*  last_node = 0;
-    size_t  current_brick = brick_of (x);
-    BOOL  allocate_in_condemned = ((condemned_gen_number == max_generation)||
-                                   (settings.promotion == FALSE));
-    int  active_old_gen_number = condemned_gen_number;
-    int  active_new_gen_number = (allocate_in_condemned ? condemned_gen_number:
-                                  (1 + condemned_gen_number));
-    generation*  older_gen = 0;
-    generation* consing_gen = condemned_gen1;
-    alloc_list  r_free_list [MAX_SOH_BUCKET_COUNT];
-    size_t r_free_list_space = 0;
-    size_t r_free_obj_space = 0;
-    size_t r_older_gen_free_list_allocated = 0;
-    size_t r_older_gen_condemned_allocated = 0;
-    size_t r_older_gen_end_seg_allocated = 0;
-    uint8_t*  r_allocation_pointer = 0;
-    uint8_t*  r_allocation_limit = 0;
-    uint8_t* r_allocation_start_region = 0;
-    heap_segment*  r_allocation_segment = 0;
-#ifdef FREE_USAGE_STATS
-    size_t r_older_gen_free_space[NUM_GEN_POWER2];
-#endif //FREE_USAGE_STATS
-    if ((condemned_gen_number < max_generation))
-    {
-        older_gen = generation_of (min ((int)max_generation, 1 + condemned_gen_number));
-        generation_allocator (older_gen)->copy_to_alloc_list (r_free_list);
-        r_free_list_space = generation_free_list_space (older_gen);
-        r_free_obj_space = generation_free_obj_space (older_gen);
-#ifdef FREE_USAGE_STATS
-        memcpy (r_older_gen_free_space, older_gen->gen_free_spaces, sizeof (r_older_gen_free_space));
-#endif //FREE_USAGE_STATS
-        generation_allocate_end_seg_p (older_gen) = FALSE;
-#ifdef DOUBLY_LINKED_FL
-        if (older_gen->gen_num == max_generation)
-        {
-            generation_set_bgc_mark_bit_p (older_gen) = FALSE;
-            generation_last_free_list_allocated (older_gen) = 0;
-        }
-#endif //DOUBLY_LINKED_FL
-        r_older_gen_free_list_allocated = generation_free_list_allocated (older_gen);
-        r_older_gen_condemned_allocated = generation_condemned_allocated (older_gen);
-        r_older_gen_end_seg_allocated = generation_end_seg_allocated (older_gen);
-        r_allocation_limit = generation_allocation_limit (older_gen);
-        r_allocation_pointer = generation_allocation_pointer (older_gen);
-        r_allocation_start_region = generation_allocation_context_start_region (older_gen);
-        r_allocation_segment = generation_allocation_segment (older_gen);
-#ifdef USE_REGIONS
-        if (older_gen->gen_num == max_generation)
-        {
-            check_seg_gen_num (r_allocation_segment);
-        }
-#endif //USE_REGIONS
-        heap_segment* start_seg = heap_segment_rw (generation_start_segment (older_gen));
-        PREFIX_ASSUME(start_seg != NULL);
-#ifdef USE_REGIONS
-        heap_segment* skip_seg = 0;
-        assert (generation_allocation_pointer (older_gen) == 0);
-        assert (generation_allocation_limit (older_gen) == 0);
-#else //USE_REGIONS
-        heap_segment* skip_seg = ephemeral_heap_segment;
-        if (start_seg != ephemeral_heap_segment)
-        {
-            assert (condemned_gen_number == (max_generation - 1));
-        }
-#endif //USE_REGIONS
-        if (start_seg != skip_seg)
-        {
-            while (start_seg && (start_seg != skip_seg))
-            {
-                assert (heap_segment_allocated (start_seg) >=
-                        heap_segment_mem (start_seg));
-                assert (heap_segment_allocated (start_seg) <=
-                        heap_segment_reserved (start_seg));
-                heap_segment_plan_allocated (start_seg) =
-                    heap_segment_allocated (start_seg);
-                start_seg = heap_segment_next_rw (start_seg);
-            }
-        }
-    }
-    {
-        int condemned_gen_index1 = get_stop_generation_index (condemned_gen_number);
-        for (; condemned_gen_index1 <= condemned_gen_number; condemned_gen_index1++)
-        {
-            generation* current_gen = generation_of (condemned_gen_index1);
-            heap_segment*  seg2 = heap_segment_rw (generation_start_segment (current_gen));
-            PREFIX_ASSUME(seg2 != NULL);
-            while (seg2)
-            {
-#ifdef USE_REGIONS
-                regions_per_gen[condemned_gen_index1]++;
-                dprintf (REGIONS_LOG, ("h%d PS: gen%d %p-%p (%d, surv: %d), %d regions",
-                    heap_number, condemned_gen_index1,
-                    heap_segment_mem (seg2), heap_segment_allocated (seg2),
-                    (heap_segment_allocated (seg2) - heap_segment_mem (seg2)),
-                    (int)heap_segment_survived (seg2), regions_per_gen[condemned_gen_index1]));
-#endif //USE_REGIONS
-                heap_segment_plan_allocated (seg2) =
-                    heap_segment_mem (seg2);
-                seg2 = heap_segment_next_rw (seg2);
-            }
-        }
-    }
-    int  condemned_gn = condemned_gen_number;
-    int bottom_gen = 0;
-    init_free_and_plug();
-    while (condemned_gn >= bottom_gen)
-    {
-        generation*  condemned_gen2 = generation_of (condemned_gn);
-        generation_allocator (condemned_gen2)->clear();
-        generation_free_list_space (condemned_gen2) = 0;
-        generation_free_obj_space (condemned_gen2) = 0;
-        generation_allocation_size (condemned_gen2) = 0;
-        generation_condemned_allocated (condemned_gen2) = 0;
-        generation_sweep_allocated (condemned_gen2) = 0;
-        generation_free_list_allocated(condemned_gen2) = 0;
-        generation_end_seg_allocated (condemned_gen2) = 0;
-        generation_pinned_allocation_sweep_size (condemned_gen2) = 0;
-        generation_pinned_allocation_compact_size (condemned_gen2) = 0;
-#ifdef FREE_USAGE_STATS
-        generation_pinned_free_obj_space (condemned_gen2) = 0;
-        generation_allocated_in_pinned_free (condemned_gen2) = 0;
-        generation_allocated_since_last_pin (condemned_gen2) = 0;
-#endif //FREE_USAGE_STATS
-#ifndef USE_REGIONS
-        generation_plan_allocation_start (condemned_gen2) = 0;
-#endif //!USE_REGIONS
-        generation_allocation_segment (condemned_gen2) =
-            heap_segment_rw (generation_start_segment (condemned_gen2));
-        PREFIX_ASSUME(generation_allocation_segment(condemned_gen2) != NULL);
-#ifdef USE_REGIONS
-        generation_allocation_pointer (condemned_gen2) =
-            heap_segment_mem (generation_allocation_segment (condemned_gen2));
-#else //USE_REGIONS
-        if (generation_start_segment (condemned_gen2) != ephemeral_heap_segment)
-        {
-            generation_allocation_pointer (condemned_gen2) =
-                heap_segment_mem (generation_allocation_segment (condemned_gen2));
-        }
-        else
-        {
-            generation_allocation_pointer (condemned_gen2) = generation_allocation_start (condemned_gen2);
-        }
-#endif //USE_REGIONS
-        generation_allocation_limit (condemned_gen2) = generation_allocation_pointer (condemned_gen2);
-        generation_allocation_context_start_region (condemned_gen2) = generation_allocation_pointer (condemned_gen2);
-        condemned_gn--;
-    }
-    BOOL allocate_first_generation_start = FALSE;
-    if (allocate_in_condemned)
-    {
-        allocate_first_generation_start = TRUE;
-    }
-    dprintf(3,( " From %zx to %zx", (size_t)x, (size_t)end));
-#ifdef USE_REGIONS
-    if (should_sweep_in_plan (seg1))
-    {
-        sweep_region_in_plan (seg1, use_mark_list, mark_list_next, mark_list_index);
-        x = end;
-    }
-#else
-    demotion_low = MAX_PTR;
-    demotion_high = heap_segment_allocated (ephemeral_heap_segment);
-    demote_gen1_p = !(settings.promotion &&
-        (settings.condemned_generation == (max_generation - 1)) &&
-        gen_to_condemn_reasons.is_only_condition(gen_low_card_p));
-    total_ephemeral_size = 0;
-#endif //!USE_REGIONS
-    print_free_and_plug ("BP");
-#ifndef USE_REGIONS
-    for (int gen_idx = 0; gen_idx <= max_generation; gen_idx++)
-    {
-        generation* temp_gen = generation_of (gen_idx);
-        dprintf (2, ("gen%d start %p, plan start %p",
-            gen_idx,
-            generation_allocation_start (temp_gen),
-            generation_plan_allocation_start (temp_gen)));
-    }
-#endif //!USE_REGIONS
-#ifdef FEATURE_EVENT_TRACE
-    bool record_fl_info_p = (EVENT_ENABLED (GCFitBucketInfo) && (condemned_gen_number == (max_generation - 1)));
-    size_t recorded_fl_info_size = 0;
-    if (record_fl_info_p)
-        init_bucket_info();
-    bool fire_pinned_plug_events_p = EVENT_ENABLED(PinPlugAtGCTime);
-#endif //FEATURE_EVENT_TRACE
-    size_t last_plug_len = 0;
-#ifdef DOUBLY_LINKED_FL
-    gen2_removed_no_undo = 0;
-    saved_pinned_plug_index = INVALID_SAVED_PINNED_PLUG_INDEX;
-#endif //DOUBLY_LINKED_FL
-    while (1)
-    {
-        if (x >= end)
-        {
-            if (!use_mark_list)
-            {
-                assert (x == end);
-            }
-#ifdef USE_REGIONS
-            if (heap_segment_swept_in_plan (seg1))
-            {
-                assert (heap_segment_gen_num (seg1) == active_old_gen_number);
-                dynamic_data* dd_active_old = dynamic_data_of (active_old_gen_number);
-                dd_survived_size (dd_active_old) += heap_segment_survived (seg1);
-                dprintf (REGIONS_LOG, ("region %p-%p SIP",
-                    heap_segment_mem (seg1), heap_segment_allocated (seg1)));
-            }
-            else
-#endif //USE_REGIONS
-            {
-                assert (heap_segment_allocated (seg1) == end);
-                save_allocated(seg1);
-                heap_segment_allocated (seg1) = plug_end;
-                current_brick = update_brick_table (tree, current_brick, x, plug_end);
-                dprintf (REGIONS_LOG, ("region %p-%p(%p) non SIP",
-                    heap_segment_mem (seg1), heap_segment_allocated (seg1),
-                    heap_segment_plan_allocated (seg1)));
-                dprintf (3, ("end of seg: new tree, sequence# 0"));
-                sequence_number = 0;
-                tree = 0;
-            }
-#ifdef USE_REGIONS
-            heap_segment_pinned_survived (seg1) = pinned_survived_region;
-            dprintf (REGIONS_LOG, ("h%d setting seg %p pin surv: %d",
-                heap_number, heap_segment_mem (seg1), pinned_survived_region));
-            pinned_survived_region = 0;
-            if (heap_segment_mem (seg1) == heap_segment_allocated (seg1))
-            {
-                num_regions_freed_in_sweep++;
-            }
-#endif //USE_REGIONS
-            if (heap_segment_next_rw (seg1))
-            {
-                seg1 = heap_segment_next_rw (seg1);
-                end = heap_segment_allocated (seg1);
-                plug_end = x = heap_segment_mem (seg1);
-                current_brick = brick_of (x);
-#ifdef USE_REGIONS
-                if (use_mark_list)
-                    mark_list_next = get_region_mark_list (use_mark_list, x, end, &mark_list_index);
-                if (should_sweep_in_plan (seg1))
-                {
-                    sweep_region_in_plan (seg1, use_mark_list, mark_list_next, mark_list_index);
-                    x = end;
-                }
-#endif //USE_REGIONS
-                dprintf(3,( " From %zx to %zx", (size_t)x, (size_t)end));
-                continue;
-            }
-            else
-            {
-#ifdef USE_REGIONS
-                int saved_active_new_gen_number = active_new_gen_number;
-                BOOL saved_allocate_in_condemned = allocate_in_condemned;
-                dprintf (REGIONS_LOG, ("h%d finished planning gen%d regions into gen%d, alloc_in_condemned: %d",
-                    heap_number, active_old_gen_number, active_new_gen_number, allocate_in_condemned));
-                if (active_old_gen_number <= (settings.promotion ? (max_generation - 1) : max_generation))
-                {
-                    dprintf (REGIONS_LOG, ("h%d active old: %d, new: %d->%d, allocate_in_condemned %d->1",
-                        heap_number, active_old_gen_number,
-                        active_new_gen_number, (active_new_gen_number - 1),
-                        allocate_in_condemned));
-                    active_new_gen_number--;
-                    allocate_in_condemned = TRUE;
-                }
-                if (active_new_gen_number >= 0)
-                {
-                    process_last_np_surv_region (consing_gen, saved_active_new_gen_number, active_new_gen_number);
-                }
-                if (active_old_gen_number == 0)
-                {
-                    process_remaining_regions (active_new_gen_number, consing_gen);
-                    break;
-                }
-                else
-                {
-                    active_old_gen_number--;
-                    seg1 = heap_segment_rw (generation_start_segment (generation_of (active_old_gen_number)));
-                    end = heap_segment_allocated (seg1);
-                    plug_end = x = heap_segment_mem (seg1);
-                    current_brick = brick_of (x);
-                    if (use_mark_list)
-                        mark_list_next = get_region_mark_list (use_mark_list, x, end, &mark_list_index);
-                    if (should_sweep_in_plan (seg1))
-                    {
-                        sweep_region_in_plan (seg1, use_mark_list, mark_list_next, mark_list_index);
-                        x = end;
-                    }
-                    dprintf (REGIONS_LOG,("h%d switching to gen%d start region %p, %p-%p",
-                        heap_number, active_old_gen_number, heap_segment_mem (seg1), x, end));
-                    continue;
-                }
-#else //USE_REGIONS
-                break;
-#endif //USE_REGIONS
-            }
-        }
-        BOOL last_npinned_plug_p = FALSE;
-        BOOL last_pinned_plug_p = FALSE;
-        uint8_t* last_pinned_plug = 0;
-        size_t num_pinned_plugs_in_plug = 0;
-        uint8_t* last_object_in_plug = 0;
-        while ((x < end) && marked (x))
-        {
-            uint8_t*  plug_start = x;
-            uint8_t*  saved_plug_end = plug_end;
-            BOOL   pinned_plug_p = FALSE;
-            BOOL   npin_before_pin_p = FALSE;
-            BOOL   saved_last_npinned_plug_p = last_npinned_plug_p;
-            uint8_t*  saved_last_object_in_plug = last_object_in_plug;
-            BOOL   merge_with_last_pin_p = FALSE;
-            size_t added_pinning_size = 0;
-            size_t artificial_pinned_size = 0;
-            store_plug_gap_info (plug_start, plug_end, last_npinned_plug_p, last_pinned_plug_p,
-                                 last_pinned_plug, pinned_plug_p, last_object_in_plug,
-                                 merge_with_last_pin_p, last_plug_len);
-#ifdef FEATURE_STRUCTALIGN
-            int requiredAlignment = ((CObjectHeader*)plug_start)->GetRequiredAlignment();
-            size_t alignmentOffset = OBJECT_ALIGNMENT_OFFSET;
-#endif // FEATURE_STRUCTALIGN
-            {
-                uint8_t* xl = x;
-                while ((xl < end) && marked (xl) && (pinned (xl) == pinned_plug_p))
-                {
-                    assert (xl < end);
-                    if (pinned(xl))
-                    {
-                        clear_pinned (xl);
-                    }
-#ifdef FEATURE_STRUCTALIGN
-                    else
-                    {
-                        int obj_requiredAlignment = ((CObjectHeader*)xl)->GetRequiredAlignment();
-                        if (obj_requiredAlignment > requiredAlignment)
-                        {
-                            requiredAlignment = obj_requiredAlignment;
-                            alignmentOffset = xl - plug_start + OBJECT_ALIGNMENT_OFFSET;
-                        }
-                    }
-#endif // FEATURE_STRUCTALIGN
-                    clear_marked (xl);
-                    dprintf(4, ("+%zx+", (size_t)xl));
-                    assert ((size (xl) > 0));
-                    assert ((size (xl) <= loh_size_threshold));
-                    last_object_in_plug = xl;
-                    xl = xl + Align (size (xl));
-                    Prefetch (xl);
-                }
-                BOOL next_object_marked_p = ((xl < end) && marked (xl));
-                if (pinned_plug_p)
-                {
-                    if (next_object_marked_p)
-                    {
-                        clear_marked (xl);
-                        last_object_in_plug = xl;
-                        size_t extra_size = Align (size (xl));
-                        xl = xl + extra_size;
-                        added_pinning_size = extra_size;
-                    }
-                }
-                else
-                {
-                    if (next_object_marked_p)
-                        npin_before_pin_p = TRUE;
-                }
-                assert (xl <= end);
-                x = xl;
-            }
-            dprintf (3, ( "%zx[", (size_t)plug_start));
-            plug_end = x;
-            size_t ps = plug_end - plug_start;
-            last_plug_len = ps;
-            dprintf (3, ( "%zx[(%zx)", (size_t)x, ps));
-            uint8_t*  new_address = 0;
-            if (!pinned_plug_p)
-            {
-                if (allocate_in_condemned &&
-                    (settings.condemned_generation == max_generation) &&
-                    (ps > OS_PAGE_SIZE))
-                {
-                    ptrdiff_t reloc = plug_start - generation_allocation_pointer (consing_gen);
-                    if ((ps > (8*OS_PAGE_SIZE)) &&
-                        (reloc > 0) &&
-                        ((size_t)reloc < (ps/16)))
-                    {
-                        dprintf (3, ("Pinning %zx; reloc would have been: %zx",
-                                     (size_t)plug_start, reloc));
-                        assert (!saved_last_npinned_plug_p);
-                        if (last_pinned_plug)
-                        {
-                            dprintf (3, ("artificially pinned plug merged with last pinned plug"));
-                            merge_with_last_pin_p = TRUE;
-                        }
-                        else
-                        {
-                            enque_pinned_plug (plug_start, FALSE, 0);
-                            last_pinned_plug = plug_start;
-                        }
-                        convert_to_pinned_plug (last_npinned_plug_p, last_pinned_plug_p, pinned_plug_p,
-                                                ps, artificial_pinned_size);
-                    }
-                }
-            }
-#ifndef USE_REGIONS
-            if (allocate_first_generation_start)
-            {
-                allocate_first_generation_start = FALSE;
-                plan_generation_start (condemned_gen1, consing_gen, plug_start);
-                assert (generation_plan_allocation_start (condemned_gen1));
-            }
-            if (seg1 == ephemeral_heap_segment)
-            {
-                process_ephemeral_boundaries (plug_start, active_new_gen_number,
-                                              active_old_gen_number,
-                                              consing_gen,
-                                              allocate_in_condemned);
-            }
-#endif //!USE_REGIONS
-            dprintf (3, ("adding %zd to gen%d surv", ps, active_old_gen_number));
-            dynamic_data* dd_active_old = dynamic_data_of (active_old_gen_number);
-            dd_survived_size (dd_active_old) += ps;
-            BOOL convert_to_pinned_p = FALSE;
-            BOOL allocated_in_older_p = FALSE;
-            if (!pinned_plug_p)
-            {
-#if defined (RESPECT_LARGE_ALIGNMENT) || defined (FEATURE_STRUCTALIGN)
-                dd_num_npinned_plugs (dd_active_old)++;
-#endif //RESPECT_LARGE_ALIGNMENT || FEATURE_STRUCTALIGN
-                add_gen_plug (active_old_gen_number, ps);
-                if (allocate_in_condemned)
-                {
-                    verify_pins_with_post_plug_info("before aic");
-                    new_address =
-                        allocate_in_condemned_generations (consing_gen,
-                                                           ps,
-                                                           active_old_gen_number,
-#ifdef SHORT_PLUGS
-                                                           &convert_to_pinned_p,
-                                                           (npin_before_pin_p ? plug_end : 0),
-                                                           seg1,
-#endif //SHORT_PLUGS
-                                                           plug_start REQD_ALIGN_AND_OFFSET_ARG);
-                    verify_pins_with_post_plug_info("after aic");
-                }
-                else
-                {
-                    new_address = allocate_in_older_generation (older_gen, ps, active_old_gen_number, plug_start REQD_ALIGN_AND_OFFSET_ARG);
-                    if (new_address != 0)
-                    {
-                        allocated_in_older_p = TRUE;
-                        if (settings.condemned_generation == (max_generation - 1))
-                        {
-                            dprintf (3, (" NA: %p-%p -> %zx, %zx (%zx)",
-                                plug_start, plug_end,
-                                (size_t)new_address, (size_t)new_address + (plug_end - plug_start),
-                                (size_t)(plug_end - plug_start)));
-                        }
-                    }
-                    else
-                    {
-                        if (generation_allocator(older_gen)->discard_if_no_fit_p())
-                        {
-                            allocate_in_condemned = TRUE;
-                        }
-                        new_address = allocate_in_condemned_generations (consing_gen, ps, active_old_gen_number,
-#ifdef SHORT_PLUGS
-                                                                         &convert_to_pinned_p,
-                                                                         (npin_before_pin_p ? plug_end : 0),
-                                                                         seg1,
-#endif //SHORT_PLUGS
-                                                                         plug_start REQD_ALIGN_AND_OFFSET_ARG);
-                    }
-                }
-#ifdef FEATURE_EVENT_TRACE
-                if (record_fl_info_p && !allocated_in_older_p)
-                {
-                    add_plug_in_condemned_info (older_gen, ps);
-                    recorded_fl_info_size += ps;
-                }
-#endif //FEATURE_EVENT_TRACE
-                if (convert_to_pinned_p)
-                {
-                    assert (last_npinned_plug_p != FALSE);
-                    assert (last_pinned_plug_p == FALSE);
-                    convert_to_pinned_plug (last_npinned_plug_p, last_pinned_plug_p, pinned_plug_p,
-                                            ps, artificial_pinned_size);
-                    enque_pinned_plug (plug_start, FALSE, 0);
-                    last_pinned_plug = plug_start;
-                }
-                else
-                {
-                    if (!new_address)
-                    {
-                        assert (generation_allocation_segment (consing_gen) ==
-                                ephemeral_heap_segment);
-                        assert ((generation_allocation_pointer (consing_gen) + Align (ps)) <
-                                heap_segment_allocated (ephemeral_heap_segment));
-                        assert ((generation_allocation_pointer (consing_gen) + Align (ps)) >
-                                (heap_segment_allocated (ephemeral_heap_segment) + Align (min_obj_size)));
-                    }
-                    else
-                    {
-                        dprintf (3, (ThreadStressLog::gcPlanPlugMsg(),
-                            (size_t)(node_gap_size (plug_start)),
-                            plug_start, plug_end, (size_t)new_address, (size_t)(plug_start - new_address),
-                                (size_t)new_address + ps, ps,
-                                (is_plug_padded (plug_start) ? 1 : 0), x,
-                                (allocated_in_older_p ? "O" : "C")));
-#ifdef SHORT_PLUGS
-                        if (is_plug_padded (plug_start))
-                        {
-                            dprintf (3, ("%p was padded", plug_start));
-                            dd_padding_size (dd_active_old) += Align (min_obj_size);
-                        }
-#endif //SHORT_PLUGS
-                    }
-                }
-            }
-            if (pinned_plug_p)
-            {
-#ifdef FEATURE_EVENT_TRACE
-                if (fire_pinned_plug_events_p)
-                {
-                    FIRE_EVENT(PinPlugAtGCTime, plug_start, plug_end,
-                               (merge_with_last_pin_p ? 0 : (uint8_t*)node_gap_size (plug_start)));
-                }
-#endif //FEATURE_EVENT_TRACE
-                if (merge_with_last_pin_p)
-                {
-                    merge_with_last_pinned_plug (last_pinned_plug, ps);
-                }
-                else
-                {
-                    assert (last_pinned_plug == plug_start);
-                    set_pinned_info (plug_start, ps, consing_gen);
-                }
-                new_address = plug_start;
-                dprintf (3, (ThreadStressLog::gcPlanPinnedPlugMsg(),
-                            (size_t)(node_gap_size (plug_start)), (size_t)plug_start,
-                            (size_t)plug_end, ps,
-                            (merge_with_last_pin_p ? 1 : 0)));
-                dprintf (3, ("adding %zd to gen%d pinned surv", plug_end - plug_start, active_old_gen_number));
-                size_t pinned_plug_size = plug_end - plug_start;
-#ifdef USE_REGIONS
-                pinned_survived_region += (int)pinned_plug_size;
-#endif //USE_REGIONS
-                dd_pinned_survived_size (dd_active_old) += pinned_plug_size;
-                dd_added_pinned_size (dd_active_old) += added_pinning_size;
-                dd_artificial_pinned_survived_size (dd_active_old) += artificial_pinned_size;
-#ifndef USE_REGIONS
-                if (!demote_gen1_p && (active_old_gen_number == (max_generation - 1)))
-                {
-                    last_gen1_pin_end = plug_end;
-                }
-#endif //!USE_REGIONS
-            }
-#ifdef _DEBUG
-            assert (!((new_address > plug_start) &&
-                (new_address < heap_segment_reserved (seg1))));
-#endif //_DEBUG
-            if (!merge_with_last_pin_p)
-            {
-                if (current_brick != brick_of (plug_start))
-                {
-                    current_brick = update_brick_table (tree, current_brick, plug_start, saved_plug_end);
-                    sequence_number = 0;
-                    tree = 0;
-                }
-                set_node_relocation_distance (plug_start, (new_address - plug_start));
-                if (last_node && (node_relocation_distance (last_node) ==
-                                  (node_relocation_distance (plug_start) +
-                                   (ptrdiff_t)node_gap_size (plug_start))))
-                {
-                    dprintf (3, ("%p Lb", plug_start));
-                    set_node_left (plug_start);
-                }
-                if (0 == sequence_number)
-                {
-                    dprintf (2, ("sn: 0, tree is set to %p", plug_start));
-                    tree = plug_start;
-                }
-                verify_pins_with_post_plug_info("before insert node");
-                tree = insert_node (plug_start, ++sequence_number, tree, last_node);
-                dprintf (3, ("tree is %p (b: %zx) after insert_node(lc: %p, rc: %p)",
-                    tree, brick_of (tree),
-                    (tree + node_left_child (tree)), (tree + node_right_child (tree))));
-                last_node = plug_start;
-#ifdef _DEBUG
-                if (!pinned_plug_p)
-                {
-                    if (mark_stack_tos > 0)
-                    {
-                        mark& m = mark_stack_array[mark_stack_tos - 1];
-                        if (m.has_post_plug_info())
-                        {
-                            uint8_t* post_plug_info_start = m.saved_post_plug_info_start;
-                            size_t* current_plug_gap_start = (size_t*)(plug_start - sizeof (plug_and_gap));
-                            if ((uint8_t*)current_plug_gap_start == post_plug_info_start)
-                            {
-                                dprintf (3, ("Ginfo: %zx, %zx, %zx",
-                                    *current_plug_gap_start, *(current_plug_gap_start + 1),
-                                    *(current_plug_gap_start + 2)));
-                                memcpy (&(m.saved_post_plug_debug), current_plug_gap_start, sizeof (gap_reloc_pair));
-                            }
-                        }
-                    }
-                }
-#endif //_DEBUG
-                verify_pins_with_post_plug_info("after insert node");
-            }
-        }
-        if (num_pinned_plugs_in_plug > 1)
-        {
-            dprintf (3, ("more than %zd pinned plugs in this plug", num_pinned_plugs_in_plug));
-        }
-        x = find_next_marked (x, end, use_mark_list, mark_list_next, mark_list_index);
-    }
-#ifndef USE_REGIONS
-    while (!pinned_plug_que_empty_p())
-    {
-        if (settings.promotion)
-        {
-            uint8_t* pplug = pinned_plug (oldest_pin());
-            if (in_range_for_segment (pplug, ephemeral_heap_segment))
-            {
-                consing_gen = ensure_ephemeral_heap_segment (consing_gen);
-                while (active_new_gen_number > 0)
-                {
-                    active_new_gen_number--;
-                    if (active_new_gen_number == (max_generation - 1))
-                    {
-                        maxgen_pinned_compact_before_advance = generation_pinned_allocation_compact_size (generation_of (max_generation));
-                        if (!demote_gen1_p)
-                            advance_pins_for_demotion (consing_gen);
-                    }
-                    generation* gen = generation_of (active_new_gen_number);
-                    plan_generation_start (gen, consing_gen, 0);
-                    if (demotion_low == MAX_PTR)
-                    {
-                        demotion_low = pplug;
-                        dprintf (3, ("end plan: dlow->%p", demotion_low));
-                    }
-                    dprintf (2, ("(%d)gen%d plan start: %zx",
-                                  heap_number, active_new_gen_number, (size_t)generation_plan_allocation_start (gen)));
-                    assert (generation_plan_allocation_start (gen));
-                }
-            }
-        }
-        if (pinned_plug_que_empty_p())
-            break;
-        size_t  entry = deque_pinned_plug();
-        mark*  m = pinned_plug_of (entry);
-        uint8_t*  plug = pinned_plug (m);
-        size_t  len = pinned_len (m);
-        heap_segment* nseg = heap_segment_rw (generation_allocation_segment (consing_gen));
-        while ((plug < generation_allocation_pointer (consing_gen)) ||
-               (plug >= heap_segment_allocated (nseg)))
-        {
-            assert ((plug < heap_segment_mem (nseg)) ||
-                    (plug > heap_segment_reserved (nseg)));
-            assert (generation_allocation_pointer (consing_gen)>=
-                    heap_segment_mem (nseg));
-            assert (generation_allocation_pointer (consing_gen)<=
-                    heap_segment_committed (nseg));
-            heap_segment_plan_allocated (nseg) =
-                generation_allocation_pointer (consing_gen);
-            nseg = heap_segment_next_rw (nseg);
-            generation_allocation_segment (consing_gen) = nseg;
-            generation_allocation_pointer (consing_gen) =
-                heap_segment_mem (nseg);
-        }
-        set_new_pin_info (m, generation_allocation_pointer (consing_gen));
-        dprintf (2, ("pin %p b: %zx->%zx", plug, brick_of (plug),
-            (size_t)(brick_table[brick_of (plug)])));
-        generation_allocation_pointer (consing_gen) = plug + len;
-        generation_allocation_limit (consing_gen) =
-            generation_allocation_pointer (consing_gen);
-        int frgn = object_gennum (plug);
-        if ((frgn != (int)max_generation) && settings.promotion)
-        {
-            generation_pinned_allocation_sweep_size ((generation_of (frgn +1))) += len;
-        }
-    }
-    plan_generation_starts (consing_gen);
-#endif //!USE_REGIONS
-    descr_generations ("AP");
-    print_free_and_plug ("AP");
-    {
-#ifdef SIMPLE_DPRINTF
-        for (int gen_idx = 0; gen_idx <= max_generation; gen_idx++)
-        {
-            generation* temp_gen = generation_of (gen_idx);
-            dynamic_data* temp_dd = dynamic_data_of (gen_idx);
-            int added_pinning_ratio = 0;
-            int artificial_pinned_ratio = 0;
-            if (dd_pinned_survived_size (temp_dd) != 0)
-            {
-                added_pinning_ratio = (int)((float)dd_added_pinned_size (temp_dd) * 100 / (float)dd_pinned_survived_size (temp_dd));
-                artificial_pinned_ratio = (int)((float)dd_artificial_pinned_survived_size (temp_dd) * 100 / (float)dd_pinned_survived_size (temp_dd));
-            }
-            size_t padding_size =
-#ifdef SHORT_PLUGS
-                dd_padding_size (temp_dd);
-#else
-                0;
-#endif //SHORT_PLUGS
-            dprintf (1, ("gen%d: NON PIN alloc: %zd, pin com: %zd, sweep: %zd, surv: %zd, pinsurv: %zd(%d%% added, %d%% art), np surv: %zd, pad: %zd",
-                gen_idx,
-                generation_allocation_size (temp_gen),
-                generation_pinned_allocation_compact_size (temp_gen),
-                generation_pinned_allocation_sweep_size (temp_gen),
-                dd_survived_size (temp_dd),
-                dd_pinned_survived_size (temp_dd),
-                added_pinning_ratio,
-                artificial_pinned_ratio,
-                (dd_survived_size (temp_dd) - dd_pinned_survived_size (temp_dd)),
-                padding_size));
-#ifndef USE_REGIONS
-            dprintf (1, ("gen%d: %p, %p(%zd)",
-                gen_idx,
-                generation_allocation_start (temp_gen),
-                generation_plan_allocation_start (temp_gen),
-                (size_t)(generation_plan_allocation_start (temp_gen) - generation_allocation_start (temp_gen))));
-#endif //USE_REGIONS
-        }
-#endif //SIMPLE_DPRINTF
-    }
-    if (settings.condemned_generation == (max_generation - 1 ))
-    {
-        generation* older_gen = generation_of (settings.condemned_generation + 1);
-        size_t rejected_free_space = generation_free_obj_space (older_gen) - r_free_obj_space;
-        size_t free_list_allocated = generation_free_list_allocated (older_gen) - r_older_gen_free_list_allocated;
-        size_t end_seg_allocated = generation_end_seg_allocated (older_gen) - r_older_gen_end_seg_allocated;
-        size_t condemned_allocated = generation_condemned_allocated (older_gen) - r_older_gen_condemned_allocated;
-        size_t growth = end_seg_allocated + condemned_allocated;
-        if (growth > 0)
-        {
-            dprintf (1, ("gen2 grew %zd (end seg alloc: %zd, condemned alloc: %zd",
-                         growth, end_seg_allocated, condemned_allocated));
-            maxgen_size_inc_p = true;
-        }
-        else
-        {
-            dprintf (1, ("gen2 didn't grow (end seg alloc: %zd, , condemned alloc: %zd, gen1 c alloc: %zd",
-                         end_seg_allocated, condemned_allocated,
-                         generation_condemned_allocated (generation_of (max_generation - 1))));
-        }
-        dprintf (2, ("older gen's free alloc: %zd->%zd, seg alloc: %zd->%zd, condemned alloc: %zd->%zd",
-                    r_older_gen_free_list_allocated, generation_free_list_allocated (older_gen),
-                    r_older_gen_end_seg_allocated, generation_end_seg_allocated (older_gen),
-                    r_older_gen_condemned_allocated, generation_condemned_allocated (older_gen)));
-        dprintf (2, ("this GC did %zd free list alloc(%zd bytes free space rejected)",
-            free_list_allocated, rejected_free_space));
-        maxgen_size_increase* maxgen_size_info = &(get_gc_data_per_heap()->maxgen_size_info);
-        maxgen_size_info->free_list_allocated = free_list_allocated;
-        maxgen_size_info->free_list_rejected = rejected_free_space;
-        maxgen_size_info->end_seg_allocated = end_seg_allocated;
-        maxgen_size_info->condemned_allocated = condemned_allocated;
-        maxgen_size_info->pinned_allocated = maxgen_pinned_compact_before_advance;
-        maxgen_size_info->pinned_allocated_advance = generation_pinned_allocation_compact_size (generation_of (max_generation)) - maxgen_pinned_compact_before_advance;
-#ifdef FREE_USAGE_STATS
-        int free_list_efficiency = 0;
-        if ((free_list_allocated + rejected_free_space) != 0)
-            free_list_efficiency = (int)(((float) (free_list_allocated) / (float)(free_list_allocated + rejected_free_space)) * (float)100);
-        size_t running_free_list_efficiency = generation_allocator_efficiency_percent(older_gen);
-        dprintf (1, ("gen%d free list alloc effi: %d%%, current effi: %zu%%",
-                    older_gen->gen_num,
-                    free_list_efficiency, running_free_list_efficiency));
-        dprintf (1, ("gen2 free list change"));
-        for (int j = 0; j < NUM_GEN_POWER2; j++)
-        {
-            dprintf (1, ("[h%d][#%zd]: 2^%d: F: %zd->%zd(%zd), P: %zd",
-                heap_number,
-                settings.gc_index,
-                (j + 10), r_older_gen_free_space[j], older_gen->gen_free_spaces[j],
-                (ptrdiff_t)(r_older_gen_free_space[j] - older_gen->gen_free_spaces[j]),
-                (generation_of(max_generation - 1))->gen_plugs[j]));
-        }
-#endif //FREE_USAGE_STATS
-    }
-    size_t fragmentation =
-        generation_fragmentation (generation_of (condemned_gen_number),
-                                  consing_gen,
-                                  heap_segment_allocated (ephemeral_heap_segment));
-    dprintf (2,("Fragmentation: %zd", fragmentation));
-    dprintf (2,("---- End of Plan phase ----"));
-    assert(IsGCInProgress());
-    BOOL should_expand = FALSE;
-    BOOL should_compact= FALSE;
-#ifndef USE_REGIONS
-    ephemeral_promotion = FALSE;
-#endif //!USE_REGIONS
-#ifdef HOST_64BIT
-    if ((!settings.concurrent) &&
-#ifdef USE_REGIONS
-        !special_sweep_p &&
-#endif //USE_REGIONS
-        !provisional_mode_triggered &&
-        ((condemned_gen_number < max_generation) &&
-         ((settings.gen0_reduction_count > 0) || (settings.entry_memory_load >= 95))))
-    {
-        dprintf (GTC_LOG, ("gen0 reduction count is %d, condemning %d, mem load %d",
-                     settings.gen0_reduction_count,
-                     condemned_gen_number,
-                     settings.entry_memory_load));
-        should_compact = TRUE;
-        get_gc_data_per_heap()->set_mechanism (gc_heap_compact,
-            ((settings.gen0_reduction_count > 0) ? compact_fragmented_gen0 : compact_high_mem_load));
-#ifndef USE_REGIONS
-        if ((condemned_gen_number >= (max_generation - 1)) &&
-            dt_low_ephemeral_space_p (tuning_deciding_expansion))
-        {
-            dprintf (GTC_LOG, ("Not enough space for all ephemeral generations with compaction"));
-            should_expand = TRUE;
-        }
-#endif //!USE_REGIONS
-    }
-    else
-#endif // HOST_64BIT
-    {
-        should_compact = decide_on_compacting (condemned_gen_number, fragmentation, should_expand);
-    }
-    if (condemned_gen_number == max_generation)
-    {
-#ifdef FEATURE_LOH_COMPACTION
-        if (settings.loh_compaction)
-        {
-            should_compact = TRUE;
-            get_gc_data_per_heap()->set_mechanism (gc_heap_compact, compact_loh_forced);
-        }
-        else
-#endif //FEATURE_LOH_COMPACTION
-        {
-            GCToEEInterface::DiagWalkUOHSurvivors(__this, loh_generation);
-            sweep_uoh_objects (loh_generation);
-        }
-        GCToEEInterface::DiagWalkUOHSurvivors(__this, poh_generation);
-        sweep_uoh_objects (poh_generation);
-    }
-    else
-    {
-        settings.loh_compaction = FALSE;
-    }
-#ifdef MULTIPLE_HEAPS
-#ifndef USE_REGIONS
-    new_heap_segment = NULL;
-#endif //!USE_REGIONS
-    if (should_compact && should_expand)
-        gc_policy = policy_expand;
-    else if (should_compact)
-        gc_policy = policy_compact;
-    else
-        gc_policy = policy_sweep;
-    dprintf (3, ("Joining for compaction decision"));
-    gc_t_join.join(this, gc_join_decide_on_compaction);
-    if (gc_t_join.joined())
-    {
-#ifndef USE_REGIONS
-        if (condemned_gen_number == max_generation)
-        {
-            for (int i = 0; i < n_heaps; i++)
-            {
-                g_heaps [i]->rearrange_uoh_segments ();
-            }
-        }
-#endif //!USE_REGIONS
-        if (maxgen_size_inc_p && provisional_mode_triggered
-#ifdef BACKGROUND_GC
-            && !is_bgc_in_progress()
-#endif //BACKGROUND_GC
-            )
-        {
-            pm_trigger_full_gc = true;
-            dprintf (GTC_LOG, ("in PM: maxgen size inc, doing a sweeping gen1 and trigger NGC2"));
-        }
-        else
-        {
-#ifdef USE_REGIONS
-            bool joined_special_sweep_p = false;
-#else
-            settings.demotion = FALSE;
-#endif //USE_REGIONS
-            int pol_max = policy_sweep;
-#ifdef GC_CONFIG_DRIVEN
-            BOOL is_compaction_mandatory = FALSE;
-#endif //GC_CONFIG_DRIVEN
-            int i;
-            for (i = 0; i < n_heaps; i++)
-            {
-                if (pol_max < g_heaps[i]->gc_policy)
-                    pol_max = policy_compact;
-#ifdef USE_REGIONS
-                joined_special_sweep_p |= g_heaps[i]->special_sweep_p;
-#else
-                if (g_heaps[i]->demotion_high >= g_heaps[i]->demotion_low)
-                {
-                    (g_heaps[i]->get_gc_data_per_heap())->set_mechanism_bit (gc_demotion_bit);
-                    settings.demotion = TRUE;
-                }
-#endif //USE_REGIONS
-#ifdef GC_CONFIG_DRIVEN
-                if (!is_compaction_mandatory)
-                {
-                    int compact_reason = (g_heaps[i]->get_gc_data_per_heap())->get_mechanism (gc_heap_compact);
-                    if (compact_reason >= 0)
-                    {
-                        if (gc_heap_compact_reason_mandatory_p[compact_reason])
-                            is_compaction_mandatory = TRUE;
-                    }
-                }
-#endif //GC_CONFIG_DRIVEN
-            }
-#ifdef GC_CONFIG_DRIVEN
-            if (!is_compaction_mandatory)
-            {
-                if (should_do_sweeping_gc (pol_max >= policy_compact))
-                {
-                    pol_max = policy_sweep;
-                }
-                else
-                {
-                    if (pol_max == policy_sweep)
-                        pol_max = policy_compact;
-                }
-            }
-#endif //GC_CONFIG_DRIVEN
-            for (i = 0; i < n_heaps; i++)
-            {
-#ifdef USE_REGIONS
-                g_heaps[i]->special_sweep_p = joined_special_sweep_p;
-                if (joined_special_sweep_p)
-                {
-                    g_heaps[i]->gc_policy = policy_sweep;
-                }
-                else
-#endif //USE_REGIONS
-                if (pol_max > g_heaps[i]->gc_policy)
-                    g_heaps[i]->gc_policy = pol_max;
-#ifndef USE_REGIONS
-                if (g_heaps[i]->gc_policy == policy_expand)
-                {
-                    g_heaps[i]->new_heap_segment =
-                        g_heaps[i]->soh_get_segment_to_expand();
-                    if (!g_heaps[i]->new_heap_segment)
-                    {
-                        set_expand_in_full_gc (condemned_gen_number);
-                        g_heaps[i]->gc_policy = policy_compact;
-                    }
-                }
-#endif //!USE_REGIONS
-            }
-            BOOL is_full_compacting_gc = FALSE;
-            if ((gc_policy >= policy_compact) && (condemned_gen_number == max_generation))
-            {
-                full_gc_counts[gc_type_compacting]++;
-                is_full_compacting_gc = TRUE;
-            }
-            for (i = 0; i < n_heaps; i++)
-            {
-#ifndef USE_REGIONS
-                if (g_gc_card_table!= g_heaps[i]->card_table)
-                {
-                    g_heaps[i]->copy_brick_card_table();
-                }
-#endif //!USE_REGIONS
-                if (is_full_compacting_gc)
-                {
-                    g_heaps[i]->loh_alloc_since_cg = 0;
-                }
-            }
-        }
-#ifdef FEATURE_EVENT_TRACE
-        if (informational_event_enabled_p)
-        {
-            gc_time_info[time_sweep] = GetHighPrecisionTimeStamp();
-            gc_time_info[time_plan] = gc_time_info[time_sweep] - gc_time_info[time_plan];
-        }
-#endif //FEATURE_EVENT_TRACE
-        dprintf(3, ("Starting all gc threads after compaction decision"));
-        gc_t_join.restart();
-    }
-    should_compact = (gc_policy >= policy_compact);
-    should_expand  = (gc_policy >= policy_expand);
-#else //MULTIPLE_HEAPS
-#ifndef USE_REGIONS
-    if (condemned_gen_number == max_generation)
-    {
-        rearrange_uoh_segments ();
-    }
-#endif //!USE_REGIONS
-    if (maxgen_size_inc_p && provisional_mode_triggered
-#ifdef BACKGROUND_GC
-        && !is_bgc_in_progress()
-#endif //BACKGROUND_GC
-        )
-    {
-        pm_trigger_full_gc = true;
-        dprintf (GTC_LOG, ("in PM: maxgen size inc, doing a sweeping gen1 and trigger NGC2"));
-    }
-    else
-    {
-#ifndef USE_REGIONS
-        settings.demotion = ((demotion_high >= demotion_low) ? TRUE : FALSE);
-        if (settings.demotion)
-            get_gc_data_per_heap()->set_mechanism_bit (gc_demotion_bit);
-#endif //!USE_REGIONS
-#ifdef GC_CONFIG_DRIVEN
-        BOOL is_compaction_mandatory = FALSE;
-        int compact_reason = get_gc_data_per_heap()->get_mechanism (gc_heap_compact);
-        if (compact_reason >= 0)
-            is_compaction_mandatory = gc_heap_compact_reason_mandatory_p[compact_reason];
-        if (!is_compaction_mandatory)
-        {
-            if (should_do_sweeping_gc (should_compact))
-                should_compact = FALSE;
-            else
-                should_compact = TRUE;
-        }
-#endif //GC_CONFIG_DRIVEN
-        if (should_compact && (condemned_gen_number == max_generation))
-        {
-            full_gc_counts[gc_type_compacting]++;
-            loh_alloc_since_cg = 0;
-        }
-    }
-#ifdef FEATURE_EVENT_TRACE
-    if (informational_event_enabled_p)
-    {
-        gc_time_info[time_sweep] = GetHighPrecisionTimeStamp();
-        gc_time_info[time_plan] = gc_time_info[time_sweep] - gc_time_info[time_plan];
-    }
-#endif //FEATURE_EVENT_TRACE
-#ifdef USE_REGIONS
-    if (special_sweep_p)
-    {
-        should_compact = FALSE;
-    }
-#endif //!USE_REGIONS
-#endif //MULTIPLE_HEAPS
-#ifdef FEATURE_LOH_COMPACTION
-    loh_compacted_p = FALSE;
-#endif //FEATURE_LOH_COMPACTION
-    if (condemned_gen_number == max_generation)
-    {
-#ifdef FEATURE_LOH_COMPACTION
-        if (settings.loh_compaction)
-        {
-            if (should_compact && plan_loh())
-            {
-                loh_compacted_p = TRUE;
-            }
-            else
-            {
-                GCToEEInterface::DiagWalkUOHSurvivors(__this, loh_generation);
-                sweep_uoh_objects (loh_generation);
-            }
-        }
-        else
-        {
-            if (loh_pinned_queue)
-            {
-                loh_pinned_queue_decay--;
-                if (!loh_pinned_queue_decay)
-                {
-                    delete[] loh_pinned_queue;
-                    loh_pinned_queue = 0;
-                }
-            }
-        }
-#endif //FEATURE_LOH_COMPACTION
-    }
-    if (!pm_trigger_full_gc && pm_stress_on && provisional_mode_triggered)
-    {
-        if ((settings.condemned_generation == (max_generation - 1)) &&
-            ((settings.gc_index % 5) == 0)
-#ifdef BACKGROUND_GC
-            && !is_bgc_in_progress()
-#endif //BACKGROUND_GC
-            )
-        {
-            pm_trigger_full_gc = true;
-        }
-    }
-    if (settings.condemned_generation == (max_generation - 1))
-    {
-        if (provisional_mode_triggered)
-        {
-            if (should_expand)
-            {
-                should_expand = FALSE;
-                dprintf (GTC_LOG, ("h%d in PM cannot expand", heap_number));
-            }
-        }
-        if (pm_trigger_full_gc)
-        {
-            should_compact = FALSE;
-            dprintf (GTC_LOG, ("h%d PM doing sweeping", heap_number));
-        }
-    }
-    if (should_compact)
-    {
-        dprintf (2,( "**** Doing Compacting GC ****"));
-#if defined(USE_REGIONS) && defined(BACKGROUND_GC)
-        if (should_update_end_mark_size())
-        {
-            background_soh_size_end_mark += generation_end_seg_allocated (older_gen) -
-                                            r_older_gen_end_seg_allocated;
-        }
-#endif //USE_REGIONS && BACKGROUND_GC
-#ifndef USE_REGIONS
-        if (should_expand)
-        {
-#ifndef MULTIPLE_HEAPS
-            heap_segment* new_heap_segment = soh_get_segment_to_expand();
-#endif //!MULTIPLE_HEAPS
-            if (new_heap_segment)
-            {
-                consing_gen = expand_heap(condemned_gen_number,
-                                          consing_gen,
-                                          new_heap_segment);
-            }
-            if (ephemeral_heap_segment != new_heap_segment)
-            {
-                set_expand_in_full_gc (condemned_gen_number);
-                should_expand = FALSE;
-            }
-        }
-#endif //!USE_REGIONS
-        generation_allocation_limit (condemned_gen1) =
-            generation_allocation_pointer (condemned_gen1);
-        if ((condemned_gen_number < max_generation))
-        {
-            generation_allocator (older_gen)->commit_alloc_list_changes();
-            fix_older_allocation_area (older_gen);
-#ifdef FEATURE_EVENT_TRACE
-            if (record_fl_info_p)
-            {
-                uint16_t non_zero_buckets = 0;
-                for (uint16_t bucket_index = 0; bucket_index < NUM_GEN2_ALIST; bucket_index++)
-                {
-                    if (bucket_info[bucket_index].count != 0)
-                    {
-                        if (bucket_index != non_zero_buckets)
-                        {
-                            bucket_info[non_zero_buckets].set (bucket_index,
-                                                            bucket_info[bucket_index].count,
-                                                            bucket_info[bucket_index].size);
-                        }
-                        else
-                        {
-                            bucket_info[bucket_index].index = bucket_index;
-                        }
-                        non_zero_buckets++;
-                    }
-                }
-                if (non_zero_buckets)
-                {
-                    FIRE_EVENT(GCFitBucketInfo,
-                            (uint16_t)etw_bucket_kind::plugs_in_condemned,
-                            recorded_fl_info_size,
-                            non_zero_buckets,
-                            (uint32_t)(sizeof (etw_bucket_info)),
-                            (void *)bucket_info);
-                    init_bucket_info();
-                }
-                size_t max_size_to_count = generation_free_list_space (older_gen) / 4;
-                non_zero_buckets =
-                    generation_allocator (older_gen)->count_largest_items (bucket_info,
-                                                                        max_size_to_count,
-                                                                        max_etw_item_count,
-                                                                        &recorded_fl_info_size);
-                if (non_zero_buckets)
-                {
-                    FIRE_EVENT(GCFitBucketInfo,
-                            (uint16_t)etw_bucket_kind::largest_fl_items,
-                            recorded_fl_info_size,
-                            non_zero_buckets,
-                            (uint32_t)(sizeof (etw_bucket_info)),
-                            (void *)bucket_info);
-                }
-            }
-#endif //FEATURE_EVENT_TRACE
-        }
-#ifndef USE_REGIONS
-        assert (generation_allocation_segment (consing_gen) ==
-                ephemeral_heap_segment);
-#endif //!USE_REGIONS
-        GCToEEInterface::DiagWalkSurvivors(__this, true);
-        relocate_phase (condemned_gen_number, first_condemned_address);
-        compact_phase (condemned_gen_number, first_condemned_address,
-                       (!settings.demotion && settings.promotion));
-        fix_generation_bounds (condemned_gen_number, consing_gen);
-        assert (generation_allocation_limit (youngest_generation) ==
-                generation_allocation_pointer (youngest_generation));
-#ifndef USE_REGIONS
-        if (condemned_gen_number >= (max_generation -1))
-        {
-#ifdef MULTIPLE_HEAPS
-            gc_t_join.join(this, gc_join_rearrange_segs_compaction);
-            if (gc_t_join.joined())
-#endif //MULTIPLE_HEAPS
-            {
-#ifdef MULTIPLE_HEAPS
-                for (int i = 0; i < n_heaps; i++)
-                {
-                    g_heaps [i]->rearrange_heap_segments (TRUE);
-                }
-#else //MULTIPLE_HEAPS
-                rearrange_heap_segments (TRUE);
-#endif //MULTIPLE_HEAPS
-#ifdef MULTIPLE_HEAPS
-                gc_t_join.restart();
-#endif //MULTIPLE_HEAPS
-            }
-            if (should_expand)
-            {
-                for (int i = 0; i < max_generation; i++)
-                {
-                    generation* gen = generation_of (i);
-                    generation_start_segment (gen) = ephemeral_heap_segment;
-                    generation_allocation_segment (gen) = ephemeral_heap_segment;
-                }
-            }
-        }
-#endif //!USE_REGIONS
-        {
-#ifdef USE_REGIONS
-            end_gen0_region_committed_space = get_gen0_end_space (memory_type_committed);
-            dprintf(REGIONS_LOG, ("h%d computed the end_gen0_region_committed_space value to be %zd", heap_number, end_gen0_region_committed_space));
-#endif //USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-            dprintf(3, ("Joining after end of compaction"));
-            gc_t_join.join(this, gc_join_adjust_handle_age_compact);
-            if (gc_t_join.joined())
-            {
-#endif //MULTIPLE_HEAPS
-#ifdef FEATURE_EVENT_TRACE
-                if (informational_event_enabled_p)
-                {
-                    uint64_t current_time = GetHighPrecisionTimeStamp();
-                    gc_time_info[time_compact] = current_time - gc_time_info[time_compact];
-                }
-#endif //FEATURE_EVENT_TRACE
-#ifdef _DEBUG
-                verify_committed_bytes ();
-#endif // _DEBUG
-#ifdef MULTIPLE_HEAPS
-                dprintf(3, ("Restarting after Promotion granted"));
-                gc_t_join.restart();
-            }
-#endif //MULTIPLE_HEAPS
-#ifdef FEATURE_PREMORTEM_FINALIZATION
-            finalize_queue->UpdatePromotedGenerations (condemned_gen_number,
-                                                       (!settings.demotion && settings.promotion));
-#endif // FEATURE_PREMORTEM_FINALIZATION
-            ScanContext sc;
-            sc.thread_number = heap_number;
-            sc.thread_count = n_heaps;
-            sc.promotion = FALSE;
-            sc.concurrent = FALSE;
-            if (settings.promotion && !settings.demotion)
-            {
-                dprintf (2, ("Promoting EE roots for gen %d",
-                             condemned_gen_number));
-                GCScan::GcPromotionsGranted(condemned_gen_number, max_generation, &sc);
-            }
-            else if (settings.demotion)
-            {
-                dprintf (2, ("Demoting EE roots for gen %d",
-                             condemned_gen_number));
-                GCScan::GcDemote (condemned_gen_number, max_generation, &sc);
-            }
-        }
-        {
-            reset_pinned_queue_bos();
-#ifndef USE_REGIONS
-            unsigned int  gen_number = (unsigned int)min ((int)max_generation, 1 + condemned_gen_number);
-            generation*  gen = generation_of (gen_number);
-            uint8_t*  low = generation_allocation_start (generation_of (gen_number-1));
-            uint8_t*  high =  heap_segment_allocated (ephemeral_heap_segment);
-#endif //!USE_REGIONS
-            while (!pinned_plug_que_empty_p())
-            {
-                mark*  m = pinned_plug_of (deque_pinned_plug());
-                size_t len = pinned_len (m);
-                uint8_t*  arr = (pinned_plug (m) - len);
-                dprintf(3,("free [%zx %zx[ pin",
-                            (size_t)arr, (size_t)arr + len));
-                if (len != 0)
-                {
-                    assert (len >= Align (min_obj_size));
-                    make_unused_array (arr, len);
-                    size_t start_brick = brick_of (arr);
-                    size_t end_brick = brick_of (arr + len);
-                    if (end_brick != start_brick)
-                    {
-                        dprintf (3,
-                                    ("Fixing bricks [%zx, %zx[ to point to unused array %zx",
-                                    start_brick, end_brick, (size_t)arr));
-                        set_brick (start_brick,
-                                    arr - brick_address (start_brick));
-                        size_t brick = start_brick+1;
-                        while (brick < end_brick)
-                        {
-                            set_brick (brick, start_brick - brick);
-                            brick++;
-                        }
-                    }
-#ifdef USE_REGIONS
-                    int gen_number = object_gennum_plan (arr);
-                    generation* gen = generation_of (gen_number);
-#else
-                    if ((heap_segment_mem (ephemeral_heap_segment) <= arr) &&
-                        (heap_segment_reserved (ephemeral_heap_segment) > arr))
-                    {
-                        while ((low <= arr) && (high > arr))
-                        {
-                            gen_number--;
-                            assert ((gen_number >= 1) || (demotion_low != MAX_PTR) ||
-                                    settings.demotion || !settings.promotion);
-                            dprintf (3, ("new free list generation %d", gen_number));
-                            gen = generation_of (gen_number);
-                            if (gen_number >= 1)
-                                low = generation_allocation_start (generation_of (gen_number-1));
-                            else
-                                low = high;
-                        }
-                    }
-                    else
-                    {
-                        dprintf (3, ("new free list generation %d", max_generation));
-                        gen_number = max_generation;
-                        gen = generation_of (gen_number);
-                    }
-#endif //USE_REGIONS
-                    dprintf(3,("h%d threading %p (%zd) before pin in gen %d",
-                        heap_number, arr, len, gen_number));
-                    thread_gap (arr, len, gen);
-                    add_gen_free (gen_number, len);
-                }
-            }
-        }
-        clear_gen1_cards();
-    }
-    else
-    {
-        settings.promotion = TRUE;
-        settings.compaction = FALSE;
-#ifdef USE_REGIONS
-        settings.demotion = FALSE;
-#endif //USE_REGIONS
-        ScanContext sc;
-        sc.thread_number = heap_number;
-        sc.thread_count = n_heaps;
-        sc.promotion = FALSE;
-        sc.concurrent = FALSE;
-        dprintf (2, ("**** Doing Mark and Sweep GC****"));
-        if ((condemned_gen_number < max_generation))
-        {
-#ifdef FREE_USAGE_STATS
-            memcpy (older_gen->gen_free_spaces, r_older_gen_free_space, sizeof (r_older_gen_free_space));
-#endif //FREE_USAGE_STATS
-            generation_allocator (older_gen)->copy_from_alloc_list (r_free_list);
-            generation_free_list_space (older_gen) = r_free_list_space;
-            generation_free_obj_space (older_gen) = r_free_obj_space;
-#ifdef DOUBLY_LINKED_FL
-            if (condemned_gen_number == (max_generation - 1))
-            {
-                dprintf (2, ("[h%d] no undo, FL %zd-%zd -> %zd, FO %zd+%zd=%zd",
-                    heap_number,
-                    generation_free_list_space (older_gen), gen2_removed_no_undo,
-                    (generation_free_list_space (older_gen) - gen2_removed_no_undo),
-                    generation_free_obj_space (older_gen), gen2_removed_no_undo,
-                    (generation_free_obj_space (older_gen) + gen2_removed_no_undo)));
-                generation_free_list_space (older_gen) -= gen2_removed_no_undo;
-                generation_free_obj_space (older_gen) += gen2_removed_no_undo;
-            }
-#endif //DOUBLY_LINKED_FL
-            generation_free_list_allocated (older_gen) = r_older_gen_free_list_allocated;
-            generation_end_seg_allocated (older_gen) = r_older_gen_end_seg_allocated;
-            generation_condemned_allocated (older_gen) = r_older_gen_condemned_allocated;
-            generation_sweep_allocated (older_gen) += dd_survived_size (dynamic_data_of (condemned_gen_number));
-            generation_allocation_limit (older_gen) = r_allocation_limit;
-            generation_allocation_pointer (older_gen) = r_allocation_pointer;
-            generation_allocation_context_start_region (older_gen) = r_allocation_start_region;
-            generation_allocation_segment (older_gen) = r_allocation_segment;
-#ifdef USE_REGIONS
-            if (older_gen->gen_num == max_generation)
-            {
-                check_seg_gen_num (r_allocation_segment);
-            }
-#endif //USE_REGIONS
-        }
-        if ((condemned_gen_number < max_generation))
-        {
-            fix_older_allocation_area (older_gen);
-        }
-        GCToEEInterface::DiagWalkSurvivors(__this, false);
-        make_free_lists (condemned_gen_number);
-        size_t total_recovered_sweep_size = recover_saved_pinned_info();
-        if (total_recovered_sweep_size > 0)
-        {
-            generation_free_obj_space (generation_of (max_generation)) -= total_recovered_sweep_size;
-            dprintf (2, ("h%d: deduct %zd for pin, fo->%zd",
-                heap_number, total_recovered_sweep_size,
-                generation_free_obj_space (generation_of (max_generation))));
-        }
-#ifdef USE_REGIONS
-        end_gen0_region_committed_space = get_gen0_end_space (memory_type_committed);
-        dprintf(REGIONS_LOG, ("h%d computed the end_gen0_region_committed_space value to be %zd", heap_number, end_gen0_region_committed_space));
-#endif //USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-        dprintf(3, ("Joining after end of sweep"));
-        gc_t_join.join(this, gc_join_adjust_handle_age_sweep);
-        if (gc_t_join.joined())
-#endif //MULTIPLE_HEAPS
-        {
-#ifdef FEATURE_EVENT_TRACE
-            if (informational_event_enabled_p)
-            {
-                uint64_t current_time = GetHighPrecisionTimeStamp();
-                gc_time_info[time_sweep] = current_time - gc_time_info[time_sweep];
-            }
-#endif //FEATURE_EVENT_TRACE
-#ifdef USE_REGIONS
-            if (!special_sweep_p)
-#endif //USE_REGIONS
-            {
-                GCScan::GcPromotionsGranted(condemned_gen_number,
-                                                max_generation, &sc);
-            }
-#ifndef USE_REGIONS
-            if (condemned_gen_number >= (max_generation -1))
-            {
-#ifdef MULTIPLE_HEAPS
-                for (int i = 0; i < n_heaps; i++)
-                {
-                    g_heaps[i]->rearrange_heap_segments(FALSE);
-                }
-#else
-                rearrange_heap_segments(FALSE);
-#endif //MULTIPLE_HEAPS
-            }
-#endif //!USE_REGIONS
-#ifdef USE_REGIONS
-            verify_region_to_generation_map ();
-#endif //USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-            dprintf(3, ("Restarting after Promotion granted"));
-            gc_t_join.restart();
-#endif //MULTIPLE_HEAPS
-        }
-#ifdef FEATURE_PREMORTEM_FINALIZATION
-#ifdef USE_REGIONS
-        if (!special_sweep_p)
-#endif //USE_REGIONS
-        {
-            finalize_queue->UpdatePromotedGenerations (condemned_gen_number, TRUE);
-        }
-#endif // FEATURE_PREMORTEM_FINALIZATION
-#ifdef USE_REGIONS
-        if (!special_sweep_p)
-#endif //USE_REGIONS
-        {
-            clear_gen1_cards();
-        }
-    }
-}
-#ifdef _PREFAST_
-#pragma warning(pop)
-#endif //_PREFAST_
-/*****************************
-Called after compact phase to fix all generation gaps
-********************************/
-void gc_heap::fix_generation_bounds (int condemned_gen_number,
-                                     generation* consing_gen)
-{
-#ifndef _DEBUG
-    UNREFERENCED_PARAMETER(consing_gen);
-#endif //_DEBUG
-    int gen_number = condemned_gen_number;
-    dprintf (2, ("---- thread regions gen%d GC ----", gen_number));
-#ifdef USE_REGIONS
-    if (settings.promotion && (condemned_gen_number < max_generation))
-    {
-        int older_gen_number = condemned_gen_number + 1;
-        generation* older_gen = generation_of (older_gen_number);
-        heap_segment* last_alloc_region = generation_allocation_segment (older_gen);
-        dprintf (REGIONS_LOG, ("fix till we see alloc region which is %p", heap_segment_mem (last_alloc_region)));
-        heap_segment* region = heap_segment_rw (generation_start_segment (older_gen));
-        while (region)
-        {
-            heap_segment_allocated (region) = heap_segment_plan_allocated (region);
-            if (region == last_alloc_region)
-                break;
-            region = heap_segment_next (region);
-        }
-    }
-    thread_final_regions (true);
-    ephemeral_heap_segment = generation_start_segment (generation_of (0));
-    alloc_allocated = heap_segment_allocated (ephemeral_heap_segment);
-#else //USE_REGIONS
-    assert (generation_allocation_segment (consing_gen) ==
-            ephemeral_heap_segment);
-    int bottom_gen = 0;
-    while (gen_number >= bottom_gen)
-    {
-        generation*  gen = generation_of (gen_number);
-        dprintf(3,("Fixing generation pointers for %d", gen_number));
-        if ((gen_number < max_generation) && ephemeral_promotion)
-        {
-            size_t saved_eph_start_size = saved_ephemeral_plan_start_size[gen_number];
-            make_unused_array (saved_ephemeral_plan_start[gen_number],
-                               saved_eph_start_size);
-            generation_free_obj_space (generation_of (max_generation)) += saved_eph_start_size;
-            dprintf (2, ("[h%d] EP %p(%zd)", heap_number, saved_ephemeral_plan_start[gen_number],
-                saved_ephemeral_plan_start_size[gen_number]));
-        }
-        reset_allocation_pointers (gen, generation_plan_allocation_start (gen));
-        make_unused_array (generation_allocation_start (gen), generation_plan_allocation_start_size (gen));
-        dprintf(3,(" start %zx", (size_t)generation_allocation_start (gen)));
-        gen_number--;
-    }
-#ifdef MULTIPLE_HEAPS
-    if (ephemeral_promotion)
-    {
-        ptrdiff_t delta = 0;
-        heap_segment* old_ephemeral_seg = seg_mapping_table_segment_of (saved_ephemeral_plan_start[max_generation-1]);
-        assert (in_range_for_segment (saved_ephemeral_plan_start[max_generation-1], old_ephemeral_seg));
-        size_t end_card = card_of (align_on_card (heap_segment_plan_allocated (old_ephemeral_seg)));
-        size_t card = card_of (saved_ephemeral_plan_start[max_generation-1]);
-        while (card != end_card)
-        {
-            set_card (card);
-            card++;
-        }
-    }
-#endif //MULTIPLE_HEAPS
-#ifdef BACKGROUND_GC
-    if (should_update_end_mark_size())
-    {
-        background_soh_size_end_mark = generation_size (max_generation);
-    }
-#endif //BACKGROUND_GC
-#endif //!USE_REGIONS
-    {
-        alloc_allocated = heap_segment_plan_allocated(ephemeral_heap_segment);
-#ifdef _DEBUG
-        uint8_t* start = get_soh_start_object (ephemeral_heap_segment, youngest_generation);
-        if (settings.promotion && !settings.demotion)
-        {
-            assert ((start + get_soh_start_obj_len (start)) ==
-                    heap_segment_plan_allocated(ephemeral_heap_segment));
-        }
-#endif //_DEBUG
-        heap_segment_allocated(ephemeral_heap_segment)=
-            heap_segment_plan_allocated(ephemeral_heap_segment);
-    }
-}
-#ifndef USE_REGIONS
-uint8_t* gc_heap::generation_limit (int gen_number)
-{
-    if (settings.promotion)
-    {
-        if (gen_number <= 1)
-            return heap_segment_reserved (ephemeral_heap_segment);
-        else
-            return generation_allocation_start (generation_of ((gen_number - 2)));
-    }
-    else
-    {
-        if (gen_number <= 0)
-            return heap_segment_reserved (ephemeral_heap_segment);
-        else
-            return generation_allocation_start (generation_of ((gen_number - 1)));
-    }
-}
-#endif //!USE_REGIONS
-BOOL gc_heap::ensure_gap_allocation (int condemned_gen_number)
-{
-#ifndef USE_REGIONS
-    uint8_t* start = heap_segment_allocated (ephemeral_heap_segment);
-    size_t size = Align (min_obj_size)*(condemned_gen_number+1);
-    assert ((start + size) <=
-            heap_segment_reserved (ephemeral_heap_segment));
-    if ((start + size) >
-        heap_segment_committed (ephemeral_heap_segment))
-    {
-        if (!grow_heap_segment (ephemeral_heap_segment, start + size))
-        {
-            return FALSE;
-        }
-    }
-#endif //USE_REGIONS
-    return TRUE;
-}
-uint8_t* gc_heap::allocate_at_end (size_t size)
-{
-    uint8_t* start = heap_segment_allocated (ephemeral_heap_segment);
-    size = Align (size);
-    uint8_t* result = start;
-    assert ((start + size) <=
-            heap_segment_reserved (ephemeral_heap_segment));
-    assert ((start + size) <=
-            heap_segment_committed (ephemeral_heap_segment));
-    heap_segment_allocated (ephemeral_heap_segment) += size;
-    return result;
-}
-#ifdef USE_REGIONS
-heap_segment* gc_heap::find_first_valid_region (heap_segment* region, bool compact_p, int* num_returned_regions)
-{
-    check_seg_gen_num (generation_allocation_segment (generation_of (max_generation)));
-    dprintf (REGIONS_LOG, ("  FFVR region %zx(%p), gen%d",
-        (size_t)region, (region ? heap_segment_mem (region) : 0),
-        (region ? heap_segment_gen_num (region) : 0)));
-    if (!region)
-        return 0;
-    heap_segment* current_region = region;
-    do
-    {
-        int gen_num = heap_segment_gen_num (current_region);
-        int plan_gen_num = -1;
-        if (compact_p)
-        {
-            assert (settings.compaction);
-            plan_gen_num = heap_segment_plan_gen_num (current_region);
-            dprintf (REGIONS_LOG, ("  gen%d->%d", gen_num, plan_gen_num));
-        }
-        else
-        {
-            plan_gen_num = (special_sweep_p ? gen_num : get_plan_gen_num (gen_num));
-            dprintf (REGIONS_LOG, ("  gen%d->%d, special_sweep_p %d, swept_in_plan %d",
-                gen_num, plan_gen_num, (int)special_sweep_p,
-                (int)heap_segment_swept_in_plan (current_region)));
-        }
-        uint8_t* allocated = (compact_p ?
-                              heap_segment_plan_allocated (current_region) :
-                              heap_segment_allocated (current_region));
-        if (heap_segment_mem (current_region) == allocated)
-        {
-            heap_segment* region_to_delete = current_region;
-            current_region = heap_segment_next (current_region);
-            return_free_region (region_to_delete);
-            (*num_returned_regions)++;
-            dprintf (REGIONS_LOG, ("  h%d gen%d return region %p to free, current->%p(%p)",
-                heap_number, gen_num, heap_segment_mem (region_to_delete),
-                current_region, (current_region ? heap_segment_mem (current_region) : 0)));
-            if (!current_region)
-                return 0;
-        }
-        else
-        {
-            if (compact_p)
-            {
-                dprintf (REGIONS_LOG, ("  gen%d setting region %p alloc %p to plan %p",
-                    gen_num, heap_segment_mem (current_region),
-                    heap_segment_allocated (current_region),
-                    heap_segment_plan_allocated (current_region)));
-                if (heap_segment_swept_in_plan (current_region))
-                {
-                    assert (heap_segment_allocated (current_region) ==
-                            heap_segment_plan_allocated (current_region));
-                }
-                else
-                {
-                    heap_segment_allocated (current_region) = heap_segment_plan_allocated (current_region);
-                }
-            }
-            else
-            {
-                set_region_plan_gen_num (current_region, plan_gen_num);
-            }
-            if (gen_num >= soh_gen2)
-            {
-                dprintf (REGIONS_LOG, ("  gen%d decommit end of region %p(%p)",
-                    gen_num, current_region, heap_segment_mem (current_region)));
-                decommit_heap_segment_pages (current_region, 0);
-            }
-            dprintf (REGIONS_LOG, ("  set region %p(%p) gen num to %d",
-                current_region, heap_segment_mem (current_region), plan_gen_num));
-            set_region_gen_num (current_region, plan_gen_num);
-            break;
-        }
-    } while (current_region);
-    assert (current_region);
-    if (heap_segment_swept_in_plan (current_region))
-    {
-        int gen_num = heap_segment_gen_num (current_region);
-        dprintf (REGIONS_LOG, ("threading SIP region %p surv %zd onto gen%d",
-            heap_segment_mem (current_region), heap_segment_survived (current_region), gen_num));
-        generation* gen = generation_of (gen_num);
-        generation_allocator (gen)->thread_sip_fl (current_region);
-        generation_free_list_space (gen) += heap_segment_free_list_size (current_region);
-        generation_free_obj_space (gen) += heap_segment_free_obj_size (current_region);
-    }
-    clear_region_sweep_in_plan (current_region);
-    clear_region_demoted (current_region);
-    return current_region;
-}
-void gc_heap::thread_final_regions (bool compact_p)
-{
-    int num_returned_regions = 0;
-    int num_new_regions = 0;
-    for (int i = 0; i < max_generation; i++)
-    {
-        if (reserved_free_regions_sip[i])
-        {
-            return_free_region (reserved_free_regions_sip[i]);
-        }
-    }
-    int condemned_gen_number = settings.condemned_generation;
-    generation_region_info generation_final_regions[max_generation + 1];
-    memset (generation_final_regions, 0, sizeof (generation_final_regions));
-    for (int gen_idx = max_generation; gen_idx > condemned_gen_number; gen_idx--)
-    {
-        generation* gen = generation_of (gen_idx);
-        generation_final_regions[gen_idx].head = heap_segment_rw (generation_start_segment (gen));
-        generation_final_regions[gen_idx].tail = generation_tail_region (gen);
-    }
-#ifdef BACKGROUND_GC
-    heap_segment* max_gen_tail_region = 0;
-    if (should_update_end_mark_size())
-    {
-        max_gen_tail_region = generation_final_regions[max_generation].tail;
-    }
-#endif //BACKGROUND_GC
-    for (int gen_idx = condemned_gen_number; gen_idx >= 0; gen_idx--)
-    {
-        heap_segment* current_region = heap_segment_rw (generation_start_segment (generation_of (gen_idx)));
-        dprintf (REGIONS_LOG, ("gen%d start from %p", gen_idx, heap_segment_mem (current_region)));
-        while ((current_region = find_first_valid_region (current_region, compact_p, &num_returned_regions)))
-        {
-            assert (!compact_p ||
-                    (heap_segment_plan_gen_num (current_region) == heap_segment_gen_num (current_region)));
-            int new_gen_num = heap_segment_plan_gen_num (current_region);
-            generation* new_gen = generation_of (new_gen_num);
-            heap_segment* next_region = heap_segment_next (current_region);
-            if (generation_final_regions[new_gen_num].head)
-            {
-                assert (generation_final_regions[new_gen_num].tail);
-                dprintf (REGIONS_LOG, ("gen%d exists, tail region %p next -> %p",
-                    new_gen_num, heap_segment_mem (generation_final_regions[new_gen_num].tail),
-                    heap_segment_mem (current_region)));
-                heap_segment_next (generation_final_regions[new_gen_num].tail) = current_region;
-                generation_final_regions[new_gen_num].tail = current_region;
-            }
-            else
-            {
-                generation_final_regions[new_gen_num].head = current_region;
-                generation_final_regions[new_gen_num].tail = current_region;
-            }
-            current_region = next_region;
-        }
-    }
-    for (int gen_idx = 0; gen_idx <= max_generation; gen_idx++)
-    {
-        generation* gen = generation_of (gen_idx);
-        if (generation_final_regions[gen_idx].tail)
-        {
-            heap_segment_next (generation_final_regions[gen_idx].tail) = 0;
-        }
-    }
-#ifdef BACKGROUND_GC
-    if (max_gen_tail_region)
-    {
-        max_gen_tail_region = heap_segment_next (max_gen_tail_region);
-        while (max_gen_tail_region)
-        {
-            background_soh_size_end_mark += heap_segment_allocated (max_gen_tail_region) -
-                                            heap_segment_mem (max_gen_tail_region);
-            max_gen_tail_region = heap_segment_next (max_gen_tail_region);
-        }
-    }
-#endif //BACKGROUND_GC
-    for (int gen_idx = 0; gen_idx <= max_generation; gen_idx++)
-    {
-        bool condemned_p = (gen_idx <= condemned_gen_number);
-        assert (condemned_p || generation_final_regions[gen_idx].head);
-        generation* gen = generation_of (gen_idx);
-        heap_segment* start_region = 0;
-        if (generation_final_regions[gen_idx].head)
-        {
-            if (condemned_p)
-            {
-                start_region = generation_final_regions[gen_idx].head;
-                thread_start_region (gen, start_region);
-            }
-            generation_tail_region (gen) = generation_final_regions[gen_idx].tail;
-            dprintf (REGIONS_LOG, ("setting gen%d start %p, tail %p",
-                gen_idx,
-                heap_segment_mem (heap_segment_rw (generation_start_segment (gen))),
-                heap_segment_mem (generation_tail_region (gen))));
-        }
-        else
-        {
-            start_region = get_free_region (gen_idx);
-            assert (start_region);
-            num_new_regions++;
-            thread_start_region (gen, start_region);
-            dprintf (REGIONS_LOG, ("creating new gen%d at %p", gen_idx, heap_segment_mem (start_region)));
-        }
-        if (condemned_p)
-        {
-            uint8_t* gen_start = heap_segment_mem (start_region);
-            reset_allocation_pointers (gen, gen_start);
-        }
-    }
-    int net_added_regions = num_new_regions - num_returned_regions;
-    dprintf (REGIONS_LOG, ("TFR: added %d, returned %d, net %d", num_new_regions, num_returned_regions, net_added_regions));
-    if ((settings.compaction || special_sweep_p) && (net_added_regions > 0))
-    {
-        new_regions_in_threading += net_added_regions;
-        assert (!"we shouldn't be getting new regions in TFR!");
-    }
-    verify_regions (true, false);
-}
-void gc_heap::thread_start_region (generation* gen, heap_segment* region)
-{
-    heap_segment* prev_region = generation_tail_ro_region (gen);
-    if (prev_region)
-    {
-        heap_segment_next (prev_region) = region;
-        dprintf (REGIONS_LOG,("gen%d tail ro %zx(%p) next -> %zx(%p)",
-            gen->gen_num, (size_t)prev_region, heap_segment_mem (prev_region),
-            (size_t)region, heap_segment_mem (region)));
-    }
-    else
-    {
-        generation_start_segment (gen) = region;
-        dprintf (REGIONS_LOG, ("start region of gen%d -> %zx(%p)", gen->gen_num,
-            (size_t)region, heap_segment_mem (region)));
-    }
-    dprintf (REGIONS_LOG, ("tail region of gen%d -> %zx(%p)", gen->gen_num,
-        (size_t)region, heap_segment_mem (region)));
-    generation_tail_region (gen) = region;
-}
-heap_segment* gc_heap::get_new_region (int gen_number, size_t size)
-{
-    heap_segment* new_region = get_free_region (gen_number, size);
-    if (new_region)
-    {
-        switch (gen_number)
-        {
-        default:
-            assert ((new_region->flags & (heap_segment_flags_loh | heap_segment_flags_poh)) == 0);
-            break;
-        case    loh_generation:
-            new_region->flags |= heap_segment_flags_loh;
-            break;
-        case    poh_generation:
-            new_region->flags |= heap_segment_flags_poh;
-            break;
-        }
-        generation* gen = generation_of (gen_number);
-        heap_segment_next (generation_tail_region (gen)) = new_region;
-        generation_tail_region (gen) = new_region;
-        verify_regions (gen_number, false, settings.concurrent);
-    }
-    return new_region;
-}
-heap_segment* gc_heap::allocate_new_region (gc_heap* hp, int gen_num, bool uoh_p, size_t size)
-{
-    uint8_t* start = 0;
-    uint8_t* end = 0;
-    assert (uoh_p || size == 0);
-    bool allocated_p = (uoh_p ?
-        global_region_allocator.allocate_large_region (gen_num, &start, &end, allocate_forward, size, on_used_changed) :
-        global_region_allocator.allocate_basic_region (gen_num, &start, &end, on_used_changed));
-    if (!allocated_p)
-    {
-        return 0;
-    }
-    heap_segment* res = make_heap_segment (start, (end - start), hp, gen_num);
-    dprintf (REGIONS_LOG, ("got a new region %zx %p->%p", (size_t)res, start, end));
-    if (res == nullptr)
-    {
-        global_region_allocator.delete_region (start);
-    }
-    return res;
-}
-void gc_heap::update_start_tail_regions (generation* gen,
-                                         heap_segment* region_to_delete,
-                                         heap_segment* prev_region,
-                                         heap_segment* next_region)
-{
-    if (region_to_delete == heap_segment_rw (generation_start_segment (gen)))
-    {
-        assert (!prev_region);
-        heap_segment* tail_ro_region = generation_tail_ro_region (gen);
-        if (tail_ro_region)
-        {
-            heap_segment_next (tail_ro_region) = next_region;
-            dprintf (REGIONS_LOG, ("gen%d tail ro %zx(%p) next updated to %zx(%p)",
-                gen->gen_num, (size_t)tail_ro_region, heap_segment_mem (tail_ro_region),
-                (size_t)next_region, heap_segment_mem (next_region)));
-        }
-        else
-        {
-            generation_start_segment (gen) = next_region;
-            dprintf (REGIONS_LOG, ("start region of gen%d updated to %zx(%p)", gen->gen_num,
-                (size_t)next_region, heap_segment_mem (next_region)));
-        }
-    }
-    if (region_to_delete == generation_tail_region (gen))
-    {
-        assert (!next_region);
-        generation_tail_region (gen) = prev_region;
-        dprintf (REGIONS_LOG, ("tail region of gen%d updated to %zx(%p)", gen->gen_num,
-            (size_t)prev_region, heap_segment_mem (prev_region)));
-    }
-    verify_regions (false, settings.concurrent);
-}
-inline
-bool gc_heap::should_sweep_in_plan (heap_segment* region)
-{
-    if (!enable_special_regions_p)
-    {
-        return false;
-    }
-    if (settings.reason == reason_induced_aggressive)
-    {
-        return false;
-    }
-    bool sip_p = false;
-    int gen_num = get_region_gen_num (region);
-    int new_gen_num = get_plan_gen_num (gen_num);
-    heap_segment_swept_in_plan (region) = false;
-    dprintf (REGIONS_LOG, ("checking if region %p should be SIP", heap_segment_mem (region)));
-#ifdef STRESS_REGIONS
-    if (0)
-    {
-        num_condemned_regions++;
-        if ((num_condemned_regions % sip_seg_interval) == 0)
-        {
-            set_region_plan_gen_num (region, new_gen_num);
-            sip_p = true;
-        }
-        if ((num_condemned_regions % sip_seg_maxgen_interval) == 0)
-        {
-            set_region_plan_gen_num (region, max_generation);
-            sip_maxgen_regions_per_gen[gen_num]++;
-            sip_p = true;
-        }
-    }
-    else
-#endif //STRESS_REGIONS
-    {
-        size_t basic_region_size = (size_t)1 << min_segment_size_shr;
-        assert (heap_segment_gen_num (region) == heap_segment_plan_gen_num (region));
-        uint8_t surv_ratio = (uint8_t)(((double)heap_segment_survived (region) * 100.0) / (double)basic_region_size);
-        dprintf (2222, ("SSIP: region %p surv %hu / %zd = %d%%(%d)",
-            heap_segment_mem (region),
-            heap_segment_survived (region),
-            basic_region_size,
-            surv_ratio, sip_surv_ratio_th));
-        if (surv_ratio >= sip_surv_ratio_th)
-        {
-            set_region_plan_gen_num (region, new_gen_num);
-            sip_p = true;
-        }
-        if (settings.promotion && (new_gen_num < max_generation))
-        {
-            int old_card_surv_ratio =
-                (int)(((double)heap_segment_old_card_survived (region) * 100.0) / (double)basic_region_size);
-            dprintf (2222, ("SSIP: region %p old card surv %d / %zd = %d%%(%d)",
-                heap_segment_mem (region),
-                heap_segment_old_card_survived (region),
-                basic_region_size,
-                old_card_surv_ratio, sip_surv_ratio_th));
-            if (old_card_surv_ratio >= sip_old_card_surv_ratio_th)
-            {
-                set_region_plan_gen_num (region, max_generation, true);
-                sip_maxgen_regions_per_gen[gen_num]++;
-                sip_p = true;
-            }
-        }
-    }
-    if (sip_p)
-    {
-        if ((new_gen_num < max_generation) &&
-            (sip_maxgen_regions_per_gen[gen_num] == regions_per_gen[gen_num]))
-        {
-            assert (get_region_gen_num (region) == 0);
-            assert (new_gen_num < max_generation);
-            heap_segment* reserved_free_region = get_free_region (gen_num);
-            if (reserved_free_region)
-            {
-                dprintf (REGIONS_LOG, ("all regions in gen%d -> SIP 2, get a new region for it %p",
-                    gen_num, heap_segment_mem (reserved_free_region)));
-                reserved_free_regions_sip[gen_num] = reserved_free_region;
-            }
-            else
-            {
-                sip_maxgen_regions_per_gen[gen_num]--;
-                set_region_plan_gen_num (region, new_gen_num, true);
-            }
-        }
-    }
-    dprintf (REGIONS_LOG, ("region %p %s SIP", heap_segment_mem (region),
-        (sip_p ? "is" : "is not")));
-    return sip_p;
-}
-void heap_segment::thread_free_obj (uint8_t* obj, size_t s)
-{
-    if (s >= min_free_list)
-    {
-        free_list_slot (obj) = 0;
-        if (free_list_head)
-        {
-            assert (free_list_tail);
-            free_list_slot (free_list_tail) = obj;
-        }
-        else
-        {
-            free_list_head = obj;
-        }
-        free_list_tail = obj;
-        free_list_size += s;
-    }
-    else
-    {
-        free_obj_size += s;
-    }
-}
-void gc_heap::sweep_region_in_plan (heap_segment* region,
-                                    BOOL use_mark_list,
-                                    uint8_t**& mark_list_next,
-                                    uint8_t** mark_list_index)
-{
-    set_region_sweep_in_plan (region);
-    region->init_free_list();
-    uint8_t* x = heap_segment_mem (region);
-    uint8_t* last_marked_obj_start = 0;
-    uint8_t* last_marked_obj_end = 0;
-    uint8_t* end = heap_segment_allocated (region);
-    dprintf (2222, ("h%d region %p->%p SIP, gen %d->%d, %s mark list(%p->%p, %p->%p)",
-        heap_number, x, end, heap_segment_gen_num (region), heap_segment_plan_gen_num (region),
-        (use_mark_list ? "using" : "not using"),
-        (uint8_t*)mark_list_next, (mark_list_next ? *mark_list_next : 0),
-        (uint8_t*)mark_list_index, (mark_list_index ? *mark_list_index : 0)));
-#ifdef _DEBUG
-    size_t survived = 0;
-    uint8_t* saved_last_unmarked_obj_start = 0;
-    uint8_t* saved_last_unmarked_obj_end = 0;
-    size_t saved_obj_brick = 0;
-    size_t saved_next_obj_brick = 0;
-#endif //_DEBUG
-    while (x < end)
-    {
-        uint8_t* obj = x;
-        size_t obj_brick = (size_t)obj / brick_size;
-        uint8_t* next_obj = 0;
-        if (marked (obj))
-        {
-            if (pinned(obj))
-            {
-                clear_pinned (obj);
-            }
-            clear_marked (obj);
-            size_t s = size (obj);
-            next_obj = obj + Align (s);
-            last_marked_obj_start = obj;
-            last_marked_obj_end = next_obj;
-#ifdef _DEBUG
-            survived += s;
-#endif //_DEBUG
-            dprintf (4444, ("M: %p-%p(%zd)", obj, next_obj, s));
-        }
-        else
-        {
-            next_obj = find_next_marked (x, end, use_mark_list, mark_list_next, mark_list_index);
-#ifdef _DEBUG
-            saved_last_unmarked_obj_start = obj;
-            saved_last_unmarked_obj_end = next_obj;
-#endif //_DEBUG
-            if ((next_obj > obj) && (next_obj != end))
-            {
-                size_t free_obj_size = next_obj - obj;
-                make_unused_array (obj, free_obj_size);
-                region->thread_free_obj (obj, free_obj_size);
-                dprintf (4444, ("UM threading: %p-%p(%zd)", obj, next_obj, (next_obj - obj)));
-            }
-        }
-        size_t next_obj_brick = (size_t)next_obj / brick_size;
-#ifdef _DEBUG
-        saved_obj_brick = obj_brick;
-        saved_next_obj_brick = next_obj_brick;
-#endif //_DEBUG
-        if (next_obj_brick != obj_brick)
-        {
-            fix_brick_to_highest (obj, next_obj);
-        }
-        x = next_obj;
-    }
-    if (last_marked_obj_start)
-    {
-        size_t last_marked_obj_start_b = brick_of (last_marked_obj_start);
-        size_t last_marked_obj_end_b = brick_of (last_marked_obj_end - 1);
-        dprintf (REGIONS_LOG, ("last live obj %p(%p)-%p, fixing its brick(s) %zx-%zx",
-            last_marked_obj_start, method_table (last_marked_obj_start), last_marked_obj_end,
-            last_marked_obj_start_b, last_marked_obj_end_b));
-        if (last_marked_obj_start_b == last_marked_obj_end_b)
-        {
-            set_brick (last_marked_obj_start_b,
-                    (last_marked_obj_start - brick_address (last_marked_obj_start_b)));
-        }
-        else
-        {
-            set_brick (last_marked_obj_end_b,
-                    (last_marked_obj_start_b - last_marked_obj_end_b));
-        }
-    }
-    else
-    {
-        last_marked_obj_end = heap_segment_mem (region);
-    }
-#ifdef _DEBUG
-    size_t region_index = get_basic_region_index_for_address (heap_segment_mem (region));
-    dprintf (REGIONS_LOG, ("region #%zd %p survived %zd, %s recorded %d",
-        region_index, heap_segment_mem (region), survived,
-        ((survived == heap_segment_survived (region)) ? "same as" : "diff from"),
-        heap_segment_survived (region)));
-#ifdef MULTIPLE_HEAPS
-    assert (survived <= heap_segment_survived (region));
-#else
-    assert (survived == heap_segment_survived (region));
-#endif //MULTIPLE_HEAPS
-#endif //_DEBUG
-    assert (last_marked_obj_end);
-    save_allocated(region);
-    heap_segment_allocated (region) = last_marked_obj_end;
-    heap_segment_plan_allocated (region) = heap_segment_allocated (region);
-    int plan_gen_num = heap_segment_plan_gen_num (region);
-    if (plan_gen_num < heap_segment_gen_num (region))
-    {
-        generation_allocation_size (generation_of (plan_gen_num)) += heap_segment_survived (region);
-        dprintf (REGIONS_LOG, ("sip: g%d alloc size is now %zd", plan_gen_num,
-            generation_allocation_size (generation_of (plan_gen_num))));
-    }
-}
-inline
-void gc_heap::check_demotion_helper_sip (uint8_t** pval, int parent_gen_num, uint8_t* parent_loc)
-{
-    uint8_t* child_object = *pval;
-    if (!is_in_heap_range (child_object))
-        return;
-    assert (child_object != nullptr);
-    int child_object_plan_gen = get_region_plan_gen_num (child_object);
-    if (child_object_plan_gen < parent_gen_num)
-    {
-        set_card (card_of (parent_loc));
-    }
-    dprintf (3, ("SCS %d, %d", child_object_plan_gen, parent_gen_num));
-}
-heap_segment* gc_heap::relocate_advance_to_non_sip (heap_segment* region)
-{
-    THREAD_FROM_HEAP;
-    heap_segment* current_region = region;
-    dprintf (REGIONS_LOG, ("Relocate searching for next non SIP, starting from %p",
-        (region ? heap_segment_mem (region) : 0)));
-    while (current_region)
-    {
-        if (heap_segment_swept_in_plan (current_region))
-        {
-            int gen_num = heap_segment_gen_num (current_region);
-            int plan_gen_num = heap_segment_plan_gen_num (current_region);
-            bool use_sip_demotion = (plan_gen_num > get_plan_gen_num (gen_num));
-            dprintf (REGIONS_LOG, ("region %p is SIP, relocating, gen %d, plan gen: %d(supposed to be %d) %s",
-                heap_segment_mem (current_region), gen_num, plan_gen_num, get_plan_gen_num (gen_num),
-                (use_sip_demotion ? "Sd" : "d")));
-            uint8_t* x = heap_segment_mem (current_region);
-            uint8_t* end = heap_segment_allocated (current_region);
-            while (x < end)
-            {
-                size_t s = size (x);
-                assert (s > 0);
-                uint8_t* next_obj = x + Align (s);
-                Prefetch (next_obj);
-                if (!(((CObjectHeader*)x)->IsFree()))
-                {
-                    if (contain_pointers (x))
-                    {
-                        dprintf (3, ("$%zx$", (size_t)x));
-                        go_through_object_nostart (method_table(x), x, s, pval,
-                        {
-                            uint8_t* child = *pval;
-                            relocate_address (pval THREAD_NUMBER_ARG);
-                            if (use_sip_demotion)
-                                check_demotion_helper_sip (pval, plan_gen_num, (uint8_t*)pval);
-                            else
-                                check_demotion_helper (pval, (uint8_t*)pval);
-                            if (child)
-                            {
-                                dprintf (4444, ("SIP %p(%p)->%p->%p(%p)",
-                                    x, (uint8_t*)pval, child, *pval, method_table (child)));
-                            }
-                        });
-                    }
-                    check_class_object_demotion (x);
-                }
-                x = next_obj;
-            }
-        }
-        else
-        {
-            int gen_num = heap_segment_gen_num (current_region);
-            int plan_gen_num = heap_segment_plan_gen_num (current_region);
-            dprintf (REGIONS_LOG, ("region %p is not SIP, relocating, gen %d, plan gen: %d",
-                heap_segment_mem (current_region), gen_num, plan_gen_num));
-            return current_region;
-        }
-        current_region = heap_segment_next (current_region);
-    }
-    return 0;
-}
-#ifdef STRESS_REGIONS
-void gc_heap::pin_by_gc (uint8_t* object)
-{
-    heap_segment* region = region_of (object);
-    HndAssignHandleGC(pinning_handles_for_alloc[ph_index_per_heap], object);
-    dprintf (REGIONS_LOG, ("h%d pinning object at %zx on eph seg %zx (ph#%d)",
-        heap_number, object, heap_segment_mem (region), ph_index_per_heap));
-    ph_index_per_heap++;
-    if (ph_index_per_heap == PINNING_HANDLE_INITIAL_LENGTH)
-    {
-        ph_index_per_heap = 0;
-    }
-}
-#endif //STRESS_REGIONS
-#endif //USE_REGIONS
-void gc_heap::make_free_lists (int condemned_gen_number)
-{
-    assert (settings.promotion);
-    make_free_args args = {};
-    int stop_gen_idx = get_stop_generation_index (condemned_gen_number);
-    for (int i = condemned_gen_number; i >= stop_gen_idx; i--)
-    {
-        generation* condemned_gen = generation_of (i);
-        heap_segment* current_heap_segment = get_start_segment (condemned_gen);
-#ifdef USE_REGIONS
-    if (!current_heap_segment)
-        continue;
-#endif //USE_REGIONS
-        uint8_t* start_address = get_soh_start_object (current_heap_segment, condemned_gen);
-        size_t current_brick = brick_of (start_address);
-        PREFIX_ASSUME(current_heap_segment != NULL);
-        uint8_t* end_address = heap_segment_allocated (current_heap_segment);
-        size_t  end_brick = brick_of (end_address - 1);
-        int current_gen_num = i;
-#ifdef USE_REGIONS
-        args.free_list_gen_number = (special_sweep_p ? current_gen_num : get_plan_gen_num (current_gen_num));
-#else
-        args.free_list_gen_number = get_plan_gen_num (current_gen_num);
-#endif //USE_REGIONS
-        args.free_list_gen = generation_of (args.free_list_gen_number);
-        args.highest_plug = 0;
-#ifdef USE_REGIONS
-        dprintf (REGIONS_LOG, ("starting at gen%d %p -> %p", i, start_address, end_address));
-#else
-        args.current_gen_limit = (((current_gen_num == max_generation)) ?
-                                  MAX_PTR :
-                                  (generation_limit (args.free_list_gen_number)));
-#endif //USE_REGIONS
-#ifndef USE_REGIONS
-        if ((start_address >= end_address) && (condemned_gen_number < max_generation))
-        {
-            break;
-        }
-#endif //!USE_REGIONS
-        while (1)
-        {
-            if ((current_brick > end_brick))
-            {
-#ifndef USE_REGIONS
-                if (args.current_gen_limit == MAX_PTR)
-                {
-                    generation* gen = generation_of (max_generation);
-                    heap_segment* start_seg = heap_segment_rw (generation_start_segment (gen));
-                    PREFIX_ASSUME(start_seg != NULL);
-                    uint8_t* gap = heap_segment_mem (start_seg);
-                    generation_allocation_start (gen) = gap;
-                    heap_segment_allocated (start_seg) = gap + Align (min_obj_size);
-                    make_unused_array (gap, Align (min_obj_size));
-                    reset_allocation_pointers (gen, gap);
-                    dprintf (3, ("Start segment empty, fixing generation start of %d to: %zx",
-                                max_generation, (size_t)gap));
-                    args.current_gen_limit = generation_limit (args.free_list_gen_number);
-                }
-#endif //!USE_REGIONS
-                if (heap_segment_next_non_sip (current_heap_segment))
-                {
-                    current_heap_segment = heap_segment_next_non_sip (current_heap_segment);
-                }
-                else
-                {
-                    break;
-                }
-                current_brick = brick_of (heap_segment_mem (current_heap_segment));
-                end_brick = brick_of (heap_segment_allocated (current_heap_segment)-1);
-                continue;
-            }
-            {
-                int brick_entry =  brick_table [ current_brick ];
-                if ((brick_entry >= 0))
-                {
-                    make_free_list_in_brick (brick_address (current_brick) + brick_entry-1, &args);
-                    dprintf(3,("Fixing brick entry %zx to %zx",
-                            current_brick, (size_t)args.highest_plug));
-                    set_brick (current_brick,
-                            (args.highest_plug - brick_address (current_brick)));
-                }
-                else
-                {
-                    if ((brick_entry > -32768))
-                    {
-#ifdef _DEBUG
-                        ptrdiff_t offset = brick_of (args.highest_plug) - current_brick;
-                        if ((brick_entry != -32767) && (! ((offset == brick_entry))))
-                        {
-                            assert ((brick_entry == -1));
-                        }
-#endif //_DEBUG
-                        set_brick (current_brick, -1);
-                    }
-                }
-            }
-            current_brick++;
-        }
-    }
-    {
-#ifdef USE_REGIONS
-        check_seg_gen_num (generation_allocation_segment (generation_of (max_generation)));
-        thread_final_regions (false);
-        generation* gen_gen0 = generation_of (0);
-        ephemeral_heap_segment = generation_start_segment (gen_gen0);
-        alloc_allocated = heap_segment_allocated (ephemeral_heap_segment);
-#else //USE_REGIONS
-        int bottom_gen = 0;
-        args.free_list_gen_number--;
-        while (args.free_list_gen_number >= bottom_gen)
-        {
-            uint8_t*  gap = 0;
-            generation* gen2 = generation_of (args.free_list_gen_number);
-            gap = allocate_at_end (Align(min_obj_size));
-            generation_allocation_start (gen2) = gap;
-            reset_allocation_pointers (gen2, gap);
-            dprintf(3,("Fixing generation start of %d to: %zx",
-                       args.free_list_gen_number, (size_t)gap));
-            PREFIX_ASSUME(gap != NULL);
-            make_unused_array (gap, Align (min_obj_size));
-            args.free_list_gen_number--;
-        }
-        uint8_t* start2 = generation_allocation_start (youngest_generation);
-        alloc_allocated = start2 + Align (size (start2));
-#endif //USE_REGIONS
-    }
-}
-void gc_heap::make_free_list_in_brick (uint8_t* tree, make_free_args* args)
-{
-    assert ((tree != NULL));
-    {
-        int  right_node = node_right_child (tree);
-        int left_node = node_left_child (tree);
-        args->highest_plug = 0;
-        if (! (0 == tree))
-        {
-            if (! (0 == left_node))
-            {
-                make_free_list_in_brick (tree + left_node, args);
-            }
-            {
-                uint8_t*  plug = tree;
-                size_t  gap_size = node_gap_size (tree);
-                uint8_t*  gap = (plug - gap_size);
-                args->highest_plug = tree;
-                dprintf (3,("plug: %p (highest p: %p), free %zx len %zd in %d",
-                        plug, args->highest_plug, (size_t)gap, gap_size, args->free_list_gen_number));
-#ifdef SHORT_PLUGS
-                if (is_plug_padded (plug))
-                {
-                    dprintf (3, ("%p padded", plug));
-                    clear_plug_padded (plug);
-                }
-#endif //SHORT_PLUGS
-#ifdef DOUBLY_LINKED_FL
-                if (is_plug_bgc_mark_bit_set (plug))
-                {
-                    dprintf (3333, ("cbgcm: %p", plug));
-                    clear_plug_bgc_mark_bit (plug);
-                }
-                if (is_free_obj_in_compact_bit_set (plug))
-                {
-                    dprintf (3333, ("cfoc: %p", plug));
-                    clear_free_obj_in_compact_bit (plug);
-                }
-#endif //DOUBLY_LINKED_FL
-#ifndef USE_REGIONS
-            gen_crossing:
-                {
-                    if ((args->current_gen_limit == MAX_PTR) ||
-                        ((plug >= args->current_gen_limit) &&
-                         ephemeral_pointer_p (plug)))
-                    {
-                        dprintf(3,(" Crossing Generation boundary at %zx",
-                               (size_t)args->current_gen_limit));
-                        if (!(args->current_gen_limit == MAX_PTR))
-                        {
-                            args->free_list_gen_number--;
-                            args->free_list_gen = generation_of (args->free_list_gen_number);
-                        }
-                        dprintf(3,( " Fixing generation start of %d to: %zx",
-                                args->free_list_gen_number, (size_t)gap));
-                        reset_allocation_pointers (args->free_list_gen, gap);
-                        args->current_gen_limit = generation_limit (args->free_list_gen_number);
-                        if ((gap_size >= (2*Align (min_obj_size))))
-                        {
-                            dprintf(3,(" Splitting the gap in two %zd left",
-                                   gap_size));
-                            make_unused_array (gap, Align(min_obj_size));
-                            gap_size = (gap_size - Align(min_obj_size));
-                            gap = (gap + Align(min_obj_size));
-                        }
-                        else
-                        {
-                            make_unused_array (gap, gap_size);
-                            gap_size = 0;
-                        }
-                        goto gen_crossing;
-                    }
-                }
-#endif //!USE_REGIONS
-                thread_gap (gap, gap_size, args->free_list_gen);
-                add_gen_free (args->free_list_gen->gen_num, gap_size);
-            }
-            if (! (0 == right_node))
-            {
-                make_free_list_in_brick (tree + right_node, args);
-            }
-        }
-    }
-}
-void gc_heap::thread_gap (uint8_t* gap_start, size_t size, generation*  gen)
-{
-#ifndef USE_REGIONS
-    assert (generation_allocation_start (gen));
-#endif
-    if ((size > 0))
-    {
-#ifndef USE_REGIONS
-        assert ((heap_segment_rw (generation_start_segment (gen)) != ephemeral_heap_segment) ||
-                (gap_start > generation_allocation_start (gen)));
-#endif //USE_REGIONS
-        assert (size >= Align (min_obj_size));
-        make_unused_array (gap_start, size,
-                          (!settings.concurrent && (gen != youngest_generation)),
-                          (gen->gen_num == max_generation));
-        dprintf (3, ("fr: [%zx, %zx[", (size_t)gap_start, (size_t)gap_start+size));
-        if ((size >= min_free_list))
-        {
-            generation_free_list_space (gen) += size;
-            generation_allocator (gen)->thread_item (gap_start, size);
-        }
-        else
-        {
-            generation_free_obj_space (gen) += size;
-        }
-    }
-}
-void gc_heap::uoh_thread_gap_front (uint8_t* gap_start, size_t size, generation*  gen)
-{
-#ifndef USE_REGIONS
-    assert (generation_allocation_start (gen));
-#endif
-    if (size >= min_free_list)
-    {
-        generation_free_list_space (gen) += size;
-        generation_allocator (gen)->thread_item_front (gap_start, size);
-    }
-}
-void gc_heap::make_unused_array (uint8_t* x, size_t size, BOOL clearp, BOOL resetp)
-{
-    dprintf (3, (ThreadStressLog::gcMakeUnusedArrayMsg(),
-        (size_t)x, (size_t)(x+size)));
-    assert (size >= Align (min_obj_size));
-    if (resetp)
-    {
-#ifdef BGC_SERVO_TUNING
-        if (!(bgc_tuning::enable_fl_tuning && bgc_tuning::fl_tuning_triggered))
-#endif //BGC_SERVO_TUNING
-        {
-            reset_memory (x, size);
-        }
-    }
-    ((CObjectHeader*)x)->SetFree(size);
-#ifdef HOST_64BIT
-#if BIGENDIAN
-#error "This won't work on big endian platforms"
-#endif
-    size_t size_as_object = (uint32_t)(size - free_object_base_size) + free_object_base_size;
-    if (size_as_object < size)
-    {
-        uint8_t * tmp = x + size_as_object;
-        size_t remaining_size = size - size_as_object;
-        while (remaining_size > UINT32_MAX)
-        {
-            size_t current_size = UINT32_MAX - get_alignment_constant (FALSE)
-                - Align (min_obj_size, get_alignment_constant (FALSE));
-            ((CObjectHeader*)tmp)->SetFree(current_size);
-            remaining_size -= current_size;
-            tmp += current_size;
-        }
-        ((CObjectHeader*)tmp)->SetFree(remaining_size);
-    }
-#endif
-    if (clearp)
-        clear_card_for_addresses (x, x + Align(size));
-}
-void gc_heap::clear_unused_array (uint8_t* x, size_t size)
-{
-    *(((PTR_PTR)x)-1) = 0;
-    ((CObjectHeader*)x)->UnsetFree();
-#ifdef HOST_64BIT
-#if BIGENDIAN
-#error "This won't work on big endian platforms"
-#endif
-    size_t size_as_object = (uint32_t)(size - free_object_base_size) + free_object_base_size;
-    if (size_as_object < size)
-    {
-        uint8_t * tmp = x + size_as_object;
-        size_t remaining_size = size - size_as_object;
-        while (remaining_size > UINT32_MAX)
-        {
-            size_t current_size = UINT32_MAX - get_alignment_constant (FALSE)
-                - Align (min_obj_size, get_alignment_constant (FALSE));
-            ((CObjectHeader*)tmp)->UnsetFree();
-            remaining_size -= current_size;
-            tmp += current_size;
-        }
-        ((CObjectHeader*)tmp)->UnsetFree();
-    }
-#else
-    UNREFERENCED_PARAMETER(size);
-#endif
-}
-inline
-uint8_t* tree_search (uint8_t* tree, uint8_t* old_address)
-{
-    uint8_t* candidate = 0;
-    int cn;
-    while (1)
-    {
-        if (tree < old_address)
-        {
-            if ((cn = node_right_child (tree)) != 0)
-            {
-                assert (candidate < tree);
-                candidate = tree;
-                tree = tree + cn;
-                Prefetch (&((plug_and_pair*)tree)[-1].m_pair.left);
-                continue;
-            }
-            else
-                break;
-        }
-        else if (tree > old_address)
-        {
-            if ((cn = node_left_child (tree)) != 0)
-            {
-                tree = tree + cn;
-                Prefetch (&((plug_and_pair*)tree)[-1].m_pair.left);
-                continue;
-            }
-            else
-                break;
-        } else
-            break;
-    }
-    if (tree <= old_address)
-        return tree;
-    else if (candidate)
-        return candidate;
-    else
-        return tree;
-}
-void gc_heap::relocate_address (uint8_t** pold_address THREAD_NUMBER_DCL)
-{
-    uint8_t* old_address = *pold_address;
-#ifdef USE_REGIONS
-    if (!is_in_gc_range (old_address) || !should_check_brick_for_reloc (old_address))
-    {
-        return;
-    }
-#else //USE_REGIONS
-    if (!((old_address >= gc_low) && (old_address < gc_high)))
-#ifdef MULTIPLE_HEAPS
-    {
-        UNREFERENCED_PARAMETER(thread);
-        if (old_address == 0)
-            return;
-        gc_heap* hp = heap_of (old_address);
-        if ((hp == this) ||
-            !((old_address >= hp->gc_low) && (old_address < hp->gc_high)))
-            return;
-    }
-#else //MULTIPLE_HEAPS
-        return ;
-#endif //MULTIPLE_HEAPS
-#endif //USE_REGIONS
-    size_t  brick = brick_of (old_address);
-    int    brick_entry =  brick_table [ brick ];
-    uint8_t*  new_address = old_address;
-    if (! ((brick_entry == 0)))
-    {
-    retry:
-        {
-            while (brick_entry < 0)
-            {
-                brick = (brick + brick_entry);
-                brick_entry =  brick_table [ brick ];
-            }
-            uint8_t* old_loc = old_address;
-            uint8_t* node = tree_search ((brick_address (brick) + brick_entry-1),
-                                      old_loc);
-            if ((node <= old_loc))
-                new_address = (old_address + node_relocation_distance (node));
-            else
-            {
-                if (node_left_p (node))
-                {
-                    dprintf(3,(" L: %zx", (size_t)node));
-                    new_address = (old_address +
-                                   (node_relocation_distance (node) +
-                                    node_gap_size (node)));
-                }
-                else
-                {
-                    brick = brick - 1;
-                    brick_entry =  brick_table [ brick ];
-                    goto retry;
-                }
-            }
-        }
-        dprintf (4, (ThreadStressLog::gcRelocateReferenceMsg(), pold_address, old_address, new_address));
-        *pold_address = new_address;
-        return;
-    }
-#ifdef FEATURE_LOH_COMPACTION
-    if (settings.loh_compaction)
-    {
-        heap_segment* pSegment = seg_mapping_table_segment_of ((uint8_t*)old_address);
-#ifdef USE_REGIONS
-        if (!pSegment)
-        {
-            return;
-        }
-#endif //USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-        if (heap_segment_heap (pSegment)->loh_compacted_p)
-#else
-        if (loh_compacted_p)
-#endif
-        {
-            size_t flags = pSegment->flags;
-            if ((flags & heap_segment_flags_loh)
-#ifdef FEATURE_BASICFREEZE
-                && !(flags & heap_segment_flags_readonly)
-#endif
-                )
-            {
-                new_address = old_address + loh_node_relocation_distance (old_address);
-                dprintf (4, (ThreadStressLog::gcRelocateReferenceMsg(), pold_address, old_address, new_address));
-                *pold_address = new_address;
-            }
-        }
-    }
-#endif //FEATURE_LOH_COMPACTION
-}
-inline void
-gc_heap::check_class_object_demotion (uint8_t* obj)
-{
-#ifdef COLLECTIBLE_CLASS
-    if (is_collectible(obj))
-    {
-        check_class_object_demotion_internal (obj);
-    }
-#else
-    UNREFERENCED_PARAMETER(obj);
-#endif //COLLECTIBLE_CLASS
-}
-#ifdef COLLECTIBLE_CLASS
-NOINLINE void
-gc_heap::check_class_object_demotion_internal (uint8_t* obj)
-{
-    if (settings.demotion)
-    {
-#ifdef MULTIPLE_HEAPS
-        set_card (card_of (obj));
-#else
-        THREAD_FROM_HEAP;
-        uint8_t* class_obj = get_class_object (obj);
-        dprintf (3, ("%p: got classobj %p", obj, class_obj));
-        uint8_t* temp_class_obj = class_obj;
-        uint8_t** temp = &temp_class_obj;
-        relocate_address (temp THREAD_NUMBER_ARG);
-        check_demotion_helper (temp, obj);
-#endif //MULTIPLE_HEAPS
-    }
-}
-#endif //COLLECTIBLE_CLASS
-inline void
-gc_heap::check_demotion_helper (uint8_t** pval, uint8_t* parent_obj)
-{
-#ifdef USE_REGIONS
-    uint8_t* child_object = *pval;
-    if (!is_in_heap_range (child_object))
-        return;
-    int child_object_plan_gen = get_region_plan_gen_num (child_object);
-    bool child_obj_demoted_p = is_region_demoted (child_object);
-    if (child_obj_demoted_p)
-    {
-        set_card (card_of (parent_obj));
-    }
-    dprintf (3, ("SC %d (%s)", child_object_plan_gen, (child_obj_demoted_p ? "D" : "ND")));
-#else //USE_REGIONS
-    if ((*pval < demotion_high) &&
-        (*pval >= demotion_low))
-    {
-        dprintf(3, ("setting card %zx:%zx",
-                    card_of((uint8_t*)pval),
-                    (size_t)pval));
-        set_card (card_of (parent_obj));
-    }
-#ifdef MULTIPLE_HEAPS
-    else if (settings.demotion)
-    {
-        dprintf (4, ("Demotion active, computing heap_of object"));
-        gc_heap* hp = heap_of (*pval);
-        if ((*pval < hp->demotion_high) &&
-            (*pval >= hp->demotion_low))
-        {
-            dprintf(3, ("setting card %zx:%zx",
-                        card_of((uint8_t*)pval),
-                        (size_t)pval));
-            set_card (card_of (parent_obj));
-        }
-    }
-#endif //MULTIPLE_HEAPS
-#endif //USE_REGIONS
-}
-inline void
-gc_heap::reloc_survivor_helper (uint8_t** pval)
-{
-    THREAD_FROM_HEAP;
-    relocate_address (pval THREAD_NUMBER_ARG);
-    check_demotion_helper (pval, (uint8_t*)pval);
-}
-inline void
-gc_heap::relocate_obj_helper (uint8_t* x, size_t s)
-{
-    THREAD_FROM_HEAP;
-    if (contain_pointers (x))
-    {
-        dprintf (3, ("o$%zx$", (size_t)x));
-        go_through_object_nostart (method_table(x), x, s, pval,
-                            {
-                                uint8_t* child = *pval;
-                                reloc_survivor_helper (pval);
-                                if (child)
-                                {
-                                    dprintf (3, ("%p->%p->%p", (uint8_t*)pval, child, *pval));
-                                }
-                            });
-    }
-    check_class_object_demotion (x);
-}
-inline
-void gc_heap::reloc_ref_in_shortened_obj (uint8_t** address_to_set_card, uint8_t** address_to_reloc)
-{
-    THREAD_FROM_HEAP;
-    uint8_t* old_val = (address_to_reloc ? *address_to_reloc : 0);
-    relocate_address (address_to_reloc THREAD_NUMBER_ARG);
-    if (address_to_reloc)
-    {
-        dprintf (3, ("SR %p: %p->%p", (uint8_t*)address_to_reloc, old_val, *address_to_reloc));
-    }
-    check_demotion_helper (address_to_reloc, (uint8_t*)address_to_set_card);
-}
-void gc_heap::relocate_pre_plug_info (mark* pinned_plug_entry)
-{
-    THREAD_FROM_HEAP;
-    uint8_t* plug = pinned_plug (pinned_plug_entry);
-    uint8_t* pre_plug_start = plug - sizeof (plug_and_gap);
-    pre_plug_start += sizeof (uint8_t*);
-    uint8_t** old_address = &pre_plug_start;
-    uint8_t* old_val = (old_address ? *old_address : 0);
-    relocate_address (old_address THREAD_NUMBER_ARG);
-    if (old_address)
-    {
-        dprintf (3, ("PreR %p: %p->%p, set reloc: %p",
-            (uint8_t*)old_address, old_val, *old_address, (pre_plug_start - sizeof (uint8_t*))));
-    }
-    pinned_plug_entry->set_pre_plug_info_reloc_start (pre_plug_start - sizeof (uint8_t*));
-}
-inline
-void gc_heap::relocate_shortened_obj_helper (uint8_t* x, size_t s, uint8_t* end, mark* pinned_plug_entry, BOOL is_pinned)
-{
-    THREAD_FROM_HEAP;
-    uint8_t* plug = pinned_plug (pinned_plug_entry);
-    if (!is_pinned)
-    {
-        relocate_pre_plug_info (pinned_plug_entry);
-    }
-    verify_pins_with_post_plug_info("after relocate_pre_plug_info");
-    uint8_t* saved_plug_info_start = 0;
-    uint8_t** saved_info_to_relocate = 0;
-    if (is_pinned)
-    {
-        saved_plug_info_start = (uint8_t*)(pinned_plug_entry->get_post_plug_info_start());
-        saved_info_to_relocate = (uint8_t**)(pinned_plug_entry->get_post_plug_reloc_info());
-    }
-    else
-    {
-        saved_plug_info_start = (plug - sizeof (plug_and_gap));
-        saved_info_to_relocate = (uint8_t**)(pinned_plug_entry->get_pre_plug_reloc_info());
-    }
-    uint8_t** current_saved_info_to_relocate = 0;
-    uint8_t* child = 0;
-    dprintf (3, ("x: %p, pp: %p, end: %p", x, plug, end));
-    if (contain_pointers (x))
-    {
-        dprintf (3,("s$%zx$", (size_t)x));
-        go_through_object_nostart (method_table(x), x, s, pval,
-        {
-            dprintf (3, ("obj %p, member: %p->%p", x, (uint8_t*)pval, *pval));
-            if ((uint8_t*)pval >= end)
-            {
-                current_saved_info_to_relocate = saved_info_to_relocate + ((uint8_t*)pval - saved_plug_info_start) / sizeof (uint8_t**);
-                child = *current_saved_info_to_relocate;
-                reloc_ref_in_shortened_obj (pval, current_saved_info_to_relocate);
-                dprintf (3, ("last part: R-%p(saved: %p)->%p ->%p",
-                    (uint8_t*)pval, current_saved_info_to_relocate, child, *current_saved_info_to_relocate));
-            }
-            else
-            {
-                reloc_survivor_helper (pval);
-            }
-        });
-    }
-    check_class_object_demotion (x);
-}
-void gc_heap::relocate_survivor_helper (uint8_t* plug, uint8_t* plug_end)
-{
-    uint8_t*  x = plug;
-    while (x < plug_end)
-    {
-        size_t s = size (x);
-        uint8_t* next_obj = x + Align (s);
-        Prefetch (next_obj);
-        relocate_obj_helper (x, s);
-        assert (s > 0);
-        x = next_obj;
-    }
-}
-void gc_heap::verify_pins_with_post_plug_info (const char* msg)
-{
-#if defined (_DEBUG) && defined (VERIFY_HEAP)
-    if (GCConfig::GetHeapVerifyLevel() & GCConfig::HEAPVERIFY_GC)
-    {
-        if (!verify_pinned_queue_p)
-            return;
-        if (settings.heap_expansion)
-            return;
-        for (size_t i = 0; i < mark_stack_tos; i++)
-        {
-            mark& m = mark_stack_array[i];
-            mark* pinned_plug_entry = pinned_plug_of(i);
-            if (pinned_plug_entry->has_post_plug_info() &&
-                pinned_plug_entry->post_short_p() &&
-                (pinned_plug_entry->saved_post_plug_debug.gap != 1))
-            {
-                uint8_t* next_obj = pinned_plug_entry->get_post_plug_info_start() + sizeof (plug_and_gap);
-                dprintf (3, ("OFP: %p, G: %zx, R: %zx, LC: %d, RC: %d",
-                    next_obj, node_gap_size (next_obj), node_relocation_distance (next_obj),
-                    (int)node_left_child (next_obj), (int)node_right_child (next_obj)));
-                size_t* post_plug_debug = (size_t*)(&m.saved_post_plug_debug);
-                if (node_gap_size (next_obj) != *post_plug_debug)
-                {
-                    dprintf (1, ("obj: %p gap should be %zx but it is %zx",
-                        next_obj, *post_plug_debug, (size_t)(node_gap_size (next_obj))));
-                    FATAL_GC_ERROR();
-                }
-                post_plug_debug++;
-                if (*((size_t*)(next_obj - 3 * sizeof (size_t))) != *post_plug_debug)
-                {
-                    dprintf (1, ("obj: %p reloc should be %zx but it is %zx",
-                        next_obj, *post_plug_debug, (size_t)(node_relocation_distance (next_obj))));
-                    FATAL_GC_ERROR();
-                }
-                if (node_left_child (next_obj) > 0)
-                {
-                    dprintf (1, ("obj: %p, vLC: %d\n", next_obj, (int)(node_left_child (next_obj))));
-                    FATAL_GC_ERROR();
-                }
-            }
-        }
-        dprintf (3, ("%s verified", msg));
-    }
-#else
-    UNREFERENCED_PARAMETER(msg);
-#endif // _DEBUG && VERIFY_HEAP
-}
-#ifdef COLLECTIBLE_CLASS
-inline void
-gc_heap::unconditional_set_card_collectible (uint8_t* obj)
-{
-    if (settings.demotion)
-    {
-        set_card (card_of (obj));
-    }
-}
-#endif //COLLECTIBLE_CLASS
-void gc_heap::relocate_shortened_survivor_helper (uint8_t* plug, uint8_t* plug_end, mark* pinned_plug_entry)
-{
-    uint8_t*  x = plug;
-    uint8_t* p_plug = pinned_plug (pinned_plug_entry);
-    BOOL is_pinned = (plug == p_plug);
-    BOOL check_short_obj_p = (is_pinned ? pinned_plug_entry->post_short_p() : pinned_plug_entry->pre_short_p());
-    plug_end += sizeof (gap_reloc_pair);
-    dprintf (3, ("%s %p-%p short, LO: %s OW", (is_pinned ? "PP" : "NP"), plug, plug_end, (check_short_obj_p ? "is" : "is not")));
-    verify_pins_with_post_plug_info("begin reloc short surv");
-    while (x < plug_end)
-    {
-        if (check_short_obj_p && ((DWORD)(plug_end - x) < (DWORD)min_pre_pin_obj_size))
-        {
-            dprintf (3, ("last obj %p is short", x));
-            if (is_pinned)
-            {
-#ifdef COLLECTIBLE_CLASS
-                if (pinned_plug_entry->post_short_collectible_p())
-                    unconditional_set_card_collectible (x);
-#endif //COLLECTIBLE_CLASS
-                uint8_t** saved_plug_info_start = (uint8_t**)(pinned_plug_entry->get_post_plug_info_start());
-                uint8_t** saved_info_to_relocate = (uint8_t**)(pinned_plug_entry->get_post_plug_reloc_info());
-                for (size_t i = 0; i < pinned_plug_entry->get_max_short_bits(); i++)
-                {
-                    if (pinned_plug_entry->post_short_bit_p (i))
-                    {
-                        reloc_ref_in_shortened_obj ((saved_plug_info_start + i), (saved_info_to_relocate + i));
-                    }
-                }
-            }
-            else
-            {
-#ifdef COLLECTIBLE_CLASS
-                if (pinned_plug_entry->pre_short_collectible_p())
-                    unconditional_set_card_collectible (x);
-#endif //COLLECTIBLE_CLASS
-                relocate_pre_plug_info (pinned_plug_entry);
-                uint8_t** saved_plug_info_start = (uint8_t**)(p_plug - sizeof (plug_and_gap));
-                uint8_t** saved_info_to_relocate = (uint8_t**)(pinned_plug_entry->get_pre_plug_reloc_info());
-                for (size_t i = 0; i < pinned_plug_entry->get_max_short_bits(); i++)
-                {
-                    if (pinned_plug_entry->pre_short_bit_p (i))
-                    {
-                        reloc_ref_in_shortened_obj ((saved_plug_info_start + i), (saved_info_to_relocate + i));
-                    }
-                }
-            }
-            break;
-        }
-        size_t s = size (x);
-        uint8_t* next_obj = x + Align (s);
-        Prefetch (next_obj);
-        if (next_obj >= plug_end)
-        {
-            dprintf (3, ("object %p is at the end of the plug %p->%p",
-                next_obj, plug, plug_end));
-            verify_pins_with_post_plug_info("before reloc short obj");
-            relocate_shortened_obj_helper (x, s, (x + Align (s) - sizeof (plug_and_gap)), pinned_plug_entry, is_pinned);
-        }
-        else
-        {
-            relocate_obj_helper (x, s);
-        }
-        assert (s > 0);
-        x = next_obj;
-    }
-    verify_pins_with_post_plug_info("end reloc short surv");
-}
-void gc_heap::relocate_survivors_in_plug (uint8_t* plug, uint8_t* plug_end,
-                                          BOOL check_last_object_p,
-                                          mark* pinned_plug_entry)
-{
-    dprintf (3,("RP: [%zx(%zx->%zx),%zx(%zx->%zx)[",
-        (size_t)plug, brick_of (plug), (size_t)brick_table[brick_of (plug)],
-        (size_t)plug_end, brick_of (plug_end), (size_t)brick_table[brick_of (plug_end)]));
-    if (check_last_object_p)
-    {
-        relocate_shortened_survivor_helper (plug, plug_end, pinned_plug_entry);
-    }
-    else
-    {
-        relocate_survivor_helper (plug, plug_end);
-    }
-}
-void gc_heap::relocate_survivors_in_brick (uint8_t* tree, relocate_args* args)
-{
-    assert ((tree != NULL));
-    dprintf (3, ("tree: %p, args->last_plug: %p, left: %p, right: %p, gap(t): %zx",
-        tree, args->last_plug,
-        (tree + node_left_child (tree)),
-        (tree + node_right_child (tree)),
-        node_gap_size (tree)));
-    if (node_left_child (tree))
-    {
-        relocate_survivors_in_brick (tree + node_left_child (tree), args);
-    }
-    {
-        uint8_t*  plug = tree;
-        BOOL   has_post_plug_info_p = FALSE;
-        BOOL   has_pre_plug_info_p = FALSE;
-        if (tree == oldest_pinned_plug)
-        {
-            args->pinned_plug_entry = get_oldest_pinned_entry (&has_pre_plug_info_p,
-                                                               &has_post_plug_info_p);
-            assert (tree == pinned_plug (args->pinned_plug_entry));
-            dprintf (3, ("tree is the oldest pin: %p", tree));
-        }
-        if (args->last_plug)
-        {
-            size_t  gap_size = node_gap_size (tree);
-            uint8_t*  gap = (plug - gap_size);
-            dprintf (3, ("tree: %p, gap: %p (%zx)", tree, gap, gap_size));
-            assert (gap_size >= Align (min_obj_size));
-            uint8_t*  last_plug_end = gap;
-            BOOL check_last_object_p = (args->is_shortened || has_pre_plug_info_p);
-            {
-                relocate_survivors_in_plug (args->last_plug, last_plug_end, check_last_object_p, args->pinned_plug_entry);
-            }
-        }
-        else
-        {
-            assert (!has_pre_plug_info_p);
-        }
-        args->last_plug = plug;
-        args->is_shortened = has_post_plug_info_p;
-        if (has_post_plug_info_p)
-        {
-            dprintf (3, ("setting %p as shortened", plug));
-        }
-        dprintf (3, ("last_plug: %p(shortened: %d)", plug, (args->is_shortened ? 1 : 0)));
-    }
-    if (node_right_child (tree))
-    {
-        relocate_survivors_in_brick (tree + node_right_child (tree), args);
-    }
-}
-inline
-void gc_heap::update_oldest_pinned_plug()
-{
-    oldest_pinned_plug = (pinned_plug_que_empty_p() ? 0 : pinned_plug (oldest_pin()));
-}
-heap_segment* gc_heap::get_start_segment (generation* gen)
-{
-    heap_segment* start_heap_segment = heap_segment_rw (generation_start_segment (gen));
-#ifdef USE_REGIONS
-    heap_segment* current_heap_segment = heap_segment_non_sip (start_heap_segment);
-    if (current_heap_segment != start_heap_segment)
-    {
-        dprintf (REGIONS_LOG, ("h%d skipped gen%d SIP regions, start %p->%p",
-            heap_number,
-            (current_heap_segment ? heap_segment_gen_num (current_heap_segment) : -1),
-            heap_segment_mem (start_heap_segment),
-            (current_heap_segment ? heap_segment_mem (current_heap_segment) : 0)));
-    }
-    start_heap_segment = current_heap_segment;
-#endif //USE_REGIONS
-    return start_heap_segment;
-}
-void gc_heap::relocate_survivors (int condemned_gen_number,
-                                  uint8_t* first_condemned_address)
-{
-    reset_pinned_queue_bos();
-    update_oldest_pinned_plug();
-    int stop_gen_idx = get_stop_generation_index (condemned_gen_number);
-#ifndef USE_REGIONS
-    assert (first_condemned_address == generation_allocation_start (generation_of (condemned_gen_number)));
-#endif //!USE_REGIONS
-    for (int i = condemned_gen_number; i >= stop_gen_idx; i--)
-    {
-        generation* condemned_gen = generation_of (i);
-        heap_segment* current_heap_segment = heap_segment_rw (generation_start_segment (condemned_gen));
-#ifdef USE_REGIONS
-        current_heap_segment = relocate_advance_to_non_sip (current_heap_segment);
-        if (!current_heap_segment)
-            continue;
-#endif //USE_REGIONS
-        uint8_t*  start_address = get_soh_start_object (current_heap_segment, condemned_gen);
-        size_t  current_brick = brick_of (start_address);
-        PREFIX_ASSUME(current_heap_segment != NULL);
-        uint8_t*  end_address = heap_segment_allocated (current_heap_segment);
-        size_t  end_brick = brick_of (end_address - 1);
-        relocate_args args;
-        args.is_shortened = FALSE;
-        args.pinned_plug_entry = 0;
-        args.last_plug = 0;
-        while (1)
-        {
-            if (current_brick > end_brick)
-            {
-                if (args.last_plug)
-                {
-                    {
-                        assert (!(args.is_shortened));
-                        relocate_survivors_in_plug (args.last_plug,
-                                                    heap_segment_allocated (current_heap_segment),
-                                                    args.is_shortened,
-                                                    args.pinned_plug_entry);
-                    }
-                    args.last_plug = 0;
-                }
-                heap_segment* next_heap_segment = heap_segment_next (current_heap_segment);
-                if (next_heap_segment)
-                {
-#ifdef USE_REGIONS
-                    next_heap_segment = relocate_advance_to_non_sip (next_heap_segment);
-#endif //USE_REGIONS
-                    if (next_heap_segment)
-                    {
-                        current_heap_segment = next_heap_segment;
-                        current_brick = brick_of (heap_segment_mem (current_heap_segment));
-                        end_brick = brick_of (heap_segment_allocated (current_heap_segment)-1);
-                        continue;
-                    }
-                    else
-                        break;
-                }
-                else
-                {
-                    break;
-                }
-            }
-            {
-                int brick_entry =  brick_table [ current_brick ];
-                if (brick_entry >= 0)
-                {
-                    relocate_survivors_in_brick (brick_address (current_brick) +
-                                                brick_entry -1,
-                                                &args);
-                }
-            }
-            current_brick++;
-        }
-    }
-}
-void gc_heap::walk_plug (uint8_t* plug, size_t size, BOOL check_last_object_p, walk_relocate_args* args)
-{
-    if (check_last_object_p)
-    {
-        size += sizeof (gap_reloc_pair);
-        mark* entry = args->pinned_plug_entry;
-        if (args->is_shortened)
-        {
-            assert (entry->has_post_plug_info());
-            entry->swap_post_plug_and_saved_for_profiler();
-        }
-        else
-        {
-            assert (entry->has_pre_plug_info());
-            entry->swap_pre_plug_and_saved_for_profiler();
-        }
-    }
-    ptrdiff_t last_plug_relocation = node_relocation_distance (plug);
-    STRESS_LOG_PLUG_MOVE(plug, (plug + size), -last_plug_relocation);
-    ptrdiff_t reloc = settings.compaction ? last_plug_relocation : 0;
-    (args->fn) (plug, (plug + size), reloc, args->profiling_context, !!settings.compaction, false);
-    if (check_last_object_p)
-    {
-        mark* entry = args->pinned_plug_entry;
-        if (args->is_shortened)
-        {
-            entry->swap_post_plug_and_saved_for_profiler();
-        }
-        else
-        {
-            entry->swap_pre_plug_and_saved_for_profiler();
-        }
-    }
-}
-void gc_heap::walk_relocation_in_brick (uint8_t* tree, walk_relocate_args* args)
-{
-    assert ((tree != NULL));
-    if (node_left_child (tree))
-    {
-        walk_relocation_in_brick (tree + node_left_child (tree), args);
-    }
-    uint8_t*  plug = tree;
-    BOOL   has_pre_plug_info_p = FALSE;
-    BOOL   has_post_plug_info_p = FALSE;
-    if (tree == oldest_pinned_plug)
-    {
-        args->pinned_plug_entry = get_oldest_pinned_entry (&has_pre_plug_info_p,
-                                                           &has_post_plug_info_p);
-        assert (tree == pinned_plug (args->pinned_plug_entry));
-    }
-    if (args->last_plug != 0)
-    {
-        size_t gap_size = node_gap_size (tree);
-        uint8_t*  gap = (plug - gap_size);
-        uint8_t*  last_plug_end = gap;
-        size_t last_plug_size = (last_plug_end - args->last_plug);
-        dprintf (3, ("tree: %p, last_plug: %p, gap: %p(%zx), last_plug_end: %p, size: %zx",
-            tree, args->last_plug, gap, gap_size, last_plug_end, last_plug_size));
-        BOOL check_last_object_p = (args->is_shortened || has_pre_plug_info_p);
-        if (!check_last_object_p)
-        {
-            assert (last_plug_size >= Align (min_obj_size));
-        }
-        walk_plug (args->last_plug, last_plug_size, check_last_object_p, args);
-    }
-    else
-    {
-        assert (!has_pre_plug_info_p);
-    }
-    dprintf (3, ("set args last plug to plug: %p", plug));
-    args->last_plug = plug;
-    args->is_shortened = has_post_plug_info_p;
-    if (node_right_child (tree))
-    {
-        walk_relocation_in_brick (tree + node_right_child (tree), args);
-    }
-}
-void gc_heap::walk_relocation (void* profiling_context, record_surv_fn fn)
-{
-    int condemned_gen_number = settings.condemned_generation;
-    int stop_gen_idx = get_stop_generation_index (condemned_gen_number);
-    reset_pinned_queue_bos();
-    update_oldest_pinned_plug();
-    for (int i = condemned_gen_number; i >= stop_gen_idx; i--)
-    {
-        generation* condemned_gen = generation_of (i);
-        heap_segment*  current_heap_segment = heap_segment_rw (generation_start_segment (condemned_gen));
-#ifdef USE_REGIONS
-        current_heap_segment = walk_relocation_sip (current_heap_segment, profiling_context, fn);
-        if (!current_heap_segment)
-            continue;
-#endif // USE_REGIONS
-        uint8_t*  start_address = get_soh_start_object (current_heap_segment, condemned_gen);
-        size_t  current_brick = brick_of (start_address);
-        PREFIX_ASSUME(current_heap_segment != NULL);
-        size_t end_brick = brick_of (heap_segment_allocated (current_heap_segment)-1);
-        walk_relocate_args args;
-        args.is_shortened = FALSE;
-        args.pinned_plug_entry = 0;
-        args.last_plug = 0;
-        args.profiling_context = profiling_context;
-        args.fn = fn;
-        while (1)
-        {
-            if (current_brick > end_brick)
-            {
-                if (args.last_plug)
-                {
-                    walk_plug (args.last_plug,
-                            (heap_segment_allocated (current_heap_segment) - args.last_plug),
-                            args.is_shortened,
-                            &args);
-                    args.last_plug = 0;
-                }
-                current_heap_segment = heap_segment_next_rw (current_heap_segment);
-#ifdef USE_REGIONS
-                current_heap_segment = walk_relocation_sip (current_heap_segment, profiling_context, fn);
-#endif // USE_REGIONS
-                if (current_heap_segment)
-                {
-                    current_brick = brick_of (heap_segment_mem (current_heap_segment));
-                    end_brick = brick_of (heap_segment_allocated (current_heap_segment)-1);
-                    continue;
-                }
-                else
-                {
-                    break;
-                }
-            }
-            {
-                int brick_entry =  brick_table [ current_brick ];
-                if (brick_entry >= 0)
-                {
-                    walk_relocation_in_brick (brick_address (current_brick) +
-                                            brick_entry - 1,
-                                            &args);
-                }
-            }
-            current_brick++;
-        }
-    }
-}
-#ifdef USE_REGIONS
-heap_segment* gc_heap::walk_relocation_sip (heap_segment* current_heap_segment, void* profiling_context, record_surv_fn fn)
-{
-    while (current_heap_segment && heap_segment_swept_in_plan (current_heap_segment))
-    {
-        uint8_t* start = heap_segment_mem (current_heap_segment);
-        uint8_t* end = heap_segment_allocated (current_heap_segment);
-        uint8_t* obj = start;
-        uint8_t* plug_start = nullptr;
-        while (obj < end)
-        {
-            if (((CObjectHeader*)obj)->IsFree())
-            {
-                if (plug_start)
-                {
-                    fn (plug_start, obj, 0, profiling_context, false, false);
-                    plug_start = nullptr;
-                }
-            }
-            else
-            {
-                if (!plug_start)
-                {
-                    plug_start = obj;
-                }
-            }
-            obj += Align (size (obj));
-        }
-        if (plug_start)
-        {
-            fn (plug_start, end, 0, profiling_context, false, false);
-        }
-        current_heap_segment = heap_segment_next_rw (current_heap_segment);
-    }
-    return current_heap_segment;
-}
-#endif // USE_REGIONS
-void gc_heap::walk_survivors (record_surv_fn fn, void* context, walk_surv_type type)
-{
-    if (type == walk_for_gc)
-        walk_survivors_relocation (context, fn);
-#if defined(BACKGROUND_GC) && defined(FEATURE_EVENT_TRACE)
-    else if (type == walk_for_bgc)
-        walk_survivors_for_bgc (context, fn);
-#endif //BACKGROUND_GC && FEATURE_EVENT_TRACE
-    else
-        assert (!"unknown type!");
-}
-#if defined(BACKGROUND_GC) && defined(FEATURE_EVENT_TRACE)
-void gc_heap::walk_survivors_for_bgc (void* profiling_context, record_surv_fn fn)
-{
-    assert(settings.concurrent);
-    for (int i = get_start_generation_index(); i < total_generation_count; i++)
-    {
-        int align_const = get_alignment_constant (i == max_generation);
-        heap_segment* seg = heap_segment_rw (generation_start_segment (generation_of (i)));
-        while (seg)
-        {
-            uint8_t* o = heap_segment_mem (seg);
-            uint8_t* end = heap_segment_allocated (seg);
-            while (o < end)
-            {
-                if (method_table(o) == g_gc_pFreeObjectMethodTable)
-                {
-                    o += Align (size (o), align_const);
-                    continue;
-                }
-                uint8_t* plug_start = o;
-                while (method_table(o) != g_gc_pFreeObjectMethodTable)
-                {
-                    o += Align (size (o), align_const);
-                    if (o >= end)
-                    {
-                        break;
-                    }
-                }
-                uint8_t* plug_end = o;
-                fn (plug_start,
-                    plug_end,
-                    0,              // Reloc distance == 0 as this is non-compacting
-                    profiling_context,
-                    false,          // Non-compacting
-                    true);          // BGC
-            }
-            seg = heap_segment_next (seg);
-        }
-    }
-}
-#endif //BACKGROUND_GC && FEATURE_EVENT_TRACE
-void gc_heap::relocate_phase (int condemned_gen_number,
-                              uint8_t* first_condemned_address)
-{
-    ScanContext sc;
-    sc.thread_number = heap_number;
-    sc.thread_count = n_heaps;
-    sc.promotion = FALSE;
-    sc.concurrent = FALSE;
-#ifdef MULTIPLE_HEAPS
-    dprintf(3, ("Joining after end of plan"));
-    gc_t_join.join(this, gc_join_begin_relocate_phase);
-    if (gc_t_join.joined())
-    {
-#endif //MULTIPLE_HEAPS
-#ifdef FEATURE_EVENT_TRACE
-        if (informational_event_enabled_p)
-        {
-            gc_time_info[time_relocate] = GetHighPrecisionTimeStamp();
-        }
-#endif //FEATURE_EVENT_TRACE
-#ifdef USE_REGIONS
-        verify_region_to_generation_map();
-#endif //USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-        dprintf(3, ("Restarting for relocation"));
-        gc_t_join.restart();
-    }
-#endif //MULTIPLE_HEAPS
-    dprintf (2, (ThreadStressLog::gcStartRelocateMsg(), heap_number));
-    dprintf(3,("Relocating roots"));
-    GCScan::GcScanRoots(GCHeap::Relocate,
-                            condemned_gen_number, max_generation, &sc);
-    verify_pins_with_post_plug_info("after reloc stack");
-#ifdef BACKGROUND_GC
-    if (gc_heap::background_running_p())
-    {
-        scan_background_roots (GCHeap::Relocate, heap_number, &sc);
-    }
-#endif //BACKGROUND_GC
-#ifdef FEATURE_CARD_MARKING_STEALING
-    {
-        dprintf(3, ("Relocating survivors"));
-        relocate_survivors(condemned_gen_number,
-            first_condemned_address);
-    }
-#ifdef FEATURE_PREMORTEM_FINALIZATION
-    dprintf(3, ("Relocating finalization data"));
-    finalize_queue->RelocateFinalizationData(condemned_gen_number,
-        __this);
-#endif // FEATURE_PREMORTEM_FINALIZATION
-    {
-        dprintf(3, ("Relocating handle table"));
-        GCScan::GcScanHandles(GCHeap::Relocate,
-            condemned_gen_number, max_generation, &sc);
-    }
-#endif // FEATURE_CARD_MARKING_STEALING
-    if (condemned_gen_number != max_generation)
-    {
-#if defined(MULTIPLE_HEAPS) && defined(FEATURE_CARD_MARKING_STEALING)
-        if (!card_mark_done_soh)
-#endif // MULTIPLE_HEAPS && FEATURE_CARD_MARKING_STEALING
-        {
-            dprintf (3, ("Relocating cross generation pointers on heap %d", heap_number));
-            mark_through_cards_for_segments(&gc_heap::relocate_address, TRUE THIS_ARG);
-            verify_pins_with_post_plug_info("after reloc cards");
-#if defined(MULTIPLE_HEAPS) && defined(FEATURE_CARD_MARKING_STEALING)
-            card_mark_done_soh = true;
-#endif // MULTIPLE_HEAPS && FEATURE_CARD_MARKING_STEALING
-        }
-    }
-    if (condemned_gen_number != max_generation)
-    {
-#if defined(MULTIPLE_HEAPS) && defined(FEATURE_CARD_MARKING_STEALING)
-        if (!card_mark_done_uoh)
-#endif // MULTIPLE_HEAPS && FEATURE_CARD_MARKING_STEALING
-        {
-            dprintf (3, ("Relocating cross generation pointers for uoh objects on heap %d", heap_number));
-            for (int i = uoh_start_generation; i < total_generation_count; i++)
-            {
-#ifndef ALLOW_REFERENCES_IN_POH
-                if (i != poh_generation)
-#endif //ALLOW_REFERENCES_IN_POH
-                    mark_through_cards_for_uoh_objects(&gc_heap::relocate_address, i, TRUE THIS_ARG);
-            }
-#if defined(MULTIPLE_HEAPS) && defined(FEATURE_CARD_MARKING_STEALING)
-            card_mark_done_uoh = true;
-#endif // MULTIPLE_HEAPS && FEATURE_CARD_MARKING_STEALING
-        }
-    }
-    else
-    {
-#ifdef FEATURE_LOH_COMPACTION
-        if (loh_compacted_p)
-        {
-            assert (settings.condemned_generation == max_generation);
-            relocate_in_loh_compact();
-        }
-        else
-#endif //FEATURE_LOH_COMPACTION
-        {
-            relocate_in_uoh_objects (loh_generation);
-        }
-#ifdef ALLOW_REFERENCES_IN_POH
-        relocate_in_uoh_objects (poh_generation);
-#endif
-    }
-#ifndef FEATURE_CARD_MARKING_STEALING
-    {
-        dprintf(3,("Relocating survivors"));
-        relocate_survivors (condemned_gen_number,
-                            first_condemned_address);
-    }
-#ifdef FEATURE_PREMORTEM_FINALIZATION
-        dprintf(3,("Relocating finalization data"));
-        finalize_queue->RelocateFinalizationData (condemned_gen_number,
-                                                       __this);
-#endif // FEATURE_PREMORTEM_FINALIZATION
-    {
-        dprintf(3,("Relocating handle table"));
-        GCScan::GcScanHandles(GCHeap::Relocate,
-                                  condemned_gen_number, max_generation, &sc);
-    }
-#endif // !FEATURE_CARD_MARKING_STEALING
-#if defined(MULTIPLE_HEAPS) && defined(FEATURE_CARD_MARKING_STEALING)
-    if (condemned_gen_number != max_generation)
-    {
-        for (int i = 0; i < gc_heap::n_heaps; i++)
-        {
-            int heap_number_to_look_at = (i + heap_number) % gc_heap::n_heaps;
-            gc_heap* hp = gc_heap::g_heaps[heap_number_to_look_at];
-            if (!hp->card_mark_done_soh)
-            {
-                dprintf(3, ("Relocating cross generation pointers on heap %d", hp->heap_number));
-                hp->mark_through_cards_for_segments(&gc_heap::relocate_address, TRUE THIS_ARG);
-                hp->card_mark_done_soh = true;
-            }
-            if (!hp->card_mark_done_uoh)
-            {
-                dprintf(3, ("Relocating cross generation pointers for uoh objects on heap %d", hp->heap_number));
-                for (int i = uoh_start_generation; i < total_generation_count; i++)
-                {
-#ifndef ALLOW_REFERENCES_IN_POH
-                    if (i != poh_generation)
-#endif //ALLOW_REFERENCES_IN_POH
-                        hp->mark_through_cards_for_uoh_objects(&gc_heap::relocate_address, i, TRUE THIS_ARG);
-                }
-                hp->card_mark_done_uoh = true;
-            }
-        }
-    }
-#endif // MULTIPLE_HEAPS && FEATURE_CARD_MARKING_STEALING
-    dprintf(2, (ThreadStressLog::gcEndRelocateMsg(), heap_number));
-}
-mark* gc_heap::get_next_pinned_entry (uint8_t* tree,
-                                      BOOL* has_pre_plug_info_p,
-                                      BOOL* has_post_plug_info_p,
-                                      BOOL deque_p)
-{
-    if (!pinned_plug_que_empty_p())
-    {
-        mark* oldest_entry = oldest_pin();
-        uint8_t* oldest_plug = pinned_plug (oldest_entry);
-        if (tree == oldest_plug)
-        {
-            *has_pre_plug_info_p =  oldest_entry->has_pre_plug_info();
-            *has_post_plug_info_p = oldest_entry->has_post_plug_info();
-            if (deque_p)
-            {
-                deque_pinned_plug();
-            }
-            dprintf (3, ("found a pinned plug %p, pre: %d, post: %d",
-                tree,
-                (*has_pre_plug_info_p ? 1 : 0),
-                (*has_post_plug_info_p ? 1 : 0)));
-            return oldest_entry;
-        }
-    }
-    return NULL;
-}
-mark* gc_heap::get_oldest_pinned_entry (BOOL* has_pre_plug_info_p,
-                                        BOOL* has_post_plug_info_p)
-{
-    mark* oldest_entry = oldest_pin();
-    *has_pre_plug_info_p =  oldest_entry->has_pre_plug_info();
-    *has_post_plug_info_p = oldest_entry->has_post_plug_info();
-    deque_pinned_plug();
-    update_oldest_pinned_plug();
-    return oldest_entry;
-}
-inline
-void gc_heap::copy_cards_range (uint8_t* dest, uint8_t* src, size_t len, BOOL copy_cards_p)
-{
-    if (copy_cards_p)
-        copy_cards_for_addresses (dest, src, len);
-    else
-        clear_card_for_addresses (dest, dest + len);
-}
-inline
-void  gc_heap::gcmemcopy (uint8_t* dest, uint8_t* src, size_t len, BOOL copy_cards_p)
-{
-    if (dest != src)
-    {
-#ifdef BACKGROUND_GC
-        if (current_c_gc_state == c_gc_state_marking)
-        {
-            copy_mark_bits_for_addresses (dest, src, len);
-        }
-#endif //BACKGROUND_GC
-#ifdef DOUBLY_LINKED_FL
-        BOOL set_bgc_mark_bits_p = is_plug_bgc_mark_bit_set (src);
-        if (set_bgc_mark_bits_p)
-        {
-            clear_plug_bgc_mark_bit (src);
-        }
-        BOOL make_free_obj_p = FALSE;
-        if (len <= min_free_item_no_prev)
-        {
-            make_free_obj_p = is_free_obj_in_compact_bit_set (src);
-            if (make_free_obj_p)
-            {
-                clear_free_obj_in_compact_bit (src);
-            }
-        }
-#endif //DOUBLY_LINKED_FL
-        dprintf(3,(ThreadStressLog::gcMemCopyMsg(), (size_t)src, (size_t)dest, (size_t)src+len, (size_t)dest+len));
-        memcopy (dest - plug_skew, src - plug_skew, len);
-#ifdef DOUBLY_LINKED_FL
-        if (set_bgc_mark_bits_p)
-        {
-            uint8_t* dest_o = dest;
-            uint8_t* dest_end_o = dest + len;
-            while (dest_o < dest_end_o)
-            {
-                uint8_t* next_o = dest_o + Align (size (dest_o));
-                background_mark (dest_o, background_saved_lowest_address, background_saved_highest_address);
-                dest_o = next_o;
-            }
-            dprintf (3333, ("[h%d] GM: %p(%zx-%zx)->%p(%zx-%zx)",
-                heap_number, dest,
-                (size_t)(&mark_array [mark_word_of (dest)]),
-                (size_t)(mark_array [mark_word_of (dest)]),
-                dest_end_o,
-                (size_t)(&mark_array [mark_word_of (dest_o)]),
-                (size_t)(mark_array [mark_word_of (dest_o)])));
-        }
-        if (make_free_obj_p)
-        {
-            size_t* filler_free_obj_size_location = (size_t*)(dest + min_free_item_no_prev);
-            size_t filler_free_obj_size = *filler_free_obj_size_location;
-            make_unused_array ((dest + len), filler_free_obj_size);
-            dprintf (3333, ("[h%d] smallobj, %p(%zd): %p->%p", heap_number,
-                filler_free_obj_size_location, filler_free_obj_size, (dest + len), (dest + len + filler_free_obj_size)));
-        }
-#endif //DOUBLY_LINKED_FL
-#ifdef FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-        if (SoftwareWriteWatch::IsEnabledForGCHeap())
-        {
-            SoftwareWriteWatch::SetDirtyRegion(dest, len - plug_skew);
-        }
-#endif // FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-        copy_cards_range (dest, src, len, copy_cards_p);
-    }
-}
-void gc_heap::compact_plug (uint8_t* plug, size_t size, BOOL check_last_object_p, compact_args* args)
-{
-    args->print();
-    uint8_t* reloc_plug = plug + args->last_plug_relocation;
-    if (check_last_object_p)
-    {
-        size += sizeof (gap_reloc_pair);
-        mark* entry = args->pinned_plug_entry;
-        if (args->is_shortened)
-        {
-            assert (entry->has_post_plug_info());
-            entry->swap_post_plug_and_saved();
-        }
-        else
-        {
-            assert (entry->has_pre_plug_info());
-            entry->swap_pre_plug_and_saved();
-        }
-    }
-    int  old_brick_entry =  brick_table [brick_of (plug)];
-    assert (node_relocation_distance (plug) == args->last_plug_relocation);
-#ifdef FEATURE_STRUCTALIGN
-    ptrdiff_t alignpad = node_alignpad(plug);
-    if (alignpad)
-    {
-        make_unused_array (reloc_plug - alignpad, alignpad);
-        if (brick_of (reloc_plug - alignpad) != brick_of (reloc_plug))
-        {
-            fix_brick_to_highest (reloc_plug - alignpad, reloc_plug);
-        }
-    }
-#else // FEATURE_STRUCTALIGN
-    size_t unused_arr_size = 0;
-    BOOL  already_padded_p = FALSE;
-#ifdef SHORT_PLUGS
-    if (is_plug_padded (plug))
-    {
-        already_padded_p = TRUE;
-        clear_plug_padded (plug);
-        unused_arr_size = Align (min_obj_size);
-    }
-#endif //SHORT_PLUGS
-    if (node_realigned (plug))
-    {
-        unused_arr_size += switch_alignment_size (already_padded_p);
-    }
-    if (unused_arr_size != 0)
-    {
-        make_unused_array (reloc_plug - unused_arr_size, unused_arr_size);
-        if (brick_of (reloc_plug - unused_arr_size) != brick_of (reloc_plug))
-        {
-            dprintf (3, ("fix B for padding: %zd: %p->%p",
-                unused_arr_size, (reloc_plug - unused_arr_size), reloc_plug));
-            fix_brick_to_highest (reloc_plug - unused_arr_size, reloc_plug);
-        }
-    }
-#endif // FEATURE_STRUCTALIGN
-#ifdef SHORT_PLUGS
-    if (is_plug_padded (plug))
-    {
-        make_unused_array (reloc_plug - Align (min_obj_size), Align (min_obj_size));
-        if (brick_of (reloc_plug - Align (min_obj_size)) != brick_of (reloc_plug))
-        {
-            fix_brick_to_highest (reloc_plug - Align (min_obj_size), reloc_plug);
-        }
-    }
-#endif //SHORT_PLUGS
-    gcmemcopy (reloc_plug, plug, size, args->copy_cards_p);
-    if (args->check_gennum_p)
-    {
-        int src_gennum = args->src_gennum;
-        if (src_gennum == -1)
-        {
-            src_gennum = object_gennum (plug);
-        }
-        int dest_gennum = object_gennum_plan (reloc_plug);
-        if (src_gennum < dest_gennum)
-        {
-            generation_allocation_size (generation_of (dest_gennum)) += size;
-        }
-    }
-    size_t current_reloc_brick = args->current_compacted_brick;
-    if (brick_of (reloc_plug) != current_reloc_brick)
-    {
-        dprintf (3, ("last reloc B: %zx, current reloc B: %zx",
-            current_reloc_brick, brick_of (reloc_plug)));
-        if (args->before_last_plug)
-        {
-            dprintf (3,(" fixing last brick %zx to point to last plug %p(%zx)",
-                     current_reloc_brick,
-                     args->before_last_plug,
-                     (args->before_last_plug - brick_address (current_reloc_brick))));
-            {
-                set_brick (current_reloc_brick,
-                        args->before_last_plug - brick_address (current_reloc_brick));
-            }
-        }
-        current_reloc_brick = brick_of (reloc_plug);
-    }
-    size_t end_brick = brick_of (reloc_plug + size-1);
-    if (end_brick != current_reloc_brick)
-    {
-        dprintf (3,("plug spanning multiple bricks, fixing first brick %zx to %zx(%zx)",
-                 current_reloc_brick, (size_t)reloc_plug,
-                 (reloc_plug - brick_address (current_reloc_brick))));
-        {
-            set_brick (current_reloc_brick,
-                    reloc_plug - brick_address (current_reloc_brick));
-        }
-        size_t brick = current_reloc_brick + 1;
-        dprintf (3,("setting intervening bricks %zu->%zu to -1",
-            brick, (end_brick - 1)));
-        while (brick < end_brick)
-        {
-            set_brick (brick, -1);
-            brick++;
-        }
-        args->before_last_plug = brick_address (end_brick) -1;
-        current_reloc_brick = end_brick;
-        dprintf (3, ("setting before last to %p, last brick to %zx",
-            args->before_last_plug, current_reloc_brick));
-    }
-    else
-    {
-        dprintf (3, ("still in the same brick: %zx", end_brick));
-        args->before_last_plug = reloc_plug;
-    }
-    args->current_compacted_brick = current_reloc_brick;
-    if (check_last_object_p)
-    {
-        mark* entry = args->pinned_plug_entry;
-        if (args->is_shortened)
-        {
-            entry->swap_post_plug_and_saved();
-        }
-        else
-        {
-            entry->swap_pre_plug_and_saved();
-        }
-    }
-}
-void gc_heap::compact_in_brick (uint8_t* tree, compact_args* args)
-{
-    assert (tree != NULL);
-    int   left_node = node_left_child (tree);
-    int   right_node = node_right_child (tree);
-    ptrdiff_t relocation = node_relocation_distance (tree);
-    args->print();
-    if (left_node)
-    {
-        dprintf (3, ("B: L: %d->%p", left_node, (tree + left_node)));
-        compact_in_brick ((tree + left_node), args);
-    }
-    uint8_t*  plug = tree;
-    BOOL   has_pre_plug_info_p = FALSE;
-    BOOL   has_post_plug_info_p = FALSE;
-    if (tree == oldest_pinned_plug)
-    {
-        args->pinned_plug_entry = get_oldest_pinned_entry (&has_pre_plug_info_p,
-                                                           &has_post_plug_info_p);
-        assert (tree == pinned_plug (args->pinned_plug_entry));
-    }
-    if (args->last_plug != 0)
-    {
-        size_t gap_size = node_gap_size (tree);
-        uint8_t*  gap = (plug - gap_size);
-        uint8_t*  last_plug_end = gap;
-        size_t last_plug_size = (last_plug_end - args->last_plug);
-        assert ((last_plug_size & (sizeof(PTR_PTR) - 1)) == 0);
-        dprintf (3, ("tree: %p, last_plug: %p, gap: %p(%zx), last_plug_end: %p, size: %zx",
-            tree, args->last_plug, gap, gap_size, last_plug_end, last_plug_size));
-        BOOL check_last_object_p = (args->is_shortened || has_pre_plug_info_p);
-        if (!check_last_object_p)
-        {
-            assert (last_plug_size >= Align (min_obj_size));
-        }
-        compact_plug (args->last_plug, last_plug_size, check_last_object_p, args);
-    }
-    else
-    {
-        assert (!has_pre_plug_info_p);
-    }
-    dprintf (3, ("set args last plug to plug: %p, reloc: %zx", plug, relocation));
-    args->last_plug = plug;
-    args->last_plug_relocation = relocation;
-    args->is_shortened = has_post_plug_info_p;
-    if (right_node)
-    {
-        dprintf (3, ("B: R: %d->%p", right_node, (tree + right_node)));
-        compact_in_brick ((tree + right_node), args);
-    }
-}
-size_t gc_heap::recover_saved_pinned_info()
-{
-    reset_pinned_queue_bos();
-    size_t total_recovered_sweep_size = 0;
-    while (!(pinned_plug_que_empty_p()))
-    {
-        mark* oldest_entry = oldest_pin();
-        size_t recovered_sweep_size = oldest_entry->recover_plug_info();
-        if (recovered_sweep_size > 0)
-        {
-            uint8_t* plug = pinned_plug (oldest_entry);
-            if (object_gennum (plug) == max_generation)
-            {
-                dprintf (3, ("recovered %p(%zd) from pin", plug, recovered_sweep_size));
-                total_recovered_sweep_size += recovered_sweep_size;
-            }
-        }
-#ifdef GC_CONFIG_DRIVEN
-        if (oldest_entry->has_pre_plug_info() && oldest_entry->has_post_plug_info())
-            record_interesting_data_point (idp_pre_and_post_pin);
-        else if (oldest_entry->has_pre_plug_info())
-            record_interesting_data_point (idp_pre_pin);
-        else if (oldest_entry->has_post_plug_info())
-            record_interesting_data_point (idp_post_pin);
-#endif //GC_CONFIG_DRIVEN
-        deque_pinned_plug();
-    }
-    return total_recovered_sweep_size;
-}
-void gc_heap::compact_phase (int condemned_gen_number,
-                             uint8_t*  first_condemned_address,
-                             BOOL clear_cards)
-{
-#ifdef MULTIPLE_HEAPS
-    dprintf(3, ("Joining after end of relocation"));
-    gc_t_join.join(this, gc_join_relocate_phase_done);
-    if (gc_t_join.joined())
-#endif //MULTIPLE_HEAPS
-    {
-#ifdef FEATURE_EVENT_TRACE
-        if (informational_event_enabled_p)
-        {
-            gc_time_info[time_compact] = GetHighPrecisionTimeStamp();
-            gc_time_info[time_relocate] = gc_time_info[time_compact] - gc_time_info[time_relocate];
-        }
-#endif //FEATURE_EVENT_TRACE
-#ifdef MULTIPLE_HEAPS
-        dprintf(3, ("Restarting for compaction"));
-        gc_t_join.restart();
-#endif //MULTIPLE_HEAPS
-    }
-    dprintf (2, (ThreadStressLog::gcStartCompactMsg(), heap_number,
-        first_condemned_address, brick_of (first_condemned_address)));
-#ifdef FEATURE_LOH_COMPACTION
-    if (loh_compacted_p)
-    {
-        compact_loh();
-    }
-#endif //FEATURE_LOH_COMPACTION
-    reset_pinned_queue_bos();
-    update_oldest_pinned_plug();
-    BOOL reused_seg = expand_reused_seg_p();
-    if (reused_seg)
-    {
-        for (int i = 1; i <= max_generation; i++)
-        {
-            generation_allocation_size (generation_of (i)) = 0;
-        }
-    }
-    int stop_gen_idx = get_stop_generation_index (condemned_gen_number);
-    for (int i = condemned_gen_number; i >= stop_gen_idx; i--)
-    {
-        generation* condemned_gen = generation_of (i);
-        heap_segment* current_heap_segment = get_start_segment (condemned_gen);
-#ifdef USE_REGIONS
-        if (!current_heap_segment)
-            continue;
-        size_t   current_brick = brick_of (heap_segment_mem (current_heap_segment));
-#else
-        size_t   current_brick = brick_of (first_condemned_address);
-#endif //USE_REGIONS
-        uint8_t*  end_address = heap_segment_allocated (current_heap_segment);
-#ifndef USE_REGIONS
-        if ((first_condemned_address >= end_address) && (condemned_gen_number < max_generation))
-        {
-            return;
-        }
-#endif //!USE_REGIONS
-        size_t  end_brick = brick_of (end_address-1);
-        compact_args args;
-        args.last_plug = 0;
-        args.before_last_plug = 0;
-        args.current_compacted_brick = ~((size_t)1);
-        args.is_shortened = FALSE;
-        args.pinned_plug_entry = 0;
-        args.copy_cards_p =  (condemned_gen_number >= 1) || !clear_cards;
-        args.check_gennum_p = reused_seg;
-        if (args.check_gennum_p)
-        {
-            args.src_gennum = ((current_heap_segment == ephemeral_heap_segment) ? -1 : 2);
-        }
-#ifdef USE_REGIONS
-        assert (!args.check_gennum_p);
-#endif //USE_REGIONS
-        while (1)
-        {
-            if (current_brick > end_brick)
-            {
-                if (args.last_plug != 0)
-                {
-                    dprintf (3, ("compacting last plug: %p", args.last_plug))
-                    compact_plug (args.last_plug,
-                                  (heap_segment_allocated (current_heap_segment) - args.last_plug),
-                                  args.is_shortened,
-                                  &args);
-                }
-                heap_segment* next_heap_segment = heap_segment_next_non_sip (current_heap_segment);
-                if (next_heap_segment)
-                {
-                    current_heap_segment = next_heap_segment;
-                    current_brick = brick_of (heap_segment_mem (current_heap_segment));
-                    end_brick = brick_of (heap_segment_allocated (current_heap_segment)-1);
-                    args.last_plug = 0;
-                    if (args.check_gennum_p)
-                    {
-                        args.src_gennum = ((current_heap_segment == ephemeral_heap_segment) ? -1 : 2);
-                    }
-                    continue;
-                }
-                else
-                {
-                    if (args.before_last_plug !=0)
-                    {
-                        dprintf (3, ("Fixing last brick %zx to point to plug %zx",
-                                    args.current_compacted_brick, (size_t)args.before_last_plug));
-                        assert (args.current_compacted_brick != ~1u);
-                        set_brick (args.current_compacted_brick,
-                                   args.before_last_plug - brick_address (args.current_compacted_brick));
-                    }
-                    break;
-                }
-            }
-            {
-                int  brick_entry =  brick_table [ current_brick ];
-                dprintf (3, ("B: %zx(%zx)->%p",
-                    current_brick, (size_t)brick_entry, (brick_address (current_brick) + brick_entry - 1)));
-                if (brick_entry >= 0)
-                {
-                    compact_in_brick ((brick_address (current_brick) + brick_entry -1),
-                                      &args);
-                }
-            }
-            current_brick++;
-        }
-    }
-    recover_saved_pinned_info();
-    concurrent_print_time_delta ("compact end");
-    dprintf (2, (ThreadStressLog::gcEndCompactMsg(), heap_number));
-}
-#ifdef MULTIPLE_HEAPS
-#ifdef _MSC_VER
-#pragma warning(push)
-#pragma warning(disable:4702) // C4702: unreachable code: gc_thread_function may not return
-#endif //_MSC_VER
-void gc_heap::gc_thread_stub (void* arg)
-{
-    gc_heap* heap = (gc_heap*)arg;
-    if (!gc_thread_no_affinitize_p)
-    {
-        set_thread_affinity_for_heap (heap->heap_number, heap_select::find_proc_no_from_heap_no (heap->heap_number));
-    }
-    GCToOSInterface::BoostThreadPriority();
-    void* tmp = _alloca (256*heap->heap_number);
-    heap->gc_thread_function();
-}
-#ifdef _MSC_VER
-#pragma warning(pop)
-#endif //_MSC_VER
-#endif //MULTIPLE_HEAPS
-#ifdef BACKGROUND_GC
-#ifdef _MSC_VER
-#pragma warning(push)
-#pragma warning(disable:4702) // C4702: unreachable code: gc_thread_function may not return
-#endif //_MSC_VER
-void gc_heap::bgc_thread_stub (void* arg)
-{
-    gc_heap* heap = (gc_heap*)arg;
-#ifdef STRESS_DYNAMIC_HEAP_COUNT
-    int r = (int)gc_rand::get_rand (30);
-    bool wait_p = (r < 10);
-    if (wait_p)
-    {
-        GCToOSInterface::Sleep (100);
-    }
-    dprintf (6666, ("h%d %s", heap->heap_number, (wait_p ? "waited" : "did not wait")));
-#endif
-    heap->bgc_thread = GCToEEInterface::GetThread();
-    assert(heap->bgc_thread != nullptr);
-    heap->bgc_thread_function();
-}
-#ifdef _MSC_VER
-#pragma warning(pop)
-#endif //_MSC_VER
-void gc_heap::background_drain_mark_list (int thread)
-{
-#ifndef MULTIPLE_HEAPS
-    UNREFERENCED_PARAMETER(thread);
-#endif //!MULTIPLE_HEAPS
-    size_t saved_c_mark_list_index = c_mark_list_index;
-    if (saved_c_mark_list_index)
-    {
-        concurrent_print_time_delta ("SML");
-    }
-    while (c_mark_list_index != 0)
-    {
-        size_t current_index = c_mark_list_index - 1;
-        uint8_t* o = c_mark_list [current_index];
-        background_mark_object (o THREAD_NUMBER_ARG);
-        c_mark_list_index--;
-    }
-    if (saved_c_mark_list_index)
-    {
-        concurrent_print_time_delta ("EML");
-    }
-    fire_drain_mark_list_event (saved_c_mark_list_index);
-}
-#ifdef MULTIPLE_HEAPS
-void gc_heap::background_scan_dependent_handles (ScanContext *sc)
-{
-    s_fUnscannedPromotions = TRUE;
-    while (true)
-    {
-        if (GCScan::GcDhUnpromotedHandlesExist(sc))
-            s_fUnpromotedHandles = TRUE;
-        bgc_t_join.join(this, gc_join_scan_dependent_handles);
-        if (bgc_t_join.joined())
-        {
-            s_fScanRequired = s_fUnscannedPromotions && s_fUnpromotedHandles;
-            s_fUnscannedPromotions = FALSE;
-            s_fUnpromotedHandles = FALSE;
-            if (!s_fScanRequired)
-            {
-#ifdef USE_REGIONS
-                BOOL all_heaps_background_overflow_p = FALSE;
-#else //USE_REGIONS
-                uint8_t* all_heaps_max = 0;
-                uint8_t* all_heaps_min = MAX_PTR;
-#endif //USE_REGIONS
-                int i;
-                for (i = 0; i < n_heaps; i++)
-                {
-#ifdef USE_REGIONS
-                    if (g_heaps[i]->background_overflow_p)
-                        all_heaps_background_overflow_p = TRUE;
-#else //USE_REGIONS
-                    if (all_heaps_max < g_heaps[i]->background_max_overflow_address)
-                        all_heaps_max = g_heaps[i]->background_max_overflow_address;
-                    if (all_heaps_min > g_heaps[i]->background_min_overflow_address)
-                        all_heaps_min = g_heaps[i]->background_min_overflow_address;
-#endif //USE_REGIONS
-                }
-                for (i = 0; i < n_heaps; i++)
-                {
-#ifdef USE_REGIONS
-                    g_heaps[i]->background_overflow_p = all_heaps_background_overflow_p;
-#else //USE_REGIONS
-                    g_heaps[i]->background_max_overflow_address = all_heaps_max;
-                    g_heaps[i]->background_min_overflow_address = all_heaps_min;
-#endif //USE_REGIONS
-                }
-            }
-            dprintf(2, ("Starting all gc thread mark stack overflow processing"));
-            bgc_t_join.restart();
-        }
-        if (background_process_mark_overflow (sc->concurrent))
-            s_fUnscannedPromotions = TRUE;
-        if (!s_fScanRequired)
-            break;
-        bgc_t_join.join(this, gc_join_rescan_dependent_handles);
-        if (bgc_t_join.joined())
-        {
-            dprintf(3, ("Starting all gc thread for dependent handle promotion"));
-            bgc_t_join.restart();
-        }
-        if (GCScan::GcDhUnpromotedHandlesExist(sc))
-            if (GCScan::GcDhReScan(sc))
-                s_fUnscannedPromotions = TRUE;
-    }
-}
-#else
-void gc_heap::background_scan_dependent_handles (ScanContext *sc)
-{
-    bool fUnscannedPromotions = true;
-    while (GCScan::GcDhUnpromotedHandlesExist(sc) && fUnscannedPromotions)
-    {
-        fUnscannedPromotions = false;
-        if (background_process_mark_overflow (sc->concurrent))
-            fUnscannedPromotions = true;
-        if (GCScan::GcDhReScan (sc))
-            fUnscannedPromotions = true;
-    }
-    background_process_mark_overflow (sc->concurrent);
-}
-#endif //MULTIPLE_HEAPS
-void gc_heap::recover_bgc_settings()
-{
-    if ((settings.condemned_generation < max_generation) && gc_heap::background_running_p())
-    {
-        dprintf (2, ("restoring bgc settings"));
-        settings = saved_bgc_settings;
-        GCHeap::GcCondemnedGeneration = gc_heap::settings.condemned_generation;
-    }
-}
-void gc_heap::allow_fgc()
-{
-    assert (bgc_thread == GCToEEInterface::GetThread());
-    bool bToggleGC = false;
-    if (g_fSuspensionPending > 0)
-    {
-        bToggleGC = GCToEEInterface::EnablePreemptiveGC();
-        if (bToggleGC)
-        {
-            GCToEEInterface::DisablePreemptiveGC();
-        }
-    }
-}
-BOOL gc_heap::is_bgc_in_progress()
-{
-#ifdef MULTIPLE_HEAPS
-    gc_heap* hp = g_heaps[0];
-#else
-    gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-    return (background_running_p() || (hp->current_bgc_state == bgc_initialized));
-}
-void gc_heap::clear_commit_flag()
-{
-    for (int i = get_start_generation_index(); i < total_generation_count; i++)
-    {
-        generation* gen = generation_of (i);
-        heap_segment* seg = heap_segment_in_range (generation_start_segment (gen));
-        while (seg)
-        {
-            if (seg->flags & heap_segment_flags_ma_committed)
-            {
-                seg->flags &= ~heap_segment_flags_ma_committed;
-            }
-            if (seg->flags & heap_segment_flags_ma_pcommitted)
-            {
-                seg->flags &= ~heap_segment_flags_ma_pcommitted;
-            }
-            seg = heap_segment_next (seg);
-        }
-    }
-}
-void gc_heap::clear_commit_flag_global()
-{
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < n_heaps; i++)
-    {
-        g_heaps[i]->clear_commit_flag();
-    }
-#else
-    clear_commit_flag();
-#endif //MULTIPLE_HEAPS
-}
-void gc_heap::verify_mark_array_cleared (uint8_t* begin, uint8_t* end, uint32_t* mark_array_addr)
-{
-#ifdef _DEBUG
-    size_t  markw = mark_word_of (begin);
-    size_t  markw_end = mark_word_of (end);
-    while (markw < markw_end)
-    {
-        if (mark_array_addr[markw])
-        {
-            uint8_t* addr = mark_word_address (markw);
-#ifdef USE_REGIONS
-            heap_segment* region = region_of (addr);
-            dprintf (1, ("The mark bits at 0x%zx:0x%x(addr: 0x%p, r: %zx(%p)) were not cleared",
-                            markw, mark_array_addr[markw], addr,
-                            (size_t)region, heap_segment_mem (region)));
-#else
-            dprintf (1, ("The mark bits at 0x%zx:0x%x(addr: 0x%p) were not cleared",
-                            markw, mark_array_addr[markw], addr));
-#endif //USE_REGIONS
-            FATAL_GC_ERROR();
-        }
-        markw++;
-    }
-#else // _DEBUG
-    UNREFERENCED_PARAMETER(begin);
-    UNREFERENCED_PARAMETER(end);
-    UNREFERENCED_PARAMETER(mark_array_addr);
-#endif //_DEBUG
-}
-uint8_t* gc_heap::get_start_address (heap_segment* seg)
-{
-    uint8_t* start =
-#ifdef USE_REGIONS
-        heap_segment_mem (seg);
-#else
-        (heap_segment_read_only_p(seg) ? heap_segment_mem (seg) : (uint8_t*)seg);
-#endif //USE_REGIONS
-    return start;
-}
-BOOL gc_heap::commit_mark_array_new_seg (gc_heap* hp,
-                                         heap_segment* seg,
-                                         uint32_t* new_card_table,
-                                         uint8_t* new_lowest_address)
-{
-    uint8_t* start = get_start_address (seg);
-    uint8_t* end = heap_segment_reserved (seg);
-    uint8_t* lowest = hp->background_saved_lowest_address;
-    uint8_t* highest = hp->background_saved_highest_address;
-    uint8_t* commit_start = NULL;
-    uint8_t* commit_end = NULL;
-    size_t commit_flag = 0;
-    if ((highest >= start) &&
-        (lowest <= end))
-    {
-        if ((start >= lowest) && (end <= highest))
-        {
-            dprintf (GC_TABLE_LOG, ("completely in bgc range: seg %p-%p, bgc: %p-%p",
-                                    start, end, lowest, highest));
-            commit_flag = heap_segment_flags_ma_committed;
-        }
-        else
-        {
-            dprintf (GC_TABLE_LOG, ("partially in bgc range: seg %p-%p, bgc: %p-%p",
-                                    start, end, lowest, highest));
-            commit_flag = heap_segment_flags_ma_pcommitted;
-#ifdef USE_REGIONS
-            assert (!"Region should not have its mark array partially committed.");
-#endif
-        }
-        commit_start = max (lowest, start);
-        commit_end = min (highest, end);
-        if (!commit_mark_array_by_range (commit_start, commit_end, hp->mark_array))
-        {
-            return FALSE;
-        }
-        if (new_card_table == 0)
-        {
-            new_card_table = g_gc_card_table;
-        }
-        if (hp->card_table != new_card_table)
-        {
-            if (new_lowest_address == 0)
-            {
-                new_lowest_address = g_gc_lowest_address;
-            }
-            uint32_t* ct = &new_card_table[card_word (gcard_of (new_lowest_address))];
-            uint32_t* ma = (uint32_t*)((uint8_t*)card_table_mark_array (ct) - size_mark_array_of (0, new_lowest_address));
-            dprintf (GC_TABLE_LOG, ("table realloc-ed: %p->%p, MA: %p->%p",
-                                    hp->card_table, new_card_table,
-                                    hp->mark_array, ma));
-            if (!commit_mark_array_by_range (commit_start, commit_end, ma))
-            {
-                return FALSE;
-            }
-        }
-        seg->flags |= commit_flag;
-    }
-    return TRUE;
-}
-BOOL gc_heap::commit_mark_array_by_range (uint8_t* begin, uint8_t* end, uint32_t* mark_array_addr)
-{
-    size_t beg_word = mark_word_of (begin);
-    size_t end_word = mark_word_of (align_on_mark_word (end));
-    uint8_t* commit_start = align_lower_page ((uint8_t*)&mark_array_addr[beg_word]);
-    uint8_t* commit_end = align_on_page ((uint8_t*)&mark_array_addr[end_word]);
-    size_t size = (size_t)(commit_end - commit_start);
-#ifdef SIMPLE_DPRINTF
-    dprintf (GC_TABLE_LOG, ("range: %p->%p mark word: %zx->%zx(%zd), mark array: %p->%p(%zd), commit %p->%p(%zd)",
-                            begin, end,
-                            beg_word, end_word,
-                            (end_word - beg_word) * sizeof (uint32_t),
-                            &mark_array_addr[beg_word],
-                            &mark_array_addr[end_word],
-                            (size_t)(&mark_array_addr[end_word] - &mark_array_addr[beg_word]),
-                            commit_start, commit_end,
-                            size));
-#endif //SIMPLE_DPRINTF
-    if (virtual_commit (commit_start, size, recorded_committed_mark_array_bucket))
-    {
-        verify_mark_array_cleared (begin, end, mark_array_addr);
-        return TRUE;
-    }
-    else
-    {
-        dprintf (GC_TABLE_LOG, ("failed to commit %zd bytes", (end_word - beg_word) * sizeof (uint32_t)));
-        return FALSE;
-    }
-}
-BOOL gc_heap::commit_mark_array_with_check (heap_segment* seg, uint32_t* new_mark_array_addr)
-{
-    uint8_t* start = get_start_address (seg);
-    uint8_t* end = heap_segment_reserved (seg);
-#ifdef MULTIPLE_HEAPS
-    uint8_t* lowest = heap_segment_heap (seg)->background_saved_lowest_address;
-    uint8_t* highest = heap_segment_heap (seg)->background_saved_highest_address;
-#else
-    uint8_t* lowest = background_saved_lowest_address;
-    uint8_t* highest = background_saved_highest_address;
-#endif //MULTIPLE_HEAPS
-    if ((highest >= start) &&
-        (lowest <= end))
-    {
-        start = max (lowest, start);
-        end = min (highest, end);
-        if (!commit_mark_array_by_range (start, end, new_mark_array_addr))
-        {
-            return FALSE;
-        }
-    }
-    return TRUE;
-}
-BOOL gc_heap::commit_mark_array_by_seg (heap_segment* seg, uint32_t* mark_array_addr)
-{
-    dprintf (GC_TABLE_LOG, ("seg: %p->%p; MA: %p",
-        seg,
-        heap_segment_reserved (seg),
-        mark_array_addr));
-    uint8_t* start = get_start_address (seg);
-    return commit_mark_array_by_range (start, heap_segment_reserved (seg), mark_array_addr);
-}
-BOOL gc_heap::commit_mark_array_bgc_init()
-{
-    dprintf (GC_TABLE_LOG, ("BGC init commit: lowest: %p, highest: %p, mark_array: %p",
-                            lowest_address, highest_address, mark_array));
-    for (int i = get_start_generation_index(); i < total_generation_count; i++)
-    {
-        generation* gen = generation_of (i);
-        heap_segment* seg = heap_segment_in_range (generation_start_segment (gen));
-        while (seg)
-        {
-            dprintf (GC_TABLE_LOG, ("h%d gen%d seg: %p(%p-%p), flags: %zd",
-                heap_number, i, seg, heap_segment_mem (seg), heap_segment_allocated (seg), seg->flags));
-            if (!(seg->flags & heap_segment_flags_ma_committed))
-            {
-                if (heap_segment_read_only_p (seg))
-                {
-                    if ((heap_segment_mem (seg) >= lowest_address) &&
-                        (heap_segment_reserved (seg) <= highest_address))
-                    {
-                        if (commit_mark_array_by_seg (seg, mark_array))
-                        {
-                            seg->flags |= heap_segment_flags_ma_committed;
-                        }
-                        else
-                        {
-                            return FALSE;
-                        }
-                    }
-                    else
-                    {
-                        uint8_t* start = max (lowest_address, heap_segment_mem (seg));
-                        uint8_t* end = min (highest_address, heap_segment_reserved (seg));
-                        if (commit_mark_array_by_range (start, end, mark_array))
-                        {
-                            seg->flags |= heap_segment_flags_ma_pcommitted;
-                        }
-                        else
-                        {
-                            return FALSE;
-                        }
-                    }
-                }
-                else
-                {
-                    if (commit_mark_array_by_seg (seg, mark_array))
-                    {
-                        if (seg->flags & heap_segment_flags_ma_pcommitted)
-                        {
-                            seg->flags &= ~heap_segment_flags_ma_pcommitted;
-                        }
-                        seg->flags |= heap_segment_flags_ma_committed;
-                    }
-                    else
-                    {
-                        return FALSE;
-                    }
-                }
-            }
-            seg = heap_segment_next (seg);
-        }
-    }
-    return TRUE;
-}
-BOOL gc_heap::commit_new_mark_array (uint32_t* new_mark_array_addr)
-{
-    dprintf (GC_TABLE_LOG, ("committing existing segs on MA %p", new_mark_array_addr));
-    for (int i = get_start_generation_index(); i < total_generation_count; i++)
-    {
-        generation* gen = generation_of (i);
-        heap_segment* seg = heap_segment_in_range (generation_start_segment (gen));
-        while (seg)
-        {
-            if (!commit_mark_array_with_check (seg, new_mark_array_addr))
-            {
-                return FALSE;
-            }
-            seg = heap_segment_next (seg);
-        }
-    }
-#if defined(MULTIPLE_HEAPS) && !defined(USE_REGIONS)
-    if (new_heap_segment)
-    {
-        if (!commit_mark_array_with_check (new_heap_segment, new_mark_array_addr))
-        {
-            return FALSE;
-        }
-    }
-#endif //MULTIPLE_HEAPS && !USE_REGIONS
-    return TRUE;
-}
-BOOL gc_heap::commit_new_mark_array_global (uint32_t* new_mark_array)
-{
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < n_heaps; i++)
-    {
-        if (!g_heaps[i]->commit_new_mark_array (new_mark_array))
-        {
-            return FALSE;
-        }
-    }
-#else
-    if (!commit_new_mark_array (new_mark_array))
-    {
-        return FALSE;
-    }
-#endif //MULTIPLE_HEAPS
-    return TRUE;
-}
-void gc_heap::decommit_mark_array_by_seg (heap_segment* seg)
-{
-    if (mark_array == NULL)
-    {
-        return;
-    }
-    dprintf (GC_TABLE_LOG, ("decommitting seg %p(%zx), MA: %p", seg, seg->flags, mark_array));
-    size_t flags = seg->flags;
-    if ((flags & heap_segment_flags_ma_committed) ||
-        (flags & heap_segment_flags_ma_pcommitted))
-    {
-        uint8_t* start = get_start_address (seg);
-        uint8_t* end = heap_segment_reserved (seg);
-        if (flags & heap_segment_flags_ma_pcommitted)
-        {
-            start = max (lowest_address, start);
-            end = min (highest_address, end);
-        }
-        size_t beg_word = mark_word_of (start);
-        size_t end_word = mark_word_of (align_on_mark_word (end));
-        uint8_t* decommit_start = align_on_page ((uint8_t*)&mark_array[beg_word]);
-        uint8_t* decommit_end = align_lower_page ((uint8_t*)&mark_array[end_word]);
-        size_t size = (size_t)(decommit_end - decommit_start);
-#ifdef SIMPLE_DPRINTF
-        dprintf (GC_TABLE_LOG, ("seg: %p mark word: %zx->%zx(%zd), mark array: %p->%p(%zd), decommit %p->%p(%zd)",
-                                seg,
-                                beg_word, end_word,
-                                (end_word - beg_word) * sizeof (uint32_t),
-                                &mark_array[beg_word],
-                                &mark_array[end_word],
-                                (size_t)(&mark_array[end_word] - &mark_array[beg_word]),
-                                decommit_start, decommit_end,
-                                size));
-#endif //SIMPLE_DPRINTF
-        if (decommit_start < decommit_end)
-        {
-            if (!virtual_decommit (decommit_start, size, recorded_committed_mark_array_bucket))
-            {
-                dprintf (GC_TABLE_LOG, ("decommit on %p for %zd bytes failed",
-                                        decommit_start, size));
-                assert (!"decommit failed");
-            }
-        }
-        dprintf (GC_TABLE_LOG, ("decommitted [%zx for address [%p", beg_word, seg));
-    }
-}
-bool gc_heap::should_update_end_mark_size()
-{
-    return ((settings.condemned_generation == (max_generation - 1)) && (current_c_gc_state == c_gc_state_planning));
-}
-void gc_heap::background_mark_phase ()
-{
-    verify_mark_array_cleared();
-    ScanContext sc;
-    sc.thread_number = heap_number;
-    sc.thread_count = n_heaps;
-    sc.promotion = TRUE;
-    sc.concurrent = FALSE;
-    THREAD_FROM_HEAP;
-    BOOL cooperative_mode = TRUE;
-#ifndef MULTIPLE_HEAPS
-    const int thread = heap_number;
-#endif //!MULTIPLE_HEAPS
-    dprintf(2,("-(GC%zu)BMark-", VolatileLoad(&settings.gc_index)));
-    assert (settings.concurrent);
-    if (gen0_must_clear_bricks > 0)
-        gen0_must_clear_bricks--;
-    background_soh_alloc_count = 0;
-    background_uoh_alloc_count = 0;
-    bgc_overflow_count = 0;
-    bpromoted_bytes (heap_number) = 0;
-    static uint32_t num_sizedrefs = 0;
-#ifdef USE_REGIONS
-    background_overflow_p = FALSE;
-#else
-    background_min_overflow_address = MAX_PTR;
-    background_max_overflow_address = 0;
-    background_min_soh_overflow_address = MAX_PTR;
-    background_max_soh_overflow_address = 0;
-#endif //USE_REGIONS
-    processed_eph_overflow_p = FALSE;
-    assert (g_mark_list);
-    mark_list = g_mark_list;
-    mark_list_end = &mark_list [0];
-    mark_list_index = &mark_list [0];
-    c_mark_list_index = 0;
-#ifndef MULTIPLE_HEAPS
-    shigh = (uint8_t*) 0;
-    slow  = MAX_PTR;
-#endif //MULTIPLE_HEAPS
-    generation*   gen = generation_of (max_generation);
-    dprintf(3,("BGC: stack marking"));
-    sc.concurrent = TRUE;
-    GCScan::GcScanRoots(background_promote_callback,
-                            max_generation, max_generation,
-                            &sc);
-    dprintf(3,("BGC: finalization marking"));
-    finalize_queue->GcScanRoots(background_promote_callback, heap_number, 0);
-    size_t total_soh_size = generation_sizes (generation_of (max_generation));
-    size_t total_loh_size = generation_size (loh_generation);
-    size_t total_poh_size = generation_size (poh_generation);
-    bgc_begin_loh_size = total_loh_size;
-    bgc_begin_poh_size = total_poh_size;
-    bgc_loh_size_increased = 0;
-    bgc_poh_size_increased = 0;
-    background_soh_size_end_mark = 0;
-    dprintf (GTC_LOG, ("BM: h%d: loh: %zd, soh: %zd, poh: %zd", heap_number, total_loh_size, total_soh_size, total_poh_size));
-    concurrent_print_time_delta ("CS");
-    FIRE_EVENT(BGC1stNonConEnd);
-#ifndef USE_REGIONS
-    saved_overflow_ephemeral_seg = 0;
-#endif //!USE_REGIONS
-    current_bgc_state = bgc_reset_ww;
-#ifdef MULTIPLE_HEAPS
-    bgc_t_join.join(this, gc_join_restart_ee);
-    if (bgc_t_join.joined())
-#endif //MULTIPLE_HEAPS
-    {
-#ifdef FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-        concurrent_print_time_delta ("CRWW begin");
-#ifdef MULTIPLE_HEAPS
-        for (int i = 0; i < n_heaps; i++)
-        {
-            g_heaps[i]->reset_write_watch (FALSE);
-        }
-#else
-        reset_write_watch (FALSE);
-#endif //MULTIPLE_HEAPS
-        concurrent_print_time_delta ("CRWW");
-#endif // FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-        num_sizedrefs = GCToEEInterface::GetTotalNumSizedRefHandles();
-        dprintf (GTC_LOG, ("setting cm_in_progress"));
-        c_write (cm_in_progress, TRUE);
-        assert (dont_restart_ee_p);
-        dont_restart_ee_p = FALSE;
-        last_alloc_reset_suspended_end_time = GetHighPrecisionTimeStamp();
-        restart_vm();
-        GCToOSInterface::YieldThread (0);
-#ifdef MULTIPLE_HEAPS
-        dprintf(3, ("Starting all gc threads for gc"));
-        bgc_t_join.restart();
-#endif //MULTIPLE_HEAPS
-    }
-#ifdef MULTIPLE_HEAPS
-    bgc_t_join.join(this, gc_join_after_reset);
-    if (bgc_t_join.joined())
-#endif //MULTIPLE_HEAPS
-    {
-        disable_preemptive (true);
-#ifndef FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-#ifdef WRITE_WATCH
-        concurrent_print_time_delta ("CRWW begin");
-#ifdef MULTIPLE_HEAPS
-        for (int i = 0; i < n_heaps; i++)
-        {
-            g_heaps[i]->reset_write_watch (TRUE);
-        }
-#else
-        reset_write_watch (TRUE);
-#endif //MULTIPLE_HEAPS
-        concurrent_print_time_delta ("CRWW");
-#endif //WRITE_WATCH
-#ifdef MULTIPLE_HEAPS
-        for (int i = 0; i < n_heaps; i++)
-        {
-            g_heaps[i]->revisit_written_pages (TRUE, TRUE);
-        }
-#else
-        revisit_written_pages (TRUE, TRUE);
-#endif //MULTIPLE_HEAPS
-        concurrent_print_time_delta ("CRW");
-#endif // !FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-#ifdef MULTIPLE_HEAPS
-        for (int i = 0; i < n_heaps; i++)
-        {
-            g_heaps[i]->current_bgc_state = bgc_mark_handles;
-        }
-#else
-        current_bgc_state = bgc_mark_handles;
-#endif //MULTIPLE_HEAPS
-        current_c_gc_state = c_gc_state_marking;
-        enable_preemptive ();
-#ifdef MULTIPLE_HEAPS
-        dprintf(3, ("Joining BGC threads after resetting writewatch"));
-        bgc_t_join.restart();
-#endif //MULTIPLE_HEAPS
-    }
-    disable_preemptive (true);
-    if (num_sizedrefs > 0)
-    {
-        GCScan::GcScanSizedRefs(background_promote, max_generation, max_generation, &sc);
-        enable_preemptive ();
-#ifdef MULTIPLE_HEAPS
-        bgc_t_join.join(this, gc_join_scan_sizedref_done);
-        if (bgc_t_join.joined())
-        {
-            dprintf(3, ("Done with marking all sized refs. Starting all bgc thread for marking other strong roots"));
-            bgc_t_join.restart();
-        }
-#endif //MULTIPLE_HEAPS
-        disable_preemptive (true);
-    }
-    dprintf (3,("BGC: handle table marking"));
-    GCScan::GcScanHandles(background_promote,
-                                max_generation, max_generation,
-                                &sc);
-    concurrent_print_time_delta ("CRH");
-    current_bgc_state = bgc_mark_stack;
-    dprintf (2,("concurrent draining mark list"));
-    background_drain_mark_list (thread);
-    concurrent_print_time_delta ("CRS");
-    dprintf (2,("concurrent revisiting dirtied pages"));
-    revisit_written_pages (TRUE);
-    revisit_written_pages (TRUE);
-    concurrent_print_time_delta ("CRre");
-    enable_preemptive ();
-#if defined(MULTIPLE_HEAPS)
-    bgc_t_join.join(this, gc_join_concurrent_overflow);
-    if (bgc_t_join.joined())
-    {
-#ifdef USE_REGIONS
-        BOOL all_heaps_background_overflow_p = FALSE;
-#else //USE_REGIONS
-        uint8_t* all_heaps_max = 0;
-        uint8_t* all_heaps_min = MAX_PTR;
-#endif //USE_REGIONS
-        int i;
-        for (i = 0; i < n_heaps; i++)
-        {
-#ifdef USE_REGIONS
-            if (g_heaps[i]->background_overflow_p)
-                all_heaps_background_overflow_p = TRUE;
-#else //USE_REGIONS
-            dprintf (3, ("heap %d overflow max is %p, min is %p",
-                i,
-                g_heaps[i]->background_max_overflow_address,
-                g_heaps[i]->background_min_overflow_address));
-            if (all_heaps_max < g_heaps[i]->background_max_overflow_address)
-                all_heaps_max = g_heaps[i]->background_max_overflow_address;
-            if (all_heaps_min > g_heaps[i]->background_min_overflow_address)
-                all_heaps_min = g_heaps[i]->background_min_overflow_address;
-#endif //USE_REGIONS
-        }
-        for (i = 0; i < n_heaps; i++)
-        {
-#ifdef USE_REGIONS
-            g_heaps[i]->background_overflow_p = all_heaps_background_overflow_p;
-#else //USE_REGIONS
-            g_heaps[i]->background_max_overflow_address = all_heaps_max;
-            g_heaps[i]->background_min_overflow_address = all_heaps_min;
-#endif //USE_REGIONS
-        }
-        dprintf(3, ("Starting all bgc threads after updating the overflow info"));
-        bgc_t_join.restart();
-    }
-#endif //MULTIPLE_HEAPS
-    disable_preemptive (true);
-    dprintf (2, ("before CRov count: %zu", bgc_overflow_count));
-    bgc_overflow_count = 0;
-    background_process_mark_overflow (TRUE);
-    dprintf (2, ("after CRov count: %zu", bgc_overflow_count));
-    bgc_overflow_count = 0;
-    concurrent_print_time_delta ("CRov");
-    FIRE_EVENT(BGC1stConEnd);
-    dprintf (2, ("Stopping the EE"));
-    enable_preemptive ();
-#ifdef MULTIPLE_HEAPS
-    bgc_t_join.join(this, gc_join_suspend_ee);
-    if (bgc_t_join.joined())
-    {
-        bgc_threads_sync_event.Reset();
-        dprintf(3, ("Joining BGC threads for non concurrent final marking"));
-        bgc_t_join.restart();
-    }
-#endif //MULTIPLE_HEAPS
-    if (heap_number == 0)
-    {
-        enter_spin_lock (&gc_lock);
-        suspended_start_time = GetHighPrecisionTimeStamp();
-        bgc_suspend_EE ();
-        bgc_threads_sync_event.Set();
-    }
-    else
-    {
-        bgc_threads_sync_event.Wait(INFINITE, FALSE);
-        dprintf (2, ("bgc_threads_sync_event is signalled"));
-    }
-    assert (settings.concurrent);
-    assert (settings.condemned_generation == max_generation);
-    dprintf (2, ("clearing cm_in_progress"));
-    c_write (cm_in_progress, FALSE);
-    bgc_alloc_lock->check();
-    current_bgc_state = bgc_final_marking;
-    concurrent_print_time_delta ("CR");
-    FIRE_EVENT(BGC2ndNonConBegin);
-    mark_absorb_new_alloc();
-#ifdef FEATURE_EVENT_TRACE
-    static uint64_t current_mark_time = 0;
-    static uint64_t last_mark_time = 0;
-#endif //FEATURE_EVENT_TRACE
-#ifdef MULTIPLE_HEAPS
-    bgc_t_join.join(this, gc_join_after_absorb);
-    if (bgc_t_join.joined())
-#endif //MULTIPLE_HEAPS
-    {
-#ifdef BGC_SERVO_TUNING
-        bgc_tuning::record_bgc_sweep_start();
-#endif //BGC_SERVO_TUNING
-        GCToEEInterface::BeforeGcScanRoots(max_generation, /* is_bgc */ true, /* is_concurrent */ false);
-#ifdef FEATURE_EVENT_TRACE
-        informational_event_enabled_p = EVENT_ENABLED (GCMarkWithType);
-        if (informational_event_enabled_p)
-            last_mark_time = GetHighPrecisionTimeStamp();
-#endif //FEATURE_EVENT_TRACE
-#ifdef MULTIPLE_HEAPS
-        dprintf(3, ("Joining BGC threads after absorb"));
-        bgc_t_join.restart();
-#endif //MULTIPLE_HEAPS
-    }
-    sc.concurrent = FALSE;
-    total_soh_size = generation_sizes (generation_of (max_generation));
-    total_loh_size = generation_size (loh_generation);
-    total_poh_size = generation_size (poh_generation);
-    dprintf (GTC_LOG, ("FM: h%d: loh: %zd, soh: %zd, poh: %zd", heap_number, total_loh_size, total_soh_size, total_poh_size));
-#if defined(FEATURE_BASICFREEZE) && !defined(USE_REGIONS)
-    if (ro_segments_in_range)
-    {
-        dprintf (2, ("nonconcurrent marking in range ro segments"));
-        mark_ro_segments();
-        concurrent_print_time_delta ("NRRO");
-    }
-#endif //FEATURE_BASICFREEZE && !USE_REGIONS
-    dprintf (2, ("nonconcurrent marking stack roots"));
-    GCScan::GcScanRoots(background_promote,
-                            max_generation, max_generation,
-                            &sc);
-    concurrent_print_time_delta ("NRS");
-    finalize_queue->GcScanRoots(background_promote, heap_number, 0);
-    dprintf (2, ("nonconcurrent marking handle table"));
-    GCScan::GcScanHandles(background_promote,
-                                max_generation, max_generation,
-                                &sc);
-    concurrent_print_time_delta ("NRH");
-    dprintf (2,("---- (GC%zu)final going through written pages ----", VolatileLoad(&settings.gc_index)));
-    revisit_written_pages (FALSE);
-    concurrent_print_time_delta ("NRre LOH");
-    dprintf (2, ("before NR 1st Hov count: %zu", bgc_overflow_count));
-    bgc_overflow_count = 0;
-    dprintf (2, ("1st dependent handle scan and process mark overflow"));
-    GCScan::GcDhInitialScan(background_promote, max_generation, max_generation, &sc);
-    background_scan_dependent_handles (&sc);
-    concurrent_print_time_delta ("NR 1st Hov");
-    dprintf (2, ("after NR 1st Hov count: %zu", bgc_overflow_count));
-    bgc_overflow_count = 0;
-#ifdef MULTIPLE_HEAPS
-    bgc_t_join.join(this, gc_join_null_dead_short_weak);
-    if (bgc_t_join.joined())
-#endif //MULTIPLE_HEAPS
-    {
-#ifdef FEATURE_EVENT_TRACE
-        bgc_time_info[time_mark_sizedref] = 0;
-        record_mark_time (bgc_time_info[time_mark_roots], current_mark_time, last_mark_time);
-#endif //FEATURE_EVENT_TRACE
-#ifdef FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-        SoftwareWriteWatch::DisableForGCHeap();
-#endif // FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-        GCToEEInterface::AfterGcScanRoots (max_generation, max_generation, &sc);
-#ifdef MULTIPLE_HEAPS
-        dprintf(3, ("Joining BGC threads for short weak handle scan"));
-        bgc_t_join.restart();
-#endif //MULTIPLE_HEAPS
-    }
-    GCScan::GcShortWeakPtrScan(max_generation, max_generation, &sc);
-    concurrent_print_time_delta ("NR GcShortWeakPtrScan");
-    {
-#ifdef MULTIPLE_HEAPS
-        bgc_t_join.join(this, gc_join_scan_finalization);
-        if (bgc_t_join.joined())
-        {
-#endif //MULTIPLE_HEAPS
-#ifdef FEATURE_EVENT_TRACE
-            record_mark_time (bgc_time_info[time_mark_short_weak], current_mark_time, last_mark_time);
-#endif //FEATURE_EVENT_TRACE
-#ifdef MULTIPLE_HEAPS
-            dprintf(3, ("Joining BGC threads for finalization"));
-            bgc_t_join.restart();
-        }
-#endif //MULTIPLE_HEAPS
-        dprintf(3,("Marking finalization data"));
-        concurrent_print_time_delta ("NRj");
-        finalize_queue->ScanForFinalization (background_promote, max_generation, __this);
-        concurrent_print_time_delta ("NRF");
-    }
-    dprintf (2, ("before NR 2nd Hov count: %zu", bgc_overflow_count));
-    bgc_overflow_count = 0;
-    dprintf (2, ("2nd dependent handle scan and process mark overflow"));
-    background_scan_dependent_handles (&sc);
-    concurrent_print_time_delta ("NR 2nd Hov");
-#ifdef MULTIPLE_HEAPS
-    bgc_t_join.join(this, gc_join_null_dead_long_weak);
-    if (bgc_t_join.joined())
-#endif //MULTIPLE_HEAPS
-    {
-#ifdef FEATURE_EVENT_TRACE
-        record_mark_time (bgc_time_info[time_mark_scan_finalization], current_mark_time, last_mark_time);
-#endif //FEATURE_EVENT_TRACE
-#ifdef MULTIPLE_HEAPS
-        dprintf(2, ("Joining BGC threads for weak pointer deletion"));
-        bgc_t_join.restart();
-#endif //MULTIPLE_HEAPS
-    }
-    GCScan::GcWeakPtrScan (max_generation, max_generation, &sc);
-    concurrent_print_time_delta ("NR GcWeakPtrScan");
-#ifdef MULTIPLE_HEAPS
-    bgc_t_join.join(this, gc_join_null_dead_syncblk);
-    if (bgc_t_join.joined())
-#endif //MULTIPLE_HEAPS
-    {
-        dprintf (2, ("calling GcWeakPtrScanBySingleThread"));
-        GCScan::GcWeakPtrScanBySingleThread (max_generation, max_generation, &sc);
-#ifdef FEATURE_EVENT_TRACE
-        record_mark_time (bgc_time_info[time_mark_long_weak], current_mark_time, last_mark_time);
-#endif //FEATURE_EVENT_TRACE
-        concurrent_print_time_delta ("NR GcWeakPtrScanBySingleThread");
-#ifdef MULTIPLE_HEAPS
-        dprintf(2, ("Starting BGC threads for end of background mark phase"));
-        bgc_t_join.restart();
-#endif //MULTIPLE_HEAPS
-    }
-    dprintf (2, ("end of bgc mark: loh: %zu, poh: %zu, soh: %zu",
-                 generation_size (loh_generation),
-                 generation_size (poh_generation),
-                 generation_sizes (generation_of (max_generation))));
-    for (int gen_idx = max_generation; gen_idx < total_generation_count; gen_idx++)
-    {
-        generation* gen = generation_of (gen_idx);
-        dynamic_data* dd = dynamic_data_of (gen_idx);
-        dd_begin_data_size (dd) = generation_size (gen_idx) -
-                                  (generation_free_list_space (gen) + generation_free_obj_space (gen)) -
-                                   get_generation_start_size (gen_idx);
-        dd_survived_size (dd) = 0;
-        dd_pinned_survived_size (dd) = 0;
-        dd_artificial_pinned_survived_size (dd) = 0;
-        dd_added_pinned_size (dd) = 0;
-    }
-    for (int i = get_start_generation_index(); i < uoh_start_generation; i++)
-    {
-        heap_segment* seg = heap_segment_rw (generation_start_segment (generation_of (i)));
-        PREFIX_ASSUME(seg != NULL);
-        while (seg)
-        {
-            seg->flags &= ~heap_segment_flags_swept;
-#ifndef USE_REGIONS
-            if (heap_segment_allocated (seg) == heap_segment_mem (seg))
-            {
-                FATAL_GC_ERROR();
-            }
-            if (seg == ephemeral_heap_segment)
-            {
-                heap_segment_background_allocated (seg) = generation_allocation_start (generation_of (max_generation - 1));
-            }
-            else
-#endif //!USE_REGIONS
-            {
-                heap_segment_background_allocated (seg) = heap_segment_allocated (seg);
-            }
-            background_soh_size_end_mark += heap_segment_background_allocated (seg) - heap_segment_mem (seg);
-            dprintf (3333, ("h%d gen%d seg %zx (%p) background allocated is %p",
-                            heap_number, i, (size_t)(seg), heap_segment_mem (seg),
-                            heap_segment_background_allocated (seg)));
-            seg = heap_segment_next_rw (seg);
-        }
-    }
-    repair_allocation_contexts (FALSE);
-    dprintf (2, ("end of bgc mark: gen2 free list space: %zu, free obj space: %zu",
-        generation_free_list_space (generation_of (max_generation)),
-        generation_free_obj_space (generation_of (max_generation))));
-    dprintf(2,("---- (GC%zu)End of background mark phase ----", VolatileLoad(&settings.gc_index)));
-}
-#ifdef MULTIPLE_HEAPS
-void
-gc_heap::bgc_suspend_EE ()
-{
-    for (int i = 0; i < n_heaps; i++)
-    {
-        gc_heap::g_heaps[i]->reset_gc_done();
-    }
-    gc_started = TRUE;
-    dprintf (2, ("bgc_suspend_EE"));
-    GCToEEInterface::SuspendEE(SUSPEND_FOR_GC_PREP);
-    gc_started = FALSE;
-    for (int i = 0; i < n_heaps; i++)
-    {
-        gc_heap::g_heaps[i]->set_gc_done();
-    }
-}
-#else
-void
-gc_heap::bgc_suspend_EE ()
-{
-    reset_gc_done();
-    gc_started = TRUE;
-    dprintf (2, ("bgc_suspend_EE"));
-    GCToEEInterface::SuspendEE(SUSPEND_FOR_GC_PREP);
-    gc_started = FALSE;
-    set_gc_done();
-}
-#endif //MULTIPLE_HEAPS
-inline uint8_t* gc_heap::high_page (heap_segment* seg, BOOL concurrent_p)
-{
-#ifdef USE_REGIONS
-    assert (!concurrent_p || (heap_segment_gen_num (seg) >= max_generation));
-#else
-    if (concurrent_p)
-    {
-        uint8_t* end = ((seg == ephemeral_heap_segment) ?
-                     generation_allocation_start (generation_of (max_generation - 1)) :
-                     heap_segment_allocated (seg));
-        return align_lower_page (end);
-    }
-    else
-#endif //USE_REGIONS
-    {
-        return heap_segment_allocated (seg);
-    }
-}
-void gc_heap::revisit_written_page (uint8_t* page,
-                                    uint8_t* end,
-                                    BOOL concurrent_p,
-                                    uint8_t*& last_page,
-                                    uint8_t*& last_object,
-                                    BOOL large_objects_p,
-                                    size_t& num_marked_objects)
-{
-    uint8_t*   start_address = page;
-    uint8_t*   o             = 0;
-    int align_const = get_alignment_constant (!large_objects_p);
-    uint8_t* high_address = end;
-    uint8_t* current_lowest_address = background_saved_lowest_address;
-    uint8_t* current_highest_address = background_saved_highest_address;
-    BOOL no_more_loop_p = FALSE;
-    THREAD_FROM_HEAP;
-#ifndef MULTIPLE_HEAPS
-    const int thread = heap_number;
-#endif //!MULTIPLE_HEAPS
-    if (large_objects_p)
-    {
-        o = last_object;
-    }
-    else
-    {
-        if (((last_page + WRITE_WATCH_UNIT_SIZE) == page)
-            || (start_address <= last_object))
-        {
-            o = last_object;
-        }
-        else
-        {
-            o = find_first_object (start_address, last_object);
-            assert (o >= last_object);
-        }
-    }
-    dprintf (3,("page %zx start: %zx, %zx[ ",
-               (size_t)page, (size_t)o,
-               (size_t)(min (high_address, page + WRITE_WATCH_UNIT_SIZE))));
-    while (o < (min (high_address, page + WRITE_WATCH_UNIT_SIZE)))
-    {
-        size_t s;
-        if (concurrent_p && large_objects_p)
-        {
-            bgc_alloc_lock->bgc_mark_set (o);
-            if (((CObjectHeader*)o)->IsFree())
-            {
-                s = unused_array_size (o);
-            }
-            else
-            {
-                s = size (o);
-            }
-        }
-        else
-        {
-            s = size (o);
-        }
-        dprintf (3,("Considering object %zx(%s)", (size_t)o, (background_object_marked (o, FALSE) ? "bm" : "nbm")));
-        assert (Align (s) >= Align (min_obj_size));
-        uint8_t* next_o =  o + Align (s, align_const);
-        if (next_o >= start_address)
-        {
-#ifdef MULTIPLE_HEAPS
-            if (concurrent_p)
-            {
-                last_object = o;
-            }
-#endif //MULTIPLE_HEAPS
-            if (contain_pointers (o) &&
-                (!((o >= current_lowest_address) && (o < current_highest_address)) ||
-                background_marked (o)))
-            {
-                dprintf (3, ("going through %zx", (size_t)o));
-                go_through_object (method_table(o), o, s, poo, start_address, use_start, (o + s),
-                                    if ((uint8_t*)poo >= min (high_address, page + WRITE_WATCH_UNIT_SIZE))
-                                    {
-                                        no_more_loop_p = TRUE;
-                                        goto end_limit;
-                                    }
-                                    uint8_t* oo = VolatileLoadWithoutBarrier(poo);
-                                    num_marked_objects++;
-                                    background_mark_object (oo THREAD_NUMBER_ARG);
-                                );
-            }
-            else if (concurrent_p &&
-                     ((CObjectHeader*)o)->IsFree() &&
-                     (next_o > min (high_address, page + WRITE_WATCH_UNIT_SIZE)))
-            {
-                no_more_loop_p = TRUE;
-                goto end_limit;
-            }
-        }
-end_limit:
-        if (concurrent_p && large_objects_p)
-        {
-            bgc_alloc_lock->bgc_mark_done ();
-        }
-        if (no_more_loop_p)
-        {
-            break;
-        }
-        o = next_o;
-    }
-#ifdef MULTIPLE_HEAPS
-    if (concurrent_p)
-    {
-        assert (last_object < (min (high_address, page + WRITE_WATCH_UNIT_SIZE)));
-    }
-    else
-#endif //MULTIPLE_HEAPS
-    {
-        last_object = o;
-    }
-    dprintf (3,("Last object: %zx", (size_t)last_object));
-    last_page = align_write_watch_lower_page (o);
-    if (concurrent_p)
-    {
-        allow_fgc();
-    }
-}
-void gc_heap::revisit_written_pages (BOOL concurrent_p, BOOL reset_only_p)
-{
-    if (concurrent_p && !reset_only_p)
-    {
-        current_bgc_state = bgc_revisit_soh;
-    }
-    size_t total_dirtied_pages = 0;
-    size_t total_marked_objects = 0;
-    bool reset_watch_state = !!concurrent_p;
-    bool is_runtime_suspended = !concurrent_p;
-    BOOL small_object_segments = TRUE;
-    int start_gen_idx = get_start_generation_index();
-#ifdef USE_REGIONS
-    if (concurrent_p && !reset_only_p)
-    {
-        start_gen_idx = max_generation;
-    }
-#endif //USE_REGIONS
-    for (int i = start_gen_idx; i < total_generation_count; i++)
-    {
-        heap_segment* seg = heap_segment_rw (generation_start_segment (generation_of (i)));
-        PREFIX_ASSUME(seg != NULL);
-        while (seg)
-        {
-            uint8_t* base_address = (uint8_t*)heap_segment_mem (seg);
-            uintptr_t bcount = array_size;
-            uint8_t* last_page = 0;
-            uint8_t* last_object = heap_segment_mem (seg);
-            uint8_t* high_address = 0;
-            BOOL skip_seg_p = FALSE;
-            if (reset_only_p)
-            {
-                if ((heap_segment_mem (seg) >= background_saved_lowest_address) ||
-                    (heap_segment_reserved (seg) <= background_saved_highest_address))
-                {
-                    dprintf (3, ("h%d: sseg: %p(-%p)", heap_number,
-                        heap_segment_mem (seg), heap_segment_reserved (seg)));
-                    skip_seg_p = TRUE;
-                }
-            }
-            if (!skip_seg_p)
-            {
-                dprintf (3, ("looking at seg %zx", (size_t)last_object));
-                if (reset_only_p)
-                {
-                    base_address = max (base_address, background_saved_lowest_address);
-                    dprintf (3, ("h%d: reset only starting %p", heap_number, base_address));
-                }
-                dprintf (3, ("h%d: starting: %p, seg %p-%p", heap_number, base_address,
-                    heap_segment_mem (seg), heap_segment_reserved (seg)));
-                while (1)
-                {
-                    if (reset_only_p)
-                    {
-                        high_address = ((seg == ephemeral_heap_segment) ? alloc_allocated : heap_segment_allocated (seg));
-                        high_address = min (high_address, background_saved_highest_address);
-                    }
-                    else
-                    {
-                        high_address = high_page (seg, concurrent_p);
-                    }
-                    if ((base_address < high_address) &&
-                        (bcount >= array_size))
-                    {
-                        ptrdiff_t region_size = high_address - base_address;
-                        dprintf (3, ("h%d: gw: [%zx(%zd)", heap_number, (size_t)base_address, (size_t)region_size));
-#ifdef FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-                        if (!is_runtime_suspended)
-                        {
-                            enter_spin_lock(&gc_lock);
-                        }
-#endif // FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-                        get_write_watch_for_gc_heap (reset_watch_state, base_address, region_size,
-                                                     (void**)background_written_addresses,
-                                                     &bcount, is_runtime_suspended);
-#ifdef FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-                        if (!is_runtime_suspended)
-                        {
-                            leave_spin_lock(&gc_lock);
-                        }
-#endif // FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-                        if (bcount != 0)
-                        {
-                            total_dirtied_pages += bcount;
-                            dprintf (3, ("Found %zu pages [%zx, %zx[",
-                                            bcount, (size_t)base_address, (size_t)high_address));
-                        }
-                        if (!reset_only_p)
-                        {
-                            high_address = high_page (seg, concurrent_p);
-                            for (unsigned i = 0; i < bcount; i++)
-                            {
-                                uint8_t* page = (uint8_t*)background_written_addresses[i];
-                                dprintf (3, ("looking at page %d at %zx(h: %zx)", i,
-                                    (size_t)page, (size_t)high_address));
-                                if (page < high_address)
-                                {
-                                    revisit_written_page (page, high_address, concurrent_p,
-                                                          last_page, last_object,
-                                                          !small_object_segments,
-                                                          total_marked_objects);
-                                }
-                                else
-                                {
-                                    dprintf (3, ("page %d at %zx is >= %zx!", i, (size_t)page, (size_t)high_address));
-                                    assert (!"page shouldn't have exceeded limit");
-                                }
-                            }
-                        }
-                        if (bcount >= array_size){
-                            base_address = background_written_addresses [array_size-1] + WRITE_WATCH_UNIT_SIZE;
-                            bcount = array_size;
-                        }
-                    }
-                    else
-                    {
-                        break;
-                    }
-                }
-            }
-            seg = heap_segment_next_rw (seg);
-        }
-        if (i == soh_gen2)
-        {
-            if (!reset_only_p)
-            {
-                dprintf (GTC_LOG, ("h%d: SOH: dp:%zd; mo: %zd", heap_number, total_dirtied_pages, total_marked_objects));
-                fire_revisit_event (total_dirtied_pages, total_marked_objects, FALSE);
-                concurrent_print_time_delta (concurrent_p ? "CR SOH" : "NR SOH");
-                total_dirtied_pages = 0;
-                total_marked_objects = 0;
-            }
-            if (concurrent_p && !reset_only_p)
-            {
-                current_bgc_state = bgc_revisit_uoh;
-            }
-            small_object_segments = FALSE;
-            dprintf (3, ("now revisiting large object segments"));
-        }
-        else
-        {
-            if (reset_only_p)
-            {
-                dprintf (GTC_LOG, ("h%d: tdp: %zd", heap_number, total_dirtied_pages));
-            }
-            else
-            {
-                dprintf (GTC_LOG, ("h%d: LOH: dp:%zd; mo: %zd", heap_number, total_dirtied_pages, total_marked_objects));
-                fire_revisit_event (total_dirtied_pages, total_marked_objects, TRUE);
-            }
-        }
-    }
-}
-void gc_heap::background_grow_c_mark_list()
-{
-    assert (c_mark_list_index >= c_mark_list_length);
-    BOOL should_drain_p = FALSE;
-    THREAD_FROM_HEAP;
-#ifndef MULTIPLE_HEAPS
-    const int thread = heap_number;
-#endif //!MULTIPLE_HEAPS
-    dprintf (2, ("stack copy buffer overflow"));
-    uint8_t** new_c_mark_list = 0;
-    {
-        FAULT_NOT_FATAL();
-        if (c_mark_list_length >= (SIZE_T_MAX / (2 * sizeof (uint8_t*))))
-        {
-            should_drain_p = TRUE;
-        }
-        else
-        {
-            new_c_mark_list = new (nothrow) uint8_t*[c_mark_list_length*2];
-            if (new_c_mark_list == 0)
-            {
-                should_drain_p = TRUE;
-            }
-        }
-    }
-    if (should_drain_p)
-    {
-        dprintf (2, ("No more memory for the stacks copy, draining.."));
-        background_drain_mark_list (thread);
-    }
-    else
-    {
-        assert (new_c_mark_list);
-        memcpy (new_c_mark_list, c_mark_list, c_mark_list_length*sizeof(uint8_t*));
-        c_mark_list_length = c_mark_list_length*2;
-        dprintf (5555, ("h%d replacing mark list at %Ix with %Ix", heap_number, (size_t)c_mark_list, (size_t)new_c_mark_list));
-        delete[] c_mark_list;
-        c_mark_list = new_c_mark_list;
-    }
-}
-void gc_heap::background_promote_callback (Object** ppObject, ScanContext* sc,
-                                  uint32_t flags)
-{
-    UNREFERENCED_PARAMETER(sc);
-    assert (settings.concurrent);
-    THREAD_NUMBER_FROM_CONTEXT;
-#ifndef MULTIPLE_HEAPS
-    const int thread = 0;
-#endif //!MULTIPLE_HEAPS
-    uint8_t* o = (uint8_t*)*ppObject;
-    if (!is_in_find_object_range (o))
-    {
-        return;
-    }
-    HEAP_FROM_THREAD;
-    gc_heap* hp = gc_heap::heap_of (o);
-    if ((o < hp->background_saved_lowest_address) || (o >= hp->background_saved_highest_address))
-    {
-        return;
-    }
-    if (flags & GC_CALL_INTERIOR)
-    {
-        o = hp->find_object (o);
-        if (o == 0)
-            return;
-    }
-#ifdef FEATURE_CONSERVATIVE_GC
-    if (GCConfig::GetConservativeGC() && ((CObjectHeader*)o)->IsFree())
-    {
-        return;
-    }
-#endif //FEATURE_CONSERVATIVE_GC
-#ifdef _DEBUG
-    ((CObjectHeader*)o)->Validate();
-#endif //_DEBUG
-    dprintf (3, ("Concurrent Background Promote %zx", (size_t)o));
-    if (o && (size (o) > loh_size_threshold))
-    {
-        dprintf (3, ("Brc %zx", (size_t)o));
-    }
-    if (hpt->c_mark_list_index >= hpt->c_mark_list_length)
-    {
-        hpt->background_grow_c_mark_list();
-    }
-    dprintf (3, ("pushing %zx into mark_list", (size_t)o));
-    hpt->c_mark_list [hpt->c_mark_list_index++] = o;
-    STRESS_LOG3(LF_GC|LF_GCROOTS, LL_INFO1000000, "    GCHeap::Background Promote: Promote GC Root *%p = %p MT = %pT", ppObject, o, o ? ((Object*) o)->GetGCSafeMethodTable() : NULL);
-}
-void gc_heap::mark_absorb_new_alloc()
-{
-    fix_allocation_contexts (FALSE);
-    gen0_bricks_cleared = FALSE;
-    clear_gen0_bricks();
-}
-#ifdef DYNAMIC_HEAP_COUNT
-void gc_heap::add_to_bgc_th_creation_history (size_t gc_index, size_t count_created,
-                                              size_t count_created_th_existed, size_t count_creation_failed)
-{
-    if ((count_created != 0) || (count_created_th_existed != 0) || (count_creation_failed != 0))
-    {
-        dprintf (6666, ("ADDING to BGC th hist entry%d gc index %Id, created %d, %d th existed, %d failed",
-            bgc_th_creation_hist_index, gc_index, count_created, count_created_th_existed, count_creation_failed));
-        bgc_thread_creation_history* current_hist = &bgc_th_creation_hist[bgc_th_creation_hist_index];
-        current_hist->gc_index = gc_index;
-        current_hist->n_heaps = (short)n_heaps;
-        current_hist->count_created = (short)count_created;
-        current_hist->count_created_th_existed = (short)count_created_th_existed;
-        current_hist->count_creation_failed = (short)count_creation_failed;
-        bgc_th_creation_hist_index = (bgc_th_creation_hist_index + 1) % max_bgc_thread_creation_count;
-    }
-}
-#endif //DYNAMIC_HEAP_COUNT
-BOOL gc_heap::prepare_bgc_thread(gc_heap* gh)
-{
-    BOOL success = FALSE;
-    BOOL thread_created = FALSE;
-    dprintf (2, ("Preparing gc thread"));
-    gh->bgc_threads_timeout_cs.Enter();
-    if (!(gh->bgc_thread_running))
-    {
-        dprintf (2, ("GC thread not running"));
-        if (gh->bgc_thread == 0)
-        {
-#ifdef STRESS_DYNAMIC_HEAP_COUNT
-            int r = (int)gc_rand::get_rand (100);
-            bool try_to_create_p = (r > 10);
-            BOOL thread_created_p = (try_to_create_p ? create_bgc_thread (gh) : FALSE);
-            if (!thread_created_p)
-            {
-                dprintf (6666, ("h%d we failed to create the thread, %s", gh->heap_number, (try_to_create_p ? "tried" : "didn't try")));
-            }
-            if (thread_created_p)
-#else //STRESS_DYNAMIC_HEAP_COUNT
-            if (create_bgc_thread(gh))
-#endif //STRESS_DYNAMIC_HEAP_COUNT
-            {
-                success = TRUE;
-                thread_created = TRUE;
-#ifdef DYNAMIC_HEAP_COUNT
-                bgc_th_count_created++;
-#endif //DYNAMIC_HEAP_COUNT
-            }
-            else
-            {
-#ifdef DYNAMIC_HEAP_COUNT
-                bgc_th_count_creation_failed++;
-#endif //DYNAMIC_HEAP_COUNT
-            }
-        }
-        else
-        {
-#ifdef DYNAMIC_HEAP_COUNT
-            bgc_th_count_created_th_existed++;
-            dprintf (6666, ("h%d we cannot have a thread that runs yet CreateThread reported it failed to create it", gh->heap_number));
-#endif //DYNAMIC_HEAP_COUNT
-            assert (!"GCToEEInterface::CreateThread returned FALSE yet the thread was created!");
-        }
-    }
-    else
-    {
-        dprintf (3, ("GC thread already running"));
-        success = TRUE;
-    }
-    gh->bgc_threads_timeout_cs.Leave();
-    if(thread_created)
-        FIRE_EVENT(GCCreateConcurrentThread_V1);
-    return success;
-}
-BOOL gc_heap::create_bgc_thread(gc_heap* gh)
-{
-    assert (background_gc_done_event.IsValid());
-    gh->bgc_thread_running = GCToEEInterface::CreateThread(gh->bgc_thread_stub, gh, true, ".NET BGC");
-    return gh->bgc_thread_running;
-}
-BOOL gc_heap::create_bgc_threads_support (int number_of_heaps)
-{
-    BOOL ret = FALSE;
-    dprintf (3, ("Creating concurrent GC thread for the first time"));
-    if (!background_gc_done_event.CreateManualEventNoThrow(TRUE))
-    {
-        goto cleanup;
-    }
-    if (!bgc_threads_sync_event.CreateManualEventNoThrow(FALSE))
-    {
-        goto cleanup;
-    }
-    if (!ee_proceed_event.CreateAutoEventNoThrow(FALSE))
-    {
-        goto cleanup;
-    }
-    if (!bgc_start_event.CreateManualEventNoThrow(FALSE))
-    {
-        goto cleanup;
-    }
-#ifdef MULTIPLE_HEAPS
-    bgc_t_join.init (number_of_heaps, join_flavor_bgc);
-#else
-    UNREFERENCED_PARAMETER(number_of_heaps);
-#endif //MULTIPLE_HEAPS
-    ret = TRUE;
-cleanup:
-    if (!ret)
-    {
-        if (background_gc_done_event.IsValid())
-        {
-            background_gc_done_event.CloseEvent();
-        }
-        if (bgc_threads_sync_event.IsValid())
-        {
-            bgc_threads_sync_event.CloseEvent();
-        }
-        if (ee_proceed_event.IsValid())
-        {
-            ee_proceed_event.CloseEvent();
-        }
-        if (bgc_start_event.IsValid())
-        {
-            bgc_start_event.CloseEvent();
-        }
-    }
-    return ret;
-}
-BOOL gc_heap::create_bgc_thread_support()
-{
-    uint8_t** parr;
-    parr = new (nothrow) uint8_t*[1 + OS_PAGE_SIZE / MIN_OBJECT_SIZE];
-    if (!parr)
-    {
-        return FALSE;
-    }
-    make_c_mark_list (parr);
-    return TRUE;
-}
-int gc_heap::check_for_ephemeral_alloc()
-{
-    int gen = ((settings.reason == reason_oos_soh) ? (max_generation - 1) : -1);
-    if (gen == -1)
-    {
-#ifdef MULTIPLE_HEAPS
-        for (int heap_index = 0; heap_index < n_heaps; heap_index++)
-#endif //MULTIPLE_HEAPS
-        {
-            for (int i = 0; i < max_generation; i++)
-            {
-#ifdef MULTIPLE_HEAPS
-                if (g_heaps[heap_index]->get_new_allocation (i) <= 0)
-#else
-                if (get_new_allocation (i) <= 0)
-#endif //MULTIPLE_HEAPS
-                {
-                    gen = max (gen, i);
-                }
-                else
-                    break;
-            }
-        }
-    }
-    return gen;
-}
-void gc_heap::wait_to_proceed()
-{
-    assert (background_gc_done_event.IsValid());
-    assert (bgc_start_event.IsValid());
-    user_thread_wait(&ee_proceed_event, FALSE);
-}
-void gc_heap::start_c_gc()
-{
-    assert (background_gc_done_event.IsValid());
-    assert (bgc_start_event.IsValid());
-    background_gc_done_event.Wait(INFINITE, FALSE);
-    background_gc_done_event.Reset();
-    bgc_start_event.Set();
-}
-void gc_heap::do_background_gc()
-{
-    dprintf (2, ("starting a BGC"));
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < n_heaps; i++)
-    {
-        g_heaps[i]->init_background_gc();
-    }
-#else
-    init_background_gc();
-#endif //MULTIPLE_HEAPS
-#ifdef BGC_SERVO_TUNING
-    bgc_tuning::record_bgc_start();
-#endif //BGC_SERVO_TUNING
-    start_c_gc ();
-    wait_to_proceed();
-}
-void gc_heap::kill_gc_thread()
-{
-    background_gc_done_event.CloseEvent();
-    bgc_start_event.CloseEvent();
-    bgc_threads_timeout_cs.Destroy();
-    bgc_thread = 0;
-}
-void gc_heap::bgc_thread_function()
-{
-    assert (background_gc_done_event.IsValid());
-    assert (bgc_start_event.IsValid());
-    dprintf (3, ("gc_thread thread starting..."));
-    BOOL do_exit = FALSE;
-    bool cooperative_mode = true;
-    bgc_thread_id.SetToCurrentThread();
-    dprintf (1, ("bgc_thread_id is set to %x", (uint32_t)GCToOSInterface::GetCurrentThreadIdForLogging()));
-    while (1)
-    {
-        dprintf (6666, ("h%d bgc thread: waiting...", heap_number));
-        cooperative_mode = enable_preemptive ();
-        uint32_t result = bgc_start_event.Wait(
-#ifdef _DEBUG
-#ifdef MULTIPLE_HEAPS
-                                             INFINITE,
-#else
-                                             2000,
-#endif //MULTIPLE_HEAPS
-#else //_DEBUG
-#ifdef MULTIPLE_HEAPS
-                                             INFINITE,
-#else
-                                             20000,
-#endif //MULTIPLE_HEAPS
-#endif //_DEBUG
-            FALSE);
-        dprintf (2, ("gc thread: finished waiting"));
-        if (result == WAIT_TIMEOUT)
-        {
-            dprintf (1, ("GC thread timeout"));
-            bgc_threads_timeout_cs.Enter();
-            if (!keep_bgc_threads_p)
-            {
-                dprintf (2, ("GC thread exiting"));
-                bgc_thread_running = FALSE;
-                bgc_thread = 0;
-                bgc_thread_id.Clear();
-                do_exit = TRUE;
-            }
-            bgc_threads_timeout_cs.Leave();
-            if (do_exit)
-                break;
-            else
-            {
-                dprintf (3, ("GC thread needed, not exiting"));
-                continue;
-            }
-        }
-#ifdef STRESS_DYNAMIC_HEAP_COUNT
-        if (n_heaps <= heap_number)
-        {
-            uint32_t delay_ms = (uint32_t)gc_rand::get_rand (200);
-            GCToOSInterface::Sleep (delay_ms);
-        }
-#endif //STRESS_DYNAMIC_HEAP_COUNT
-        if (!settings.concurrent)
-        {
-            dprintf (6666, ("h%d no concurrent GC needed, exiting", heap_number));
-#ifdef STRESS_DYNAMIC_HEAP_COUNT
-            flush_gc_log (true);
-            GCToOSInterface::DebugBreak();
-#endif
-            break;
-        }
-#ifdef DYNAMIC_HEAP_COUNT
-        if (n_heaps <= heap_number)
-        {
-            Interlocked::Increment (&dynamic_heap_count_data.idle_bgc_thread_count);
-            add_to_bgc_hc_history (hc_record_bgc_inactive);
-            dprintf (6666, ("BGC%Id h%d going idle (%d heaps), idle count is now %d",
-                VolatileLoadWithoutBarrier (&settings.gc_index), heap_number, n_heaps, VolatileLoadWithoutBarrier (&dynamic_heap_count_data.idle_bgc_thread_count)));
-            bgc_idle_thread_event.Wait(INFINITE, FALSE);
-            dprintf (6666, ("BGC%Id h%d woke from idle (%d heaps), idle count is now %d",
-                VolatileLoadWithoutBarrier (&settings.gc_index), heap_number, n_heaps, VolatileLoadWithoutBarrier (&dynamic_heap_count_data.idle_bgc_thread_count)));
-            continue;
-        }
-        else
-        {
-            if (heap_number == 0)
-            {
-                const int spin_count = 1024;
-                int idle_bgc_thread_count = total_bgc_threads - n_heaps;
-                dprintf (6666, ("n_heaps %d, total %d bgc threads, bgc idle should be %d and is %d",
-                    n_heaps, total_bgc_threads, idle_bgc_thread_count, VolatileLoadWithoutBarrier (&dynamic_heap_count_data.idle_bgc_thread_count)));
-                if (idle_bgc_thread_count != dynamic_heap_count_data.idle_bgc_thread_count)
-                {
-                    dprintf (6666, ("current idle is %d, trying to get to %d",
-                        VolatileLoadWithoutBarrier (&dynamic_heap_count_data.idle_bgc_thread_count), idle_bgc_thread_count));
-                    spin_and_wait (spin_count, (idle_bgc_thread_count == dynamic_heap_count_data.idle_bgc_thread_count));
-                }
-            }
-            add_to_bgc_hc_history (hc_record_bgc_active);
-        }
-#endif //DYNAMIC_HEAP_COUNT
-        if (heap_number == 0)
-        {
-            gc_background_running = TRUE;
-            dprintf (6666, (ThreadStressLog::gcStartBgcThread(), heap_number,
-                generation_free_list_space (generation_of (max_generation)),
-                generation_free_obj_space (generation_of (max_generation)),
-                dd_fragmentation (dynamic_data_of (max_generation))));
-        }
-        gc1();
-#ifndef DOUBLY_LINKED_FL
-        current_bgc_state = bgc_not_in_process;
-#endif //!DOUBLY_LINKED_FL
-        enable_preemptive ();
-#ifdef MULTIPLE_HEAPS
-        bgc_t_join.join(this, gc_join_done);
-        if (bgc_t_join.joined())
-#endif //MULTIPLE_HEAPS
-        {
-            enter_spin_lock (&gc_lock);
-            dprintf (SPINLOCK_LOG, ("bgc Egc"));
-            bgc_start_event.Reset();
-            do_post_gc();
-#ifdef MULTIPLE_HEAPS
-            for (int gen = max_generation; gen < total_generation_count; gen++)
-            {
-                size_t desired_per_heap = 0;
-                size_t total_desired = 0;
-                gc_heap* hp = 0;
-                dynamic_data* dd;
-                for (int i = 0; i < n_heaps; i++)
-                {
-                    hp = g_heaps[i];
-                    dd = hp->dynamic_data_of (gen);
-                    size_t temp_total_desired = total_desired + dd_desired_allocation (dd);
-                    if (temp_total_desired < total_desired)
-                    {
-                        total_desired = (size_t)MAX_PTR;
-                        break;
-                    }
-                    total_desired = temp_total_desired;
-                }
-                desired_per_heap = Align ((total_desired/n_heaps), get_alignment_constant (FALSE));
-                if (gen >= loh_generation)
-                {
-                    desired_per_heap = exponential_smoothing (gen, dd_collection_count (dynamic_data_of (max_generation)), desired_per_heap);
-                }
-                for (int i = 0; i < n_heaps; i++)
-                {
-                    hp = gc_heap::g_heaps[i];
-                    dd = hp->dynamic_data_of (gen);
-                    dd_desired_allocation (dd) = desired_per_heap;
-                    dd_gc_new_allocation (dd) = desired_per_heap;
-                    dd_new_allocation (dd) = desired_per_heap;
-                }
-            }
-            fire_pevents();
-#endif //MULTIPLE_HEAPS
-#ifdef DYNAMIC_HEAP_COUNT
-            if (trigger_bgc_for_rethreading_p)
-            {
-                trigger_bgc_for_rethreading_p = false;
-            }
-#endif //DYNAMIC_HEAP_COUNT
-            c_write (settings.concurrent, FALSE);
-            gc_background_running = FALSE;
-            keep_bgc_threads_p = FALSE;
-            background_gc_done_event.Set();
-            dprintf (SPINLOCK_LOG, ("bgc Lgc"));
-            leave_spin_lock (&gc_lock);
-#ifdef MULTIPLE_HEAPS
-            dprintf(1, ("End of BGC"));
-            bgc_t_join.restart();
-#endif //MULTIPLE_HEAPS
-        }
-    }
-    FIRE_EVENT(GCTerminateConcurrentThread_V1);
-    dprintf (3, ("bgc_thread thread exiting"));
-    return;
-}
-#ifdef BGC_SERVO_TUNING
-bool gc_heap::bgc_tuning::stepping_trigger (uint32_t current_memory_load, size_t current_gen2_count)
-{
-    if (!bgc_tuning::enable_fl_tuning)
-    {
-        return false;
-    }
-    bool stepping_trigger_p = false;
-    if (use_stepping_trigger_p)
-    {
-        dprintf (BGC_TUNING_LOG, ("current ml: %d, goal: %d",
-            current_memory_load, memory_load_goal));
-        if ((current_memory_load <= (memory_load_goal * 2 / 3)) ||
-            ((memory_load_goal > current_memory_load) &&
-             ((memory_load_goal - current_memory_load) > (stepping_interval * 3))))
-        {
-            int memory_load_delta = (int)current_memory_load - (int)last_stepping_mem_load;
-            if (memory_load_delta >= (int)stepping_interval)
-            {
-                stepping_trigger_p = (current_gen2_count == last_stepping_bgc_count);
-                if (stepping_trigger_p)
-                {
-                    current_gen2_count++;
-                }
-                dprintf (BGC_TUNING_LOG, ("current ml: %u - %u = %d (>= %u), gen2 count: %zu->%zu, stepping trigger: %s ",
-                    current_memory_load, last_stepping_mem_load, memory_load_delta, stepping_interval,
-                    last_stepping_bgc_count, current_gen2_count,
-                    (stepping_trigger_p ? "yes" : "no")));
-                last_stepping_mem_load = current_memory_load;
-                last_stepping_bgc_count = current_gen2_count;
-            }
-        }
-        else
-        {
-            use_stepping_trigger_p = false;
-        }
-    }
-    return stepping_trigger_p;
-}
-bool gc_heap::bgc_tuning::should_trigger_bgc_loh()
-{
-    if (fl_tuning_triggered)
-    {
-#ifdef MULTIPLE_HEAPS
-        gc_heap* hp = g_heaps[0];
-#else
-        gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-        if (!(gc_heap::background_running_p()))
-        {
-            size_t current_alloc = get_total_servo_alloc (loh_generation);
-            tuning_calculation* current_gen_calc = &gen_calc[loh_generation - max_generation];
-            if (current_alloc < current_gen_calc->last_bgc_end_alloc)
-            {
-                dprintf (BGC_TUNING_LOG, ("BTL: current alloc: %zd, last alloc: %zd?",
-                    current_alloc, current_gen_calc->last_bgc_end_alloc));
-            }
-            bool trigger_p = ((current_alloc - current_gen_calc->last_bgc_end_alloc) >= current_gen_calc->alloc_to_trigger);
-            dprintf (2, ("BTL3: LOH a %zd, la: %zd(%zd), %zd",
-                    current_alloc, current_gen_calc->last_bgc_end_alloc,
-                    (current_alloc - current_gen_calc->last_bgc_end_alloc),
-                    current_gen_calc->alloc_to_trigger));
-            if (trigger_p)
-            {
-                dprintf (BGC_TUNING_LOG, ("BTL3: LOH detected (%zd - %zd) >= %zd, TRIGGER",
-                        current_alloc, current_gen_calc->last_bgc_end_alloc, current_gen_calc->alloc_to_trigger));
-                return true;
-            }
-        }
-    }
-    return false;
-}
-bool gc_heap::bgc_tuning::should_trigger_bgc()
-{
-    if (!bgc_tuning::enable_fl_tuning || gc_heap::background_running_p())
-    {
-        return false;
-    }
-    if (settings.reason == reason_bgc_tuning_loh)
-    {
-        bgc_tuning::next_bgc_p = true;
-        dprintf (BGC_TUNING_LOG, ("BTL LOH triggered"));
-        return true;
-    }
-    if (!bgc_tuning::next_bgc_p &&
-        !fl_tuning_triggered &&
-        (gc_heap::settings.entry_memory_load >= (memory_load_goal * 2 / 3)) &&
-        (gc_heap::full_gc_counts[gc_type_background] >= 2))
-    {
-        next_bgc_p = true;
-        gen_calc[0].first_alloc_to_trigger = gc_heap::get_total_servo_alloc (max_generation);
-        gen_calc[1].first_alloc_to_trigger = gc_heap::get_total_servo_alloc (loh_generation);
-        dprintf (BGC_TUNING_LOG, ("BTL[GTC] mem high enough: %d(goal: %d), %zd BGCs done, g2a=%zd, g3a=%zd, trigger FL tuning!",
-            gc_heap::settings.entry_memory_load, memory_load_goal,
-            gc_heap::full_gc_counts[gc_type_background],
-            gen_calc[0].first_alloc_to_trigger,
-            gen_calc[1].first_alloc_to_trigger));
-    }
-    if (bgc_tuning::next_bgc_p)
-    {
-        dprintf (BGC_TUNING_LOG, ("BTL started FL tuning"));
-        return true;
-    }
-    if (!fl_tuning_triggered)
-    {
-        return false;
-    }
-    int index = 0;
-    bgc_tuning::tuning_calculation* current_gen_calc = 0;
-    index = 0;
-    current_gen_calc = &bgc_tuning::gen_calc[index];
-#ifdef MULTIPLE_HEAPS
-    gc_heap* hp = g_heaps[0];
-#else
-    gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-    size_t current_gen1_index = dd_collection_count (hp->dynamic_data_of (max_generation - 1));
-    size_t gen1_so_far = current_gen1_index - gen1_index_last_bgc_end;
-    if (current_gen_calc->alloc_to_trigger > 0)
-    {
-        size_t current_alloc = get_total_servo_alloc (max_generation);
-        if ((current_alloc - current_gen_calc->last_bgc_end_alloc) >= current_gen_calc->alloc_to_trigger)
-        {
-            dprintf (BGC_TUNING_LOG, ("BTL2: SOH detected (%zd - %zd) >= %zd, TRIGGER",
-                    current_alloc, current_gen_calc->last_bgc_end_alloc, current_gen_calc->alloc_to_trigger));
-            settings.reason = reason_bgc_tuning_soh;
-            return true;
-        }
-    }
-    return false;
-}
-bool gc_heap::bgc_tuning::should_delay_alloc (int gen_number)
-{
-    if ((gen_number != max_generation) || !bgc_tuning::enable_fl_tuning)
-        return false;
-    if (current_c_gc_state == c_gc_state_planning)
-    {
-        int i = 0;
-#ifdef MULTIPLE_HEAPS
-        for (; i < gc_heap::n_heaps; i++)
-        {
-            gc_heap* hp = gc_heap::g_heaps[i];
-            size_t current_fl_size = generation_free_list_space (hp->generation_of (max_generation));
-            size_t last_bgc_fl_size = hp->bgc_maxgen_end_fl_size;
-#else
-        {
-            size_t current_fl_size = generation_free_list_space (generation_of (max_generation));
-            size_t last_bgc_fl_size = bgc_maxgen_end_fl_size;
-#endif //MULTIPLE_HEAPS
-            if (last_bgc_fl_size)
-            {
-                float current_flr = (float) current_fl_size / (float)last_bgc_fl_size;
-                if (current_flr < 0.4)
-                {
-                    dprintf (BGC_TUNING_LOG, ("BTL%d h%d last fl %zd, curr fl %zd (%.3f) d1",
-                            gen_number, i, last_bgc_fl_size, current_fl_size, current_flr));
-                    return true;
-                }
-            }
-        }
-    }
-    return false;
-}
-void gc_heap::bgc_tuning::update_bgc_start (int gen_number, size_t num_gen1s_since_end)
-{
-    int tuning_data_index = gen_number - max_generation;
-    tuning_calculation* current_gen_calc = &gen_calc[tuning_data_index];
-    tuning_stats* current_gen_stats = &gen_stats[tuning_data_index];
-    size_t total_generation_size = get_total_generation_size (gen_number);
-    ptrdiff_t current_bgc_fl_size = get_total_generation_fl_size (gen_number);
-    double physical_gen_flr = (double)current_bgc_fl_size * 100.0 / (double)total_generation_size;
-    ptrdiff_t artificial_additional_fl = 0;
-    if (fl_tuning_triggered)
-    {
-        artificial_additional_fl = ((current_gen_calc->end_gen_size_goal > total_generation_size) ? (current_gen_calc->end_gen_size_goal - total_generation_size) : 0);
-        total_generation_size += artificial_additional_fl;
-        current_bgc_fl_size += artificial_additional_fl;
-    }
-    current_gen_calc->current_bgc_start_flr = (double)current_bgc_fl_size * 100.0 / (double)total_generation_size;
-    size_t current_alloc = get_total_servo_alloc (gen_number);
-    dprintf (BGC_TUNING_LOG, ("BTL%d: st a: %zd, la: %zd",
-        gen_number, current_alloc, current_gen_stats->last_alloc));
-    current_gen_stats->last_alloc_end_to_start = current_alloc - current_gen_stats->last_alloc;
-    current_gen_stats->last_alloc = current_alloc;
-    current_gen_calc->actual_alloc_to_trigger = current_alloc - current_gen_calc->last_bgc_end_alloc;
-    dprintf (BGC_TUNING_LOG, ("BTL%d: st: %zd g1s (%zd->%zd/gen1) since end, flr: %.3f(afl: %zd, %.3f)",
-             gen_number, actual_num_gen1s_to_trigger,
-             current_gen_stats->last_alloc_end_to_start,
-             (num_gen1s_since_end ? (current_gen_stats->last_alloc_end_to_start / num_gen1s_since_end) : 0),
-             current_gen_calc->current_bgc_start_flr, artificial_additional_fl, physical_gen_flr));
-}
-void gc_heap::bgc_tuning::record_bgc_start()
-{
-    if (!bgc_tuning::enable_fl_tuning)
-        return;
-    uint64_t elapsed_time_so_far = GetHighPrecisionTimeStamp() - process_start_time;
-    size_t current_gen1_index = get_current_gc_index (max_generation - 1);
-    dprintf (BGC_TUNING_LOG, ("BTL: g2t[st][g1 %zd]: %0.3f minutes",
-        current_gen1_index,
-        (double)elapsed_time_so_far / (double)1000000 / (double)60));
-    actual_num_gen1s_to_trigger = current_gen1_index - gen1_index_last_bgc_end;
-    gen1_index_last_bgc_start = current_gen1_index;
-    update_bgc_start (max_generation, actual_num_gen1s_to_trigger);
-    update_bgc_start (loh_generation, actual_num_gen1s_to_trigger);
-}
-double convert_range (double lower, double upper, double num, double percentage)
-{
-    double d = num - lower;
-    if (d < 0.0)
-        return 0.0;
-    else
-    {
-        d = min ((upper - lower), d);
-        return (d * percentage);
-    }
-}
-double calculate_gradual_d (double delta_double, double step)
-{
-    bool changed_sign = false;
-    if (delta_double < 0.0)
-    {
-        delta_double = -delta_double;
-        changed_sign = true;
-    }
-    double res = 0;
-    double current_lower_limit = 0;
-    double current_ratio = 1.0;
-    while (current_ratio > 0.22)
-    {
-        res += convert_range (current_lower_limit, (current_lower_limit + step), delta_double, current_ratio);
-        current_lower_limit += step;
-        current_ratio *= 0.6;
-    }
-    if (changed_sign)
-        res = -res;
-    return res;
-}
-void gc_heap::bgc_tuning::update_bgc_sweep_start (int gen_number, size_t num_gen1s_since_start)
-{
-    int tuning_data_index = gen_number - max_generation;
-    tuning_calculation* current_gen_calc = &gen_calc[tuning_data_index];
-    tuning_stats* current_gen_stats = &gen_stats[tuning_data_index];
-    size_t total_generation_size = 0;
-    ptrdiff_t current_bgc_fl_size = 0;
-    total_generation_size = get_total_generation_size (gen_number);
-    current_bgc_fl_size = get_total_generation_fl_size (gen_number);
-    double physical_gen_flr = (double)current_bgc_fl_size * 100.0 / (double)total_generation_size;
-    ptrdiff_t artificial_additional_fl = 0;
-    if (fl_tuning_triggered)
-    {
-        artificial_additional_fl = ((current_gen_calc->end_gen_size_goal > total_generation_size) ? (current_gen_calc->end_gen_size_goal - total_generation_size) : 0);
-        total_generation_size += artificial_additional_fl;
-        current_bgc_fl_size += artificial_additional_fl;
-    }
-    current_gen_calc->current_bgc_sweep_flr = (double)current_bgc_fl_size * 100.0 / (double)total_generation_size;
-    size_t current_alloc = get_total_servo_alloc (gen_number);
-    dprintf (BGC_TUNING_LOG, ("BTL%d: sw a: %zd, la: %zd",
-        gen_number, current_alloc, current_gen_stats->last_alloc));
-    current_gen_stats->last_alloc_start_to_sweep = current_alloc - current_gen_stats->last_alloc;
-    current_gen_stats->last_alloc = 0;
-#ifdef SIMPLE_DPRINTF
-    dprintf (BGC_TUNING_LOG, ("BTL%d: sflr: %.3f%%->%.3f%% (%zd->%zd, %zd->%zd) (%zd:%zd-%zd/gen1) since start (afl: %zd, %.3f)",
-             gen_number,
-             current_gen_calc->last_bgc_flr, current_gen_calc->current_bgc_sweep_flr,
-             current_gen_calc->last_bgc_size, total_generation_size,
-             current_gen_stats->last_bgc_fl_size, current_bgc_fl_size,
-             num_gen1s_since_start, current_gen_stats->last_alloc_start_to_sweep,
-             (num_gen1s_since_start? (current_gen_stats->last_alloc_start_to_sweep / num_gen1s_since_start) : 0),
-             artificial_additional_fl, physical_gen_flr));
-#endif //SIMPLE_DPRINTF
-}
-void gc_heap::bgc_tuning::record_bgc_sweep_start()
-{
-    if (!bgc_tuning::enable_fl_tuning)
-        return;
-    size_t current_gen1_index = get_current_gc_index (max_generation - 1);
-    size_t num_gen1s_since_start = current_gen1_index - gen1_index_last_bgc_start;
-    gen1_index_last_bgc_sweep = current_gen1_index;
-    uint64_t elapsed_time_so_far = GetHighPrecisionTimeStamp() - process_start_time;
-    dprintf (BGC_TUNING_LOG, ("BTL: g2t[sw][g1 %zd]: %0.3f minutes",
-        current_gen1_index,
-        (double)elapsed_time_so_far / (double)1000000 / (double)60));
-    update_bgc_sweep_start (max_generation, num_gen1s_since_start);
-    update_bgc_sweep_start (loh_generation, num_gen1s_since_start);
-}
-void gc_heap::bgc_tuning::calculate_tuning (int gen_number, bool use_this_loop_p)
-{
-    BOOL use_kd_p = enable_kd;
-    BOOL use_ki_p = enable_ki;
-    BOOL use_smooth_p = enable_smooth;
-    BOOL use_tbh_p = enable_tbh;
-    BOOL use_ff_p = enable_ff;
-    int tuning_data_index = gen_number - max_generation;
-    tuning_calculation* current_gen_calc = &gen_calc[tuning_data_index];
-    tuning_stats* current_gen_stats = &gen_stats[tuning_data_index];
-    bgc_size_data* data = &current_bgc_end_data[tuning_data_index];
-    size_t total_generation_size = data->gen_size;
-    size_t current_bgc_fl = data->gen_fl_size;
-    size_t current_bgc_surv_size = get_total_surv_size (gen_number);
-    size_t current_bgc_begin_data_size = get_total_begin_data_size (gen_number);
-    size_t current_alloc = get_total_servo_alloc (gen_number);
-    dprintf (BGC_TUNING_LOG, ("BTL%d: en a: %zd, la: %zd, lbgca: %zd",
-        gen_number, current_alloc, current_gen_stats->last_alloc, current_gen_calc->last_bgc_end_alloc));
-    double current_bgc_surv_rate = (current_bgc_begin_data_size == 0) ?
-                                    0 : ((double)current_bgc_surv_size * 100.0 / (double)current_bgc_begin_data_size);
-    current_gen_stats->last_alloc_sweep_to_end = current_alloc - current_gen_stats->last_alloc;
-    size_t gen1_index = get_current_gc_index (max_generation - 1);
-    size_t gen2_index = get_current_gc_index (max_generation);
-    size_t num_gen1s_since_sweep = gen1_index - gen1_index_last_bgc_sweep;
-    size_t num_gen1s_bgc_end = gen1_index - gen1_index_last_bgc_end;
-    size_t gen_end_size_goal = current_gen_calc->end_gen_size_goal;
-    double gen_sweep_flr_goal = current_gen_calc->sweep_flr_goal;
-    size_t last_gen_alloc_to_trigger = current_gen_calc->alloc_to_trigger;
-    size_t gen_actual_alloc_to_trigger = current_gen_calc->actual_alloc_to_trigger;
-    size_t last_gen_alloc_to_trigger_0 = current_gen_calc->alloc_to_trigger_0;
-    double current_end_to_sweep_flr = current_gen_calc->last_bgc_flr - current_gen_calc->current_bgc_sweep_flr;
-    bool current_sweep_above_p = (current_gen_calc->current_bgc_sweep_flr > gen_sweep_flr_goal);
-#ifdef SIMPLE_DPRINTF
-    dprintf (BGC_TUNING_LOG, ("BTL%d: sflr: c %.3f (%s), p %s, palloc: %zd, aalloc %zd(%s)",
-        gen_number,
-        current_gen_calc->current_bgc_sweep_flr,
-        (current_sweep_above_p ? "above" : "below"),
-        (current_gen_calc->last_sweep_above_p ? "above" : "below"),
-        last_gen_alloc_to_trigger,
-        current_gen_calc->actual_alloc_to_trigger,
-        (use_this_loop_p ? "this" : "last")));
-    dprintf (BGC_TUNING_LOG, ("BTL%d-en[g1: %zd, g2: %zd]: end fl: %zd (%zd: S-%zd, %.3f%%->%.3f%%)",
-            gen_number,
-            gen1_index, gen2_index, current_bgc_fl,
-            total_generation_size, current_bgc_surv_size,
-            current_gen_stats->last_bgc_surv_rate, current_bgc_surv_rate));
-    dprintf (BGC_TUNING_LOG, ("BTLS%d sflr: %.3f, end-start: %zd(%zd), start-sweep: %zd(%zd), sweep-end: %zd(%zd)",
-            gen_number,
-            current_gen_calc->current_bgc_sweep_flr,
-            (gen1_index_last_bgc_start - gen1_index_last_bgc_end), current_gen_stats->last_alloc_end_to_start,
-            (gen1_index_last_bgc_sweep - gen1_index_last_bgc_start), current_gen_stats->last_alloc_start_to_sweep,
-            num_gen1s_since_sweep, current_gen_stats->last_alloc_sweep_to_end));
-#endif //SIMPLE_DPRINTF
-    size_t saved_alloc_to_trigger = 0;
-    double current_alloc_to_trigger = 0.0;
-    if (!fl_tuning_triggered && use_tbh_p)
-    {
-        current_gen_calc->alloc_to_trigger_0 = current_gen_calc->actual_alloc_to_trigger;
-        dprintf (BGC_TUNING_LOG, ("BTL%d[g1: %zd]: not in FL tuning yet, setting alloc_to_trigger_0 to %zd",
-                 gen_number,
-                 gen1_index, current_gen_calc->alloc_to_trigger_0));
-    }
-    if (fl_tuning_triggered)
-    {
-        BOOL tuning_kd_finished_p = FALSE;
-        double max_alloc_to_trigger = ((double)current_bgc_fl * (100 - gen_sweep_flr_goal) / 100.0);
-        double min_alloc_to_trigger = (double)current_bgc_fl * 0.05;
-        {
-            if (current_gen_calc->current_bgc_sweep_flr < 0.0)
-            {
-                dprintf (BGC_TUNING_LOG, ("BTL%d: sflr is %.3f!!! < 0, make it 0", gen_number, current_gen_calc->current_bgc_sweep_flr));
-                current_gen_calc->current_bgc_sweep_flr = 0.0;
-            }
-            double adjusted_above_goal_kp = above_goal_kp;
-            double above_goal_distance = current_gen_calc->current_bgc_sweep_flr - gen_sweep_flr_goal;
-            if (use_ki_p)
-            {
-                if (current_gen_calc->above_goal_accu_error > max_alloc_to_trigger)
-                {
-                    dprintf (BGC_TUNING_LOG, ("g%d: ae TB! %.1f->%.1f", gen_number, current_gen_calc->above_goal_accu_error, max_alloc_to_trigger));
-                }
-                else if (current_gen_calc->above_goal_accu_error < min_alloc_to_trigger)
-                {
-                    dprintf (BGC_TUNING_LOG, ("g%d: ae TS! %.1f->%.1f", gen_number, current_gen_calc->above_goal_accu_error, min_alloc_to_trigger));
-                }
-                current_gen_calc->above_goal_accu_error = min (max_alloc_to_trigger, current_gen_calc->above_goal_accu_error);
-                current_gen_calc->above_goal_accu_error = max (min_alloc_to_trigger, current_gen_calc->above_goal_accu_error);
-                double above_goal_ki_gain = above_goal_ki * above_goal_distance * current_bgc_fl;
-                double temp_accu_error = current_gen_calc->above_goal_accu_error + above_goal_ki_gain;
-                if ((temp_accu_error > min_alloc_to_trigger) &&
-                    (temp_accu_error < max_alloc_to_trigger))
-                {
-                    current_gen_calc->above_goal_accu_error = temp_accu_error;
-                }
-                else
-                {
-                    dprintf (BGC_TUNING_LOG, ("g%d: aae + %.1f=%.1f, exc", gen_number,
-                            above_goal_ki_gain,
-                            temp_accu_error));
-                }
-            }
-            {
-                saved_alloc_to_trigger = current_gen_calc->alloc_to_trigger;
-                current_alloc_to_trigger = adjusted_above_goal_kp * above_goal_distance * current_bgc_fl;
-                dprintf (BGC_TUNING_LOG, ("BTL%d: sflr %.3f above * %.4f * %zd = %zd bytes in alloc, la: %zd(+%zd), laa: %zd(+%zd)",
-                        gen_number,
-                        (current_gen_calc->current_bgc_sweep_flr - (double)gen_sweep_flr_goal),
-                        adjusted_above_goal_kp,
-                        current_bgc_fl,
-                        (size_t)current_alloc_to_trigger,
-                        saved_alloc_to_trigger,
-                        (size_t)(current_alloc_to_trigger - (double)saved_alloc_to_trigger),
-                        gen_actual_alloc_to_trigger,
-                        (gen_actual_alloc_to_trigger - saved_alloc_to_trigger)));
-                if (use_ki_p)
-                {
-                    current_alloc_to_trigger += current_gen_calc->above_goal_accu_error;
-                    dprintf (BGC_TUNING_LOG, ("BTL%d: +accu err %zd=%zd",
-                            gen_number,
-                            (size_t)(current_gen_calc->above_goal_accu_error),
-                            (size_t)current_alloc_to_trigger));
-                }
-            }
-            if (use_tbh_p)
-            {
-                if (current_gen_calc->last_sweep_above_p != current_sweep_above_p)
-                {
-                    size_t new_alloc_to_trigger_0 = (last_gen_alloc_to_trigger + last_gen_alloc_to_trigger_0) / 2;
-                    dprintf (BGC_TUNING_LOG, ("BTL%d: tbh crossed SP, setting both to %zd", gen_number, new_alloc_to_trigger_0));
-                    current_gen_calc->alloc_to_trigger_0 = new_alloc_to_trigger_0;
-                    current_gen_calc->alloc_to_trigger = new_alloc_to_trigger_0;
-                }
-                tuning_kd_finished_p = TRUE;
-            }
-        }
-        if (!tuning_kd_finished_p)
-        {
-            if (use_kd_p)
-            {
-                saved_alloc_to_trigger = last_gen_alloc_to_trigger;
-                size_t alloc_delta = saved_alloc_to_trigger - gen_actual_alloc_to_trigger;
-                double adjust_ratio = (double)alloc_delta / (double)gen_actual_alloc_to_trigger;
-                double saved_adjust_ratio = adjust_ratio;
-                if (enable_gradual_d)
-                {
-                    adjust_ratio = calculate_gradual_d (adjust_ratio, above_goal_kd);
-                    dprintf (BGC_TUNING_LOG, ("BTL%d: gradual kd - reduced from %.3f to %.3f",
-                            gen_number, saved_adjust_ratio, adjust_ratio));
-                }
-                else
-                {
-                    double kd = above_goal_kd;
-                    double neg_kd = 0 - kd;
-                    if (adjust_ratio > kd) adjust_ratio = kd;
-                    if (adjust_ratio < neg_kd) adjust_ratio = neg_kd;
-                    dprintf (BGC_TUNING_LOG, ("BTL%d: kd - reduced from %.3f to %.3f",
-                            gen_number, saved_adjust_ratio, adjust_ratio));
-                }
-                current_gen_calc->alloc_to_trigger = (size_t)((double)gen_actual_alloc_to_trigger * (1 + adjust_ratio));
-                dprintf (BGC_TUNING_LOG, ("BTL%d: kd %.3f, reduced it to %.3f * %zd, adjust %zd->%zd",
-                        gen_number, saved_adjust_ratio,
-                        adjust_ratio, gen_actual_alloc_to_trigger,
-                        saved_alloc_to_trigger, current_gen_calc->alloc_to_trigger));
-            }
-            if (use_smooth_p && use_this_loop_p)
-            {
-                saved_alloc_to_trigger = current_gen_calc->alloc_to_trigger;
-                size_t gen_smoothed_alloc_to_trigger = current_gen_calc->smoothed_alloc_to_trigger;
-                double current_num_gen1s_smooth_factor = (num_gen1s_smooth_factor > (double)num_bgcs_since_tuning_trigger) ?
-                                                        (double)num_bgcs_since_tuning_trigger : num_gen1s_smooth_factor;
-                current_gen_calc->smoothed_alloc_to_trigger = (size_t)((double)saved_alloc_to_trigger / current_num_gen1s_smooth_factor +
-                    ((double)gen_smoothed_alloc_to_trigger / current_num_gen1s_smooth_factor) * (current_num_gen1s_smooth_factor - 1.0));
-                dprintf (BGC_TUNING_LOG, ("BTL%d: smoothed %zd / %.3f + %zd / %.3f * %.3f adjust %zd->%zd",
-                    gen_number, saved_alloc_to_trigger, current_num_gen1s_smooth_factor,
-                    gen_smoothed_alloc_to_trigger, current_num_gen1s_smooth_factor,
-                    (current_num_gen1s_smooth_factor - 1.0),
-                    saved_alloc_to_trigger, current_gen_calc->smoothed_alloc_to_trigger));
-                current_gen_calc->alloc_to_trigger = current_gen_calc->smoothed_alloc_to_trigger;
-            }
-        }
-        if (use_ff_p)
-        {
-            double next_end_to_sweep_flr = data->gen_flr - gen_sweep_flr_goal;
-            if (next_end_to_sweep_flr > 0.0)
-            {
-                saved_alloc_to_trigger = current_gen_calc->alloc_to_trigger;
-                double ff_ratio = next_end_to_sweep_flr / current_end_to_sweep_flr - 1;
-                if (use_this_loop_p)
-                {
-                    double ff_step = above_goal_ff * 0.5;
-                    double adjusted_above_goal_ff = above_goal_ff;
-                    if (ff_ratio > 0)
-                        adjusted_above_goal_ff -= ff_step;
-                    else
-                        adjusted_above_goal_ff += ff_step;
-                    double adjusted_ff_ratio = ff_ratio * adjusted_above_goal_ff;
-                    current_gen_calc->alloc_to_trigger = saved_alloc_to_trigger + (size_t)((double)saved_alloc_to_trigger * adjusted_ff_ratio);
-                    dprintf (BGC_TUNING_LOG, ("BTL%d: ff (%.3f / %.3f - 1) * %.3f = %.3f adjust %zd->%zd",
-                        gen_number, next_end_to_sweep_flr, current_end_to_sweep_flr, adjusted_above_goal_ff, adjusted_ff_ratio,
-                        saved_alloc_to_trigger, current_gen_calc->alloc_to_trigger));
-                }
-            }
-        }
-        if (use_this_loop_p)
-        {
-            if (current_alloc_to_trigger > max_alloc_to_trigger)
-            {
-                dprintf (BGC_TUNING_LOG, ("BTL%d: TB! %.1f -> %.1f",
-                    gen_number, current_alloc_to_trigger, max_alloc_to_trigger));
-                current_alloc_to_trigger = max_alloc_to_trigger;
-            }
-            if (current_alloc_to_trigger < min_alloc_to_trigger)
-            {
-                dprintf (BGC_TUNING_LOG, ("BTL%d: TS! %zd -> %zd",
-                        gen_number, (ptrdiff_t)current_alloc_to_trigger, (size_t)min_alloc_to_trigger));
-                current_alloc_to_trigger = min_alloc_to_trigger;
-            }
-            current_gen_calc->alloc_to_trigger = (size_t)current_alloc_to_trigger;
-        }
-        else
-        {
-            dprintf (BGC_TUNING_LOG, ("BTL%d: ag, revert %zd->%zd",
-                gen_number, current_gen_calc->alloc_to_trigger, last_gen_alloc_to_trigger));
-            current_gen_calc->alloc_to_trigger = last_gen_alloc_to_trigger;
-        }
-    }
-    if (next_bgc_p)
-    {
-        size_t first_alloc = (size_t)((double)current_gen_calc->first_alloc_to_trigger * 0.75);
-        size_t min_first_alloc = current_bgc_fl / 20;
-        current_gen_calc->alloc_to_trigger = max (first_alloc, min_first_alloc);
-        dprintf (BGC_TUNING_LOG, ("BTL%d[g1: %zd]: BGC end, trigger FL, set gen%d alloc to max (0.75 of first: %zd, 5%% fl: %zd), actual alloc: %zd",
-            gen_number, gen1_index, gen_number,
-            first_alloc, min_first_alloc,
-            current_gen_calc->actual_alloc_to_trigger));
-    }
-    dprintf (BGC_TUNING_LOG, ("BTL%d* %zd, %.3f, %.3f, %.3f, %.3f, %.3f, %zd, %zd, %zd, %zd",
-                              gen_number,
-                              total_generation_size,
-                              current_gen_calc->current_bgc_start_flr,
-                              current_gen_calc->current_bgc_sweep_flr,
-                              current_bgc_end_data[tuning_data_index].gen_flr,
-                              current_gen_stats->last_gen_increase_flr,
-                              current_bgc_surv_rate,
-                              actual_num_gen1s_to_trigger,
-                              num_gen1s_bgc_end,
-                              gen_actual_alloc_to_trigger,
-                              current_gen_calc->alloc_to_trigger));
-    gen1_index_last_bgc_end = gen1_index;
-    current_gen_calc->last_bgc_size = total_generation_size;
-    current_gen_calc->last_bgc_flr = current_bgc_end_data[tuning_data_index].gen_flr;
-    current_gen_calc->last_sweep_above_p = current_sweep_above_p;
-    current_gen_calc->last_bgc_end_alloc = current_alloc;
-    current_gen_stats->last_bgc_physical_size = data->gen_physical_size;
-    current_gen_stats->last_alloc_end_to_start = 0;
-    current_gen_stats->last_alloc_start_to_sweep = 0;
-    current_gen_stats->last_alloc_sweep_to_end = 0;
-    current_gen_stats->last_alloc = current_alloc;
-    current_gen_stats->last_bgc_fl_size = current_bgc_end_data[tuning_data_index].gen_fl_size;
-    current_gen_stats->last_bgc_surv_rate = current_bgc_surv_rate;
-    current_gen_stats->last_gen_increase_flr = 0;
-}
-void gc_heap::bgc_tuning::init_bgc_end_data (int gen_number, bool use_this_loop_p)
-{
-    int index = gen_number - max_generation;
-    bgc_size_data* data = &current_bgc_end_data[index];
-    size_t physical_size = get_total_generation_size (gen_number);
-    ptrdiff_t physical_fl_size = get_total_generation_fl_size (gen_number);
-    data->gen_actual_phys_fl_size = physical_fl_size;
-    if (fl_tuning_triggered && !use_this_loop_p)
-    {
-        tuning_calculation* current_gen_calc = &gen_calc[gen_number - max_generation];
-        if (current_gen_calc->actual_alloc_to_trigger > current_gen_calc->alloc_to_trigger)
-        {
-            dprintf (BGC_TUNING_LOG, ("BTL%d: gen alloc also exceeded %zd (la: %zd), no action",
-                gen_number, current_gen_calc->actual_alloc_to_trigger, current_gen_calc->alloc_to_trigger));
-        }
-        else
-        {
-            size_t remaining_alloc = current_gen_calc->alloc_to_trigger -
-                                     current_gen_calc->actual_alloc_to_trigger;
-            size_t gen_size = current_gen_calc->end_gen_size_goal;
-            double sweep_flr = current_gen_calc->current_bgc_sweep_flr;
-            size_t sweep_fl_size = (size_t)((double)gen_size * sweep_flr / 100.0);
-            if (sweep_fl_size < remaining_alloc)
-            {
-                dprintf (BGC_TUNING_LOG, ("BTL%d: sweep fl %zd < remain alloc %zd", gen_number, sweep_fl_size, remaining_alloc));
-                remaining_alloc = sweep_fl_size - (10 * 1024);
-            }
-            size_t new_sweep_fl_size = sweep_fl_size - remaining_alloc;
-            ptrdiff_t signed_new_sweep_fl_size = sweep_fl_size - remaining_alloc;
-            double new_current_bgc_sweep_flr = (double)new_sweep_fl_size * 100.0 / (double)gen_size;
-            double signed_new_current_bgc_sweep_flr = (double)signed_new_sweep_fl_size * 100.0 / (double)gen_size;
-            dprintf (BGC_TUNING_LOG, ("BTL%d: sg: %zd(%zd), sfl: %zd->%zd(%zd)(%.3f->%.3f(%.3f)), la: %zd, aa: %zd",
-                gen_number, gen_size, physical_size, sweep_fl_size,
-                new_sweep_fl_size, signed_new_sweep_fl_size,
-                sweep_flr, new_current_bgc_sweep_flr, signed_new_current_bgc_sweep_flr,
-                current_gen_calc->alloc_to_trigger, current_gen_calc->actual_alloc_to_trigger));
-            current_gen_calc->actual_alloc_to_trigger = current_gen_calc->alloc_to_trigger;
-            current_gen_calc->current_bgc_sweep_flr = new_current_bgc_sweep_flr;
-            size_t current_bgc_surv_size = get_total_surv_size (gen_number);
-            size_t current_bgc_begin_data_size = get_total_begin_data_size (gen_number);
-            double current_bgc_surv_rate = (current_bgc_begin_data_size == 0) ?
-                                            0 : ((double)current_bgc_surv_size / (double)current_bgc_begin_data_size);
-            size_t remaining_alloc_surv = (size_t)((double)remaining_alloc * current_bgc_surv_rate);
-            physical_fl_size -= remaining_alloc_surv;
-            dprintf (BGC_TUNING_LOG, ("BTL%d: asfl %zd-%zd=%zd, flr %.3f->%.3f, %.3f%% s, fl %zd-%zd->%zd",
-                gen_number, sweep_fl_size, remaining_alloc, new_sweep_fl_size,
-                sweep_flr, current_gen_calc->current_bgc_sweep_flr,
-                (current_bgc_surv_rate * 100.0),
-                (physical_fl_size + remaining_alloc_surv),
-                remaining_alloc_surv, physical_fl_size));
-        }
-    }
-    double physical_gen_flr = (double)physical_fl_size * 100.0 / (double)physical_size;
-    data->gen_physical_size = physical_size;
-    data->gen_physical_fl_size = physical_fl_size;
-    data->gen_physical_flr = physical_gen_flr;
-}
-void gc_heap::bgc_tuning::calc_end_bgc_fl (int gen_number)
-{
-    int index = gen_number - max_generation;
-    bgc_size_data* data = &current_bgc_end_data[index];
-    tuning_calculation* current_gen_calc = &gen_calc[gen_number - max_generation];
-    size_t virtual_size = current_gen_calc->end_gen_size_goal;
-    size_t physical_size = data->gen_physical_size;
-    ptrdiff_t physical_fl_size = data->gen_physical_fl_size;
-    ptrdiff_t virtual_fl_size = (ptrdiff_t)virtual_size - (ptrdiff_t)physical_size;
-    ptrdiff_t end_gen_fl_size = physical_fl_size + virtual_fl_size;
-    if (end_gen_fl_size < 0)
-    {
-        end_gen_fl_size = 0;
-    }
-    data->gen_size = virtual_size;
-    data->gen_fl_size = end_gen_fl_size;
-    data->gen_flr = (double)(data->gen_fl_size) * 100.0 / (double)(data->gen_size);
-    dprintf (BGC_TUNING_LOG, ("BTL%d: vfl: %zd, size %zd->%zd, fl %zd->%zd, flr %.3f->%.3f",
-        gen_number, virtual_fl_size,
-        data->gen_physical_size, data->gen_size,
-        data->gen_physical_fl_size, data->gen_fl_size,
-        data->gen_physical_flr, data->gen_flr));
-}
-double gc_heap::bgc_tuning::calculate_ml_tuning (uint64_t current_available_physical, bool reduce_p,
-                                                 ptrdiff_t* _vfl_from_kp, ptrdiff_t* _vfl_from_ki)
-{
-    ptrdiff_t error = (ptrdiff_t)(current_available_physical - available_memory_goal);
-    size_t gen2_physical_size = current_bgc_end_data[0].gen_physical_size;
-    size_t gen3_physical_size = current_bgc_end_data[1].gen_physical_size;
-    double max_output = (double)(total_physical_mem - available_memory_goal -
-                                 gen2_physical_size - gen3_physical_size);
-    double error_ratio = (double)error / (double)total_physical_mem;
-    bool include_in_i_p = ((error_ratio > 0.005) || (error_ratio < -0.005));
-    dprintf (BGC_TUNING_LOG, ("total phy %zd, mem goal: %zd, curr phy: %zd, g2 phy: %zd, g3 phy: %zd",
-            (size_t)total_physical_mem, (size_t)available_memory_goal,
-            (size_t)current_available_physical,
-            gen2_physical_size, gen3_physical_size));
-    dprintf (BGC_TUNING_LOG, ("BTL: Max output: %zd, ER %zd / %zd = %.3f, %s",
-            (size_t)max_output,
-            error, available_memory_goal, error_ratio,
-            (include_in_i_p ? "inc" : "exc")));
-    if (include_in_i_p)
-    {
-        double error_ki = ml_ki * (double)error;
-        double temp_accu_error = accu_error + error_ki;
-        if ((temp_accu_error > 0) && (temp_accu_error < max_output))
-            accu_error = temp_accu_error;
-        else
-        {
-            dprintf (BGC_TUNING_LOG, ("mae + %zd=%zd, exc",
-                    (size_t)error_ki, (size_t)temp_accu_error));
-        }
-    }
-    if (reduce_p)
-    {
-        double saved_accu_error = accu_error;
-        accu_error = accu_error * 2.0 / 3.0;
-        panic_activated_p = false;
-        accu_error_panic = 0;
-        dprintf (BGC_TUNING_LOG, ("BTL reduced accu ki %zd->%zd", (ptrdiff_t)saved_accu_error, (ptrdiff_t)accu_error));
-    }
-    if (panic_activated_p)
-        accu_error_panic += (double)error;
-    else
-        accu_error_panic = 0.0;
-    double vfl_from_kp = (double)error * ml_kp;
-    double total_virtual_fl_size = vfl_from_kp + accu_error;
-    if (total_virtual_fl_size < 0)
-    {
-        dprintf (BGC_TUNING_LOG, ("BTL vfl %zd < 0", (size_t)total_virtual_fl_size));
-        total_virtual_fl_size = 0;
-    }
-    else if (total_virtual_fl_size > max_output)
-    {
-        dprintf (BGC_TUNING_LOG, ("BTL vfl %zd > max", (size_t)total_virtual_fl_size));
-        total_virtual_fl_size = max_output;
-    }
-    *_vfl_from_kp = (ptrdiff_t)vfl_from_kp;
-    *_vfl_from_ki = (ptrdiff_t)accu_error;
-    return total_virtual_fl_size;
-}
-void gc_heap::bgc_tuning::set_total_gen_sizes (bool use_gen2_loop_p, bool use_gen3_loop_p)
-{
-    size_t gen2_physical_size = current_bgc_end_data[0].gen_physical_size;
-    size_t gen3_physical_size = 0;
-    ptrdiff_t gen3_virtual_fl_size = 0;
-    gen3_physical_size = current_bgc_end_data[1].gen_physical_size;
-    double gen2_size_ratio = (double)gen2_physical_size / ((double)gen2_physical_size + (double)gen3_physical_size);
-    uint32_t current_memory_load = settings.entry_memory_load;
-    uint64_t current_available_physical = settings.entry_available_physical_mem;
-    panic_activated_p = (current_memory_load >= (memory_load_goal + memory_load_goal_slack));
-    if (panic_activated_p)
-    {
-        dprintf (BGC_TUNING_LOG, ("BTL: exceeded slack %zd >= (%zd + %zd)",
-            (size_t)current_memory_load, (size_t)memory_load_goal,
-            (size_t)memory_load_goal_slack));
-    }
-    ptrdiff_t vfl_from_kp = 0;
-    ptrdiff_t vfl_from_ki = 0;
-    double total_virtual_fl_size = calculate_ml_tuning (current_available_physical, false, &vfl_from_kp, &vfl_from_ki);
-    if (use_gen2_loop_p || use_gen3_loop_p)
-    {
-        if (use_gen2_loop_p)
-        {
-            gen2_ratio_correction += ratio_correction_step;
-        }
-        else
-        {
-            gen2_ratio_correction -= ratio_correction_step;
-        }
-        dprintf (BGC_TUNING_LOG, ("BTL: rc: g2 ratio %.3f%% + %d%% = %.3f%%",
-            (gen2_size_ratio * 100.0), (int)(gen2_ratio_correction * 100.0), ((gen2_size_ratio + gen2_ratio_correction) * 100.0)));
-        gen2_ratio_correction = min (0.99, gen2_ratio_correction);
-        gen2_ratio_correction = max (-0.99, gen2_ratio_correction);
-        dprintf (BGC_TUNING_LOG, ("BTL: rc again: g2 ratio %.3f%% + %d%% = %.3f%%",
-            (gen2_size_ratio * 100.0), (int)(gen2_ratio_correction * 100.0), ((gen2_size_ratio + gen2_ratio_correction) * 100.0)));
-        gen2_size_ratio += gen2_ratio_correction;
-        if (gen2_size_ratio <= 0.0)
-        {
-            gen2_size_ratio = 0.01;
-            dprintf (BGC_TUNING_LOG, ("BTL: rc: g2 ratio->0.01"));
-        }
-        if (gen2_size_ratio >= 1.0)
-        {
-            gen2_size_ratio = 0.99;
-            dprintf (BGC_TUNING_LOG, ("BTL: rc: g2 ratio->0.99"));
-        }
-    }
-    ptrdiff_t gen2_virtual_fl_size = (ptrdiff_t)(total_virtual_fl_size * gen2_size_ratio);
-    gen3_virtual_fl_size = (ptrdiff_t)(total_virtual_fl_size * (1.0 - gen2_size_ratio));
-    if (gen2_virtual_fl_size < 0)
-    {
-        ptrdiff_t saved_gen2_virtual_fl_size = gen2_virtual_fl_size;
-        ptrdiff_t half_gen2_physical_size = (ptrdiff_t)((double)gen2_physical_size * 0.5);
-        if (-gen2_virtual_fl_size > half_gen2_physical_size)
-        {
-            gen2_virtual_fl_size = -half_gen2_physical_size;
-        }
-        dprintf (BGC_TUNING_LOG, ("BTL2: n_vfl %zd(%zd)->%zd", saved_gen2_virtual_fl_size, half_gen2_physical_size, gen2_virtual_fl_size));
-        gen2_virtual_fl_size = 0;
-    }
-    if (gen3_virtual_fl_size < 0)
-    {
-        ptrdiff_t saved_gen3_virtual_fl_size = gen3_virtual_fl_size;
-        ptrdiff_t half_gen3_physical_size = (ptrdiff_t)((double)gen3_physical_size * 0.5);
-        if (-gen3_virtual_fl_size > half_gen3_physical_size)
-        {
-            gen3_virtual_fl_size = -half_gen3_physical_size;
-        }
-        dprintf (BGC_TUNING_LOG, ("BTL3: n_vfl %zd(%zd)->%zd", saved_gen3_virtual_fl_size, half_gen3_physical_size, gen3_virtual_fl_size));
-        gen3_virtual_fl_size = 0;
-    }
-    gen_calc[0].end_gen_size_goal = gen2_physical_size + gen2_virtual_fl_size;
-    gen_calc[1].end_gen_size_goal = gen3_physical_size + gen3_virtual_fl_size;
-    calc_end_bgc_fl (max_generation);
-    calc_end_bgc_fl (loh_generation);
-#ifdef SIMPLE_DPRINTF
-    dprintf (BGC_TUNING_LOG, ("BTL: ml: %d (g: %d)(%s), a: %zd (g: %zd, elg: %zd+%zd=%zd, %zd+%zd=%zd, pi=%zd), vfl: %zd=%zd+%zd",
-        current_memory_load, memory_load_goal,
-        ((current_available_physical > available_memory_goal) ? "above" : "below"),
-        current_available_physical, available_memory_goal,
-        gen2_physical_size, gen2_virtual_fl_size, gen_calc[0].end_gen_size_goal,
-        gen3_physical_size, gen3_virtual_fl_size, gen_calc[1].end_gen_size_goal,
-        (ptrdiff_t)accu_error_panic,
-        (ptrdiff_t)total_virtual_fl_size, vfl_from_kp, vfl_from_ki));
-#endif //SIMPLE_DPRINTF
-}
-bool gc_heap::bgc_tuning::should_trigger_ngc2()
-{
-    return panic_activated_p;
-}
-void gc_heap::bgc_tuning::convert_to_fl (bool use_gen2_loop_p, bool use_gen3_loop_p)
-{
-    size_t current_bgc_count = full_gc_counts[gc_type_background];
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < gc_heap::n_heaps; i++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[i];
-        hp->bgc_maxgen_end_fl_size = generation_free_list_space (hp->generation_of (max_generation));
-    }
-#else
-    bgc_maxgen_end_fl_size = generation_free_list_space (generation_of (max_generation));
-#endif //MULTIPLE_HEAPS
-    init_bgc_end_data (max_generation, use_gen2_loop_p);
-    init_bgc_end_data (loh_generation, use_gen3_loop_p);
-    set_total_gen_sizes (use_gen2_loop_p, use_gen3_loop_p);
-    dprintf (BGC_TUNING_LOG, ("BTL: gen2 %zd, fl %zd(%.3f)->%zd; gen3 %zd, fl %zd(%.3f)->%zd, %zd BGCs",
-        current_bgc_end_data[0].gen_size, current_bgc_end_data[0].gen_fl_size,
-        current_bgc_end_data[0].gen_flr, gen_calc[0].end_gen_size_goal,
-        current_bgc_end_data[1].gen_size, current_bgc_end_data[1].gen_fl_size,
-        current_bgc_end_data[1].gen_flr, gen_calc[1].end_gen_size_goal,
-        current_bgc_count));
-}
-void gc_heap::bgc_tuning::record_and_adjust_bgc_end()
-{
-    if (!bgc_tuning::enable_fl_tuning)
-        return;
-    uint64_t elapsed_time_so_far = GetHighPrecisionTimeStamp() - process_start_time;
-    size_t current_gen1_index = get_current_gc_index (max_generation - 1);
-    dprintf (BGC_TUNING_LOG, ("BTL: g2t[en][g1 %zd]: %0.3f minutes",
-        current_gen1_index,
-        (double)elapsed_time_so_far / (double)1000000 / (double)60));
-    if (fl_tuning_triggered)
-    {
-        num_bgcs_since_tuning_trigger++;
-    }
-    bool use_gen2_loop_p = (settings.reason == reason_bgc_tuning_soh);
-    bool use_gen3_loop_p = (settings.reason == reason_bgc_tuning_loh);
-    dprintf (BGC_TUNING_LOG, ("BTL: reason: %d, gen2 loop: %s; gen3 loop: %s, promoted %zd bytes",
-        (((settings.reason != reason_bgc_tuning_soh) && (settings.reason != reason_bgc_tuning_loh)) ?
-            saved_bgc_tuning_reason : settings.reason),
-        (use_gen2_loop_p ? "yes" : "no"),
-        (use_gen3_loop_p ? "yes" : "no"),
-        get_total_bgc_promoted()));
-    convert_to_fl (use_gen2_loop_p, use_gen3_loop_p);
-    calculate_tuning (max_generation, true);
-    if (total_uoh_a_last_bgc > 0)
-    {
-        calculate_tuning (loh_generation, true);
-    }
-    else
-    {
-        dprintf (BGC_TUNING_LOG, ("BTL: gen3 not allocated"));
-    }
-    if (next_bgc_p)
-    {
-        next_bgc_p = false;
-        fl_tuning_triggered = true;
-        dprintf (BGC_TUNING_LOG, ("BTL: FL tuning ENABLED!!!"));
-    }
-    saved_bgc_tuning_reason = -1;
-}
-#endif //BGC_SERVO_TUNING
-#endif //BACKGROUND_GC
-void gc_heap::clear_cards (size_t start_card, size_t end_card)
-{
-    if (start_card < end_card)
-    {
-        size_t start_word = card_word (start_card);
-        size_t end_word = card_word (end_card);
-        if (start_word < end_word)
-        {
-            unsigned bits = card_bit (start_card);
-            card_table [start_word] &= lowbits (~0, bits);
-            for (size_t i = start_word+1; i < end_word; i++)
-                card_table [i] = 0;
-            bits = card_bit (end_card);
-            if (bits != 0)
-            {
-                card_table [end_word] &= highbits (~0, bits);
-            }
-        }
-        else
-        {
-            card_table [start_word] &= (lowbits (~0, card_bit (start_card)) |
-                                        highbits (~0, card_bit (end_card)));
-        }
-#if defined(_DEBUG) && defined(VERIFY_HEAP)
-        if (GCConfig::GetHeapVerifyLevel() & GCConfig::HEAPVERIFY_GC)
-        {
-            size_t  card = start_card;
-            while (card < end_card)
-            {
-                assert (!(card_set_p (card)));
-                card++;
-            }
-        }
-#endif //_DEBUG && VERIFY_HEAP
-        dprintf (3,("Cleared cards [%zx:%zx, %zx:%zx[",
-                  start_card, (size_t)card_address (start_card),
-                  end_card, (size_t)card_address (end_card)));
-    }
-}
-void gc_heap::clear_card_for_addresses (uint8_t* start_address, uint8_t* end_address)
-{
-    size_t   start_card = card_of (align_on_card (start_address));
-    size_t   end_card = card_of (align_lower_card (end_address));
-    clear_cards (start_card, end_card);
-}
-inline
-void gc_heap::copy_cards (size_t dst_card,
-                          size_t src_card,
-                          size_t end_card,
-                          BOOL nextp)
-{
-    if (!(dst_card < end_card))
-        return;
-    unsigned int srcbit = card_bit (src_card);
-    unsigned int dstbit = card_bit (dst_card);
-    size_t srcwrd = card_word (src_card);
-    size_t dstwrd = card_word (dst_card);
-    unsigned int srctmp = card_table[srcwrd];
-    unsigned int dsttmp = card_table[dstwrd];
-    for (size_t card = dst_card; card < end_card; card++)
-    {
-        if (srctmp & (1 << srcbit))
-            dsttmp |= 1 << dstbit;
-        else
-            dsttmp &= ~(1 << dstbit);
-        if (!(++srcbit % 32))
-        {
-            srctmp = card_table[++srcwrd];
-            srcbit = 0;
-        }
-        if (nextp)
-        {
-            if (srctmp & (1 << srcbit))
-                dsttmp |= 1 << dstbit;
-        }
-        if (!(++dstbit % 32))
-        {
-            card_table[dstwrd] = dsttmp;
-#ifdef FEATURE_MANUALLY_MANAGED_CARD_BUNDLES
-            if (dsttmp != 0)
-            {
-                card_bundle_set(cardw_card_bundle(dstwrd));
-            }
-#endif
-            dstwrd++;
-            dsttmp = card_table[dstwrd];
-            dstbit = 0;
-        }
-    }
-    card_table[dstwrd] = dsttmp;
-#ifdef FEATURE_MANUALLY_MANAGED_CARD_BUNDLES
-    if (dsttmp != 0)
-    {
-        card_bundle_set(cardw_card_bundle(dstwrd));
-    }
-#endif
-}
-void gc_heap::copy_cards_for_addresses (uint8_t* dest, uint8_t* src, size_t len)
-{
-    ptrdiff_t relocation_distance = src - dest;
-    size_t start_dest_card = card_of (align_on_card (dest));
-    size_t end_dest_card = card_of (dest + len - 1);
-    size_t dest_card = start_dest_card;
-    size_t src_card = card_of (card_address (dest_card)+relocation_distance);
-    dprintf (3,("Copying cards [%zx:%zx->%zx:%zx, ",
-                 src_card, (size_t)src, dest_card, (size_t)dest));
-    dprintf (3,(" %zx->%zx:%zx[",
-              (size_t)src+len, end_dest_card, (size_t)dest+len));
-    dprintf (3, ("dest: %p, src: %p, len: %zx, reloc: %zx, align_on_card(dest) is %p",
-        dest, src, len, relocation_distance, (align_on_card (dest))));
-    dprintf (3, ("start_dest_card: %zx (address: %p), end_dest_card: %zx(addr: %p), card_of (dest): %zx",
-        start_dest_card, card_address (start_dest_card), end_dest_card, card_address (end_dest_card), card_of (dest)));
-    if (start_dest_card != card_of (dest))
-    {
-        if ((card_of (card_address (start_dest_card) + relocation_distance) <= card_of (src + len - 1))&&
-            card_set_p (card_of (card_address (start_dest_card) + relocation_distance)))
-        {
-            dprintf (3, ("card_address (start_dest_card) + reloc is %p, card: %zx(set), src+len-1: %p, card: %zx",
-                    (card_address (start_dest_card) + relocation_distance),
-                    card_of (card_address (start_dest_card) + relocation_distance),
-                    (src + len - 1),
-                    card_of (src + len - 1)));
-            dprintf (3, ("setting card: %zx", card_of (dest)));
-            set_card (card_of (dest));
-        }
-    }
-    if (card_set_p (card_of (src)))
-        set_card (card_of (dest));
-    copy_cards (dest_card, src_card, end_dest_card,
-                ((dest - align_lower_card (dest)) != (src - align_lower_card (src))));
-    if ((card_of (card_address (end_dest_card) + relocation_distance) >= card_of (src)) &&
-        card_set_p (card_of (card_address (end_dest_card) + relocation_distance)))
-    {
-        dprintf (3, ("card_address (end_dest_card) + reloc is %p, card: %zx(set), src: %p, card: %zx",
-                (card_address (end_dest_card) + relocation_distance),
-                card_of (card_address (end_dest_card) + relocation_distance),
-                src,
-                card_of (src)));
-        dprintf (3, ("setting card: %zx", end_dest_card));
-        set_card (end_dest_card);
-    }
-    if (card_set_p (card_of (src + len - 1)))
-        set_card (end_dest_card);
-#ifdef FEATURE_MANUALLY_MANAGED_CARD_BUNDLES
-    card_bundles_set(cardw_card_bundle(card_word(card_of(dest))), cardw_card_bundle(align_cardw_on_bundle(card_word(end_dest_card))));
-#endif
-}
-#ifdef BACKGROUND_GC
-void gc_heap::copy_mark_bits_for_addresses (uint8_t* dest, uint8_t* src, size_t len)
-{
-    dprintf (3, ("Copying mark_bits for addresses [%zx->%zx, %zx->%zx[",
-                 (size_t)src, (size_t)dest,
-                 (size_t)src+len, (size_t)dest+len));
-    uint8_t* src_o = src;
-    uint8_t* dest_o;
-    uint8_t* src_end = src + len;
-    int align_const = get_alignment_constant (TRUE);
-    ptrdiff_t reloc = dest - src;
-    while (src_o < src_end)
-    {
-        uint8_t*  next_o = src_o + Align (size (src_o), align_const);
-        if (background_object_marked (src_o, TRUE))
-        {
-            dest_o = src_o + reloc;
-            background_mark (dest_o,
-                             background_saved_lowest_address,
-                             background_saved_highest_address);
-            dprintf (3, ("bc*%zx*bc, b*%zx*b", (size_t)src_o, (size_t)(dest_o)));
-        }
-        src_o = next_o;
-    }
-}
-#endif //BACKGROUND_GC
-void gc_heap::fix_brick_to_highest (uint8_t* o, uint8_t* next_o)
-{
-    size_t new_current_brick = brick_of (o);
-    set_brick (new_current_brick,
-               (o - brick_address (new_current_brick)));
-    size_t b = 1 + new_current_brick;
-    size_t limit = brick_of (next_o);
-    dprintf(3,("b:%zx->%zx-%zx",
-               new_current_brick, (size_t)o, (size_t)next_o));
-    while (b < limit)
-    {
-        set_brick (b,(new_current_brick - b));
-        b++;
-    }
-}
-uint8_t* gc_heap::find_first_object (uint8_t* start, uint8_t* first_object)
-{
-    size_t brick = brick_of (start);
-    uint8_t* o = 0;
-    if ((brick == brick_of (first_object) || (start <= first_object)))
-    {
-        o = first_object;
-    }
-    else
-    {
-        ptrdiff_t  min_brick = (ptrdiff_t)brick_of (first_object);
-        ptrdiff_t  prev_brick = (ptrdiff_t)brick - 1;
-        int         brick_entry = 0;
-        while (1)
-        {
-            if (prev_brick < min_brick)
-            {
-                break;
-            }
-            if ((brick_entry = get_brick_entry(prev_brick)) >= 0)
-            {
-                break;
-            }
-            assert (! ((brick_entry == 0)));
-            prev_brick = (brick_entry + prev_brick);
-        }
-        o = ((prev_brick < min_brick) ? first_object :
-                      brick_address (prev_brick) + brick_entry - 1);
-        assert (o <= start);
-    }
-    assert (Align (size (o)) >= Align (min_obj_size));
-    uint8_t*  next_o = o + Align (size (o));
-    size_t curr_cl = (size_t)next_o / brick_size;
-    size_t min_cl = (size_t)first_object / brick_size;
-#ifdef TRACE_GC
-    unsigned int n_o = 1;
-#endif //TRACE_GC
-    uint8_t* next_b = min (align_lower_brick (next_o) + brick_size, start+1);
-    while (next_o <= start)
-    {
-        do
-        {
-#ifdef TRACE_GC
-            n_o++;
-#endif //TRACE_GC
-            o = next_o;
-            assert (Align (size (o)) >= Align (min_obj_size));
-            next_o = o + Align (size (o));
-            Prefetch (next_o);
-        }while (next_o < next_b);
-        if (((size_t)next_o / brick_size) != curr_cl)
-        {
-            if (curr_cl >= min_cl)
-            {
-                fix_brick_to_highest (o, next_o);
-            }
-            curr_cl = (size_t) next_o / brick_size;
-        }
-        next_b = min (align_lower_brick (next_o) + brick_size, start+1);
-    }
-    size_t bo = brick_of (o);
-    dprintf (3, ("%u o, [%zx-[%zx",
-        n_o, bo, brick));
-    if (bo < brick)
-    {
-        set_brick (bo, (o - brick_address(bo)));
-        size_t b = 1 + bo;
-        int x = -1;
-        while (b < brick)
-        {
-            set_brick (b,x--);
-            b++;
-        }
-    }
-    return o;
-}
-#ifdef CARD_BUNDLE
-BOOL gc_heap::find_card_dword (size_t& cardw, size_t cardw_end)
-{
-    dprintf (3, ("gc: %zd, find_card_dword cardw: %zx, cardw_end: %zx",
-                 dd_collection_count (dynamic_data_of (0)), cardw, cardw_end));
-    if (card_bundles_enabled())
-    {
-        size_t cardb = cardw_card_bundle (cardw);
-        size_t end_cardb = cardw_card_bundle (align_cardw_on_bundle (cardw_end));
-        while (1)
-        {
-            while (cardb < end_cardb)
-            {
-                uint32_t cbw = card_bundle_table[card_bundle_word(cardb)] >> card_bundle_bit (cardb);
-                DWORD bit_index;
-                if (BitScanForward (&bit_index, cbw))
-                {
-                    cardb += bit_index;
-                    break;
-                }
-                else
-                {
-                    cardb += sizeof(cbw)*8 - card_bundle_bit (cardb);
-                }
-            }
-            if (cardb >= end_cardb)
-                return FALSE;
-            uint32_t* card_word = &card_table[max(card_bundle_cardw (cardb),cardw)];
-            uint32_t* card_word_end = &card_table[min(card_bundle_cardw (cardb+1),cardw_end)];
-            while ((card_word < card_word_end) && !(*card_word))
-            {
-                card_word++;
-            }
-            if (card_word != card_word_end)
-            {
-                cardw = (card_word - &card_table[0]);
-                return TRUE;
-            }
-            if (cardw == (card_bundle_cardw (cardb) + 1) && !card_table[cardw-1])
-            {
-                cardw--;
-            }
-            card_word_end = &card_table[card_bundle_cardw (cardb+1)];
-            while ((card_word < card_word_end) && !(*card_word))
-            {
-                card_word++;
-            }
-            if ((cardw <= card_bundle_cardw (cardb)) &&
-                (card_word == card_word_end))
-            {
-                dprintf  (3, ("gc: %zd, find_card_dword clear bundle: %zx cardw:[%zx,%zx[",
-                        dd_collection_count (dynamic_data_of (0)),
-                        cardb, card_bundle_cardw (cardb),
-                        card_bundle_cardw (cardb+1)));
-                card_bundle_clear (cardb);
-            }
-            cardb++;
-        }
-    }
-    else
-    {
-        uint32_t* card_word = &card_table[cardw];
-        uint32_t* card_word_end = &card_table [cardw_end];
-        while (card_word < card_word_end)
-        {
-            if ((*card_word) != 0)
-            {
-                cardw = (card_word - &card_table [0]);
-                return TRUE;
-            }
-            card_word++;
-        }
-        return FALSE;
-    }
-}
-#endif //CARD_BUNDLE
-BOOL gc_heap::find_card(uint32_t* card_table,
-                        size_t&   card,
-                        size_t    card_word_end,
-                        size_t&   end_card)
-{
-    uint32_t* last_card_word;
-    uint32_t card_word_value;
-    uint32_t bit_position;
-    if (card_word (card) >= card_word_end)
-        return FALSE;
-    last_card_word = &card_table [card_word (card)];
-    bit_position = card_bit (card);
-#ifdef CARD_BUNDLE
-    if (bit_position == 0)
-    {
-        card_word_value = 0;
-    }
-    else
-#endif
-    {
-        card_word_value = (*last_card_word) >> bit_position;
-    }
-    if (!card_word_value)
-    {
-#ifdef CARD_BUNDLE
-        size_t lcw = card_word(card) + (bit_position != 0);
-        if (gc_heap::find_card_dword (lcw, card_word_end) == FALSE)
-        {
-            return FALSE;
-        }
-        else
-        {
-            last_card_word = &card_table [lcw];
-            card_word_value = *last_card_word;
-        }
-        bit_position = 0;
-#else //CARD_BUNDLE
-        do
-        {
-            ++last_card_word;
-        }
-        while ((last_card_word < &card_table [card_word_end]) && !(*last_card_word));
-        if (last_card_word < &card_table [card_word_end])
-        {
-            card_word_value = *last_card_word;
-        }
-        else
-        {
-            return FALSE;
-        }
-#endif //CARD_BUNDLE
-    }
-    if (card_word_value)
-    {
-        DWORD bit_index;
-        uint8_t res = BitScanForward (&bit_index, card_word_value);
-        assert (res != 0);
-        card_word_value >>= bit_index;
-        bit_position += bit_index;
-    }
-    card = (last_card_word - &card_table[0]) * card_word_width + bit_position;
-    do
-    {
-        bit_position++;
-        card_word_value = card_word_value / 2;
-        if ((bit_position == card_word_width) && (last_card_word < &card_table [card_word_end-1]))
-        {
-            do
-            {
-                card_word_value = *(++last_card_word);
-            } while ((last_card_word < &card_table [card_word_end-1]) &&
-                     (card_word_value == ~0u /* (1 << card_word_width)-1 */));
-            bit_position = 0;
-        }
-    } while (card_word_value & 1);
-    end_card = (last_card_word - &card_table [0])* card_word_width + bit_position;
-    dprintf (3, ("fc: [%zx, %zx[", card, end_card));
-    return TRUE;
-}
-uint8_t* compute_next_end (heap_segment* seg, uint8_t* low)
-{
-    if ((low >=  heap_segment_mem (seg)) &&
-        (low < heap_segment_allocated (seg)))
-        return low;
-    else
-        return heap_segment_allocated (seg);
-}
-#ifndef USE_REGIONS
-uint8_t*
-gc_heap::compute_next_boundary (int gen_number,
-                                BOOL relocating)
-{
-    if (relocating && (gen_number == (settings.condemned_generation + 1)))
-    {
-        generation* gen = generation_of (gen_number - 1);
-        uint8_t* gen_alloc = generation_plan_allocation_start (gen);
-        assert (gen_alloc);
-        return gen_alloc;
-    }
-    else
-    {
-        assert (gen_number > settings.condemned_generation);
-        return generation_allocation_start (generation_of (gen_number - 1 ));
-    }
-}
-#endif //!USE_REGIONS
-inline void
-gc_heap::mark_through_cards_helper (uint8_t** poo, size_t& n_gen,
-                                    size_t& cg_pointers_found,
-                                    card_fn fn, uint8_t* nhigh,
-                                    uint8_t* next_boundary,
-                                    int condemned_gen,
-                                    int current_gen
-                                    CARD_MARKING_STEALING_ARG(gc_heap* hpt))
-{
-#if defined(FEATURE_CARD_MARKING_STEALING) && defined(MULTIPLE_HEAPS)
-    int thread = hpt->heap_number;
-#else
-    THREAD_FROM_HEAP;
-#ifdef MULTIPLE_HEAPS
-    gc_heap* hpt = this;
-#endif //MULTIPLE_HEAPS
-#endif //FEATURE_CARD_MARKING_STEALING && MULTIPLE_HEAPS
-#ifdef USE_REGIONS
-    assert (nhigh == 0);
-    assert (next_boundary == 0);
-    uint8_t* child_object = *poo;
-    if ((child_object < ephemeral_low) || (ephemeral_high <= child_object))
-        return;
-    int child_object_gen = get_region_gen_num (child_object);
-    int saved_child_object_gen = child_object_gen;
-    uint8_t* saved_child_object = child_object;
-    if (child_object_gen <= condemned_gen)
-    {
-        n_gen++;
-        call_fn(hpt,fn) (poo THREAD_NUMBER_ARG);
-    }
-    if (fn == &gc_heap::relocate_address)
-    {
-        child_object_gen = get_region_plan_gen_num (*poo);
-    }
-    if (child_object_gen < current_gen)
-    {
-        cg_pointers_found++;
-        dprintf (4, ("cg pointer %zx found, %zd so far",
-                        (size_t)*poo, cg_pointers_found ));
-    }
-#else //USE_REGIONS
-    assert (condemned_gen == -1);
-    if ((gc_low <= *poo) && (gc_high > *poo))
-    {
-        n_gen++;
-        call_fn(hpt,fn) (poo THREAD_NUMBER_ARG);
-    }
-#ifdef MULTIPLE_HEAPS
-    else if (*poo)
-    {
-        gc_heap* hp = heap_of_gc (*poo);
-        if (hp != this)
-        {
-            if ((hp->gc_low <= *poo) &&
-                (hp->gc_high > *poo))
-            {
-                n_gen++;
-                call_fn(hpt,fn) (poo THREAD_NUMBER_ARG);
-            }
-            if ((fn == &gc_heap::relocate_address) ||
-                ((hp->ephemeral_low <= *poo) &&
-                 (hp->ephemeral_high > *poo)))
-            {
-                cg_pointers_found++;
-            }
-        }
-    }
-#endif //MULTIPLE_HEAPS
-    if ((next_boundary <= *poo) && (nhigh > *poo))
-    {
-        cg_pointers_found ++;
-        dprintf (4, ("cg pointer %zx found, %zd so far",
-                     (size_t)*poo, cg_pointers_found ));
-    }
-#endif //USE_REGIONS
-}
-BOOL gc_heap::card_transition (uint8_t* po, uint8_t* end, size_t card_word_end,
-                               size_t& cg_pointers_found,
-                               size_t& n_eph, size_t& n_card_set,
-                               size_t& card, size_t& end_card,
-                               BOOL& foundp, uint8_t*& start_address,
-                               uint8_t*& limit, size_t& n_cards_cleared
-                               CARD_MARKING_STEALING_ARGS(card_marking_enumerator& card_mark_enumerator, heap_segment* seg, size_t &card_word_end_out))
-{
-    dprintf (3, ("pointer %zx past card %zx, cg %zd", (size_t)po, (size_t)card, cg_pointers_found));
-    BOOL passed_end_card_p = FALSE;
-    foundp = FALSE;
-    if (cg_pointers_found == 0)
-    {
-        dprintf(3,(" CC [%zx, %zx[ ",
-                (size_t)card_address(card), (size_t)po));
-        clear_cards (card, card_of(po));
-        n_card_set -= (card_of (po) - card);
-        n_cards_cleared += (card_of (po) - card);
-    }
-    n_eph +=cg_pointers_found;
-    cg_pointers_found = 0;
-    card = card_of (po);
-    if (card >= end_card)
-    {
-        passed_end_card_p = TRUE;
-        dprintf (3, ("card %zx exceeding end_card %zx",
-                    (size_t)card, (size_t)end_card));
-        foundp = find_card (card_table, card, card_word_end, end_card);
-        if (foundp)
-        {
-            n_card_set+= end_card - card;
-            start_address = card_address (card);
-            dprintf (3, ("NewC: %zx, start: %zx, end: %zx",
-                        (size_t)card, (size_t)start_address,
-                        (size_t)card_address (end_card)));
-        }
-        limit = min (end, card_address (end_card));
-#ifdef FEATURE_CARD_MARKING_STEALING
-        assert(!((card_word(end_card) < card_word_end) &&
-            card_set_p(end_card)));
-        if (!foundp)
-        {
-            card_word_end_out = 0;
-            foundp = find_next_chunk(card_mark_enumerator, seg, n_card_set, start_address, limit, card, end_card, card_word_end_out);
-        }
-#else
-        assert (!((limit < end) &&
-                card_set_p (end_card)));
-#endif
-    }
-    return passed_end_card_p;
-}
-#ifdef FEATURE_CARD_MARKING_STEALING
-bool card_marking_enumerator::move_next(heap_segment* seg, uint8_t*& low, uint8_t*& high)
-{
-    if (segment == nullptr)
-        return false;
-    uint32_t chunk_index = old_chunk_index;
-    old_chunk_index = INVALID_CHUNK_INDEX;
-    if (chunk_index == INVALID_CHUNK_INDEX)
-        chunk_index = Interlocked::Increment((volatile int32_t *)chunk_index_counter);
-    while (true)
-    {
-        uint32_t chunk_index_within_seg = chunk_index - segment_start_chunk_index;
-        uint8_t* start = heap_segment_mem(segment);
-        uint8_t* end = compute_next_end(segment, gc_low);
-        uint8_t* aligned_start = (uint8_t*)((size_t)start & ~(CARD_MARKING_STEALING_GRANULARITY - 1));
-        size_t seg_size = end - aligned_start;
-        uint32_t chunk_count_within_seg = (uint32_t)((seg_size + (CARD_MARKING_STEALING_GRANULARITY - 1)) / CARD_MARKING_STEALING_GRANULARITY);
-        if (chunk_index_within_seg < chunk_count_within_seg)
-        {
-            if (seg == segment)
-            {
-                low = (chunk_index_within_seg == 0) ? start : (aligned_start + (size_t)chunk_index_within_seg * CARD_MARKING_STEALING_GRANULARITY);
-                high = (chunk_index_within_seg + 1 == chunk_count_within_seg) ? end : (aligned_start + (size_t)(chunk_index_within_seg + 1) * CARD_MARKING_STEALING_GRANULARITY);
-                chunk_high = high;
-                dprintf (3, ("cme:mn ci: %u, low: %p, high: %p", chunk_index, low, high));
-                return true;
-            }
-            else
-            {
-#ifdef _DEBUG
-                for (heap_segment* cur_seg = seg; cur_seg != segment; cur_seg = heap_segment_next_in_range(cur_seg))
-                {
-                    assert(cur_seg);
-                }
-#endif //_DEBUG
-                old_chunk_index = chunk_index;
-                dprintf (3, ("cme:mn oci: %u, seg mismatch seg: %p, segment: %p", old_chunk_index, heap_segment_mem (segment), heap_segment_mem (seg)));
-                return false;
-            }
-        }
-        segment = heap_segment_next_in_range(segment);
-        segment_start_chunk_index += chunk_count_within_seg;
-        if (segment == nullptr)
-        {
-            old_chunk_index = chunk_index;
-            dprintf (3, ("cme:mn oci: %u no more segments", old_chunk_index));
-            return false;
-        }
-    }
-}
-bool gc_heap::find_next_chunk(card_marking_enumerator& card_mark_enumerator, heap_segment* seg, size_t& n_card_set,
-    uint8_t*& start_address, uint8_t*& limit,
-    size_t& card, size_t& end_card, size_t& card_word_end)
-{
-    while (true)
-    {
-        if (card_word_end != 0 && find_card(card_table, card, card_word_end, end_card))
-        {
-            assert(end_card <= card_word_end * card_word_width);
-            n_card_set += end_card - card;
-            start_address = card_address(card);
-            dprintf(3, ("NewC: %zx, start: %zx, end: %zx",
-                (size_t)card, (size_t)start_address,
-                (size_t)card_address(end_card)));
-            limit = min(card_mark_enumerator.get_chunk_high(), card_address(end_card));
-            dprintf (3, ("New run of cards on heap %d: [%zx,%zx[", heap_number, (size_t)start_address, (size_t)limit));
-            return true;
-        }
-        uint8_t* chunk_low = nullptr;
-        uint8_t* chunk_high = nullptr;
-        if (!card_mark_enumerator.move_next(seg, chunk_low, chunk_high))
-        {
-            dprintf (3, ("No more chunks on heap %d\n", heap_number));
-            return false;
-        }
-        card = max(card, card_of(chunk_low));
-        card_word_end = (card_of(align_on_card_word(chunk_high)) / card_word_width);
-        dprintf (3, ("Moved to next chunk on heap %d: [%zx,%zx[", heap_number, (size_t)chunk_low, (size_t)chunk_high));
-    }
-}
-#endif // FEATURE_CARD_MARKING_STEALING
-void gc_heap::mark_through_cards_for_segments (card_fn fn, BOOL relocating CARD_MARKING_STEALING_ARG(gc_heap* hpt))
-{
-#ifdef BACKGROUND_GC
-#ifdef USE_REGIONS
-    dprintf (3, ("current_sweep_pos is %p", current_sweep_pos));
-#else
-    dprintf (3, ("current_sweep_pos is %p, saved_sweep_ephemeral_seg is %p(%p)",
-                 current_sweep_pos, saved_sweep_ephemeral_seg, saved_sweep_ephemeral_start));
-#endif //USE_REGIONS
-    for (int i = get_start_generation_index(); i < max_generation; i++)
-    {
-        heap_segment* soh_seg = heap_segment_rw (generation_start_segment (generation_of (i)));
-        PREFIX_ASSUME(soh_seg != NULL);
-        while (soh_seg)
-        {
-            dprintf (3, ("seg %p, bgc_alloc: %p, alloc: %p",
-                soh_seg,
-                heap_segment_background_allocated (soh_seg),
-                heap_segment_allocated (soh_seg)));
-            soh_seg = heap_segment_next_rw (soh_seg);
-        }
-    }
-#endif //BACKGROUND_GC
-    size_t end_card = 0;
-    generation*   oldest_gen        = generation_of (max_generation);
-    int           curr_gen_number   = max_generation;
-#ifdef USE_REGIONS
-    uint8_t* low = 0;
-    uint8_t*      gen_boundary      = 0;
-    uint8_t*      next_boundary     = 0;
-    int condemned_gen               = settings.condemned_generation;
-    uint8_t*      nhigh             = 0;
-#else
-    uint8_t* low = gc_low;
-    uint8_t* high = gc_high;
-    uint8_t*      gen_boundary      = generation_allocation_start(generation_of(curr_gen_number - 1));
-    uint8_t*      next_boundary     = compute_next_boundary(curr_gen_number, relocating);
-    int condemned_gen = -1;
-    uint8_t*      nhigh             = (relocating ?
-                                       heap_segment_plan_allocated (ephemeral_heap_segment) : high);
-#endif //USE_REGIONS
-    heap_segment* seg               = heap_segment_rw (generation_start_segment (oldest_gen));
-    PREFIX_ASSUME(seg != NULL);
-    uint8_t*      beg               = get_soh_start_object (seg, oldest_gen);
-    uint8_t*      end               = compute_next_end (seg, low);
-    uint8_t*      last_object       = beg;
-    size_t  cg_pointers_found = 0;
-    size_t  card_word_end = (card_of (align_on_card_word (end)) / card_word_width);
-    size_t        n_eph             = 0;
-    size_t        n_gen             = 0;
-    size_t        n_card_set        = 0;
-    BOOL          foundp            = FALSE;
-    uint8_t*      start_address     = 0;
-    uint8_t*      limit             = 0;
-    size_t        card              = card_of (beg);
-#ifdef BACKGROUND_GC
-    BOOL consider_bgc_mark_p        = FALSE;
-    BOOL check_current_sweep_p      = FALSE;
-    BOOL check_saved_sweep_p        = FALSE;
-    should_check_bgc_mark (seg, &consider_bgc_mark_p, &check_current_sweep_p, &check_saved_sweep_p);
-#endif //BACKGROUND_GC
-    dprintf(3, ("CMs: %zx->%zx", (size_t)beg, (size_t)end));
-    size_t total_cards_cleared = 0;
-#ifdef FEATURE_CARD_MARKING_STEALING
-    card_marking_enumerator card_mark_enumerator (seg, low, (VOLATILE(uint32_t)*)&card_mark_chunk_index_soh);
-    card_word_end = 0;
-#endif // FEATURE_CARD_MARKING_STEALING
-    while (1)
-    {
-        if (card_of(last_object) > card)
-        {
-            dprintf (3, ("Found %zd cg pointers", cg_pointers_found));
-            if (cg_pointers_found == 0)
-            {
-                uint8_t* last_object_processed = last_object;
-#ifdef FEATURE_CARD_MARKING_STEALING
-                last_object_processed = min(limit, last_object);
-#endif // FEATURE_CARD_MARKING_STEALING
-                dprintf (3, (" Clearing cards [%zx, %zx[ ", (size_t)card_address(card), (size_t)last_object_processed));
-                clear_cards(card, card_of(last_object_processed));
-                n_card_set -= (card_of(last_object_processed) - card);
-                total_cards_cleared += (card_of(last_object_processed) - card);
-            }
-            n_eph += cg_pointers_found;
-            cg_pointers_found = 0;
-            card = card_of (last_object);
-        }
-        if (card >= end_card)
-        {
-#ifdef FEATURE_CARD_MARKING_STEALING
-            foundp = find_next_chunk(card_mark_enumerator, seg, n_card_set, start_address, limit, card, end_card, card_word_end);
-#else // FEATURE_CARD_MARKING_STEALING
-            foundp = find_card(card_table, card, card_word_end, end_card);
-            if (foundp)
-            {
-                n_card_set += end_card - card;
-                start_address = max (beg, card_address (card));
-            }
-            limit = min (end, card_address (end_card));
-#endif // FEATURE_CARD_MARKING_STEALING
-        }
-        if (!foundp || (last_object >= end) || (card_address (card) >= end))
-        {
-            if (foundp && (cg_pointers_found == 0))
-            {
-#ifndef USE_REGIONS
-                end_card = card_of (end);
-#endif
-                dprintf(3,(" Clearing cards [%zx, %zx[ ", (size_t)card_address(card),
-                            (size_t)card_address(end_card)));
-                clear_cards (card, end_card);
-                n_card_set -= (end_card - card);
-                total_cards_cleared += (end_card - card);
-            }
-            n_eph += cg_pointers_found;
-            cg_pointers_found = 0;
-#ifdef FEATURE_CARD_MARKING_STEALING
-            card_mark_enumerator.exhaust_segment(seg);
-#endif // FEATURE_CARD_MARKING_STEALING
-            seg = heap_segment_next_in_range (seg);
-#ifdef USE_REGIONS
-            if (!seg)
-            {
-                curr_gen_number--;
-                if (curr_gen_number > condemned_gen)
-                {
-                    seg = generation_start_segment (generation_of (curr_gen_number));
-#ifdef FEATURE_CARD_MARKING_STEALING
-                    card_mark_enumerator.switch_to_segment(seg);
-#endif // FEATURE_CARD_MARKING_STEALING
-                    dprintf (REGIONS_LOG, ("h%d switching to gen%d start seg %zx",
-                        heap_number, curr_gen_number, (size_t)seg));
-                }
-            }
-#endif //USE_REGIONS
-            if (seg)
-            {
-#ifdef BACKGROUND_GC
-                should_check_bgc_mark (seg, &consider_bgc_mark_p, &check_current_sweep_p, &check_saved_sweep_p);
-#endif //BACKGROUND_GC
-                beg = heap_segment_mem (seg);
-#ifdef USE_REGIONS
-                end = heap_segment_allocated (seg);
-#else
-                end = compute_next_end (seg, low);
-#endif //USE_REGIONS
-#ifdef FEATURE_CARD_MARKING_STEALING
-                card_word_end = 0;
-#else // FEATURE_CARD_MARKING_STEALING
-                card_word_end = card_of (align_on_card_word (end)) / card_word_width;
-#endif // FEATURE_CARD_MARKING_STEALING
-                card = card_of (beg);
-                last_object = beg;
-                end_card = 0;
-                continue;
-            }
-            else
-            {
-                break;
-            }
-        }
-        assert (card_set_p (card));
-        {
-            uint8_t* o = last_object;
-            o = find_first_object (start_address, last_object);
-            assert (o >= last_object);
-#ifndef USE_REGIONS
-            dprintf(3, ("c: %zx, o: %zx, l: %zx[ boundary: %zx",
-                   card, (size_t)o, (size_t)limit, (size_t)gen_boundary));
-#endif //USE_REGIONS
-            while (o < limit)
-            {
-                assert (Align (size (o)) >= Align (min_obj_size));
-                size_t s = size (o);
-                uint8_t* next_o =  o + Align (s);
-                uint8_t* cont_o = next_o;
-                Prefetch (next_o);
-#ifndef USE_REGIONS
-                if ((o >= gen_boundary) &&
-                    (seg == ephemeral_heap_segment))
-                {
-                    dprintf (3, ("switching gen boundary %zx", (size_t)gen_boundary));
-                    curr_gen_number--;
-                    assert ((curr_gen_number > 0));
-                    gen_boundary = generation_allocation_start
-                        (generation_of (curr_gen_number - 1));
-                    next_boundary = (compute_next_boundary
-                                     (curr_gen_number, relocating));
-                }
-#endif //!USE_REGIONS
-                dprintf (4, ("|%zx|", (size_t)o));
-                if (next_o < start_address)
-                {
-                    goto end_object;
-                }
-#ifdef BACKGROUND_GC
-                if (!fgc_should_consider_object (o, seg, consider_bgc_mark_p, check_current_sweep_p, check_saved_sweep_p))
-                {
-                    goto end_object;
-                }
-#endif //BACKGROUND_GC
-#ifdef COLLECTIBLE_CLASS
-                if (is_collectible(o))
-                {
-                    BOOL passed_end_card_p = FALSE;
-                    if (card_of (o) > card)
-                    {
-                        passed_end_card_p = card_transition (o, end, card_word_end,
-                            cg_pointers_found,
-                            n_eph, n_card_set,
-                            card, end_card,
-                            foundp, start_address,
-                            limit, total_cards_cleared
-                            CARD_MARKING_STEALING_ARGS(card_mark_enumerator, seg, card_word_end));
-                    }
-                    if ((!passed_end_card_p || foundp) && (card_of (o) == card))
-                    {
-                        if (fn == &gc_heap::relocate_address)
-                        {
-                            cg_pointers_found++;
-                        }
-                        else
-                        {
-                            uint8_t* class_obj = get_class_object (o);
-                            mark_through_cards_helper (&class_obj, n_gen,
-                                                       cg_pointers_found, fn,
-                                                       nhigh, next_boundary,
-                                                       condemned_gen, curr_gen_number CARD_MARKING_STEALING_ARG(hpt));
-                        }
-                    }
-                    if (passed_end_card_p)
-                    {
-                        if (foundp && (card_address (card) < next_o))
-                        {
-                            goto go_through_refs;
-                        }
-                        else if (foundp && (start_address < limit))
-                        {
-                            cont_o = find_first_object (start_address, o);
-                            goto end_object;
-                        }
-                        else
-                            goto end_limit;
-                    }
-                }
-go_through_refs:
-#endif //COLLECTIBLE_CLASS
-                if (contain_pointers (o))
-                {
-                    dprintf(3,("Going through %zx start_address: %zx", (size_t)o, (size_t)start_address));
-                    {
-                        dprintf (4, ("normal object path"));
-                        go_through_object
-                            (method_table(o), o, s, poo,
-                             start_address, use_start, (o + s),
-                             {
-                                 dprintf (4, ("<%zx>:%zx", (size_t)poo, (size_t)*poo));
-                                 if (card_of ((uint8_t*)poo) > card)
-                                 {
-                                     BOOL passed_end_card_p  = card_transition ((uint8_t*)poo, end,
-                                            card_word_end,
-                                            cg_pointers_found,
-                                            n_eph, n_card_set,
-                                            card, end_card,
-                                            foundp, start_address,
-                                            limit, total_cards_cleared
-                                            CARD_MARKING_STEALING_ARGS(card_mark_enumerator, seg, card_word_end));
-                                     if (passed_end_card_p)
-                                     {
-                                         if (foundp && (card_address (card) < next_o))
-                                         {
-                                             {
-                                                 if (ppstop <= (uint8_t**)start_address)
-                                                     {break;}
-                                                 else if (poo < (uint8_t**)start_address)
-                                                     {poo = (uint8_t**)start_address;}
-                                             }
-                                         }
-                                         else if (foundp && (start_address < limit))
-                                         {
-                                             cont_o = find_first_object (start_address, o);
-                                             goto end_object;
-                                         }
-                                         else
-                                             goto end_limit;
-                                     }
-                                 }
-                                 mark_through_cards_helper (poo, n_gen,
-                                                            cg_pointers_found, fn,
-                                                            nhigh, next_boundary,
-                                                            condemned_gen, curr_gen_number CARD_MARKING_STEALING_ARG(hpt));
-                             }
-                            );
-                    }
-                }
-            end_object:
-                if (((size_t)next_o / brick_size) != ((size_t) o / brick_size))
-                {
-                    if (brick_table [brick_of (o)] <0)
-                        fix_brick_to_highest (o, next_o);
-                }
-                o = cont_o;
-            }
-        end_limit:
-            last_object = o;
-        }
-    }
-    if (!relocating)
-    {
-#ifdef FEATURE_CARD_MARKING_STEALING
-        Interlocked::ExchangeAddPtr(&n_eph_soh, n_eph);
-        Interlocked::ExchangeAddPtr(&n_gen_soh, n_gen);
-        dprintf (3, ("h%d marking h%d Msoh: cross: %zd, useful: %zd, cards set: %zd, cards cleared: %zd, ratio: %d",
-            hpt->heap_number, heap_number, n_eph, n_gen, n_card_set, total_cards_cleared,
-            (n_eph ? (int)(((float)n_gen / (float)n_eph) * 100) : 0)));
-        dprintf (3, ("h%d marking h%d Msoh: total cross %zd, useful: %zd, running ratio: %d",
-            hpt->heap_number, heap_number, (size_t)n_eph_soh, (size_t)n_gen_soh,
-            (n_eph_soh ? (int)(((float)n_gen_soh / (float)n_eph_soh) * 100) : 0)));
-#else
-        generation_skip_ratio = ((n_eph > MIN_SOH_CROSS_GEN_REFS) ? (int)(((float)n_gen / (float)n_eph) * 100) : 100);
-        dprintf (3, ("marking h%d Msoh: cross: %zd, useful: %zd, cards set: %zd, cards cleared: %zd, ratio: %d",
-            heap_number, n_eph, n_gen, n_card_set, total_cards_cleared, generation_skip_ratio));
-#endif //FEATURE_CARD_MARKING_STEALING
-    }
-    else
-    {
-        dprintf (3, ("R: Msoh: cross: %zd, useful: %zd, cards set: %zd, cards cleared: %zd, ratio: %d",
-            n_gen, n_eph, n_card_set, total_cards_cleared, generation_skip_ratio));
-    }
-}
-#ifndef USE_REGIONS
-#ifdef SEG_REUSE_STATS
-size_t gc_heap::dump_buckets (size_t* ordered_indices, int count, size_t* total_size)
-{
-    size_t total_items = 0;
-    *total_size = 0;
-    for (int i = 0; i < count; i++)
-    {
-        total_items += ordered_indices[i];
-        *total_size += ordered_indices[i] << (MIN_INDEX_POWER2 + i);
-        dprintf (SEG_REUSE_LOG_0, ("[%d]%4d 2^%2d", heap_number, ordered_indices[i], (MIN_INDEX_POWER2 + i)));
-    }
-    dprintf (SEG_REUSE_LOG_0, ("[%d]Total %d items, total size is 0x%zx", heap_number, total_items, *total_size));
-    return total_items;
-}
-#endif // SEG_REUSE_STATS
-void gc_heap::count_plug (size_t last_plug_size, uint8_t*& last_plug)
-{
-    if (!pinned_plug_que_empty_p() && (last_plug == pinned_plug (oldest_pin())))
-    {
-        deque_pinned_plug();
-        update_oldest_pinned_plug();
-        dprintf (3, ("deque pin,now oldest pin is %p", pinned_plug (oldest_pin())));
-    }
-    else
-    {
-        size_t plug_size = last_plug_size + Align(min_obj_size);
-        BOOL is_padded = FALSE;
-#ifdef SHORT_PLUGS
-        plug_size += Align (min_obj_size);
-        is_padded = TRUE;
-#endif //SHORT_PLUGS
-#ifdef RESPECT_LARGE_ALIGNMENT
-        plug_size += switch_alignment_size (is_padded);
-#endif //RESPECT_LARGE_ALIGNMENT
-        total_ephemeral_plugs += plug_size;
-        size_t plug_size_power2 = round_up_power2 (plug_size);
-        ordered_plug_indices[relative_index_power2_plug (plug_size_power2)]++;
-        dprintf (SEG_REUSE_LOG_1, ("[%d]count_plug: adding 0x%p - %zd (2^%d) to ordered plug array",
-            heap_number,
-            last_plug,
-            plug_size,
-            (relative_index_power2_plug (plug_size_power2) + MIN_INDEX_POWER2)));
-    }
-}
-void gc_heap::count_plugs_in_brick (uint8_t* tree, uint8_t*& last_plug)
-{
-    assert ((tree != NULL));
-    if (node_left_child (tree))
-    {
-        count_plugs_in_brick (tree + node_left_child (tree), last_plug);
-    }
-    if (last_plug != 0)
-    {
-        uint8_t*  plug = tree;
-        size_t gap_size = node_gap_size (plug);
-        uint8_t*   gap = (plug - gap_size);
-        uint8_t*  last_plug_end = gap;
-        size_t  last_plug_size = (last_plug_end - last_plug);
-        dprintf (3, ("tree: %p, last plug: %p, gap size: %zx, gap: %p, last plug size: %zx",
-            tree, last_plug, gap_size, gap, last_plug_size));
-        if (tree == oldest_pinned_plug)
-        {
-            dprintf (3, ("tree %p is pinned, last plug is %p, size is %zx",
-                tree, last_plug, last_plug_size));
-            mark* m = oldest_pin();
-            if (m->has_pre_plug_info())
-            {
-                last_plug_size += sizeof (gap_reloc_pair);
-                dprintf (3, ("pin %p has pre plug, adjusting plug size to %zx", tree, last_plug_size));
-            }
-        }
-        count_plug (last_plug_size, last_plug);
-    }
-    last_plug = tree;
-    if (node_right_child (tree))
-    {
-        count_plugs_in_brick (tree + node_right_child (tree), last_plug);
-    }
-}
-void gc_heap::build_ordered_plug_indices ()
-{
-    memset (ordered_plug_indices, 0, sizeof(ordered_plug_indices));
-    memset (saved_ordered_plug_indices, 0, sizeof(saved_ordered_plug_indices));
-    uint8_t*  start_address = generation_limit (max_generation);
-    uint8_t* end_address = heap_segment_allocated (ephemeral_heap_segment);
-    size_t  current_brick = brick_of (start_address);
-    size_t  end_brick = brick_of (end_address - 1);
-    uint8_t* last_plug = 0;
-    reset_pinned_queue_bos();
-    while (!pinned_plug_que_empty_p())
-    {
-        mark* m = oldest_pin();
-        if ((m->first >= start_address) && (m->first < end_address))
-        {
-            dprintf (3, ("found a pin %p between %p and %p", m->first, start_address, end_address));
-            break;
-        }
-        else
-            deque_pinned_plug();
-    }
-    update_oldest_pinned_plug();
-    while (current_brick <= end_brick)
-    {
-        int brick_entry =  brick_table [ current_brick ];
-        if (brick_entry >= 0)
-        {
-            count_plugs_in_brick (brick_address (current_brick) + brick_entry -1, last_plug);
-        }
-        current_brick++;
-    }
-    if (last_plug !=0)
-    {
-        count_plug (end_address - last_plug, last_plug);
-    }
-    size_t extra_size = END_SPACE_AFTER_GC_FL;
-    total_ephemeral_plugs += extra_size;
-    dprintf (SEG_REUSE_LOG_0, ("Making sure we can fit a large object after fitting all plugs"));
-    ordered_plug_indices[relative_index_power2_plug (round_up_power2 (extra_size))]++;
-    memcpy (saved_ordered_plug_indices, ordered_plug_indices, sizeof(ordered_plug_indices));
-#ifdef SEG_REUSE_STATS
-    dprintf (SEG_REUSE_LOG_0, ("Plugs:"));
-    size_t total_plug_power2 = 0;
-    dump_buckets (ordered_plug_indices, MAX_NUM_BUCKETS, &total_plug_power2);
-    dprintf (SEG_REUSE_LOG_0, ("plugs: 0x%zx (rounded up to 0x%zx (%d%%))",
-                total_ephemeral_plugs,
-                total_plug_power2,
-                (total_ephemeral_plugs ?
-                    (total_plug_power2 * 100 / total_ephemeral_plugs) :
-                    0)));
-    dprintf (SEG_REUSE_LOG_0, ("-------------------"));
-#endif // SEG_REUSE_STATS
-}
-void gc_heap::init_ordered_free_space_indices ()
-{
-    memset (ordered_free_space_indices, 0, sizeof(ordered_free_space_indices));
-    memset (saved_ordered_free_space_indices, 0, sizeof(saved_ordered_free_space_indices));
-}
-void gc_heap::trim_free_spaces_indices ()
-{
-    trimmed_free_space_index = -1;
-    size_t max_count = max_free_space_items - 1;
-    size_t count = 0;
-    int i = 0;
-    for (i = (MAX_NUM_BUCKETS - 1); i >= 0; i--)
-    {
-        count += ordered_free_space_indices[i];
-        if (count >= max_count)
-        {
-            break;
-        }
-    }
-    ptrdiff_t extra_free_space_items = count - max_count;
-    if (extra_free_space_items > 0)
-    {
-        ordered_free_space_indices[i] -= extra_free_space_items;
-        free_space_items = max_count;
-        trimmed_free_space_index = i;
-    }
-    else
-    {
-        free_space_items = count;
-    }
-    if (i == -1)
-    {
-        i = 0;
-    }
-    free_space_buckets = MAX_NUM_BUCKETS - i;
-    for (--i; i >= 0; i--)
-    {
-        ordered_free_space_indices[i] = 0;
-    }
-    memcpy (saved_ordered_free_space_indices,
-            ordered_free_space_indices,
-            sizeof(ordered_free_space_indices));
-}
-BOOL gc_heap::can_fit_in_spaces_p (size_t* ordered_blocks, int small_index, size_t* ordered_spaces, int big_index)
-{
-    assert (small_index <= big_index);
-    assert (big_index < MAX_NUM_BUCKETS);
-    size_t small_blocks = ordered_blocks[small_index];
-    if (small_blocks == 0)
-    {
-        return TRUE;
-    }
-    size_t big_spaces = ordered_spaces[big_index];
-    if (big_spaces == 0)
-    {
-        return FALSE;
-    }
-    dprintf (SEG_REUSE_LOG_1, ("[%d]Fitting %zu 2^%d plugs into %zu 2^%d free spaces",
-        heap_number,
-        small_blocks, (small_index + MIN_INDEX_POWER2),
-        big_spaces, (big_index + MIN_INDEX_POWER2)));
-    size_t big_to_small = big_spaces << (big_index - small_index);
-    ptrdiff_t extra_small_spaces = big_to_small - small_blocks;
-    dprintf (SEG_REUSE_LOG_1, ("[%d]%zu 2^%d spaces can fit %zu 2^%d blocks",
-        heap_number,
-        big_spaces, (big_index + MIN_INDEX_POWER2), big_to_small, (small_index + MIN_INDEX_POWER2)));
-    BOOL can_fit = (extra_small_spaces >= 0);
-    if (can_fit)
-    {
-        dprintf (SEG_REUSE_LOG_1, ("[%d]Can fit with %zd 2^%d extras blocks",
-            heap_number,
-            extra_small_spaces, (small_index + MIN_INDEX_POWER2)));
-    }
-    int i = 0;
-    dprintf (SEG_REUSE_LOG_1, ("[%d]Setting # of 2^%d spaces to 0", heap_number, (big_index + MIN_INDEX_POWER2)));
-    ordered_spaces[big_index] = 0;
-    if (extra_small_spaces > 0)
-    {
-        dprintf (SEG_REUSE_LOG_1, ("[%d]Setting # of 2^%d blocks to 0", heap_number, (small_index + MIN_INDEX_POWER2)));
-        ordered_blocks[small_index] = 0;
-        for (i = small_index; i < big_index; i++)
-        {
-            if (extra_small_spaces & 1)
-            {
-                dprintf (SEG_REUSE_LOG_1, ("[%d]Increasing # of 2^%d spaces from %zu to %zu",
-                    heap_number,
-                    (i + MIN_INDEX_POWER2), ordered_spaces[i], (ordered_spaces[i] + 1)));
-                ordered_spaces[i] += 1;
-            }
-            extra_small_spaces >>= 1;
-        }
-        dprintf (SEG_REUSE_LOG_1, ("[%d]Finally increasing # of 2^%d spaces from %zu to %zu",
-            heap_number,
-            (i + MIN_INDEX_POWER2), ordered_spaces[i], (ordered_spaces[i] + extra_small_spaces)));
-        ordered_spaces[i] += extra_small_spaces;
-    }
-    else
-    {
-        dprintf (SEG_REUSE_LOG_1, ("[%d]Decreasing # of 2^%d blocks from %zu to %zu",
-            heap_number,
-            (small_index + MIN_INDEX_POWER2),
-            ordered_blocks[small_index],
-            (ordered_blocks[small_index] - big_to_small)));
-        ordered_blocks[small_index] -= big_to_small;
-    }
-#ifdef SEG_REUSE_STATS
-    size_t temp;
-    dprintf (SEG_REUSE_LOG_1, ("[%d]Plugs became:", heap_number));
-    dump_buckets (ordered_blocks, MAX_NUM_BUCKETS, &temp);
-    dprintf (SEG_REUSE_LOG_1, ("[%d]Free spaces became:", heap_number));
-    dump_buckets (ordered_spaces, MAX_NUM_BUCKETS, &temp);
-#endif //SEG_REUSE_STATS
-    return can_fit;
-}
-BOOL gc_heap::can_fit_blocks_p (size_t* ordered_blocks, int block_index, size_t* ordered_spaces, int* space_index)
-{
-    assert (*space_index >= block_index);
-    while (!can_fit_in_spaces_p (ordered_blocks, block_index, ordered_spaces, *space_index))
-    {
-        (*space_index)--;
-        if (*space_index < block_index)
-        {
-            return FALSE;
-        }
-    }
-    return TRUE;
-}
-BOOL gc_heap::can_fit_all_blocks_p (size_t* ordered_blocks, size_t* ordered_spaces, int count)
-{
-#ifdef FEATURE_STRUCTALIGN
-    return FALSE;
-#endif // FEATURE_STRUCTALIGN
-    int space_index = count - 1;
-    for (int block_index = (count - 1); block_index >= 0; block_index--)
-    {
-        if (!can_fit_blocks_p (ordered_blocks, block_index, ordered_spaces, &space_index))
-        {
-            return FALSE;
-        }
-    }
-    return TRUE;
-}
-void gc_heap::build_ordered_free_spaces (heap_segment* seg)
-{
-    assert (bestfit_seg);
-    bestfit_seg->add_buckets (MIN_INDEX_POWER2,
-                        ordered_free_space_indices,
-                        MAX_NUM_BUCKETS,
-                        free_space_items);
-    assert (settings.condemned_generation == max_generation);
-    uint8_t* first_address = heap_segment_mem (seg);
-    uint8_t* end_address   = heap_segment_reserved (seg);
-    reset_pinned_queue_bos();
-    mark* m = 0;
-    size_t eph_gen_starts = eph_gen_starts_size + Align (min_obj_size);
-    BOOL has_fit_gen_starts = FALSE;
-    while (!pinned_plug_que_empty_p())
-    {
-        m = oldest_pin();
-        if ((pinned_plug (m) >= first_address) &&
-            (pinned_plug (m) < end_address) &&
-            (pinned_len (m) >= eph_gen_starts))
-        {
-            assert ((pinned_plug (m) - pinned_len (m)) == bestfit_first_pin);
-            break;
-        }
-        else
-        {
-            deque_pinned_plug();
-        }
-    }
-    if (!pinned_plug_que_empty_p())
-    {
-        bestfit_seg->add ((void*)m, TRUE, TRUE);
-        deque_pinned_plug();
-        m = oldest_pin();
-        has_fit_gen_starts = TRUE;
-    }
-    while (!pinned_plug_que_empty_p() &&
-            ((pinned_plug (m) >= first_address) && (pinned_plug (m) < end_address)))
-    {
-        bestfit_seg->add ((void*)m, TRUE, FALSE);
-        deque_pinned_plug();
-        m = oldest_pin();
-    }
-    if (commit_end_of_seg)
-    {
-        if (!has_fit_gen_starts)
-        {
-            assert (bestfit_first_pin == heap_segment_plan_allocated (seg));
-        }
-        bestfit_seg->add ((void*)seg, FALSE, (!has_fit_gen_starts));
-    }
-#ifdef _DEBUG
-    bestfit_seg->check();
-#endif //_DEBUG
-}
-BOOL gc_heap::try_best_fit (BOOL end_of_segment_p)
-{
-    if (!end_of_segment_p)
-    {
-        trim_free_spaces_indices ();
-    }
-    BOOL can_bestfit = can_fit_all_blocks_p (ordered_plug_indices,
-                                             ordered_free_space_indices,
-                                             MAX_NUM_BUCKETS);
-    return can_bestfit;
-}
-BOOL gc_heap::best_fit (size_t free_space,
-                        size_t largest_free_space,
-                        size_t additional_space,
-                        BOOL* use_additional_space)
-{
-    dprintf (SEG_REUSE_LOG_0, ("gen%d: trying best fit mechanism", settings.condemned_generation));
-    assert (!additional_space || (additional_space && use_additional_space));
-    if (use_additional_space)
-    {
-        *use_additional_space = FALSE;
-    }
-    if (ordered_plug_indices_init == FALSE)
-    {
-        total_ephemeral_plugs = 0;
-        build_ordered_plug_indices();
-        ordered_plug_indices_init = TRUE;
-    }
-    else
-    {
-        memcpy (ordered_plug_indices, saved_ordered_plug_indices, sizeof(ordered_plug_indices));
-    }
-    if (total_ephemeral_plugs == END_SPACE_AFTER_GC_FL)
-    {
-        dprintf (SEG_REUSE_LOG_0, ("No ephemeral plugs to realloc, done"));
-        size_t empty_eph = (END_SPACE_AFTER_GC_FL + (Align (min_obj_size)) * (max_generation + 1));
-        BOOL can_fit_empty_eph = (largest_free_space >= empty_eph);
-        if (!can_fit_empty_eph)
-        {
-            can_fit_empty_eph = (additional_space >= empty_eph);
-            if (can_fit_empty_eph)
-            {
-                *use_additional_space = TRUE;
-            }
-        }
-        return can_fit_empty_eph;
-    }
-    if ((total_ephemeral_plugs + approximate_new_allocation()) >= (free_space + additional_space))
-    {
-        dprintf (SEG_REUSE_LOG_0, ("We won't have enough free space left in this segment after fitting, done"));
-        return FALSE;
-    }
-    if ((free_space + additional_space) == 0)
-    {
-        dprintf (SEG_REUSE_LOG_0, ("No free space in this segment, done"));
-        return FALSE;
-    }
-#ifdef SEG_REUSE_STATS
-    dprintf (SEG_REUSE_LOG_0, ("Free spaces:"));
-    size_t total_free_space_power2 = 0;
-    size_t total_free_space_items =
-        dump_buckets (ordered_free_space_indices,
-                      MAX_NUM_BUCKETS,
-                      &total_free_space_power2);
-    dprintf (SEG_REUSE_LOG_0, ("currently max free spaces is %zd", max_free_space_items));
-    dprintf (SEG_REUSE_LOG_0, ("Ephemeral plugs: 0x%zx, free space: 0x%zx (rounded down to 0x%zx (%zd%%)), additional free_space: 0x%zx",
-                total_ephemeral_plugs,
-                free_space,
-                total_free_space_power2,
-                (free_space ? (total_free_space_power2 * 100 / free_space) : 0),
-                additional_space));
-    size_t saved_all_free_space_indices[MAX_NUM_BUCKETS];
-    memcpy (saved_all_free_space_indices,
-            ordered_free_space_indices,
-            sizeof(saved_all_free_space_indices));
-#endif // SEG_REUSE_STATS
-    if (total_ephemeral_plugs > (free_space + additional_space))
-    {
-        return FALSE;
-    }
-    use_bestfit = try_best_fit(FALSE);
-    if (!use_bestfit && additional_space)
-    {
-        int relative_free_space_index = relative_index_power2_free_space (round_down_power2 (additional_space));
-        if (relative_free_space_index != -1)
-        {
-            int relative_plug_index = 0;
-            size_t plugs_to_fit = 0;
-            for (relative_plug_index = (MAX_NUM_BUCKETS - 1); relative_plug_index >= 0; relative_plug_index--)
-            {
-                plugs_to_fit = ordered_plug_indices[relative_plug_index];
-                if (plugs_to_fit != 0)
-                {
-                    break;
-                }
-            }
-            if ((relative_plug_index > relative_free_space_index) ||
-                ((relative_plug_index == relative_free_space_index) &&
-                (plugs_to_fit > 1)))
-            {
-#ifdef SEG_REUSE_STATS
-                dprintf (SEG_REUSE_LOG_0, ("additional space is 2^%d but we stopped at %d 2^%d plug(s)",
-                            (relative_free_space_index + MIN_INDEX_POWER2),
-                            plugs_to_fit,
-                            (relative_plug_index + MIN_INDEX_POWER2)));
-#endif // SEG_REUSE_STATS
-                goto adjust;
-            }
-            dprintf (SEG_REUSE_LOG_0, ("Adding end of segment (2^%d)", (relative_free_space_index + MIN_INDEX_POWER2)));
-            ordered_free_space_indices[relative_free_space_index]++;
-            use_bestfit = try_best_fit(TRUE);
-            if (use_bestfit)
-            {
-                free_space_items++;
-                if (relative_free_space_index > trimmed_free_space_index)
-                {
-                    *use_additional_space = TRUE;
-                }
-                else
-                {
-                    saved_ordered_free_space_indices[trimmed_free_space_index]++;
-                }
-            }
-        }
-    }
-adjust:
-    if (!use_bestfit)
-    {
-        dprintf (SEG_REUSE_LOG_0, ("couldn't fit..."));
-#ifdef SEG_REUSE_STATS
-        size_t saved_max = max_free_space_items;
-        BOOL temp_bestfit = FALSE;
-        dprintf (SEG_REUSE_LOG_0, ("----Starting experiment process----"));
-        dprintf (SEG_REUSE_LOG_0, ("----Couldn't fit with max free items %zd", max_free_space_items));
-        while (max_free_space_items <= total_free_space_items)
-        {
-            max_free_space_items += max_free_space_items / 2;
-            dprintf (SEG_REUSE_LOG_0, ("----Temporarily increasing max free spaces to %zd", max_free_space_items));
-            memcpy (ordered_free_space_indices,
-                    saved_all_free_space_indices,
-                    sizeof(ordered_free_space_indices));
-            if (try_best_fit(FALSE))
-            {
-                temp_bestfit = TRUE;
-                break;
-            }
-        }
-        if (temp_bestfit)
-        {
-            dprintf (SEG_REUSE_LOG_0, ("----With %zd max free spaces we could fit", max_free_space_items));
-        }
-        else
-        {
-            dprintf (SEG_REUSE_LOG_0, ("----Tried all free spaces and still couldn't fit, lost too much space"));
-        }
-        dprintf (SEG_REUSE_LOG_0, ("----Restoring max free spaces to %zd", saved_max));
-        max_free_space_items = saved_max;
-#endif // SEG_REUSE_STATS
-        if (free_space_items)
-        {
-            max_free_space_items = min ((size_t)MAX_NUM_FREE_SPACES, free_space_items * 2);
-            max_free_space_items = max (max_free_space_items, (size_t)MIN_NUM_FREE_SPACES);
-        }
-        else
-        {
-            max_free_space_items = MAX_NUM_FREE_SPACES;
-        }
-    }
-    dprintf (SEG_REUSE_LOG_0, ("Adjusted number of max free spaces to %zd", max_free_space_items));
-    dprintf (SEG_REUSE_LOG_0, ("------End of best fitting process------\n"));
-    return use_bestfit;
-}
-BOOL gc_heap::process_free_space (heap_segment* seg,
-                                  size_t free_space,
-                                  size_t min_free_size,
-                                  size_t min_cont_size,
-                                  size_t* total_free_space,
-                                  size_t* largest_free_space)
-{
-    *total_free_space += free_space;
-    *largest_free_space = max (*largest_free_space, free_space);
-#ifdef SIMPLE_DPRINTF
-    dprintf (SEG_REUSE_LOG_1, ("free space len: %zx, total free space: %zx, largest free space: %zx",
-                free_space, *total_free_space, *largest_free_space));
-#endif //SIMPLE_DPRINTF
-    if ((*total_free_space >= min_free_size) && (*largest_free_space >= min_cont_size))
-    {
-#ifdef SIMPLE_DPRINTF
-        dprintf (SEG_REUSE_LOG_0, ("(gen%d)total free: %zx(min: %zx), largest free: %zx(min: %zx). Found segment %zx to reuse without bestfit",
-            settings.condemned_generation,
-            *total_free_space, min_free_size, *largest_free_space, min_cont_size,
-            (size_t)seg));
-#else
-        UNREFERENCED_PARAMETER(seg);
-#endif //SIMPLE_DPRINTF
-        return TRUE;
-    }
-    int free_space_index = relative_index_power2_free_space (round_down_power2 (free_space));
-    if (free_space_index != -1)
-    {
-        ordered_free_space_indices[free_space_index]++;
-    }
-    return FALSE;
-}
-BOOL gc_heap::can_expand_into_p (heap_segment* seg, size_t min_free_size, size_t min_cont_size,
-                                 allocator* gen_allocator)
-{
-    min_cont_size += END_SPACE_AFTER_GC;
-    use_bestfit = FALSE;
-    commit_end_of_seg = FALSE;
-    bestfit_first_pin = 0;
-    uint8_t* first_address = heap_segment_mem (seg);
-    uint8_t* end_address   = heap_segment_reserved (seg);
-    size_t end_extra_space = end_space_after_gc();
-    if ((heap_segment_reserved (seg) - end_extra_space) <= heap_segment_plan_allocated (seg))
-    {
-        dprintf (SEG_REUSE_LOG_0, ("can_expand_into_p: can't use segment [%p %p, has less than %zu bytes at the end",
-                                   first_address, end_address, end_extra_space));
-        return FALSE;
-    }
-    end_address -= end_extra_space;
-    dprintf (SEG_REUSE_LOG_0, ("can_expand_into_p(gen%d): min free: %zx, min continuous: %zx",
-        settings.condemned_generation, min_free_size, min_cont_size));
-    size_t eph_gen_starts = eph_gen_starts_size;
-    if (settings.condemned_generation == max_generation)
-    {
-        size_t free_space = 0;
-        size_t largest_free_space = free_space;
-        dprintf (SEG_REUSE_LOG_0, ("can_expand_into_p: gen2: testing segment [%p %p", first_address, end_address));
-        reset_pinned_queue_bos();
-        mark* m = 0;
-        BOOL has_fit_gen_starts = FALSE;
-        init_ordered_free_space_indices ();
-        while (!pinned_plug_que_empty_p())
-        {
-            m = oldest_pin();
-            if ((pinned_plug (m) >= first_address) &&
-                (pinned_plug (m) < end_address) &&
-                (pinned_len (m) >= (eph_gen_starts + Align (min_obj_size))))
-            {
-                break;
-            }
-            else
-            {
-                deque_pinned_plug();
-            }
-        }
-        if (!pinned_plug_que_empty_p())
-        {
-            bestfit_first_pin = pinned_plug (m) - pinned_len (m);
-            if (process_free_space (seg,
-                                    pinned_len (m) - eph_gen_starts,
-                                    min_free_size, min_cont_size,
-                                    &free_space, &largest_free_space))
-            {
-                return TRUE;
-            }
-            deque_pinned_plug();
-            m = oldest_pin();
-            has_fit_gen_starts = TRUE;
-        }
-        dprintf (3, ("first pin is %p", pinned_plug (m)));
-        while (!pinned_plug_que_empty_p() &&
-               ((pinned_plug (m) >= first_address) && (pinned_plug (m) < end_address)))
-        {
-            dprintf (3, ("looking at pin %p", pinned_plug (m)));
-            if (process_free_space (seg,
-                                    pinned_len (m),
-                                    min_free_size, min_cont_size,
-                                    &free_space, &largest_free_space))
-            {
-                return TRUE;
-            }
-            deque_pinned_plug();
-            m = oldest_pin();
-        }
-        size_t end_space = (end_address - heap_segment_plan_allocated (seg));
-        size_t additional_space = ((min_free_size > free_space) ? (min_free_size - free_space) : 0);
-        dprintf (SEG_REUSE_LOG_0, ("end space: %zx; additional: %zx", end_space, additional_space));
-        if (end_space >= additional_space)
-        {
-            BOOL can_fit = TRUE;
-            commit_end_of_seg = TRUE;
-            if (largest_free_space < min_cont_size)
-            {
-                if (end_space >= min_cont_size)
-                {
-                    additional_space = max (min_cont_size, additional_space);
-                    dprintf (SEG_REUSE_LOG_0, ("(gen2)Found segment %p to reuse without bestfit, with committing end of seg for eph",
-                        seg));
-                }
-                else
-                {
-                    if (settings.concurrent)
-                    {
-                        can_fit = FALSE;
-                        commit_end_of_seg = FALSE;
-                    }
-                    else
-                    {
-                        size_t additional_space_bestfit = additional_space;
-                        if (!has_fit_gen_starts)
-                        {
-                            if (additional_space_bestfit < (eph_gen_starts + Align (min_obj_size)))
-                            {
-                                dprintf (SEG_REUSE_LOG_0, ("(gen2)Couldn't fit, gen starts not allocated yet and end space is too small: %zd",
-                                        additional_space_bestfit));
-                                return FALSE;
-                            }
-                            bestfit_first_pin = heap_segment_plan_allocated (seg);
-                            additional_space_bestfit -= eph_gen_starts;
-                        }
-                        can_fit = best_fit (free_space,
-                                            largest_free_space,
-                                            additional_space_bestfit,
-                                            &commit_end_of_seg);
-                        if (can_fit)
-                        {
-                            dprintf (SEG_REUSE_LOG_0, ("(gen2)Found segment %p to reuse with bestfit, %s committing end of seg",
-                                seg, (commit_end_of_seg ? "with" : "without")));
-                        }
-                        else
-                        {
-                            dprintf (SEG_REUSE_LOG_0, ("(gen2)Couldn't fit, total free space is %zx", (free_space + end_space)));
-                        }
-                    }
-                }
-            }
-            else
-            {
-                dprintf (SEG_REUSE_LOG_0, ("(gen2)Found segment %p to reuse without bestfit, with committing end of seg", seg));
-            }
-            assert (additional_space <= end_space);
-            if (commit_end_of_seg)
-            {
-                if (!grow_heap_segment (seg, heap_segment_plan_allocated (seg) + additional_space))
-                {
-                    dprintf (2, ("Couldn't commit end of segment?!"));
-                    use_bestfit = FALSE;
-                    return FALSE;
-                }
-                if (use_bestfit)
-                {
-                    size_t free_space_end_of_seg =
-                        heap_segment_committed (seg) - heap_segment_plan_allocated (seg);
-                    int relative_free_space_index = relative_index_power2_free_space (round_down_power2 (free_space_end_of_seg));
-                    saved_ordered_free_space_indices[relative_free_space_index]++;
-                }
-            }
-            if (use_bestfit)
-            {
-                memcpy (ordered_free_space_indices,
-                        saved_ordered_free_space_indices,
-                        sizeof(ordered_free_space_indices));
-                max_free_space_items = max ((size_t)MIN_NUM_FREE_SPACES, free_space_items * 3 / 2);
-                max_free_space_items = min ((size_t)MAX_NUM_FREE_SPACES, max_free_space_items);
-                dprintf (SEG_REUSE_LOG_0, ("could fit! %zd free spaces, %zd max", free_space_items, max_free_space_items));
-            }
-            return can_fit;
-        }
-        dprintf (SEG_REUSE_LOG_0, ("(gen2)Couldn't fit, total free space is %zx", (free_space + end_space)));
-        return FALSE;
-    }
-    else
-    {
-        assert (settings.condemned_generation == (max_generation-1));
-        size_t free_space = (end_address - heap_segment_plan_allocated (seg));
-        size_t largest_free_space = free_space;
-        dprintf (SEG_REUSE_LOG_0, ("can_expand_into_p: gen1: testing segment [%p %p", first_address, end_address));
-        uint8_t* free_list = 0;
-        unsigned int a_l_idx = gen_allocator->first_suitable_bucket(eph_gen_starts);
-        for (; a_l_idx < gen_allocator->number_of_buckets(); a_l_idx++)
-        {
-            free_list = gen_allocator->alloc_list_head_of (a_l_idx);
-            while (free_list)
-            {
-                if ((free_list >= first_address) &&
-                    (free_list < end_address) &&
-                    (unused_array_size (free_list) >= eph_gen_starts))
-                {
-                    goto next;
-                }
-                else
-                {
-                    free_list = free_list_slot (free_list);
-                }
-            }
-        }
-next:
-        if (free_list)
-        {
-            init_ordered_free_space_indices ();
-            if (process_free_space (seg,
-                                    unused_array_size (free_list) - eph_gen_starts + Align (min_obj_size),
-                                    min_free_size, min_cont_size,
-                                    &free_space, &largest_free_space))
-            {
-                return TRUE;
-            }
-            free_list = free_list_slot (free_list);
-        }
-        else
-        {
-            dprintf (SEG_REUSE_LOG_0, ("(gen1)Couldn't fit, no free list"));
-            return FALSE;
-        }
-        while (1)
-        {
-            while (free_list)
-            {
-                if ((free_list >= first_address) && (free_list < end_address) &&
-                    process_free_space (seg,
-                                        unused_array_size (free_list),
-                                        min_free_size, min_cont_size,
-                                        &free_space, &largest_free_space))
-                {
-                    return TRUE;
-                }
-                free_list = free_list_slot (free_list);
-            }
-            a_l_idx++;
-            if (a_l_idx < gen_allocator->number_of_buckets())
-            {
-                free_list = gen_allocator->alloc_list_head_of (a_l_idx);
-            }
-            else
-                break;
-        }
-        dprintf (SEG_REUSE_LOG_0, ("(gen1)Couldn't fit, total free space is %zx", free_space));
-        return FALSE;
-        /*
-        BOOL can_fit = best_fit (free_space, 0, NULL);
-        if (can_fit)
-        {
-            dprintf (SEG_REUSE_LOG_0, ("(gen1)Found segment %zx to reuse with bestfit", seg));
-        }
-        else
-        {
-            dprintf (SEG_REUSE_LOG_0, ("(gen1)Couldn't fit, total free space is %zx", free_space));
-        }
-        return can_fit;
-        */
-    }
-}
-void gc_heap::realloc_plug (size_t last_plug_size, uint8_t*& last_plug,
-                            generation* gen, uint8_t* start_address,
-                            unsigned int& active_new_gen_number,
-                            uint8_t*& last_pinned_gap, BOOL& leftp,
-                            BOOL shortened_p
-#ifdef SHORT_PLUGS
-                            , mark* pinned_plug_entry
-#endif //SHORT_PLUGS
-                            )
-{
-    if (!use_bestfit)
-    {
-        if ((active_new_gen_number > 1) &&
-            (last_plug >= generation_limit (active_new_gen_number)))
-        {
-            assert (last_plug >= start_address);
-            active_new_gen_number--;
-            realloc_plan_generation_start (generation_of (active_new_gen_number), gen);
-            assert (generation_plan_allocation_start (generation_of (active_new_gen_number)));
-            leftp = FALSE;
-        }
-    }
-    if (!pinned_plug_que_empty_p() && (last_plug == pinned_plug (oldest_pin())))
-    {
-        size_t  entry = deque_pinned_plug();
-        mark*  m = pinned_plug_of (entry);
-        size_t saved_pinned_len = pinned_len(m);
-        pinned_len(m) = last_plug - last_pinned_gap;
-        if (m->has_post_plug_info())
-        {
-            last_plug_size += sizeof (gap_reloc_pair);
-            dprintf (3, ("ra pinned %p was shortened, adjusting plug size to %zx", last_plug, last_plug_size))
-        }
-        last_pinned_gap = last_plug + last_plug_size;
-        dprintf (3, ("ra found pin %p, len: %zx->%zx, last_p: %p, last_p_size: %zx",
-            pinned_plug (m), saved_pinned_len, pinned_len (m), last_plug, last_plug_size));
-        leftp = FALSE;
-        {
-            size_t end_card = card_of (align_on_card (last_plug + last_plug_size));
-            size_t card = card_of (last_plug);
-            while (card != end_card)
-            {
-                set_card (card);
-                card++;
-            }
-        }
-    }
-    else if (last_plug >= start_address)
-    {
-#ifdef FEATURE_STRUCTALIGN
-        int requiredAlignment;
-        ptrdiff_t pad;
-        node_aligninfo (last_plug, requiredAlignment, pad);
-        uint8_t* reloc_plug = last_plug + node_relocation_distance (last_plug);
-        ptrdiff_t alignmentOffset = ComputeStructAlignPad(reloc_plug, requiredAlignment, 0);
-        if (!alignmentOffset)
-        {
-            alignmentOffset = requiredAlignment;
-        }
-        clear_node_aligninfo (last_plug);
-#else // FEATURE_STRUCTALIGN
-        clear_node_realigned (last_plug);
-#endif // FEATURE_STRUCTALIGN
-        BOOL adjacentp = FALSE;
-        BOOL set_padding_on_saved_p = FALSE;
-        if (shortened_p)
-        {
-            last_plug_size += sizeof (gap_reloc_pair);
-#ifdef SHORT_PLUGS
-            assert (pinned_plug_entry != NULL);
-            if (last_plug_size <= sizeof (plug_and_gap))
-            {
-                set_padding_on_saved_p = TRUE;
-            }
-#endif //SHORT_PLUGS
-            dprintf (3, ("ra plug %p was shortened, adjusting plug size to %zx", last_plug, last_plug_size))
-        }
-#ifdef SHORT_PLUGS
-        clear_padding_in_expand (last_plug, set_padding_on_saved_p, pinned_plug_entry);
-#endif //SHORT_PLUGS
-        uint8_t* new_address = allocate_in_expanded_heap(gen, last_plug_size, adjacentp, last_plug,
-#ifdef SHORT_PLUGS
-                                     set_padding_on_saved_p,
-                                     pinned_plug_entry,
-#endif //SHORT_PLUGS
-                                     TRUE, active_new_gen_number REQD_ALIGN_AND_OFFSET_ARG);
-        dprintf (3, ("ra NA: [%p, %p[: %zx", new_address, (new_address + last_plug_size), last_plug_size));
-        assert (new_address);
-        set_node_relocation_distance (last_plug, new_address - last_plug);
-#ifdef FEATURE_STRUCTALIGN
-        if (leftp && node_alignpad (last_plug) == 0)
-#else // FEATURE_STRUCTALIGN
-        if (leftp && !node_realigned (last_plug))
-#endif // FEATURE_STRUCTALIGN
-        {
-        }
-        dprintf (3,(" Re-allocating %zx->%zx len %zd", (size_t)last_plug, (size_t)new_address, last_plug_size));
-        leftp = adjacentp;
-    }
-}
-void gc_heap::realloc_in_brick (uint8_t* tree, uint8_t*& last_plug,
-                                uint8_t* start_address,
-                                generation* gen,
-                                unsigned int& active_new_gen_number,
-                                uint8_t*& last_pinned_gap, BOOL& leftp)
-{
-    assert (tree != NULL);
-    int   left_node = node_left_child (tree);
-    int   right_node = node_right_child (tree);
-    dprintf (3, ("ra: tree: %p, last_pin_gap: %p, last_p: %p, L: %d, R: %d",
-        tree, last_pinned_gap, last_plug, left_node, right_node));
-    if (left_node)
-    {
-        dprintf (3, ("LN: realloc %p(%p)", (tree + left_node), last_plug));
-        realloc_in_brick ((tree + left_node), last_plug, start_address,
-                          gen, active_new_gen_number, last_pinned_gap,
-                          leftp);
-    }
-    if (last_plug != 0)
-    {
-        uint8_t*  plug = tree;
-        BOOL has_pre_plug_info_p = FALSE;
-        BOOL has_post_plug_info_p = FALSE;
-        mark* pinned_plug_entry = get_next_pinned_entry (tree,
-                                                         &has_pre_plug_info_p,
-                                                         &has_post_plug_info_p,
-                                                         FALSE);
-        size_t gap_size = node_gap_size (plug);
-        uint8_t*   gap = (plug - gap_size);
-        uint8_t*  last_plug_end = gap;
-        size_t  last_plug_size = (last_plug_end - last_plug);
-        dprintf (3, ("ra: plug %p, gap size: %zd, last_pin_gap: %p, last_p: %p, last_p_end: %p, shortened: %d",
-            plug, gap_size, last_pinned_gap, last_plug, last_plug_end, (has_pre_plug_info_p ? 1 : 0)));
-        realloc_plug (last_plug_size, last_plug, gen, start_address,
-                      active_new_gen_number, last_pinned_gap,
-                      leftp, has_pre_plug_info_p
-#ifdef SHORT_PLUGS
-                      , pinned_plug_entry
-#endif //SHORT_PLUGS
-                      );
-    }
-    last_plug = tree;
-    if (right_node)
-    {
-        dprintf (3, ("RN: realloc %p(%p)", (tree + right_node), last_plug));
-        realloc_in_brick ((tree + right_node), last_plug, start_address,
-                          gen, active_new_gen_number, last_pinned_gap,
-                          leftp);
-    }
-}
-void
-gc_heap::realloc_plugs (generation* consing_gen, heap_segment* seg,
-                        uint8_t* start_address, uint8_t* end_address,
-                        unsigned active_new_gen_number)
-{
-    dprintf (3, ("--- Reallocing ---"));
-    if (use_bestfit)
-    {
-        int  gen_number = max_generation - 1;
-        while (gen_number >= 0)
-        {
-            generation* gen = generation_of (gen_number);
-            if (0 == generation_plan_allocation_start (gen))
-            {
-                generation_plan_allocation_start (gen) =
-                    bestfit_first_pin + (max_generation - gen_number - 1) * Align (min_obj_size);
-                generation_plan_allocation_start_size (gen) = Align (min_obj_size);
-                assert (generation_plan_allocation_start (gen));
-            }
-            gen_number--;
-        }
-    }
-    uint8_t* first_address = start_address;
-    reset_pinned_queue_bos();
-    uint8_t* planned_ephemeral_seg_end = heap_segment_plan_allocated (seg);
-    while (!pinned_plug_que_empty_p())
-    {
-        mark* m = oldest_pin();
-        if ((pinned_plug (m) >= planned_ephemeral_seg_end) && (pinned_plug (m) < end_address))
-        {
-            if (pinned_plug (m) < first_address)
-            {
-                first_address = pinned_plug (m);
-            }
-            break;
-        }
-        else
-            deque_pinned_plug();
-    }
-    size_t  current_brick = brick_of (first_address);
-    size_t  end_brick = brick_of (end_address-1);
-    uint8_t*  last_plug = 0;
-    uint8_t* last_pinned_gap = heap_segment_plan_allocated (seg);
-    BOOL leftp = FALSE;
-    dprintf (3, ("start addr: %p, first addr: %p, current oldest pin: %p",
-        start_address, first_address, pinned_plug (oldest_pin())));
-    while (current_brick <= end_brick)
-    {
-        int   brick_entry =  brick_table [ current_brick ];
-        if (brick_entry >= 0)
-        {
-            realloc_in_brick ((brick_address (current_brick) + brick_entry - 1),
-                              last_plug, start_address, consing_gen,
-                              active_new_gen_number, last_pinned_gap,
-                              leftp);
-        }
-        current_brick++;
-    }
-    if (last_plug != 0)
-    {
-        realloc_plug (end_address - last_plug, last_plug, consing_gen,
-                      start_address,
-                      active_new_gen_number, last_pinned_gap,
-                      leftp, FALSE
-#ifdef SHORT_PLUGS
-                      , NULL
-#endif //SHORT_PLUGS
-                      );
-    }
-    assert (last_pinned_gap >= heap_segment_mem (seg));
-    assert (last_pinned_gap <= heap_segment_committed (seg));
-    heap_segment_plan_allocated (seg) = last_pinned_gap;
-}
-void gc_heap::set_expand_in_full_gc (int condemned_gen_number)
-{
-    if (!should_expand_in_full_gc)
-    {
-        if ((condemned_gen_number != max_generation) &&
-            (settings.pause_mode != pause_low_latency) &&
-            (settings.pause_mode != pause_sustained_low_latency))
-        {
-            should_expand_in_full_gc = TRUE;
-        }
-    }
-}
-void gc_heap::save_ephemeral_generation_starts()
-{
-    for (int ephemeral_generation = 0; ephemeral_generation < max_generation; ephemeral_generation++)
-    {
-        saved_ephemeral_plan_start[ephemeral_generation] =
-            generation_plan_allocation_start (generation_of (ephemeral_generation));
-        saved_ephemeral_plan_start_size[ephemeral_generation] =
-            generation_plan_allocation_start_size (generation_of (ephemeral_generation));
-    }
-}
-generation* gc_heap::expand_heap (int condemned_generation,
-                                  generation* consing_gen,
-                                  heap_segment* new_heap_segment)
-{
-#ifndef _DEBUG
-    UNREFERENCED_PARAMETER(condemned_generation);
-#endif //!_DEBUG
-    assert (condemned_generation >= (max_generation -1));
-    unsigned int active_new_gen_number = max_generation; //Set one too high to get generation gap
-    uint8_t*  start_address = generation_limit (max_generation);
-    uint8_t*  end_address = heap_segment_allocated (ephemeral_heap_segment);
-    BOOL should_promote_ephemeral = FALSE;
-    ptrdiff_t eph_size = total_ephemeral_size;
-#ifdef BACKGROUND_GC
-    dprintf(2,("%s: ---- Heap Expansion ----", (gc_heap::background_running_p() ? "FGC" : "NGC")));
-#endif //BACKGROUND_GC
-    settings.heap_expansion = TRUE;
-    dprintf (2, ("Elevation: elevation = el_none"));
-    if (settings.should_lock_elevation && !expand_reused_seg_p())
-        settings.should_lock_elevation = FALSE;
-    heap_segment* new_seg = new_heap_segment;
-    if (!new_seg)
-        return consing_gen;
-    if (g_gc_card_table!= card_table)
-        copy_brick_card_table();
-    BOOL new_segment_p = (heap_segment_next (new_seg) == 0);
-    dprintf (2, ("new_segment_p %zx", (size_t)new_segment_p));
-    assert (generation_plan_allocation_start (generation_of (max_generation-1)));
-    assert (generation_plan_allocation_start (generation_of (max_generation-1)) >=
-            heap_segment_mem (ephemeral_heap_segment));
-    assert (generation_plan_allocation_start (generation_of (max_generation-1)) <=
-            heap_segment_committed (ephemeral_heap_segment));
-    assert (generation_plan_allocation_start (youngest_generation));
-    assert (generation_plan_allocation_start (youngest_generation) <
-            heap_segment_plan_allocated (ephemeral_heap_segment));
-    if (settings.pause_mode == pause_no_gc)
-    {
-        if ((size_t)(heap_segment_reserved (new_seg) - heap_segment_mem (new_seg)) < (eph_size + soh_allocation_no_gc))
-            should_promote_ephemeral = TRUE;
-    }
-    else
-    {
-        if (!use_bestfit)
-        {
-            should_promote_ephemeral = dt_low_ephemeral_space_p (tuning_deciding_promote_ephemeral);
-        }
-    }
-    if (should_promote_ephemeral)
-    {
-        ephemeral_promotion = TRUE;
-        get_gc_data_per_heap()->set_mechanism (gc_heap_expand, expand_new_seg_ep);
-        dprintf (2, ("promoting ephemeral"));
-        save_ephemeral_generation_starts();
-        generation* max_gen = generation_of (max_generation);
-        for (int i = 1; i < max_generation; i++)
-        {
-            generation_free_obj_space (max_gen) +=
-                generation_free_obj_space (generation_of (i));
-            dprintf (2, ("[h%d] maxgen freeobj + %zd=%zd",
-                heap_number, generation_free_obj_space (generation_of (i)),
-                generation_free_obj_space (max_gen)));
-        }
-        heap_segment_used (new_seg) = heap_segment_committed (new_seg);
-    }
-    else
-    {
-        if ((eph_size > 0) && new_segment_p)
-        {
-#ifdef FEATURE_STRUCTALIGN
-            eph_size += ComputeStructAlignPad(heap_segment_mem (new_seg), MAX_STRUCTALIGN, OBJECT_ALIGNMENT_OFFSET);
-#endif // FEATURE_STRUCTALIGN
-#ifdef RESPECT_LARGE_ALIGNMENT
-            eph_size += switch_alignment_size(FALSE);
-#endif //RESPECT_LARGE_ALIGNMENT
-            if (grow_heap_segment (new_seg, heap_segment_mem (new_seg) + eph_size) == 0)
-            {
-                fgm_result.set_fgm (fgm_commit_eph_segment, eph_size, FALSE);
-                return consing_gen;
-            }
-            heap_segment_used (new_seg) = heap_segment_committed (new_seg);
-        }
-        heap_segment_plan_allocated (ephemeral_heap_segment) =
-            generation_plan_allocation_start (generation_of (max_generation-1));
-        dprintf (3, ("Old ephemeral allocated set to %zx",
-                    (size_t)heap_segment_plan_allocated (ephemeral_heap_segment)));
-    }
-    if (new_segment_p)
-    {
-        size_t first_brick = brick_of (heap_segment_mem (new_seg));
-        set_brick (first_brick,
-                heap_segment_mem (new_seg) - brick_address (first_brick));
-    }
-    generation_allocation_limit (consing_gen) =
-        heap_segment_plan_allocated (ephemeral_heap_segment);
-    generation_allocation_pointer (consing_gen) = generation_allocation_limit (consing_gen);
-    generation_allocation_segment (consing_gen) = ephemeral_heap_segment;
-    {
-        int generation_num = max_generation-1;
-        while (generation_num >= 0)
-        {
-            generation* gen = generation_of (generation_num);
-            generation_plan_allocation_start (gen) = 0;
-            generation_num--;
-        }
-    }
-    heap_segment* old_seg = ephemeral_heap_segment;
-    ephemeral_heap_segment = new_seg;
-    consing_gen = ensure_ephemeral_heap_segment (consing_gen);
-    if (!should_promote_ephemeral)
-    {
-        realloc_plugs (consing_gen, old_seg, start_address, end_address,
-                    active_new_gen_number);
-    }
-    if (!use_bestfit)
-    {
-        repair_allocation_in_expanded_heap (consing_gen);
-    }
-#ifdef _DEBUG
-    {
-        int generation_num = max_generation-1;
-        while (generation_num >= 0)
-        {
-            generation* gen = generation_of (generation_num);
-            assert (generation_plan_allocation_start (gen));
-            generation_num--;
-        }
-    }
-#endif // _DEBUG
-    if (!new_segment_p)
-    {
-        dprintf (2, ("Demoting ephemeral segment"));
-        settings.demotion = TRUE;
-        get_gc_data_per_heap()->set_mechanism_bit (gc_demotion_bit);
-        demotion_low = heap_segment_mem (ephemeral_heap_segment);
-        demotion_high = heap_segment_reserved (ephemeral_heap_segment);
-    }
-    else
-    {
-        demotion_low = MAX_PTR;
-        demotion_high = 0;
-#ifndef MULTIPLE_HEAPS
-        settings.demotion = FALSE;
-        get_gc_data_per_heap()->clear_mechanism_bit (gc_demotion_bit);
-#endif //!MULTIPLE_HEAPS
-    }
-    if (!should_promote_ephemeral && new_segment_p)
-    {
-        assert ((ptrdiff_t)total_ephemeral_size <= eph_size);
-    }
-    if (heap_segment_mem (old_seg) == heap_segment_plan_allocated (old_seg))
-    {
-        verify_no_pins (heap_segment_mem (old_seg), heap_segment_reserved (old_seg));
-    }
-    verify_no_pins (heap_segment_plan_allocated (old_seg), heap_segment_reserved(old_seg));
-    dprintf(2,("---- End of Heap Expansion ----"));
-    return consing_gen;
-}
-#endif //!USE_REGIONS
-BOOL gc_heap::expand_reused_seg_p()
-{
-#ifdef USE_REGIONS
-    return FALSE;
-#else
-    BOOL reused_seg = FALSE;
-    int heap_expand_mechanism = gc_data_per_heap.get_mechanism (gc_heap_expand);
-    if ((heap_expand_mechanism == expand_reuse_bestfit) ||
-        (heap_expand_mechanism == expand_reuse_normal))
-    {
-        reused_seg = TRUE;
-    }
-    return reused_seg;
-#endif //USE_REGIONS
-}
-void gc_heap::verify_no_pins (uint8_t* start, uint8_t* end)
-{
-#ifdef VERIFY_HEAP
-    if (GCConfig::GetHeapVerifyLevel() & GCConfig::HEAPVERIFY_GC)
-    {
-        BOOL contains_pinned_plugs = FALSE;
-        size_t mi = 0;
-        mark* m = 0;
-        while (mi != mark_stack_tos)
-        {
-            m = pinned_plug_of (mi);
-            if ((pinned_plug (m) >= start) && (pinned_plug (m) < end))
-            {
-                contains_pinned_plugs = TRUE;
-                break;
-            }
-            else
-                mi++;
-        }
-        if (contains_pinned_plugs)
-        {
-            FATAL_GC_ERROR();
-        }
-    }
-#endif //VERIFY_HEAP
-}
-void gc_heap::set_static_data()
-{
-    static_data* pause_mode_sdata = static_data_table[latency_level];
-    for (int i = 0; i < total_generation_count; i++)
-    {
-        dynamic_data* dd = dynamic_data_of (i);
-        static_data* sdata = &pause_mode_sdata[i];
-        dd->sdata = sdata;
-        dd->min_size = sdata->min_size;
-        dprintf (GTC_LOG, ("PM: %d, gen%d:  min: %zd, max: %zd, fr_l: %zd, fr_b: %d%%",
-            settings.pause_mode,i,
-            dd->min_size, dd_max_size (dd),
-            sdata->fragmentation_limit, (int)(sdata->fragmentation_burden_limit * 100)));
-    }
-}
-void gc_heap::init_static_data()
-{
-    size_t gen0_min_size = get_gen0_min_size();
-    size_t gen0_max_size =
-#ifdef MULTIPLE_HEAPS
-        max ((size_t)6*1024*1024, min ( Align(soh_segment_size/2), (size_t)200*1024*1024));
-#else //MULTIPLE_HEAPS
-        (
-#ifdef BACKGROUND_GC
-            gc_can_use_concurrent ?
-            6*1024*1024 :
-#endif //BACKGROUND_GC
-            max ((size_t)6*1024*1024,  min ( Align(soh_segment_size/2), (size_t)200*1024*1024))
-        );
-#endif //MULTIPLE_HEAPS
-    gen0_max_size = max (gen0_min_size, gen0_max_size);
-    if (heap_hard_limit)
-    {
-        size_t gen0_max_size_seg = soh_segment_size / 4;
-        dprintf (GTC_LOG, ("limit gen0 max %zd->%zd", gen0_max_size, gen0_max_size_seg));
-        gen0_max_size = min (gen0_max_size, gen0_max_size_seg);
-    }
-    size_t gen0_max_size_config = (size_t)GCConfig::GetGCGen0MaxBudget();
-    if (gen0_max_size_config)
-    {
-        gen0_max_size = min (gen0_max_size, gen0_max_size_config);
-#ifdef FEATURE_EVENT_TRACE
-        gen0_max_budget_from_config = gen0_max_size;
-#endif //FEATURE_EVENT_TRACE
-    }
-    gen0_max_size = Align (gen0_max_size);
-    gen0_min_size = min (gen0_min_size, gen0_max_size);
-    size_t gen1_max_size = (size_t)
-#ifdef MULTIPLE_HEAPS
-        max ((size_t)6*1024*1024, Align(soh_segment_size/2));
-#else //MULTIPLE_HEAPS
-        (
-#ifdef BACKGROUND_GC
-            gc_can_use_concurrent ?
-            6*1024*1024 :
-#endif //BACKGROUND_GC
-            max ((size_t)6*1024*1024, Align(soh_segment_size/2))
-        );
-#endif //MULTIPLE_HEAPS
-    size_t gen1_max_size_config = (size_t)GCConfig::GetGCGen1MaxBudget();
-    if (gen1_max_size_config)
-    {
-        gen1_max_size = min (gen1_max_size, gen1_max_size_config);
-    }
-    gen1_max_size = Align (gen1_max_size);
-    dprintf (GTC_LOG, ("gen0 min: %zd, max: %zd, gen1 max: %zd",
-        gen0_min_size, gen0_max_size, gen1_max_size));
-    for (int i = latency_level_first; i <= latency_level_last; i++)
-    {
-        static_data_table[i][0].min_size = gen0_min_size;
-        static_data_table[i][0].max_size = gen0_max_size;
-        static_data_table[i][1].max_size = gen1_max_size;
-    }
-}
-bool gc_heap::init_dynamic_data()
-{
-    uint64_t now_raw_ts = RawGetHighPrecisionTimeStamp ();
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-    start_raw_ts = now_raw_ts;
-#endif //HEAP_BALANCE_INSTRUMENTATION
-    uint64_t now = (uint64_t)((double)now_raw_ts * qpf_us);
-    set_static_data();
-    if (heap_number == 0)
-    {
-        process_start_time = now;
-        smoothed_desired_total[0] = dynamic_data_of (0)->min_size * n_heaps;
-#ifdef DYNAMIC_HEAP_COUNT
-        last_suspended_end_time = now;
-#endif //DYNAMIC_HEAP_COUNT
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-        last_gc_end_time_us = now;
-        dprintf (HEAP_BALANCE_LOG, ("qpf=%zd, start: %zd(%d)", qpf, start_raw_ts, now));
-#endif //HEAP_BALANCE_INSTRUMENTATION
-    }
-    for (int i = 0; i < total_generation_count; i++)
-    {
-        dynamic_data* dd = dynamic_data_of (i);
-        dd->gc_clock = 0;
-        dd->time_clock = now;
-        dd->previous_time_clock = now;
-        dd->current_size = 0;
-        dd->promoted_size = 0;
-        dd->collection_count = 0;
-        dd->new_allocation = dd->min_size;
-        dd->gc_new_allocation = dd->new_allocation;
-        dd->desired_allocation = dd->new_allocation;
-        dd->fragmentation = 0;
-    }
-    return true;
-}
-float gc_heap::surv_to_growth (float cst, float limit, float max_limit)
-{
-    if (cst < ((max_limit - limit ) / (limit * (max_limit-1.0f))))
-        return ((limit - limit*cst) / (1.0f - (cst * limit)));
-    else
-        return max_limit;
-}
-static size_t linear_allocation_model (float allocation_fraction, size_t new_allocation,
-                                       size_t previous_desired_allocation, float time_since_previous_collection_secs)
-{
-    if ((allocation_fraction < 0.95) && (allocation_fraction > 0.0))
-    {
-        const float decay_time = 5*60.0f; // previous desired allocation expires over 5 minutes
-        float decay_factor = (decay_time <= time_since_previous_collection_secs) ?
-                                0 :
-                                ((decay_time - time_since_previous_collection_secs) / decay_time);
-        float previous_allocation_factor = (1.0f - allocation_fraction) * decay_factor;
-        dprintf (2, ("allocation fraction: %d, decay factor: %d, previous allocation factor: %d",
-            (int)(allocation_fraction*100.0), (int)(decay_factor*100.0), (int)(previous_allocation_factor*100.0)));
-        new_allocation = (size_t)((1.0 - previous_allocation_factor)*new_allocation + previous_allocation_factor * previous_desired_allocation);
-    }
-    return new_allocation;
-}
-size_t gc_heap::desired_new_allocation (dynamic_data* dd,
-                                        size_t out, int gen_number,
-                                        int pass)
-{
-    gc_history_per_heap* current_gc_data_per_heap = get_gc_data_per_heap();
-    if (dd_begin_data_size (dd) == 0)
-    {
-        size_t new_allocation = dd_min_size (dd);
-        current_gc_data_per_heap->gen_data[gen_number].new_allocation = new_allocation;
-        return new_allocation;
-    }
-    else
-    {
-        float     cst;
-        size_t    previous_desired_allocation = dd_desired_allocation (dd);
-        size_t    current_size = dd_current_size (dd);
-        float     max_limit = dd_max_limit (dd);
-        float     limit = dd_limit (dd);
-        size_t    min_gc_size = dd_min_size (dd);
-        float     f = 0;
-        size_t    max_size = dd_max_size (dd);
-        size_t    new_allocation = 0;
-        float     time_since_previous_collection_secs = (dd_time_clock (dd) - dd_previous_time_clock (dd))*1e-6f;
-        float allocation_fraction = (float) (dd_desired_allocation (dd) - dd_gc_new_allocation (dd)) / (float) (dd_desired_allocation (dd));
-        if (gen_number >= max_generation)
-        {
-            size_t    new_size = 0;
-            cst = min (1.0f, float (out) / float (dd_begin_data_size (dd)));
-            f = surv_to_growth (cst, limit, max_limit);
-            if (conserve_mem_setting != 0)
-            {
-                float f_conserve = ((10.0f / conserve_mem_setting) - 1) * 0.5f + 1.0f;
-                f = min (f, f_conserve);
-            }
-            size_t max_growth_size = (size_t)(max_size / f);
-            if (current_size >= max_growth_size)
-            {
-                new_size = max_size;
-            }
-            else
-            {
-                new_size = (size_t) min (max ( (size_t)(f * current_size), min_gc_size), max_size);
-            }
-            assert ((new_size >= current_size) || (new_size == max_size));
-            if (gen_number == max_generation)
-            {
-                new_allocation  =  max((new_size - current_size), min_gc_size);
-                new_allocation = linear_allocation_model (allocation_fraction, new_allocation,
-                                                          dd_desired_allocation (dd), time_since_previous_collection_secs);
-                if (
-#ifdef BGC_SERVO_TUNING
-                    !bgc_tuning::fl_tuning_triggered &&
-#endif //BGC_SERVO_TUNING
-                    (conserve_mem_setting == 0) &&
-                    (dd_fragmentation (dd) > ((size_t)((f-1)*current_size))))
-                {
-                    size_t new_allocation1 = max (min_gc_size,
-                                                  (size_t)((float)new_allocation * current_size /
-                                                           ((float)current_size + 2*dd_fragmentation (dd))));
-                    dprintf (2, ("Reducing max_gen allocation due to fragmentation from %zd to %zd",
-                                 new_allocation, new_allocation1));
-                    new_allocation = new_allocation1;
-                }
-            }
-            else // not a SOH generation
-            {
-                uint32_t memory_load = 0;
-                uint64_t available_physical = 0;
-                get_memory_info (&memory_load, &available_physical);
-#ifdef TRACE_GC
-                if (heap_hard_limit)
-                {
-                    size_t allocated = 0;
-                    size_t committed = uoh_committed_size (gen_number, &allocated);
-                    dprintf (1, ("GC#%zd h%d, GMI: UOH budget, UOH commit %zd (obj %zd, frag %zd), total commit: %zd (recorded: %zd)",
-                        (size_t)settings.gc_index, heap_number,
-                        committed, allocated,
-                        dd_fragmentation (dynamic_data_of (gen_number)),
-                        get_total_committed_size(), (current_total_committed - current_total_committed_bookkeeping)));
-                }
-#endif //TRACE_GC
-                if (heap_number == 0)
-                    settings.exit_memory_load = memory_load;
-                if (available_physical > 1024*1024)
-                    available_physical -= 1024*1024;
-                uint64_t available_free = available_physical + (uint64_t)generation_free_list_space (generation_of (gen_number));
-                if (available_free > (uint64_t)MAX_PTR)
-                {
-                    available_free = (uint64_t)MAX_PTR;
-                }
-                new_allocation = max (min(max((new_size - current_size), dd_desired_allocation (dynamic_data_of (max_generation))),
-                                          (size_t)available_free),
-                                      max ((current_size/4), min_gc_size));
-                new_allocation = linear_allocation_model (allocation_fraction, new_allocation,
-                                                          dd_desired_allocation (dd), time_since_previous_collection_secs);
-            }
-        }
-        else
-        {
-            size_t survivors = out;
-            cst = float (survivors) / float (dd_begin_data_size (dd));
-            f = surv_to_growth (cst, limit, max_limit);
-            new_allocation = (size_t) min (max ((size_t)(f * (survivors)), min_gc_size), max_size);
-            new_allocation = linear_allocation_model (allocation_fraction, new_allocation,
-                                                      dd_desired_allocation (dd), time_since_previous_collection_secs);
-#ifdef DYNAMIC_HEAP_COUNT
-            if (dynamic_adaptation_mode != dynamic_adaptation_to_application_sizes)
-#endif //DYNAMIC_HEAP_COUNT
-            {
-                if (gen_number == 0)
-                {
-                    if (pass == 0)
-                    {
-                        size_t free_space = generation_free_list_space (generation_of (gen_number));
-                        dprintf (GTC_LOG, ("frag: %zd, min: %zd", free_space, min_gc_size));
-                        if (free_space > min_gc_size)
-                        {
-                            settings.gen0_reduction_count = 2;
-                        }
-                        else
-                        {
-                            if (settings.gen0_reduction_count > 0)
-                                settings.gen0_reduction_count--;
-                        }
-                    }
-                    if (settings.gen0_reduction_count > 0)
-                    {
-                        dprintf (2, ("Reducing new allocation based on fragmentation"));
-                        new_allocation = min (new_allocation,
-                                              max (min_gc_size, (max_size/3)));
-                    }
-                }
-            }
-        }
-        size_t new_allocation_ret = Align (new_allocation, get_alignment_constant (gen_number <= max_generation));
-        int gen_data_index = gen_number;
-        gc_generation_data* gen_data = &(current_gc_data_per_heap->gen_data[gen_data_index]);
-        gen_data->new_allocation = new_allocation_ret;
-        dd_surv (dd) = cst;
-        dprintf (1, (ThreadStressLog::gcDesiredNewAllocationMsg(),
-                    heap_number, gen_number, out, current_size, (dd_desired_allocation (dd) - dd_gc_new_allocation (dd)),
-                    (int)(cst*100), (int)(f*100), current_size + new_allocation, new_allocation));
-        return new_allocation_ret;
-    }
-}
-size_t gc_heap::generation_plan_size (int gen_number)
-{
-#ifdef USE_REGIONS
-    size_t result = 0;
-    heap_segment* seg = heap_segment_rw (generation_start_segment (generation_of (gen_number)));
-    while (seg)
-    {
-        uint8_t* end = heap_segment_plan_allocated (seg);
-        result += end - heap_segment_mem (seg);
-        dprintf (REGIONS_LOG, ("h%d size + %zd (%p - %p) -> %zd",
-            heap_number, (end - heap_segment_mem (seg)),
-            heap_segment_mem (seg), end, result));
-        seg = heap_segment_next (seg);
-    }
-    return result;
-#else //USE_REGIONS
-    if (0 == gen_number)
-        return (size_t)max((heap_segment_plan_allocated (ephemeral_heap_segment) -
-                    generation_plan_allocation_start (generation_of (gen_number))),
-                   (ptrdiff_t)Align (min_obj_size));
-    else
-    {
-        generation* gen = generation_of (gen_number);
-        if (heap_segment_rw (generation_start_segment (gen)) == ephemeral_heap_segment)
-            return (generation_plan_allocation_start (generation_of (gen_number - 1)) -
-                    generation_plan_allocation_start (generation_of (gen_number)));
-        else
-        {
-            size_t gensize = 0;
-            heap_segment* seg = heap_segment_rw (generation_start_segment (gen));
-            PREFIX_ASSUME(seg != NULL);
-            while (seg && (seg != ephemeral_heap_segment))
-            {
-                gensize += heap_segment_plan_allocated (seg) -
-                           heap_segment_mem (seg);
-                seg = heap_segment_next_rw (seg);
-            }
-            if (seg)
-            {
-                gensize += (generation_plan_allocation_start (generation_of (gen_number - 1)) -
-                            heap_segment_mem (ephemeral_heap_segment));
-            }
-            return gensize;
-        }
-    }
-#endif //USE_REGIONS
-}
-size_t gc_heap::generation_size (int gen_number)
-{
-#ifdef USE_REGIONS
-    size_t result = 0;
-    heap_segment* seg = heap_segment_rw (generation_start_segment (generation_of (gen_number)));
-    while (seg)
-    {
-        uint8_t* end = heap_segment_allocated (seg);
-        result += end - heap_segment_mem (seg);
-        dprintf (2, ("h%d size + %zd (%p - %p) -> %zd",
-            heap_number, (end - heap_segment_mem (seg)),
-            heap_segment_mem (seg), end, result));
-        seg = heap_segment_next (seg);
-    }
-    return result;
-#else //USE_REGIONS
-    if (0 == gen_number)
-        return (size_t)max((heap_segment_allocated (ephemeral_heap_segment) -
-                    generation_allocation_start (generation_of (gen_number))),
-                   (ptrdiff_t)Align (min_obj_size));
-    else
-    {
-        generation* gen = generation_of (gen_number);
-        if (heap_segment_rw (generation_start_segment (gen)) == ephemeral_heap_segment)
-            return (generation_allocation_start (generation_of (gen_number - 1)) -
-                    generation_allocation_start (generation_of (gen_number)));
-        else
-        {
-            size_t gensize = 0;
-            heap_segment* seg = heap_segment_rw (generation_start_segment (gen));
-            PREFIX_ASSUME(seg != NULL);
-            while (seg && (seg != ephemeral_heap_segment))
-            {
-                gensize += heap_segment_allocated (seg) -
-                           heap_segment_mem (seg);
-                seg = heap_segment_next_rw (seg);
-            }
-            if (seg)
-            {
-                gensize += (generation_allocation_start (generation_of (gen_number - 1)) -
-                            heap_segment_mem (ephemeral_heap_segment));
-            }
-            return gensize;
-        }
-    }
-#endif //USE_REGIONS
-}
-size_t  gc_heap::compute_in (int gen_number)
-{
-    assert (gen_number != 0);
-    dynamic_data* dd = dynamic_data_of (gen_number);
-    size_t in = generation_allocation_size (generation_of (gen_number));
-#ifndef USE_REGIONS
-    if (gen_number == max_generation && ephemeral_promotion)
-    {
-        in = 0;
-        for (int i = 0; i <= max_generation; i++)
-        {
-            dynamic_data* dd = dynamic_data_of (i);
-            in += dd_survived_size (dd);
-            if (i != max_generation)
-            {
-                generation_condemned_allocated (generation_of (gen_number)) += dd_survived_size (dd);
-            }
-        }
-    }
-#endif //!USE_REGIONS
-    dd_gc_new_allocation (dd) -= in;
-    dd_new_allocation (dd) = dd_gc_new_allocation (dd);
-    gc_history_per_heap* current_gc_data_per_heap = get_gc_data_per_heap();
-    gc_generation_data* gen_data = &(current_gc_data_per_heap->gen_data[gen_number]);
-    gen_data->in = in;
-    generation_allocation_size (generation_of (gen_number)) = 0;
-    return in;
-}
-#ifdef HOST_64BIT
-inline
-size_t gc_heap::trim_youngest_desired (uint32_t memory_load,
-                                       size_t total_new_allocation,
-                                       size_t total_min_allocation)
-{
-    if (memory_load < MAX_ALLOWED_MEM_LOAD)
-    {
-        size_t remain_memory_load = (MAX_ALLOWED_MEM_LOAD - memory_load) * mem_one_percent;
-        return min (total_new_allocation, remain_memory_load);
-    }
-    else
-    {
-        size_t total_max_allocation = max ((size_t)mem_one_percent, total_min_allocation);
-        return min (total_new_allocation, total_max_allocation);
-    }
-}
-size_t gc_heap::joined_youngest_desired (size_t new_allocation)
-{
-    dprintf (2, ("Entry memory load: %d; gen0 new_alloc: %zd", settings.entry_memory_load, new_allocation));
-    size_t final_new_allocation = new_allocation;
-    if (new_allocation > MIN_YOUNGEST_GEN_DESIRED)
-    {
-        uint32_t num_heaps = 1;
-#ifdef MULTIPLE_HEAPS
-        num_heaps = gc_heap::n_heaps;
-#endif //MULTIPLE_HEAPS
-        size_t total_new_allocation = new_allocation * num_heaps;
-        size_t total_min_allocation = MIN_YOUNGEST_GEN_DESIRED * num_heaps;
-        if ((settings.entry_memory_load >= MAX_ALLOWED_MEM_LOAD) ||
-            (total_new_allocation > max (youngest_gen_desired_th, total_min_allocation)))
-        {
-            uint32_t memory_load = 0;
-            get_memory_info (&memory_load);
-            settings.exit_memory_load = memory_load;
-            dprintf (2, ("Current memory load: %d", memory_load));
-            size_t final_total =
-                trim_youngest_desired (memory_load, total_new_allocation, total_min_allocation);
-            size_t max_new_allocation =
-#ifdef MULTIPLE_HEAPS
-                                         dd_max_size (g_heaps[0]->dynamic_data_of (0));
-#else //MULTIPLE_HEAPS
-                                         dd_max_size (dynamic_data_of (0));
-#endif //MULTIPLE_HEAPS
-            final_new_allocation  = min (Align ((final_total / num_heaps), get_alignment_constant (TRUE)), max_new_allocation);
-        }
-    }
-    if (final_new_allocation < new_allocation)
-    {
-        settings.gen0_reduction_count = 2;
-    }
-    return final_new_allocation;
-}
-#endif // HOST_64BIT
-inline
-gc_history_global* gc_heap::get_gc_data_global()
-{
-#ifdef BACKGROUND_GC
-    return (settings.concurrent ? &bgc_data_global : &gc_data_global);
-#else
-    return &gc_data_global;
-#endif //BACKGROUND_GC
-}
-inline
-gc_history_per_heap* gc_heap::get_gc_data_per_heap()
-{
-#ifdef BACKGROUND_GC
-    return (settings.concurrent ? &bgc_data_per_heap : &gc_data_per_heap);
-#else
-    return &gc_data_per_heap;
-#endif //BACKGROUND_GC
-}
-void gc_heap::compute_new_dynamic_data (int gen_number)
-{
-    PREFIX_ASSUME(gen_number >= 0);
-    PREFIX_ASSUME(gen_number <= max_generation);
-    dynamic_data* dd = dynamic_data_of (gen_number);
-    generation*   gen = generation_of (gen_number);
-    size_t        in = (gen_number==0) ? 0 : compute_in (gen_number);
-    size_t total_gen_size = generation_size (gen_number);
-    dd_fragmentation (dd) = generation_free_list_space (gen) + generation_free_obj_space (gen);
-    generation_condemned_allocated (gen) = 0;
-    if (settings.concurrent)
-    {
-        generation_free_list_allocated (gen) = 0;
-        generation_end_seg_allocated (gen) = 0;
-    }
-    else
-    {
-        assert (generation_free_list_allocated (gen) == 0);
-        assert (generation_end_seg_allocated (gen) == 0);
-    }
-    if (dd_fragmentation (dd) <= total_gen_size)
-        dd_current_size (dd) = total_gen_size - dd_fragmentation (dd);
-    else
-        dd_current_size (dd) = 0;
-    gc_history_per_heap* current_gc_data_per_heap = get_gc_data_per_heap();
-    size_t out = dd_survived_size (dd);
-    gc_generation_data* gen_data = &(current_gc_data_per_heap->gen_data[gen_number]);
-    gen_data->size_after = total_gen_size;
-    gen_data->free_list_space_after = generation_free_list_space (gen);
-    gen_data->free_obj_space_after = generation_free_obj_space (gen);
-    if ((settings.pause_mode == pause_low_latency) && (gen_number <= 1))
-    {
-        dd_desired_allocation (dd) = low_latency_alloc;
-        dd_gc_new_allocation (dd) = dd_desired_allocation (dd);
-        dd_new_allocation (dd) = dd_gc_new_allocation (dd);
-    }
-    else
-    {
-        if (gen_number == 0)
-        {
-            size_t final_promoted = 0;
-            final_promoted = min (finalization_promoted_bytes, out);
-            PREFIX_ASSUME(final_promoted <= out);
-            dprintf (2, ("gen: %d final promoted: %zd", gen_number, final_promoted));
-            dd_freach_previous_promotion (dd) = final_promoted;
-            size_t lower_bound = desired_new_allocation  (dd, out-final_promoted, gen_number, 0);
-            if (settings.condemned_generation == 0)
-            {
-                dd_desired_allocation (dd) = lower_bound;
-            }
-            else
-            {
-                size_t higher_bound = desired_new_allocation (dd, out, gen_number, 1);
-                if (dd_desired_allocation (dd) < lower_bound)
-                {
-                    dd_desired_allocation (dd) = lower_bound;
-                }
-                else if (dd_desired_allocation (dd) > higher_bound)
-                {
-                    dd_desired_allocation (dd) = higher_bound;
-                }
-#if defined (HOST_64BIT) && !defined (MULTIPLE_HEAPS)
-                dd_desired_allocation (dd) = joined_youngest_desired (dd_desired_allocation (dd));
-#endif // HOST_64BIT && !MULTIPLE_HEAPS
-                trim_youngest_desired_low_memory();
-                dprintf (2, ("final gen0 new_alloc: %zd", dd_desired_allocation (dd)));
-            }
-        }
-        else
-        {
-            dd_desired_allocation (dd) = desired_new_allocation (dd, out, gen_number, 0);
-        }
-        dd_gc_new_allocation (dd) = dd_desired_allocation (dd);
-#ifdef USE_REGIONS
-        dd_new_allocation (dd) = dd_gc_new_allocation (dd) - in;
-#else //USE_REGIONS
-        dd_new_allocation (dd) = dd_gc_new_allocation (dd);
-#endif //USE_REGIONS
-    }
-    gen_data->pinned_surv = dd_pinned_survived_size (dd);
-    gen_data->npinned_surv = dd_survived_size (dd) - dd_pinned_survived_size (dd);
-    dd_promoted_size (dd) = out;
-    if (gen_number == max_generation)
-    {
-        for (int i = (gen_number + 1); i < total_generation_count; i++)
-        {
-            dd = dynamic_data_of (i);
-            total_gen_size = generation_size (i);
-            generation* gen = generation_of (i);
-            dd_fragmentation (dd) = generation_free_list_space (gen) +
-                generation_free_obj_space (gen);
-            dd_current_size (dd) = total_gen_size - dd_fragmentation (dd);
-            dd_survived_size (dd) = dd_current_size (dd);
-            in = 0;
-            out = dd_current_size (dd);
-            dd_desired_allocation (dd) = desired_new_allocation (dd, out, i, 0);
-            dd_gc_new_allocation (dd) = Align (dd_desired_allocation (dd),
-                get_alignment_constant (FALSE));
-            dd_new_allocation (dd) = dd_gc_new_allocation (dd);
-            gen_data = &(current_gc_data_per_heap->gen_data[i]);
-            gen_data->size_after = total_gen_size;
-            gen_data->free_list_space_after = generation_free_list_space (gen);
-            gen_data->free_obj_space_after = generation_free_obj_space (gen);
-            gen_data->npinned_surv = out;
-#ifdef BACKGROUND_GC
-            if (i == loh_generation)
-                end_loh_size = total_gen_size;
-            if (i == poh_generation)
-                end_poh_size = total_gen_size;
-#endif //BACKGROUND_GC
-            dd_promoted_size (dd) = out;
-        }
-    }
-}
-void gc_heap::trim_youngest_desired_low_memory()
-{
-    if (g_low_memory_status)
-    {
-        size_t committed_mem = committed_size();
-        dynamic_data* dd = dynamic_data_of (0);
-        size_t current = dd_desired_allocation (dd);
-        size_t candidate = max (Align ((committed_mem / 10), get_alignment_constant(FALSE)), dd_min_size (dd));
-        dd_desired_allocation (dd) = min (current, candidate);
-    }
-}
-ptrdiff_t gc_heap::estimate_gen_growth (int gen_number)
-{
-    dynamic_data* dd_gen = dynamic_data_of (gen_number);
-    generation *gen = generation_of (gen_number);
-    ptrdiff_t new_allocation_gen = dd_new_allocation (dd_gen);
-    ptrdiff_t free_list_space_gen = generation_free_list_space (gen);
-#ifdef USE_REGIONS
-    ptrdiff_t reserved_not_in_use = 0;
-    ptrdiff_t allocated_gen = 0;
-    for (heap_segment* region = generation_start_segment_rw (gen); region != nullptr; region = heap_segment_next (region))
-    {
-        allocated_gen += heap_segment_allocated (region) - heap_segment_mem (region);
-        reserved_not_in_use += heap_segment_reserved (region) - heap_segment_allocated (region);
-    }
-    double free_list_fraction_gen = (allocated_gen == 0) ? 0.0 : (double)(free_list_space_gen) / (double)allocated_gen;
-    ptrdiff_t usable_free_space = (ptrdiff_t)(free_list_fraction_gen * free_list_space_gen);
-    ptrdiff_t budget_gen = new_allocation_gen - usable_free_space - reserved_not_in_use;
-    dprintf (REGIONS_LOG, ("h%2d gen %d budget %zd allocated: %zd, FL: %zd, reserved_not_in_use %zd budget_gen %zd",
-        heap_number, gen_number, new_allocation_gen, allocated_gen, free_list_space_gen, reserved_not_in_use, budget_gen));
-#else  //USE_REGIONS
-    ptrdiff_t budget_gen = new_allocation_gen - (free_list_space_gen / 2);
-    dprintf (REGIONS_LOG, ("budget for gen %d on heap %d is %zd (new %zd, free %zd)",
-        gen_number, heap_number, budget_gen, new_allocation_gen, free_list_space_gen));
-#endif //USE_REGIONS
-    return budget_gen;
-}
-#if !defined(USE_REGIONS) || defined(MULTIPLE_HEAPS)
-uint8_t* gc_heap::get_smoothed_decommit_target (uint8_t* previous_decommit_target, uint8_t* new_decommit_target, heap_segment* seg)
-{
-    uint8_t* decommit_target = new_decommit_target;
-    if (decommit_target < previous_decommit_target)
-    {
-        ptrdiff_t target_decrease = previous_decommit_target - decommit_target;
-        decommit_target += target_decrease * 2 / 3;
-    }
-#ifdef STRESS_DECOMMIT
-    decommit_target = heap_segment_mem (seg) + gc_rand::get_rand (heap_segment_reserved (seg) - heap_segment_mem (seg));
-#endif //STRESS_DECOMMIT
-#ifdef MULTIPLE_HEAPS
-    if (decommit_target < heap_segment_committed (seg))
-    {
-        gradual_decommit_in_progress_p = TRUE;
-    }
-#endif //MULTIPLE_HEAPS
-    int gen_num =
-#ifdef USE_REGIONS
-        seg->gen_num;
-#else
-        0;
-#endif
-    dprintf (3, ("h%2d gen %d allocated: %zdkb committed: %zdkb target: %zdkb",
-        heap_number,
-        gen_num,
-        ((heap_segment_allocated (seg) - heap_segment_mem (seg)) / 1024),
-        ((heap_segment_committed (seg) - heap_segment_mem (seg)) / 1024),
-        (heap_segment_decommit_target (seg) - heap_segment_mem (seg)) / 1024));
-    return decommit_target;
-}
-void gc_heap::decommit_ephemeral_segment_pages()
-{
-    if (settings.concurrent || use_large_pages_p || (settings.pause_mode == pause_no_gc))
-    {
-        return;
-    }
-#if defined(MULTIPLE_HEAPS) && defined(USE_REGIONS)
-    for (int gen_number = soh_gen0; gen_number <= soh_gen1; gen_number++)
-    {
-        generation *gen = generation_of (gen_number);
-        heap_segment* tail_region = generation_tail_region (gen);
-        uint8_t* previous_decommit_target = heap_segment_decommit_target (tail_region);
-        for (heap_segment* region = generation_start_segment_rw (gen); region != nullptr; region = heap_segment_next (region))
-        {
-            heap_segment_decommit_target (region) = heap_segment_reserved (region);
-        }
-        ptrdiff_t budget_gen = estimate_gen_growth (gen_number) + loh_size_threshold;
-        if (budget_gen >= 0)
-        {
-            continue;
-        }
-        ptrdiff_t tail_region_size = heap_segment_reserved (tail_region) - heap_segment_mem (tail_region);
-        ptrdiff_t unneeded_tail_size = min (-budget_gen, tail_region_size);
-        uint8_t *decommit_target = heap_segment_reserved (tail_region) - unneeded_tail_size;
-        decommit_target = max (decommit_target, heap_segment_allocated (tail_region));
-        heap_segment_decommit_target (tail_region) = get_smoothed_decommit_target (previous_decommit_target, decommit_target, tail_region);
-    }
-#elif !defined(USE_REGIONS)
-    dynamic_data* dd0 = dynamic_data_of (0);
-    ptrdiff_t desired_allocation = dd_new_allocation (dd0) +
-                                   max (estimate_gen_growth (soh_gen1), (ptrdiff_t)0) +
-                                   loh_size_threshold;
-    size_t slack_space =
-#ifdef HOST_64BIT
-                max(min(min(soh_segment_size/32, dd_max_size (dd0)), (generation_size (max_generation) / 10)), (size_t)desired_allocation);
-#else
-                desired_allocation;
-#endif // HOST_64BIT
-    uint8_t* decommit_target = heap_segment_allocated (ephemeral_heap_segment) + slack_space;
-    uint8_t* previous_decommit_target = heap_segment_decommit_target (ephemeral_heap_segment);
-    heap_segment_decommit_target (ephemeral_heap_segment) = get_smoothed_decommit_target (previous_decommit_target, decommit_target, ephemeral_heap_segment);
-#if defined(MULTIPLE_HEAPS) && defined(_DEBUG)
-    ephemeral_heap_segment->saved_committed = heap_segment_committed (ephemeral_heap_segment);
-    ephemeral_heap_segment->saved_desired_allocation = dd_desired_allocation (dd0);
-#endif //MULTIPLE_HEAPS && _DEBUG
-#ifndef MULTIPLE_HEAPS
-    size_t ephemeral_elapsed = (size_t)((dd_time_clock (dd0) - gc_last_ephemeral_decommit_time) / 1000);
-    gc_last_ephemeral_decommit_time = dd_time_clock (dd0);
-    ptrdiff_t decommit_size = heap_segment_committed (ephemeral_heap_segment) - decommit_target;
-    ptrdiff_t max_decommit_size = min (ephemeral_elapsed, (size_t)(10*1000)) * DECOMMIT_SIZE_PER_MILLISECOND;
-    decommit_size = min (decommit_size, max_decommit_size);
-    slack_space = heap_segment_committed (ephemeral_heap_segment) - heap_segment_allocated (ephemeral_heap_segment) - decommit_size;
-    decommit_heap_segment_pages (ephemeral_heap_segment, slack_space);
-#endif // !MULTIPLE_HEAPS
-    gc_history_per_heap* current_gc_data_per_heap = get_gc_data_per_heap();
-    current_gc_data_per_heap->extra_gen0_committed = heap_segment_committed (ephemeral_heap_segment) - heap_segment_allocated (ephemeral_heap_segment);
-#endif //MULTIPLE_HEAPS && USE_REGIONS
-}
-#endif //!USE_REGIONS || MULTIPLE_HEAPS
-#if defined(MULTIPLE_HEAPS) || defined(USE_REGIONS)
-bool gc_heap::decommit_step (uint64_t step_milliseconds)
-{
-    if (settings.pause_mode == pause_no_gc)
-    {
-        return false;
-    }
-    size_t decommit_size = 0;
-#ifdef USE_REGIONS
-    const size_t max_decommit_step_size = DECOMMIT_SIZE_PER_MILLISECOND * step_milliseconds;
-    for (int kind = basic_free_region; kind < count_free_region_kinds; kind++)
-    {
-        dprintf (REGIONS_LOG, ("decommit_step %d, regions_to_decommit = %zd",
-            kind, global_regions_to_decommit[kind].get_num_free_regions()));
-        while (global_regions_to_decommit[kind].get_num_free_regions() > 0)
-        {
-            heap_segment* region = global_regions_to_decommit[kind].unlink_region_front();
-            size_t size = decommit_region (region, recorded_committed_free_bucket, -1);
-            decommit_size += size;
-            if (decommit_size >= max_decommit_step_size)
-            {
-                return true;
-            }
-        }
-    }
-    if (use_large_pages_p)
-    {
-        return (decommit_size != 0);
-    }
-#endif //USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-    assert(!use_large_pages_p);
-    for (int i = 0; i < n_heaps; i++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[i];
-        decommit_size += hp->decommit_ephemeral_segment_pages_step ();
-    }
-#endif //MULTIPLE_HEAPS
-    return (decommit_size != 0);
-}
-#endif //MULTIPLE_HEAPS || USE_REGIONS
-#ifdef USE_REGIONS
-size_t gc_heap::decommit_region (heap_segment* region, int bucket, int h_number)
-{
-    FIRE_EVENT(GCFreeSegment_V1, heap_segment_mem (region));
-    uint8_t* page_start = align_lower_page (get_region_start (region));
-    uint8_t* decommit_end = heap_segment_committed (region);
-    size_t decommit_size = decommit_end - page_start;
-    bool decommit_succeeded_p = virtual_decommit (page_start, decommit_size, bucket, h_number);
-    bool require_clearing_memory_p = !decommit_succeeded_p || use_large_pages_p;
-    dprintf (REGIONS_LOG, ("decommitted region %p(%p-%p) (%zu bytes) - success: %d",
-        region,
-        page_start,
-        decommit_end,
-        decommit_size,
-        decommit_succeeded_p));
-    if (require_clearing_memory_p)
-    {
-        uint8_t* clear_end = use_large_pages_p ? heap_segment_used (region) : heap_segment_committed (region);
-        size_t clear_size = clear_end - page_start;
-        memclr (page_start, clear_size);
-        heap_segment_used (region) = heap_segment_mem (region);
-        dprintf(REGIONS_LOG, ("cleared region %p(%p-%p) (%zu bytes)",
-            region,
-            page_start,
-            clear_end,
-            clear_size));
-    }
-    else
-    {
-        heap_segment_committed (region) = heap_segment_mem (region);
-    }
-#ifdef BACKGROUND_GC
-    if ((region->flags & heap_segment_flags_ma_committed) != 0)
-    {
-#ifdef MULTIPLE_HEAPS
-        gc_heap* hp = g_heaps [0];
-#else
-        gc_heap* hp = pGenGCHeap;
-#endif
-        hp->decommit_mark_array_by_seg (region);
-        region->flags &= ~(heap_segment_flags_ma_committed);
-    }
-#endif //BACKGROUND_GC
-    if (use_large_pages_p)
-    {
-        assert (heap_segment_used (region) == heap_segment_mem (region));
-    }
-    else
-    {
-        assert (heap_segment_committed (region) == heap_segment_mem (region));
-    }
-#ifdef BACKGROUND_GC
-    assert ((region->flags & heap_segment_flags_ma_committed) == 0);
-#endif //BACKGROUND_GC
-    global_region_allocator.delete_region (get_region_start (region));
-    return decommit_size;
-}
-#endif //USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-size_t gc_heap::decommit_ephemeral_segment_pages_step ()
-{
-    size_t size = 0;
-#ifdef USE_REGIONS
-    for (int gen_number = soh_gen0; gen_number <= soh_gen1; gen_number++)
-    {
-        generation* gen = generation_of (gen_number);
-        heap_segment* seg = generation_tail_region (gen);
-#else // USE_REGIONS
-    {
-        heap_segment* seg = ephemeral_heap_segment;
-        assert (seg->saved_desired_allocation == dd_desired_allocation (dynamic_data_of (0)));
-#endif // USE_REGIONS
-        uint8_t* decommit_target = heap_segment_decommit_target (seg);
-        size_t EXTRA_SPACE = 2 * OS_PAGE_SIZE;
-        decommit_target += EXTRA_SPACE;
-        uint8_t* committed = heap_segment_committed (seg);
-        uint8_t* allocated = (seg == ephemeral_heap_segment) ? alloc_allocated : heap_segment_allocated (seg);
-        if ((allocated <= decommit_target) && (decommit_target < committed))
-        {
-#ifdef USE_REGIONS
-            if (gen_number == soh_gen0)
-            {
-                if (!try_enter_spin_lock (&more_space_lock_soh))
-                {
-                    continue;
-                }
-                add_saved_spinlock_info (false, me_acquire, mt_decommit_step, msl_entered);
-                seg = generation_tail_region (gen);
-#ifndef STRESS_DECOMMIT
-                decommit_target = heap_segment_decommit_target (seg);
-                decommit_target += EXTRA_SPACE;
-#endif
-                committed = heap_segment_committed (seg);
-                allocated = (seg == ephemeral_heap_segment) ? alloc_allocated : heap_segment_allocated (seg);
-            }
-            if ((allocated <= decommit_target) && (decommit_target < committed))
-#else // USE_REGIONS
-            assert (seg->saved_committed == heap_segment_committed (seg));
-#endif // USE_REGIONS
-            {
-                size_t full_decommit_size = (committed - decommit_target);
-                size_t decommit_size = min (max_decommit_step_size, full_decommit_size);
-                uint8_t* new_committed = (committed - decommit_size);
-                size += decommit_heap_segment_pages_worker (seg, new_committed);
-#if defined(_DEBUG) && !defined(USE_REGIONS)
-                seg->saved_committed = committed - size;
-#endif //_DEBUG && !USE_REGIONS
-            }
-#ifdef USE_REGIONS
-            if (gen_number == soh_gen0)
-            {
-                add_saved_spinlock_info (false, me_release, mt_decommit_step, msl_entered);
-                leave_spin_lock (&more_space_lock_soh);
-            }
-#endif // USE_REGIONS
-        }
-    }
-    return size;
-}
-#endif //MULTIPLE_HEAPS
-size_t gc_heap::generation_fragmentation (generation* gen,
-                                          generation* consing_gen,
-                                          uint8_t* end)
-{
-    ptrdiff_t frag = 0;
-#ifdef USE_REGIONS
-    for (int gen_num = 0; gen_num <= gen->gen_num; gen_num++)
-    {
-        generation* gen = generation_of (gen_num);
-        heap_segment* seg = heap_segment_rw (generation_start_segment (gen));
-        while (seg)
-        {
-            frag += (heap_segment_saved_allocated (seg) -
-                 heap_segment_plan_allocated (seg));
-            dprintf (3, ("h%d g%d adding seg plan frag: %p-%p=%zd -> %zd",
-                heap_number, gen_num,
-                heap_segment_saved_allocated (seg),
-                heap_segment_plan_allocated (seg),
-                (heap_segment_saved_allocated (seg) - heap_segment_plan_allocated (seg)),
-                frag));
-            seg = heap_segment_next_rw (seg);
-        }
-    }
-#else //USE_REGIONS
-    uint8_t* alloc = generation_allocation_pointer (consing_gen);
-    if (in_range_for_segment (alloc, ephemeral_heap_segment))
-    {
-        if (alloc <= heap_segment_allocated(ephemeral_heap_segment))
-            frag = end - alloc;
-        else
-        {
-            frag = 0;
-        }
-        dprintf (3, ("ephemeral frag: %zd", frag));
-    }
-    else
-        frag = (heap_segment_allocated (ephemeral_heap_segment) -
-                heap_segment_mem (ephemeral_heap_segment));
-    heap_segment* seg = heap_segment_rw (generation_start_segment (gen));
-    PREFIX_ASSUME(seg != NULL);
-    while (seg != ephemeral_heap_segment)
-    {
-        frag += (heap_segment_allocated (seg) -
-                 heap_segment_plan_allocated (seg));
-        dprintf (3, ("seg: %zx, frag: %zd", (size_t)seg,
-                     (heap_segment_allocated (seg) -
-                      heap_segment_plan_allocated (seg))));
-        seg = heap_segment_next_rw (seg);
-        assert (seg);
-    }
-#endif //USE_REGIONS
-    dprintf (3, ("frag: %zd discounting pinned plugs", frag));
-    size_t bos = 0;
-    while (bos < mark_stack_bos)
-    {
-        frag += (pinned_len (pinned_plug_of (bos)));
-        dprintf (3, ("adding pinned len %zd to frag ->%zd",
-            pinned_len (pinned_plug_of (bos)), frag));
-        bos++;
-    }
-    return frag;
-}
-size_t gc_heap::generation_sizes (generation* gen, bool use_saved_p)
-{
-    size_t result = 0;
-#ifdef USE_REGIONS
-    int gen_num = gen->gen_num;
-    int start_gen_index = ((gen_num > max_generation) ? gen_num : 0);
-    for (int i = start_gen_index; i <= gen_num; i++)
-    {
-        heap_segment* seg = heap_segment_in_range (generation_start_segment (generation_of (i)));
-        while (seg)
-        {
-            uint8_t* end = (use_saved_p ?
-                heap_segment_saved_allocated (seg) : heap_segment_allocated (seg));
-            result += end - heap_segment_mem (seg);
-            dprintf (3, ("h%d gen%d size + %zd (%p - %p) -> %zd",
-                heap_number, i, (end - heap_segment_mem (seg)),
-                heap_segment_mem (seg), end, result));
-            seg = heap_segment_next (seg);
-        }
-    }
-#else //USE_REGIONS
-    if (generation_start_segment (gen ) == ephemeral_heap_segment)
-        result = (heap_segment_allocated (ephemeral_heap_segment) -
-                  generation_allocation_start (gen));
-    else
-    {
-        heap_segment* seg = heap_segment_in_range (generation_start_segment (gen));
-        PREFIX_ASSUME(seg != NULL);
-        while (seg)
-        {
-            result += (heap_segment_allocated (seg) -
-                       heap_segment_mem (seg));
-            seg = heap_segment_next_in_range (seg);
-        }
-    }
-#endif //USE_REGIONS
-    return result;
-}
-#ifdef USE_REGIONS
-bool gc_heap::decide_on_compaction_space()
-{
-    size_t gen0size = approximate_new_allocation();
-    dprintf (REGIONS_LOG, ("gen0size: %zd, free: %zd",
-        gen0size, (num_regions_freed_in_sweep * ((size_t)1 << min_segment_size_shr))));
-    if (sufficient_space_regions ((num_regions_freed_in_sweep * ((size_t)1 << min_segment_size_shr)),
-                                  gen0size))
-    {
-        dprintf (REGIONS_LOG, ("it is sufficient!"));
-        return false;
-    }
-    get_gen0_end_plan_space();
-    if (!gen0_large_chunk_found)
-    {
-        gen0_large_chunk_found = (free_regions[basic_free_region].get_num_free_regions() > 0);
-    }
-    dprintf (REGIONS_LOG, ("gen0_pinned_free_space: %zd, end_gen0_region_space: %zd, gen0size: %zd",
-            gen0_pinned_free_space, end_gen0_region_space, gen0size));
-    if (sufficient_space_regions ((gen0_pinned_free_space + end_gen0_region_space), gen0size) &&
-        gen0_large_chunk_found)
-    {
-        sufficient_gen0_space_p = TRUE;
-    }
-    return true;
-}
-#endif //USE_REGIONS
-size_t gc_heap::estimated_reclaim (int gen_number)
-{
-    dynamic_data* dd = dynamic_data_of (gen_number);
-    size_t gen_allocated = (dd_desired_allocation (dd) - dd_new_allocation (dd));
-    size_t gen_total_size = gen_allocated + dd_current_size (dd);
-    size_t est_gen_surv = (size_t)((float) (gen_total_size) * dd_surv (dd));
-    size_t est_gen_free = gen_total_size - est_gen_surv + dd_fragmentation (dd);
-    dprintf (GTC_LOG, ("h%d gen%d total size: %zd, est dead space: %zd (s: %d, allocated: %zd), frag: %zd",
-                heap_number, gen_number,
-                gen_total_size,
-                est_gen_free,
-                (int)(dd_surv (dd) * 100),
-                gen_allocated,
-                dd_fragmentation (dd)));
-    return est_gen_free;
-}
-bool gc_heap::is_full_compacting_gc_productive()
-{
-#ifdef USE_REGIONS
-    heap_segment* gen1_start_region = generation_start_segment (generation_of (max_generation - 1));
-    if (heap_segment_plan_gen_num (gen1_start_region) == max_generation)
-    {
-        dprintf (REGIONS_LOG, ("gen1 start region %p is now part of gen2, unproductive",
-            heap_segment_mem (gen1_start_region)));
-        return false;
-    }
-    else
-    {
-        heap_segment* gen2_tail_region = generation_tail_region (generation_of (max_generation));
-        if (heap_segment_plan_allocated (gen2_tail_region) >= heap_segment_allocated (gen2_tail_region))
-        {
-            dprintf (REGIONS_LOG, ("last gen2 region extended %p->%p, unproductive",
-                heap_segment_allocated (gen2_tail_region), heap_segment_plan_allocated (gen2_tail_region)));
-            return false;
-        }
-    }
-    return true;
-#else //USE_REGIONS
-    if (generation_plan_allocation_start (generation_of (max_generation - 1)) >=
-        generation_allocation_start (generation_of (max_generation - 1)))
-    {
-        dprintf (1, ("gen1 start %p->%p, gen2 size %zd->%zd, lock elevation",
-                generation_allocation_start (generation_of (max_generation - 1)),
-                generation_plan_allocation_start (generation_of (max_generation - 1)),
-                    generation_size (max_generation),
-                    generation_plan_size (max_generation)));
-        return false;
-    }
-    else
-        return true;
-#endif //USE_REGIONS
-}
-BOOL gc_heap::decide_on_compacting (int condemned_gen_number,
-                                    size_t fragmentation,
-                                    BOOL& should_expand)
-{
-    BOOL should_compact = FALSE;
-    should_expand = FALSE;
-    generation*   gen = generation_of (condemned_gen_number);
-    dynamic_data* dd = dynamic_data_of (condemned_gen_number);
-    size_t gen_sizes     = generation_sizes(gen, true);
-    float  fragmentation_burden = ( ((0 == fragmentation) || (0 == gen_sizes)) ? (0.0f) :
-                                    (float (fragmentation) / gen_sizes) );
-    dprintf (GTC_LOG, ("h%d g%d fragmentation: %zd (%d%%), gen_sizes: %zd",
-        heap_number, settings.condemned_generation,
-        fragmentation, (int)(fragmentation_burden * 100.0),
-        gen_sizes));
-#ifdef USE_REGIONS
-    if (special_sweep_p)
-    {
-        return FALSE;
-    }
-#endif //USE_REGIONS
-#if defined(STRESS_HEAP) && !defined(FEATURE_NATIVEAOT)
-    if (GCStress<cfg_any>::IsEnabled() && !settings.concurrent)
-        should_compact = TRUE;
-#endif //defined(STRESS_HEAP) && !defined(FEATURE_NATIVEAOT)
-    if (GCConfig::GetForceCompact())
-        should_compact = TRUE;
-    if ((condemned_gen_number == max_generation) && last_gc_before_oom)
-    {
-        should_compact = TRUE;
-#ifndef USE_REGIONS
-        last_gc_before_oom = FALSE;
-#endif //!USE_REGIONS
-        get_gc_data_per_heap()->set_mechanism (gc_heap_compact, compact_last_gc);
-    }
-    if (settings.reason == reason_induced_compacting)
-    {
-        dprintf (2, ("induced compacting GC"));
-        should_compact = TRUE;
-        get_gc_data_per_heap()->set_mechanism (gc_heap_compact, compact_induced_compacting);
-    }
-    if (settings.reason == reason_induced_aggressive)
-    {
-        dprintf (2, ("aggressive compacting GC"));
-        should_compact = TRUE;
-        get_gc_data_per_heap()->set_mechanism (gc_heap_compact, compact_aggressive_compacting);
-    }
-    if (settings.reason == reason_pm_full_gc)
-    {
-        assert (condemned_gen_number == max_generation);
-        if (heap_number == 0)
-        {
-            dprintf (GTC_LOG, ("PM doing compacting full GC after a gen1"));
-        }
-        should_compact = TRUE;
-    }
-    dprintf (2, ("Fragmentation: %zu Fragmentation burden %d%%",
-                fragmentation, (int) (100*fragmentation_burden)));
-    if (provisional_mode_triggered && (condemned_gen_number == (max_generation - 1)))
-    {
-        dprintf (GTC_LOG, ("gen1 in PM always compact"));
-        should_compact = TRUE;
-    }
-#ifdef USE_REGIONS
-    if (!should_compact)
-    {
-        should_compact = !!decide_on_compaction_space();
-    }
-#else //USE_REGIONS
-    if (!should_compact)
-    {
-        if (dt_low_ephemeral_space_p (tuning_deciding_compaction))
-        {
-            dprintf(GTC_LOG, ("compacting due to low ephemeral"));
-            should_compact = TRUE;
-            get_gc_data_per_heap()->set_mechanism (gc_heap_compact, compact_low_ephemeral);
-        }
-    }
-    if (should_compact)
-    {
-        if ((condemned_gen_number >= (max_generation - 1)))
-        {
-            if (dt_low_ephemeral_space_p (tuning_deciding_expansion))
-            {
-                dprintf (GTC_LOG,("Not enough space for all ephemeral generations with compaction"));
-                should_expand = TRUE;
-            }
-        }
-    }
-#endif //USE_REGIONS
-#ifdef HOST_64BIT
-    BOOL high_memory = FALSE;
-#endif // HOST_64BIT
-    if (!should_compact)
-    {
-        dprintf (REGIONS_LOG, ("frag: %zd, fragmentation_burden: %.3f",
-            fragmentation, fragmentation_burden));
-        BOOL frag_exceeded = ((fragmentation >= dd_fragmentation_limit (dd)) &&
-                                (fragmentation_burden >= dd_fragmentation_burden_limit (dd)));
-        if (frag_exceeded)
-        {
-#ifdef BACKGROUND_GC
-            IN_STRESS_HEAP(if (!settings.stress_induced))
-            {
-#endif // BACKGROUND_GC
-            assert (settings.concurrent == FALSE);
-            should_compact = TRUE;
-            get_gc_data_per_heap()->set_mechanism (gc_heap_compact, compact_high_frag);
-#ifdef BACKGROUND_GC
-            }
-#endif // BACKGROUND_GC
-        }
-#ifdef HOST_64BIT
-        if(!should_compact)
-        {
-            uint32_t num_heaps = 1;
-#ifdef MULTIPLE_HEAPS
-            num_heaps = gc_heap::n_heaps;
-#endif // MULTIPLE_HEAPS
-            ptrdiff_t reclaim_space = generation_size(max_generation) - generation_plan_size(max_generation);
-            if((settings.entry_memory_load >= high_memory_load_th) && (settings.entry_memory_load < v_high_memory_load_th))
-            {
-                if(reclaim_space > (int64_t)(min_high_fragmentation_threshold (entry_available_physical_mem, num_heaps)))
-                {
-                    dprintf(GTC_LOG,("compacting due to fragmentation in high memory"));
-                    should_compact = TRUE;
-                    get_gc_data_per_heap()->set_mechanism (gc_heap_compact, compact_high_mem_frag);
-                }
-                high_memory = TRUE;
-            }
-            else if(settings.entry_memory_load >= v_high_memory_load_th)
-            {
-                if(reclaim_space > (ptrdiff_t)(min_reclaim_fragmentation_threshold (num_heaps)))
-                {
-                    dprintf(GTC_LOG,("compacting due to fragmentation in very high memory"));
-                    should_compact = TRUE;
-                    get_gc_data_per_heap()->set_mechanism (gc_heap_compact, compact_vhigh_mem_frag);
-                }
-                high_memory = TRUE;
-            }
-        }
-#endif // HOST_64BIT
-    }
-    if ((should_compact == FALSE) &&
-        (ensure_gap_allocation (condemned_gen_number) == FALSE))
-    {
-        should_compact = TRUE;
-        get_gc_data_per_heap()->set_mechanism (gc_heap_compact, compact_no_gaps);
-    }
-    if (settings.condemned_generation == max_generation)
-    {
-        if (
-#ifdef HOST_64BIT
-            (high_memory && !should_compact) ||
-#endif // HOST_64BIT
-            !is_full_compacting_gc_productive())
-        {
-            settings.should_lock_elevation = TRUE;
-        }
-    }
-    if (settings.pause_mode == pause_no_gc)
-    {
-        should_compact = TRUE;
-        if ((size_t)(heap_segment_reserved (ephemeral_heap_segment) - heap_segment_plan_allocated (ephemeral_heap_segment))
-            < soh_allocation_no_gc)
-        {
-            should_expand = TRUE;
-        }
-    }
-    dprintf (2, ("will %s(%s)", (should_compact ? "compact" : "sweep"), (should_expand ? "ex" : "")));
-    return should_compact;
-}
-size_t align_lower_good_size_allocation (size_t size)
-{
-    return (size/64)*64;
-}
-size_t gc_heap::approximate_new_allocation()
-{
-    dynamic_data* dd0 = dynamic_data_of (0);
-    return max (2*dd_min_size (dd0), ((dd_desired_allocation (dd0)*2)/3));
-}
-bool gc_heap::check_against_hard_limit (size_t space_required)
-{
-    bool can_fit = TRUE;
-    if (heap_hard_limit)
-    {
-        size_t left_in_commit = heap_hard_limit - current_total_committed;
-        int num_heaps = get_num_heaps();
-        left_in_commit /= num_heaps;
-        if (left_in_commit < space_required)
-        {
-            can_fit = FALSE;
-        }
-        dprintf (2, ("h%d end seg %zd, but only %zd left in HARD LIMIT commit, required: %zd %s on eph",
-            heap_number, space_required,
-            left_in_commit, space_required,
-            (can_fit ? "ok" : "short")));
-    }
-    return can_fit;
-}
-#ifdef USE_REGIONS
-bool gc_heap::sufficient_space_regions_for_allocation (size_t end_space, size_t end_space_required)
-{
-    size_t free_regions_space = (free_regions[basic_free_region].get_num_free_regions() * ((size_t)1 << min_segment_size_shr)) +
-                                global_region_allocator.get_free();
-    size_t total_alloc_space = end_space + free_regions_space;
-    dprintf (REGIONS_LOG, ("h%d required %zd, end %zd + free %zd=%zd",
-        heap_number, end_space_required, end_space, free_regions_space, total_alloc_space));
-    size_t total_commit_space = end_gen0_region_committed_space + free_regions[basic_free_region].get_size_committed_in_free();
-    if (total_alloc_space > end_space_required)
-    {
-        if (end_space_required > total_commit_space)
-        {
-            return check_against_hard_limit (end_space_required - total_commit_space);
-        }
-        else
-        {
-            return true;
-        }
-    }
-    else
-    {
-        return false;
-    }
-}
-bool gc_heap::sufficient_space_regions (size_t end_space, size_t end_space_required)
-{
-    size_t free_regions_space = (free_regions[basic_free_region].get_num_free_regions() * ((size_t)1 << min_segment_size_shr)) +
-                                global_region_allocator.get_free();
-    size_t total_alloc_space = end_space + free_regions_space;
-    dprintf (REGIONS_LOG, ("h%d required %zd, end %zd + free %zd=%zd",
-        heap_number, end_space_required, end_space, free_regions_space, total_alloc_space));
-    if (total_alloc_space > end_space_required)
-    {
-        return check_against_hard_limit (end_space_required);
-    }
-    else
-    {
-        return false;
-    }
-}
-#else //USE_REGIONS
-BOOL gc_heap::sufficient_space_end_seg (uint8_t* start, uint8_t* committed, uint8_t* reserved, size_t end_space_required)
-{
-    BOOL can_fit = FALSE;
-    size_t committed_space = (size_t)(committed - start);
-    size_t end_seg_space = (size_t)(reserved - start);
-    if (committed_space > end_space_required)
-    {
-        return true;
-    }
-    else if (end_seg_space > end_space_required)
-    {
-        return check_against_hard_limit (end_space_required - committed_space);
-    }
-    else
-        return false;
-}
-#endif //USE_REGIONS
-size_t gc_heap::end_space_after_gc()
-{
-    return max ((dd_min_size (dynamic_data_of (0))/2), (END_SPACE_AFTER_GC_FL));
-}
-BOOL gc_heap::ephemeral_gen_fit_p (gc_tuning_point tp)
-{
-    uint8_t* start = 0;
-#ifdef USE_REGIONS
-    assert ((tp == tuning_deciding_condemned_gen) || (tp == tuning_deciding_full_gc));
-#else//USE_REGIONS
-    if ((tp == tuning_deciding_condemned_gen) ||
-        (tp == tuning_deciding_compaction))
-    {
-        start = (settings.concurrent ? alloc_allocated : heap_segment_allocated (ephemeral_heap_segment));
-        if (settings.concurrent)
-        {
-            dprintf (2, ("%zd left at the end of ephemeral segment (alloc_allocated)",
-                (size_t)(heap_segment_reserved (ephemeral_heap_segment) - alloc_allocated)));
-        }
-        else
-        {
-            dprintf (2, ("%zd left at the end of ephemeral segment (allocated)",
-                (size_t)(heap_segment_reserved (ephemeral_heap_segment) - heap_segment_allocated (ephemeral_heap_segment))));
-        }
-    }
-    else if (tp == tuning_deciding_expansion)
-    {
-        start = heap_segment_plan_allocated (ephemeral_heap_segment);
-        dprintf (2, ("%zd left at the end of ephemeral segment based on plan",
-            (size_t)(heap_segment_reserved (ephemeral_heap_segment) - start)));
-    }
-    else
-    {
-        assert (tp == tuning_deciding_full_gc);
-        dprintf (2, ("FGC: %zd left at the end of ephemeral segment (alloc_allocated)",
-            (size_t)(heap_segment_reserved (ephemeral_heap_segment) - alloc_allocated)));
-        start = alloc_allocated;
-    }
-    if (start == 0) // empty ephemeral generations
-    {
-        assert (tp == tuning_deciding_expansion);
-        start = generation_allocation_pointer (generation_of (max_generation));
-        assert (start == heap_segment_mem (ephemeral_heap_segment));
-    }
-    if (tp == tuning_deciding_expansion)
-    {
-        assert (settings.condemned_generation >= (max_generation-1));
-        size_t gen0size = approximate_new_allocation();
-        size_t eph_size = gen0size;
-        size_t gen_min_sizes = 0;
-        for (int j = 1; j <= max_generation-1; j++)
-        {
-            gen_min_sizes += 2*dd_min_size (dynamic_data_of(j));
-        }
-        eph_size += gen_min_sizes;
-        dprintf (3, ("h%d deciding on expansion, need %zd (gen0: %zd, 2*min: %zd)",
-            heap_number, gen0size, gen_min_sizes, eph_size));
-        if ((size_t)(heap_segment_reserved (ephemeral_heap_segment) - start) > eph_size)
-        {
-            dprintf (3, ("Enough room before end of segment"));
-            return TRUE;
-        }
-        else
-        {
-            size_t room = align_lower_good_size_allocation
-                (heap_segment_reserved (ephemeral_heap_segment) - start);
-            size_t end_seg = room;
-            size_t largest_alloc = END_SPACE_AFTER_GC_FL;
-            bool large_chunk_found = FALSE;
-            size_t bos = 0;
-            uint8_t* gen0start = generation_plan_allocation_start (youngest_generation);
-            dprintf (3, ("ephemeral_gen_fit_p: gen0 plan start: %zx", (size_t)gen0start));
-            if (gen0start == 0)
-                return FALSE;
-            dprintf (3, ("ephemeral_gen_fit_p: room before free list search %zd, needed: %zd",
-                         room, gen0size));
-            while ((bos < mark_stack_bos) &&
-                   !((room >= gen0size) && large_chunk_found))
-            {
-                uint8_t* plug = pinned_plug (pinned_plug_of (bos));
-                if (in_range_for_segment (plug, ephemeral_heap_segment))
-                {
-                    if (plug >= gen0start)
-                    {
-                        size_t chunk = align_lower_good_size_allocation (pinned_len (pinned_plug_of (bos)));
-                        room += chunk;
-                        if (!large_chunk_found)
-                        {
-                            large_chunk_found = (chunk >= largest_alloc);
-                        }
-                        dprintf (3, ("ephemeral_gen_fit_p: room now %zd, large chunk: %d",
-                                     room, large_chunk_found));
-                    }
-                }
-                bos++;
-            }
-            if (room >= gen0size)
-            {
-                if (large_chunk_found)
-                {
-                    sufficient_gen0_space_p = TRUE;
-                    dprintf (3, ("Enough room"));
-                    return TRUE;
-                }
-                else
-                {
-                    if (end_seg >= end_space_after_gc())
-                    {
-                        dprintf (3, ("Enough room (may need end of seg)"));
-                        return TRUE;
-                    }
-                }
-            }
-            dprintf (3, ("Not enough room"));
-                return FALSE;
-        }
-    }
-    else
-#endif //USE_REGIONS
-    {
-        size_t end_space = 0;
-        dynamic_data* dd = dynamic_data_of (0);
-        if ((tp == tuning_deciding_condemned_gen) ||
-            (tp == tuning_deciding_full_gc))
-        {
-            end_space = max (2*dd_min_size (dd), end_space_after_gc());
-        }
-        else
-        {
-            assert (tp == tuning_deciding_compaction);
-            end_space = approximate_new_allocation();
-        }
-#ifdef USE_REGIONS
-        size_t gen0_end_space = get_gen0_end_space (memory_type_reserved);
-        BOOL can_fit = sufficient_space_regions (gen0_end_space, end_space);
-#else //USE_REGIONS
-        BOOL can_fit = sufficient_space_end_seg (start, heap_segment_committed (ephemeral_heap_segment), heap_segment_reserved (ephemeral_heap_segment), end_space);
-#endif //USE_REGIONS
-        return can_fit;
-    }
-}
-CObjectHeader* gc_heap::allocate_uoh_object (size_t jsize, uint32_t flags, int gen_number, int64_t& alloc_bytes)
-{
-    alloc_context acontext;
-    acontext.init();
-#if HOST_64BIT
-    size_t maxObjectSize = (INT64_MAX - 7 - Align(min_obj_size));
-#else
-    size_t maxObjectSize = (INT32_MAX - 7 - Align(min_obj_size));
-#endif
-    if (jsize >= maxObjectSize)
-    {
-        if (GCConfig::GetBreakOnOOM())
-        {
-            GCToOSInterface::DebugBreak();
-        }
-        return NULL;
-    }
-    size_t size = AlignQword (jsize);
-    int align_const = get_alignment_constant (FALSE);
-    size_t pad = 0;
-#ifdef FEATURE_LOH_COMPACTION
-    if (gen_number == loh_generation)
-    {
-        pad = Align (loh_padding_obj_size, align_const);
-    }
-#endif //FEATURE_LOH_COMPACTION
-    assert (size >= Align (min_obj_size, align_const));
-#ifdef _MSC_VER
-#pragma inline_depth(0)
-#endif //_MSC_VER
-    if (! allocate_more_space (&acontext, (size + pad), flags, gen_number))
-    {
-        return 0;
-    }
-#ifdef _MSC_VER
-#pragma inline_depth(20)
-#endif //_MSC_VER
-#ifdef FEATURE_LOH_COMPACTION
-#endif //FEATURE_LOH_COMPACTION
-    uint8_t*  result = acontext.alloc_ptr;
-    assert ((size_t)(acontext.alloc_limit - acontext.alloc_ptr) == size);
-    alloc_bytes += size;
-    CObjectHeader* obj = (CObjectHeader*)result;
-    assert (obj != 0);
-    assert ((size_t)obj == Align ((size_t)obj, align_const));
-    return obj;
-}
-void gc_heap::reset_memory (uint8_t* o, size_t sizeo)
-{
-    if (gc_heap::use_large_pages_p)
-        return;
-    if (sizeo > 128 * 1024)
-    {
-        size_t size_to_skip = min_free_list - plug_skew;
-        size_t page_start = align_on_page ((size_t)(o + size_to_skip));
-        size_t size = align_lower_page ((size_t)o + sizeo - size_to_skip - plug_skew) - page_start;
-        if (reset_mm_p && gc_heap::dt_high_memory_load_p())
-        {
-#ifdef MULTIPLE_HEAPS
-            bool unlock_p = true;
-#else
-            bool unlock_p = false;
-#endif //MULTIPLE_HEAPS
-            reset_mm_p = GCToOSInterface::VirtualReset((void*)page_start, size, unlock_p);
-        }
-    }
-}
-BOOL gc_heap::uoh_object_marked (uint8_t* o, BOOL clearp)
-{
-    BOOL m = FALSE;
-    if ((o >= lowest_address) && (o < highest_address))
-    {
-        if (marked (o))
-        {
-            if (clearp)
-            {
-                clear_marked (o);
-                if (pinned (o))
-                    clear_pinned(o);
-            }
-            m = TRUE;
-        }
-        else
-            m = FALSE;
-    }
-    else
-        m = TRUE;
-    return m;
-}
-void gc_heap::walk_survivors_relocation (void* profiling_context, record_surv_fn fn)
-{
-    walk_relocation (profiling_context, fn);
-#ifdef FEATURE_LOH_COMPACTION
-    if (loh_compacted_p)
-    {
-        walk_relocation_for_loh (profiling_context, fn);
-    }
-#endif //FEATURE_LOH_COMPACTION
-}
-void gc_heap::walk_survivors_for_uoh (void* profiling_context, record_surv_fn fn, int gen_number)
-{
-    generation* gen        = generation_of (gen_number);
-    heap_segment* seg      = heap_segment_rw (generation_start_segment (gen));;
-    PREFIX_ASSUME(seg != NULL);
-    uint8_t* o                = get_uoh_start_object (seg, gen);
-    uint8_t* plug_end         = o;
-    uint8_t* plug_start       = o;
-    while (1)
-    {
-        if (o >= heap_segment_allocated (seg))
-        {
-            seg = heap_segment_next (seg);
-            if (seg == 0)
-                break;
-            else
-                o = heap_segment_mem (seg);
-        }
-        if (uoh_object_marked(o, FALSE))
-        {
-            plug_start = o;
-            BOOL m = TRUE;
-            while (m)
-            {
-                o = o + AlignQword (size (o));
-                if (o >= heap_segment_allocated (seg))
-                {
-                    break;
-                }
-                m = uoh_object_marked (o, FALSE);
-            }
-            plug_end = o;
-            fn (plug_start, plug_end, 0, profiling_context, false, false);
-        }
-        else
-        {
-            while (o < heap_segment_allocated (seg) && !uoh_object_marked(o, FALSE))
-            {
-                o = o + AlignQword (size (o));
-            }
-        }
-    }
-}
-#ifdef BACKGROUND_GC
-BOOL gc_heap::background_object_marked (uint8_t* o, BOOL clearp)
-{
-    BOOL m = FALSE;
-    if ((o >= background_saved_lowest_address) && (o < background_saved_highest_address))
-    {
-        if (mark_array_marked (o))
-        {
-            if (clearp)
-            {
-                mark_array_clear_marked (o);
-                dprintf (3, ("CM: %p", o));
-            }
-            m = TRUE;
-        }
-        else
-            m = FALSE;
-    }
-    else
-        m = TRUE;
-    dprintf (3, ("o %p(%zu) %s", o, size(o), (m ? "was bm" : "was NOT bm")));
-    return m;
-}
-void gc_heap::background_delay_delete_uoh_segments()
-{
-    for (int i = uoh_start_generation; i < total_generation_count; i++)
-    {
-        generation* gen = generation_of (i);
-        heap_segment* seg = heap_segment_rw (generation_start_segment (gen));
-        heap_segment* prev_seg = 0;
-#ifdef USE_REGIONS
-        heap_segment* first_remaining_region = 0;
-#endif //USE_REGIONS
-        while (seg)
-        {
-            heap_segment* next_seg = heap_segment_next (seg);
-            if (seg->flags & heap_segment_flags_uoh_delete)
-            {
-                dprintf (3, ("deleting %zx-%p-%p", (size_t)seg, heap_segment_allocated (seg), heap_segment_reserved (seg)));
-                delete_heap_segment (seg, (GCConfig::GetRetainVM() != 0));
-                heap_segment_next (prev_seg) = next_seg;
-#ifdef USE_REGIONS
-                update_start_tail_regions (gen, seg, prev_seg, next_seg);
-#endif //USE_REGIONS
-            }
-            else
-            {
-#ifdef USE_REGIONS
-                if (!first_remaining_region)
-                    first_remaining_region = seg;
-#endif //USE_REGIONS
-                prev_seg = seg;
-            }
-            seg = next_seg;
-        }
-#ifdef USE_REGIONS
-        assert (heap_segment_rw (generation_start_segment (gen)) == generation_start_segment (gen));
-        if (generation_start_segment (gen) != first_remaining_region)
-        {
-            dprintf (REGIONS_LOG, ("h%d gen%d start %p -> %p",
-                heap_number, gen->gen_num,
-                heap_segment_mem (generation_start_segment (gen)),
-                heap_segment_mem (first_remaining_region)));
-            generation_start_segment (gen) = first_remaining_region;
-        }
-        if (generation_tail_region (gen) != prev_seg)
-        {
-            dprintf (REGIONS_LOG, ("h%d gen%d start %p -> %p",
-                heap_number, gen->gen_num,
-                heap_segment_mem (generation_tail_region (gen)),
-                heap_segment_mem (prev_seg)));
-            generation_tail_region (gen) = prev_seg;
-        }
-#endif //USE_REGIONS
-    }
-}
-uint8_t* gc_heap::background_next_end (heap_segment* seg, BOOL uoh_objects_p)
-{
-    return
-        (uoh_objects_p ? heap_segment_allocated (seg) : heap_segment_background_allocated (seg));
-}
-void gc_heap::set_mem_verify (uint8_t* start, uint8_t* end, uint8_t b)
-{
-#ifdef VERIFY_HEAP
-    if (end > start)
-    {
-        if ((GCConfig::GetHeapVerifyLevel() & GCConfig::HEAPVERIFY_GC) &&
-           !(GCConfig::GetHeapVerifyLevel() & GCConfig::HEAPVERIFY_NO_MEM_FILL))
-        {
-            dprintf (3, ("setting mem to %c [%p, [%p", b, start, end));
-            memset (start, b, (end - start));
-        }
-    }
-#endif //VERIFY_HEAP
-}
-void gc_heap::generation_delete_heap_segment (generation* gen,
-                                              heap_segment* seg,
-                                              heap_segment* prev_seg,
-                                              heap_segment* next_seg)
-{
-    dprintf (3, ("bgc sweep: deleting seg %zx(%p), next %zx(%p), prev %zx(%p)",
-        (size_t)seg, heap_segment_mem (seg),
-        (size_t)next_seg, (next_seg ? heap_segment_mem (next_seg) : 0),
-        (size_t)prev_seg, (prev_seg ? heap_segment_mem (prev_seg) : 0)));
-    if (gen->gen_num > max_generation)
-    {
-        dprintf (3, ("Preparing empty large segment %zx for deletion", (size_t)seg));
-        seg->flags |= heap_segment_flags_uoh_delete;
-        heap_segment_allocated (seg) = heap_segment_mem (seg);
-    }
-    else
-    {
-        assert (seg != ephemeral_heap_segment);
-#ifdef DOUBLY_LINKED_FL
-        heap_segment_next (prev_seg) = next_seg;
-#else //DOUBLY_LINKED_FL
-        heap_segment_next (next_seg) = prev_seg;
-#endif //DOUBLY_LINKED_FL
-        dprintf (3, ("Preparing empty small segment %zx for deletion", (size_t)seg));
-        heap_segment_next (seg) = freeable_soh_segment;
-        freeable_soh_segment = seg;
-#ifdef USE_REGIONS
-#ifdef DOUBLY_LINKED_FL
-        heap_segment* next_region = next_seg;
-        heap_segment* prev_region = prev_seg;
-#else //DOUBLY_LINKED_FL
-        heap_segment* next_region = prev_seg;
-        heap_segment* prev_region = next_seg;
-#endif //DOUBLY_LINKED_FL
-        update_start_tail_regions (gen, seg, prev_region, next_region);
-#endif //USE_REGIONS
-    }
-    decommit_heap_segment (seg);
-    seg->flags |= heap_segment_flags_decommitted;
-    set_mem_verify (heap_segment_allocated (seg) - plug_skew, heap_segment_used (seg), 0xbb);
-}
-void gc_heap::process_background_segment_end (heap_segment* seg,
-                                              generation* gen,
-                                              uint8_t* last_plug_end,
-                                              heap_segment* start_seg,
-                                              BOOL* delete_p,
-                                              size_t free_obj_size_last_gap)
-{
-    *delete_p = FALSE;
-    uint8_t* allocated = heap_segment_allocated (seg);
-    uint8_t* background_allocated = heap_segment_background_allocated (seg);
-    BOOL uoh_p = heap_segment_uoh_p (seg);
-    dprintf (3, ("EoS [%zx, %p[(%p[), last: %p(%zu)",
-                (size_t)heap_segment_mem (seg), background_allocated, allocated, last_plug_end, free_obj_size_last_gap));
-    if (!uoh_p && (allocated != background_allocated))
-    {
-        assert (gen->gen_num <= max_generation);
-        dprintf (3, ("Make a free object before newly promoted objects [%zx, %p[",
-                    (size_t)last_plug_end, background_allocated));
-        size_t last_gap = background_allocated - last_plug_end;
-        if (last_gap > 0)
-        {
-            thread_gap (last_plug_end, last_gap, generation_of (max_generation));
-            add_gen_free (max_generation, last_gap);
-            fix_brick_to_highest (last_plug_end, background_allocated);
-            fix_brick_to_highest (background_allocated, background_allocated);
-        }
-    }
-    else
-    {
-        if (seg == ephemeral_heap_segment)
-        {
-            FATAL_GC_ERROR();
-        }
-#ifndef USE_REGIONS
-        if (allocated == heap_segment_mem (seg))
-        {
-            assert (gen->gen_num > max_generation);
-        }
-#endif //!USE_REGIONS
-        if (last_plug_end == heap_segment_mem (seg))
-        {
-            if (seg != start_seg)
-            {
-                *delete_p = TRUE;
-            }
-            dprintf (3, ("h%d seg %p %s be deleted", heap_number,
-                        heap_segment_mem (seg), (*delete_p ? "should" : "should not")));
-        }
-        if (!*delete_p)
-        {
-            dprintf (3, ("[h%d] seg %zx alloc %p->%zx",
-                heap_number, (size_t)seg,
-                heap_segment_allocated (seg),
-                (size_t)last_plug_end));
-            heap_segment_allocated (seg) = last_plug_end;
-            set_mem_verify (heap_segment_allocated (seg) - plug_skew, heap_segment_used (seg), 0xbb);
-            decommit_heap_segment_pages (seg, 0);
-        }
-    }
-    if (free_obj_size_last_gap)
-    {
-        generation_free_obj_space (gen) -= free_obj_size_last_gap;
-        dprintf (2, ("[h%d] PS: gen2FO-: %zd->%zd",
-            heap_number, free_obj_size_last_gap, generation_free_obj_space (gen)));
-    }
-    dprintf (3, ("verifying seg %p's mark array was completely cleared", seg));
-    bgc_verify_mark_array_cleared (seg);
-}
-inline
-BOOL gc_heap::fgc_should_consider_object (uint8_t* o,
-                                          heap_segment* seg,
-                                          BOOL consider_bgc_mark_p,
-                                          BOOL check_current_sweep_p,
-                                          BOOL check_saved_sweep_p)
-{
-#ifdef USE_REGIONS
-    assert (!check_saved_sweep_p);
-#endif //USE_REGIONS
-    BOOL no_bgc_mark_p = FALSE;
-    if (consider_bgc_mark_p)
-    {
-        if (check_current_sweep_p && (o < current_sweep_pos))
-        {
-            dprintf (3, ("no bgc mark - o: %p < cs: %p", o, current_sweep_pos));
-            no_bgc_mark_p = TRUE;
-        }
-        if (!no_bgc_mark_p)
-        {
-#ifndef USE_REGIONS
-            if(check_saved_sweep_p && (o >= saved_sweep_ephemeral_start))
-            {
-                dprintf (3, ("no bgc mark - o: %p >= ss: %p", o, saved_sweep_ephemeral_start));
-                no_bgc_mark_p = TRUE;
-            }
-#endif //!USE_REGIONS
-            if (!check_saved_sweep_p)
-            {
-                uint8_t* background_allocated = heap_segment_background_allocated (seg);
-#ifndef USE_REGIONS
-                assert (heap_segment_background_allocated (seg) != saved_sweep_ephemeral_start);
-#endif //!USE_REGIONS
-                if (o >= background_allocated)
-                {
-                    dprintf (3, ("no bgc mark - o: %p >= ba: %p", o, background_allocated));
-                    no_bgc_mark_p = TRUE;
-                }
-            }
-        }
-    }
-    else
-    {
-        no_bgc_mark_p = TRUE;
-    }
-    dprintf (3, ("bgc mark %p: %s (bm: %s)", o, (no_bgc_mark_p ? "no" : "yes"), ((no_bgc_mark_p || background_object_marked (o, FALSE)) ? "yes" : "no")));
-    return (no_bgc_mark_p ? TRUE : background_object_marked (o, FALSE));
-}
-void gc_heap::should_check_bgc_mark (heap_segment* seg,
-                                     BOOL* consider_bgc_mark_p,
-                                     BOOL* check_current_sweep_p,
-                                     BOOL* check_saved_sweep_p)
-{
-    *consider_bgc_mark_p = FALSE;
-    *check_current_sweep_p = FALSE;
-    *check_saved_sweep_p = FALSE;
-    if (current_c_gc_state == c_gc_state_planning)
-    {
-        if ((seg->flags & heap_segment_flags_swept) || (current_sweep_pos == heap_segment_reserved (seg)))
-        {
-            dprintf (3, ("seg %p is already swept by bgc", seg));
-        }
-        else if (heap_segment_background_allocated (seg) == 0)
-        {
-            dprintf (3, ("seg %p newly alloc during bgc", seg));
-        }
-        else
-        {
-            *consider_bgc_mark_p = TRUE;
-            dprintf (3, ("seg %p hasn't been swept by bgc", seg));
-#ifndef USE_REGIONS
-            if (seg == saved_sweep_ephemeral_seg)
-            {
-                dprintf (3, ("seg %p is the saved ephemeral seg", seg));
-                *check_saved_sweep_p = TRUE;
-            }
-#endif //!USE_REGIONS
-            if (in_range_for_segment (current_sweep_pos, seg))
-            {
-                dprintf (3, ("current sweep pos is %p and within seg %p",
-                              current_sweep_pos, seg));
-                *check_current_sweep_p = TRUE;
-            }
-        }
-    }
-}
-void gc_heap::background_ephemeral_sweep()
-{
-    dprintf (3, ("bgc ephemeral sweep"));
-    int align_const = get_alignment_constant (TRUE);
-#ifndef USE_REGIONS
-    saved_sweep_ephemeral_seg = ephemeral_heap_segment;
-    saved_sweep_ephemeral_start = generation_allocation_start (generation_of (max_generation - 1));
-#endif //!USE_REGIONS
-    allocator youngest_free_list;
-    size_t youngest_free_list_space = 0;
-    size_t youngest_free_obj_space = 0;
-    youngest_free_list.clear();
-    for (int i = 0; i <= (max_generation - 1); i++)
-    {
-        generation* gen_to_reset = generation_of (i);
-        assert (generation_free_list_space (gen_to_reset) == 0);
-    }
-    for (int i = (max_generation - 1); i >= 0; i--)
-    {
-        generation* current_gen = generation_of (i);
-#ifdef USE_REGIONS
-        heap_segment* ephemeral_region = heap_segment_rw (generation_start_segment (current_gen));
-        while (ephemeral_region)
-#endif //USE_REGIONS
-        {
-#ifdef USE_REGIONS
-            uint8_t* o = heap_segment_mem (ephemeral_region);
-            uint8_t* end = heap_segment_background_allocated (ephemeral_region);
-            dprintf (3, ("bgc eph: gen%d seg %p(%p-%p)",
-                heap_segment_gen_num (ephemeral_region),
-                heap_segment_mem (ephemeral_region),
-                heap_segment_allocated (ephemeral_region),
-                heap_segment_background_allocated (ephemeral_region)));
-            if (!end)
-            {
-                ephemeral_region->flags |= heap_segment_flags_swept;
-                ephemeral_region = heap_segment_next (ephemeral_region);
-                continue;
-            }
-#else //USE_REGIONS
-            uint8_t* o = generation_allocation_start (current_gen);
-            o = o + Align(size (o), align_const);
-            uint8_t* end = ((i > 0) ?
-                        generation_allocation_start (generation_of (i - 1)) :
-                        heap_segment_allocated (ephemeral_heap_segment));
-#endif //USE_REGIONS
-            uint8_t* plug_end = o;
-            uint8_t* plug_start = o;
-            BOOL marked_p = FALSE;
-            while (o < end)
-            {
-                marked_p = background_object_marked (o, TRUE);
-                if (marked_p)
-                {
-                    plug_start = o;
-                    size_t plug_size = plug_start - plug_end;
-                    if (i >= 1)
-                    {
-                        thread_gap (plug_end, plug_size, current_gen);
-                    }
-                    else
-                    {
-                        if (plug_size > 0)
-                        {
-                            make_unused_array (plug_end, plug_size);
-                            if (plug_size >= min_free_list)
-                            {
-                                youngest_free_list_space += plug_size;
-                                youngest_free_list.thread_item (plug_end, plug_size);
-                            }
-                            else
-                            {
-                                youngest_free_obj_space += plug_size;
-                            }
-                        }
-                    }
-                    fix_brick_to_highest (plug_end, plug_start);
-                    fix_brick_to_highest (plug_start, plug_start);
-                    BOOL m = TRUE;
-                    while (m)
-                    {
-                        o = o + Align (size (o), align_const);
-                        if (o >= end)
-                        {
-                            break;
-                        }
-                        m = background_object_marked (o, TRUE);
-                    }
-                    plug_end = o;
-                    dprintf (3, ("bgs: plug [%zx, %zx[", (size_t)plug_start, (size_t)plug_end));
-                }
-                else
-                {
-                    while ((o < end) && !background_object_marked (o, FALSE))
-                    {
-                        o = o + Align (size (o), align_const);
-                    }
-                }
-            }
-            if (plug_end != end)
-            {
-                if (i >= 1)
-                {
-                    thread_gap (plug_end, end - plug_end, current_gen);
-                }
-                else
-                {
-#ifndef USE_REGIONS
-                    heap_segment_allocated (ephemeral_heap_segment) = plug_end;
-                    heap_segment_saved_bg_allocated (ephemeral_heap_segment) = plug_end;
-#endif //!USE_REGIONS
-                    make_unused_array (plug_end, (end - plug_end));
-                }
-                fix_brick_to_highest (plug_end, end);
-            }
-#ifdef USE_REGIONS
-            ephemeral_region->flags |= heap_segment_flags_swept;
-            heap_segment_background_allocated (ephemeral_region) = 0;
-            ephemeral_region = heap_segment_next (ephemeral_region);
-#endif //USE_REGIONS
-        }
-        dd_fragmentation (dynamic_data_of (i)) =
-            generation_free_list_space (current_gen) + generation_free_obj_space (current_gen);
-    }
-    generation* youngest_gen = generation_of (0);
-    generation_free_list_space (youngest_gen) = youngest_free_list_space;
-    generation_free_obj_space (youngest_gen) = youngest_free_obj_space;
-    dd_fragmentation (dynamic_data_of (0)) = youngest_free_list_space + youngest_free_obj_space;
-    generation_allocator (youngest_gen)->copy_with_no_repair (&youngest_free_list);
-}
-void gc_heap::background_sweep()
-{
-    concurrent_print_time_delta ("Sw");
-    dprintf (2, ("---- (GC%zu)Background Sweep Phase ----", VolatileLoad(&settings.gc_index)));
-    bool rebuild_maxgen_fl_p = true;
-#ifdef DOUBLY_LINKED_FL
-#ifdef DYNAMIC_HEAP_COUNT
-    rebuild_maxgen_fl_p = trigger_bgc_for_rethreading_p;
-#else
-    rebuild_maxgen_fl_p = false;
-#endif //DYNAMIC_HEAP_COUNT
-#endif //DOUBLY_LINKED_FL
-    for (int i = 0; i <= max_generation; i++)
-    {
-        generation* gen_to_reset = generation_of (i);
-        bool clear_fl_p = true;
-#ifdef DOUBLY_LINKED_FL
-        if (i == max_generation)
-        {
-            clear_fl_p = rebuild_maxgen_fl_p;
-            dprintf (6666, ("h%d: gen2 still has FL: %zd, FO: %zd, clear gen2 FL %s",
-                heap_number,
-                generation_free_list_space (gen_to_reset),
-                generation_free_obj_space (gen_to_reset),
-                (clear_fl_p ? "yes" : "no")));
-        }
-#endif //DOUBLY_LINKED_FL
-        if (clear_fl_p)
-        {
-            if (i == max_generation)
-            {
-                dprintf (6666, ("clearing g2 FL for h%d!", heap_number));
-            }
-            generation_allocator (gen_to_reset)->clear();
-            generation_free_list_space (gen_to_reset) = 0;
-            generation_free_obj_space (gen_to_reset) = 0;
-        }
-        generation_free_list_allocated (gen_to_reset) = 0;
-        generation_end_seg_allocated (gen_to_reset) = 0;
-        generation_condemned_allocated (gen_to_reset) = 0;
-        generation_sweep_allocated (gen_to_reset) = 0;
-        generation_allocation_pointer (gen_to_reset)= 0;
-        generation_allocation_limit (gen_to_reset) = 0;
-        generation_allocation_segment (gen_to_reset) = heap_segment_rw (generation_start_segment (gen_to_reset));
-    }
-    FIRE_EVENT(BGC2ndNonConEnd);
-    uoh_alloc_thread_count = 0;
-    init_free_and_plug();
-    current_bgc_state = bgc_sweep_soh;
-    verify_soh_segment_list();
-#ifdef DOUBLY_LINKED_FL
-    current_sweep_seg = heap_segment_rw (generation_start_segment (generation_of (max_generation)));
-    current_sweep_pos = 0;
-#endif //DOUBLY_LINKED_FL
-#ifdef FEATURE_BASICFREEZE
-    sweep_ro_segments();
-#endif //FEATURE_BASICFREEZE
-    dprintf (3, ("lh state: planning"));
-    if (current_c_gc_state != c_gc_state_planning)
-    {
-        current_c_gc_state = c_gc_state_planning;
-    }
-    concurrent_print_time_delta ("Swe");
-    for (int i = uoh_start_generation; i < total_generation_count; i++)
-    {
-        heap_segment* uoh_seg = heap_segment_rw (generation_start_segment (generation_of (i)));
-        PREFIX_ASSUME(uoh_seg  != NULL);
-        while (uoh_seg)
-        {
-            uoh_seg->flags &= ~heap_segment_flags_swept;
-            heap_segment_background_allocated (uoh_seg) = heap_segment_allocated (uoh_seg);
-            uoh_seg = heap_segment_next_rw (uoh_seg);
-        }
-    }
-#ifdef MULTIPLE_HEAPS
-    bgc_t_join.join(this, gc_join_restart_ee);
-    if (bgc_t_join.joined())
-    {
-        dprintf(2, ("Starting BGC threads for resuming EE"));
-        bgc_t_join.restart();
-    }
-#endif //MULTIPLE_HEAPS
-    if (heap_number == 0)
-    {
-        get_and_reset_uoh_alloc_info();
-        uint64_t suspended_end_ts = GetHighPrecisionTimeStamp();
-        last_bgc_info[last_bgc_info_index].pause_durations[1] = (size_t)(suspended_end_ts - suspended_start_time);
-        total_suspended_time += last_bgc_info[last_bgc_info_index].pause_durations[1];
-        restart_EE ();
-    }
-    FIRE_EVENT(BGC2ndConBegin);
-    background_ephemeral_sweep();
-    concurrent_print_time_delta ("Swe eph");
-#ifdef MULTIPLE_HEAPS
-    bgc_t_join.join(this, gc_join_after_ephemeral_sweep);
-    if (bgc_t_join.joined())
-#endif //MULTIPLE_HEAPS
-    {
-#ifdef FEATURE_EVENT_TRACE
-        bgc_heap_walk_for_etw_p = GCEventStatus::IsEnabled(GCEventProvider_Default,
-                                                           GCEventKeyword_GCHeapSurvivalAndMovement,
-                                                           GCEventLevel_Information);
-#endif //FEATURE_EVENT_TRACE
-        leave_spin_lock (&gc_lock);
-#ifdef MULTIPLE_HEAPS
-        dprintf(2, ("Starting BGC threads for BGC sweeping"));
-        bgc_t_join.restart();
-#endif //MULTIPLE_HEAPS
-    }
-    disable_preemptive (true);
-    dynamic_data* dd     = dynamic_data_of (max_generation);
-    const int num_objs   = 256;
-    int current_num_objs = 0;
-    for (int i = max_generation; i < total_generation_count; i++)
-    {
-        generation* gen = generation_of (i);
-        heap_segment* gen_start_seg = heap_segment_rw (generation_start_segment(gen));
-        heap_segment* next_seg = 0;
-        heap_segment* prev_seg;
-        heap_segment* start_seg;
-        int align_const = get_alignment_constant (i == max_generation);
-#ifndef DOUBLY_LINKED_FL
-        if (i == max_generation)
-        {
-#ifdef USE_REGIONS
-            start_seg = generation_tail_region (gen);
-#else
-            start_seg = saved_sweep_ephemeral_seg;
-#endif //USE_REGIONS
-            prev_seg = heap_segment_next(start_seg);
-        }
-        else
-#endif //!DOUBLY_LINKED_FL
-        {
-            start_seg = gen_start_seg;
-            prev_seg = NULL;
-            if (i > max_generation)
-            {
-                generation_allocator (gen)->clear();
-                generation_free_list_space (gen) = 0;
-                generation_free_obj_space (gen) = 0;
-                generation_free_list_allocated (gen) = 0;
-                generation_end_seg_allocated (gen) = 0;
-                generation_condemned_allocated (gen) = 0;
-                generation_sweep_allocated (gen) = 0;
-                generation_allocation_pointer (gen)= 0;
-                generation_allocation_limit (gen) = 0;
-                generation_allocation_segment (gen) = heap_segment_rw (generation_start_segment (gen));
-            }
-            else
-            {
-                dprintf (3333, ("h%d: SOH sweep start on seg %zx: total FL: %zd, FO: %zd",
-                    heap_number, (size_t)start_seg,
-                    generation_free_list_space (gen),
-                    generation_free_obj_space (gen)));
-            }
-        }
-        PREFIX_ASSUME(start_seg != NULL);
-        heap_segment* seg = start_seg;
-        dprintf (2, ("bgs: sweeping gen %d seg %p->%p(%p)", gen->gen_num,
-            heap_segment_mem (seg),
-            heap_segment_allocated (seg),
-            heap_segment_background_allocated (seg)));
-        while (seg
-#ifdef DOUBLY_LINKED_FL
-               && !((heap_segment_background_allocated (seg) == 0) && (gen != large_object_generation))
-#endif //DOUBLY_LINKED_FL
-                )
-        {
-            uint8_t* o = heap_segment_mem (seg);
-            if (seg == gen_start_seg)
-            {
-#ifndef USE_REGIONS
-                assert (o == generation_allocation_start (gen));
-                assert (method_table (o) == g_gc_pFreeObjectMethodTable);
-                o = o + Align (size (o), align_const);
-#endif //!USE_REGIONS
-            }
-            uint8_t* plug_end = o;
-            current_sweep_pos = o;
-            next_sweep_obj = o;
-#ifdef DOUBLY_LINKED_FL
-            current_sweep_seg = seg;
-#endif //DOUBLY_LINKED_FL
-            size_t free_obj_size_last_gap = 0;
-            allow_fgc();
-            uint8_t* end = background_next_end (seg, (i > max_generation));
-            dprintf (3333, ("bgs: seg: %zx, [%zx, %zx[%zx", (size_t)seg,
-                            (size_t)heap_segment_mem (seg),
-                            (size_t)heap_segment_allocated (seg),
-                            (size_t)heap_segment_background_allocated (seg)));
-            while (o < end)
-            {
-                if (background_object_marked (o, TRUE))
-                {
-                    uint8_t* plug_start = o;
-                    if (i > max_generation)
-                    {
-                        dprintf (2, ("uoh fr: [%p-%p[(%zd)", plug_end, plug_start, plug_start-plug_end));
-                    }
-                    thread_gap (plug_end, plug_start-plug_end, gen);
-                    if (i == max_generation)
-                    {
-                        add_gen_free (max_generation, plug_start-plug_end);
-#ifdef DOUBLY_LINKED_FL
-                        if (free_obj_size_last_gap)
-                        {
-                            generation_free_obj_space (gen) -= free_obj_size_last_gap;
-                            dprintf (3333, ("[h%d] LG: gen2FO-: %zd->%zd",
-                                heap_number, free_obj_size_last_gap, generation_free_obj_space (gen)));
-                            free_obj_size_last_gap = 0;
-                        }
-#endif //DOUBLY_LINKED_FL
-                        fix_brick_to_highest (plug_end, plug_start);
-                        fix_brick_to_highest (plug_start, plug_start);
-                    }
-                    do
-                    {
-                        next_sweep_obj = o + Align (size (o), align_const);
-                        current_num_objs++;
-                        if (current_num_objs >= num_objs)
-                        {
-                            current_sweep_pos = next_sweep_obj;
-                            allow_fgc();
-                            current_num_objs = 0;
-                        }
-                        o = next_sweep_obj;
-                    } while ((o < end) && background_object_marked(o, TRUE));
-                    plug_end = o;
-                    if (i == max_generation)
-                    {
-                        add_gen_plug (max_generation, plug_end-plug_start);
-                        dd_survived_size (dd) += (plug_end - plug_start);
-                    }
-                    dprintf (3, ("bgs: plug [%zx, %zx[", (size_t)plug_start, (size_t)plug_end));
-                }
-                while ((o < end) && !background_object_marked (o, FALSE))
-                {
-                    size_t size_o = Align(size (o), align_const);
-                    next_sweep_obj = o + size_o;
-#ifdef DOUBLY_LINKED_FL
-                    if ((i == max_generation) && !rebuild_maxgen_fl_p)
-                    {
-                        if (method_table (o) == g_gc_pFreeObjectMethodTable)
-                        {
-                            free_obj_size_last_gap += size_o;
-                            if (is_on_free_list (o, size_o))
-                            {
-#ifdef MULTIPLE_HEAPS
-                                assert (heap_of (o) == this);
-#endif //MULTIPLE_HEAPS
-                                generation_allocator (gen)->unlink_item_no_undo (o, size_o);
-                                generation_free_list_space (gen) -= size_o;
-                                assert ((ptrdiff_t)generation_free_list_space (gen) >= 0);
-                                generation_free_obj_space (gen) += size_o;
-                                dprintf (3333, ("[h%d] gen2F-: %p->%p(%zd) FL: %zd",
-                                    heap_number, o, (o + size_o), size_o,
-                                    generation_free_list_space (gen)));
-                                dprintf (3333, ("h%d: gen2FO+: %p(%zx)->%zd (g: %zd)",
-                                    heap_number, o, size_o,
-                                    generation_free_obj_space (gen),
-                                    free_obj_size_last_gap));
-                                remove_gen_free (max_generation, size_o);
-                            }
-                            else
-                            {
-                                dprintf (3333, ("h%d: gen2FO: %p(%zd)->%zd (g: %zd)",
-                                    heap_number, o, size_o,
-                                    generation_free_obj_space (gen), free_obj_size_last_gap));
-                            }
-                            dprintf (3333, ("h%d: total FO: %p->%p FL: %zd, FO: %zd (g: %zd)",
-                                heap_number, plug_end, next_sweep_obj,
-                                generation_free_list_space (gen),
-                                generation_free_obj_space (gen),
-                                free_obj_size_last_gap));
-                        }
-                    }
-#endif //DOUBLY_LINKED_FL
-                    current_num_objs++;
-                    if (current_num_objs >= num_objs)
-                    {
-                        current_sweep_pos = plug_end;
-                        dprintf (1234, ("f: swept till %p", current_sweep_pos));
-                        allow_fgc();
-                        current_num_objs = 0;
-                    }
-                    o = next_sweep_obj;
-                }
-            }
-#ifdef DOUBLY_LINKED_FL
-            next_seg = heap_segment_next (seg);
-#else //DOUBLY_LINKED_FL
-            if (i > max_generation)
-            {
-                next_seg = heap_segment_next (seg);
-            }
-            else
-            {
-                next_seg = heap_segment_prev (gen_start_seg, seg);
-            }
-#endif //DOUBLY_LINKED_FL
-            BOOL delete_p = FALSE;
-            if (!heap_segment_read_only_p (seg))
-            {
-                if (i > max_generation)
-                {
-                    process_background_segment_end (seg, gen, plug_end,
-                                                    start_seg, &delete_p, 0);
-                }
-                else
-                {
-                    assert (heap_segment_background_allocated (seg) != 0);
-                    process_background_segment_end (seg, gen, plug_end,
-                                                    start_seg, &delete_p, free_obj_size_last_gap);
-#ifndef USE_REGIONS
-                    assert (next_seg || !delete_p);
-#endif //!USE_REGIONS
-                }
-            }
-            heap_segment* saved_prev_seg = prev_seg;
-            if (delete_p)
-            {
-                generation_delete_heap_segment (gen, seg, prev_seg, next_seg);
-            }
-            else
-            {
-                prev_seg = seg;
-                dprintf (2, ("seg %p (%p) has been swept", seg, heap_segment_mem (seg)));
-                seg->flags |= heap_segment_flags_swept;
-                current_sweep_pos = end;
-            }
-            verify_soh_segment_list();
-#ifdef DOUBLY_LINKED_FL
-            while (next_seg && heap_segment_background_allocated (next_seg) == 0)
-            {
-                dprintf (2, ("[h%d] skip new %p ", heap_number, next_seg));
-                next_seg = heap_segment_next (next_seg);
-            }
-#endif //DOUBLY_LINKED_FL
-            dprintf (GTC_LOG, ("seg: %p(%p), next_seg: %p(%p), prev_seg: %p(%p), delete_p %d",
-                seg, (seg ? heap_segment_mem (seg) : 0),
-                next_seg, (next_seg ? heap_segment_mem (next_seg) : 0),
-                saved_prev_seg, (saved_prev_seg ? heap_segment_mem (saved_prev_seg) : 0),
-                (delete_p ? 1 : 0)));
-            seg = next_seg;
-        }
-        generation_allocation_segment (gen) = heap_segment_rw (generation_start_segment (gen));
-        PREFIX_ASSUME(generation_allocation_segment(gen) != NULL);
-        if (i == max_generation)
-        {
-            dprintf (2, ("bgs: sweeping uoh objects"));
-            concurrent_print_time_delta ("Swe SOH");
-            FIRE_EVENT(BGC1stSweepEnd, 0);
-            enter_spin_lock (&more_space_lock_uoh);
-            add_saved_spinlock_info (true, me_acquire, mt_bgc_uoh_sweep, msl_entered);
-            concurrent_print_time_delta ("Swe UOH took msl");
-            int spin_count = yp_spin_count_unit;
-            while (uoh_alloc_thread_count)
-            {
-                spin_and_switch (spin_count, (uoh_alloc_thread_count == 0));
-            }
-            current_bgc_state = bgc_sweep_uoh;
-        }
-    }
-    size_t total_soh_size = generation_sizes (generation_of (max_generation));
-    size_t total_loh_size = generation_size (loh_generation);
-    size_t total_poh_size = generation_size (poh_generation);
-    dprintf (GTC_LOG, ("h%d: S: poh: %zd, loh: %zd, soh: %zd", heap_number, total_poh_size, total_loh_size, total_soh_size));
-    dprintf (GTC_LOG, ("end of bgc sweep: gen2 FL: %zd, FO: %zd",
-        generation_free_list_space (generation_of (max_generation)),
-        generation_free_obj_space (generation_of (max_generation))));
-    dprintf (GTC_LOG, ("h%d: end of bgc sweep: loh FL: %zd, FO: %zd",
-        heap_number,
-        generation_free_list_space (generation_of (loh_generation)),
-        generation_free_obj_space (generation_of (loh_generation))));
-    dprintf (GTC_LOG, ("h%d: end of bgc sweep: poh FL: %zd, FO: %zd",
-        heap_number,
-        generation_free_list_space (generation_of (poh_generation)),
-        generation_free_obj_space (generation_of (poh_generation))));
-    FIRE_EVENT(BGC2ndConEnd);
-    concurrent_print_time_delta ("background sweep");
-    heap_segment* reset_seg = heap_segment_rw (generation_start_segment (generation_of (max_generation)));
-    PREFIX_ASSUME(reset_seg != NULL);
-    while (reset_seg)
-    {
-        heap_segment_saved_bg_allocated (reset_seg) = heap_segment_background_allocated (reset_seg);
-        heap_segment_background_allocated (reset_seg) = 0;
-        reset_seg = heap_segment_next_rw (reset_seg);
-    }
-    compute_new_dynamic_data (max_generation);
-    gc_history_per_heap* current_gc_data_per_heap = get_gc_data_per_heap();
-    for (int i = uoh_start_generation; i < total_generation_count; i++)
-    {
-        assert(uoh_a_bgc_marking[i - uoh_start_generation] == 0);
-        assert(uoh_a_no_bgc[i - uoh_start_generation] == 0);
-        current_gc_data_per_heap->gen_data[i].size_before += uoh_a_bgc_planning[i - uoh_start_generation];
-    }
-#ifdef DOUBLY_LINKED_FL
-    current_bgc_state = bgc_not_in_process;
-    current_sweep_seg = 0;
-#endif //DOUBLY_LINKED_FL
-    enable_preemptive ();
-#ifdef MULTIPLE_HEAPS
-    bgc_t_join.join(this, gc_join_set_state_free);
-    if (bgc_t_join.joined())
-#endif //MULTIPLE_HEAPS
-    {
-        current_c_gc_state = c_gc_state_free;
-#ifdef DYNAMIC_HEAP_COUNT
-        update_total_soh_stable_size();
-#endif //DYNAMIC_HEAP_COUNT
-#ifdef BGC_SERVO_TUNING
-        if (bgc_tuning::enable_fl_tuning)
-        {
-            enter_spin_lock (&gc_lock);
-            bgc_tuning::record_and_adjust_bgc_end();
-            leave_spin_lock (&gc_lock);
-        }
-#endif //BGC_SERVO_TUNING
-#ifdef MULTIPLE_HEAPS
-        dprintf(2, ("Starting BGC threads after background sweep phase"));
-        bgc_t_join.restart();
-#endif //MULTIPLE_HEAPS
-    }
-    disable_preemptive (true);
-    add_saved_spinlock_info (true, me_release, mt_bgc_uoh_sweep, msl_entered);
-    leave_spin_lock (&more_space_lock_uoh);
-    dprintf (GTC_LOG, ("---- (GC%zu)ESw ----", VolatileLoad(&settings.gc_index)));
-}
-#endif //BACKGROUND_GC
-void gc_heap::sweep_uoh_objects (int gen_num)
-{
-    generation* gen        = generation_of (gen_num);
-    heap_segment* start_seg = heap_segment_rw (generation_start_segment (gen));
-    PREFIX_ASSUME(start_seg != NULL);
-    heap_segment* seg      = start_seg;
-    heap_segment* prev_seg = 0;
-    uint8_t* o             = get_uoh_start_object (seg, gen);
-    uint8_t* plug_end         = o;
-    uint8_t* plug_start       = o;
-    generation_allocator (gen)->clear();
-    generation_free_list_space (gen) = 0;
-    generation_free_obj_space (gen) = 0;
-    generation_free_list_allocated (gen) = 0;
-    dprintf (3, ("sweeping uoh objects"));
-    dprintf (3, ("seg: %zx, [%zx, %zx[, starting from %p",
-                 (size_t)seg,
-                 (size_t)heap_segment_mem (seg),
-                 (size_t)heap_segment_allocated (seg),
-                 o));
-    while (1)
-    {
-        if (o >= heap_segment_allocated (seg))
-        {
-            heap_segment* next_seg = heap_segment_next (seg);
-            if ((plug_end == heap_segment_mem (seg)) &&
-                (seg != start_seg) && !heap_segment_read_only_p (seg))
-            {
-                dprintf (3, ("Preparing empty large segment %zx", (size_t)seg));
-                assert (prev_seg);
-                heap_segment_next (prev_seg) = next_seg;
-                heap_segment_next (seg) = freeable_uoh_segment;
-                freeable_uoh_segment = seg;
-#ifdef USE_REGIONS
-                update_start_tail_regions (gen, seg, prev_seg, next_seg);
-#endif //USE_REGIONS
-            }
-            else
-            {
-                if (!heap_segment_read_only_p (seg))
-                {
-                    dprintf (3, ("Trimming seg to %zx[", (size_t)plug_end));
-                    heap_segment_allocated (seg) = plug_end;
-                    decommit_heap_segment_pages (seg, 0);
-                }
-                prev_seg = seg;
-            }
-            seg = next_seg;
-            if (seg == 0)
-                break;
-            else
-            {
-                o = heap_segment_mem (seg);
-                plug_end = o;
-                dprintf (3, ("seg: %zx, [%zx, %zx[", (size_t)seg,
-                             (size_t)heap_segment_mem (seg),
-                             (size_t)heap_segment_allocated (seg)));
-#ifdef USE_REGIONS
-                continue;
-#endif //USE_REGIONS
-            }
-        }
-        if (uoh_object_marked(o, TRUE))
-        {
-            plug_start = o;
-            thread_gap (plug_end, plug_start-plug_end, gen);
-            BOOL m = TRUE;
-            while (m)
-            {
-                o = o + AlignQword (size (o));
-                if (o >= heap_segment_allocated (seg))
-                {
-                    break;
-                }
-                m = uoh_object_marked (o, TRUE);
-            }
-            plug_end = o;
-            dprintf (3, ("plug [%zx, %zx[", (size_t)plug_start, (size_t)plug_end));
-        }
-        else
-        {
-            while (o < heap_segment_allocated (seg) && !uoh_object_marked(o, FALSE))
-            {
-                o = o + AlignQword (size (o));
-            }
-        }
-    }
-    generation_allocation_segment (gen) = heap_segment_rw (generation_start_segment (gen));
-    PREFIX_ASSUME(generation_allocation_segment(gen) != NULL);
-}
-void gc_heap::relocate_in_uoh_objects (int gen_num)
-{
-    generation* gen = generation_of (gen_num);
-    heap_segment* seg = heap_segment_rw (generation_start_segment (gen));
-    PREFIX_ASSUME(seg != NULL);
-    uint8_t* o = get_uoh_start_object (seg, gen);
-    while (1)
-    {
-        if (o >= heap_segment_allocated (seg))
-        {
-            seg = heap_segment_next_rw (seg);
-            if (seg == 0)
-                break;
-            else
-            {
-                o = heap_segment_mem (seg);
-            }
-        }
-        while (o < heap_segment_allocated (seg))
-        {
-            check_class_object_demotion (o);
-            if (contain_pointers (o))
-            {
-                dprintf(3, ("Relocating through uoh object %zx", (size_t)o));
-                go_through_object_nostart (method_table (o), o, size(o), pval,
-                        {
-                            reloc_survivor_helper (pval);
-                        });
-            }
-            o = o + AlignQword (size (o));
-        }
-    }
-}
-void gc_heap::mark_through_cards_for_uoh_objects (card_fn fn,
-                                                  int gen_num,
-                                                  BOOL relocating
-                                                  CARD_MARKING_STEALING_ARG(gc_heap* hpt))
-{
-#ifdef USE_REGIONS
-    uint8_t*      low               = 0;
-#else
-    uint8_t*      low               = gc_low;
-#endif //USE_REGIONS
-    size_t        end_card          = 0;
-    generation*   oldest_gen        = generation_of (gen_num);
-    heap_segment* seg               = heap_segment_rw (generation_start_segment (oldest_gen));
-    PREFIX_ASSUME(seg != NULL);
-    uint8_t*      beg               = get_uoh_start_object (seg, oldest_gen);
-    uint8_t*      end               = heap_segment_allocated (seg);
-    size_t  cg_pointers_found = 0;
-    size_t  card_word_end = (card_of (align_on_card_word (end)) /
-                             card_word_width);
-    size_t      n_eph             = 0;
-    size_t      n_gen             = 0;
-    size_t      n_card_set        = 0;
-#ifdef USE_REGIONS
-    uint8_t*    next_boundary = 0;
-    uint8_t*    nhigh         = 0;
-#else
-    uint8_t*    next_boundary = (relocating ?
-                              generation_plan_allocation_start (generation_of (max_generation -1)) :
-                              ephemeral_low);
-    uint8_t*    nhigh         = (relocating ?
-                              heap_segment_plan_allocated (ephemeral_heap_segment) :
-                              ephemeral_high);
-#endif //USE_REGIONS
-    BOOL          foundp            = FALSE;
-    uint8_t*      start_address     = 0;
-    uint8_t*      limit             = 0;
-    size_t        card              = card_of (beg);
-    uint8_t*      o                 = beg;
-#ifdef BACKGROUND_GC
-    BOOL consider_bgc_mark_p        = FALSE;
-    BOOL check_current_sweep_p      = FALSE;
-    BOOL check_saved_sweep_p        = FALSE;
-    should_check_bgc_mark (seg, &consider_bgc_mark_p, &check_current_sweep_p, &check_saved_sweep_p);
-#endif //BACKGROUND_GC
-    size_t total_cards_cleared = 0;
-#ifdef FEATURE_CARD_MARKING_STEALING
-    VOLATILE(uint32_t)* chunk_index = (VOLATILE(uint32_t)*) &(gen_num == loh_generation ?
-        card_mark_chunk_index_loh :
-        card_mark_chunk_index_poh);
-    card_marking_enumerator card_mark_enumerator(seg, low, chunk_index);
-    card_word_end = 0;
-#endif // FEATURE_CARD_MARKING_STEALING
-#ifdef USE_REGIONS
-    int condemned_gen = settings.condemned_generation;
-#else
-    int condemned_gen = -1;
-#endif //USE_REGIONS
-    dprintf(3, ("CMl: %zx->%zx", (size_t)beg, (size_t)end));
-    while (1)
-    {
-        if ((o < end) && (card_of(o) > card))
-        {
-            dprintf (3, ("Found %zd cg pointers", cg_pointers_found));
-            if (cg_pointers_found == 0)
-            {
-                uint8_t* last_object_processed = o;
-#ifdef FEATURE_CARD_MARKING_STEALING
-                last_object_processed = min(limit, o);
-#endif // FEATURE_CARD_MARKING_STEALING
-                dprintf (3, (" Clearing cards [%zx, %zx[ ", (size_t)card_address(card), (size_t)last_object_processed));
-                clear_cards (card, card_of((uint8_t*)last_object_processed));
-                total_cards_cleared += (card_of((uint8_t*)last_object_processed) - card);
-            }
-            n_eph +=cg_pointers_found;
-            cg_pointers_found = 0;
-            card = card_of ((uint8_t*)o);
-        }
-        if ((o < end) &&(card >= end_card))
-        {
-#ifdef FEATURE_CARD_MARKING_STEALING
-            foundp = find_next_chunk(card_mark_enumerator, seg, n_card_set, start_address, limit, card, end_card, card_word_end);
-#else // FEATURE_CARD_MARKING_STEALING
-            foundp = find_card (card_table, card, card_word_end, end_card);
-            if (foundp)
-            {
-                n_card_set+= end_card - card;
-                start_address = max (beg, card_address (card));
-            }
-            limit = min (end, card_address (end_card));
-#endif  // FEATURE_CARD_MARKING_STEALING
-        }
-        if ((!foundp) || (o >= end) || (card_address (card) >= end))
-        {
-            if ((foundp) && (cg_pointers_found == 0))
-            {
-                dprintf(3,(" Clearing cards [%zx, %zx[ ", (size_t)card_address(card),
-                           (size_t)card_address(card+1)));
-                clear_cards (card, card+1);
-                total_cards_cleared += 1;
-            }
-            n_eph +=cg_pointers_found;
-            cg_pointers_found = 0;
-#ifdef FEATURE_CARD_MARKING_STEALING
-            card_mark_enumerator.exhaust_segment(seg);
-#endif // FEATURE_CARD_MARKING_STEALING
-            if ((seg = heap_segment_next_rw (seg)) != 0)
-            {
-#ifdef BACKGROUND_GC
-                should_check_bgc_mark (seg, &consider_bgc_mark_p, &check_current_sweep_p, &check_saved_sweep_p);
-#endif //BACKGROUND_GC
-                beg = heap_segment_mem (seg);
-                end = compute_next_end (seg, low);
-#ifdef FEATURE_CARD_MARKING_STEALING
-                card_word_end = 0;
-#else // FEATURE_CARD_MARKING_STEALING
-                card_word_end = card_of (align_on_card_word (end)) / card_word_width;
-#endif // FEATURE_CARD_MARKING_STEALING
-                card = card_of (beg);
-                o  = beg;
-                end_card = 0;
-                continue;
-            }
-            else
-            {
-                break;
-            }
-        }
-        assert (card_set_p (card));
-        {
-            dprintf(3,("card %zx: o: %zx, l: %zx[ ",
-                       card, (size_t)o, (size_t)limit));
-            assert (Align (size (o)) >= Align (min_obj_size));
-            size_t s = size (o);
-            uint8_t* next_o =  o + AlignQword (s);
-            Prefetch (next_o);
-            while (o < limit)
-            {
-                s = size (o);
-                assert (Align (s) >= Align (min_obj_size));
-                next_o =  o + AlignQword (s);
-                Prefetch (next_o);
-                dprintf (4, ("|%zx|", (size_t)o));
-                if (next_o < start_address)
-                {
-                    goto end_object;
-                }
-#ifdef BACKGROUND_GC
-                if (!fgc_should_consider_object (o, seg, consider_bgc_mark_p, check_current_sweep_p, check_saved_sweep_p))
-                {
-                    goto end_object;
-                }
-#endif //BACKGROUND_GC
-#ifdef COLLECTIBLE_CLASS
-                if (is_collectible(o))
-                {
-                    BOOL passed_end_card_p = FALSE;
-                    if (card_of (o) > card)
-                    {
-                        passed_end_card_p = card_transition (o, end, card_word_end,
-                            cg_pointers_found,
-                            n_eph, n_card_set,
-                            card, end_card,
-                            foundp, start_address,
-                            limit, total_cards_cleared
-                            CARD_MARKING_STEALING_ARGS(card_mark_enumerator, seg, card_word_end));
-                    }
-                    if ((!passed_end_card_p || foundp) && (card_of (o) == card))
-                    {
-                        if (fn == &gc_heap::relocate_address)
-                        {
-                            cg_pointers_found++;
-                        }
-                        else
-                        {
-                            uint8_t* class_obj = get_class_object (o);
-                            mark_through_cards_helper (&class_obj, n_gen,
-                                                       cg_pointers_found, fn,
-                                                       nhigh, next_boundary,
-                                                       condemned_gen, max_generation CARD_MARKING_STEALING_ARG(hpt));
-                        }
-                    }
-                    if (passed_end_card_p)
-                    {
-                        if (foundp && (card_address (card) < next_o))
-                        {
-                            goto go_through_refs;
-                        }
-                        else
-                        {
-                            goto end_object;
-                        }
-                    }
-                }
-go_through_refs:
-#endif //COLLECTIBLE_CLASS
-                if (contain_pointers (o))
-                {
-                    dprintf(3,("Going through %zx", (size_t)o));
-                    go_through_object (method_table(o), o, s, poo,
-                                       start_address, use_start, (o + s),
-                       {
-                           if (card_of ((uint8_t*)poo) > card)
-                           {
-                                BOOL passed_end_card_p  = card_transition ((uint8_t*)poo, end,
-                                        card_word_end,
-                                        cg_pointers_found,
-                                        n_eph, n_card_set,
-                                        card, end_card,
-                                        foundp, start_address,
-                                        limit, total_cards_cleared
-                                        CARD_MARKING_STEALING_ARGS(card_mark_enumerator, seg, card_word_end));
-                                if (passed_end_card_p)
-                                {
-                                    if (foundp && (card_address (card) < next_o))
-                                    {
-                                        {
-                                            if (ppstop <= (uint8_t**)start_address)
-                                            {break;}
-                                            else if (poo < (uint8_t**)start_address)
-                                            {poo = (uint8_t**)start_address;}
-                                        }
-                                    }
-                                    else
-                                    {
-                                        goto end_object;
-                                    }
-                                }
-                            }
-                           mark_through_cards_helper (poo, n_gen,
-                                                      cg_pointers_found, fn,
-                                                      nhigh, next_boundary,
-                                                      condemned_gen, max_generation CARD_MARKING_STEALING_ARG(hpt));
-                       }
-                        );
-                }
-            end_object:
-                o = next_o;
-            }
-        }
-    }
-    if (!relocating)
-    {
-#ifdef FEATURE_CARD_MARKING_STEALING
-        Interlocked::ExchangeAddPtr(&n_eph_loh, n_eph);
-        Interlocked::ExchangeAddPtr(&n_gen_loh, n_gen);
-        dprintf (3, ("h%d marking h%d Mloh: cross: %zd, useful: %zd, cards set: %zd, cards cleared: %zd, ratio: %d",
-            hpt->heap_number, heap_number, n_eph, n_gen, n_card_set, total_cards_cleared,
-            (n_eph ? (int)(((float)n_gen / (float)n_eph) * 100) : 0)));
-        dprintf (3, ("h%d marking h%d Mloh: total cross %zd, useful: %zd, running ratio: %d",
-            hpt->heap_number, heap_number, (size_t)n_eph_loh, (size_t)n_gen_loh,
-            (n_eph_loh ? (int)(((float)n_gen_loh / (float)n_eph_loh) * 100) : 0)));
-#else
-        generation_skip_ratio = min (((n_eph > MIN_LOH_CROSS_GEN_REFS) ?
-            (int)(((float)n_gen / (float)n_eph) * 100) : 100),
-            generation_skip_ratio);
-        dprintf (3, ("marking h%d Mloh: cross: %zd, useful: %zd, cards cleared: %zd, cards set: %zd, ratio: %d",
-            heap_number, n_eph, n_gen, total_cards_cleared, n_card_set, generation_skip_ratio));
-#endif //FEATURE_CARD_MARKING_STEALING
-    }
-    else
-    {
-        dprintf (3, ("R: Mloh: cross: %zd, useful: %zd, cards set: %zd, ratio: %d",
-             n_eph, n_gen, n_card_set, generation_skip_ratio));
-    }
-}
-void gc_heap::descr_generations_to_profiler (gen_walk_fn fn, void *context)
-{
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < n_heaps; i++)
-    {
-        gc_heap* hp = g_heaps[i];
-#else //MULTIPLE_HEAPS
-    {
-        gc_heap* hp = NULL;
-#ifdef _PREFAST_
-        PREFIX_ASSUME(hp != NULL);
-#endif // _PREFAST_
-#endif //MULTIPLE_HEAPS
-        for (int curr_gen_number = total_generation_count-1; curr_gen_number >= 0; curr_gen_number--)
-        {
-            generation* gen = hp->generation_of (curr_gen_number);
-            heap_segment* seg = heap_segment_rw (generation_start_segment (gen));
-#ifdef USE_REGIONS
-            while (seg)
-            {
-                fn(context, curr_gen_number, heap_segment_mem (seg),
-                                              heap_segment_allocated (seg),
-                                              heap_segment_reserved (seg));
-                seg = heap_segment_next_rw (seg);
-            }
-#else
-            while (seg && (seg != hp->ephemeral_heap_segment))
-            {
-                assert (curr_gen_number > 0);
-                fn(context, curr_gen_number, heap_segment_mem (seg),
-                                              heap_segment_allocated (seg),
-                                              (curr_gen_number > max_generation) ?
-                                                heap_segment_reserved (seg) : heap_segment_allocated (seg));
-                seg = heap_segment_next_rw (seg);
-            }
-            if (seg)
-            {
-                assert (seg == hp->ephemeral_heap_segment);
-                assert (curr_gen_number <= max_generation);
-                if (curr_gen_number == max_generation)
-                {
-                    if (heap_segment_mem (seg) < generation_allocation_start (hp->generation_of (max_generation-1)))
-                    {
-                        fn(context, curr_gen_number, heap_segment_mem (seg),
-                                                      generation_allocation_start (hp->generation_of (max_generation-1)),
-                                                      generation_allocation_start (hp->generation_of (max_generation-1)) );
-                    }
-                }
-                else if (curr_gen_number != 0)
-                {
-                    fn(context, curr_gen_number, generation_allocation_start (hp->generation_of (curr_gen_number)),
-                                                  generation_allocation_start (hp->generation_of (curr_gen_number-1)),
-                                                  generation_allocation_start (hp->generation_of (curr_gen_number-1)));
-                }
-                else
-                {
-                    fn(context, curr_gen_number, generation_allocation_start (hp->generation_of (curr_gen_number)),
-                                                  heap_segment_allocated (hp->ephemeral_heap_segment),
-                                                  heap_segment_reserved (hp->ephemeral_heap_segment) );
-                }
-            }
-#endif //USE_REGIONS
-        }
-    }
-}
-#ifdef TRACE_GC
-void gc_heap::print_free_list (int gen, heap_segment* seg)
-{
-    UNREFERENCED_PARAMETER(gen);
-    UNREFERENCED_PARAMETER(seg);
-/*
-    if (settings.concurrent == FALSE)
-    {
-        uint8_t* seg_start = heap_segment_mem (seg);
-        uint8_t* seg_end = heap_segment_allocated (seg);
-        dprintf (3, ("Free list in seg %zx:", seg_start));
-        size_t total_free_item = 0;
-        allocator* gen_allocator = generation_allocator (generation_of (gen));
-        for (unsigned int b = 0; b < gen_allocator->number_of_buckets(); b++)
-        {
-            uint8_t* fo = gen_allocator->alloc_list_head_of (b);
-            while (fo)
-            {
-                if (fo >= seg_start && fo < seg_end)
-                {
-                    total_free_item++;
-                    size_t free_item_len = size(fo);
-                    dprintf (3, ("[%zx, %zx[:%zd",
-                                 (size_t)fo,
-                                 (size_t)(fo + free_item_len),
-                                 free_item_len));
-                }
-                fo = free_list_slot (fo);
-            }
-        }
-        dprintf (3, ("total %zd free items", total_free_item));
-    }
-*/
-}
-#endif //TRACE_GC
-void gc_heap::descr_generations (const char* msg)
-{
-#ifndef TRACE_GC
-    UNREFERENCED_PARAMETER(msg);
-#endif //!TRACE_GC
-#ifdef STRESS_LOG
-    if (StressLog::StressLogOn(LF_GC, LL_INFO10))
-    {
-        gc_heap* hp = 0;
-#ifdef MULTIPLE_HEAPS
-        hp= this;
-#endif //MULTIPLE_HEAPS
-        STRESS_LOG1(LF_GC, LL_INFO10, "GC Heap %p\n", hp);
-        for (int n = max_generation; n >= 0; --n)
-        {
-#ifndef USE_REGIONS
-            STRESS_LOG4(LF_GC, LL_INFO10, "    Generation %d [%p, %p] cur = %p\n",
-                    n,
-                    generation_allocation_start(generation_of(n)),
-                    generation_allocation_limit(generation_of(n)),
-                    generation_allocation_pointer(generation_of(n)));
-#endif //USE_REGIONS
-            heap_segment* seg = generation_start_segment(generation_of(n));
-            while (seg)
-            {
-                STRESS_LOG4(LF_GC, LL_INFO10, "        Segment mem %p alloc = %p used %p committed %p\n",
-                        heap_segment_mem(seg),
-                        heap_segment_allocated(seg),
-                        heap_segment_used(seg),
-                        heap_segment_committed(seg));
-                seg = heap_segment_next(seg);
-            }
-        }
-    }
-#endif  // STRESS_LOG
-#ifdef TRACE_GC
-    dprintf (2, ("lowest_address: %zx highest_address: %zx",
-             (size_t) lowest_address, (size_t) highest_address));
-#ifdef BACKGROUND_GC
-    dprintf (2, ("bgc lowest_address: %zx bgc highest_address: %zx",
-             (size_t) background_saved_lowest_address, (size_t) background_saved_highest_address));
-#endif //BACKGROUND_GC
-    if (heap_number == 0)
-    {
-#ifdef USE_REGIONS
-        size_t alloc_size = get_total_heap_size () / 1024 / 1024;
-        size_t commit_size = get_total_committed_size () / 1024 / 1024;
-        size_t frag_size = get_total_fragmentation () / 1024 / 1024;
-        int total_new_gen0_regions_in_plns = get_total_new_gen0_regions_in_plns ();
-        int total_new_regions_in_prr = get_total_new_regions_in_prr ();
-        int total_new_regions_in_threading = get_total_new_regions_in_threading ();
-        uint64_t elapsed_time_so_far = GetHighPrecisionTimeStamp () - process_start_time;
-        size_t idx = VolatileLoadWithoutBarrier (&settings.gc_index);
-        dprintf (REGIONS_LOG, ("[%s] GC#%5Id [%s] heap %Idmb (F: %Idmb %d%%) commit size: %Idmb, %0.3f min, %d,%d new in plan, %d in threading",
-            msg, idx, (settings.promotion ? "PM" : "NPM"), alloc_size, frag_size,
-            (int)((double)frag_size * 100.0 / (double)alloc_size),
-            commit_size,
-            (double)elapsed_time_so_far / (double)1000000 / (double)60,
-            total_new_gen0_regions_in_plns, total_new_regions_in_prr, total_new_regions_in_threading));
-        size_t total_gen_size_mb[loh_generation + 1] = { 0, 0, 0, 0 };
-        size_t total_gen_fragmentation_mb[loh_generation + 1] = { 0, 0, 0, 0 };
-        for (int i = 0; i < (loh_generation + 1); i++)
-        {
-            total_gen_size_mb[i] = get_total_generation_size (i) / 1024 / 1024;
-            total_gen_fragmentation_mb[i] = get_total_gen_fragmentation (i) / 1024 / 1024;
-        }
-        int bgcs = VolatileLoadWithoutBarrier (&current_bgc_state);
-#ifdef SIMPLE_DPRINTF
-        dprintf (REGIONS_LOG, ("[%s] GC#%Id (bgcs: %d, %s) g0: %Idmb (f: %Idmb %d%%), g1: %Idmb (f: %Idmb %d%%), g2: %Idmb (f: %Idmb %d%%), g3: %Idmb (f: %Idmb %d%%)",
-            msg, idx, bgcs, str_bgc_state[bgcs],
-            total_gen_size_mb[0], total_gen_fragmentation_mb[0], (total_gen_size_mb[0] ? (int)((double)total_gen_fragmentation_mb[0] * 100.0 / (double)total_gen_size_mb[0]) : 0),
-            total_gen_size_mb[1], total_gen_fragmentation_mb[1], (total_gen_size_mb[1] ? (int)((double)total_gen_fragmentation_mb[1] * 100.0 / (double)total_gen_size_mb[1]) : 0),
-            total_gen_size_mb[2], total_gen_fragmentation_mb[2], (total_gen_size_mb[2] ? (int)((double)total_gen_fragmentation_mb[2] * 100.0 / (double)total_gen_size_mb[2]) : 0),
-            total_gen_size_mb[3], total_gen_fragmentation_mb[3], (total_gen_size_mb[3] ? (int)((double)total_gen_fragmentation_mb[3] * 100.0 / (double)total_gen_size_mb[3]) : 0)));
-#endif //SIMPLE_DPRINTF
-        if ((idx % 20) == 0)
-        {
-            dprintf (1, ("[%5s] GC#%5Id total heap size: %Idmb (F: %Idmb %d%%) commit size: %Idmb, %0.3f min, %d,%d new in plan, %d in threading\n",
-                msg, idx, alloc_size, frag_size,
-                (int)((double)frag_size * 100.0 / (double)alloc_size),
-                commit_size,
-                (double)elapsed_time_so_far / (double)1000000 / (double)60,
-                total_new_gen0_regions_in_plns, total_new_regions_in_prr, total_new_regions_in_threading));
-        }
-#endif //USE_REGIONS
-    }
-    for (int curr_gen_number = total_generation_count - 1; curr_gen_number >= 0; curr_gen_number--)
-    {
-        size_t total_gen_size = generation_size (curr_gen_number);
-#ifdef SIMPLE_DPRINTF
-        dprintf (GTC_LOG, ("[%s][g%d]gen %d:, size: %zd, frag: %zd(L: %zd, O: %zd), f: %d%% %s %s %s",
-                      msg,
-                      settings.condemned_generation,
-                      curr_gen_number,
-                      total_gen_size,
-                      dd_fragmentation (dynamic_data_of (curr_gen_number)),
-                      generation_free_list_space (generation_of (curr_gen_number)),
-                      generation_free_obj_space (generation_of (curr_gen_number)),
-                      (total_gen_size ?
-                        (int)(((double)dd_fragmentation (dynamic_data_of (curr_gen_number)) / (double)total_gen_size) * 100) :
-                        0),
-                      (settings.compaction ? "(compact)" : "(sweep)"),
-                      (settings.heap_expansion ? "(EX)" : " "),
-                      (settings.promotion ? "Promotion" : "NoPromotion")));
-#else
-        dprintf (2, ( "Generation %d: generation size: %zd, fragmentation: %zd",
-                      curr_gen_number,
-                      total_gen_size,
-                      dd_fragmentation (dynamic_data_of (curr_gen_number))));
-#endif //SIMPLE_DPRINTF
-        generation* gen = generation_of (curr_gen_number);
-        heap_segment* seg = heap_segment_rw (generation_start_segment (gen));
-#ifdef USE_REGIONS
-        dprintf (GTC_LOG, ("g%d: start seg: %p alloc seg: %p, tail region: %p",
-            curr_gen_number,
-            heap_segment_mem (seg),
-            (generation_allocation_segment (gen) ? heap_segment_mem (generation_allocation_segment (gen)) : 0),
-            heap_segment_mem (generation_tail_region (gen))));
-        while (seg)
-        {
-            dprintf (GTC_LOG, ("g%d: (%d:p %d) [%zx %zx(sa: %zx, pa: %zx)[-%zx[ (%zd) (%zd)",
-                               curr_gen_number,
-                               heap_segment_gen_num (seg),
-                               heap_segment_plan_gen_num (seg),
-                               (size_t)heap_segment_mem (seg),
-                               (size_t)heap_segment_allocated (seg),
-                               (size_t)heap_segment_saved_allocated (seg),
-                               (size_t)heap_segment_plan_allocated (seg),
-                               (size_t)heap_segment_committed (seg),
-                               (size_t)(heap_segment_allocated (seg) - heap_segment_mem (seg)),
-                               (size_t)(heap_segment_committed (seg) - heap_segment_allocated (seg))));
-            print_free_list (curr_gen_number, seg);
-            seg = heap_segment_next (seg);
-        }
-#else
-        while (seg && (seg != ephemeral_heap_segment))
-        {
-            dprintf (GTC_LOG, ("g%d: [%zx %zx[-%zx[ (%zd) (%zd)",
-                        curr_gen_number,
-                        (size_t)heap_segment_mem (seg),
-                        (size_t)heap_segment_allocated (seg),
-                        (size_t)heap_segment_committed (seg),
-                        (size_t)(heap_segment_allocated (seg) - heap_segment_mem (seg)),
-                        (size_t)(heap_segment_committed (seg) - heap_segment_allocated (seg))));
-            print_free_list (curr_gen_number, seg);
-            seg = heap_segment_next (seg);
-        }
-        if (seg && (seg != generation_start_segment (gen)))
-        {
-            dprintf (GTC_LOG, ("g%d: [%zx %zx[",
-                         curr_gen_number,
-                         (size_t)heap_segment_mem (seg),
-                         (size_t)generation_allocation_start (generation_of (curr_gen_number-1))));
-            print_free_list (curr_gen_number, seg);
-        }
-        else if (seg)
-        {
-            dprintf (GTC_LOG, ("g%d: [%zx %zx[",
-                         curr_gen_number,
-                         (size_t)generation_allocation_start (generation_of (curr_gen_number)),
-                         (size_t)(((curr_gen_number == 0)) ?
-                                  (heap_segment_allocated
-                                   (generation_start_segment
-                                    (generation_of (curr_gen_number)))) :
-                                  (generation_allocation_start
-                                   (generation_of (curr_gen_number - 1))))
-                         ));
-            print_free_list (curr_gen_number, seg);
-        }
-#endif //USE_REGIONS
-    }
-#endif //TRACE_GC
-}
-VOLATILE(BOOL)    GCHeap::GcInProgress            = FALSE;
-GCEvent           *GCHeap::WaitForGCEvent         = NULL;
-unsigned          GCHeap::GcCondemnedGeneration   = 0;
-size_t            GCHeap::totalSurvivedSize       = 0;
-#ifdef FEATURE_PREMORTEM_FINALIZATION
-CFinalize*        GCHeap::m_Finalize              = 0;
-BOOL              GCHeap::GcCollectClasses        = FALSE;
-VOLATILE(int32_t) GCHeap::m_GCFLock               = 0;
-#ifndef FEATURE_NATIVEAOT // NativeAOT forces relocation a different way
-#ifdef STRESS_HEAP
-#ifndef MULTIPLE_HEAPS
-OBJECTHANDLE      GCHeap::m_StressObjs[NUM_HEAP_STRESS_OBJS];
-int               GCHeap::m_CurStressObj          = 0;
-#endif // !MULTIPLE_HEAPS
-#endif // STRESS_HEAP
-#endif // FEATURE_NATIVEAOT
-#endif //FEATURE_PREMORTEM_FINALIZATION
-class NoGCRegionLockHolder
-{
-public:
-    NoGCRegionLockHolder()
-    {
-        enter_spin_lock_noinstru(&g_no_gc_lock);
-    }
-    ~NoGCRegionLockHolder()
-    {
-        leave_spin_lock_noinstru(&g_no_gc_lock);
-    }
-};
-enable_no_gc_region_callback_status gc_heap::enable_no_gc_callback(NoGCRegionCallbackFinalizerWorkItem* callback, uint64_t callback_threshold)
-{
-    dprintf(1, ("[no_gc_callback] calling enable_no_gc_callback with callback_threshold = %llu\n", callback_threshold));
-    enable_no_gc_region_callback_status status = enable_no_gc_region_callback_status::succeed;
-    suspend_EE();
-    {
-        if (!current_no_gc_region_info.started)
-        {
-            status = enable_no_gc_region_callback_status::not_started;
-        }
-        else if (current_no_gc_region_info.callback != nullptr)
-        {
-            status = enable_no_gc_region_callback_status::already_registered;
-        }
-        else
-        {
-            uint64_t total_original_soh_budget = 0;
-            uint64_t total_original_loh_budget = 0;
-#ifdef MULTIPLE_HEAPS
-            for (int i = 0; i < gc_heap::n_heaps; i++)
-            {
-                gc_heap* hp = gc_heap::g_heaps [i];
-#else
-            {
-                gc_heap* hp = pGenGCHeap;
-#endif
-                total_original_soh_budget += hp->soh_allocation_no_gc;
-                total_original_loh_budget += hp->loh_allocation_no_gc;
-            }
-            uint64_t total_original_budget = total_original_soh_budget + total_original_loh_budget;
-            if (total_original_budget >= callback_threshold)
-            {
-                uint64_t total_withheld = total_original_budget - callback_threshold;
-                float soh_ratio = ((float)total_original_soh_budget)/total_original_budget;
-                float loh_ratio = ((float)total_original_loh_budget)/total_original_budget;
-                size_t soh_withheld_budget = (size_t)(soh_ratio * total_withheld);
-                size_t loh_withheld_budget = (size_t)(loh_ratio * total_withheld);
-#ifdef MULTIPLE_HEAPS
-                soh_withheld_budget = soh_withheld_budget / gc_heap::n_heaps;
-                loh_withheld_budget = loh_withheld_budget / gc_heap::n_heaps;
-#endif
-                soh_withheld_budget = max(soh_withheld_budget, (size_t)1);
-                soh_withheld_budget = Align(soh_withheld_budget, get_alignment_constant (TRUE));
-                loh_withheld_budget = Align(loh_withheld_budget, get_alignment_constant (FALSE));
-#ifdef MULTIPLE_HEAPS
-                for (int i = 0; i < gc_heap::n_heaps; i++)
-                {
-                    gc_heap* hp = gc_heap::g_heaps [i];
-#else
-                {
-                    gc_heap* hp = pGenGCHeap;
-#endif
-                    if (dd_new_allocation (hp->dynamic_data_of (soh_gen0)) <= (ptrdiff_t)soh_withheld_budget)
-                    {
-                        dprintf(1, ("[no_gc_callback] failed because of running out of soh budget= %llu\n", soh_withheld_budget));
-                        status = insufficient_budget;
-                    }
-                    if (dd_new_allocation (hp->dynamic_data_of (loh_generation)) <= (ptrdiff_t)loh_withheld_budget)
-                    {
-                        dprintf(1, ("[no_gc_callback] failed because of running out of loh budget= %llu\n", loh_withheld_budget));
-                        status = insufficient_budget;
-                    }
-                }
-                if (status == enable_no_gc_region_callback_status::succeed)
-                {
-                    dprintf(1, ("[no_gc_callback] enabling succeed\n"));
-#ifdef MULTIPLE_HEAPS
-                    for (int i = 0; i < gc_heap::n_heaps; i++)
-                    {
-                        gc_heap* hp = gc_heap::g_heaps [i];
-#else
-                    {
-                        gc_heap* hp = pGenGCHeap;
-#endif
-                        dd_new_allocation (hp->dynamic_data_of (soh_gen0)) -= soh_withheld_budget;
-                        dd_new_allocation (hp->dynamic_data_of (loh_generation)) -= loh_withheld_budget;
-                    }
-                    current_no_gc_region_info.soh_withheld_budget = soh_withheld_budget;
-                    current_no_gc_region_info.loh_withheld_budget = loh_withheld_budget;
-                    current_no_gc_region_info.callback = callback;
-                }
-            }
-            else
-            {
-                status = enable_no_gc_region_callback_status::insufficient_budget;
-            }
-        }
-    }
-    restart_EE();
-    return status;
-}
-#ifdef BACKGROUND_GC
-BOOL gc_heap::bgc_mark_array_range (heap_segment* seg,
-                                    BOOL whole_seg_p,
-                                    uint8_t** range_beg,
-                                    uint8_t** range_end)
-{
-    uint8_t* seg_start = heap_segment_mem (seg);
-    uint8_t* seg_end = (whole_seg_p ? heap_segment_reserved (seg) : align_on_mark_word (heap_segment_allocated (seg)));
-    if ((seg_start < background_saved_highest_address) &&
-        (seg_end > background_saved_lowest_address))
-    {
-        *range_beg = max (seg_start, background_saved_lowest_address);
-        *range_end = min (seg_end, background_saved_highest_address);
-        return TRUE;
-    }
-    else
-    {
-        return FALSE;
-    }
-}
-void gc_heap::bgc_verify_mark_array_cleared (heap_segment* seg, bool always_verify_p)
-{
-#ifdef _DEBUG
-    if (gc_heap::background_running_p() || always_verify_p)
-    {
-        uint8_t* range_beg = 0;
-        uint8_t* range_end = 0;
-        if (bgc_mark_array_range (seg, TRUE, &range_beg, &range_end) || always_verify_p)
-        {
-            if (always_verify_p)
-            {
-                range_beg = heap_segment_mem (seg);
-                range_end = heap_segment_reserved (seg);
-            }
-            size_t  markw = mark_word_of (range_beg);
-            size_t  markw_end = mark_word_of (range_end);
-            while (markw < markw_end)
-            {
-                if (mark_array [markw])
-                {
-                    dprintf (1, ("The mark bits at 0x%zx:0x%u(addr: 0x%p) were not cleared",
-                                    markw, mark_array [markw], mark_word_address (markw)));
-                    FATAL_GC_ERROR();
-                }
-                markw++;
-            }
-            uint8_t* p = mark_word_address (markw_end);
-            while (p < range_end)
-            {
-                assert (!(mark_array_marked (p)));
-                p++;
-            }
-        }
-    }
-#endif //_DEBUG
-}
-void gc_heap::verify_mark_bits_cleared (uint8_t* obj, size_t s)
-{
-#ifdef VERIFY_HEAP
-    size_t start_mark_bit = mark_bit_of (obj) + 1;
-    size_t end_mark_bit = mark_bit_of (obj + s);
-    unsigned int startbit = mark_bit_bit (start_mark_bit);
-    unsigned int endbit = mark_bit_bit (end_mark_bit);
-    size_t startwrd = mark_bit_word (start_mark_bit);
-    size_t endwrd = mark_bit_word (end_mark_bit);
-    unsigned int result = 0;
-    unsigned int firstwrd = ~(lowbits (~0, startbit));
-    unsigned int lastwrd = ~(highbits (~0, endbit));
-    if (startwrd == endwrd)
-    {
-        unsigned int wrd = firstwrd & lastwrd;
-        result = mark_array[startwrd] & wrd;
-        if (result)
-        {
-            FATAL_GC_ERROR();
-        }
-        return;
-    }
-    if (startbit)
-    {
-        result = mark_array[startwrd] & firstwrd;
-        if (result)
-        {
-            FATAL_GC_ERROR();
-        }
-        startwrd++;
-    }
-    for (size_t wrdtmp = startwrd; wrdtmp < endwrd; wrdtmp++)
-    {
-        result = mark_array[wrdtmp];
-        if (result)
-        {
-            FATAL_GC_ERROR();
-        }
-    }
-    if (endbit)
-    {
-        result = mark_array[endwrd] & lastwrd;
-        if (result)
-        {
-            FATAL_GC_ERROR();
-        }
-    }
-#endif //VERIFY_HEAP
-}
-void gc_heap::verify_mark_array_cleared()
-{
-#ifdef VERIFY_HEAP
-    if (gc_heap::background_running_p() &&
-        (GCConfig::GetHeapVerifyLevel() & GCConfig::HEAPVERIFY_GC))
-    {
-        for (int i = get_start_generation_index(); i < total_generation_count; i++)
-        {
-            generation* gen = generation_of (i);
-            heap_segment* seg = heap_segment_rw (generation_start_segment (gen));
-            while (seg)
-            {
-                bgc_verify_mark_array_cleared (seg);
-                seg = heap_segment_next_rw (seg);
-            }
-        }
-    }
-#endif //VERIFY_HEAP
-}
-#endif //BACKGROUND_GC
-void gc_heap::verify_soh_segment_list()
-{
-#ifdef VERIFY_HEAP
-    if (GCConfig::GetHeapVerifyLevel() & GCConfig::HEAPVERIFY_GC)
-    {
-        for (int i = get_start_generation_index(); i <= max_generation; i++)
-        {
-            generation* gen = generation_of (i);
-            heap_segment* seg = heap_segment_rw (generation_start_segment (gen));
-            heap_segment* last_seg = 0;
-            while (seg)
-            {
-                last_seg = seg;
-                seg = heap_segment_next_rw (seg);
-            }
-#ifdef USE_REGIONS
-            if (last_seg != generation_tail_region (gen))
-#else
-            if (last_seg != ephemeral_heap_segment)
-#endif //USE_REGIONS
-            {
-                FATAL_GC_ERROR();
-            }
-        }
-    }
-#endif //VERIFY_HEAP
-}
-#ifdef BACKGROUND_GC
-void gc_heap::verify_partial()
-{
-    BOOL mark_missed_p = FALSE;
-    BOOL bad_ref_p = FALSE;
-    BOOL free_ref_p = FALSE;
-    for (int i = get_start_generation_index(); i < total_generation_count; i++)
-    {
-        generation* gen = generation_of (i);
-        int align_const = get_alignment_constant (i == max_generation);
-        heap_segment* seg = heap_segment_rw (generation_start_segment (gen));
-        while (seg)
-        {
-            uint8_t* o = heap_segment_mem (seg);
-            uint8_t* end = heap_segment_allocated (seg);
-            while (o < end)
-            {
-                size_t s = size (o);
-                BOOL marked_p = background_object_marked (o, FALSE);
-                if (marked_p)
-                {
-                    go_through_object_cl (method_table (o), o, s, oo,
-                        {
-                            if (*oo)
-                            {
-                                MethodTable *pMT = method_table (*oo);
-                                if (pMT == g_gc_pFreeObjectMethodTable)
-                                {
-                                    free_ref_p = TRUE;
-                                    FATAL_GC_ERROR();
-                                }
-                                if (!pMT->SanityCheck())
-                                {
-                                    bad_ref_p = TRUE;
-                                    dprintf (1, ("Bad member of %zx %zx",
-                                                (size_t)oo, (size_t)*oo));
-                                    FATAL_GC_ERROR();
-                                }
-                                if (current_bgc_state == bgc_final_marking)
-                                {
-                                    if (marked_p && !background_object_marked (*oo, FALSE))
-                                    {
-                                        mark_missed_p = TRUE;
-                                        FATAL_GC_ERROR();
-                                    }
-                                }
-                            }
-                        }
-                    );
-                }
-                o = o + Align(s, align_const);
-            }
-            seg = heap_segment_next_rw (seg);
-        }
-    }
-}
-#endif //BACKGROUND_GC
-#ifdef VERIFY_HEAP
-void
-gc_heap::verify_free_lists ()
-{
-    for (int gen_num = 0; gen_num < total_generation_count; gen_num++)
-    {
-        dprintf (3, ("Verifying free list for gen:%d", gen_num));
-        allocator* gen_alloc = generation_allocator (generation_of (gen_num));
-        size_t sz = gen_alloc->first_bucket_size();
-        bool verify_undo_slot = (gen_num != 0) && (gen_num <= max_generation) && !gen_alloc->discard_if_no_fit_p();
-        for (unsigned int a_l_number = 0; a_l_number < gen_alloc->number_of_buckets(); a_l_number++)
-        {
-            uint8_t* free_list = gen_alloc->alloc_list_head_of (a_l_number);
-            uint8_t* prev = 0;
-            while (free_list)
-            {
-                if (!((CObjectHeader*)free_list)->IsFree())
-                {
-                    dprintf (1, ("Verifiying Heap: curr free list item %zx isn't a free object",
-                                 (size_t)free_list));
-                    FATAL_GC_ERROR();
-                }
-                if (((a_l_number < (gen_alloc->number_of_buckets()-1))&& (unused_array_size (free_list) >= sz))
-                    || ((a_l_number != 0) && (unused_array_size (free_list) < sz/2)))
-                {
-                    dprintf (1, ("Verifiying Heap: curr free list item %zx isn't in the right bucket",
-                                 (size_t)free_list));
-                    FATAL_GC_ERROR();
-                }
-                if (verify_undo_slot && (free_list_undo (free_list) != UNDO_EMPTY))
-                {
-                    dprintf (1, ("Verifiying Heap: curr free list item %zx has non empty undo slot",
-                                 (size_t)free_list));
-                    FATAL_GC_ERROR();
-                }
-                if ((gen_num <= max_generation) && (object_gennum (free_list)!= gen_num))
-                {
-                    dprintf (1, ("Verifiying Heap: curr free list item %zx is in the wrong generation free list",
-                                 (size_t)free_list));
-                    FATAL_GC_ERROR();
-                }
-#ifdef DOUBLY_LINKED_FL
-                uint8_t* prev_free_item = free_list_prev (free_list);
-                if (gen_num == max_generation)
-                {
-                    if (prev_free_item != prev)
-                    {
-                        dprintf (1, ("%p prev should be: %p, actual: %p", free_list, prev_free_item, prev));
-                        FATAL_GC_ERROR();
-                    }
-                }
-#endif //DOUBLY_LINKED_FL
-#if defined(USE_REGIONS) && defined(MULTIPLE_HEAPS)
-                heap_segment* region = region_of (free_list);
-                if (region->heap != this)
-                {
-                    dprintf (1, ("curr free item %p should be on heap %d, but actually is on heap %d: %d", free_list, this->heap_number, region->heap->heap_number));
-                    FATAL_GC_ERROR();
-                }
-#endif //USE_REGIONS && MULTIPLE_HEAPS
-                prev = free_list;
-                free_list = free_list_slot (free_list);
-            }
-            uint8_t* tail = gen_alloc->alloc_list_tail_of (a_l_number);
-            if (!((tail == 0) || (tail == prev)))
-            {
-                dprintf (1, ("Verifying Heap: tail of free list is not correct, tail %p, prev %p", tail, prev));
-                FATAL_GC_ERROR();
-            }
-            if (tail == 0)
-            {
-                uint8_t* head = gen_alloc->alloc_list_head_of (a_l_number);
-                if ((head != 0) && (free_list_slot (head) != 0))
-                {
-                    dprintf (1, ("Verifying Heap: head of free list is not correct, head %p -> %p",
-                        head, free_list_slot (head)));
-                    FATAL_GC_ERROR();
-                }
-            }
-            sz *=2;
-        }
-    }
-}
-void gc_heap::verify_committed_bytes_per_heap()
-{
-    size_t committed_bookkeeping = 0; // unused
-    for (int oh = soh; oh < total_oh_count; oh++)
-    {
-#ifdef MULTIPLE_HEAPS
-        assert (committed_by_oh_per_heap[oh] == compute_committed_bytes_per_heap (oh, committed_bookkeeping));
-#else
-        assert (committed_by_oh[oh] == compute_committed_bytes_per_heap (oh, committed_bookkeeping));
-#endif //MULTIPLE_HEAPS
-    }
-}
-void gc_heap::verify_committed_bytes()
-{
-#ifndef USE_REGIONS
-    return;
-#endif //!USE_REGIONS
-    size_t total_committed = 0;
-    size_t committed_decommit; // unused
-    size_t committed_free; // unused
-    size_t committed_bookkeeping = 0;
-    size_t new_current_total_committed;
-    size_t new_current_total_committed_bookkeeping;
-    size_t new_committed_by_oh[recorded_committed_bucket_counts];
-    compute_committed_bytes(total_committed, committed_decommit, committed_free,
-                            committed_bookkeeping, new_current_total_committed, new_current_total_committed_bookkeeping,
-                            new_committed_by_oh);
-#ifdef MULTIPLE_HEAPS
-    for (int h = 0; h < n_heaps; h++)
-    {
-        for (int oh = soh; oh < total_oh_count; oh++)
-        {
-            assert (g_heaps[h]->committed_by_oh_per_heap[oh] == g_heaps[h]->committed_by_oh_per_heap_refresh[oh]);
-        }
-    }
-    for (int i = 0; i < recorded_committed_bucket_counts; i++)
-    {
-        assert (new_committed_by_oh[i] == committed_by_oh[i]);
-    }
-#endif //MULTIPLE_HEAPS
-    assert (new_current_total_committed_bookkeeping == current_total_committed_bookkeeping);
-    assert (new_current_total_committed == current_total_committed);
-}
-#ifdef USE_REGIONS
-void gc_heap::verify_regions (int gen_number, bool can_verify_gen_num, bool can_verify_tail)
-{
-#ifdef _DEBUG
-    generation* gen = generation_of (gen_number);
-    int num_regions_in_gen = 0;
-    heap_segment* seg_in_gen = heap_segment_rw (generation_start_segment (gen));
-    heap_segment* prev_region_in_gen = 0;
-    heap_segment* tail_region = generation_tail_region (gen);
-    while (seg_in_gen)
-    {
-        if (can_verify_gen_num)
-        {
-            if (heap_segment_gen_num (seg_in_gen) != min (gen_number, (int)max_generation))
-            {
-                dprintf (REGIONS_LOG, ("h%d gen%d region %p(%p) gen is %d!",
-                    heap_number, gen_number, seg_in_gen, heap_segment_mem (seg_in_gen),
-                    heap_segment_gen_num (seg_in_gen)));
-                FATAL_GC_ERROR();
-            }
-            if (heap_segment_gen_num (seg_in_gen) != heap_segment_plan_gen_num (seg_in_gen))
-            {
-                dprintf (REGIONS_LOG, ("h%d gen%d region %p(%p) gen is %d but plan gen is %d!!",
-                    heap_number, gen_number, seg_in_gen, heap_segment_mem (seg_in_gen),
-                    heap_segment_gen_num (seg_in_gen), heap_segment_plan_gen_num (seg_in_gen)));
-                FATAL_GC_ERROR();
-            }
-        }
-        if (heap_segment_allocated (seg_in_gen) > heap_segment_reserved (seg_in_gen))
-        {
-            dprintf (REGIONS_LOG, ("h%d gen%d region %p alloc %p > reserved %p!!",
-                heap_number, gen_number, heap_segment_mem (seg_in_gen),
-                heap_segment_allocated (seg_in_gen), heap_segment_reserved (seg_in_gen)));
-            FATAL_GC_ERROR();
-        }
-        prev_region_in_gen = seg_in_gen;
-        num_regions_in_gen++;
-        heap_segment* next_region = heap_segment_next (seg_in_gen);
-        if (seg_in_gen == next_region)
-        {
-            dprintf (REGIONS_LOG, ("h%d gen%d region %p(%p) pointing to itself!!",
-                heap_number, gen_number, seg_in_gen, heap_segment_mem (seg_in_gen)));
-            FATAL_GC_ERROR();
-        }
-        seg_in_gen = next_region;
-    }
-    if (num_regions_in_gen == 0)
-    {
-        dprintf (REGIONS_LOG, ("h%d gen%d has no regions!!", heap_number, gen_number));
-        FATAL_GC_ERROR();
-    }
-    if (can_verify_tail && (tail_region != prev_region_in_gen))
-    {
-        dprintf (REGIONS_LOG, ("h%d gen%d tail region is %p(%p), diff from last region %p(%p)!!",
-            heap_number, gen_number,
-            tail_region, heap_segment_mem (tail_region),
-            prev_region_in_gen, heap_segment_mem (prev_region_in_gen)));
-        FATAL_GC_ERROR();
-    }
-#endif // _DEBUG
-}
-inline bool is_user_alloc_gen (int gen_number)
-{
-    return ((gen_number == soh_gen0) || (gen_number == loh_generation) || (gen_number == poh_generation));
-}
-void gc_heap::verify_regions (bool can_verify_gen_num, bool concurrent_p)
-{
-#ifdef _DEBUG
-    for (int i = 0; i < total_generation_count; i++)
-    {
-        bool can_verify_tail = (concurrent_p ? !is_user_alloc_gen (i) : true);
-        verify_regions (i, can_verify_gen_num, can_verify_tail);
-        if (can_verify_gen_num &&
-            can_verify_tail &&
-            (i >= max_generation))
-        {
-            verify_committed_bytes_per_heap ();
-        }
-    }
-#endif // _DEBUG
-}
-#endif // USE_REGIONS
-BOOL gc_heap::check_need_card (uint8_t* child_obj, int gen_num_for_cards,
-                               uint8_t* low, uint8_t* high)
-{
-#ifdef USE_REGIONS
-    return (is_in_heap_range (child_obj) && (get_region_gen_num (child_obj) < gen_num_for_cards));
-#else
-    return ((child_obj < high) && (child_obj >= low));
-#endif //USE_REGIONS
-}
-void gc_heap::enter_gc_lock_for_verify_heap()
-{
-#ifdef VERIFY_HEAP
-    if (GCConfig::GetHeapVerifyLevel() & GCConfig::HEAPVERIFY_GC)
-    {
-        enter_spin_lock (&gc_heap::gc_lock);
-        dprintf (SPINLOCK_LOG, ("enter gc_lock for verify_heap"));
-    }
-#endif // VERIFY_HEAP
-}
-void gc_heap::leave_gc_lock_for_verify_heap()
-{
-#ifdef VERIFY_HEAP
-    if (GCConfig::GetHeapVerifyLevel() & GCConfig::HEAPVERIFY_GC)
-    {
-        dprintf (SPINLOCK_LOG, ("leave gc_lock taken for verify_heap"));
-        leave_spin_lock (&gc_heap::gc_lock);
-    }
-#endif // VERIFY_HEAP
-}
-void gc_heap::verify_heap (BOOL begin_gc_p)
-{
-    int heap_verify_level = static_cast<int>(GCConfig::GetHeapVerifyLevel());
-#ifdef MULTIPLE_HEAPS
-    t_join* current_join = &gc_t_join;
-#ifdef BACKGROUND_GC
-    if (settings.concurrent && (bgc_thread_id.IsCurrentThread()))
-    {
-        current_join = &bgc_t_join;
-    }
-#endif //BACKGROUND_GC
-#endif //MULTIPLE_HEAPS
-#ifndef TRACE_GC
-    UNREFERENCED_PARAMETER(begin_gc_p);
-#endif //!TRACE_GC
-#ifdef BACKGROUND_GC
-    dprintf (2,("[%s]GC#%zu(%s): Verifying heap - begin",
-        (begin_gc_p ? "BEG" : "END"),
-        VolatileLoad(&settings.gc_index),
-        (settings.concurrent ? "BGC" : (gc_heap::background_running_p() ? "FGC" : "NGC"))));
-#else
-    dprintf (2,("[%s]GC#%zu: Verifying heap - begin",
-                (begin_gc_p ? "BEG" : "END"), VolatileLoad(&settings.gc_index)));
-#endif //BACKGROUND_GC
-#ifndef MULTIPLE_HEAPS
-#ifndef USE_REGIONS
-    if ((ephemeral_low != generation_allocation_start (generation_of (max_generation - 1))) ||
-        (ephemeral_high != heap_segment_reserved (ephemeral_heap_segment)))
-    {
-        FATAL_GC_ERROR();
-    }
-#endif //!USE_REGIONS
-#endif //MULTIPLE_HEAPS
-#ifdef BACKGROUND_GC
-    if (!settings.concurrent)
-#endif //BACKGROUND_GC
-    {
-        if (!(heap_verify_level & GCConfig::HEAPVERIFY_NO_MEM_FILL))
-        {
-            for (int i = get_start_generation_index(); i < total_generation_count; i++)
-            {
-                generation* gen1 = generation_of (i);
-                heap_segment* seg1 = heap_segment_rw (generation_start_segment (gen1));
-                while (seg1)
-                {
-                    uint8_t* clear_start = heap_segment_allocated (seg1) - plug_skew;
-                    if (heap_segment_used (seg1) > clear_start)
-                    {
-                        dprintf (3, ("setting end of seg %p: [%p-[%p to 0xaa",
-                            heap_segment_mem (seg1),
-                            clear_start ,
-                            heap_segment_used (seg1)));
-                        memset (heap_segment_allocated (seg1) - plug_skew, 0xaa,
-                            (heap_segment_used (seg1) - clear_start));
-                    }
-                    seg1 = heap_segment_next_rw (seg1);
-                }
-            }
-        }
-    }
-#ifndef USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-    current_join->join(this, gc_join_verify_copy_table);
-    if (current_join->joined())
-#endif //MULTIPLE_HEAPS
-    {
-        copy_brick_card_table_on_growth ();
-#ifdef MULTIPLE_HEAPS
-        current_join->restart();
-#endif //MULTIPLE_HEAPS
-    }
-#endif //!USE_REGIONS
-    {
-#ifdef _DEBUG
-#ifdef USE_REGIONS
-        verify_regions (true, settings.concurrent);
-#else //USE_REGIONS
-        generation* gen = generation_of (max_generation);
-        assert (generation_allocation_start (gen) ==
-                heap_segment_mem (heap_segment_rw (generation_start_segment (gen))));
-        int gen_num = max_generation-1;
-        generation* prev_gen = gen;
-        while (gen_num >= 0)
-        {
-            gen = generation_of (gen_num);
-            assert (generation_allocation_segment (gen) == ephemeral_heap_segment);
-            assert (generation_allocation_start (gen) >= heap_segment_mem (ephemeral_heap_segment));
-            assert (generation_allocation_start (gen) < heap_segment_allocated (ephemeral_heap_segment));
-            if (generation_start_segment (prev_gen ) ==
-                generation_start_segment (gen))
-            {
-                assert (generation_allocation_start (prev_gen) <
-                        generation_allocation_start (gen));
-            }
-            prev_gen = gen;
-            gen_num--;
-        }
-#endif //USE_REGIONS
-#endif //_DEBUG
-    }
-    size_t          total_objects_verified = 0;
-    size_t          total_objects_verified_deep = 0;
-    BOOL            bCurrentBrickInvalid = FALSE;
-    size_t          last_valid_brick = 0;
-    size_t          curr_brick = 0;
-    size_t          prev_brick = (size_t)-1;
-    int             gen_num_for_cards = 0;
-#ifdef USE_REGIONS
-    int             gen_num_to_stop = 0;
-    uint8_t*        e_high = 0;
-    uint8_t*        next_boundary = 0;
-#else //USE_REGIONS
-    int gen_num_to_stop = max_generation;
-    uint8_t*        e_high = ephemeral_high;
-    uint8_t*        next_boundary = generation_allocation_start (generation_of (max_generation - 1));
-    uint8_t*        begin_youngest = generation_allocation_start(generation_of(0));
-#endif //!USE_REGIONS
-    for (int curr_gen_num = total_generation_count - 1; curr_gen_num >= gen_num_to_stop; curr_gen_num--)
-    {
-        int             align_const = get_alignment_constant (curr_gen_num == max_generation);
-        BOOL            large_brick_p = (curr_gen_num > max_generation);
-#ifdef USE_REGIONS
-        gen_num_for_cards = ((curr_gen_num >= max_generation) ? max_generation : curr_gen_num);
-#endif //USE_REGIONS
-        heap_segment*   seg = heap_segment_in_range (generation_start_segment (generation_of (curr_gen_num) ));
-        while (seg)
-        {
-            uint8_t*        curr_object = heap_segment_mem (seg);
-            uint8_t*        prev_object = 0;
-            bool verify_bricks_p = true;
-#ifdef USE_REGIONS
-            if (heap_segment_read_only_p(seg))
-            {
-                dprintf(1, ("seg %zx is ro! Shouldn't happen with regions", (size_t)seg));
-                FATAL_GC_ERROR();
-            }
-            if (heap_segment_gen_num (seg) != heap_segment_plan_gen_num (seg))
-            {
-                dprintf (1, ("Seg %p, gen num is %d, plan gen num is %d",
-                    heap_segment_mem (seg), heap_segment_gen_num (seg), heap_segment_plan_gen_num (seg)));
-                FATAL_GC_ERROR();
-            }
-#else //USE_REGIONS
-            if (heap_segment_read_only_p(seg))
-            {
-                size_t current_brick = brick_of(max(heap_segment_mem(seg), lowest_address));
-                size_t end_brick = brick_of(min(heap_segment_reserved(seg), highest_address) - 1);
-                while (current_brick <= end_brick)
-                {
-                    if (brick_table[current_brick] != 0)
-                    {
-                        dprintf(1, ("Verifying Heap: %zx brick of a frozen segment is not zeroed", current_brick));
-                        FATAL_GC_ERROR();
-                    }
-                    current_brick++;
-                }
-                verify_bricks_p = false;
-            }
-#endif //USE_REGIONS
-#ifdef BACKGROUND_GC
-            BOOL consider_bgc_mark_p    = FALSE;
-            BOOL check_current_sweep_p  = FALSE;
-            BOOL check_saved_sweep_p    = FALSE;
-            should_check_bgc_mark (seg, &consider_bgc_mark_p, &check_current_sweep_p, &check_saved_sweep_p);
-#endif //BACKGROUND_GC
-            while (curr_object < heap_segment_allocated (seg))
-            {
-                if (is_mark_set (curr_object))
-                {
-                    dprintf (1, ("curr_object: %zx is marked!",(size_t)curr_object));
-                    FATAL_GC_ERROR();
-                }
-                size_t s = size (curr_object);
-                dprintf (3, ("o: %zx, s: %zu", (size_t)curr_object, s));
-                if (s == 0)
-                {
-                    dprintf (1, ("Verifying Heap: size of current object %p == 0", curr_object));
-                    FATAL_GC_ERROR();
-                }
-#ifndef USE_REGIONS
-                if (seg == ephemeral_heap_segment)
-                {
-                    if ((curr_gen_num > 0) && (curr_object >= next_boundary))
-                    {
-                        curr_gen_num--;
-                        if (curr_gen_num > 0)
-                        {
-                            next_boundary = generation_allocation_start (generation_of (curr_gen_num - 1));
-                        }
-                    }
-                }
-#endif //!USE_REGIONS
-#ifdef USE_REGIONS
-                if (verify_bricks_p && curr_gen_num != 0)
-#else
-                if (verify_bricks_p && ((seg != ephemeral_heap_segment) ||
-                     (brick_of(curr_object) < brick_of(begin_youngest))))
-#endif //USE_REGIONS
-                {
-                    curr_brick = brick_of(curr_object);
-                    if (curr_brick != prev_brick)
-                    {
-                        if (bCurrentBrickInvalid &&
-                            (curr_brick != brick_of (heap_segment_mem (seg))) &&
-                            !heap_segment_read_only_p (seg))
-                        {
-                            dprintf (1, ("curr brick %zx invalid", curr_brick));
-                            FATAL_GC_ERROR();
-                        }
-                        if (large_brick_p)
-                        {
-                            if ((heap_segment_reserved (seg) <= highest_address) &&
-                                (heap_segment_mem (seg) >= lowest_address) &&
-                                brick_table [curr_brick] != 0)
-                            {
-                                dprintf (1, ("curr_brick %zx for large object %zx is set to %zx",
-                                    curr_brick, (size_t)curr_object, (size_t)brick_table[curr_brick]));
-                                FATAL_GC_ERROR();
-                            }
-                            else
-                            {
-                                bCurrentBrickInvalid = FALSE;
-                            }
-                        }
-                        else
-                        {
-                            if (brick_table [curr_brick] <= 0)
-                            {
-                                if (brick_table [curr_brick] == 0)
-                                {
-                                    dprintf(1, ("curr_brick %zx for object %zx set to 0",
-                                            curr_brick, (size_t)curr_object));
-                                    FATAL_GC_ERROR();
-                                }
-                                ptrdiff_t i = curr_brick;
-                                while ((i >= ((ptrdiff_t) brick_of (heap_segment_mem (seg)))) &&
-                                       (brick_table[i] < 0))
-                                {
-                                    i = i + brick_table[i];
-                                }
-                                if (i <  ((ptrdiff_t)(brick_of (heap_segment_mem (seg))) - 1))
-                                {
-                                    dprintf (1, ("ptrdiff i: %zx < brick_of (heap_segment_mem (seg)):%zx - 1. curr_brick: %zx",
-                                            i, brick_of (heap_segment_mem (seg)),
-                                            curr_brick));
-                                    FATAL_GC_ERROR();
-                                }
-                                bCurrentBrickInvalid = FALSE;
-                            }
-                            else if (!heap_segment_read_only_p (seg))
-                            {
-                                bCurrentBrickInvalid = TRUE;
-                            }
-                        }
-                    }
-                    if (bCurrentBrickInvalid)
-                    {
-                        if (curr_object == (brick_address(curr_brick) + brick_table[curr_brick] - 1))
-                        {
-                            bCurrentBrickInvalid = FALSE;
-                            last_valid_brick = curr_brick;
-                        }
-                    }
-                }
-                if (*((uint8_t**)curr_object) != (uint8_t *) g_gc_pFreeObjectMethodTable)
-                {
-#ifdef FEATURE_LOH_COMPACTION
-                    if ((curr_gen_num == loh_generation) && (prev_object != 0))
-                    {
-                        assert (method_table (prev_object) == g_gc_pFreeObjectMethodTable);
-                    }
-#endif //FEATURE_LOH_COMPACTION
-                    total_objects_verified++;
-                    BOOL can_verify_deep = TRUE;
-#ifdef BACKGROUND_GC
-                    can_verify_deep = fgc_should_consider_object (curr_object, seg, consider_bgc_mark_p, check_current_sweep_p, check_saved_sweep_p);
-#endif //BACKGROUND_GC
-                    BOOL deep_verify_obj = can_verify_deep;
-                    if ((heap_verify_level & GCConfig::HEAPVERIFY_DEEP_ON_COMPACT) && !settings.compaction)
-                        deep_verify_obj = FALSE;
-                    ((CObjectHeader*)curr_object)->ValidateHeap(deep_verify_obj);
-                    if (can_verify_deep)
-                    {
-                        if (curr_gen_num > 0)
-                        {
-                            BOOL need_card_p = FALSE;
-                            if (contain_pointers_or_collectible (curr_object))
-                            {
-                                dprintf (4, ("curr_object: %zx", (size_t)curr_object));
-                                size_t crd = card_of (curr_object);
-                                BOOL found_card_p = card_set_p (crd);
-#ifdef COLLECTIBLE_CLASS
-                                if (is_collectible(curr_object))
-                                {
-                                    uint8_t* class_obj = get_class_object (curr_object);
-                                    if (check_need_card (class_obj, gen_num_for_cards, next_boundary, e_high))
-                                    {
-                                        if (!found_card_p)
-                                        {
-                                            dprintf (1, ("Card not set, curr_object = [%zx:%zx pointing to class object %p",
-                                                        card_of (curr_object), (size_t)curr_object, class_obj));
-                                            FATAL_GC_ERROR();
-                                        }
-                                    }
-                                }
-#endif //COLLECTIBLE_CLASS
-                                if (contain_pointers(curr_object))
-                                {
-                                    go_through_object_nostart
-                                        (method_table(curr_object), curr_object, s, oo,
-                                        {
-                                            if (crd != card_of ((uint8_t*)oo))
-                                            {
-                                                crd = card_of ((uint8_t*)oo);
-                                                found_card_p = card_set_p (crd);
-                                                need_card_p = FALSE;
-                                            }
-                                            if (*oo && check_need_card (*oo, gen_num_for_cards, next_boundary, e_high))
-                                            {
-                                                need_card_p = TRUE;
-                                            }
-                                            if (need_card_p && !found_card_p)
-                                            {
-                                                dprintf (1, ("(in loop) Card not set, curr_object = [%zx:%zx, %zx:%zx[",
-                                                            card_of (curr_object), (size_t)curr_object,
-                                                            card_of (curr_object+Align(s, align_const)),
-                                                            (size_t)(curr_object+Align(s, align_const))));
-                                                FATAL_GC_ERROR();
-                                            }
-                                        }
-                                            );
-                                }
-                                if (need_card_p && !found_card_p)
-                                {
-                                    dprintf (1, ("Card not set, curr_object = [%zx:%zx, %zx:%zx[",
-                                        card_of (curr_object), (size_t)curr_object,
-                                        card_of (curr_object + Align(s, align_const)),
-                                        (size_t)(curr_object + Align(s, align_const))));
-                                    FATAL_GC_ERROR();
-                                }
-                            }
-                        }
-                        total_objects_verified_deep++;
-                    }
-                }
-                prev_object = curr_object;
-                prev_brick = curr_brick;
-                curr_object = curr_object + Align(s, align_const);
-                if (curr_object < prev_object)
-                {
-                    dprintf (1, ("overflow because of a bad object size: %p size %zx", prev_object, s));
-                    FATAL_GC_ERROR();
-                }
-            }
-            if (curr_object > heap_segment_allocated(seg))
-            {
-                dprintf (1, ("Verifiying Heap: curr_object: %zx > heap_segment_allocated (seg: %zx) %p",
-                        (size_t)curr_object, (size_t)seg, heap_segment_allocated (seg)));
-                FATAL_GC_ERROR();
-            }
-            seg = heap_segment_next_in_range (seg);
-        }
-    }
-#ifdef BACKGROUND_GC
-    dprintf (2, ("(%s)(%s)(%s) total_objects_verified is %zd, total_objects_verified_deep is %zd",
-                 (settings.concurrent ? "BGC" : (gc_heap::background_running_p () ? "FGC" : "NGC")),
-                 (begin_gc_p ? "BEG" : "END"),
-                 ((current_c_gc_state == c_gc_state_planning) ? "in plan" : "not in plan"),
-                 total_objects_verified, total_objects_verified_deep));
-    if (current_c_gc_state != c_gc_state_planning)
-    {
-        assert (total_objects_verified == total_objects_verified_deep);
-    }
-#endif //BACKGROUND_GC
-    verify_free_lists();
-#ifdef FEATURE_PREMORTEM_FINALIZATION
-    finalize_queue->CheckFinalizerObjects();
-#endif // FEATURE_PREMORTEM_FINALIZATION
-    {
-        ScanContext sc;
-        sc.thread_number = heap_number;
-        sc.thread_count = n_heaps;
-        GCScan::VerifyHandleTable(max_generation, max_generation, &sc);
-    }
-#ifdef MULTIPLE_HEAPS
-    current_join->join(this, gc_join_verify_objects_done);
-    if (current_join->joined())
-#endif //MULTIPLE_HEAPS
-    {
-        GCToEEInterface::VerifySyncTableEntry();
-#ifdef MULTIPLE_HEAPS
-#ifdef USE_REGIONS
-        for (int hn = n_heaps; hn < n_max_heaps; hn++)
-        {
-            gc_heap* hp = g_heaps[hn];
-            hp->check_decommissioned_heap();
-        }
-#endif //USE_REGIONS
-        current_join->restart();
-#endif //MULTIPLE_HEAPS
-    }
-#ifdef BACKGROUND_GC
-    if (settings.concurrent)
-    {
-        verify_mark_array_cleared();
-    }
-    dprintf (2,("GC%zu(%s): Verifying heap - end",
-        VolatileLoad(&settings.gc_index),
-        (settings.concurrent ? "BGC" : (gc_heap::background_running_p() ? "FGC" : "NGC"))));
-#else
-    dprintf (2,("GC#d: Verifying heap - end", VolatileLoad(&settings.gc_index)));
-#endif //BACKGROUND_GC
-}
-#endif  //VERIFY_HEAP
-void GCHeap::ValidateObjectMember (Object* obj)
-{
-#ifdef VERIFY_HEAP
-    size_t s = size (obj);
-    uint8_t* o = (uint8_t*)obj;
-    go_through_object_cl (method_table (obj), o, s, oo,
-        {
-            uint8_t* child_o = *oo;
-            if (child_o)
-            {
-                MethodTable *pMT = method_table (child_o);
-                assert(pMT);
-                if (!pMT->SanityCheck()) {
-                    dprintf (1, ("Bad member of %zx %zx",
-                                (size_t)oo, (size_t)child_o));
-                    FATAL_GC_ERROR();
-                }
-            }
-        } );
-#endif // VERIFY_HEAP
-}
-HRESULT GCHeap::StaticShutdown()
-{
-    deleteGCShadow();
-    GCScan::GcRuntimeStructuresValid (FALSE);
-    uint32_t* ct = &g_gc_card_table[card_word (gcard_of (g_gc_lowest_address))];
-    if (card_table_refcount (ct) == 0)
-    {
-        destroy_card_table (ct);
-        g_gc_card_table = nullptr;
-#ifdef FEATURE_MANUALLY_MANAGED_CARD_BUNDLES
-        g_gc_card_bundle_table = nullptr;
-#endif
-#ifdef FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-        SoftwareWriteWatch::StaticClose();
-#endif // FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-    }
-#ifndef USE_REGIONS
-    while(gc_heap::segment_standby_list != 0)
-    {
-        heap_segment* next_seg = heap_segment_next (gc_heap::segment_standby_list);
-#ifdef MULTIPLE_HEAPS
-        (gc_heap::g_heaps[0])->delete_heap_segment (gc_heap::segment_standby_list, FALSE);
-#else //MULTIPLE_HEAPS
-        pGenGCHeap->delete_heap_segment (gc_heap::segment_standby_list, FALSE);
-#endif //MULTIPLE_HEAPS
-        gc_heap::segment_standby_list = next_seg;
-    }
-#endif // USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < gc_heap::n_heaps; i ++)
-    {
-        gc_heap::destroy_gc_heap (gc_heap::g_heaps[i]);
-    }
-#else
-    gc_heap::destroy_gc_heap (pGenGCHeap);
-#endif //MULTIPLE_HEAPS
-    gc_heap::shutdown_gc();
-    return S_OK;
-}
-#ifdef FEATURE_PREMORTEM_FINALIZATION
-static
-HRESULT AllocateCFinalize(CFinalize **pCFinalize)
-{
-    *pCFinalize = new (nothrow) CFinalize();
-    if (*pCFinalize == NULL || !(*pCFinalize)->Initialize())
-        return E_OUTOFMEMORY;
-    return S_OK;
-}
-#endif // FEATURE_PREMORTEM_FINALIZATION
-HRESULT GCHeap::Init(size_t hn)
-{
-    HRESULT hres = S_OK;
-#ifdef MULTIPLE_HEAPS
-    if ((pGenGCHeap = gc_heap::make_gc_heap(this, (int)hn)) == 0)
-        hres = E_OUTOFMEMORY;
-#else
-    UNREFERENCED_PARAMETER(hn);
-    if (!gc_heap::make_gc_heap())
-        hres = E_OUTOFMEMORY;
-#endif //MULTIPLE_HEAPS
-    return hres;
-}
-HRESULT GCHeap::Initialize()
-{
-#ifndef TRACE_GC
-    STRESS_LOG_VA (1, (ThreadStressLog::gcLoggingIsOffMsg()));
-#endif
-    HRESULT hr = S_OK;
-    qpf = (uint64_t)GCToOSInterface::QueryPerformanceFrequency();
-    qpf_ms = 1000.0 / (double)qpf;
-    qpf_us = 1000.0 * 1000.0 / (double)qpf;
-    g_gc_pFreeObjectMethodTable = GCToEEInterface::GetFreeObjectMethodTable();
-    g_num_processors = GCToOSInterface::GetTotalProcessorCount();
-    assert(g_num_processors != 0);
-    gc_heap::total_physical_mem = (size_t)GCConfig::GetGCTotalPhysicalMemory();
-    if (gc_heap::total_physical_mem != 0)
-    {
-        gc_heap::is_restricted_physical_mem = true;
-#ifdef FEATURE_EVENT_TRACE
-        gc_heap::physical_memory_from_config = (size_t)gc_heap::total_physical_mem;
-#endif //FEATURE_EVENT_TRACE
-    }
-    else
-    {
-        gc_heap::total_physical_mem = GCToOSInterface::GetPhysicalMemoryLimit (&gc_heap::is_restricted_physical_mem);
-    }
-    memset (gc_heap::committed_by_oh, 0, sizeof (gc_heap::committed_by_oh));
-    if (!gc_heap::compute_hard_limit())
-    {
-        return CLR_E_GC_BAD_HARD_LIMIT;
-    }
-    uint32_t nhp = 1;
-    uint32_t nhp_from_config = 0;
-    uint32_t max_nhp_from_config = (uint32_t)GCConfig::GetMaxHeapCount();
-#ifndef MULTIPLE_HEAPS
-    GCConfig::SetServerGC(false);
-#else //!MULTIPLE_HEAPS
-    GCConfig::SetServerGC(true);
-    AffinitySet config_affinity_set;
-    GCConfigStringHolder cpu_index_ranges_holder(GCConfig::GetGCHeapAffinitizeRanges());
-    uintptr_t config_affinity_mask = static_cast<uintptr_t>(GCConfig::GetGCHeapAffinitizeMask());
-    if (!ParseGCHeapAffinitizeRanges(cpu_index_ranges_holder.Get(), &config_affinity_set, config_affinity_mask))
-    {
-        return CLR_E_GC_BAD_AFFINITY_CONFIG_FORMAT;
-    }
-    const AffinitySet* process_affinity_set = GCToOSInterface::SetGCThreadsAffinitySet(config_affinity_mask, &config_affinity_set);
-    GCConfig::SetGCHeapAffinitizeMask(static_cast<int64_t>(config_affinity_mask));
-    if (process_affinity_set->IsEmpty())
-    {
-        return CLR_E_GC_BAD_AFFINITY_CONFIG;
-    }
-    if ((cpu_index_ranges_holder.Get() != nullptr)
-#ifdef TARGET_WINDOWS
-        || (config_affinity_mask != 0)
-#endif
-    )
-    {
-        affinity_config_specified_p = true;
-    }
-    nhp_from_config = static_cast<uint32_t>(GCConfig::GetHeapCount());
-    g_num_active_processors = min (GCToEEInterface::GetCurrentProcessCpuCount(), g_num_processors);
-    if (nhp_from_config)
-    {
-        nhp_from_config = min (nhp_from_config, g_num_active_processors);
-    }
-    nhp = ((nhp_from_config == 0) ? g_num_active_processors : nhp_from_config);
-    nhp = min (nhp, (uint32_t)MAX_SUPPORTED_CPUS);
-    gc_heap::gc_thread_no_affinitize_p = (gc_heap::heap_hard_limit ?
-        !affinity_config_specified_p : (GCConfig::GetNoAffinitize() != 0));
-    if (!(gc_heap::gc_thread_no_affinitize_p))
-    {
-        uint32_t num_affinitized_processors = (uint32_t)process_affinity_set->Count();
-        if (num_affinitized_processors != 0)
-        {
-            nhp = min(nhp, num_affinitized_processors);
-        }
-    }
-#endif //!MULTIPLE_HEAPS
-    if (gc_heap::heap_hard_limit)
-    {
-        gc_heap::hard_limit_config_p = true;
-    }
-    size_t seg_size_from_config = 0;
-    bool compute_memory_settings_succeed = gc_heap::compute_memory_settings(true, nhp, nhp_from_config, seg_size_from_config, 0);
-    assert (compute_memory_settings_succeed);
-    if ((!gc_heap::heap_hard_limit) && gc_heap::use_large_pages_p)
-    {
-        return CLR_E_GC_LARGE_PAGE_MISSING_HARD_LIMIT;
-    }
-    GCConfig::SetGCLargePages(gc_heap::use_large_pages_p);
-#ifdef USE_REGIONS
-    gc_heap::regions_range = (size_t)GCConfig::GetGCRegionRange();
-    if (gc_heap::regions_range == 0)
-    {
-        if (gc_heap::heap_hard_limit)
-        {
-            if (gc_heap::heap_hard_limit_oh[soh])
-            {
-                gc_heap::regions_range = gc_heap::heap_hard_limit;
-            }
-            else
-            {
-                gc_heap::regions_range = ((gc_heap::use_large_pages_p) ? (2 * gc_heap::heap_hard_limit)
-                                                                       : (5 * gc_heap::heap_hard_limit));
-            }
-        }
-        else
-        {
-            gc_heap::regions_range = max((size_t)256 * 1024 * 1024 * 1024, (size_t)(2 * gc_heap::total_physical_mem));
-        }
-        size_t virtual_mem_limit = GCToOSInterface::GetVirtualMemoryLimit();
-        gc_heap::regions_range = min(gc_heap::regions_range, virtual_mem_limit/2);
-        gc_heap::regions_range = align_on_page(gc_heap::regions_range);
-    }
-    GCConfig::SetGCRegionRange(gc_heap::regions_range);
-#endif //USE_REGIONS
-    size_t seg_size = 0;
-    size_t large_seg_size = 0;
-    size_t pin_seg_size = 0;
-    seg_size = gc_heap::soh_segment_size;
-#ifndef USE_REGIONS
-    if (gc_heap::heap_hard_limit)
-    {
-        if (gc_heap::heap_hard_limit_oh[soh])
-        {
-            large_seg_size = max (gc_heap::adjust_segment_size_hard_limit (gc_heap::heap_hard_limit_oh[loh], nhp), seg_size_from_config);
-            pin_seg_size = max (gc_heap::adjust_segment_size_hard_limit (gc_heap::heap_hard_limit_oh[poh], nhp), seg_size_from_config);
-        }
-        else
-        {
-            large_seg_size = gc_heap::use_large_pages_p ? gc_heap::soh_segment_size : gc_heap::soh_segment_size * 2;
-            pin_seg_size = large_seg_size;
-        }
-        if (gc_heap::use_large_pages_p)
-            gc_heap::min_segment_size = min_segment_size_hard_limit;
-    }
-    else
-    {
-        large_seg_size = get_valid_segment_size (TRUE);
-        pin_seg_size = large_seg_size;
-    }
-    assert (g_theGCHeap->IsValidSegmentSize (seg_size));
-    assert (g_theGCHeap->IsValidSegmentSize (large_seg_size));
-    assert (g_theGCHeap->IsValidSegmentSize (pin_seg_size));
-    dprintf (1, ("%d heaps, soh seg size: %zd mb, loh: %zd mb\n",
-        nhp,
-        (seg_size / (size_t)1024 / 1024),
-        (large_seg_size / 1024 / 1024)));
-    gc_heap::min_uoh_segment_size = min (large_seg_size, pin_seg_size);
-    if (gc_heap::min_segment_size == 0)
-    {
-        gc_heap::min_segment_size = min (seg_size, gc_heap::min_uoh_segment_size);
-    }
-#endif //!USE_REGIONS
-    GCConfig::SetHeapCount(static_cast<int64_t>(nhp));
-    loh_size_threshold = (size_t)GCConfig::GetLOHThreshold();
-    loh_size_threshold = max (loh_size_threshold, LARGE_OBJECT_SIZE);
-#ifdef USE_REGIONS
-    gc_heap::enable_special_regions_p = (bool)GCConfig::GetGCEnableSpecialRegions();
-    size_t gc_region_size = (size_t)GCConfig::GetGCRegionSize();
-    if (gc_region_size >= MAX_REGION_SIZE)
-    {
-        return CLR_E_GC_BAD_REGION_SIZE;
-    }
-    if (gc_region_size == 0)
-    {
-        size_t max_region_size = gc_heap::regions_range / 2 / nhp / min_regions_per_heap;
-        if (max_region_size >= (4 * 1024 * 1024))
-        {
-            gc_region_size = 4 * 1024 * 1024;
-        }
-        else if (max_region_size >= (2 * 1024 * 1024))
-        {
-            gc_region_size = 2 * 1024 * 1024;
-        }
-        else
-        {
-            gc_region_size = 1 * 1024 * 1024;
-        }
-    }
-    if (!power_of_two_p(gc_region_size) || ((gc_region_size * nhp * min_regions_per_heap) > gc_heap::regions_range))
-    {
-        return E_OUTOFMEMORY;
-    }
-    /*
-     * Allocation requests less than loh_size_threshold will be allocated on the small object heap.
-     *
-     * An object cannot span more than one region and regions in small object heap are of the same size - gc_region_size.
-     * However, the space available for actual allocations is reduced by the following implementation details -
-     *
-     * 1.) heap_segment_mem is set to the new pages + sizeof(aligned_plug_and_gap) in make_heap_segment.
-     * 2.) a_fit_segment_end_p set pad to Align(min_obj_size, align_const).
-     * 3.) a_size_fit_p requires the available space to be >= the allocated size + Align(min_obj_size, align_const)
-     *
-     * It is guaranteed that an allocation request with this amount or less will succeed unless
-     * we cannot commit memory for it.
-     */
-    int align_const = get_alignment_constant (TRUE);
-    size_t effective_max_small_object_size = gc_region_size - sizeof(aligned_plug_and_gap) - Align(min_obj_size, align_const) * 2;
-#ifdef FEATURE_STRUCTALIGN
-    /*
-     * The above assumed FEATURE_STRUCTALIGN is not turned on for platforms where USE_REGIONS is supported, otherwise it is possible
-     * that the allocation size is inflated by ComputeMaxStructAlignPad in GCHeap::Alloc and we have to compute an upper bound of that
-     * function.
-     *
-     * Note that ComputeMaxStructAlignPad is defined to be 0 if FEATURE_STRUCTALIGN is turned off.
-     */
-#error "FEATURE_STRUCTALIGN is not supported for USE_REGIONS"
-#endif //FEATURE_STRUCTALIGN
-    loh_size_threshold = min (loh_size_threshold, effective_max_small_object_size);
-    GCConfig::SetLOHThreshold(loh_size_threshold);
-    gc_heap::min_segment_size_shr = index_of_highest_set_bit (gc_region_size);
-#else
-    gc_heap::min_segment_size_shr = index_of_highest_set_bit (gc_heap::min_segment_size);
-#endif //USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-    assert (nhp <= g_num_processors);
-    if (max_nhp_from_config)
-    {
-        nhp = min (nhp, max_nhp_from_config);
-    }
-    gc_heap::n_max_heaps = nhp;
-    gc_heap::n_heaps = nhp;
-    hr = gc_heap::initialize_gc (seg_size, large_seg_size, pin_seg_size, nhp);
-#else
-    hr = gc_heap::initialize_gc (seg_size, large_seg_size, pin_seg_size);
-#endif //MULTIPLE_HEAPS
-    GCConfig::SetGCHeapHardLimit(static_cast<int64_t>(gc_heap::heap_hard_limit));
-    GCConfig::SetGCHeapHardLimitSOH(static_cast<int64_t>(gc_heap::heap_hard_limit_oh[soh]));
-    GCConfig::SetGCHeapHardLimitLOH(static_cast<int64_t>(gc_heap::heap_hard_limit_oh[loh]));
-    GCConfig::SetGCHeapHardLimitPOH(static_cast<int64_t>(gc_heap::heap_hard_limit_oh[poh]));
-    if (hr != S_OK)
-        return hr;
-    gc_heap::pm_stress_on = (GCConfig::GetGCProvModeStress() != 0);
-#if defined(HOST_64BIT)
-    gc_heap::youngest_gen_desired_th = gc_heap::mem_one_percent;
-#endif // HOST_64BIT
-    WaitForGCEvent = new (nothrow) GCEvent;
-    if (!WaitForGCEvent)
-    {
-        return E_OUTOFMEMORY;
-    }
-    if (!WaitForGCEvent->CreateManualEventNoThrow(TRUE))
-    {
-        GCToEEInterface::LogErrorToHost("Creation of WaitForGCEvent failed");
-        return E_FAIL;
-    }
-#ifndef FEATURE_NATIVEAOT // NativeAOT forces relocation a different way
-#if defined (STRESS_HEAP) && !defined (MULTIPLE_HEAPS)
-    if (GCStress<cfg_any>::IsEnabled())
-    {
-        for (int i = 0; i < GCHeap::NUM_HEAP_STRESS_OBJS; i++)
-        {
-            m_StressObjs[i] = CreateGlobalHandle(0);
-        }
-        m_CurStressObj = 0;
-    }
-#endif //STRESS_HEAP && !MULTIPLE_HEAPS
-#endif // FEATURE_NATIVEAOT
-    initGCShadow();         // If we are debugging write barriers, initialize heap shadow
-#ifdef USE_REGIONS
-    gc_heap::ephemeral_low = MAX_PTR;
-    gc_heap::ephemeral_high = nullptr;
-#endif //!USE_REGIONS
-#ifdef MULTIPLE_HEAPS
-    for (uint32_t i = 0; i < nhp; i++)
-    {
-        GCHeap* Hp = new (nothrow) GCHeap();
-        if (!Hp)
-            return E_OUTOFMEMORY;
-        if ((hr = Hp->Init (i))!= S_OK)
-        {
-            return hr;
-        }
-    }
-    heap_select::init_numa_node_to_heap_map (nhp);
-    if (g_num_active_processors > nhp)
-    {
-        bool distribute_all_p = false;
-#ifdef DYNAMIC_HEAP_COUNT
-        distribute_all_p = (gc_heap::dynamic_adaptation_mode == dynamic_adaptation_to_application_sizes);
-#endif //DYNAMIC_HEAP_COUNT
-        heap_select::distribute_other_procs (distribute_all_p);
-    }
-    gc_heap* hp = gc_heap::g_heaps[0];
-    dynamic_data* gen0_dd = hp->dynamic_data_of (0);
-    gc_heap::min_gen0_balance_delta = (dd_min_size (gen0_dd) >> 6);
-    bool can_use_cpu_groups = GCToOSInterface::CanEnableGCCPUGroups();
-    GCConfig::SetGCCpuGroup(can_use_cpu_groups);
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-    cpu_group_enabled_p = can_use_cpu_groups;
-    if (!GCToOSInterface::GetNumaInfo (&total_numa_nodes_on_machine, &procs_per_numa_node))
-    {
-        total_numa_nodes_on_machine = 1;
-        if (GCToOSInterface::GetCPUGroupInfo (&total_cpu_groups_on_machine, &procs_per_cpu_group))
-            procs_per_numa_node = procs_per_cpu_group + ((total_cpu_groups_on_machine - 1) << 6);
-        else
-            procs_per_numa_node = g_num_processors;
-    }
-    hb_info_numa_nodes = new (nothrow) heap_balance_info_numa[total_numa_nodes_on_machine];
-    dprintf (HEAP_BALANCE_LOG, ("total: %d, numa: %d", g_num_processors, total_numa_nodes_on_machine));
-    int hb_info_size_per_proc = sizeof (heap_balance_info_proc);
-    for (int numa_node_index = 0; numa_node_index < total_numa_nodes_on_machine; numa_node_index++)
-    {
-        int hb_info_size_per_node = hb_info_size_per_proc * procs_per_numa_node;
-        uint8_t* numa_mem = (uint8_t*)GCToOSInterface::VirtualReserve (hb_info_size_per_node, 0, 0, (uint16_t)numa_node_index);
-        if (!numa_mem)
-        {
-            GCToEEInterface::LogErrorToHost("Reservation of numa_mem failed");
-            return E_FAIL;
-        }
-        if (!GCToOSInterface::VirtualCommit (numa_mem, hb_info_size_per_node, (uint16_t)numa_node_index))
-        {
-            GCToEEInterface::LogErrorToHost("Commit of numa_mem failed");
-            return E_FAIL;
-        }
-        heap_balance_info_proc* hb_info_procs = (heap_balance_info_proc*)numa_mem;
-        hb_info_numa_nodes[numa_node_index].hb_info_procs = hb_info_procs;
-        for (int proc_index = 0; proc_index < (int)procs_per_numa_node; proc_index++)
-        {
-            heap_balance_info_proc* hb_info_proc = &hb_info_procs[proc_index];
-            hb_info_proc->count = default_max_hb_heap_balance_info;
-            hb_info_proc->index = 0;
-        }
-    }
-#endif //HEAP_BALANCE_INSTRUMENTATION
-#else
-    hr = Init (0);
-#endif //MULTIPLE_HEAPS
-#ifdef USE_REGIONS
-    if (initial_regions)
-    {
-        delete[] initial_regions;
-    }
-#endif //USE_REGIONS
-    if (hr == S_OK)
-    {
-#ifdef MULTIPLE_HEAPS
-        dprintf (6666, ("conserve mem %d, concurent %d, max heap %d", gc_heap::conserve_mem_setting, gc_heap::gc_can_use_concurrent, gc_heap::n_heaps));
-#else
-        dprintf (6666, ("conserve mem %d, concurent %d, WKS", gc_heap::conserve_mem_setting, gc_heap::gc_can_use_concurrent));
-#endif
-#ifdef DYNAMIC_HEAP_COUNT
-        if (gc_heap::dynamic_adaptation_mode == dynamic_adaptation_to_application_sizes)
-        {
-            gc_heap::smoothed_desired_total[0] /= gc_heap::n_heaps;
-            int initial_n_heaps = 1;
-            dprintf (6666, ("n_heaps is %d, initial n_heaps is %d, %d cores", gc_heap::n_heaps, initial_n_heaps, g_num_processors));
-            {
-                if (!gc_heap::prepare_to_change_heap_count (initial_n_heaps))
-                {
-                    return E_FAIL;
-                }
-                gc_heap::dynamic_heap_count_data.new_n_heaps = initial_n_heaps;
-                gc_heap::dynamic_heap_count_data.idle_thread_count = 0;
-                gc_heap::dynamic_heap_count_data.init_only_p = true;
-                int max_threads_to_wake = max (gc_heap::n_heaps, initial_n_heaps);
-                gc_t_join.update_n_threads (max_threads_to_wake);
-                gc_heap::gc_start_event.Set ();
-            }
-            gc_heap::g_heaps[0]->change_heap_count (initial_n_heaps);
-            gc_heap::gc_start_event.Reset ();
-            gc_heap::dynamic_heap_count_data.last_n_heaps = 0;
-            int target_tcp = (int)GCConfig::GetGCDTargetTCP();
-            if (target_tcp > 0)
-            {
-                gc_heap::dynamic_heap_count_data.target_tcp = (float)target_tcp;
-            }
-            gc_heap::dynamic_heap_count_data.around_target_threshold = 10.0;
-            gc_heap::dynamic_heap_count_data.max_gen0_new_allocation = Align (min (dd_max_size (gc_heap::g_heaps[0]->dynamic_data_of (0)), (size_t)(64 * 1024 * 1024)), get_alignment_constant (TRUE));
-            gc_heap::dynamic_heap_count_data.min_gen0_new_allocation = Align (dd_min_size (gc_heap::g_heaps[0]->dynamic_data_of (0)), get_alignment_constant (TRUE));
-            dprintf (6666, ("datas max gen0 budget %Id, min %Id",
-                gc_heap::dynamic_heap_count_data.max_gen0_new_allocation, gc_heap::dynamic_heap_count_data.min_gen0_new_allocation));
-        }
-#endif //DYNAMIC_HEAP_COUNT
-        GCScan::GcRuntimeStructuresValid (TRUE);
-        GCToEEInterface::DiagUpdateGenerationBounds();
-#if defined(STRESS_REGIONS) && defined(FEATURE_BASICFREEZE)
-#ifdef MULTIPLE_HEAPS
-        gc_heap* hp = gc_heap::g_heaps[0];
-#else
-        gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-        for (int i = 0; i < 2; i++)
-        {
-            size_t ro_seg_size = 1024 * 1024;
-            uint8_t* seg_mem = new (nothrow) uint8_t [ro_seg_size];
-            if (seg_mem == nullptr)
-            {
-                GCToEEInterface::LogErrorToHost("STRESS_REGIONS couldn't allocate ro segment");
-                hr = E_FAIL;
-                break;
-            }
-            segment_info seg_info;
-            seg_info.pvMem = seg_mem;
-            seg_info.ibFirstObject = 0; // nothing is there, don't fake it with sizeof(ObjHeader)
-            seg_info.ibAllocated = 0;
-            seg_info.ibCommit = ro_seg_size;
-            seg_info.ibReserved = seg_info.ibCommit;
-            if (!RegisterFrozenSegment(&seg_info))
-            {
-                GCToEEInterface::LogErrorToHost("STRESS_REGIONS failed to RegisterFrozenSegment");
-                hr = E_FAIL;
-                break;
-            }
-        }
-#endif //STRESS_REGIONS && FEATURE_BASICFREEZE
-    }
-    return hr;
-}
-bool GCHeap::IsPromoted(Object* object)
-{
-    uint8_t* o = (uint8_t*)object;
-    bool is_marked;
-    if (gc_heap::settings.condemned_generation == max_generation)
-    {
-#ifdef MULTIPLE_HEAPS
-        gc_heap* hp = gc_heap::g_heaps[0];
-#else
-        gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-#ifdef BACKGROUND_GC
-        if (gc_heap::settings.concurrent)
-        {
-            is_marked = (!((o < hp->background_saved_highest_address) && (o >= hp->background_saved_lowest_address))||
-                            hp->background_marked (o));
-        }
-        else
-#endif //BACKGROUND_GC
-        {
-            is_marked = (!((o < hp->highest_address) && (o >= hp->lowest_address))
-                        || hp->is_mark_set (o));
-        }
-    }
-    else
-    {
-#ifdef USE_REGIONS
-        is_marked = (gc_heap::is_in_gc_range (o) ? (gc_heap::is_in_condemned_gc (o) ? gc_heap::is_mark_set (o) : true) : true);
-#else
-        gc_heap* hp = gc_heap::heap_of (o);
-        is_marked = (!((o < hp->gc_high) && (o >= hp->gc_low))
-                   || hp->is_mark_set (o));
-#endif //USE_REGIONS
-    }
-#ifdef _DEBUG
-    if (o)
-    {
-        ((CObjectHeader*)o)->Validate(TRUE, TRUE, is_marked);
-        assert(is_marked || !IsInFrozenSegment(object));
-    }
-#endif //_DEBUG
-    return is_marked;
-}
-size_t GCHeap::GetPromotedBytes(int heap_index)
-{
-#ifdef BACKGROUND_GC
-    if (gc_heap::settings.concurrent)
-    {
-        return gc_heap::bpromoted_bytes (heap_index);
-    }
-    else
-#endif //BACKGROUND_GC
-    {
-        gc_heap* hp =
-#ifdef MULTIPLE_HEAPS
-            gc_heap::g_heaps[heap_index];
-#else
-            pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-        return hp->get_promoted_bytes();
-    }
-}
-void GCHeap::SetYieldProcessorScalingFactor (float scalingFactor)
-{
-    if (!gc_heap::spin_count_unit_config_p)
-    {
-        assert (yp_spin_count_unit != 0);
-        uint32_t saved_yp_spin_count_unit = yp_spin_count_unit;
-        yp_spin_count_unit = (uint32_t)((float)original_spin_count_unit * scalingFactor / (float)9);
-        if ((yp_spin_count_unit == 0) || (yp_spin_count_unit > MAX_YP_SPIN_COUNT_UNIT))
-        {
-            yp_spin_count_unit = saved_yp_spin_count_unit;
-        }
-    }
-}
-unsigned int GCHeap::WhichGeneration (Object* object)
-{
-    uint8_t* o = (uint8_t*)object;
-#ifdef FEATURE_BASICFREEZE
-    if (!((o < g_gc_highest_address) && (o >= g_gc_lowest_address)))
-    {
-        return INT32_MAX;
-    }
-#ifndef USE_REGIONS
-    if (GCHeap::IsInFrozenSegment (object))
-    {
-        return INT32_MAX;
-    }
-#endif
-#endif //FEATURE_BASICFREEZE
-    gc_heap* hp = gc_heap::heap_of (o);
-    unsigned int g = hp->object_gennum (o);
-    dprintf (3, ("%zx is in gen %d", (size_t)object, g));
-    return g;
-}
-enable_no_gc_region_callback_status GCHeap::EnableNoGCRegionCallback(NoGCRegionCallbackFinalizerWorkItem* callback, uint64_t callback_threshold)
-{
-    return gc_heap::enable_no_gc_callback(callback, callback_threshold);
-}
-FinalizerWorkItem* GCHeap::GetExtraWorkForFinalization()
-{
-    return Interlocked::ExchangePointer(&gc_heap::finalizer_work, nullptr);
-}
-unsigned int GCHeap::GetGenerationWithRange (Object* object, uint8_t** ppStart, uint8_t** ppAllocated, uint8_t** ppReserved)
-{
-    int generation = -1;
-    heap_segment * hs = gc_heap::find_segment ((uint8_t*)object, FALSE);
-#ifdef USE_REGIONS
-    generation = heap_segment_gen_num (hs);
-    if (generation == max_generation)
-    {
-        if (heap_segment_loh_p (hs))
-        {
-            generation = loh_generation;
-        }
-        else if (heap_segment_poh_p (hs))
-        {
-            generation = poh_generation;
-        }
-    }
-    *ppStart = heap_segment_mem (hs);
-    *ppAllocated = heap_segment_allocated (hs);
-    *ppReserved = heap_segment_reserved (hs);
-#else
-#ifdef MULTIPLE_HEAPS
-    gc_heap* hp = heap_segment_heap (hs);
-#else
-    gc_heap* hp = __this;
-#endif //MULTIPLE_HEAPS
-    if (hs == hp->ephemeral_heap_segment)
-    {
-        uint8_t* reserved = heap_segment_reserved (hs);
-        uint8_t* end = heap_segment_allocated(hs);
-        for (int gen = 0; gen < max_generation; gen++)
-        {
-            uint8_t* start = generation_allocation_start (hp->generation_of (gen));
-            if ((uint8_t*)object >= start)
-            {
-                generation = gen;
-                *ppStart = start;
-                *ppAllocated = end;
-                *ppReserved = reserved;
-                break;
-            }
-            end = reserved = start;
-        }
-        if (generation == -1)
-        {
-            generation = max_generation;
-            *ppStart = heap_segment_mem (hs);
-            *ppAllocated = *ppReserved = generation_allocation_start (hp->generation_of (max_generation - 1));
-        }
-    }
-    else
-    {
-        generation = max_generation;
-        if (heap_segment_loh_p (hs))
-        {
-            generation = loh_generation;
-        }
-        else if (heap_segment_poh_p (hs))
-        {
-            generation = poh_generation;
-        }
-        *ppStart = heap_segment_mem (hs);
-        *ppAllocated = heap_segment_allocated (hs);
-        *ppReserved = heap_segment_reserved (hs);
-    }
-#endif //USE_REGIONS
-    return (unsigned int)generation;
-}
-bool GCHeap::IsEphemeral (Object* object)
-{
-    uint8_t* o = (uint8_t*)object;
-#if defined(FEATURE_BASICFREEZE) && defined(USE_REGIONS)
-    if (!is_in_heap_range (o))
-    {
-        return FALSE;
-    }
-#endif
-    gc_heap* hp = gc_heap::heap_of (o);
-    return !!hp->ephemeral_pointer_p (o);
-}
-Object * GCHeap::NextObj (Object * object)
-{
-#ifdef VERIFY_HEAP
-    uint8_t* o = (uint8_t*)object;
-#ifndef FEATURE_BASICFREEZE
-    if (!((o < g_gc_highest_address) && (o >= g_gc_lowest_address)))
-    {
-        return NULL;
-    }
-#endif //!FEATURE_BASICFREEZE
-    heap_segment * hs = gc_heap::find_segment (o, FALSE);
-    if (!hs)
-    {
-        return NULL;
-    }
-    BOOL large_object_p = heap_segment_uoh_p (hs);
-    if (large_object_p)
-        return NULL; //could be racing with another core allocating.
-#ifdef MULTIPLE_HEAPS
-    gc_heap* hp = heap_segment_heap (hs);
-#else //MULTIPLE_HEAPS
-    gc_heap* hp = 0;
-#endif //MULTIPLE_HEAPS
-#ifdef USE_REGIONS
-    unsigned int g = heap_segment_gen_num (hs);
-#else
-    unsigned int g = hp->object_gennum ((uint8_t*)object);
-#endif
-    int align_const = get_alignment_constant (!large_object_p);
-    uint8_t* nextobj = o + Align (size (o), align_const);
-    if (nextobj <= o) // either overflow or 0 sized object.
-    {
-        return NULL;
-    }
-    if (nextobj < heap_segment_mem (hs))
-    {
-        return NULL;
-    }
-    uint8_t* saved_alloc_allocated = hp->alloc_allocated;
-    heap_segment* saved_ephemeral_heap_segment = hp->ephemeral_heap_segment;
-    if ((nextobj >= heap_segment_allocated (hs)) &&
-        ((hs != saved_ephemeral_heap_segment) ||
-         !in_range_for_segment(saved_alloc_allocated, saved_ephemeral_heap_segment) ||
-         (nextobj >= saved_alloc_allocated)))
-    {
-        return NULL;
-    }
-    return (Object *)nextobj;
-#else
-    return nullptr;
-#endif // VERIFY_HEAP
-}
-bool GCHeap::IsHeapPointer (void* vpObject, bool small_heap_only)
-{
-    uint8_t* object = (uint8_t*) vpObject;
-#ifndef FEATURE_BASICFREEZE
-    if (!((object < g_gc_highest_address) && (object >= g_gc_lowest_address)))
-        return FALSE;
-#endif //!FEATURE_BASICFREEZE
-    heap_segment * hs = gc_heap::find_segment (object, small_heap_only);
-    return !!hs;
-}
-void GCHeap::Promote(Object** ppObject, ScanContext* sc, uint32_t flags)
-{
-    THREAD_NUMBER_FROM_CONTEXT;
-#ifndef MULTIPLE_HEAPS
-    const int thread = 0;
-#endif //!MULTIPLE_HEAPS
-    uint8_t* o = (uint8_t*)*ppObject;
-    if (!gc_heap::is_in_find_object_range (o))
-    {
-        return;
-    }
-#ifdef DEBUG_DestroyedHandleValue
-    if (o == (uint8_t*)DEBUG_DestroyedHandleValue)
-        return;
-#endif //DEBUG_DestroyedHandleValue
-    HEAP_FROM_THREAD;
-    gc_heap* hp = gc_heap::heap_of (o);
-#ifdef USE_REGIONS
-    if (!gc_heap::is_in_condemned_gc (o))
-#else //USE_REGIONS
-    if ((o < hp->gc_low) || (o >= hp->gc_high))
-#endif //USE_REGIONS
-    {
-        return;
-    }
-    dprintf (3, ("Promote %zx", (size_t)o));
-    if (flags & GC_CALL_INTERIOR)
-    {
-        if ((o = hp->find_object (o)) == 0)
-        {
-            return;
-        }
-    }
-#ifdef FEATURE_CONSERVATIVE_GC
-    if (GCConfig::GetConservativeGC()
-        && ((CObjectHeader*)o)->IsFree())
-    {
-        return;
-    }
-#endif
-#ifdef _DEBUG
-    ((CObjectHeader*)o)->Validate();
-#else
-    UNREFERENCED_PARAMETER(sc);
-#endif //_DEBUG
-    if (flags & GC_CALL_PINNED)
-        hp->pin_object (o, (uint8_t**) ppObject);
-#ifdef STRESS_PINNING
-    if ((++n_promote % 20) == 1)
-            hp->pin_object (o, (uint8_t**) ppObject);
-#endif //STRESS_PINNING
-    hpt->mark_object_simple (&o THREAD_NUMBER_ARG);
-    STRESS_LOG_ROOT_PROMOTE(ppObject, o, o ? header(o)->GetMethodTable() : NULL);
-}
-void GCHeap::Relocate (Object** ppObject, ScanContext* sc,
-                       uint32_t flags)
-{
-    UNREFERENCED_PARAMETER(sc);
-    uint8_t* object = (uint8_t*)(Object*)(*ppObject);
-    if (!gc_heap::is_in_find_object_range (object))
-    {
-        return;
-    }
-    THREAD_NUMBER_FROM_CONTEXT;
-    dprintf (3, ("R: %zx", (size_t)ppObject));
-    gc_heap* hp = gc_heap::heap_of (object);
-#ifdef _DEBUG
-    if (!(flags & GC_CALL_INTERIOR))
-    {
-#ifdef USE_REGIONS
-        if (!gc_heap::is_in_condemned_gc (object))
-#else //USE_REGIONS
-        if (!((object >= hp->gc_low) && (object < hp->gc_high)))
-#endif //USE_REGIONS
-        {
-            ((CObjectHeader*)object)->Validate(FALSE);
-        }
-    }
-#endif //_DEBUG
-    dprintf (3, ("Relocate %zx\n", (size_t)object));
-    uint8_t* pheader;
-    if ((flags & GC_CALL_INTERIOR) && gc_heap::settings.loh_compaction)
-    {
-#ifdef USE_REGIONS
-        if (!gc_heap::is_in_condemned_gc (object))
-#else //USE_REGIONS
-        if (!((object >= hp->gc_low) && (object < hp->gc_high)))
-#endif //USE_REGIONS
-        {
-            return;
-        }
-        if (gc_heap::loh_object_p (object))
-        {
-            pheader = hp->find_object (object);
-            if (pheader == 0)
-            {
-                return;
-            }
-            ptrdiff_t ref_offset = object - pheader;
-            hp->relocate_address(&pheader THREAD_NUMBER_ARG);
-            *ppObject = (Object*)(pheader + ref_offset);
-            return;
-        }
-    }
-    {
-        pheader = object;
-        hp->relocate_address(&pheader THREAD_NUMBER_ARG);
-        *ppObject = (Object*)pheader;
-    }
-    STRESS_LOG_ROOT_RELOCATE(ppObject, object, pheader, ((!(flags & GC_CALL_INTERIOR)) ? ((Object*)object)->GetGCSafeMethodTable() : 0));
-}
-/*static*/ bool GCHeap::IsLargeObject(Object *pObj)
-{
-    return size( pObj ) >= loh_size_threshold;
-}
-#ifndef FEATURE_NATIVEAOT // NativeAOT forces relocation a different way
-#ifdef STRESS_HEAP
-void StressHeapDummy ();
-int StressRNG(int iMaxValue)
-{
-    static BOOL bisRandInit = FALSE;
-    static int lHoldrand = 1L;
-    if (!bisRandInit)
-    {
-        lHoldrand = (int)time(NULL);
-        bisRandInit = TRUE;
-    }
-    int randValue = (((lHoldrand = lHoldrand * 214013L + 2531011L) >> 16) & 0x7fff);
-    return randValue % iMaxValue;
-}
-#endif // STRESS_HEAP
-#endif // !FEATURE_NATIVEAOT
-bool GCHeap::StressHeap(gc_alloc_context * context)
-{
-#if defined(STRESS_HEAP) && !defined(FEATURE_NATIVEAOT)
-    alloc_context* acontext = static_cast<alloc_context*>(context);
-    assert(context != nullptr);
-    if (!GCStressPolicy::IsEnabled())
-        return FALSE;
-#ifdef _DEBUG
-    if (g_pConfig->FastGCStressLevel() && !GCToEEInterface::GetThread()->StressHeapIsEnabled()) {
-        return FALSE;
-    }
-#endif //_DEBUG
-    if ((g_pConfig->GetGCStressLevel() & EEConfig::GCSTRESS_UNIQUE)
-#ifdef _DEBUG
-        || g_pConfig->FastGCStressLevel() > 1
-#endif //_DEBUG
-        ) {
-        if (!Thread::UniqueStack(&acontext)) {
-            return FALSE;
-        }
-    }
-#ifdef BACKGROUND_GC
-    if (GCToEEInterface::WasCurrentThreadCreatedByGC())
-    {
-        return FALSE;
-    }
-#endif //BACKGROUND_GC
-    if (g_pStringClass == 0)
-    {
-        _ASSERTE(g_fEEInit);
-        return FALSE;
-    }
-#ifndef MULTIPLE_HEAPS
-    static int32_t OneAtATime = -1;
-    if (Interlocked::Increment(&OneAtATime) == 0 &&
-        !TrackAllocations()) // Messing with object sizes can confuse the profiler (see ICorProfilerInfo::GetObjectSize)
-    {
-        StringObject* str;
-        if (HndFetchHandle(m_StressObjs[m_CurStressObj]) == 0)
-        {
-            int i = m_CurStressObj;
-            while(HndFetchHandle(m_StressObjs[i]) == 0)
-            {
-                _ASSERTE(m_StressObjs[i] != 0);
-                unsigned strLen = ((unsigned)loh_size_threshold - 32) / sizeof(WCHAR);
-                unsigned strSize = PtrAlign(StringObject::GetSize(strLen));
-                SetTypeHandleOnThreadForAlloc(TypeHandle(g_pStringClass));
-                str = (StringObject*) pGenGCHeap->allocate (strSize, acontext, /*flags*/ 0);
-                if (str)
-                {
-                    str->SetMethodTable (g_pStringClass);
-                    str->SetStringLength (strLen);
-                    HndAssignHandle(m_StressObjs[i], ObjectToOBJECTREF(str));
-                }
-                i = (i + 1) % NUM_HEAP_STRESS_OBJS;
-                if (i == m_CurStressObj) break;
-            }
-            m_CurStressObj = (m_CurStressObj + 1) % NUM_HEAP_STRESS_OBJS;
-        }
-        str = (StringObject*) OBJECTREFToObject(HndFetchHandle(m_StressObjs[m_CurStressObj]));
-        if (str)
-        {
-            unsigned sizeOfNewObj = (unsigned)Align(min_obj_size * 31);
-            if (str->GetStringLength() > sizeOfNewObj / sizeof(WCHAR))
-            {
-                unsigned sizeToNextObj = (unsigned)Align(size(str));
-                uint8_t* freeObj = ((uint8_t*) str) + sizeToNextObj - sizeOfNewObj;
-                pGenGCHeap->make_unused_array (freeObj, sizeOfNewObj);
-#if !defined(TARGET_AMD64) && !defined(TARGET_X86)
-                MemoryBarrier();
-#endif
-                str->SetStringLength(str->GetStringLength() - (sizeOfNewObj / sizeof(WCHAR)));
-            }
-            else
-            {
-                HndAssignHandle(m_StressObjs[m_CurStressObj], 0);
-            }
-        }
-    }
-    Interlocked::Decrement(&OneAtATime);
-#endif // !MULTIPLE_HEAPS
-    if (g_pConfig->GetGCStressLevel() & EEConfig::GCSTRESS_INSTR_JIT)
-    {
-        int rgen = StressRNG(100);
-        if (rgen >= 98)
-            rgen = 2;
-        else if (rgen >= 90)
-            rgen = 1;
-        else
-            rgen = 0;
-        GarbageCollectTry (rgen, FALSE, collection_gcstress);
-    }
-    else if (IsConcurrentGCEnabled())
-    {
-        int rgen = StressRNG(10);
-        if (rgen >= 8)
-            rgen = 2;
-        else if (rgen >= 4)
-            rgen = 1;
-        else
-            rgen = 0;
-        GarbageCollectTry (rgen, FALSE, collection_gcstress);
-    }
-    else
-    {
-        GarbageCollect(max_generation, FALSE, collection_gcstress);
-    }
-    return TRUE;
-#else
-    UNREFERENCED_PARAMETER(context);
-    return FALSE;
-#endif //STRESS_HEAP && !FEATURE_NATIVEAOT
-}
-#ifdef FEATURE_PREMORTEM_FINALIZATION
-#define REGISTER_FOR_FINALIZATION(_object, _size) \
-    hp->finalize_queue->RegisterForFinalization (0, (_object), (_size))
-#else // FEATURE_PREMORTEM_FINALIZATION
-#define REGISTER_FOR_FINALIZATION(_object, _size) true
-#endif // FEATURE_PREMORTEM_FINALIZATION
-#define CHECK_ALLOC_AND_POSSIBLY_REGISTER_FOR_FINALIZATION(_object, _size, _register) do {  \
-    if ((_object) == NULL || ((_register) && !REGISTER_FOR_FINALIZATION(_object, _size)))   \
-    {                                                                                       \
-        STRESS_LOG_OOM_STACK(_size);                                                        \
-        return NULL;                                                                        \
-    }                                                                                       \
-} while (false)
-Object* AllocAlign8(alloc_context* acontext, gc_heap* hp, size_t size, uint32_t flags)
-{
-    CONTRACTL {
-        NOTHROW;
-        GC_TRIGGERS;
-    } CONTRACTL_END;
-    Object* newAlloc = NULL;
-    size_t desiredAlignment = (flags & GC_ALLOC_ALIGN8_BIAS) ? 4 : 0;
-    uint8_t*  result = acontext->alloc_ptr;
-    if ((((size_t)result & 7) == desiredAlignment) && ((result + size) <= acontext->alloc_limit))
-    {
-        newAlloc = (Object*) hp->allocate (size, acontext, flags);
-        ASSERT(((size_t)newAlloc & 7) == desiredAlignment);
-    }
-    else
-    {
-        ASSERT((Align(min_obj_size) & 7) == 4);
-        CObjectHeader *freeobj = (CObjectHeader*) hp->allocate (Align(size) + Align(min_obj_size), acontext, flags);
-        if (freeobj)
-        {
-            if (((size_t)freeobj & 7) == desiredAlignment)
-            {
-                newAlloc = (Object*)freeobj;
-                freeobj = (CObjectHeader*)((uint8_t*)freeobj + Align(size));
-            }
-            else
-            {
-                newAlloc = (Object*)((uint8_t*)freeobj + Align(min_obj_size));
-                ASSERT(((size_t)newAlloc & 7) == desiredAlignment);
-                if (flags & GC_ALLOC_ZEROING_OPTIONAL)
-                {
-                    *(((PTR_PTR)newAlloc)-1) = 0;
-                }
-            }
-            freeobj->SetFree(min_obj_size);
-        }
-    }
-    return newAlloc;
-}
-Object*
-GCHeap::Alloc(gc_alloc_context* context, size_t size, uint32_t flags REQD_ALIGN_DCL)
-{
-    CONTRACTL {
-        NOTHROW;
-        GC_TRIGGERS;
-    } CONTRACTL_END;
-    TRIGGERSGC();
-    Object* newAlloc = NULL;
-    alloc_context* acontext = static_cast<alloc_context*>(context);
-#ifdef MULTIPLE_HEAPS
-    if (acontext->get_alloc_heap() == 0)
-    {
-        AssignHeap (acontext);
-        assert (acontext->get_alloc_heap());
-    }
-    gc_heap* hp = acontext->get_alloc_heap()->pGenGCHeap;
-#else
-    gc_heap* hp = pGenGCHeap;
-#ifdef _PREFAST_
-    PREFIX_ASSUME(hp != NULL);
-#endif //_PREFAST_
-#endif //MULTIPLE_HEAPS
-    assert(size < loh_size_threshold || (flags & GC_ALLOC_LARGE_OBJECT_HEAP));
-    if (flags & GC_ALLOC_USER_OLD_HEAP)
-    {
-        ASSERT((flags & GC_ALLOC_ALIGN8_BIAS) == 0);
-        ASSERT(65536 < loh_size_threshold);
-        int gen_num = (flags & GC_ALLOC_PINNED_OBJECT_HEAP) ? poh_generation : loh_generation;
-        newAlloc = (Object*) hp->allocate_uoh_object (size + ComputeMaxStructAlignPadLarge(requiredAlignment), flags, gen_num, acontext->alloc_bytes_uoh);
-        ASSERT(((size_t)newAlloc & 7) == 0);
-#ifdef MULTIPLE_HEAPS
-        if (flags & GC_ALLOC_FINALIZE)
-        {
-            hp = gc_heap::heap_of ((uint8_t*)newAlloc);
-        }
-#endif //MULTIPLE_HEAPS
-#ifdef FEATURE_STRUCTALIGN
-        newAlloc = (Object*) hp->pad_for_alignment_large ((uint8_t*) newAlloc, requiredAlignment, size);
-#endif // FEATURE_STRUCTALIGN
-    }
-    else
-    {
-        if (flags & GC_ALLOC_ALIGN8)
-        {
-            newAlloc = AllocAlign8 (acontext, hp, size, flags);
-        }
-        else
-        {
-            newAlloc = (Object*) hp->allocate (size + ComputeMaxStructAlignPad(requiredAlignment), acontext, flags);
-        }
-#ifdef MULTIPLE_HEAPS
-        if (flags & GC_ALLOC_FINALIZE)
-        {
-#ifdef DYNAMIC_HEAP_COUNT
-            hp = (newAlloc == nullptr) ? acontext->get_alloc_heap()->pGenGCHeap : gc_heap::heap_of ((uint8_t*)newAlloc);
-#else //DYNAMIC_HEAP_COUNT
-            hp = acontext->get_alloc_heap()->pGenGCHeap;
-            assert ((newAlloc == nullptr) || (hp == gc_heap::heap_of ((uint8_t*)newAlloc)));
-#endif //DYNAMIC_HEAP_COUNT
-        }
-#endif //MULTIPLE_HEAPS
-#ifdef FEATURE_STRUCTALIGN
-        newAlloc = (Object*) hp->pad_for_alignment ((uint8_t*) newAlloc, requiredAlignment, size, acontext);
-#endif // FEATURE_STRUCTALIGN
-    }
-    CHECK_ALLOC_AND_POSSIBLY_REGISTER_FOR_FINALIZATION(newAlloc, size, flags & GC_ALLOC_FINALIZE);
-#ifdef USE_REGIONS
-    assert (IsHeapPointer (newAlloc));
-#endif //USE_REGIONS
-    return newAlloc;
-}
-void
-GCHeap::FixAllocContext (gc_alloc_context* context, void* arg, void *heap)
-{
-    alloc_context* acontext = static_cast<alloc_context*>(context);
-#ifdef MULTIPLE_HEAPS
-    if (arg != 0)
-        acontext->init_alloc_count();
-    uint8_t * alloc_ptr = acontext->alloc_ptr;
-    if (!alloc_ptr)
-        return;
-    gc_heap* hp = gc_heap::heap_of (alloc_ptr);
-#else
-    gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-    if (heap == NULL || heap == hp)
-    {
-        hp->fix_allocation_context (acontext, ((arg != 0)? TRUE : FALSE), TRUE);
-    }
-}
-Object*
-GCHeap::GetContainingObject (void *pInteriorPtr, bool fCollectedGenOnly)
-{
-    uint8_t *o = (uint8_t*)pInteriorPtr;
-    if (!gc_heap::is_in_find_object_range (o))
-    {
-        return NULL;
-    }
-    gc_heap* hp = gc_heap::heap_of (o);
-#ifdef USE_REGIONS
-    if (fCollectedGenOnly && !gc_heap::is_in_condemned_gc (o))
-    {
-        return NULL;
-    }
-#else //USE_REGIONS
-    uint8_t* lowest = (fCollectedGenOnly ? hp->gc_low : hp->lowest_address);
-    uint8_t* highest = (fCollectedGenOnly ? hp->gc_high : hp->highest_address);
-    if (!((o >= lowest) && (o < highest)))
-    {
-        return NULL;
-    }
-#endif //USE_REGIONS
-    return (Object*)(hp->find_object (o));
-}
-BOOL should_collect_optimized (dynamic_data* dd, BOOL low_memory_p)
-{
-    if (dd_new_allocation (dd) < 0)
-    {
-        return TRUE;
-    }
-    if (((float)(dd_new_allocation (dd)) / (float)dd_desired_allocation (dd)) < (low_memory_p ? 0.7 : 0.3))
-    {
-        return TRUE;
-    }
-    return FALSE;
-}
-HRESULT
-GCHeap::GarbageCollect (int generation, bool low_memory_p, int mode)
-{
-#if defined(HOST_64BIT)
-    if (low_memory_p)
-    {
-        size_t total_allocated = 0;
-        size_t total_desired = 0;
-#ifdef MULTIPLE_HEAPS
-        int hn = 0;
-        for (hn = 0; hn < gc_heap::n_heaps; hn++)
-        {
-            gc_heap* hp = gc_heap::g_heaps [hn];
-            total_desired += dd_desired_allocation (hp->dynamic_data_of (0));
-            total_allocated += dd_desired_allocation (hp->dynamic_data_of (0))-
-                dd_new_allocation (hp->dynamic_data_of (0));
-        }
-#else
-        gc_heap* hp = pGenGCHeap;
-        total_desired = dd_desired_allocation (hp->dynamic_data_of (0));
-        total_allocated = dd_desired_allocation (hp->dynamic_data_of (0))-
-            dd_new_allocation (hp->dynamic_data_of (0));
-#endif //MULTIPLE_HEAPS
-        if ((total_desired > gc_heap::mem_one_percent) && (total_allocated < gc_heap::mem_one_percent))
-        {
-            dprintf (2, ("Async low mem but we've only allocated %zu (< 10%% of physical mem) out of %zu, returning",
-                         total_allocated, total_desired));
-            return S_OK;
-        }
-    }
-#endif // HOST_64BIT
-#ifdef MULTIPLE_HEAPS
-    gc_heap* hpt = gc_heap::g_heaps[0];
-#else
-    gc_heap* hpt = 0;
-#endif //MULTIPLE_HEAPS
-    generation = (generation < 0) ? max_generation : min (generation, (int)max_generation);
-    dynamic_data* dd = hpt->dynamic_data_of (generation);
-#ifdef BACKGROUND_GC
-    if (gc_heap::background_running_p())
-    {
-        if ((mode == collection_optimized) || (mode & collection_non_blocking))
-        {
-            return S_OK;
-        }
-        if (mode & collection_blocking)
-        {
-            pGenGCHeap->background_gc_wait();
-            if (mode & collection_optimized)
-            {
-                return S_OK;
-            }
-        }
-    }
-#endif //BACKGROUND_GC
-    if (mode & collection_optimized)
-    {
-        if (pGenGCHeap->gc_started)
-        {
-            return S_OK;
-        }
-        else
-        {
-            BOOL should_collect = FALSE;
-            BOOL should_check_uoh = (generation == max_generation);
-#ifdef MULTIPLE_HEAPS
-            for (int heap_number = 0; heap_number < gc_heap::n_heaps; heap_number++)
-            {
-                dynamic_data* dd1 = gc_heap::g_heaps [heap_number]->dynamic_data_of (generation);
-                should_collect = should_collect_optimized (dd1, low_memory_p);
-                if (should_check_uoh)
-                {
-                    for (int i = uoh_start_generation; i < total_generation_count && !should_collect; i++)
-                    {
-                        should_collect = should_collect_optimized (gc_heap::g_heaps [heap_number]->dynamic_data_of (i), low_memory_p);
-                    }
-                }
-                if (should_collect)
-                    break;
-            }
-#else
-            should_collect = should_collect_optimized (dd, low_memory_p);
-            if (should_check_uoh)
-            {
-                for (int i = uoh_start_generation; i < total_generation_count && !should_collect; i++)
-                {
-                    should_collect = should_collect_optimized (hpt->dynamic_data_of (i), low_memory_p);
-                }
-            }
-#endif //MULTIPLE_HEAPS
-            if (!should_collect)
-            {
-                return S_OK;
-            }
-        }
-    }
-    size_t CollectionCountAtEntry = dd_collection_count (dd);
-    size_t BlockingCollectionCountAtEntry = gc_heap::full_gc_counts[gc_type_blocking];
-    size_t CurrentCollectionCount = 0;
-retry:
-    CurrentCollectionCount = GarbageCollectTry(generation, low_memory_p, mode);
-    if ((mode & collection_blocking) &&
-        (generation == max_generation) &&
-        (gc_heap::full_gc_counts[gc_type_blocking] == BlockingCollectionCountAtEntry))
-    {
-#ifdef BACKGROUND_GC
-        if (gc_heap::background_running_p())
-        {
-            pGenGCHeap->background_gc_wait();
-        }
-#endif //BACKGROUND_GC
-        goto retry;
-    }
-    if (CollectionCountAtEntry == CurrentCollectionCount)
-    {
-        goto retry;
-    }
-    return S_OK;
-}
-size_t
-GCHeap::GarbageCollectTry (int generation, BOOL low_memory_p, int mode)
-{
-    int gen = (generation < 0) ?
-               max_generation : min (generation, (int)max_generation);
-    gc_reason reason = reason_empty;
-    if (low_memory_p)
-    {
-        if (mode & collection_blocking)
-        {
-            reason = reason_lowmemory_blocking;
-        }
-        else
-        {
-            reason = reason_lowmemory;
-        }
-    }
-    else
-    {
-        reason = reason_induced;
-    }
-    if (reason == reason_induced)
-    {
-        if (mode & collection_aggressive)
-        {
-            reason = reason_induced_aggressive;
-        }
-        else if (mode & collection_compacting)
-        {
-            reason = reason_induced_compacting;
-        }
-        else if (mode & collection_non_blocking)
-        {
-            reason = reason_induced_noforce;
-        }
-#ifdef STRESS_HEAP
-        else if (mode & collection_gcstress)
-        {
-            reason = reason_gcstress;
-        }
-#endif
-    }
-    return GarbageCollectGeneration (gen, reason);
-}
-#ifdef BACKGROUND_GC
-void gc_heap::add_bgc_pause_duration_0()
-{
-    if (settings.concurrent)
-    {
-        uint64_t suspended_end_ts = GetHighPrecisionTimeStamp();
-        size_t pause_duration = (size_t)(suspended_end_ts - suspended_start_time);
-        last_recorded_gc_info* last_gc_info = &(last_bgc_info[last_bgc_info_index]);
-        last_gc_info->pause_durations[0] = pause_duration;
-        if (last_gc_info->index < last_ephemeral_gc_info.index)
-        {
-            last_gc_info->pause_durations[0] -= last_ephemeral_gc_info.pause_durations[0];
-        }
-        total_suspended_time += last_gc_info->pause_durations[0];
-    }
-}
-last_recorded_gc_info* gc_heap::get_completed_bgc_info()
-{
-    int completed_bgc_index = gc_heap::background_running_p() ?
-        (int)(!(gc_heap::last_bgc_info_index)) : (int)gc_heap::last_bgc_info_index;
-    return &gc_heap::last_bgc_info[completed_bgc_index];
-}
-#endif //BACKGROUND_GC
-void gc_heap::do_pre_gc()
-{
-    STRESS_LOG_GC_STACK;
-#ifdef STRESS_LOG
-    STRESS_LOG_GC_START(VolatileLoad(&settings.gc_index),
-                        (uint32_t)settings.condemned_generation,
-                        (uint32_t)settings.reason);
-#endif // STRESS_LOG
-#ifdef MULTIPLE_HEAPS
-    gc_heap* hp = g_heaps[0];
-#else
-    gc_heap* hp = 0;
-#endif //MULTIPLE_HEAPS
-#ifdef BACKGROUND_GC
-    settings.b_state = hp->current_bgc_state;
-    if (settings.concurrent)
-    {
-        last_bgc_info_index = !last_bgc_info_index;
-        last_bgc_info[last_bgc_info_index].index = settings.gc_index;
-    }
-#endif //BACKGROUND_GC
-#ifdef TRACE_GC
-    size_t total_allocated_since_last_gc[total_oh_count];
-    get_total_allocated_since_last_gc (total_allocated_since_last_gc);
-#ifdef BACKGROUND_GC
-    size_t heap_size_before = get_total_heap_size();
-    uint64_t start_gc_time = GetHighPrecisionTimeStamp();
-    uint64_t elapsed_since_last_gc_us = start_gc_time - last_alloc_reset_suspended_end_time;
-    max_peak_heap_size = max (max_peak_heap_size, heap_size_before);
-    dprintf (6666, (ThreadStressLog::gcDetailedStartMsg(),
-        VolatileLoad(&settings.gc_index),
-        dd_collection_count (hp->dynamic_data_of (0)),
-        settings.condemned_generation,
-        (elapsed_since_last_gc_us / 1000.0),
-        total_allocated_since_last_gc[gc_oh_num::soh],
-        (dd_desired_allocation (hp->dynamic_data_of (0)) * n_heaps),
-        dd_desired_allocation (hp->dynamic_data_of (0)),
-        (elapsed_since_last_gc_us ? (total_allocated_since_last_gc[gc_oh_num::soh] / 1000.0 / elapsed_since_last_gc_us) : 0),
-        total_allocated_since_last_gc[gc_oh_num::loh],
-        (elapsed_since_last_gc_us ? (total_allocated_since_last_gc[gc_oh_num::loh] / 1000.0 / elapsed_since_last_gc_us) : 0),
-        total_allocated_since_last_gc[gc_oh_num::poh],
-        (elapsed_since_last_gc_us ? (total_allocated_since_last_gc[gc_oh_num::poh] / 1000.0 / elapsed_since_last_gc_us) : 0),
-        (settings.concurrent ? "BGC" : (gc_heap::background_running_p() ? "FGC" : "NGC")),
-        settings.b_state,
-        n_heaps,
-        (heap_size_before / 1000.0 / 1000.0),
-        (max_peak_heap_size / 1000.0 / 1000.0)));
-#else
-    dprintf (1, ("*GC* %d(gen0:%d)(%d)(alloc: %zd)",
-        VolatileLoad(&settings.gc_index),
-        dd_collection_count(hp->dynamic_data_of(0)),
-        settings.condemned_generation,
-        (total_allocated_since_last_gc[0] + total_allocated_since_last_gc[1] + total_allocated_since_last_gc[2])));
-#endif //BACKGROUND_GC
-    if (heap_hard_limit)
-    {
-        size_t total_heap_committed = get_total_committed_size();
-        size_t total_heap_committed_recorded = current_total_committed - current_total_committed_bookkeeping;
-        dprintf (1, ("(%d)GC commit BEG #%zd: %zd (recorded: %zd = %zd-%zd)",
-            settings.condemned_generation,
-            (size_t)settings.gc_index, total_heap_committed, total_heap_committed_recorded,
-            current_total_committed, current_total_committed_bookkeeping));
-    }
-#endif //TRACE_GC
-    GCHeap::UpdatePreGCCounters();
-    fire_committed_usage_event();
-#if defined(__linux__)
-    GCToEEInterface::UpdateGCEventStatus(static_cast<int>(GCEventStatus::GetEnabledLevel(GCEventProvider_Default)),
-                                         static_cast<int>(GCEventStatus::GetEnabledKeywords(GCEventProvider_Default)),
-                                         static_cast<int>(GCEventStatus::GetEnabledLevel(GCEventProvider_Private)),
-                                         static_cast<int>(GCEventStatus::GetEnabledKeywords(GCEventProvider_Private)));
-#endif // __linux__
-    if (settings.concurrent)
-    {
-#ifdef BACKGROUND_GC
-        full_gc_counts[gc_type_background]++;
-#endif // BACKGROUND_GC
-    }
-    else
-    {
-        if (settings.condemned_generation == max_generation)
-        {
-            full_gc_counts[gc_type_blocking]++;
-        }
-        else
-        {
-#ifdef BACKGROUND_GC
-            if (settings.background_p)
-            {
-                ephemeral_fgc_counts[settings.condemned_generation]++;
-            }
-#endif //BACKGROUND_GC
-        }
-    }
-}
-#ifdef GC_CONFIG_DRIVEN
-void gc_heap::record_interesting_info_per_heap()
-{
-    if (!(settings.concurrent))
-    {
-        for (int i = 0; i < max_idp_count; i++)
-        {
-            interesting_data_per_heap[i] += interesting_data_per_gc[i];
-        }
-    }
-    int compact_reason = get_gc_data_per_heap()->get_mechanism (gc_heap_compact);
-    if (compact_reason >= 0)
-        (compact_reasons_per_heap[compact_reason])++;
-    int expand_mechanism = get_gc_data_per_heap()->get_mechanism (gc_heap_expand);
-    if (expand_mechanism >= 0)
-        (expand_mechanisms_per_heap[expand_mechanism])++;
-    for (int i = 0; i < max_gc_mechanism_bits_count; i++)
-    {
-        if (get_gc_data_per_heap()->is_mechanism_bit_set ((gc_mechanism_bit_per_heap)i))
-            (interesting_mechanism_bits_per_heap[i])++;
-    }
-    cprintf (("%2d | %6d | %1d | %1s | %2s | %2s | %2s | %2s | %2s || %5Id | %5Id | %5Id | %5Id | %5Id | %5Id | %5Id | %5Id | %5Id |",
-            heap_number,
-            (size_t)settings.gc_index,
-            settings.condemned_generation,
-            (settings.compaction ? (((compact_reason >= 0) && gc_heap_compact_reason_mandatory_p[compact_reason]) ? "M" : "W") : ""), // compaction
-            ((expand_mechanism >= 0)? "X" : ""), // EX
-            ((expand_mechanism == expand_reuse_normal) ? "X" : ""), // NF
-            ((expand_mechanism == expand_reuse_bestfit) ? "X" : ""), // BF
-            (get_gc_data_per_heap()->is_mechanism_bit_set (gc_mark_list_bit) ? "X" : ""), // ML
-            (get_gc_data_per_heap()->is_mechanism_bit_set (gc_demotion_bit) ? "X" : ""), // DM
-            interesting_data_per_gc[idp_pre_short],
-            interesting_data_per_gc[idp_post_short],
-            interesting_data_per_gc[idp_merged_pin],
-            interesting_data_per_gc[idp_converted_pin],
-            interesting_data_per_gc[idp_pre_pin],
-            interesting_data_per_gc[idp_post_pin],
-            interesting_data_per_gc[idp_pre_and_post_pin],
-            interesting_data_per_gc[idp_pre_short_padded],
-            interesting_data_per_gc[idp_post_short_padded]));
-}
-void gc_heap::record_global_mechanisms()
-{
-    for (int i = 0; i < max_global_mechanisms_count; i++)
-    {
-        if (gc_data_global.get_mechanism_p ((gc_global_mechanism_p)i))
-        {
-            ::record_global_mechanism (i);
-        }
-    }
-}
-BOOL gc_heap::should_do_sweeping_gc (BOOL compact_p)
-{
-    if (!compact_ratio)
-        return (!compact_p);
-    size_t compact_count = compact_or_sweep_gcs[0];
-    size_t sweep_count = compact_or_sweep_gcs[1];
-    size_t total_count = compact_count + sweep_count;
-    BOOL should_compact = compact_p;
-    if (total_count > 3)
-    {
-        if (compact_p)
-        {
-            int temp_ratio = (int)((compact_count + 1) * 100 / (total_count + 1));
-            if (temp_ratio > compact_ratio)
-            {
-                should_compact = FALSE;
-            }
-        }
-        else
-        {
-            int temp_ratio = (int)((sweep_count + 1) * 100 / (total_count + 1));
-            if (temp_ratio > (100 - compact_ratio))
-            {
-                should_compact = TRUE;
-            }
-        }
-    }
-    return !should_compact;
-}
-#endif //GC_CONFIG_DRIVEN
-#ifdef BGC_SERVO_TUNING
-void gc_heap::check_and_adjust_bgc_tuning (int gen_number, size_t physical_size, ptrdiff_t virtual_fl_size)
-{
-    int min_gen_to_check = ((gen_number == max_generation) ? (max_generation - 1) : 0);
-    if (settings.condemned_generation >= min_gen_to_check)
-    {
-#ifdef MULTIPLE_HEAPS
-        gc_heap* hp = g_heaps[0];
-#else
-        gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-        size_t total_gen_size = physical_size;
-        size_t total_generation_fl_size = get_total_generation_fl_size (gen_number);
-        double gen_flr = (double)total_generation_fl_size * 100.0 / (double)total_gen_size;
-        size_t gen1_index = dd_collection_count (hp->dynamic_data_of (max_generation - 1));
-        size_t gen2_index = dd_collection_count (hp->dynamic_data_of (max_generation));
-        bgc_tuning::tuning_calculation* current_gen_calc = &bgc_tuning::gen_calc[gen_number - max_generation];
-        bgc_tuning::tuning_stats* current_gen_stats = &bgc_tuning::gen_stats[gen_number - max_generation];
-        bool gen_size_inc_p = (total_gen_size > current_gen_calc->last_bgc_size);
-        if ((settings.condemned_generation >= min_gen_to_check) &&
-            (settings.condemned_generation != max_generation))
-        {
-            if (gen_size_inc_p)
-            {
-                current_gen_stats->last_gen_increase_flr = gen_flr;
-                dprintf (BGC_TUNING_LOG, ("BTLp[g1: %zd, g2: %zd]: gen%d size inc %s %zd->%zd, flr: %.3f",
-                        gen1_index, gen2_index, gen_number,
-                        (gc_heap::background_running_p() ? "during bgc" : ""),
-                        current_gen_stats->last_bgc_physical_size, total_gen_size, gen_flr));
-            }
-            if (!bgc_tuning::fl_tuning_triggered)
-            {
-                if (bgc_tuning::enable_fl_tuning)
-                {
-                    if (!((gc_heap::background_running_p() || (hp->current_bgc_state == bgc_initialized))))
-                    {
-                        assert (settings.entry_memory_load);
-                        if ((settings.entry_memory_load >= (bgc_tuning::memory_load_goal * 2 / 3)) &&
-                            (full_gc_counts[gc_type_background] >= 2))
-                        {
-                            bgc_tuning::next_bgc_p = true;
-                            current_gen_calc->first_alloc_to_trigger = get_total_servo_alloc (gen_number);
-                            dprintf (BGC_TUNING_LOG, ("BTL[g1: %zd] mem high enough: %d(goal: %d), gen%d fl alloc: %zd, trigger BGC!",
-                                gen1_index, settings.entry_memory_load, bgc_tuning::memory_load_goal,
-                                gen_number, current_gen_calc->first_alloc_to_trigger));
-                        }
-                    }
-                }
-            }
-        }
-        if ((settings.condemned_generation == max_generation) && !(settings.concurrent))
-        {
-            size_t total_survived = get_total_surv_size (gen_number);
-            size_t total_begin = get_total_begin_data_size (gen_number);
-            double current_gc_surv_rate = (double)total_survived * 100.0 / (double)total_begin;
-            double total_virtual_size = (double)physical_size + (double)virtual_fl_size;
-            double total_fl_size = (double)total_generation_fl_size + (double)virtual_fl_size;
-            double new_gen_flr = total_fl_size * 100.0 / total_virtual_size;
-            dprintf (BGC_TUNING_LOG, ("BTL%d NGC2 size %zd->%zd, fl %zd(%.3f)->%zd(%.3f)",
-                gen_number, physical_size, (size_t)total_virtual_size,
-                total_generation_fl_size, gen_flr,
-                (size_t)total_fl_size, new_gen_flr));
-            dprintf (BGC_TUNING_LOG, ("BTL%d* %zd, %.3f, %.3f, %.3f, %.3f, %.3f, %d, %d, %d, %zd",
-                                    gen_number,
-                                    (size_t)total_virtual_size,
-                                    0.0,
-                                    0.0,
-                                    new_gen_flr,
-                                    current_gen_stats->last_gen_increase_flr,
-                                    current_gc_surv_rate,
-                                    0,
-                                    0,
-                                    0,
-                                    current_gen_calc->alloc_to_trigger));
-            bgc_tuning::gen1_index_last_bgc_end = gen1_index;
-            current_gen_calc->last_bgc_size = total_gen_size;
-            current_gen_calc->last_bgc_flr = new_gen_flr;
-            current_gen_calc->last_sweep_above_p = false;
-            current_gen_calc->last_bgc_end_alloc = 0;
-            current_gen_stats->last_alloc_end_to_start = 0;
-            current_gen_stats->last_alloc_start_to_sweep = 0;
-            current_gen_stats->last_alloc_sweep_to_end = 0;
-            current_gen_stats->last_bgc_fl_size = total_generation_fl_size;
-            current_gen_stats->last_bgc_surv_rate = current_gc_surv_rate;
-            current_gen_stats->last_gen_increase_flr = 0;
-        }
-    }
-}
-#endif //BGC_SERVO_TUNING
-#ifdef BACKGROUND_GC
-void gc_heap::get_and_reset_uoh_alloc_info()
-{
-    total_uoh_a_last_bgc = 0;
-    uint64_t total_uoh_a_no_bgc = 0;
-    uint64_t total_uoh_a_bgc_marking = 0;
-    uint64_t total_uoh_a_bgc_planning = 0;
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < gc_heap::n_heaps; i++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[i];
-#else //MULTIPLE_HEAPS
-    {
-        gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-        gc_history_per_heap* current_gc_data_per_heap = hp->get_gc_data_per_heap();
-        for (int i = uoh_start_generation; i < total_generation_count; i++)
-        {
-            current_gc_data_per_heap->gen_data[i].size_before += hp->uoh_a_bgc_marking[i - uoh_start_generation];
-            total_uoh_a_no_bgc += hp->uoh_a_no_bgc[i - uoh_start_generation];
-            hp->uoh_a_no_bgc[i - uoh_start_generation] = 0;
-            total_uoh_a_bgc_marking += hp->uoh_a_bgc_marking[i - uoh_start_generation];
-            hp->uoh_a_bgc_marking[i - uoh_start_generation] = 0;
-            total_uoh_a_bgc_planning += hp->uoh_a_bgc_planning[i - uoh_start_generation];
-            hp->uoh_a_bgc_planning[i - uoh_start_generation] = 0;
-        }
-    }
-    dprintf (2, ("LOH alloc: outside bgc: %zd; bm: %zd; bp: %zd",
-        total_uoh_a_no_bgc,
-        total_uoh_a_bgc_marking,
-        total_uoh_a_bgc_planning));
-    total_uoh_a_last_bgc = total_uoh_a_no_bgc + total_uoh_a_bgc_marking + total_uoh_a_bgc_planning;
-}
-#endif //BACKGROUND_GC
-bool gc_heap::is_pm_ratio_exceeded()
-{
-    size_t maxgen_frag = 0;
-    size_t maxgen_size = 0;
-    size_t total_heap_size = get_total_heap_size();
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < gc_heap::n_heaps; i++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[i];
-#else //MULTIPLE_HEAPS
-    {
-        gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-        maxgen_frag += dd_fragmentation (hp->dynamic_data_of (max_generation));
-        maxgen_size += hp->generation_size (max_generation);
-    }
-    double maxgen_ratio = (double)maxgen_size / (double)total_heap_size;
-    double maxgen_frag_ratio = (double)maxgen_frag / (double)maxgen_size;
-    dprintf (GTC_LOG, ("maxgen %zd(%d%% total heap), frag: %zd (%d%% maxgen)",
-        maxgen_size, (int)(maxgen_ratio * 100.0),
-        maxgen_frag, (int)(maxgen_frag_ratio * 100.0)));
-    bool maxgen_highfrag_p = ((maxgen_ratio > 0.5) && (maxgen_frag_ratio > 0.1));
-    if (maxgen_highfrag_p)
-    {
-        settings.should_lock_elevation = FALSE;
-        dprintf (GTC_LOG, ("high frag gen2, turn off elevation"));
-    }
-    return maxgen_highfrag_p;
-}
-void gc_heap::update_recorded_gen_data (last_recorded_gc_info* gc_info)
-{
-    memset (gc_info->gen_info, 0, sizeof (gc_info->gen_info));
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < gc_heap::n_heaps; i++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[i];
-#else //MULTIPLE_HEAPS
-    {
-        gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-        gc_history_per_heap* current_gc_data_per_heap = hp->get_gc_data_per_heap();
-        for (int gen_number = 0; gen_number < total_generation_count; gen_number++)
-        {
-            recorded_generation_info* recorded_info = &(gc_info->gen_info[gen_number]);
-            gc_generation_data* data = &(current_gc_data_per_heap->gen_data[gen_number]);
-            recorded_info->size_before += data->size_before;
-            recorded_info->fragmentation_before += data->free_list_space_before + data->free_obj_space_before;
-            recorded_info->size_after += data->size_after;
-            recorded_info->fragmentation_after += data->free_list_space_after + data->free_obj_space_after;
-        }
-    }
-}
-void gc_heap::do_post_gc()
-{
-#ifdef MULTIPLE_HEAPS
-    gc_heap* hp = g_heaps[0];
-#else
-    gc_heap* hp = 0;
-#endif //MULTIPLE_HEAPS
-    GCToEEInterface::GcDone(settings.condemned_generation);
-    GCToEEInterface::DiagGCEnd(VolatileLoad(&settings.gc_index),
-                         (uint32_t)settings.condemned_generation,
-                         (uint32_t)settings.reason,
-                         !!settings.concurrent);
-    add_to_history();
-    uint32_t current_memory_load = 0;
-#ifdef BGC_SERVO_TUNING
-    if (bgc_tuning::enable_fl_tuning)
-    {
-        uint64_t current_available_physical = 0;
-        size_t gen2_physical_size = 0;
-        size_t gen3_physical_size = 0;
-        ptrdiff_t gen2_virtual_fl_size = 0;
-        ptrdiff_t gen3_virtual_fl_size = 0;
-        ptrdiff_t vfl_from_kp = 0;
-        ptrdiff_t vfl_from_ki = 0;
-        gen2_physical_size = get_total_generation_size (max_generation);
-        gen3_physical_size = get_total_generation_size (loh_generation);
-        get_memory_info (&current_memory_load, &current_available_physical);
-        if ((settings.condemned_generation == max_generation) && !settings.concurrent)
-        {
-            double gen2_size_ratio = (double)gen2_physical_size / ((double)gen2_physical_size + (double)gen3_physical_size);
-            double total_virtual_fl_size = bgc_tuning::calculate_ml_tuning (current_available_physical, true, &vfl_from_kp, &vfl_from_ki);
-            gen2_virtual_fl_size = (ptrdiff_t)(total_virtual_fl_size * gen2_size_ratio);
-            gen3_virtual_fl_size = (ptrdiff_t)(total_virtual_fl_size * (1.0 - gen2_size_ratio));
-#ifdef SIMPLE_DPRINTF
-            dprintf (BGC_TUNING_LOG, ("BTL: ml: %d (g: %d)(%s), a: %zd (g: %zd, elg: %zd+%zd=%zd, %zd+%zd=%zd), vfl: %zd=%zd+%zd(NGC2)",
-                current_memory_load, bgc_tuning::memory_load_goal,
-                ((current_available_physical > bgc_tuning::available_memory_goal) ? "above" : "below"),
-                current_available_physical, bgc_tuning::available_memory_goal,
-                gen2_physical_size, gen2_virtual_fl_size, (gen2_physical_size + gen2_virtual_fl_size),
-                gen3_physical_size, gen3_virtual_fl_size, (gen3_physical_size + gen3_virtual_fl_size),
-                (ptrdiff_t)total_virtual_fl_size, vfl_from_kp, vfl_from_ki));
-#endif //SIMPLE_DPRINTF
-        }
-        check_and_adjust_bgc_tuning (max_generation, gen2_physical_size, gen2_virtual_fl_size);
-        check_and_adjust_bgc_tuning (loh_generation, gen3_physical_size, gen3_virtual_fl_size);
-    }
-#endif //BGC_SERVO_TUNING
-#ifdef BACKGROUND_GC
-    const char* str_gc_type = (settings.concurrent ? "BGC" : (gc_heap::background_running_p () ? "FGC" : "NGC"));
-#else
-    const char* str_gc_type = "NGC";
-#endif //BACKGROUND_GC
-    dprintf (6666, (ThreadStressLog::gcDetailedEndMsg(),
-        VolatileLoad (&settings.gc_index),
-        dd_collection_count (hp->dynamic_data_of (0)),
-        (get_total_heap_size() / 1000.0 / 1000.0),
-        settings.condemned_generation,
-        str_gc_type,
-        (settings.compaction ? "C" : "S"),
-        (settings.promotion ? "P" : "S"),
-        settings.entry_memory_load,
-        current_memory_load));
-#if defined(TRACE_GC) && defined(SIMPLE_DPRINTF)
-    flush_gc_log (false);
-#endif //TRACE_GC && SIMPLE_DPRINTF
-    last_recorded_gc_info* last_gc_info = 0;
-#ifdef BACKGROUND_GC
-    if (settings.concurrent)
-    {
-        last_gc_info = &last_bgc_info[last_bgc_info_index];
-        assert (last_gc_info->index == settings.gc_index);
-    }
-    else
-#endif //BACKGROUND_GC
-    {
-        last_gc_info = ((settings.condemned_generation == max_generation) ?
-                        &last_full_blocking_gc_info : &last_ephemeral_gc_info);
-        last_gc_info->index = settings.gc_index;
-    }
-    size_t total_heap_committed = get_total_committed_size();
-    last_gc_info->total_committed = total_heap_committed;
-    last_gc_info->promoted = get_total_promoted();
-    last_gc_info->pinned_objects = get_total_pinned_objects();
-    last_gc_info->finalize_promoted_objects = GCHeap::GetFinalizablePromotedCount();
-    if (!settings.concurrent)
-    {
-        dynamic_data* dd = hp->dynamic_data_of (settings.condemned_generation);
-        uint64_t gc_start_ts = dd_time_clock (dd);
-        size_t pause_duration = (size_t)(end_gc_time - dd_time_clock (dd));
-#ifdef BACKGROUND_GC
-        if ((hp->current_bgc_state != bgc_initialized) && (settings.reason != reason_pm_full_gc))
-        {
-            pause_duration += (size_t)(gc_start_ts - suspended_start_time);
-        }
-#endif //BACKGROUND_GC
-        last_gc_info->pause_durations[0] = pause_duration;
-        total_suspended_time += pause_duration;
-        last_gc_info->pause_durations[1] = 0;
-    }
-    uint64_t total_process_time = end_gc_time - process_start_time;
-    last_gc_info->pause_percentage = (float)(total_process_time ?
-        ((double)total_suspended_time / (double)total_process_time * 100.0) : 0);
-    update_recorded_gen_data (last_gc_info);
-    last_gc_info->heap_size = get_total_heap_size();
-    last_gc_info->fragmentation = get_total_fragmentation();
-    if (settings.exit_memory_load != 0)
-        last_gc_info->memory_load = settings.exit_memory_load;
-    else if (settings.entry_memory_load != 0)
-        last_gc_info->memory_load = settings.entry_memory_load;
-    last_gc_info->condemned_generation = (uint8_t)settings.condemned_generation;
-    last_gc_info->compaction = settings.compaction;
-    last_gc_info->concurrent = settings.concurrent;
-#ifdef BACKGROUND_GC
-    is_last_recorded_bgc = settings.concurrent;
-#endif //BACKGROUND_GC
-#ifdef TRACE_GC
-    if (heap_hard_limit)
-    {
-        size_t total_heap_committed_recorded = current_total_committed - current_total_committed_bookkeeping;
-        dprintf (1, ("(%d)GC commit END #%zd: %zd (recorded: %zd=%zd-%zd), heap %zd, frag: %zd",
-            settings.condemned_generation,
-            (size_t)settings.gc_index, total_heap_committed, total_heap_committed_recorded,
-            current_total_committed, current_total_committed_bookkeeping,
-            last_gc_info->heap_size, last_gc_info->fragmentation));
-    }
-#endif //TRACE_GC
-    if ((settings.condemned_generation == max_generation) && (!settings.concurrent))
-    {
-        if (pm_stress_on)
-        {
-            size_t full_compacting_gc_count = full_gc_counts[gc_type_compacting];
-            if (provisional_mode_triggered)
-            {
-                uint64_t r = gc_rand::get_rand(10);
-                if ((full_compacting_gc_count - provisional_triggered_gc_count) >= r)
-                {
-                    provisional_mode_triggered = false;
-                    provisional_off_gc_count = full_compacting_gc_count;
-                    dprintf (GTC_LOG, ("%zd NGC2s when turned on, %zd NGCs since(%zd)",
-                        provisional_triggered_gc_count, (full_compacting_gc_count - provisional_triggered_gc_count),
-                        num_provisional_triggered));
-                }
-            }
-            else
-            {
-                uint64_t r = gc_rand::get_rand(5);
-                if ((full_compacting_gc_count - provisional_off_gc_count) >= r)
-                {
-                    provisional_mode_triggered = true;
-                    provisional_triggered_gc_count = full_compacting_gc_count;
-                    num_provisional_triggered++;
-                    dprintf (GTC_LOG, ("%zd NGC2s when turned off, %zd NGCs since(%zd)",
-                        provisional_off_gc_count, (full_compacting_gc_count - provisional_off_gc_count),
-                        num_provisional_triggered));
-                }
-            }
-        }
-        else
-        {
-            if (provisional_mode_triggered)
-            {
-                if ((settings.entry_memory_load < high_memory_load_th) ||
-                    !is_pm_ratio_exceeded())
-                {
-                    dprintf (GTC_LOG, ("turning off PM"));
-                    provisional_mode_triggered = false;
-                }
-            }
-            else if ((settings.entry_memory_load >= high_memory_load_th) && is_pm_ratio_exceeded())
-            {
-                dprintf (GTC_LOG, ("highmem && highfrag - turning on PM"));
-                provisional_mode_triggered = true;
-                num_provisional_triggered++;
-            }
-        }
-    }
-    if (!settings.concurrent)
-    {
-        fire_committed_usage_event ();
-    }
-    GCHeap::UpdatePostGCCounters();
-    reinit_pinned_objects();
-#ifdef STRESS_LOG
-    STRESS_LOG_GC_END(VolatileLoad(&settings.gc_index),
-                      (uint32_t)settings.condemned_generation,
-                      (uint32_t)settings.reason);
-#endif // STRESS_LOG
-#ifdef GC_CONFIG_DRIVEN
-    if (!settings.concurrent)
-    {
-        if (settings.compaction)
-            (compact_or_sweep_gcs[0])++;
-        else
-            (compact_or_sweep_gcs[1])++;
-    }
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < n_heaps; i++)
-        g_heaps[i]->record_interesting_info_per_heap();
-#else
-    record_interesting_info_per_heap();
-#endif //MULTIPLE_HEAPS
-    record_global_mechanisms();
-#endif //GC_CONFIG_DRIVEN
-    if (mark_list_overflow)
-    {
-        grow_mark_list();
-        mark_list_overflow = false;
-    }
-}
-unsigned GCHeap::GetGcCount()
-{
-    return (unsigned int)VolatileLoad(&pGenGCHeap->settings.gc_index);
-}
-size_t
-GCHeap::GarbageCollectGeneration (unsigned int gen, gc_reason reason)
-{
-    dprintf (2, ("triggered a GC!"));
-#ifdef COMMITTED_BYTES_SHADOW
-    GCHeap::RefreshMemoryLimit();
-#endif //COMMITTED_BYTES_SHADOW
-#ifdef MULTIPLE_HEAPS
-    gc_heap* hpt = gc_heap::g_heaps[0];
-#else
-    gc_heap* hpt = 0;
-#endif //MULTIPLE_HEAPS
-    bool cooperative_mode = true;
-    dynamic_data* dd = hpt->dynamic_data_of (gen);
-    size_t localCount = dd_collection_count (dd);
-    enter_spin_lock (&gc_heap::gc_lock);
-    dprintf (SPINLOCK_LOG, ("GC Egc"));
-    ASSERT_HOLDING_SPIN_LOCK(&gc_heap::gc_lock);
-    {
-        size_t col_count = dd_collection_count (dd);
-        if (localCount != col_count)
-        {
-#ifdef SYNCHRONIZATION_STATS
-            gc_lock_contended++;
-#endif //SYNCHRONIZATION_STATS
-            dprintf (SPINLOCK_LOG, ("no need GC Lgc"));
-            leave_spin_lock (&gc_heap::gc_lock);
-            return col_count;
-         }
-    }
-    gc_heap::g_low_memory_status = (reason == reason_lowmemory) ||
-                                    (reason == reason_lowmemory_blocking) ||
-                                    (gc_heap::latency_level == latency_level_memory_footprint);
-    gc_trigger_reason = reason;
-#ifdef MULTIPLE_HEAPS
-    for (int i = 0; i < gc_heap::n_heaps; i++)
-    {
-        gc_heap::g_heaps[i]->reset_gc_done();
-    }
-#else
-    gc_heap::reset_gc_done();
-#endif //MULTIPLE_HEAPS
-    gc_heap::gc_started = TRUE;
-    {
-        init_sync_log_stats();
-#ifndef MULTIPLE_HEAPS
-        cooperative_mode = gc_heap::enable_preemptive ();
-        dprintf (2, ("Suspending EE"));
-        gc_heap::suspended_start_time = GetHighPrecisionTimeStamp();
-        BEGIN_TIMING(suspend_ee_during_log);
-        GCToEEInterface::SuspendEE(SUSPEND_FOR_GC);
-        END_TIMING(suspend_ee_during_log);
-        gc_heap::proceed_with_gc_p = gc_heap::should_proceed_with_gc();
-        gc_heap::disable_preemptive (cooperative_mode);
-        if (gc_heap::proceed_with_gc_p)
-            pGenGCHeap->settings.init_mechanisms();
-        else
-            gc_heap::update_collection_counts_for_no_gc();
-#endif //!MULTIPLE_HEAPS
-    }
-    unsigned int condemned_generation_number = gen;
-    FIRE_EVENT(GCTriggered, static_cast<uint32_t>(reason));
-#ifdef MULTIPLE_HEAPS
-    GcCondemnedGeneration = condemned_generation_number;
-    cooperative_mode = gc_heap::enable_preemptive ();
-    BEGIN_TIMING(gc_during_log);
-    gc_heap::ee_suspend_event.Set();
-    gc_heap::wait_for_gc_done();
-    END_TIMING(gc_during_log);
-    gc_heap::disable_preemptive (cooperative_mode);
-    condemned_generation_number = GcCondemnedGeneration;
-#else
-    if (gc_heap::proceed_with_gc_p)
-    {
-        BEGIN_TIMING(gc_during_log);
-        pGenGCHeap->garbage_collect (condemned_generation_number);
-        if (gc_heap::pm_trigger_full_gc)
-        {
-            pGenGCHeap->garbage_collect_pm_full_gc();
-        }
-        END_TIMING(gc_during_log);
-    }
-#endif //MULTIPLE_HEAPS
-#ifndef MULTIPLE_HEAPS
-#ifdef BACKGROUND_GC
-    if (!gc_heap::dont_restart_ee_p)
-#endif //BACKGROUND_GC
-    {
-#ifdef BACKGROUND_GC
-        gc_heap::add_bgc_pause_duration_0();
-#endif //BACKGROUND_GC
-        BEGIN_TIMING(restart_ee_during_log);
-        GCToEEInterface::RestartEE(TRUE);
-        END_TIMING(restart_ee_during_log);
-    }
-#endif //!MULTIPLE_HEAPS
-#ifndef MULTIPLE_HEAPS
-    process_sync_log_stats();
-    gc_heap::gc_started = FALSE;
-    gc_heap::set_gc_done();
-    dprintf (SPINLOCK_LOG, ("GC Lgc"));
-    leave_spin_lock (&gc_heap::gc_lock);
-#endif //!MULTIPLE_HEAPS
-#ifdef FEATURE_PREMORTEM_FINALIZATION
-    GCToEEInterface::EnableFinalization(!pGenGCHeap->settings.concurrent && pGenGCHeap->settings.found_finalizers);
-#endif // FEATURE_PREMORTEM_FINALIZATION
-    return dd_collection_count (dd);
-}
-size_t GCHeap::GetTotalBytesInUse ()
-{
-    enter_spin_lock (&pGenGCHeap->gc_lock);
-#ifdef MULTIPLE_HEAPS
-    size_t tot_size = 0;
-    for (int i = 0; i < gc_heap::n_heaps; i++)
-    {
-        GCHeap* Hp = gc_heap::g_heaps [i]->vm_heap;
-        tot_size += Hp->ApproxTotalBytesInUse();
-    }
-#else
-    size_t tot_size = ApproxTotalBytesInUse();
-#endif //MULTIPLE_HEAPS
-    leave_spin_lock (&pGenGCHeap->gc_lock);
-    return tot_size;
-}
-uint64_t GCHeap::GetTotalAllocatedBytes()
-{
-#ifdef MULTIPLE_HEAPS
-    uint64_t total_alloc_bytes = 0;
-    for (int i = 0; i < gc_heap::n_heaps; i++)
-    {
-        gc_heap* hp = gc_heap::g_heaps[i];
-        total_alloc_bytes += hp->total_alloc_bytes_soh;
-        total_alloc_bytes += hp->total_alloc_bytes_uoh;
-    }
-    return total_alloc_bytes;
-#else
-    return (pGenGCHeap->total_alloc_bytes_soh +  pGenGCHeap->total_alloc_bytes_uoh);
-#endif //MULTIPLE_HEAPS
-}
-int GCHeap::CollectionCount (int generation, int get_bgc_fgc_count)
-{
-    if (get_bgc_fgc_count != 0)
-    {
-#ifdef BACKGROUND_GC
-        if (generation == max_generation)
-        {
-            return (int)(gc_heap::full_gc_counts[gc_type_background]);
-        }
-        else
-        {
-            return (int)(gc_heap::ephemeral_fgc_counts[generation]);
-        }
-#else
-        return 0;
-#endif //BACKGROUND_GC
-    }
-#ifdef MULTIPLE_HEAPS
-    gc_heap* hp = gc_heap::g_heaps [0];
-#else  //MULTIPLE_HEAPS
-    gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-    if (generation > max_generation)
-        return 0;
-    else
-        return (int)dd_collection_count (hp->dynamic_data_of (generation));
-}
-size_t GCHeap::ApproxTotalBytesInUse(BOOL small_heap_only)
-{
-    size_t totsize = 0;
-    generation* gen = pGenGCHeap->generation_of (0);
-    size_t gen0_frag = generation_free_list_space (gen) + generation_free_obj_space (gen);
-    uint8_t* current_alloc_allocated = pGenGCHeap->alloc_allocated;
-    heap_segment* current_eph_seg = pGenGCHeap->ephemeral_heap_segment;
-    size_t gen0_size = 0;
-#ifdef USE_REGIONS
-    heap_segment* gen0_seg = generation_start_segment (gen);
-    while (gen0_seg)
-    {
-        uint8_t* end = in_range_for_segment (current_alloc_allocated, gen0_seg) ?
-                       current_alloc_allocated : heap_segment_allocated (gen0_seg);
-        gen0_size += end - heap_segment_mem (gen0_seg);
-        if (gen0_seg == current_eph_seg)
-        {
-            break;
-        }
-        gen0_seg = heap_segment_next (gen0_seg);
-    }
-#else //USE_REGIONS
-    gen0_size = current_alloc_allocated - heap_segment_mem (current_eph_seg);
-#endif //USE_REGIONS
-    totsize = gen0_size - gen0_frag;
-    int stop_gen_index = max_generation;
-#ifdef BACKGROUND_GC
-    if (gc_heap::current_c_gc_state == c_gc_state_planning)
-    {
-        generation* oldest_gen = pGenGCHeap->generation_of (max_generation);
-        totsize = pGenGCHeap->background_soh_size_end_mark - generation_free_list_space (oldest_gen) - generation_free_obj_space (oldest_gen);
-        stop_gen_index--;
-    }
-#endif //BACKGROUND_GC
-    for (int i = (max_generation - 1); i <= stop_gen_index; i++)
-    {
-        generation* gen = pGenGCHeap->generation_of (i);
-        totsize += pGenGCHeap->generation_size (i) - generation_free_list_space (gen) - generation_free_obj_space (gen);
-    }
-    if (!small_heap_only)
-    {
-        for (int i = uoh_start_generation; i < total_generation_count; i++)
-        {
-            generation* gen = pGenGCHeap->generation_of (i);
-            totsize += pGenGCHeap->generation_size (i) - generation_free_list_space (gen) - generation_free_obj_space (gen);
-        }
-    }
-    return totsize;
-}
-#ifdef MULTIPLE_HEAPS
-void GCHeap::AssignHeap (alloc_context* acontext)
-{
-    acontext->set_alloc_heap(GetHeap(heap_select::select_heap(acontext)));
-    acontext->set_home_heap(acontext->get_alloc_heap());
-    acontext->init_handle_info();
-}
-GCHeap* GCHeap::GetHeap (int n)
-{
-    assert (n < gc_heap::n_heaps);
-    return gc_heap::g_heaps[n]->vm_heap;
-}
-#endif //MULTIPLE_HEAPS
-bool GCHeap::IsThreadUsingAllocationContextHeap(gc_alloc_context* context, int thread_number)
-{
-    alloc_context* acontext = static_cast<alloc_context*>(context);
-#ifdef MULTIPLE_HEAPS
-    assert (thread_number < gc_heap::n_heaps);
-    assert ((acontext->get_home_heap() == 0) ||
-            (acontext->get_home_heap()->pGenGCHeap->heap_number < gc_heap::n_heaps));
-    return ((acontext->get_home_heap() == GetHeap(thread_number)) ||
-            ((acontext->get_home_heap() == 0) && (thread_number == 0)));
-#else
-    UNREFERENCED_PARAMETER(acontext);
-    UNREFERENCED_PARAMETER(thread_number);
-    return true;
-#endif //MULTIPLE_HEAPS
-}
-int GCHeap::GetNumberOfHeaps ()
-{
-#ifdef MULTIPLE_HEAPS
-    return gc_heap::n_heaps;
-#else
-    return 1;
-#endif //MULTIPLE_HEAPS
-}
-/*
-  in this way we spend extra time cycling through all the heaps while create the handle
-  it ought to be changed by keeping alloc_context.home_heap as number (equals heap_number)
-*/
-int GCHeap::GetHomeHeapNumber ()
-{
-#ifdef MULTIPLE_HEAPS
-    gc_alloc_context* ctx = GCToEEInterface::GetAllocContext();
-    if (!ctx)
-    {
-        return 0;
-    }
-    GCHeap *hp = static_cast<alloc_context*>(ctx)->get_home_heap();
-    return (hp ? hp->pGenGCHeap->heap_number : 0);
-#else
-    return 0;
-#endif //MULTIPLE_HEAPS
-}
-unsigned int GCHeap::GetCondemnedGeneration()
-{
-    return gc_heap::settings.condemned_generation;
-}
-void GCHeap::GetMemoryInfo(uint64_t* highMemLoadThresholdBytes,
-                           uint64_t* totalAvailableMemoryBytes,
-                           uint64_t* lastRecordedMemLoadBytes,
-                           uint64_t* lastRecordedHeapSizeBytes,
-                           uint64_t* lastRecordedFragmentationBytes,
-                           uint64_t* totalCommittedBytes,
-                           uint64_t* promotedBytes,
-                           uint64_t* pinnedObjectCount,
-                           uint64_t* finalizationPendingCount,
-                           uint64_t* index,
-                           uint32_t* generation,
-                           uint32_t* pauseTimePct,
-                           bool* isCompaction,
-                           bool* isConcurrent,
-                           uint64_t* genInfoRaw,
-                           uint64_t* pauseInfoRaw,
-                           int kind)
-{
-    last_recorded_gc_info* last_gc_info = 0;
-    if ((gc_kind)kind == gc_kind_ephemeral)
-    {
-        last_gc_info = &gc_heap::last_ephemeral_gc_info;
-    }
-    else if ((gc_kind)kind == gc_kind_full_blocking)
-    {
-        last_gc_info = &gc_heap::last_full_blocking_gc_info;
-    }
-#ifdef BACKGROUND_GC
-    else if ((gc_kind)kind == gc_kind_background)
-    {
-        last_gc_info = gc_heap::get_completed_bgc_info();
-    }
-#endif //BACKGROUND_GC
-    else
-    {
-        assert ((gc_kind)kind == gc_kind_any);
-#ifdef BACKGROUND_GC
-        if (gc_heap::is_last_recorded_bgc)
-        {
-            last_gc_info = gc_heap::get_completed_bgc_info();
-        }
-        else
-#endif //BACKGROUND_GC
-        {
-            last_gc_info = ((gc_heap::last_ephemeral_gc_info.index > gc_heap::last_full_blocking_gc_info.index) ?
-                &gc_heap::last_ephemeral_gc_info : &gc_heap::last_full_blocking_gc_info);
-        }
-    }
-    *highMemLoadThresholdBytes = (uint64_t) (((double)(gc_heap::high_memory_load_th)) / 100 * gc_heap::total_physical_mem);
-    *totalAvailableMemoryBytes = gc_heap::heap_hard_limit != 0 ? gc_heap::heap_hard_limit : gc_heap::total_physical_mem;
-    *lastRecordedMemLoadBytes = (uint64_t) (((double)(last_gc_info->memory_load)) / 100 * gc_heap::total_physical_mem);
-    *lastRecordedHeapSizeBytes = last_gc_info->heap_size;
-    *lastRecordedFragmentationBytes = last_gc_info->fragmentation;
-    *totalCommittedBytes = last_gc_info->total_committed;
-    *promotedBytes = last_gc_info->promoted;
-    *pinnedObjectCount = last_gc_info->pinned_objects;
-    *finalizationPendingCount = last_gc_info->finalize_promoted_objects;
-    *index = last_gc_info->index;
-    *generation = last_gc_info->condemned_generation;
-    *pauseTimePct = (int)(last_gc_info->pause_percentage * 100);
-    *isCompaction = last_gc_info->compaction;
-    *isConcurrent = last_gc_info->concurrent;
-    int genInfoIndex = 0;
-    for (int i = 0; i < total_generation_count; i++)
-    {
-        genInfoRaw[genInfoIndex++] = last_gc_info->gen_info[i].size_before;
-        genInfoRaw[genInfoIndex++] = last_gc_info->gen_info[i].fragmentation_before;
-        genInfoRaw[genInfoIndex++] = last_gc_info->gen_info[i].size_after;
-        genInfoRaw[genInfoIndex++] = last_gc_info->gen_info[i].fragmentation_after;
-    }
-    for (int i = 0; i < 2; i++)
-    {
-        pauseInfoRaw[i] = (uint64_t)(last_gc_info->pause_durations[i]) * 10;
-    }
-#ifdef _DEBUG
-    if (VolatileLoadWithoutBarrier (&last_gc_info->index) != 0)
-    {
-        if ((gc_kind)kind == gc_kind_ephemeral)
-        {
-            assert (last_gc_info->condemned_generation < max_generation);
-        }
-        else if ((gc_kind)kind == gc_kind_full_blocking)
-        {
-            assert (last_gc_info->condemned_generation == max_generation);
-            assert (last_gc_info->concurrent == false);
-        }
-#ifdef BACKGROUND_GC
-        else if ((gc_kind)kind == gc_kind_background)
-        {
-            assert (last_gc_info->condemned_generation == max_generation);
-            assert (last_gc_info->concurrent == true);
-        }
-#endif //BACKGROUND_GC
-    }
-#endif //_DEBUG
-}
-int64_t GCHeap::GetTotalPauseDuration()
-{
-    return (int64_t)(gc_heap::total_suspended_time * 10);
-}
-void GCHeap::EnumerateConfigurationValues(void* context, ConfigurationValueFunc configurationValueFunc)
-{
-    GCConfig::EnumerateConfigurationValues(context, configurationValueFunc);
-}
-uint32_t GCHeap::GetMemoryLoad()
-{
-    uint32_t memory_load = 0;
-    if (gc_heap::settings.exit_memory_load != 0)
-        memory_load = gc_heap::settings.exit_memory_load;
-    else if (gc_heap::settings.entry_memory_load != 0)
-        memory_load = gc_heap::settings.entry_memory_load;
-    return memory_load;
-}
-int GCHeap::GetGcLatencyMode()
-{
-    return (int)(pGenGCHeap->settings.pause_mode);
-}
-int GCHeap::SetGcLatencyMode (int newLatencyMode)
-{
-    if (gc_heap::settings.pause_mode == pause_no_gc)
-        return (int)set_pause_mode_no_gc;
-    gc_pause_mode new_mode = (gc_pause_mode)newLatencyMode;
-    if (new_mode == pause_low_latency)
-    {
-#ifndef MULTIPLE_HEAPS
-        pGenGCHeap->settings.pause_mode = new_mode;
-#endif //!MULTIPLE_HEAPS
-    }
-    else if (new_mode == pause_sustained_low_latency)
-    {
-#ifdef BACKGROUND_GC
-        if (gc_heap::gc_can_use_concurrent)
-        {
-            pGenGCHeap->settings.pause_mode = new_mode;
-        }
-#endif //BACKGROUND_GC
-    }
-    else
-    {
-        pGenGCHeap->settings.pause_mode = new_mode;
-    }
-#ifdef BACKGROUND_GC
-    if (gc_heap::background_running_p())
-    {
-        if (gc_heap::saved_bgc_settings.pause_mode != new_mode)
-        {
-            gc_heap::saved_bgc_settings.pause_mode = new_mode;
-        }
-    }
-#endif //BACKGROUND_GC
-    return (int)set_pause_mode_success;
-}
-int GCHeap::GetLOHCompactionMode()
-{
-#ifdef FEATURE_LOH_COMPACTION
-    return pGenGCHeap->loh_compaction_mode;
-#else
-    return loh_compaction_default;
-#endif //FEATURE_LOH_COMPACTION
-}
-void GCHeap::SetLOHCompactionMode (int newLOHCompactionMode)
-{
-#ifdef FEATURE_LOH_COMPACTION
-    pGenGCHeap->loh_compaction_mode = (gc_loh_compaction_mode)newLOHCompactionMode;
-#endif //FEATURE_LOH_COMPACTION
-}
-bool GCHeap::RegisterForFullGCNotification(uint32_t gen2Percentage,
-                                           uint32_t lohPercentage)
-{
-#ifdef MULTIPLE_HEAPS
-    for (int hn = 0; hn < gc_heap::n_heaps; hn++)
-    {
-        gc_heap* hp = gc_heap::g_heaps [hn];
-        hp->fgn_last_alloc = dd_new_allocation (hp->dynamic_data_of (0));
-        hp->fgn_maxgen_percent = gen2Percentage;
-    }
-#else //MULTIPLE_HEAPS
-    pGenGCHeap->fgn_last_alloc = dd_new_allocation (pGenGCHeap->dynamic_data_of (0));
-    pGenGCHeap->fgn_maxgen_percent = gen2Percentage;
-#endif //MULTIPLE_HEAPS
-    pGenGCHeap->full_gc_approach_event.Reset();
-    pGenGCHeap->full_gc_end_event.Reset();
-    pGenGCHeap->full_gc_approach_event_set = false;
-    pGenGCHeap->fgn_loh_percent = lohPercentage;
-    return TRUE;
-}
-bool GCHeap::CancelFullGCNotification()
-{
-#ifdef MULTIPLE_HEAPS
-    for (int hn = 0; hn < gc_heap::n_heaps; hn++)
-    {
-        gc_heap* hp = gc_heap::g_heaps [hn];
-        hp->fgn_maxgen_percent = 0;
-    }
-#else //MULTIPLE_HEAPS
-    pGenGCHeap->fgn_maxgen_percent = 0;
-#endif //MULTIPLE_HEAPS
-    pGenGCHeap->fgn_loh_percent = 0;
-    pGenGCHeap->full_gc_approach_event.Set();
-    pGenGCHeap->full_gc_end_event.Set();
-    return TRUE;
-}
-int GCHeap::WaitForFullGCApproach(int millisecondsTimeout)
-{
-    dprintf (2, ("WFGA: Begin wait"));
-    int result = gc_heap::full_gc_wait (&(pGenGCHeap->full_gc_approach_event), millisecondsTimeout);
-    dprintf (2, ("WFGA: End wait"));
-    return result;
-}
-int GCHeap::WaitForFullGCComplete(int millisecondsTimeout)
-{
-    dprintf (2, ("WFGE: Begin wait"));
-    int result = gc_heap::full_gc_wait (&(pGenGCHeap->full_gc_end_event), millisecondsTimeout);
-    dprintf (2, ("WFGE: End wait"));
-    return result;
-}
-int GCHeap::StartNoGCRegion(uint64_t totalSize, bool lohSizeKnown, uint64_t lohSize, bool disallowFullBlockingGC)
-{
-    NoGCRegionLockHolder lh;
-    dprintf (1, ("begin no gc called"));
-    start_no_gc_region_status status = gc_heap::prepare_for_no_gc_region (totalSize, lohSizeKnown, lohSize, disallowFullBlockingGC);
-    if (status == start_no_gc_success)
-    {
-        GarbageCollect (max_generation);
-        status = gc_heap::get_start_no_gc_region_status();
-    }
-    if (status != start_no_gc_success)
-        gc_heap::handle_failure_for_no_gc();
-    return (int)status;
-}
-int GCHeap::EndNoGCRegion()
-{
-    NoGCRegionLockHolder lh;
-    return (int)gc_heap::end_no_gc_region();
-}
-void GCHeap::PublishObject (uint8_t* Obj)
-{
-#ifdef BACKGROUND_GC
-    gc_heap* hp = gc_heap::heap_of (Obj);
-    hp->bgc_alloc_lock->uoh_alloc_done (Obj);
-    hp->bgc_untrack_uoh_alloc();
-#endif //BACKGROUND_GC
-}
-size_t GCHeap::GetValidSegmentSize(bool large_seg)
-{
-#ifdef USE_REGIONS
-    return (large_seg ? global_region_allocator.get_large_region_alignment() :
-                        global_region_allocator.get_region_alignment());
-#else
-    return (large_seg ? gc_heap::min_uoh_segment_size : gc_heap::soh_segment_size);
-#endif //USE_REGIONS
-}
-size_t gc_heap::get_gen0_min_size()
-{
-    size_t gen0size = static_cast<size_t>(GCConfig::GetGen0Size());
-    bool is_config_invalid = ((gen0size == 0) || !g_theGCHeap->IsValidGen0MaxSize(gen0size));
-    if (is_config_invalid)
-    {
-#ifdef SERVER_GC
-        gen0size = max(GCToOSInterface::GetCacheSizePerLogicalCpu(FALSE), (size_t)(256*1024));
-        size_t trueSize = max(GCToOSInterface::GetCacheSizePerLogicalCpu(TRUE), (size_t)(256*1024));
-        dprintf (1, ("cache: %zd-%zd",
-            GCToOSInterface::GetCacheSizePerLogicalCpu(FALSE),
-            GCToOSInterface::GetCacheSizePerLogicalCpu(TRUE)));
-        int n_heaps = gc_heap::n_heaps;
-#else //SERVER_GC
-        size_t trueSize = GCToOSInterface::GetCacheSizePerLogicalCpu(TRUE);
-        gen0size = max((4*trueSize/5),(size_t)(256*1024));
-        trueSize = max(trueSize, (size_t)(256*1024));
-        int n_heaps = 1;
-#endif //SERVER_GC
-        llc_size = trueSize;
-#ifdef DYNAMIC_HEAP_COUNT
-        if (dynamic_adaptation_mode == dynamic_adaptation_to_application_sizes)
-        {
-            gen0size = min (gen0size, (size_t)(4*1024*1024));
-        }
-#endif //DYNAMIC_HEAP_COUNT
-        dprintf (1, ("gen0size: %zd * %d = %zd, physical mem: %zd / 6 = %zd",
-                gen0size, n_heaps, (gen0size * n_heaps),
-                gc_heap::total_physical_mem,
-                gc_heap::total_physical_mem / 6));
-        while ((gen0size * n_heaps) > (gc_heap::total_physical_mem / 6))
-        {
-            gen0size = gen0size / 2;
-            if (gen0size <= trueSize)
-            {
-                gen0size = trueSize;
-                break;
-            }
-        }
-    }
-#ifdef FEATURE_EVENT_TRACE
-    else
-    {
-        gen0_min_budget_from_config = gen0size;
-    }
-#endif //FEATURE_EVENT_TRACE
-    size_t seg_size = gc_heap::soh_segment_size;
-    assert (seg_size);
-    if (gen0size >= (seg_size / 2))
-        gen0size = seg_size / 2;
-    if (is_config_invalid)
-    {
-        if (heap_hard_limit)
-        {
-            size_t gen0size_seg = seg_size / 8;
-            if (gen0size >= gen0size_seg)
-            {
-                dprintf (1, ("gen0 limited by seg size %zd->%zd", gen0size, gen0size_seg));
-                gen0size = gen0size_seg;
-            }
-        }
-        gen0size = gen0size / 8 * 5;
-    }
-#ifdef USE_REGIONS
-#ifdef STRESS_REGIONS
-    gen0size = ((size_t)1 << min_segment_size_shr) * 3;
-#endif //STRESS_REGIONS
-#endif //USE_REGIONS
-    gen0size = Align (gen0size);
-    return gen0size;
-}
-void GCHeap::SetReservedVMLimit (size_t vmlimit)
-{
-    gc_heap::reserved_memory_limit = vmlimit;
-}
-#ifdef FEATURE_PREMORTEM_FINALIZATION
-Object* GCHeap::GetNextFinalizableObject()
-{
-#ifdef MULTIPLE_HEAPS
-    for (int hn = 0; hn < gc_heap::n_heaps; hn++)
-    {
-        gc_heap* hp = gc_heap::g_heaps [hn];
-        Object* O = hp->finalize_queue->GetNextFinalizableObject(TRUE);
-        if (O)
-            return O;
-    }
-    for (int hn = 0; hn < gc_heap::n_heaps; hn++)
-    {
-        gc_heap* hp = gc_heap::g_heaps [hn];
-        Object* O = hp->finalize_queue->GetNextFinalizableObject(FALSE);
-        if (O)
-            return O;
-    }
-    return 0;
-#else //MULTIPLE_HEAPS
-    return pGenGCHeap->finalize_queue->GetNextFinalizableObject();
-#endif //MULTIPLE_HEAPS
-}
-size_t GCHeap::GetNumberFinalizableObjects()
-{
-#ifdef MULTIPLE_HEAPS
-    size_t cnt = 0;
-    for (int hn = 0; hn < gc_heap::n_heaps; hn++)
-    {
-        gc_heap* hp = gc_heap::g_heaps [hn];
-        cnt += hp->finalize_queue->GetNumberFinalizableObjects();
-    }
-    return cnt;
-#else //MULTIPLE_HEAPS
-    return pGenGCHeap->finalize_queue->GetNumberFinalizableObjects();
-#endif //MULTIPLE_HEAPS
-}
-size_t GCHeap::GetFinalizablePromotedCount()
-{
-#ifdef MULTIPLE_HEAPS
-    size_t cnt = 0;
-    for (int hn = 0; hn < gc_heap::n_heaps; hn++)
-    {
-        gc_heap* hp = gc_heap::g_heaps [hn];
-        cnt += hp->finalize_queue->GetPromotedCount();
-    }
-    return cnt;
-#else //MULTIPLE_HEAPS
-    return pGenGCHeap->finalize_queue->GetPromotedCount();
-#endif //MULTIPLE_HEAPS
-}
-bool GCHeap::RegisterForFinalization (int gen, Object* obj)
-{
-    if (gen == -1)
-        gen = 0;
-    if (((((CObjectHeader*)obj)->GetHeader()->GetBits()) & BIT_SBLK_FINALIZER_RUN))
-    {
-        ((CObjectHeader*)obj)->GetHeader()->ClrBit(BIT_SBLK_FINALIZER_RUN);
-        return true;
-    }
-    else
-    {
-        gc_heap* hp = gc_heap::heap_of ((uint8_t*)obj);
-        return hp->finalize_queue->RegisterForFinalization (gen, obj);
-    }
-}
-void GCHeap::SetFinalizationRun (Object* obj)
-{
-    ((CObjectHeader*)obj)->GetHeader()->SetBit(BIT_SBLK_FINALIZER_RUN);
-}
-inline
-unsigned int gen_segment (int gen)
-{
-    assert (((signed)total_generation_count - gen - 1)>=0);
-    return (total_generation_count - gen - 1);
-}
-bool CFinalize::Initialize()
-{
-    CONTRACTL {
-        NOTHROW;
-        GC_NOTRIGGER;
-    } CONTRACTL_END;
-    const int INITIAL_FINALIZER_ARRAY_SIZE = 100;
-    m_Array = new (nothrow)(Object*[INITIAL_FINALIZER_ARRAY_SIZE]);
-    if (!m_Array)
-    {
-        ASSERT (m_Array);
-        STRESS_LOG_OOM_STACK(sizeof(Object*[INITIAL_FINALIZER_ARRAY_SIZE]));
-        if (GCConfig::GetBreakOnOOM())
-        {
-            GCToOSInterface::DebugBreak();
-        }
-        return false;
-    }
-    m_EndArray = &m_Array[INITIAL_FINALIZER_ARRAY_SIZE];
-    for (int i =0; i < FreeList; i++)
-    {
-        SegQueueLimit (i) = m_Array;
-    }
-    m_PromotedCount = 0;
-    lock = -1;
-#ifdef _DEBUG
-    lockowner_threadid.Clear();
-#endif // _DEBUG
-    return true;
-}
-CFinalize::~CFinalize()
-{
-    delete[] m_Array;
-}
-size_t CFinalize::GetPromotedCount ()
-{
-    return m_PromotedCount;
-}
-inline
-void CFinalize::EnterFinalizeLock()
-{
-    _ASSERTE(dbgOnly_IsSpecialEEThread() ||
-             GCToEEInterface::GetThread() == 0 ||
-             GCToEEInterface::IsPreemptiveGCDisabled());
-retry:
-    if (Interlocked::CompareExchange(&lock, 0, -1) >= 0)
-    {
-        unsigned int i = 0;
-        while (lock >= 0)
-        {
-            if (g_num_processors > 1)
-            {
-                int spin_count = 128 * yp_spin_count_unit;
-                for (int j = 0; j < spin_count; j++)
-                {
-                    if (lock < 0)
-                        break;
-                    YieldProcessor ();
-                }
-            }
-            if (lock < 0)
-                break;
-            if (++i & 7)
-                GCToOSInterface::YieldThread (0);
-            else
-                GCToOSInterface::Sleep (5);
-        }
-        goto retry;
-    }
-#ifdef _DEBUG
-    lockowner_threadid.SetToCurrentThread();
-#endif // _DEBUG
-}
-inline
-void CFinalize::LeaveFinalizeLock()
-{
-    _ASSERTE(dbgOnly_IsSpecialEEThread() ||
-             GCToEEInterface::GetThread() == 0 ||
-             GCToEEInterface::IsPreemptiveGCDisabled());
-#ifdef _DEBUG
-    lockowner_threadid.Clear();
-#endif // _DEBUG
-    lock = -1;
-}
-bool
-CFinalize::RegisterForFinalization (int gen, Object* obj, size_t size)
-{
-    CONTRACTL {
-        NOTHROW;
-        GC_NOTRIGGER;
-    } CONTRACTL_END;
-    EnterFinalizeLock();
-    unsigned int dest = gen_segment (gen);
-    Object*** s_i = &SegQueue (FreeListSeg);
-    if ((*s_i) == SegQueueLimit(FreeListSeg))
-    {
-        if (!GrowArray())
-        {
-            LeaveFinalizeLock();
-            if (method_table(obj) == NULL)
-            {
-                assert (size >= Align (min_obj_size));
-                dprintf (3, (ThreadStressLog::gcMakeUnusedArrayMsg(), (size_t)obj, (size_t)(obj+size)));
-                ((CObjectHeader*)obj)->SetFree(size);
-            }
-            STRESS_LOG_OOM_STACK(0);
-            if (GCConfig::GetBreakOnOOM())
-            {
-                GCToOSInterface::DebugBreak();
-            }
-            return false;
-        }
-    }
-    Object*** end_si = &SegQueueLimit (dest);
-    do
-    {
-        if (!(*s_i == *(s_i-1)))
-        {
-            *(*s_i) = *(*(s_i-1));
-        }
-        (*s_i)++;
-        s_i--;
-    } while (s_i > end_si);
-    **s_i = obj;
-    (*s_i)++;
-    LeaveFinalizeLock();
-    return true;
-}
-Object*
-CFinalize::GetNextFinalizableObject (BOOL only_non_critical)
-{
-    Object* obj = 0;
-    EnterFinalizeLock();
-    if (!IsSegEmpty(FinalizerListSeg))
-    {
-        obj =  *(--SegQueueLimit (FinalizerListSeg));
-    }
-    else if (!only_non_critical && !IsSegEmpty(CriticalFinalizerListSeg))
-    {
-        obj =  *(--SegQueueLimit (CriticalFinalizerListSeg));
-        --SegQueueLimit (FinalizerListSeg);
-    }
-    if (obj)
-    {
-        dprintf (3, ("running finalizer for %p (mt: %p)", obj, method_table (obj)));
-    }
-    LeaveFinalizeLock();
-    return obj;
-}
-size_t
-CFinalize::GetNumberFinalizableObjects()
-{
-    return SegQueueLimit(FinalizerMaxSeg) - SegQueue(FinalizerStartSeg);
-}
-void
-CFinalize::MoveItem (Object** fromIndex,
-                     unsigned int fromSeg,
-                     unsigned int toSeg)
-{
-    int step;
-    ASSERT (fromSeg != toSeg);
-    if (fromSeg > toSeg)
-        step = -1;
-    else
-        step = +1;
-    Object** srcIndex = fromIndex;
-    for (unsigned int i = fromSeg; i != toSeg; i+= step)
-    {
-        Object**& destFill = m_FillPointers[i+(step - 1 )/2];
-        Object** destIndex = destFill - (step + 1)/2;
-        if (srcIndex != destIndex)
-        {
-            Object* tmp = *srcIndex;
-            *srcIndex = *destIndex;
-            *destIndex = tmp;
-        }
-        destFill -= step;
-        srcIndex = destIndex;
-    }
-}
-void
-CFinalize::GcScanRoots (promote_func* fn, int hn, ScanContext *pSC)
-{
-    ScanContext sc;
-    if (pSC == 0)
-        pSC = &sc;
-    pSC->thread_number = hn;
-    Object** startIndex  = SegQueue (FinalizerStartSeg);
-    Object** stopIndex  = SegQueueLimit (FinalizerMaxSeg);
-    for (Object** po = startIndex; po < stopIndex; po++)
-    {
-        Object* o = *po;
-        dprintf (3, ("scan f %zx", (size_t)o));
-        (*fn)(po, pSC, 0);
-    }
-}
-void CFinalize::WalkFReachableObjects (fq_walk_fn fn)
-{
-    Object** startIndex = SegQueue (FinalizerListSeg);
-    Object** stopIndex = SegQueueLimit (FinalizerListSeg);
-    for (Object** po = startIndex; po < stopIndex; po++)
-    {
-        bool isCriticalFinalizer = false;
-        fn(isCriticalFinalizer, *po);
-    }
-    startIndex = SegQueue (CriticalFinalizerListSeg);
-    stopIndex = SegQueueLimit (CriticalFinalizerListSeg);
-    for (Object** po = startIndex; po < stopIndex; po++)
-    {
-        bool isCriticalFinalizer = true;
-        fn(isCriticalFinalizer, *po);
-    }
-}
-BOOL
-CFinalize::ScanForFinalization (promote_func* pfn, int gen, gc_heap* hp)
-{
-    ScanContext sc;
-    sc.promotion = TRUE;
-#ifdef MULTIPLE_HEAPS
-    sc.thread_number = hp->heap_number;
-    sc.thread_count = gc_heap::n_heaps;
-#else
-    UNREFERENCED_PARAMETER(hp);
-    sc.thread_count = 1;
-#endif //MULTIPLE_HEAPS
-    BOOL finalizedFound = FALSE;
-    unsigned int startSeg = gen_segment (gen);
-    {
-        m_PromotedCount = 0;
-        for (unsigned int Seg = startSeg; Seg <= gen_segment(0); Seg++)
-        {
-            Object** endIndex = SegQueue (Seg);
-            for (Object** i = SegQueueLimit (Seg)-1; i >= endIndex ;i--)
-            {
-                CObjectHeader* obj = (CObjectHeader*)*i;
-                dprintf (3, ("scanning: %zx", (size_t)obj));
-                if (!g_theGCHeap->IsPromoted (obj))
-                {
-                    dprintf (3, ("freacheable: %zx", (size_t)obj));
-                    assert (method_table(obj)->HasFinalizer());
-                    if (GCToEEInterface::EagerFinalized(obj))
-                    {
-                        MoveItem (i, Seg, FreeListSeg);
-                    }
-                    else if ((obj->GetHeader()->GetBits()) & BIT_SBLK_FINALIZER_RUN)
-                    {
-                        MoveItem (i, Seg, FreeListSeg);
-                        obj->GetHeader()->ClrBit (BIT_SBLK_FINALIZER_RUN);
-                    }
-                    else
-                    {
-                        m_PromotedCount++;
-                        if (method_table(obj)->HasCriticalFinalizer())
-                        {
-                            MoveItem (i, Seg, CriticalFinalizerListSeg);
-                        }
-                        else
-                        {
-                            MoveItem (i, Seg, FinalizerListSeg);
-                        }
-                    }
-                }
-#ifdef BACKGROUND_GC
-                else
-                {
-                    if ((gen == max_generation) && (gc_heap::background_running_p()))
-                    {
-                        dprintf (3, ("%zx is marked", (size_t)obj));
-                    }
-                }
-#endif //BACKGROUND_GC
-            }
-        }
-    }
-    finalizedFound = !IsSegEmpty(FinalizerListSeg) ||
-                     !IsSegEmpty(CriticalFinalizerListSeg);
-    if (finalizedFound)
-    {
-        GcScanRoots (pfn,
-#ifdef MULTIPLE_HEAPS
-                     hp->heap_number
-#else
-                     0
-#endif //MULTIPLE_HEAPS
-                     , 0);
-        hp->settings.found_finalizers = TRUE;
-#ifdef BACKGROUND_GC
-        if (hp->settings.concurrent)
-        {
-            hp->settings.found_finalizers = !(IsSegEmpty(FinalizerListSeg) && IsSegEmpty(CriticalFinalizerListSeg));
-        }
-#endif //BACKGROUND_GC
-        if (hp->settings.concurrent && hp->settings.found_finalizers)
-        {
-            GCToEEInterface::EnableFinalization(true);
-        }
-    }
-    return finalizedFound;
-}
-void
-CFinalize::RelocateFinalizationData (int gen, gc_heap* hp)
-{
-    ScanContext sc;
-    sc.promotion = FALSE;
-#ifdef MULTIPLE_HEAPS
-    sc.thread_number = hp->heap_number;
-    sc.thread_count = gc_heap::n_heaps;
-#else
-    UNREFERENCED_PARAMETER(hp);
-    sc.thread_count = 1;
-#endif //MULTIPLE_HEAPS
-    unsigned int Seg = gen_segment (gen);
-    Object** startIndex = SegQueue (Seg);
-    dprintf (3, ("RelocateFinalizationData gen=%d, [%p,%p[", gen, startIndex, SegQueue (FreeList)));
-    for (Object** po = startIndex; po < SegQueue (FreeList);po++)
-    {
-        GCHeap::Relocate (po, &sc);
-    }
-}
-void
-CFinalize::UpdatePromotedGenerations (int gen, BOOL gen_0_empty_p)
-{
-    dprintf(3, ("UpdatePromotedGenerations gen=%d, gen_0_empty_p=%d", gen, gen_0_empty_p));
-    if (gen_0_empty_p)
-    {
-        for (int i = min (gen+1, (int)max_generation); i > 0; i--)
-        {
-            m_FillPointers [gen_segment(i)] = m_FillPointers [gen_segment(i-1)];
-        }
-    }
-    else
-    {
-        for (int i = gen; i >= 0; i--)
-        {
-            unsigned int Seg = gen_segment (i);
-            Object** startIndex = SegQueue (Seg);
-            for (Object** po = startIndex;
-                 po < SegQueueLimit (gen_segment(i)); po++)
-            {
-                int new_gen = g_theGCHeap->WhichGeneration (*po);
-                if (new_gen != i)
-                {
-                    assert (new_gen <= max_generation);
-                    dprintf (3, ("Moving object %p->%p from gen %d to gen %d", po, *po, i, new_gen));
-                    if (new_gen > i)
-                    {
-                        MoveItem (po, gen_segment (i), gen_segment (new_gen));
-                    }
-                    else
-                    {
-                        MoveItem (po, gen_segment (i), gen_segment (new_gen));
-                        po--;
-                    }
-                }
-            }
-        }
-    }
-}
-BOOL
-CFinalize::GrowArray()
-{
-    size_t oldArraySize = (m_EndArray - m_Array);
-    size_t newArraySize =  (size_t)(((float)oldArraySize / 10) * 12);
-    Object** newArray = new (nothrow) Object*[newArraySize];
-    if (!newArray)
-    {
-        return FALSE;
-    }
-    memcpy (newArray, m_Array, oldArraySize*sizeof(Object*));
-    dprintf (3, ("Grow finalizer array [%p,%p[ -> [%p,%p[", m_Array, m_EndArray, newArray, &m_Array[newArraySize]));
-    for (int i = 0; i < FreeList; i++)
-    {
-        m_FillPointers [i] += (newArray - m_Array);
-    }
-    delete[] m_Array;
-    m_Array = newArray;
-    m_EndArray = &m_Array [newArraySize];
-    return TRUE;
-}
-bool CFinalize::MergeFinalizationData (CFinalize* other_fq)
-{
-    size_t otherNeededArraySize = other_fq->UsedCount();
-    if (otherNeededArraySize == 0)
-    {
-        return true;
-    }
-    size_t thisArraySize = (m_EndArray - m_Array);
-    size_t thisNeededArraySize = UsedCount();
-    size_t neededArraySize = thisNeededArraySize + otherNeededArraySize;
-    Object ** newArray = m_Array;
-    if (thisArraySize < neededArraySize)
-    {
-        newArray = new (nothrow) Object*[neededArraySize];
-        if (!newArray)
-        {
-            dprintf (3, ("ran out of space merging finalization data"));
-            return false;
-        }
-    }
-    for (int i = FreeList - 1; i >= 0; i--)
-    {
-        size_t thisIndex = SegQueue (i) - m_Array;
-        size_t otherIndex = other_fq->SegQueue (i) - other_fq->m_Array;
-        size_t thisLimit = SegQueueLimit (i) - m_Array;
-        size_t otherLimit = other_fq->SegQueueLimit (i) - other_fq->m_Array;
-        size_t thisSize = thisLimit - thisIndex;
-        size_t otherSize = otherLimit - otherIndex;
-        memmove (&newArray[thisIndex + otherIndex],           &m_Array[thisIndex ], sizeof(newArray[0])*thisSize );
-        memmove (&newArray[thisLimit + otherIndex], &other_fq->m_Array[otherIndex], sizeof(newArray[0])*otherSize);
-    }
-    for (int i = FreeList - 1; i >= 0; i--)
-    {
-        size_t thisLimit = SegQueueLimit (i) - m_Array;
-        size_t otherLimit = other_fq->SegQueueLimit (i) - other_fq->m_Array;
-        SegQueueLimit (i) = &newArray[thisLimit + otherLimit];
-        other_fq->SegQueueLimit (i) = other_fq->m_Array;
-    }
-    if (m_Array != newArray)
-    {
-        delete[] m_Array;
-        m_Array = newArray;
-        m_EndArray = &m_Array [neededArraySize];
-    }
-    return true;
-}
-bool CFinalize::SplitFinalizationData (CFinalize* other_fq)
-{
-    size_t otherCurrentArraySize = other_fq->UsedCount();
-    assert (otherCurrentArraySize == 0);
-    size_t thisCurrentArraySize = UsedCount();
-    if (thisCurrentArraySize == 0)
-    {
-        return true;
-    }
-    size_t otherNeededArraySize = thisCurrentArraySize / 2;
-    size_t otherArraySize = other_fq->m_EndArray - other_fq->m_Array;
-    if (otherArraySize < otherNeededArraySize)
-    {
-        Object ** newArray = new (nothrow) Object*[otherNeededArraySize];
-        if (!newArray)
-        {
-            return false;
-        }
-        delete[] other_fq->m_Array;
-        other_fq->m_Array = newArray;
-        other_fq->m_EndArray = &other_fq->m_Array[otherNeededArraySize];
-    }
-    PTR_PTR_Object newFillPointers[MaxSeg];
-    PTR_PTR_Object segQueue = m_Array;
-    for (int i = 0; i < FreeList; i++)
-    {
-        size_t thisIndex = SegQueue (i) - m_Array;
-        size_t thisLimit = SegQueueLimit (i) - m_Array;
-        size_t thisSize = thisLimit - thisIndex;
-        size_t otherSize = thisSize / 2;
-        size_t otherIndex = other_fq->SegQueue (i) - other_fq->m_Array;
-        size_t thisNewSize = thisSize - otherSize;
-        memmove (&other_fq->m_Array[otherIndex], &m_Array[thisIndex + thisNewSize], sizeof(other_fq->m_Array[0])*otherSize);
-        other_fq->SegQueueLimit (i) = &other_fq->m_Array[otherIndex + otherSize];
-        memmove (segQueue, &m_Array[thisIndex], sizeof(m_Array[0])*thisNewSize);
-        segQueue += thisNewSize;
-        newFillPointers[i] = segQueue;
-    }
-    for (int i = 0; i < MaxSeg; i++)
-    {
-        m_FillPointers[i] = newFillPointers[i];
-    }
-    return true;
-}
-#ifdef VERIFY_HEAP
-void CFinalize::CheckFinalizerObjects()
-{
-    for (int i = 0; i <= max_generation; i++)
-    {
-        Object **startIndex = SegQueue (gen_segment (i));
-        Object **stopIndex  = SegQueueLimit (gen_segment (i));
-        for (Object **po = startIndex; po < stopIndex; po++)
-        {
-            if ((int)g_theGCHeap->WhichGeneration (*po) < i)
-                FATAL_GC_ERROR ();
-            ((CObjectHeader*)*po)->Validate();
-        }
-    }
-}
-#endif //VERIFY_HEAP
-#endif // FEATURE_PREMORTEM_FINALIZATION
-void gc_heap::walk_heap_per_heap (walk_fn fn, void* context, int gen_number, BOOL walk_large_object_heap_p)
-{
-    generation* gen = gc_heap::generation_of (gen_number);
-    heap_segment*    seg = generation_start_segment (gen);
-    uint8_t* x = ((gen_number == max_generation) ? heap_segment_mem (seg) : get_soh_start_object (seg, gen));
-    uint8_t*       end = heap_segment_allocated (seg);
-    int align_const = get_alignment_constant (TRUE);
-    BOOL walk_pinned_object_heap = walk_large_object_heap_p;
-    while (1)
-    {
-        if (x >= end)
-        {
-            if ((seg = heap_segment_next (seg)) != 0)
-            {
-                x = heap_segment_mem (seg);
-                end = heap_segment_allocated (seg);
-                continue;
-            }
-#ifdef USE_REGIONS
-            else if (gen_number > 0)
-            {
-                gen_number--;
-                gen = gc_heap::generation_of (gen_number);
-                seg = generation_start_segment (gen);
-                x = heap_segment_mem (seg);
-                end = heap_segment_allocated (seg);
-                continue;
-            }
-#endif // USE_REGIONS
-            else
-            {
-                if (walk_large_object_heap_p)
-                {
-                    walk_large_object_heap_p = FALSE;
-                    seg = generation_start_segment (large_object_generation);
-                }
-                else if (walk_pinned_object_heap)
-                {
-                    walk_pinned_object_heap = FALSE;
-                    seg = generation_start_segment (pinned_object_generation);
-                }
-                else
-                {
-                    break;
-                }
-                align_const = get_alignment_constant (FALSE);
-                x = heap_segment_mem (seg);
-                end = heap_segment_allocated (seg);
-                continue;
-            }
-        }
-        size_t s = size (x);
-        CObjectHeader* o = (CObjectHeader*)x;
-        if (!o->IsFree())
-        {
-            _ASSERTE(((size_t)o & 0x3) == 0); // Last two bits should never be set at this point
-            if (!fn (o->GetObjectBase(), context))
-                return;
-        }
-        x = x + Align (s, align_const);
-    }
-}
-void gc_heap::walk_finalize_queue (fq_walk_fn fn)
-{
-#ifdef FEATURE_PREMORTEM_FINALIZATION
-    finalize_queue->WalkFReachableObjects (fn);
-#endif //FEATURE_PREMORTEM_FINALIZATION
-}
-void gc_heap::walk_heap (walk_fn fn, void* context, int gen_number, BOOL walk_large_object_heap_p)
-{
-#ifdef MULTIPLE_HEAPS
-    for (int hn = 0; hn < gc_heap::n_heaps; hn++)
-    {
-        gc_heap* hp = gc_heap::g_heaps [hn];
-        hp->walk_heap_per_heap (fn, context, gen_number, walk_large_object_heap_p);
-    }
-#else
-    walk_heap_per_heap(fn, context, gen_number, walk_large_object_heap_p);
-#endif //MULTIPLE_HEAPS
-}
-void GCHeap::DiagWalkObject (Object* obj, walk_fn fn, void* context)
-{
-    uint8_t* o = (uint8_t*)obj;
-    if (o)
-    {
-        go_through_object_cl (method_table (o), o, size(o), oo,
-                                    {
-                                        if (*oo)
-                                        {
-                                            Object *oh = (Object*)*oo;
-                                            if (!fn (oh, context))
-                                                return;
-                                        }
-                                    }
-            );
-    }
-}
-void GCHeap::DiagWalkObject2 (Object* obj, walk_fn2 fn, void* context)
-{
-    uint8_t* o = (uint8_t*)obj;
-    if (o)
-    {
-        go_through_object_cl (method_table (o), o, size(o), oo,
-                                    {
-                                        if (*oo)
-                                        {
-                                            if (!fn (obj, oo, context))
-                                                return;
-                                        }
-                                    }
-            );
-    }
-}
-void GCHeap::DiagWalkSurvivorsWithType (void* gc_context, record_surv_fn fn, void* diag_context, walk_surv_type type, int gen_number)
-{
-    gc_heap* hp = (gc_heap*)gc_context;
-    if (type == walk_for_uoh)
-    {
-        hp->walk_survivors_for_uoh (diag_context, fn, gen_number);
-    }
-    else
-    {
-        hp->walk_survivors (fn, diag_context, type);
-    }
-}
-void GCHeap::DiagWalkHeap (walk_fn fn, void* context, int gen_number, bool walk_large_object_heap_p)
-{
-    gc_heap::walk_heap (fn, context, gen_number, walk_large_object_heap_p);
-}
-void GCHeap::DiagWalkHeapWithACHandling (walk_fn fn, void* context, int gen_number, bool walk_large_object_heap_p)
-{
-#ifdef MULTIPLE_HEAPS
-    for (int hn = 0; hn < gc_heap::n_heaps; hn++)
-    {
-        gc_heap* hp = gc_heap::g_heaps [hn];
-#else
-    {
-        gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-        hp->fix_allocation_contexts (FALSE);
-    }
-    DiagWalkHeap (fn, context, gen_number, walk_large_object_heap_p);
-#ifdef MULTIPLE_HEAPS
-    for (int hn = 0; hn < gc_heap::n_heaps; hn++)
-    {
-        gc_heap* hp = gc_heap::g_heaps [hn];
-#else
-    {
-        gc_heap* hp = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-        hp->repair_allocation_contexts (TRUE);
-    }
-}
-void GCHeap::DiagWalkFinalizeQueue (void* gc_context, fq_walk_fn fn)
-{
-    gc_heap* hp = (gc_heap*)gc_context;
-    hp->walk_finalize_queue (fn);
-}
-void GCHeap::DiagScanFinalizeQueue (fq_scan_fn fn, ScanContext* sc)
-{
-#ifdef MULTIPLE_HEAPS
-    for (int hn = 0; hn < gc_heap::n_heaps; hn++)
-    {
-        gc_heap* hp = gc_heap::g_heaps [hn];
-        hp->finalize_queue->GcScanRoots(fn, hn, sc);
-    }
-#else
-        pGenGCHeap->finalize_queue->GcScanRoots(fn, 0, sc);
-#endif //MULTIPLE_HEAPS
-}
-void GCHeap::DiagScanHandles (handle_scan_fn fn, int gen_number, ScanContext* context)
-{
-    GCScan::GcScanHandlesForProfilerAndETW (gen_number, context, fn);
-}
-void GCHeap::DiagScanDependentHandles (handle_scan_fn fn, int gen_number, ScanContext* context)
-{
-    GCScan::GcScanDependentHandlesForProfilerAndETW (gen_number, context, fn);
-}
-size_t GCHeap::GetLOHThreshold()
-{
-    return loh_size_threshold;
-}
-void GCHeap::DiagGetGCSettings(EtwGCSettingsInfo* etw_settings)
-{
-#ifdef FEATURE_EVENT_TRACE
-    etw_settings->heap_hard_limit = gc_heap::heap_hard_limit;
-    etw_settings->loh_threshold = loh_size_threshold;
-    etw_settings->physical_memory_from_config = gc_heap::physical_memory_from_config;
-    etw_settings->gen0_min_budget_from_config = gc_heap::gen0_min_budget_from_config;
-    etw_settings->gen0_max_budget_from_config = gc_heap::gen0_max_budget_from_config;
-    etw_settings->high_mem_percent_from_config = gc_heap::high_mem_percent_from_config;
-#ifdef BACKGROUND_GC
-    etw_settings->concurrent_gc_p = gc_heap::gc_can_use_concurrent;
-#else
-    etw_settings->concurrent_gc_p = false;
-#endif //BACKGROUND_GC
-    etw_settings->use_large_pages_p = gc_heap::use_large_pages_p;
-    etw_settings->use_frozen_segments_p = gc_heap::use_frozen_segments_p;
-    etw_settings->hard_limit_config_p = gc_heap::hard_limit_config_p;
-    etw_settings->no_affinitize_p =
-#ifdef MULTIPLE_HEAPS
-        gc_heap::gc_thread_no_affinitize_p;
-#else
-        true;
-#endif //MULTIPLE_HEAPS
-#endif //FEATURE_EVENT_TRACE
-}
-#if defined(WRITE_BARRIER_CHECK) && !defined (SERVER_GC)
-void deleteGCShadow()
-{
-    if (g_GCShadow != 0)
-        GCToOSInterface::VirtualRelease (g_GCShadow, g_GCShadowEnd - g_GCShadow);
-    g_GCShadow = 0;
-    g_GCShadowEnd = 0;
-}
-void initGCShadow()
-{
-    if (!(GCConfig::GetHeapVerifyLevel() & GCConfig::HEAPVERIFY_BARRIERCHECK))
-        return;
-    uint8_t* highest = nullptr;
-#ifdef USE_REGIONS
-    highest = global_region_allocator.get_left_used_unsafe();
-#else
-    highest = g_gc_highest_address;
-#endif
-    size_t len = g_gc_highest_address - g_gc_lowest_address;
-    size_t commit_len = highest - g_gc_lowest_address;
-    if (len > (size_t)(g_GCShadowEnd - g_GCShadow))
-    {
-        deleteGCShadow();
-        g_GCShadowEnd = g_GCShadow = (uint8_t *)GCToOSInterface::VirtualReserve (len, 0, VirtualReserveFlags::None);
-        if (g_GCShadow == NULL || !GCToOSInterface::VirtualCommit (g_GCShadow, commit_len))
-        {
-            _ASSERTE(!"Not enough memory to run HeapVerify level 2");
-            deleteGCShadow();
-            return;
-        }
-        g_GCShadowEnd += commit_len;
-    }
-    g_shadow_lowest_address = g_gc_lowest_address;
-    for (int i = get_start_generation_index(); i < total_generation_count; i++)
-    {
-        generation* gen = gc_heap::generation_of (i);
-        heap_segment* seg = heap_segment_rw (generation_start_segment (gen));
-        ptrdiff_t delta = g_GCShadow - g_gc_lowest_address;
-        while (seg)
-        {
-            uint8_t* start = heap_segment_mem (seg);
-            uint8_t* end = heap_segment_allocated (seg);
-            memcpy (start + delta, start, end - start);
-            seg = heap_segment_next_rw (seg);
-        }
-    }
-}
-#define INVALIDGCVALUE (void*)((size_t)0xcccccccd)
-inline void testGCShadow(Object** ptr)
-{
-    Object** shadow = (Object**) &g_GCShadow[((uint8_t*) ptr - g_gc_lowest_address)];
-    if (*ptr != 0 && (uint8_t*) shadow < g_GCShadowEnd && *ptr != *shadow)
-    {
-        if(*shadow!=INVALIDGCVALUE)
-        {
-#ifdef FEATURE_BASICFREEZE
-            if (!g_theGCHeap->IsInFrozenSegment (*ptr))
-#endif // FEATURE_BASICFREEZE
-            {
-                _ASSERTE(!"Pointer updated without using write barrier");
-            }
-        }
-        /*
-        else
-        {
-             printf("saw a INVALIDGCVALUE. (just to let you know)\n");
-        }
-        */
-    }
-}
-void testGCShadowHelper (uint8_t* x)
-{
-    size_t s = size (x);
-    if (contain_pointers (x))
-    {
-        go_through_object_nostart (method_table(x), x, s, oo,
-                           { testGCShadow((Object**) oo); });
-    }
-}
-void checkGCWriteBarrier()
-{
-    if (g_GCShadowEnd <= g_GCShadow || g_shadow_lowest_address != g_gc_lowest_address)
-    {
-        return;
-    }
-    for (int i = get_start_generation_index(); i < total_generation_count; i++)
-    {
-        int alignment = get_alignment_constant(i <= max_generation);
-        {
-            generation* gen = gc_heap::generation_of (i);
-            heap_segment* seg = heap_segment_rw (generation_start_segment (gen));
-            PREFIX_ASSUME(seg != NULL);
-            while(seg)
-            {
-                uint8_t* x = heap_segment_mem (seg);
-                while (x < heap_segment_allocated (seg))
-                {
-                    size_t s = size (x);
-                    testGCShadowHelper (x);
-                    x = x + Align (s, alignment);
-                }
-                seg = heap_segment_next_rw (seg);
-            }
-        }
-    }
-}
-#endif //WRITE_BARRIER_CHECK && !SERVER_GC
-#ifdef FEATURE_BASICFREEZE
-void gc_heap::walk_read_only_segment(heap_segment *seg, void *pvContext, object_callback_func pfnMethodTable, object_callback_func pfnObjRef)
-{
-    uint8_t *o = heap_segment_mem(seg);
-    int alignment = get_alignment_constant(TRUE);
-    while (o < heap_segment_allocated(seg))
-    {
-        pfnMethodTable(pvContext, o);
-        if (contain_pointers (o))
-        {
-            go_through_object_nostart (method_table (o), o, size(o), oo,
-                   {
-                       if (*oo)
-                           pfnObjRef(pvContext, oo);
-                   }
-            );
-        }
-        o += Align(size(o), alignment);
-    }
-}
-#endif // FEATURE_BASICFREEZE
-HRESULT GCHeap::WaitUntilConcurrentGCCompleteAsync(int millisecondsTimeout)
-{
-#ifdef BACKGROUND_GC
-    if (gc_heap::background_running_p())
-    {
-        uint32_t dwRet = pGenGCHeap->background_gc_wait(awr_ignored, millisecondsTimeout);
-        if (dwRet == WAIT_OBJECT_0)
-            return S_OK;
-        else if (dwRet == WAIT_TIMEOUT)
-            return HRESULT_FROM_WIN32(ERROR_TIMEOUT);
-        else
-            return E_FAIL;      // It is not clear if what the last error would be if the wait failed,
-    }
-#endif
-    return S_OK;
-}
-void GCHeap::TemporaryEnableConcurrentGC()
-{
-#ifdef BACKGROUND_GC
-    gc_heap::temp_disable_concurrent_p = false;
-#endif //BACKGROUND_GC
-}
-void GCHeap::TemporaryDisableConcurrentGC()
-{
-#ifdef BACKGROUND_GC
-    gc_heap::temp_disable_concurrent_p = true;
-#endif //BACKGROUND_GC
-}
-bool GCHeap::IsConcurrentGCEnabled()
-{
-#ifdef BACKGROUND_GC
-    return (gc_heap::gc_can_use_concurrent && !(gc_heap::temp_disable_concurrent_p));
-#else
-    return FALSE;
-#endif //BACKGROUND_GC
-}
-void PopulateDacVars(GcDacVars *gcDacVars)
-{
-    bool v2 = gcDacVars->minor_version_number >= 2;
-#define DEFINE_FIELD(field_name, field_type) offsetof(CLASS_NAME, field_name),
-#define DEFINE_DPTR_FIELD(field_name, field_type) offsetof(CLASS_NAME, field_name),
-#define DEFINE_ARRAY_FIELD(field_name, field_type, array_length) offsetof(CLASS_NAME, field_name),
-#define DEFINE_MISSING_FIELD(field_name) -1,
-#ifdef MULTIPLE_HEAPS
-    static int gc_heap_field_offsets[] = {
-#define CLASS_NAME gc_heap
-#include "dac_gcheap_fields.h"
-#undef CLASS_NAME
-    };
-#endif //MULTIPLE_HEAPS
-    static int generation_field_offsets[] = {
-#define CLASS_NAME generation
-#include "dac_generation_fields.h"
-#undef CLASS_NAME
-#undef DEFINE_MISSING_FIELD
-#undef DEFINE_ARRAY_FIELD
-#undef DEFINE_DPTR_FIELD
-#undef DEFINE_FIELD
-    };
-    assert(gcDacVars != nullptr);
-    gcDacVars->major_version_number = 2;
-    gcDacVars->minor_version_number = 0;
-    if (v2)
-    {
-        gcDacVars->total_bookkeeping_elements = total_bookkeeping_elements;
-        gcDacVars->card_table_info_size = sizeof(card_table_info);
-    }
-#ifdef USE_REGIONS
-    gcDacVars->minor_version_number |= 1;
-    if (v2)
-    {
-        gcDacVars->count_free_region_kinds = count_free_region_kinds;
-        gcDacVars->global_regions_to_decommit = reinterpret_cast<dac_region_free_list**>(&gc_heap::global_regions_to_decommit);
-        gcDacVars->global_free_huge_regions = reinterpret_cast<dac_region_free_list**>(&gc_heap::global_free_huge_regions);
-    }
-#endif //USE_REGIONS
-#ifndef BACKGROUND_GC
-    gcDacVars->minor_version_number |= 2;
-#endif //!BACKGROUND_GC
-    gcDacVars->built_with_svr = &g_built_with_svr_gc;
-    gcDacVars->build_variant = &g_build_variant;
-    gcDacVars->gc_structures_invalid_cnt = const_cast<int32_t*>(&GCScan::m_GcStructuresInvalidCnt);
-    gcDacVars->generation_size = sizeof(generation);
-    gcDacVars->total_generation_count = total_generation_count;
-    gcDacVars->max_gen = &g_max_generation;
-#ifdef BACKGROUND_GC
-    gcDacVars->current_c_gc_state = const_cast<c_gc_state*>(&gc_heap::current_c_gc_state);
-#else //BACKGROUND_GC
-    gcDacVars->current_c_gc_state = 0;
-#endif //BACKGROUND_GC
-#ifndef MULTIPLE_HEAPS
-    gcDacVars->ephemeral_heap_segment = reinterpret_cast<dac_heap_segment**>(&gc_heap::ephemeral_heap_segment);
-#ifdef USE_REGIONS
-    if (v2)
-    {
-        gcDacVars->free_regions = reinterpret_cast<dac_region_free_list**>(&gc_heap::free_regions);
-    }
-#endif
-#ifdef BACKGROUND_GC
-    gcDacVars->mark_array = &gc_heap::mark_array;
-    gcDacVars->background_saved_lowest_address = &gc_heap::background_saved_lowest_address;
-    gcDacVars->background_saved_highest_address = &gc_heap::background_saved_highest_address;
-    if (v2)
-    {
-        gcDacVars->freeable_soh_segment = reinterpret_cast<dac_heap_segment**>(&gc_heap::freeable_soh_segment);
-        gcDacVars->freeable_uoh_segment = reinterpret_cast<dac_heap_segment**>(&gc_heap::freeable_uoh_segment);
-    }
-    gcDacVars->next_sweep_obj = &gc_heap::next_sweep_obj;
-#ifdef USE_REGIONS
-    gcDacVars->saved_sweep_ephemeral_seg = 0;
-    gcDacVars->saved_sweep_ephemeral_start = 0;
-#else
-    gcDacVars->saved_sweep_ephemeral_seg = reinterpret_cast<dac_heap_segment**>(&gc_heap::saved_sweep_ephemeral_seg);
-    gcDacVars->saved_sweep_ephemeral_start = &gc_heap::saved_sweep_ephemeral_start;
-#endif //USE_REGIONS
-#else //BACKGROUND_GC
-    gcDacVars->mark_array = 0;
-    gcDacVars->background_saved_lowest_address = 0;
-    gcDacVars->background_saved_highest_address = 0;
-    if (v2)
-    {
-        gcDacVars->freeable_soh_segment = 0;
-        gcDacVars->freeable_uoh_segment = 0;
-    }
-    gcDacVars->next_sweep_obj = 0;
-    gcDacVars->saved_sweep_ephemeral_seg = 0;
-    gcDacVars->saved_sweep_ephemeral_start = 0;
-#endif //BACKGROUND_GC
-    gcDacVars->alloc_allocated = &gc_heap::alloc_allocated;
-    gcDacVars->oom_info = &gc_heap::oom_info;
-    gcDacVars->finalize_queue = reinterpret_cast<dac_finalize_queue**>(&gc_heap::finalize_queue);
-    gcDacVars->generation_table = reinterpret_cast<unused_generation**>(&gc_heap::generation_table);
-#ifdef GC_CONFIG_DRIVEN
-    gcDacVars->gc_global_mechanisms = reinterpret_cast<size_t**>(&gc_global_mechanisms);
-    gcDacVars->interesting_data_per_heap = reinterpret_cast<size_t**>(&gc_heap::interesting_data_per_heap);
-    gcDacVars->compact_reasons_per_heap = reinterpret_cast<size_t**>(&gc_heap::compact_reasons_per_heap);
-    gcDacVars->expand_mechanisms_per_heap = reinterpret_cast<size_t**>(&gc_heap::expand_mechanisms_per_heap);
-    gcDacVars->interesting_mechanism_bits_per_heap = reinterpret_cast<size_t**>(&gc_heap::interesting_mechanism_bits_per_heap);
-#endif // GC_CONFIG_DRIVEN
-#ifdef HEAP_ANALYZE
-    gcDacVars->internal_root_array = &gc_heap::internal_root_array;
-    gcDacVars->internal_root_array_index = &gc_heap::internal_root_array_index;
-    gcDacVars->heap_analyze_success = &gc_heap::heap_analyze_success;
-#endif // HEAP_ANALYZE
-#else
-    gcDacVars->n_heaps = &gc_heap::n_heaps;
-    gcDacVars->g_heaps = reinterpret_cast<unused_gc_heap***>(&gc_heap::g_heaps);
-    gcDacVars->gc_heap_field_offsets = reinterpret_cast<int**>(&gc_heap_field_offsets);
-#endif // MULTIPLE_HEAPS
-    gcDacVars->generation_field_offsets = reinterpret_cast<int**>(&generation_field_offsets);
-    if (v2)
-    {
-        gcDacVars->bookkeeping_start = &gc_heap::bookkeeping_start;
-    }
-}
-int GCHeap::RefreshMemoryLimit()
-{
-    return gc_heap::refresh_memory_limit();
-}
-bool gc_heap::compute_hard_limit()
-{
-    heap_hard_limit_oh[soh] = 0;
-#ifdef HOST_64BIT
-    heap_hard_limit = (size_t)GCConfig::GetGCHeapHardLimit();
-    heap_hard_limit_oh[soh] = (size_t)GCConfig::GetGCHeapHardLimitSOH();
-    heap_hard_limit_oh[loh] = (size_t)GCConfig::GetGCHeapHardLimitLOH();
-    heap_hard_limit_oh[poh] = (size_t)GCConfig::GetGCHeapHardLimitPOH();
-    use_large_pages_p = GCConfig::GetGCLargePages();
-    if (heap_hard_limit_oh[soh] || heap_hard_limit_oh[loh] || heap_hard_limit_oh[poh])
-    {
-        if (!heap_hard_limit_oh[soh])
-        {
-            return false;
-        }
-        if (!heap_hard_limit_oh[loh])
-        {
-            return false;
-        }
-        heap_hard_limit = heap_hard_limit_oh[soh] +
-            heap_hard_limit_oh[loh] + heap_hard_limit_oh[poh];
-    }
-    else
-    {
-        uint32_t percent_of_mem_soh = (uint32_t)GCConfig::GetGCHeapHardLimitSOHPercent();
-        uint32_t percent_of_mem_loh = (uint32_t)GCConfig::GetGCHeapHardLimitLOHPercent();
-        uint32_t percent_of_mem_poh = (uint32_t)GCConfig::GetGCHeapHardLimitPOHPercent();
-        if (percent_of_mem_soh || percent_of_mem_loh || percent_of_mem_poh)
-        {
-            if ((percent_of_mem_soh <= 0) || (percent_of_mem_soh >= 100))
-            {
-                return false;
-            }
-            if ((percent_of_mem_loh <= 0) || (percent_of_mem_loh >= 100))
-            {
-                return false;
-            }
-            else if ((percent_of_mem_poh < 0) || (percent_of_mem_poh >= 100))
-            {
-                return false;
-            }
-            if ((percent_of_mem_soh + percent_of_mem_loh + percent_of_mem_poh) >= 100)
-            {
-                return false;
-            }
-            heap_hard_limit_oh[soh] = (size_t)(total_physical_mem * (uint64_t)percent_of_mem_soh / (uint64_t)100);
-            heap_hard_limit_oh[loh] = (size_t)(total_physical_mem * (uint64_t)percent_of_mem_loh / (uint64_t)100);
-            heap_hard_limit_oh[poh] = (size_t)(total_physical_mem * (uint64_t)percent_of_mem_poh / (uint64_t)100);
-            heap_hard_limit = heap_hard_limit_oh[soh] +
-                heap_hard_limit_oh[loh] + heap_hard_limit_oh[poh];
-        }
-    }
-    if (heap_hard_limit_oh[soh] && (!heap_hard_limit_oh[poh]) && (!use_large_pages_p))
-    {
-        return false;
-    }
-    if (!(heap_hard_limit))
-    {
-        uint32_t percent_of_mem = (uint32_t)GCConfig::GetGCHeapHardLimitPercent();
-        if ((percent_of_mem > 0) && (percent_of_mem < 100))
-        {
-            heap_hard_limit = (size_t)(total_physical_mem * (uint64_t)percent_of_mem / (uint64_t)100);
-        }
-    }
-#endif //HOST_64BIT
-    return true;
-}
-bool gc_heap::compute_memory_settings(bool is_initialization, uint32_t& nhp, uint32_t nhp_from_config, size_t& seg_size_from_config, size_t new_current_total_committed)
-{
-#ifdef HOST_64BIT
-    if (!hard_limit_config_p)
-    {
-        if (is_restricted_physical_mem)
-        {
-            uint64_t physical_mem_for_gc = total_physical_mem * (uint64_t)75 / (uint64_t)100;
-#ifndef USE_REGIONS
-            if (is_initialization)
-#endif //USE_REGIONS
-            {
-                heap_hard_limit = (size_t)max ((uint64_t)(20 * 1024 * 1024), physical_mem_for_gc);
-            }
-        }
-    }
-    if (heap_hard_limit && (heap_hard_limit < new_current_total_committed))
-    {
-        return false;
-    }
-#endif //HOST_64BIT
-#ifdef USE_REGIONS
-    {
-#else
-    if (is_initialization)
-    {
-#endif //USE_REGIONS
-        if (heap_hard_limit)
-        {
-            if (is_initialization && (!nhp_from_config))
-            {
-                nhp = adjust_heaps_hard_limit (nhp);
-            }
-            seg_size_from_config = (size_t)GCConfig::GetSegmentSize();
-            if (seg_size_from_config)
-            {
-                seg_size_from_config = adjust_segment_size_hard_limit_va (seg_size_from_config);
-            }
-            size_t limit_to_check = (heap_hard_limit_oh[soh] ? heap_hard_limit_oh[soh] : heap_hard_limit);
-            soh_segment_size = max (adjust_segment_size_hard_limit (limit_to_check, nhp), seg_size_from_config);
-        }
-        else
-        {
-            soh_segment_size = get_valid_segment_size();
-        }
-    }
-    mem_one_percent = total_physical_mem / 100;
-#ifndef MULTIPLE_HEAPS
-    mem_one_percent /= g_num_processors;
-#endif //!MULTIPLE_HEAPS
-    uint32_t highmem_th_from_config = (uint32_t)GCConfig::GetGCHighMemPercent();
-    if (highmem_th_from_config)
-    {
-        high_memory_load_th = min (99u, highmem_th_from_config);
-        v_high_memory_load_th = min (99u, (highmem_th_from_config + 7));
-#ifdef FEATURE_EVENT_TRACE
-        high_mem_percent_from_config = highmem_th_from_config;
-#endif //FEATURE_EVENT_TRACE
-    }
-    else
-    {
-        int available_mem_th = 10;
-        if (total_physical_mem >= ((uint64_t)80 * 1024 * 1024 * 1024))
-        {
-            int adjusted_available_mem_th = 3 + (int)((float)47 / (float)g_num_processors);
-            available_mem_th = min (available_mem_th, adjusted_available_mem_th);
-        }
-        high_memory_load_th = 100 - available_mem_th;
-        v_high_memory_load_th = 97;
-    }
-    m_high_memory_load_th = min ((high_memory_load_th + 5), v_high_memory_load_th);
-    return true;
-}
-size_t gc_heap::compute_committed_bytes_per_heap(int oh, size_t& committed_bookkeeping)
-{
-#ifdef USE_REGIONS
-    int start_generation = (oh == 0) ? 0 : oh + max_generation;
-#else
-    int start_generation = oh + max_generation;
-#endif
-    int end_generation = oh + max_generation;
-    size_t total_committed_per_heap = 0;
-    for (int gen = start_generation; gen <= end_generation; gen++)
-    {
-        accumulate_committed_bytes (generation_start_segment (generation_of (gen)), total_committed_per_heap, committed_bookkeeping);
-    }
-#ifdef BACKGROUND_GC
-    if (oh == soh)
-    {
-        accumulate_committed_bytes (freeable_soh_segment, total_committed_per_heap, committed_bookkeeping);
-    }
-    else
-#endif //BACKGROUND_GC
-    {
-        accumulate_committed_bytes (freeable_uoh_segment, total_committed_per_heap, committed_bookkeeping, (gc_oh_num)oh);
-    }
-    return total_committed_per_heap;
-}
-void gc_heap::compute_committed_bytes(size_t& total_committed, size_t& committed_decommit, size_t& committed_free,
-                                      size_t& committed_bookkeeping, size_t& new_current_total_committed, size_t& new_current_total_committed_bookkeeping,
-                                      size_t* new_committed_by_oh)
-{
-    for (int oh = soh; oh < total_oh_count; oh++)
-    {
-        size_t total_committed_per_oh = 0;
-#ifdef MULTIPLE_HEAPS
-        for (int h = 0; h < n_heaps; h++)
-        {
-            gc_heap* heap = g_heaps[h];
-#else
-        {
-            gc_heap* heap = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-            size_t total_committed_per_heap = heap->compute_committed_bytes_per_heap (oh, committed_bookkeeping);
-#if defined(MULTIPLE_HEAPS) && defined(_DEBUG)
-            heap->committed_by_oh_per_heap_refresh[oh] = total_committed_per_heap;
-#endif // MULTIPLE_HEAPS && _DEBUG
-            total_committed_per_oh += total_committed_per_heap;
-        }
-        new_committed_by_oh[oh] = total_committed_per_oh;
-        total_committed += total_committed_per_oh;
-    }
-#ifdef USE_REGIONS
-    size_t committed_old_free = 0;
-    committed_free = 0;
-#ifdef MULTIPLE_HEAPS
-    for (int h = 0; h < n_heaps; h++)
-    {
-        gc_heap* heap = g_heaps[h];
-#else
-    {
-        gc_heap* heap = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-        for (int i = 0; i < count_free_region_kinds; i++)
-        {
-            heap_segment* seg = heap->free_regions[i].get_first_free_region();
-            heap->accumulate_committed_bytes (seg, committed_free, committed_bookkeeping);
-        }
-    }
-    committed_old_free += committed_free;
-    committed_decommit = 0;
-    for (int i = 0; i < count_free_region_kinds; i++)
-    {
-        heap_segment* seg = global_regions_to_decommit[i].get_first_free_region();
-#ifdef MULTIPLE_HEAPS
-        gc_heap* heap = g_heaps[0];
-#else
-        gc_heap* heap = nullptr;
-#endif //MULTIPLE_HEAPS
-        heap->accumulate_committed_bytes (seg, committed_decommit, committed_bookkeeping);
-    }
-    committed_old_free += committed_decommit;
-    {
-        heap_segment* seg = global_free_huge_regions.get_first_free_region();
-#ifdef MULTIPLE_HEAPS
-        gc_heap* heap = g_heaps[0];
-#else
-        gc_heap* heap = pGenGCHeap;
-#endif //MULTIPLE_HEAPS
-        heap->accumulate_committed_bytes (seg, committed_old_free, committed_bookkeeping);
-    }
-    new_committed_by_oh[recorded_committed_free_bucket] = committed_old_free;
-    total_committed += committed_old_free;
-    uint8_t* commit_begins[total_bookkeeping_elements];
-    size_t commit_sizes[total_bookkeeping_elements];
-    size_t new_sizes[total_bookkeeping_elements];
-    bool get_card_table_commit_layout_result = get_card_table_commit_layout(g_gc_lowest_address, bookkeeping_covered_committed, commit_begins, commit_sizes, new_sizes);
-    assert (get_card_table_commit_layout_result);
-    for (int i = card_table_element; i <= seg_mapping_table_element; i++)
-    {
-        assert (commit_sizes[i] >= 0);
-        committed_bookkeeping += commit_sizes[i];
-    }
-    new_current_total_committed_bookkeeping = committed_bookkeeping;
-    new_committed_by_oh[recorded_committed_bookkeeping_bucket] = committed_bookkeeping;
-#else
-    new_committed_by_oh[recorded_committed_ignored_bucket] = committed_free = 0;
-    uint32_t* ct = &g_gc_card_table[card_word (gcard_of (g_gc_lowest_address))];
-    while (ct)
-    {
-        uint8_t* lowest = card_table_lowest_address (ct);
-        uint8_t* highest = card_table_highest_address (ct);
-        get_card_table_element_layout(lowest, highest, card_table_element_layout);
-        size_t result = card_table_element_layout[seg_mapping_table_element + 1];
-        committed_bookkeeping += result;
-        ct = card_table_next (ct);
-    }
-    new_committed_by_oh[recorded_committed_bookkeeping_bucket] = new_current_total_committed_bookkeeping = committed_bookkeeping;
-#endif //USE_REGIONS
-    total_committed += committed_bookkeeping;
-    new_current_total_committed = total_committed;
-}
-int gc_heap::refresh_memory_limit()
-{
-    refresh_memory_limit_status status = refresh_success;
-    if (GCConfig::GetGCTotalPhysicalMemory() != 0)
-    {
-        return (int)status;
-    }
-    GCToEEInterface::SuspendEE(SUSPEND_FOR_GC);
-    uint32_t nhp_from_config = static_cast<uint32_t>(GCConfig::GetHeapCount());
-#ifdef MULTIPLE_HEAPS
-    uint32_t nhp = n_heaps;
-#else
-    uint32_t nhp = 1;
-#endif //MULTIPLE_HEAPS
-    size_t seg_size_from_config;
-    bool old_is_restricted_physical_mem = is_restricted_physical_mem;
-    uint64_t old_total_physical_mem = total_physical_mem;
-    size_t old_heap_hard_limit = heap_hard_limit;
-    size_t old_heap_hard_limit_soh = heap_hard_limit_oh[soh];
-    size_t old_heap_hard_limit_loh = heap_hard_limit_oh[loh];
-    size_t old_heap_hard_limit_poh = heap_hard_limit_oh[poh];
-    bool old_hard_limit_config_p = hard_limit_config_p;
-    total_physical_mem = GCToOSInterface::GetPhysicalMemoryLimit (&is_restricted_physical_mem);
-    bool succeed = true;
-#ifdef USE_REGIONS
-    GCConfig::RefreshHeapHardLimitSettings();
-    if (!compute_hard_limit())
-    {
-        succeed = false;
-        status = refresh_hard_limit_invalid;
-    }
-    hard_limit_config_p = heap_hard_limit != 0;
-#else
-    size_t new_current_total_committed = 0;
-#endif //USE_REGIONS
-    if (succeed && !compute_memory_settings(false, nhp, nhp_from_config, seg_size_from_config, current_total_committed))
-    {
-        succeed = false;
-        status = refresh_hard_limit_too_low;
-    }
-    if (!succeed)
-    {
-        is_restricted_physical_mem = old_is_restricted_physical_mem;
-        total_physical_mem = old_total_physical_mem;
-        heap_hard_limit = old_heap_hard_limit;
-        heap_hard_limit_oh[soh] = old_heap_hard_limit_soh;
-        heap_hard_limit_oh[loh] = old_heap_hard_limit_loh;
-        heap_hard_limit_oh[poh] = old_heap_hard_limit_poh;
-        hard_limit_config_p = old_hard_limit_config_p;
-    }
-#ifdef COMMITTED_BYTES_SHADOW
-    else
-    {
-        decommit_lock.Enter();
-        verify_committed_bytes ();
-        decommit_lock.Leave();
-    }
-#endif //COMMITTED_BYTES_SHADOW
-    GCToEEInterface::RestartEE(TRUE);
-    return (int)status;
-}
-void gc_heap::accumulate_committed_bytes(heap_segment* seg, size_t& committed_bytes, size_t& mark_array_committed_bytes, gc_oh_num oh)
-{
-    seg = heap_segment_rw (seg);
-    while (seg)
-    {
-        if ((oh == unknown) || (heap_segment_oh (seg) == oh))
-        {
-            uint8_t* start;
-#ifdef USE_REGIONS
-            mark_array_committed_bytes += get_mark_array_size (seg);
-            start = get_region_start (seg);
-#else
-            start = (uint8_t*)seg;
-#endif
-            committed_bytes += (heap_segment_committed (seg) - start);
-        }
-        seg = heap_segment_next_rw (seg);
-    }
-}
-#ifdef USE_REGIONS
-size_t gc_heap::get_mark_array_size (heap_segment* seg)
-{
-#ifdef BACKGROUND_GC
-    if (seg->flags & heap_segment_flags_ma_committed)
-    {
-        uint32_t* mark_array_addr = mark_array;
-        uint8_t* begin = get_start_address (seg);
-        uint8_t* end = heap_segment_reserved (seg);
-        size_t beg_word = mark_word_of (begin);
-        size_t end_word = mark_word_of (align_on_mark_word (end));
-        uint8_t* commit_start = align_lower_page ((uint8_t*)&mark_array_addr[beg_word]);
-        uint8_t* commit_end = align_on_page ((uint8_t*)&mark_array_addr[end_word]);
-        return (size_t)(commit_end - commit_start);
-    }
-#endif //BACKGROUND_GC
-    return 0;
-}
-#endif //USE_REGIONS

--- a/src/coreclr/gc/gcconfig.h
+++ b//dev/null
@@ -1,151 +0,0 @@
-#ifndef __GCCONFIG_H__
-#define __GCCONFIG_H__
-class GCConfigStringHolder
-{
-private:
-    const char* m_str;
-public:
-    explicit GCConfigStringHolder(const char* str)
-      : m_str(str) {}
-    GCConfigStringHolder(const GCConfigStringHolder&) = delete;
-    GCConfigStringHolder& operator=(const GCConfigStringHolder&) = delete;
-    GCConfigStringHolder(GCConfigStringHolder&&) = default;
-    ~GCConfigStringHolder()
-    {
-        if (m_str)
-        {
-            GCToEEInterface::FreeStringConfigValue(m_str);
-        }
-        m_str = nullptr;
-    }
-    const char* Get() const { return m_str; }
-};
-#define GC_CONFIGURATION_KEYS \
-    BOOL_CONFIG  (ServerGC,                  "gcServer",                  "System.GC.Server",                  false,              "Whether we should be using Server GC")                                                   \
-    BOOL_CONFIG  (ConcurrentGC,              "gcConcurrent",              "System.GC.Concurrent",              true,               "Whether we should be using Concurrent GC")                                                \
-    BOOL_CONFIG  (ConservativeGC,            "gcConservative",            NULL,                                false,              "Enables/Disables conservative GC")                                                       \
-    BOOL_CONFIG  (ForceCompact,              "gcForceCompact",            NULL,                                false,              "When set to true, always do compacting GC")                                              \
-    BOOL_CONFIG  (RetainVM,                  "GCRetainVM",                "System.GC.RetainVM",                false,              "When set we put the segments that should be deleted on a standby list (instead of "       \
-                                                                                                                                          "releasing them back to the OS) which will be considered to satisfy new segment requests" \
-                                                                                                                                          " (note that the same thing can be specified via API which is the supported way)")        \
-    BOOL_CONFIG  (BreakOnOOM,                "GCBreakOnOOM",              NULL,                                false,              "Does a DebugBreak at the soonest time we detect an OOM")                                 \
-    BOOL_CONFIG  (NoAffinitize,              "GCNoAffinitize",            "System.GC.NoAffinitize",            false,              "If set, do not affinitize server GC threads")                                             \
-    BOOL_CONFIG  (LogEnabled,                "GCLogEnabled",              NULL,                                false,              "Specifies if you want to turn on logging in GC")                                         \
-    BOOL_CONFIG  (ConfigLogEnabled,          "GCConfigLogEnabled",        NULL,                                false,              "Specifies the name of the GC config log file")                                           \
-    BOOL_CONFIG  (GCNumaAware,               "GCNumaAware",               NULL,                                true,               "Enables numa allocations in the GC")                                                     \
-    BOOL_CONFIG  (GCCpuGroup,                "GCCpuGroup",                "System.GC.CpuGroup",                false,              "Enables CPU groups in the GC")                                                            \
-    BOOL_CONFIG  (GCLargePages,              "GCLargePages",              "System.GC.LargePages",              false,              "Enables using Large Pages in the GC")                                                     \
-    INT_CONFIG   (HeapVerifyLevel,           "HeapVerify",                NULL,                                HEAPVERIFY_NONE,    "When set verifies the integrity of the managed heap on entry and exit of each GC")       \
-    INT_CONFIG   (LOHCompactionMode,         "GCLOHCompact",              NULL,                                0,                  "Specifies the LOH compaction mode")                                                      \
-    INT_CONFIG   (LOHThreshold,              "GCLOHThreshold",            "System.GC.LOHThreshold",            LARGE_OBJECT_SIZE,  "Specifies the size that will make objects go on LOH")                                    \
-    INT_CONFIG   (BGCSpinCount,              "BGCSpinCount",              NULL,                                140,                "Specifies the bgc spin count")                                                           \
-    INT_CONFIG   (BGCSpin,                   "BGCSpin",                   NULL,                                2,                  "Specifies the bgc spin time")                                                            \
-    INT_CONFIG   (HeapCount,                 "GCHeapCount",               "System.GC.HeapCount",               0,                  "Specifies the number of server GC heaps")                                                 \
-    INT_CONFIG   (MaxHeapCount,              "GCMaxHeapCount",            "System.GC.MaxHeapCount",            0,                  "Specifies the max number of server GC heaps to adjust to")                                                 \
-    INT_CONFIG   (Gen0Size,                  "GCgen0size",                NULL,                                0,                  "Specifies the smallest gen0 budget")                                                     \
-    INT_CONFIG   (SegmentSize,               "GCSegmentSize",             NULL,                                0,                  "Specifies the managed heap segment size")                                                \
-    INT_CONFIG   (LatencyMode,               "GCLatencyMode",             NULL,                                -1,                 "Specifies the GC latency mode - batch, interactive or low latency (note that the same "   \
-                                                                                                                                           "thing can be specified via API which is the supported way")                             \
-    INT_CONFIG   (LatencyLevel,              "GCLatencyLevel",            NULL,                                1,                  "Specifies the GC latency level that you want to optimize for. Must be a number from 0 "  \
-                                                                                                                                          "to 3. See documentation for more details on each level.")                                \
-    INT_CONFIG   (LogFileSize,               "GCLogFileSize",             NULL,                                0,                  "Specifies the GC log file size")                                                         \
-    INT_CONFIG   (CompactRatio,              "GCCompactRatio",            NULL,                                0,                  "Specifies the ratio compacting GCs vs sweeping")                                         \
-    INT_CONFIG   (GCHeapAffinitizeMask,      "GCHeapAffinitizeMask",      "System.GC.HeapAffinitizeMask",      0,                  "Specifies processor mask for Server GC threads")                                          \
-    STRING_CONFIG(GCHeapAffinitizeRanges,    "GCHeapAffinitizeRanges",    "System.GC.HeapAffinitizeRanges",                        "Specifies list of processors for Server GC threads. The format is a comma separated "     \
-                                                                                                                                          "list of processor numbers or ranges of processor numbers. On Windows, each entry is "    \
-                                                                                                                                          "prefixed by the CPU group number. Example: Unix - 1,3,5,7-9,12, Windows - 0:1,1:7-9")    \
-    INT_CONFIG   (GCHighMemPercent,          "GCHighMemPercent",          "System.GC.HighMemoryPercent",       0,                  "The percent for GC to consider as high memory")                                           \
-    INT_CONFIG   (GCProvModeStress,          "GCProvModeStress",          NULL,                                0,                  "Stress the provisional modes")                                                           \
-    INT_CONFIG   (GCGen0MaxBudget,           "GCGen0MaxBudget",           NULL,                                0,                  "Specifies the largest gen0 allocation budget")                                           \
-    INT_CONFIG   (GCGen1MaxBudget,           "GCGen1MaxBudget",           NULL,                                0,                  "Specifies the largest gen1 allocation budget")                                           \
-    INT_CONFIG   (GCLowSkipRatio,            "GCLowSkipRatio",            NULL,                                30,                 "Specifies the low generation skip ratio")                                                \
-    INT_CONFIG   (GCHeapHardLimit,           "GCHeapHardLimit",           "System.GC.HeapHardLimit",           0,                  "Specifies a hard limit for the GC heap")                                                 \
-    INT_CONFIG   (GCHeapHardLimitPercent,    "GCHeapHardLimitPercent",    "System.GC.HeapHardLimitPercent",    0,                  "Specifies the GC heap usage as a percentage of the total memory")                        \
-    INT_CONFIG   (GCTotalPhysicalMemory,     "GCTotalPhysicalMemory",     NULL,                                0,                  "Specifies what the GC should consider to be total physical memory")                      \
-    INT_CONFIG   (GCRegionRange,             "GCRegionRange",             NULL,                                0,                  "Specifies the range for the GC heap")                                                    \
-    INT_CONFIG   (GCRegionSize,              "GCRegionSize",              NULL,                                0,                  "Specifies the size for a basic GC region")                                               \
-    INT_CONFIG   (GCEnableSpecialRegions,    "GCEnableSpecialRegions",    NULL,                                0,                  "Specifies to enable special handling some regions like SIP")                             \
-    STRING_CONFIG(LogFile,                   "GCLogFile",                 NULL,                                                    "Specifies the name of the GC log file")                                                  \
-    STRING_CONFIG(ConfigLogFile,             "GCConfigLogFile",           NULL,                                                    "Specifies the name of the GC config log file")                                           \
-    INT_CONFIG   (BGCFLTuningEnabled,        "BGCFLTuningEnabled",        NULL,                                0,                  "Enables FL tuning")                                                                      \
-    INT_CONFIG   (BGCMemGoal,                "BGCMemGoal",                NULL,                                75,                 "Specifies the physical memory load goal")                                                \
-    INT_CONFIG   (BGCMemGoalSlack,           "BGCMemGoalSlack",           NULL,                                10,                 "Specifies comfort zone of going above goal")                                             \
-    INT_CONFIG   (BGCFLSweepGoal,            "BGCFLSweepGoal",            NULL,                                0,                  "Specifies the gen2 sweep FL ratio goal")                                                 \
-    INT_CONFIG   (BGCFLSweepGoalLOH,         "BGCFLSweepGoalLOH",         NULL,                                0,                  "Specifies the LOH sweep FL ratio goal")                                                  \
-    INT_CONFIG   (BGCFLkp,                   "BGCFLkp",                   NULL,                                6000,               "Specifies kp for above goal tuning")                                                     \
-    INT_CONFIG   (BGCFLki,                   "BGCFLki",                   NULL,                                1000,               "Specifies ki for above goal tuning")                                                     \
-    INT_CONFIG   (BGCFLkd,                   "BGCFLkd",                   NULL,                                11,                 "Specifies kd for above goal tuning")                                                     \
-    INT_CONFIG   (BGCFLff,                   "BGCFLff",                   NULL,                                100,                "Specifies ff ratio")                                                                     \
-    INT_CONFIG   (BGCFLSmoothFactor,         "BGCFLSmoothFactor",         NULL,                                150,                "Smoothing over these")                                                                   \
-    INT_CONFIG   (BGCFLGradualD,             "BGCFLGradualD",             NULL,                                0,                  "Enable gradual D instead of cutting off at the value")                                   \
-    INT_CONFIG   (BGCMLkp,                   "BGCMLkp",                   NULL,                                1000,               "Specifies kp for ML tuning")                                                             \
-    INT_CONFIG   (BGCMLki,                   "BGCMLki",                   NULL,                                16,                 "Specifies ki for ML tuning")                                                             \
-    INT_CONFIG   (BGCFLEnableKi,             "BGCFLEnableKi",             NULL,                                1,                  "Enables ki for above goal tuning")                                                       \
-    INT_CONFIG   (BGCFLEnableKd,             "BGCFLEnableKd",             NULL,                                0,                  "Enables kd for above goal tuning")                                                       \
-    INT_CONFIG   (BGCFLEnableSmooth,         "BGCFLEnableSmooth",         NULL,                                0,                  "Enables smoothing")                                                                      \
-    INT_CONFIG   (BGCFLEnableTBH,            "BGCFLEnableTBH",            NULL,                                0,                  "Enables TBH")                                                                            \
-    INT_CONFIG   (BGCFLEnableFF,             "BGCFLEnableFF",             NULL,                                0,                  "Enables FF")                                                                             \
-    INT_CONFIG   (BGCG2RatioStep,            "BGCG2RatioStep",            NULL,                                5,                  "Ratio correction factor for ML loop")                                                    \
-    INT_CONFIG   (GCHeapHardLimitSOH,        "GCHeapHardLimitSOH",        "System.GC.HeapHardLimitSOH",        0,                  "Specifies a hard limit for the GC heap SOH")                                             \
-    INT_CONFIG   (GCHeapHardLimitLOH,        "GCHeapHardLimitLOH",        "System.GC.HeapHardLimitLOH",        0,                  "Specifies a hard limit for the GC heap LOH")                                             \
-    INT_CONFIG   (GCHeapHardLimitPOH,        "GCHeapHardLimitPOH",        "System.GC.HeapHardLimitPOH",        0,                  "Specifies a hard limit for the GC heap POH")                                             \
-    INT_CONFIG   (GCHeapHardLimitSOHPercent, "GCHeapHardLimitSOHPercent", "System.GC.HeapHardLimitSOHPercent", 0,                  "Specifies the GC heap SOH usage as a percentage of the total memory")                    \
-    INT_CONFIG   (GCHeapHardLimitLOHPercent, "GCHeapHardLimitLOHPercent", "System.GC.HeapHardLimitLOHPercent", 0,                  "Specifies the GC heap LOH usage as a percentage of the total memory")                    \
-    INT_CONFIG   (GCHeapHardLimitPOHPercent, "GCHeapHardLimitPOHPercent", "System.GC.HeapHardLimitPOHPercent", 0,                  "Specifies the GC heap POH usage as a percentage of the total memory")                    \
-    INT_CONFIG   (GCEnabledInstructionSets,  "GCEnabledInstructionSets",  NULL,                                -1,                 "Specifies whether GC can use AVX2 or AVX512F - 0 for neither, 1 for AVX2, 3 for AVX512F")\
-    INT_CONFIG   (GCConserveMem,             "GCConserveMemory",          "System.GC.ConserveMemory",          0,                  "Specifies how hard GC should try to conserve memory - values 0-9")                       \
-    INT_CONFIG   (GCWriteBarrier,            "GCWriteBarrier",            NULL,                                0,                  "Specifies whether GC should use more precise but slower write barrier")                  \
-    STRING_CONFIG(GCName,                    "GCName",                    "System.GC.Name",                                        "Specifies the name of the standalone GC implementation.")                                \
-    STRING_CONFIG(GCPath,                    "GCPath",                    "System.GC.Path",                                        "Specifies the path of the standalone GC implementation.")                                \
-    INT_CONFIG   (GCSpinCountUnit,           "GCSpinCountUnit",           NULL,                                0,                  "Specifies the spin count unit used by the GC.")                                          \
-    INT_CONFIG   (GCDynamicAdaptationMode,   "GCDynamicAdaptationMode",   "System.GC.DynamicAdaptationMode",   1,                  "Enable the GC to dynamically adapt to application sizes.")                               \
-    INT_CONFIG   (GCDTargetTCP,              "GCDTargetTCP",              "System.GC.DTargetTCP",              0,                  "Specifies the target tcp for DATAS")                                                     \
-    INT_CONFIG   (GCDBGCRatio,              " GCDBGCRatio",               NULL,                                0,                  "Specifies the ratio of BGC to NGC2 for HC change")                                       \
-    BOOL_CONFIG  (GCLogBGCThreadId,          "GCLogBGCThreadId",          NULL,                                false,              "Specifies if BGC ThreadId should be logged")                                             \
-    BOOL_CONFIG  (GCCacheSizeFromSysConf,    "GCCacheSizeFromSysConf",    NULL,                                false,              "Specifies using sysconf to retrieve the last level cache size for Unix.")
-class GCConfig
-{
-#define BOOL_CONFIG(name, unused_private_key, unused_public_key, unused_default, unused_doc) \
-  public: static bool Get##name();                                \
-  public: static bool Get##name(bool defaultValue);               \
-  public: static void Set##name(bool value);                      \
-  private: static bool s_##name;                                  \
-  private: static bool s_##name##Provided;                        \
-  private: static bool s_Updated##name;
-#define INT_CONFIG(name, unused_private_key, unused_public_key, unused_default, unused_doc) \
-  public: static int64_t Get##name();                            \
-  public: static int64_t Get##name(int64_t defaultValue);        \
-  public: static void Set##name(int64_t value);                  \
-  private: static int64_t s_##name;                              \
-  private: static bool s_##name##Provided;                       \
-  private: static int64_t s_Updated##name;                       \
-#define STRING_CONFIG(name, unused_private_key, unused_public_key, unused_doc) \
-  public: static GCConfigStringHolder Get##name();
-GC_CONFIGURATION_KEYS
-#undef BOOL_CONFIG
-#undef INT_CONFIG
-#undef STRING_CONFIG
-public:
-  static void RefreshHeapHardLimitSettings();
-  static void EnumerateConfigurationValues(void* context, ConfigurationValueFunc configurationValueFunc);
-enum HeapVerifyFlags {
-    HEAPVERIFY_NONE             = 0,
-    HEAPVERIFY_GC               = 1,   // Verify the heap at beginning and end of GC
-    HEAPVERIFY_BARRIERCHECK     = 2,   // Verify the assignment operations correctly went through write barrier code
-    HEAPVERIFY_SYNCBLK          = 4,   // Verify sync block scanning
-    HEAPVERIFY_NO_RANGE_CHECKS  = 0x10,   // Excludes checking if an OBJECTREF is within the bounds of the managed heap
-    HEAPVERIFY_NO_MEM_FILL      = 0x20,   // Excludes filling unused segment portions with fill pattern
-    HEAPVERIFY_POST_GC_ONLY     = 0x40,   // Performs heap verification post-GCs only (instead of before and after each GC)
-    HEAPVERIFY_DEEP_ON_COMPACT  = 0x80    // Performs deep object verfication only on compacting GCs.
-};
-enum WriteBarrierFlavor
-{
-    WRITE_BARRIER_DEFAULT = 0,
-    WRITE_BARRIER_REGION_BIT = 1,
-    WRITE_BARRIER_REGION_BYTE = 2,
-    WRITE_BARRIER_SERVER = 3,
-};
-static void Initialize();
-};
-bool ParseGCHeapAffinitizeRanges(const char* cpu_index_ranges, AffinitySet* config_affinity_set, uintptr_t& config_affinity_mask);
-#endif // __GCCONFIG_H__

--- a/src/coreclr/gc/gcpriv.h
+++ b//dev/null
@@ -1,4564 +0,0 @@
-#ifndef _DEBUG
-#ifdef _MSC_VER
-#pragma optimize( "t", on )
-#endif
-#endif
-#ifdef __GNUC__
-#define inline __attribute__((always_inline)) inline
-#else
-#define inline __forceinline
-#endif // __GNUC__
-#include "gc.h"
-#include "gcrecord.h"
-#ifdef MULTIPLE_HEAPS
-#define PER_HEAP_FIELD
-#define PER_HEAP_FIELD_MAINTAINED
-#define PER_HEAP_FIELD_MAINTAINED_ALLOC
-#define PER_HEAP_FIELD_SINGLE_GC
-#define PER_HEAP_FIELD_SINGLE_GC_ALLOC
-#define PER_HEAP_FIELD_ALLOC
-#define PER_HEAP_FIELD_INIT_ONLY
-#define PER_HEAP_FIELD_DIAG_ONLY
-#define PER_HEAP_METHOD
-#else //MULTIPLE_HEAPS
-#define PER_HEAP_FIELD static
-#define PER_HEAP_FIELD_MAINTAINED static
-#define PER_HEAP_FIELD_MAINTAINED_ALLOC static
-#define PER_HEAP_FIELD_SINGLE_GC static
-#define PER_HEAP_FIELD_SINGLE_GC_ALLOC static
-#define PER_HEAP_FIELD_ALLOC static
-#define PER_HEAP_FIELD_INIT_ONLY static
-#define PER_HEAP_FIELD_DIAG_ONLY static
-#define PER_HEAP_METHOD static
-#endif // MULTIPLE_HEAPS
-#define PER_HEAP_ISOLATED_FIELD static
-#define PER_HEAP_ISOLATED_METHOD static
-#define PER_HEAP_ISOLATED_FIELD_MAINTAINED static
-#define PER_HEAP_ISOLATED_FIELD_MAINTAINED_ALLOC static
-#define PER_HEAP_ISOLATED_FIELD_SINGLE_GC static
-#define PER_HEAP_ISOLATED_FIELD_SINGLE_GC_ALLOC static
-#define PER_HEAP_ISOLATED_FIELD_INIT_ONLY static
-#define PER_HEAP_ISOLATED_FIELD_DIAG_ONLY static
-#ifdef _MSC_VER
-#pragma warning(disable:4293)
-#pragma warning(disable:4477)
-#endif //_MSC_VER
-inline void FATAL_GC_ERROR()
-{
-#if defined(TRACE_GC) && defined(SIMPLE_DPRINTF)
-    flush_gc_log (true);
-#endif //TRACE_GC && SIMPLE_DPRINTF
-    GCToOSInterface::DebugBreak();
-    _ASSERTE(!"Fatal Error in GC.");
-    GCToEEInterface::HandleFatalError((unsigned int)COR_E_EXECUTIONENGINE);
-}
-#ifdef MULTIPLE_HEAPS
-#endif //MULTIPLE_HEAPS
-#ifdef _MSC_VER
-#pragma inline_depth(20)
-#endif
-/* the following section defines the optional features */
-#if defined (HOST_64BIT) && !defined (BUILD_AS_STANDALONE) && !defined(__APPLE__) && !defined(__sun)
-#define USE_REGIONS
-#endif //HOST_64BIT && BUILD_AS_STANDALONE && !__APPLE__
-#if defined(USE_REGIONS) && defined(MULTIPLE_HEAPS)
-#define DYNAMIC_HEAP_COUNT
-#endif //USE_REGIONS && MULTIPLE_HEAPS
-#ifdef USE_REGIONS
-#define MARK_PHASE_PREFETCH
-#endif //USE_REGIONS
-#define FEATURE_LOH_COMPACTION
-#ifdef FEATURE_64BIT_ALIGNMENT
-#define RESPECT_LARGE_ALIGNMENT //Preserve double alignment of objects during relocation
-#endif //FEATURE_64BIT_ALIGNMENT
-#define SHORT_PLUGS //used to keep ephemeral plugs short so they fit better into the oldest generation free items
-#ifdef SHORT_PLUGS
-#define DESIRED_PLUG_LENGTH (1000)
-#endif //SHORT_PLUGS
-#define FEATURE_PREMORTEM_FINALIZATION
-#define GC_HISTORY
-#define BACKGROUND_GC   //concurrent background GC (requires WRITE_WATCH)
-#if defined(BACKGROUND_GC) && defined(HOST_64BIT)
-#define DOUBLY_LINKED_FL
-#endif //HOST_64BIT
-#ifndef FEATURE_NATIVEAOT
-#define HEAP_ANALYZE
-#define COLLECTIBLE_CLASS
-#endif // !FEATURE_NATIVEAOT
-#ifdef HEAP_ANALYZE
-#define initial_internal_roots        (1024*16)
-#endif // HEAP_ANALYZE
-#ifdef SERVER_GC
-#define MH_SC_MARK //scalable marking
-#endif //SERVER_GC
-#if defined (SERVER_GC) && defined (MH_SC_MARK)
-#define SERVER_SC_MARK_VOLATILE(x) VOLATILE(x)
-#else //SERVER_GC&&MH_SC_MARK
-#define SERVER_SC_MARK_VOLATILE(x) x
-#endif //SERVER_GC&&MH_SC_MARK
-#define CARD_BUNDLE         //enable card bundle feature.(requires WRITE_WATCH)
-#define ALLOW_REFERENCES_IN_POH  //Allow POH objects to contain references.
-#ifdef BACKGROUND_GC
-#define BGC_SERVO_TUNING
-#endif //BACKGROUND_GC
-#if defined(BACKGROUND_GC) || defined(CARD_BUNDLE) || defined(FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP)
-#define WRITE_WATCH     //Write Watch feature
-#endif //BACKGROUND_GC || CARD_BUNDLE
-#ifdef WRITE_WATCH
-#define array_size 100
-#endif //WRITE_WATCH
-#define FFIND_DECAY  7      //Number of GC for which fast find will be active
-#ifdef SYNCHRONIZATION_STATS
-#define BEGIN_TIMING(x) \
-    int64_t x##_start; \
-    x##_start = GCToOSInterface::QueryPerformanceCounter()
-#define END_TIMING(x) \
-    int64_t x##_end; \
-    x##_end = GCToOSInterface::QueryPerformanceCounter(); \
-    x += x##_end - x##_start
-#else //SYNCHRONIZATION_STATS
-#define BEGIN_TIMING(x)
-#define END_TIMING(x)
-#endif //SYNCHRONIZATION_STATS
-#ifdef GC_CONFIG_DRIVEN
-void GCLogConfig (const char *fmt, ... );
-#define cprintf(x) {GCLogConfig x;}
-#endif //GC_CONFIG_DRIVEN
-#define MIN_INDEX_POWER2 6
-#ifdef SERVER_GC
-#ifdef HOST_64BIT
-#define MAX_INDEX_POWER2 30
-#else
-#define MAX_INDEX_POWER2 26
-#endif  // HOST_64BIT
-#else //SERVER_GC
-#ifdef HOST_64BIT
-#define MAX_INDEX_POWER2 28
-#else
-#define MAX_INDEX_POWER2 24
-#endif  // HOST_64BIT
-#endif //SERVER_GC
-#define MAX_NUM_BUCKETS (MAX_INDEX_POWER2 - MIN_INDEX_POWER2 + 1)
-#ifdef USE_REGIONS
-#define MAX_REGION_SIZE ((size_t)1 << ((sizeof (int32_t) * 8) - 1))
-#endif // USE_REGIONS
-#define MAX_NUM_FREE_SPACES 200
-#define MIN_NUM_FREE_SPACES 5
-#ifdef memcpy
-#undef memcpy
-#endif //memcpy
-#ifdef FEATURE_STRUCTALIGN
-#define REQD_ALIGN_DCL ,int requiredAlignment
-#define REQD_ALIGN_ARG ,requiredAlignment
-#define REQD_ALIGN_AND_OFFSET_DCL ,int requiredAlignment,size_t alignmentOffset
-#define REQD_ALIGN_AND_OFFSET_DEFAULT_DCL ,int requiredAlignment=DATA_ALIGNMENT,size_t alignmentOffset=0
-#define REQD_ALIGN_AND_OFFSET_ARG ,requiredAlignment,alignmentOffset
-#else // FEATURE_STRUCTALIGN
-#define REQD_ALIGN_DCL
-#define REQD_ALIGN_ARG
-#define REQD_ALIGN_AND_OFFSET_DCL
-#define REQD_ALIGN_AND_OFFSET_DEFAULT_DCL
-#define REQD_ALIGN_AND_OFFSET_ARG
-#endif // FEATURE_STRUCTALIGN
-#ifdef MULTIPLE_HEAPS
-#define THREAD_NUMBER_DCL ,int thread
-#define THREAD_NUMBER_ARG ,thread
-#define THREAD_NUMBER_FROM_CONTEXT int thread = sc->thread_number;
-#define THREAD_FROM_HEAP  int thread = heap_number;
-#define HEAP_FROM_THREAD  gc_heap* hpt = gc_heap::g_heaps[thread];
-#else
-#define THREAD_NUMBER_DCL
-#define THREAD_NUMBER_ARG
-#define THREAD_NUMBER_FROM_CONTEXT
-#define THREAD_FROM_HEAP
-#define HEAP_FROM_THREAD  gc_heap* hpt = 0;
-#endif //MULTIPLE_HEAPS
-const int policy_sweep = 0;
-const int policy_compact = 1;
-const int policy_expand  = 2;
-#if !defined(FEATURE_NATIVEAOT) && !defined(BUILD_AS_STANDALONE)
-#undef  assert
-#define assert _ASSERTE
-#undef  ASSERT
-#define ASSERT _ASSERTE
-#endif // FEATURE_NATIVEAOT
-struct GCDebugSpinLock {
-    VOLATILE(int32_t) lock;                   // -1 if free, 0 if held
-#ifdef _DEBUG
-    VOLATILE(Thread *) holding_thread;     // -1 if no thread holds the lock.
-    VOLATILE(BOOL) released_by_gc_p;       // a GC thread released the lock.
-#endif
-#if defined (SYNCHRONIZATION_STATS)
-    unsigned int num_switch_thread;
-    unsigned int num_wait_longer;
-    unsigned int num_switch_thread_w;
-    unsigned int num_disable_preemptive_w;
-#endif
-#if defined(DYNAMIC_HEAP_COUNT)
-    uint64_t msl_wait_time;
-#endif //DYNAMIC_HEAP_COUNT
-    GCDebugSpinLock()
-        : lock(-1)
-#ifdef _DEBUG
-        , holding_thread((Thread*) -1)
-#endif
-#if defined (SYNCHRONIZATION_STATS)
-        , num_switch_thread(0), num_wait_longer(0), num_switch_thread_w(0), num_disable_preemptive_w(0)
-#endif
-#if defined(DYNAMIC_HEAP_COUNT)
-        , msl_wait_time(0)
-#endif //DYNAMIC_HEAP_COUNT
-    {
-    }
-#if defined (SYNCHRONIZATION_STATS)
-    void init()
-    {
-        num_switch_thread = 0;
-        num_wait_longer = 0;
-        num_switch_thread_w = 0;
-        num_disable_preemptive_w = 0;
-    }
-#endif
-};
-typedef GCDebugSpinLock GCSpinLock;
-class mark;
-class heap_segment;
-class CObjectHeader;
-class sorted_table;
-class seg_free_spaces;
-class gc_heap;
-#define youngest_generation (generation_of (0))
-#define large_object_generation (generation_of (loh_generation))
-#define pinned_object_generation (generation_of (poh_generation))
-#ifdef BACKGROUND_GC
-class exclusive_sync;
-class recursive_gc_sync;
-#endif //BACKGROUND_GC
-#ifdef MULTIPLE_HEAPS
-#define FEATURE_CARD_MARKING_STEALING
-#endif //MULTIPLE_HEAPS
-#ifdef FEATURE_CARD_MARKING_STEALING
-class card_marking_enumerator;
-#define CARD_MARKING_STEALING_ARG(a)    ,a
-#define CARD_MARKING_STEALING_ARGS(a,b,c)    ,a,b,c
-#else // FEATURE_CARD_MARKING_STEALING
-#define CARD_MARKING_STEALING_ARG(a)
-#define CARD_MARKING_STEALING_ARGS(a,b,c)
-#endif // FEATURE_CARD_MARKING_STEALING
-enum gc_pause_mode
-{
-    pause_batch = 0, //We are not concerned about pause length
-    pause_interactive = 1,     //We are running an interactive app
-    pause_low_latency = 2,     //short pauses are essential
-    pause_sustained_low_latency = 3,
-    pause_no_gc = 4
-};
-enum gc_loh_compaction_mode
-{
-    loh_compaction_default = 1, // the default mode, don't compact LOH.
-    loh_compaction_once = 2, // only compact once the next time a blocking full GC happens.
-    loh_compaction_auto = 4 // GC decides when to compact LOH, to be implemented.
-};
-enum set_pause_mode_status
-{
-    set_pause_mode_success = 0,
-    set_pause_mode_no_gc = 1 // NoGCRegion is in progress, can't change pause mode.
-};
-/*
- Latency modes required user to have specific GC knowledge (eg, budget, full blocking GC).
- We are trying to move away from them as it makes a lot more sense for users to tell
- us what's the most important out of the perf aspects that make sense to them.
- In general there are 3 such aspects:
- + memory footprint
- + throughput
- + pause predictibility
- Currently the following levels are supported. We may (and will likely) add more
- in the future.
- +----------+--------------------+---------------------------------------+
- | Level    | Optimization Goals | Latency Characteristics               |
- +==========+====================+=======================================+
- | 0        | memory footprint   | pauses can be long and more frequent  |
- +----------+--------------------+---------------------------------------+
- | 1        | balanced           | pauses are more predictable and more  |
- |          |                    | frequent. the longest pauses are      |
- |          |                    | shorter than 1.                       |
- +----------+--------------------+---------------------------------------+
-*/
-enum gc_latency_level
-{
-    latency_level_first = 0,
-    latency_level_memory_footprint = latency_level_first,
-    latency_level_balanced = 1,
-    latency_level_last = latency_level_balanced,
-    latency_level_default = latency_level_balanced
-};
-enum gc_tuning_point
-{
-    tuning_deciding_condemned_gen = 0,
-    tuning_deciding_full_gc = 1,
-    tuning_deciding_compaction = 2,
-    tuning_deciding_expansion = 3,
-    tuning_deciding_promote_ephemeral = 4,
-    tuning_deciding_short_on_seg = 5
-};
-enum gc_oh_num
-{
-    soh = 0,
-    loh = 1,
-    poh = 2,
-    unknown = -1,
-};
-const int total_oh_count = gc_oh_num::poh + 1;
-#ifdef USE_REGIONS
-const int recorded_committed_free_bucket = total_oh_count;
-const int recorded_committed_bookkeeping_bucket = recorded_committed_free_bucket + 1;
-const int recorded_committed_mark_array_bucket = recorded_committed_bookkeeping_bucket;
-#else
-const int recorded_committed_ignored_bucket = total_oh_count;
-const int recorded_committed_bookkeeping_bucket = recorded_committed_ignored_bucket + 1;
-const int recorded_committed_mark_array_bucket = recorded_committed_ignored_bucket;
-#endif //USE_REGIONS
-const int recorded_committed_bucket_counts = recorded_committed_bookkeeping_bucket + 1;
-gc_oh_num gen_to_oh (int gen);
-enum memory_type
-{
-    memory_type_reserved = 0,
-    memory_type_committed = 1
-};
-#if defined(TRACE_GC) && defined(BACKGROUND_GC)
-static const char * const str_bgc_state[] =
-{
-    "not_in_process",
-    "bgc_initialized",
-    "reset_ww",
-    "mark_handles",
-    "mark_stack",
-    "revisit_soh",
-    "revisit_uoh",
-    "overflow_soh",
-    "overflow_uoh",
-    "final_marking",
-    "sweep_soh",
-    "sweep_uoh",
-    "plan_phase"
-};
-#endif // defined(TRACE_GC) && defined(BACKGROUND_GC)
-enum allocation_state
-{
-    a_state_start = 0,
-    a_state_can_allocate,
-    a_state_cant_allocate,
-    a_state_retry_allocate,
-    a_state_try_fit,
-    a_state_try_fit_new_seg,
-    a_state_try_fit_after_cg,
-    a_state_try_fit_after_bgc,
-    a_state_try_free_full_seg_in_bgc,
-    a_state_try_free_after_bgc,
-    a_state_try_seg_end,
-    a_state_acquire_seg,
-    a_state_acquire_seg_after_cg,
-    a_state_acquire_seg_after_bgc,
-    a_state_check_and_wait_for_bgc,
-    a_state_trigger_full_compact_gc,
-    a_state_trigger_ephemeral_gc,
-    a_state_trigger_2nd_ephemeral_gc,
-    a_state_check_retry_seg,
-    a_state_max
-};
-enum enter_msl_status
-{
-    msl_entered,
-    msl_retry_different_heap
-};
-enum gc_type
-{
-    gc_type_compacting = 0,
-    gc_type_blocking = 1,
-#ifdef BACKGROUND_GC
-    gc_type_background = 2,
-#endif //BACKGROUND_GC
-    gc_type_max = 3
-};
-#ifdef DYNAMIC_HEAP_COUNT
-enum gc_dynamic_adaptation_mode
-{
-    dynamic_adaptation_default = 0,
-    dynamic_adaptation_to_application_sizes = 1,
-};
-enum hc_record_stage
-{
-    hc_record_set_last_heaps = 0,
-    hc_record_before_check_timeout = 1,
-    hc_record_before_check_gc_start = 2,
-    hc_record_change_done = 3,
-    hc_record_still_active = 4,
-    hc_record_became_active = 5,
-    hc_record_became_inactive = 6,
-    hc_record_inactive_waiting = 7, 
-    hc_record_check_cancelled_prep = 8,
-#ifdef BACKGROUND_GC
-    hc_record_check_cancelled_bgc = 9,
-    hc_record_bgc_active = 10,
-    hc_record_bgc_inactive = 11,
-#endif //BACKGROUND_GC
-};
-struct hc_history
-{
-    size_t gc_index;
-    short stage;
-    short last_n_heaps;
-    short n_heaps;
-    short new_n_heaps;
-    short idle_thread_count;
-    short gc_t_join_n_threads;
-    short gc_t_join_join_lock;
-#ifdef BACKGROUND_GC
-    short bgc_t_join_n_threads;
-#if defined(TARGET_AMD64) && defined(TARGET_WINDOWS) && !defined(_DEBUG) && !defined(FEATURE_NATIVEAOT)
-    int bgc_thread_os_id;
-#endif
-    short bgc_t_join_join_lock;
-#endif //BACKGROUND_GC
-    bool gc_t_join_joined_p;
-#ifdef BACKGROUND_GC
-    bool bgc_t_join_joined_p;
-    bool concurrent_p;
-    bool bgc_thread_running;
-#endif //BACKGROUND_GC
-};
-#endif //DYNAMIC_HEAP_COUNT
-class gc_mechanisms
-{
-public:
-    VOLATILE(size_t) gc_index; // starts from 1 for the first GC, like dd_collection_count
-    int condemned_generation;
-    BOOL promotion;
-    BOOL compaction;
-    BOOL loh_compaction;
-    BOOL heap_expansion;
-    uint32_t concurrent;
-    BOOL demotion;
-    BOOL card_bundles;
-    int  gen0_reduction_count;
-    BOOL should_lock_elevation;
-    int elevation_locked_count;
-    BOOL elevation_reduced;
-    BOOL minimal_gc;
-    gc_reason reason;
-    gc_pause_mode pause_mode;
-    BOOL found_finalizers;
-#ifdef BACKGROUND_GC
-    BOOL background_p;
-    bgc_state b_state;
-#endif //BACKGROUND_GC
-#ifdef STRESS_HEAP
-    BOOL stress_induced;
-#endif // STRESS_HEAP
-    uint32_t entry_memory_load;
-    uint64_t entry_available_physical_mem;
-    uint32_t exit_memory_load;
-    void init_mechanisms(); //for each GC
-    void first_init(); // for the life of the EE
-    void record (gc_history_global* history);
-};
-class gc_mechanisms_store
-{
-public:
-    size_t gc_index;
-    bool promotion;
-    bool compaction;
-    bool loh_compaction;
-    bool heap_expansion;
-    bool concurrent;
-    bool demotion;
-    bool card_bundles;
-    bool should_lock_elevation;
-    int condemned_generation   : 8;
-    int gen0_reduction_count   : 8;
-    int elevation_locked_count : 8;
-    gc_reason reason           : 8;
-    gc_pause_mode pause_mode   : 8;
-#ifdef BACKGROUND_GC
-    bgc_state b_state          : 8;
-#endif //BACKGROUND_GC
-    bool found_finalizers;
-#ifdef BACKGROUND_GC
-    bool background_p;
-#endif //BACKGROUND_GC
-#ifdef STRESS_HEAP
-    bool stress_induced;
-#endif // STRESS_HEAP
-#ifdef HOST_64BIT
-    uint32_t entry_memory_load;
-#endif // HOST_64BIT
-    void store (gc_mechanisms* gm)
-    {
-        gc_index                = gm->gc_index;
-        condemned_generation    = gm->condemned_generation;
-        promotion               = (gm->promotion != 0);
-        compaction              = (gm->compaction != 0);
-        loh_compaction          = (gm->loh_compaction != 0);
-        heap_expansion          = (gm->heap_expansion != 0);
-        concurrent              = (gm->concurrent != 0);
-        demotion                = (gm->demotion != 0);
-        card_bundles            = (gm->card_bundles != 0);
-        gen0_reduction_count    = gm->gen0_reduction_count;
-        should_lock_elevation   = (gm->should_lock_elevation != 0);
-        elevation_locked_count  = gm->elevation_locked_count;
-        reason                  = gm->reason;
-        pause_mode              = gm->pause_mode;
-        found_finalizers        = (gm->found_finalizers != 0);
-#ifdef BACKGROUND_GC
-        background_p            = (gm->background_p != 0);
-        b_state                 = gm->b_state;
-#endif //BACKGROUND_GC
-#ifdef STRESS_HEAP
-        stress_induced          = (gm->stress_induced != 0);
-#endif // STRESS_HEAP
-#ifdef HOST_64BIT
-        entry_memory_load       = gm->entry_memory_load;
-#endif // HOST_64BIT
-    }
-};
-typedef DPTR(class heap_segment)               PTR_heap_segment;
-typedef DPTR(class gc_heap)                    PTR_gc_heap;
-typedef DPTR(PTR_gc_heap)                      PTR_PTR_gc_heap;
-#ifdef FEATURE_PREMORTEM_FINALIZATION
-typedef DPTR(class CFinalize)                  PTR_CFinalize;
-#endif // FEATURE_PREMORTEM_FINALIZATION
-#define MAX_SOH_BUCKET_COUNT (13)//Max number of buckets for the SOH generations.
-#define MAX_BUCKET_COUNT (20)//Max number of buckets.
-class alloc_list
-{
-#ifdef DOUBLY_LINKED_FL
-    uint8_t* added_head;
-    uint8_t* added_tail;
-#endif //DOUBLY_LINKED_FL
-    uint8_t* head;
-    uint8_t* tail;
-    size_t damage_count;
-public:
-#ifdef FL_VERIFICATION
-    size_t item_count;
-#endif //FL_VERIFICATION
-#ifdef DOUBLY_LINKED_FL
-    uint8_t*& added_alloc_list_head () { return added_head;}
-    uint8_t*& added_alloc_list_tail () { return added_tail;}
-#endif //DOUBLY_LINKED_FL
-    uint8_t*& alloc_list_head () { return head;}
-    uint8_t*& alloc_list_tail () { return tail;}
-    size_t& alloc_list_damage_count(){ return damage_count; }
-    alloc_list()
-    {
-#ifdef DOUBLY_LINKED_FL
-        added_head = 0;
-        added_tail = 0;
-#endif //DOUBLY_LINKED_FL
-        head = 0;
-        tail = 0;
-        damage_count = 0;
-    }
-};
-#ifdef FEATURE_EVENT_TRACE
-struct etw_bucket_info
-{
-    uint16_t index;
-    uint32_t count;
-    size_t size;
-    void set (uint16_t _index, uint32_t _count, size_t _size)
-    {
-        index = _index;
-        count = _count;
-        size = _size;
-    }
-};
-#endif //FEATURE_EVENT_TRACE
-#ifdef DYNAMIC_HEAP_COUNT
-struct min_fl_list_info
-{
-    uint8_t* head;
-    uint8_t* tail;
-#ifdef DOUBLY_LINKED_FL
-    void thread_item (uint8_t* item);
-#endif //DOUBLY_LINKED_FL
-    void thread_item_no_prev (uint8_t* item);
-};
-#endif //DYNAMIC_HEAP_COUNT
-class allocator
-{
-    int first_bucket_bits;
-    unsigned int num_buckets;
-    alloc_list first_bucket;
-    alloc_list* buckets;
-    int gen_number;
-    alloc_list& alloc_list_of (unsigned int bn);
-    size_t& alloc_list_damage_count_of (unsigned int bn);
-    void thread_free_item_end (uint8_t* free_item, uint8_t*& head, uint8_t*& tail, int bn);
-public:
-    allocator (unsigned int num_b, int fbb, alloc_list* b, int gen=-1);
-    allocator()
-    {
-        num_buckets = 1;
-        first_bucket_bits = sizeof(size_t) * 8 - 1;
-        gen_number = 0;
-    }
-    unsigned int number_of_buckets()
-    {
-        return num_buckets;
-    }
-    unsigned int first_suitable_bucket (size_t size)
-    {
-        size = (size >> first_bucket_bits) | 1;
-        DWORD highest_set_bit_index;
-    #ifdef HOST_64BIT
-        BitScanReverse64(&highest_set_bit_index, size);
-    #else
-        BitScanReverse(&highest_set_bit_index, size);
-    #endif
-        return min ((unsigned int)highest_set_bit_index, (num_buckets - 1));
-    }
-    size_t first_bucket_size()
-    {
-        return ((size_t)1 << (first_bucket_bits + 1));
-    }
-    uint8_t*& alloc_list_head_of (unsigned int bn)
-    {
-        return alloc_list_of (bn).alloc_list_head();
-    }
-    uint8_t*& alloc_list_tail_of (unsigned int bn)
-    {
-        return alloc_list_of (bn).alloc_list_tail();
-    }
-#ifdef DOUBLY_LINKED_FL
-    uint8_t*& added_alloc_list_head_of (unsigned int bn)
-    {
-        return alloc_list_of (bn).added_alloc_list_head();
-    }
-    uint8_t*& added_alloc_list_tail_of (unsigned int bn)
-    {
-        return alloc_list_of (bn).added_alloc_list_tail();
-    }
-#endif //DOUBLY_LINKED_FL
-    void clear();
-    BOOL discard_if_no_fit_p()
-    {
-        return (num_buckets == 1);
-    }
-    void copy_with_no_repair (allocator* allocator_to_copy)
-    {
-        assert (num_buckets == allocator_to_copy->number_of_buckets());
-        for (unsigned int i = 0; i < num_buckets; i++)
-        {
-            alloc_list* al = &(allocator_to_copy->alloc_list_of (i));
-            alloc_list_tail_of(i) = al->alloc_list_tail();
-#if !defined(TARGET_AMD64) && !defined(TARGET_X86)
-            MemoryBarrier();
-#endif
-            alloc_list_head_of(i) = al->alloc_list_head();
-        }
-    }
-    void unlink_item (unsigned int bn, uint8_t* item, uint8_t* previous_item, BOOL use_undo_p);
-    void thread_item (uint8_t* item, size_t size);
-    void thread_item_front (uint8_t* item, size_t size);
-#ifdef DOUBLY_LINKED_FL
-    int thread_item_front_added (uint8_t* itme, size_t size);
-    void unlink_item_no_undo (uint8_t* item, size_t size);
-    void unlink_item_no_undo (unsigned int bn, uint8_t* item);
-    void unlink_item_no_undo_added (unsigned int bn, uint8_t* item, uint8_t* previous_item);
-#endif //DOUBLY_LINKED_FL
-#ifdef DYNAMIC_HEAP_COUNT
-    void count_items (gc_heap* this_hp, size_t* fl_items_count, size_t* fl_items_for_oh_count);
-    void rethread_items (size_t* num_total_fl_items,
-                         size_t* num_total_fl_items_rethread,
-                         gc_heap* current_heap,
-                         min_fl_list_info* min_fl_list,
-                         size_t* free_list_space_per_heap,
-                         int num_heap);
-    void merge_items (gc_heap* current_heap, int to_num_heaps, int from_num_heaps);
-#endif //DYNAMIC_HEAP_COUNT
-    void copy_to_alloc_list (alloc_list* toalist);
-    void copy_from_alloc_list (alloc_list* fromalist);
-    void commit_alloc_list_changes();
-#ifdef USE_REGIONS
-    void thread_sip_fl (heap_segment* region);
-#endif //USE_REGIONS
-#ifdef FEATURE_EVENT_TRACE
-    uint16_t count_largest_items (etw_bucket_info* bucket_info,
-                                  size_t max_size,
-                                  size_t max_item_count,
-                                  size_t* recorded_fl_info_size);
-#endif //FEATURE_EVENT_TRACE
-#ifdef DOUBLY_LINKED_FL
-    bool is_doubly_linked_p()
-    {
-        return (gen_number == max_generation);
-    }
-#endif //DOUBLY_LINKED_FL
-};
-#define NUM_GEN_POWER2 (20)
-#define BASE_GEN_SIZE (1*512)
-class generation
-{
-public:
-    alloc_context   allocation_context;
-    PTR_heap_segment start_segment;
-#ifndef USE_REGIONS
-    uint8_t*        allocation_start;
-#endif //!USE_REGIONS
-    heap_segment*   allocation_segment;
-    uint8_t*        allocation_context_start_region;
-#ifdef USE_REGIONS
-    heap_segment*   tail_region;
-    heap_segment*   tail_ro_region;
-#endif //USE_REGIONS
-    allocator       free_list_allocator;
-    size_t          free_list_allocated;
-    size_t          end_seg_allocated;
-    size_t          condemned_allocated;
-    size_t          sweep_allocated;
-    BOOL            allocate_end_seg_p;
-    size_t          free_list_space;
-    size_t          free_obj_space;
-    size_t          allocation_size;
-#ifndef USE_REGIONS
-    uint8_t*        plan_allocation_start;
-    size_t          plan_allocation_start_size;
-#endif //!USE_REGIONS
-    size_t          pinned_allocation_compact_size;
-    size_t          pinned_allocation_sweep_size;
-    int             gen_num;
-#ifdef DOUBLY_LINKED_FL
-    BOOL            set_bgc_mark_bit_p;
-    uint8_t*        last_free_list_allocated;
-#endif //DOUBLY_LINKED_FL
-#ifdef FREE_USAGE_STATS
-    size_t          gen_free_spaces[NUM_GEN_POWER2];
-    size_t          gen_plugs[NUM_GEN_POWER2];
-    size_t          gen_current_pinned_free_spaces[NUM_GEN_POWER2];
-    size_t          pinned_free_obj_space;
-    size_t          allocated_in_pinned_free;
-    size_t          allocated_since_last_pin;
-#endif //FREE_USAGE_STATS
-};
-struct static_data
-{
-    size_t min_size;
-    size_t max_size;
-    size_t fragmentation_limit;
-    float fragmentation_burden_limit;
-    float limit;
-    float max_limit;
-    uint64_t time_clock; // time after which to collect generation, in performance counts (see QueryPerformanceCounter)
-    size_t gc_clock; // number of gcs after which to collect generation
-};
-class dynamic_data
-{
-public:
-    ptrdiff_t new_allocation;
-    ptrdiff_t gc_new_allocation;
-    float     surv;
-    size_t    desired_allocation;
-    size_t    begin_data_size;
-    size_t    survived_size;
-    size_t    pinned_survived_size;
-    size_t    artificial_pinned_survived_size;
-    size_t    added_pinned_size;
-#ifdef SHORT_PLUGS
-    size_t    padding_size;
-#endif //SHORT_PLUGS
-#if defined (RESPECT_LARGE_ALIGNMENT) || defined (FEATURE_STRUCTALIGN)
-    size_t    num_npinned_plugs;
-#endif //RESPECT_LARGE_ALIGNMENT || FEATURE_STRUCTALIGN
-    size_t    current_size;
-    size_t    collection_count;
-    size_t    promoted_size;
-    size_t    freach_previous_promotion;
-    size_t    fragmentation;
-    size_t    gc_clock; // the gc index
-    uint64_t  time_clock; // time when this gc started
-    uint64_t  previous_time_clock; // time when previous gc started
-    size_t    gc_elapsed_time;  // time it took for the gc to complete
-    size_t    min_size;
-    static_data* sdata;
-};
-struct recorded_generation_info
-{
-    size_t size_before;
-    size_t fragmentation_before;
-    size_t size_after;
-    size_t fragmentation_after;
-};
-struct last_recorded_gc_info
-{
-    VOLATILE(size_t) index;
-    size_t total_committed;
-    size_t promoted;
-    size_t pinned_objects;
-    size_t finalize_promoted_objects;
-    size_t pause_durations[2];
-    float pause_percentage;
-    recorded_generation_info gen_info[total_generation_count];
-    size_t heap_size;
-    size_t fragmentation;
-    uint32_t memory_load;
-    uint8_t condemned_generation;
-    bool compaction;
-    bool concurrent;
-};
-#define ALIGNCONST (DATA_ALIGNMENT-1)
-inline
-size_t Align (size_t nbytes, int alignment=ALIGNCONST)
-{
-    return (nbytes + alignment) & ~alignment;
-}
-inline
-int get_alignment_constant (BOOL small_object_p)
-{
-#ifdef FEATURE_STRUCTALIGN
-    return ALIGNCONST;
-#else // FEATURE_STRUCTALIGN
-    return small_object_p ? ALIGNCONST : 7;
-#endif // FEATURE_STRUCTALIGN
-}
-struct etw_opt_info
-{
-    size_t desired_allocation;
-    size_t new_allocation;
-    int    gen_number;
-};
-enum alloc_wait_reason
-{
-    awr_ignored = -1,
-    awr_low_memory = 0,
-    awr_low_ephemeral = 1,
-    awr_gen0_alloc = 2,
-    awr_loh_alloc = 3,
-    awr_alloc_loh_low_mem = 4,
-    awr_loh_oos = 5,
-    awr_gen0_oos_bgc = 6,
-    awr_loh_oos_bgc = 7,
-    awr_fgc_wait_for_bgc = 8,
-    awr_get_loh_seg = 9,
-    awr_loh_alloc_during_plan = 10,
-    awr_uoh_alloc_during_bgc = 11
-};
-struct alloc_thread_wait_data
-{
-    int awr;
-};
-enum msl_take_state
-{
-    mt_get_large_seg = 0,
-    mt_bgc_uoh_sweep,
-    mt_wait_bgc,
-    mt_block_gc,
-    mt_clr_mem,
-    mt_clr_large_mem,
-    mt_t_eph_gc,
-    mt_t_full_gc,
-    mt_alloc_small,
-    mt_alloc_large,
-    mt_alloc_small_cant,
-    mt_alloc_large_cant,
-    mt_try_alloc,
-    mt_try_budget,
-    mt_try_servo_budget,
-    mt_decommit_step
-};
-enum msl_enter_state
-{
-    me_acquire,
-    me_release
-};
-struct spinlock_info
-{
-    msl_enter_state enter_state;
-    msl_take_state take_state;
-    allocation_state current_uoh_alloc_state;
-    EEThreadId thread_id;
-    bool loh_p;
-};
-#define HS_CACHE_LINE_SIZE 128
-#ifdef SNOOP_STATS
-struct snoop_stats_data
-{
-    int heap_index;
-    size_t objects_checked_count;
-    size_t zero_ref_count;
-    size_t objects_marked_count;
-    size_t stolen_stack_count;
-    size_t partial_stack_count;
-    size_t normal_stack_count;
-    size_t non_stack_count;
-    size_t stack_idle_count;
-    size_t switch_to_thread_count;
-    size_t check_level_count;
-    size_t busy_count;
-    size_t interlocked_count;
-    size_t partial_mark_parent_count;
-    size_t stolen_or_pm_count;
-    size_t stolen_entry_count;
-    size_t pm_not_ready_count;
-    size_t normal_count;
-    size_t stack_bottom_clear_count;
-};
-#endif //SNOOP_STATS
-struct no_gc_region_info
-{
-    size_t soh_allocation_size;
-    size_t loh_allocation_size;
-    size_t started;
-    size_t num_gcs;
-    size_t num_gcs_induced;
-    start_no_gc_region_status start_status;
-    gc_pause_mode saved_pause_mode;
-    size_t saved_gen0_min_size;
-    size_t saved_gen3_min_size;
-    BOOL minimal_gc_p;
-    size_t soh_withheld_budget;
-    size_t loh_withheld_budget;
-    NoGCRegionCallbackFinalizerWorkItem* callback;
-};
-enum interesting_data_point
-{
-    idp_pre_short = 0,
-    idp_post_short = 1,
-    idp_merged_pin = 2,
-    idp_converted_pin = 3,
-    idp_pre_pin = 4,
-    idp_post_pin = 5,
-    idp_pre_and_post_pin = 6,
-    idp_pre_short_padded = 7,
-    idp_post_short_padded = 8,
-    max_idp_count
-};
-#ifdef USE_REGIONS
-enum free_region_kind
-{
-    basic_free_region,
-    large_free_region,
-    huge_free_region,
-    count_free_region_kinds,
-};
-static_assert(count_free_region_kinds == FREE_REGION_KINDS, "Keep count_free_region_kinds in sync with FREE_REGION_KINDS, changing this is not a version breaking change.");
-class region_free_list
-{
-    size_t  num_free_regions;
-    size_t  size_free_regions;
-    size_t  size_committed_in_free_regions;
-    size_t  num_free_regions_added;
-    size_t  num_free_regions_removed;
-    heap_segment* head_free_region;
-    heap_segment* tail_free_region;
-    static free_region_kind get_region_kind(heap_segment* region);
-    void update_added_region_info (heap_segment* region);
-public:
-    region_free_list();
-    void verify (bool empty_p);
-    void reset();
-    void add_region_front (heap_segment* region);
-    void add_region_in_descending_order (heap_segment* region_to_add);
-    void transfer_regions (region_free_list* from);
-    heap_segment* unlink_region_front();
-    heap_segment* unlink_smallest_region (size_t size);
-    size_t get_num_free_regions();
-    size_t get_size_committed_in_free() { return size_committed_in_free_regions; }
-    size_t get_size_free_regions() { return size_free_regions; }
-    heap_segment* get_first_free_region() { return head_free_region; }
-    static void unlink_region (heap_segment* region);
-    static void add_region (heap_segment* region, region_free_list to_free_list[count_free_region_kinds]);
-    static void add_region_descending (heap_segment* region, region_free_list to_free_list[count_free_region_kinds]);
-    void age_free_regions();
-    static void age_free_regions (region_free_list free_list[count_free_region_kinds]);
-    void print (int hn, const char* msg="", int* ages=nullptr);
-    static void print (region_free_list free_list[count_free_region_kinds], int hn, const char* msg="", int* ages=nullptr);
-    void sort_by_committed_and_age();
-    static bool is_on_free_list (heap_segment* region, region_free_list free_list[count_free_region_kinds]);
-};
-static_assert(sizeof(region_free_list) == sizeof(dac_region_free_list), "The DAC relies on the size of these two types matching for pointer arithmetic.");
-#endif
-enum bookkeeping_element
-{
-    card_table_element,
-    brick_table_element,
-#ifdef CARD_BUNDLE
-    card_bundle_table_element,
-#endif
-#ifdef FEATURE_USE_SOFTWARE_WRITE_WATCH_FOR_GC_HEAP
-    software_write_watch_table_element,
-#endif
-#ifdef USE_REGIONS
-    region_to_generation_table_element,
-#endif //USE_REGIONS
-    seg_mapping_table_element,
-#ifdef BACKGROUND_GC
-    mark_array_element,
-#endif
-    total_bookkeeping_elements
-};
-class mark_queue_t
-{
-#ifdef MARK_PHASE_PREFETCH
-    static const size_t slot_count = 16;
-    uint8_t* slot_table[slot_count];
-    size_t curr_slot_index;
-#endif //MARK_PHASE_PREFETCH
-public:
-    mark_queue_t();
-    uint8_t *queue_mark(uint8_t *o);
-    uint8_t *queue_mark(uint8_t *o, int condemned_gen);
-    uint8_t* get_next_marked();
-    void verify_empty();
-};
-float median_of_3 (float a, float b, float c);
-class gc_heap
-{
-    friend class GCHeap;
-#ifdef FEATURE_PREMORTEM_FINALIZATION
-    friend class CFinalize;
-#endif // FEATURE_PREMORTEM_FINALIZATION
-    friend struct ::alloc_context;
-    friend void ProfScanRootsHelper(Object** object, ScanContext *pSC, uint32_t dwFlags);
-    friend void GCProfileWalkHeapWorker(BOOL fProfilerPinned, BOOL fShouldWalkHeapRootsForEtw, BOOL fShouldWalkHeapObjectsForEtw);
-    friend Object* AllocAlign8(alloc_context* acontext, gc_heap* hp, size_t size, uint32_t flags);
-    friend class t_join;
-    friend class gc_mechanisms;
-    friend class seg_free_spaces;
-    friend class mark;
-    friend class CObjectHeader;
-    friend class allocator;
-#ifdef BACKGROUND_GC
-    friend class exclusive_sync;
-    friend class recursive_gc_sync;
-#endif //BACKGROUND_GC
-#if defined (WRITE_BARRIER_CHECK) && !defined (SERVER_GC)
-    friend void checkGCWriteBarrier();
-    friend void initGCShadow();
-#endif //defined (WRITE_BARRIER_CHECK) && !defined (SERVER_GC)
-    friend void PopulateDacVars(GcDacVars *gcDacVars);
-    friend class mark_queue_t;
-#ifdef MULTIPLE_HEAPS
-    typedef void (gc_heap::* card_fn) (uint8_t**, int);
-#define call_fn(this_arg,fn) (this_arg->*fn)
-#define __this this
-#else
-    typedef void (* card_fn) (uint8_t**);
-#define call_fn(this_arg,fn) (*fn)
-#define __this (gc_heap*)0
-#endif
-public:
-    enum region_info : uint8_t
-    {
-        RI_GEN_0 = 0x0,
-        RI_GEN_1 = 0x1,
-        RI_GEN_2 = 0x2,
-        RI_GEN_MASK = 0x3,
-        RI_SIP = 0x4,
-        RI_DEMOTED = 0x8,
-        RI_PLAN_GEN_SHR = 0x6, // how much to shift the value right to obtain plan gen
-        RI_PLAN_GEN_0 = 0x00,
-        RI_PLAN_GEN_1 = 0x40,
-        RI_PLAN_GEN_2 = 0x80,
-        RI_PLAN_GEN_MASK = 0xC0,
-    };
-private:
-#ifdef TRACE_GC
-    PER_HEAP_METHOD void print_free_list (int gen, heap_segment* seg);
-#endif // TRACE_GC
-#ifdef SYNCHRONIZATION_STATS
-    PER_HEAP_ISOLATED_METHOD void init_sync_stats()
-    {
-#ifdef MULTIPLE_HEAPS
-        for (int i = 0; i < gc_heap::n_heaps; i++)
-        {
-            gc_heap::g_heaps[i]->init_heap_sync_stats();
-        }
-#else  //MULTIPLE_HEAPS
-        init_heap_sync_stats();
-#endif  //MULTIPLE_HEAPS
-    }
-    PER_HEAP_ISOLATED_METHOD void print_sync_stats(unsigned int gc_count_during_log)
-    {
-        printf("%2s%2s%10s%10s%12s%6s%4s%8s(  st,  wl, stw, dpw)\n",
-            "H", "T", "good_sus", "bad_sus", "avg_msl", "high", "low", "num_msl");
-#ifdef MULTIPLE_HEAPS
-        for (int i = 0; i < gc_heap::n_heaps; i++)
-        {
-            gc_heap::g_heaps[i]->print_heap_sync_stats(i, gc_count_during_log);
-        }
-#else  //MULTIPLE_HEAPS
-        print_heap_sync_stats(0, gc_count_during_log);
-#endif  //MULTIPLE_HEAPS
-    }
-#endif //SYNCHRONIZATION_STATS
-    PER_HEAP_METHOD void verify_soh_segment_list();
-#ifdef VERIFY_HEAP
-    PER_HEAP_METHOD void verify_free_lists();
-#if defined (USE_REGIONS)
-    PER_HEAP_METHOD void verify_regions (int gen_number, bool can_verify_gen_num, bool can_verify_tail);
-    PER_HEAP_METHOD void verify_regions (bool can_verify_gen_num, bool concurrent_p);
-#endif //USE_REGIONS
-    PER_HEAP_ISOLATED_METHOD void enter_gc_lock_for_verify_heap();
-    PER_HEAP_ISOLATED_METHOD void leave_gc_lock_for_verify_heap();
-    PER_HEAP_METHOD void verify_heap (BOOL begin_gc_p);
-    PER_HEAP_METHOD BOOL check_need_card (uint8_t* child_obj, int gen_num_for_cards,
-                          uint8_t* low, uint8_t* high);
-#endif //VERIFY_HEAP
-    PER_HEAP_METHOD void verify_committed_bytes_per_heap();
-    PER_HEAP_ISOLATED_METHOD void verify_committed_bytes();
-    PER_HEAP_ISOLATED_METHOD void fire_per_heap_hist_event (gc_history_per_heap* current_gc_data_per_heap, int heap_num);
-    PER_HEAP_ISOLATED_METHOD void fire_pevents();
-    PER_HEAP_ISOLATED_METHOD void fire_committed_usage_event();
-#ifdef FEATURE_BASICFREEZE
-    PER_HEAP_ISOLATED_METHOD void walk_read_only_segment(heap_segment *seg, void *pvContext, object_callback_func pfnMethodTable, object_callback_func pfnObjRef);
-#endif
-    PER_HEAP_ISOLATED_METHOD int get_plan_gen_num (int gen_number);
-    PER_HEAP_METHOD uint8_t* get_uoh_start_object (heap_segment* region, generation* gen);
-    PER_HEAP_METHOD uint8_t* get_soh_start_object (heap_segment* region, generation* gen);
-    PER_HEAP_METHOD size_t get_soh_start_obj_len (uint8_t* start_obj);
-    PER_HEAP_METHOD void clear_gen1_cards();
-#ifdef USE_REGIONS
-    PER_HEAP_METHOD bool sufficient_space_regions (size_t end_space, size_t end_space_required);
-    PER_HEAP_METHOD bool sufficient_space_regions_for_allocation (size_t end_space, size_t end_space_required);
-    PER_HEAP_METHOD bool initial_make_soh_regions (gc_heap* hp);
-    PER_HEAP_METHOD bool initial_make_uoh_regions (int gen, gc_heap* hp);
-    PER_HEAP_METHOD void return_free_region (heap_segment* region);
-    PER_HEAP_METHOD heap_segment* get_free_region (int gen_number, size_t size = 0);
-    PER_HEAP_METHOD void clear_region_info (heap_segment* region);
-    PER_HEAP_ISOLATED_METHOD heap_segment* region_of (uint8_t* obj);
-    PER_HEAP_ISOLATED_METHOD heap_segment* get_region_at_index (size_t index);
-    PER_HEAP_ISOLATED_METHOD int get_region_gen_num (heap_segment* region);
-    PER_HEAP_METHOD void check_seg_gen_num (heap_segment* seg);
-    PER_HEAP_ISOLATED_METHOD int get_region_gen_num (uint8_t* obj);
-    PER_HEAP_ISOLATED_METHOD void set_region_gen_num (heap_segment* region, int gen_num);
-    PER_HEAP_ISOLATED_METHOD int get_region_plan_gen_num (uint8_t* obj);
-    PER_HEAP_ISOLATED_METHOD bool is_region_demoted (uint8_t* obj);
-    PER_HEAP_METHOD void set_region_plan_gen_num (heap_segment* region, int plan_gen_num, bool replace_p = false);
-    PER_HEAP_METHOD void set_region_plan_gen_num_sip (heap_segment* region, int plan_gen_num);
-    PER_HEAP_METHOD void set_region_sweep_in_plan (heap_segment* region);
-    PER_HEAP_METHOD void clear_region_sweep_in_plan (heap_segment* region);
-    PER_HEAP_METHOD void clear_region_demoted (heap_segment* region);
-    PER_HEAP_METHOD void decide_on_demotion_pin_surv (heap_segment* region, int* no_pinned_surv_region_count);
-    PER_HEAP_METHOD void skip_pins_in_alloc_region (generation* consing_gen, int plan_gen_num);
-    PER_HEAP_METHOD void process_last_np_surv_region (generation* consing_gen,
-                                      int current_plan_gen_num,
-                                      int next_plan_gen_num);
-    PER_HEAP_METHOD void process_remaining_regions (int current_plan_gen_num,
-                                    generation* consing_gen);
-    PER_HEAP_METHOD void grow_mark_list_piece();
-    PER_HEAP_METHOD void save_current_survived();
-    PER_HEAP_METHOD void update_old_card_survived();
-    PER_HEAP_METHOD void update_planned_gen0_free_space (size_t free_size, uint8_t* plug);
-    PER_HEAP_METHOD void get_gen0_end_plan_space();
-    PER_HEAP_METHOD size_t get_gen0_end_space(memory_type type);
-    PER_HEAP_METHOD bool decide_on_compaction_space();
-    PER_HEAP_METHOD bool try_get_new_free_region();
-    PER_HEAP_METHOD bool init_table_for_region (int gen_number, heap_segment* region);
-    PER_HEAP_METHOD heap_segment* find_first_valid_region (heap_segment* region, bool compact_p, int* num_returned_regions);
-    PER_HEAP_METHOD void thread_final_regions (bool compact_p);
-    PER_HEAP_METHOD void thread_start_region (generation* gen, heap_segment* region);
-    PER_HEAP_METHOD heap_segment* get_new_region (int gen_number, size_t size = 0);
-    PER_HEAP_ISOLATED_METHOD heap_segment* allocate_new_region (gc_heap* hp, int gen_num, bool uoh_p, size_t size = 0);
-    PER_HEAP_METHOD void update_start_tail_regions (generation* gen,
-                                    heap_segment* region_to_delete,
-                                    heap_segment* prev_region,
-                                    heap_segment* next_region);
-    PER_HEAP_METHOD bool should_sweep_in_plan (heap_segment* region);
-    PER_HEAP_METHOD void sweep_region_in_plan (heap_segment* region,
-                               BOOL use_mark_list,
-                               uint8_t**& mark_list_next,
-                               uint8_t** mark_list_index);
-    PER_HEAP_METHOD void check_demotion_helper_sip (uint8_t** pval,
-                                    int parent_gen_num,
-                                    uint8_t* parent_loc);
-    PER_HEAP_METHOD heap_segment* relocate_advance_to_non_sip (heap_segment* region);
-    PER_HEAP_METHOD size_t get_mark_array_size(heap_segment* seg);
-    PER_HEAP_ISOLATED_METHOD void verify_region_to_generation_map();
-    PER_HEAP_ISOLATED_METHOD void compute_gc_and_ephemeral_range (int condemned_gen_number, bool end_of_gc_p);
-    PER_HEAP_ISOLATED_METHOD void distribute_free_regions();
-    PER_HEAP_ISOLATED_METHOD void age_free_regions (const char* msg);
-#ifdef STRESS_REGIONS
-    PER_HEAP_METHOD void pin_by_gc (uint8_t* object);
-#endif //STRESS_REGIONS
-#endif //USE_REGIONS
-    PER_HEAP_METHOD void accumulate_committed_bytes(heap_segment* seg, size_t& committed_bytes, size_t& mark_array_committed_bytes, gc_oh_num oh = unknown);
-    PER_HEAP_ISOLATED_METHOD gc_heap* make_gc_heap(
-#if defined (MULTIPLE_HEAPS)
-                                                   GCHeap* vm_heap,
-                                                   int heap_number
-#endif //MULTIPLE_HEAPS
-        );
-    PER_HEAP_ISOLATED_METHOD void destroy_gc_heap(gc_heap* heap);
-    PER_HEAP_ISOLATED_METHOD HRESULT initialize_gc  (size_t soh_segment_size,
-                                                     size_t loh_segment_size,
-                                                     size_t poh_segment_size
-#ifdef MULTIPLE_HEAPS
-                                                     , int number_of_heaps
-#endif //MULTIPLE_HEAPS
-        );
-    PER_HEAP_ISOLATED_METHOD void shutdown_gc();
-    PER_HEAP_ISOLATED_METHOD void suspend_EE ();
-    PER_HEAP_ISOLATED_METHOD void restart_EE ();
-    PER_HEAP_ISOLATED_METHOD uint32_t adjust_heaps_hard_limit (uint32_t nhp);
-    PER_HEAP_ISOLATED_METHOD size_t adjust_segment_size_hard_limit_va (size_t seg_size);
-    PER_HEAP_ISOLATED_METHOD size_t adjust_segment_size_hard_limit (size_t limit, uint32_t nhp);
-    PER_HEAP_ISOLATED_METHOD bool should_retry_other_heap (int gen_number, size_t size);
-    PER_HEAP_METHOD bool check_against_hard_limit (size_t space_required);
-    PER_HEAP_METHOD CObjectHeader* allocate (size_t jsize,
-                             alloc_context* acontext,
-                             uint32_t flags);
-#ifdef MULTIPLE_HEAPS
-    PER_HEAP_ISOLATED_METHOD void hb_log_new_allocation();
-    PER_HEAP_ISOLATED_METHOD void hb_log_balance_activities();
-    PER_HEAP_ISOLATED_METHOD void balance_heaps (alloc_context* acontext);
-    PER_HEAP_METHOD ptrdiff_t get_balance_heaps_uoh_effective_budget (int generation_num);
-    PER_HEAP_ISOLATED_METHOD gc_heap* balance_heaps_uoh (alloc_context* acontext, size_t size, int generation_num);
-    PER_HEAP_ISOLATED_METHOD gc_heap* balance_heaps_uoh_hard_limit_retry (alloc_context* acontext, size_t size, int generation_num);
-    PER_HEAP_ISOLATED_METHOD void gc_thread_stub (void* arg);
-#endif //MULTIPLE_HEAPS
-    PER_HEAP_METHOD CObjectHeader* allocate_uoh_object (size_t size, uint32_t flags, int gen_num, int64_t& alloc_bytes);
-#ifdef FEATURE_STRUCTALIGN
-    PER_HEAP_METHOD uint8_t* pad_for_alignment_large (uint8_t* newAlloc, int requiredAlignment, size_t size);
-#endif // FEATURE_STRUCTALIGN
-    PER_HEAP_ISOLATED_METHOD void do_pre_gc();
-    PER_HEAP_ISOLATED_METHOD void do_post_gc();
-    PER_HEAP_ISOLATED_METHOD void update_recorded_gen_data (last_recorded_gc_info* gc_info);
-    PER_HEAP_METHOD void update_end_gc_time_per_heap();
-    PER_HEAP_ISOLATED_METHOD void update_end_ngc_time();
-    PER_HEAP_METHOD void add_to_history_per_heap();
-    PER_HEAP_ISOLATED_METHOD void add_to_history();
-#ifdef BACKGROUND_GC
-    PER_HEAP_ISOLATED_METHOD void get_and_reset_uoh_alloc_info();
-#endif //BACKGROUND_GC
-#ifdef BGC_SERVO_TUNING
-    class bgc_tuning
-    {
-    public:
-        struct tuning_calculation
-        {
-            size_t end_gen_size_goal;
-            double sweep_flr_goal;
-            size_t last_bgc_size;
-            double current_bgc_sweep_flr;
-            double last_bgc_flr;
-            double current_bgc_start_flr;
-            double above_goal_accu_error;
-            size_t alloc_to_trigger;
-            size_t actual_alloc_to_trigger;
-            size_t last_bgc_end_alloc;
-            size_t smoothed_alloc_to_trigger;
-            bool last_sweep_above_p;
-            size_t alloc_to_trigger_0;
-            size_t first_alloc_to_trigger;
-        };
-        struct tuning_stats
-        {
-            size_t last_bgc_physical_size;
-            size_t last_alloc_end_to_start;
-            size_t last_alloc_start_to_sweep;
-            size_t last_alloc_sweep_to_end;
-            size_t last_alloc;
-            size_t last_bgc_fl_size;
-            double last_bgc_surv_rate;
-            double last_gen_increase_flr;
-        };
-        struct bgc_size_data
-        {
-            size_t gen_size;
-            size_t gen_physical_size;
-            size_t gen_fl_size;
-            size_t gen_actual_phys_fl_size;
-            ptrdiff_t gen_physical_fl_size;
-            double gen_physical_flr;
-            double gen_flr;
-        };
-        static bool enable_fl_tuning;
-        static uint32_t memory_load_goal;
-        static uint32_t memory_load_goal_slack;
-        static uint64_t available_memory_goal;
-        static bool panic_activated_p;
-        static double accu_error_panic;
-        static double above_goal_kp;
-        static double above_goal_ki;
-        static bool enable_ki;
-        static bool enable_kd;
-        static bool enable_smooth;
-        static bool enable_tbh;
-        static bool enable_ff;
-        static bool enable_gradual_d;
-        static double above_goal_kd;
-        static double above_goal_ff;
-        static double num_gen1s_smooth_factor;
-        static double ml_kp;
-        static double ml_ki;
-        static double accu_error;
-        static bool fl_tuning_triggered;
-        static size_t num_bgcs_since_tuning_trigger;
-        static bool next_bgc_p;
-        static tuning_calculation gen_calc[2];
-        static size_t actual_num_gen1s_to_trigger;
-        static size_t gen1_index_last_bgc_end;
-        static size_t gen1_index_last_bgc_start;
-        static size_t gen1_index_last_bgc_sweep;
-        static tuning_stats gen_stats[2];
-        static bgc_size_data current_bgc_end_data[2];
-        static size_t last_stepping_bgc_count;
-        static uint32_t last_stepping_mem_load;
-        static uint32_t stepping_interval;
-        static bool use_stepping_trigger_p;
-        static double gen2_ratio_correction;
-        static double ratio_correction_step;
-        static void calculate_tuning(int gen_number, bool use_this_loop_p);
-        static void init_bgc_end_data(int gen_number, bool use_this_loop_p);
-        static void calc_end_bgc_fl(int gen_number);
-        static void convert_to_fl(bool use_gen2_loop_p, bool use_gen3_loop_p);
-        static double calculate_ml_tuning(uint64_t current_available_physical, bool reduce_p, ptrdiff_t* _vfl_from_kp, ptrdiff_t* _vfl_from_ki);
-        static void set_total_gen_sizes(bool use_gen2_loop_p, bool use_gen3_loop_p);
-        static bool should_trigger_bgc_loh();
-        static bool should_trigger_bgc();
-        static bool should_trigger_ngc2();
-        static bool should_delay_alloc(int gen_number);
-        static bool stepping_trigger(uint32_t current_memory_load, size_t current_gen2_count);
-        static void update_bgc_start(int gen_number, size_t num_gen1s_since_end);
-        static void record_bgc_start();
-        static void update_bgc_sweep_start(int gen_number, size_t num_gen1s_since_start);
-        static void record_bgc_sweep_start();
-        static void record_and_adjust_bgc_end();
-    };
-    PER_HEAP_ISOLATED_METHOD void check_and_adjust_bgc_tuning (int gen_number, size_t physical_size, ptrdiff_t virtual_fl_size);
-#endif //BGC_SERVO_TUNING
-#ifndef USE_REGIONS
-    PER_HEAP_METHOD BOOL expand_soh_with_minimal_gc();
-#endif //!USE_REGIONS
-    PER_HEAP_METHOD void garbage_collect (int n);
-    PER_HEAP_ISOLATED_METHOD void pm_full_gc_init_or_clear();
-    PER_HEAP_METHOD void garbage_collect_pm_full_gc();
-    PER_HEAP_ISOLATED_METHOD bool is_pm_ratio_exceeded();
-    PER_HEAP_METHOD void init_records();
-    PER_HEAP_ISOLATED_METHOD uint32_t* make_card_table (uint8_t* start, uint8_t* end);
-    PER_HEAP_ISOLATED_METHOD void get_card_table_element_layout (uint8_t* start, uint8_t* end, size_t layout[total_bookkeeping_elements + 1]);
-    PER_HEAP_ISOLATED_METHOD void get_card_table_element_sizes (uint8_t* start, uint8_t* end, size_t bookkeeping_sizes[total_bookkeeping_elements]);
-    PER_HEAP_ISOLATED_METHOD void set_fgm_result (failure_get_memory f, size_t s, BOOL loh_p);
-#ifdef USE_REGIONS
-    PER_HEAP_ISOLATED_METHOD bool on_used_changed (uint8_t* left);
-    PER_HEAP_ISOLATED_METHOD bool get_card_table_commit_layout (uint8_t* from, uint8_t* to,
-                                        uint8_t* commit_begins[total_bookkeeping_elements],
-                                        size_t commit_sizes[total_bookkeeping_elements],
-                                        size_t new_sizes[total_bookkeeping_elements]);
-    PER_HEAP_ISOLATED_METHOD bool inplace_commit_card_table (uint8_t* from, uint8_t* to);
-#else //USE_REGIONS
-    PER_HEAP_ISOLATED_METHOD int grow_brick_card_tables (uint8_t* start,
-                                uint8_t* end,
-                                size_t size,
-                                heap_segment* new_seg,
-                                gc_heap* hp,
-                                BOOL loh_p);
-    PER_HEAP_METHOD void copy_brick_card_range (uint8_t* la, uint32_t* old_card_table,
-        short* old_brick_table,
-        uint8_t* start, uint8_t* end);
-    PER_HEAP_METHOD void copy_brick_card_table ();
-    PER_HEAP_ISOLATED_METHOD void copy_brick_card_table_on_growth ();
-#endif //USE_REGIONS
-    PER_HEAP_ISOLATED_METHOD BOOL is_mark_set (uint8_t* o);
-    PER_HEAP_ISOLATED_METHOD BOOL reserve_initial_memory (size_t normal_size, size_t large_size, size_t pinned_size, int num_heaps, bool use_large_pages_p, bool separated_poh_p, uint16_t* heap_no_to_numa_node);
-    PER_HEAP_ISOLATED_METHOD void destroy_initial_memory();
-    PER_HEAP_ISOLATED_METHOD void walk_heap (walk_fn fn, void* context, int gen_number, BOOL walk_large_object_heap_p);
-    PER_HEAP_METHOD void walk_heap_per_heap (walk_fn fn, void* context, int gen_number, BOOL walk_large_object_heap_p);
-    struct walk_relocate_args
-    {
-        uint8_t* last_plug;
-        BOOL is_shortened;
-        mark* pinned_plug_entry;
-        void* profiling_context;
-        record_surv_fn fn;
-    };
-    PER_HEAP_METHOD void walk_survivors (record_surv_fn fn, void* context, walk_surv_type type);
-    PER_HEAP_METHOD void walk_plug (uint8_t* plug, size_t size, BOOL check_last_object_p,
-                    walk_relocate_args* args);
-    PER_HEAP_METHOD void walk_relocation (void* profiling_context, record_surv_fn fn);
-#ifdef USE_REGIONS
-    PER_HEAP_METHOD heap_segment* walk_relocation_sip (heap_segment* current_heap_segment, void* profiling_context, record_surv_fn fn);
-#endif // USE_REGIONS
-    PER_HEAP_METHOD void walk_relocation_in_brick (uint8_t* tree, walk_relocate_args* args);
-    PER_HEAP_METHOD void walk_finalize_queue (fq_walk_fn fn);
-#if defined(BACKGROUND_GC) && defined(FEATURE_EVENT_TRACE)
-    PER_HEAP_METHOD void walk_survivors_for_bgc (void* profiling_context, record_surv_fn fn);
-#endif // defined(BACKGROUND_GC) && defined(FEATURE_EVENT_TRACE)
-    PER_HEAP_METHOD void walk_survivors_relocation (void* profiling_context, record_surv_fn fn);
-    PER_HEAP_METHOD void walk_survivors_for_uoh (void* profiling_context, record_surv_fn fn, int gen_number);
-    PER_HEAP_ISOLATED_METHOD size_t generation_allocator_efficiency_percent (generation* inst);
-    PER_HEAP_ISOLATED_METHOD size_t generation_unusable_fragmentation (generation* inst, int hn);
-    PER_HEAP_METHOD int generation_to_condemn (int n,
-                               BOOL* blocking_collection_p,
-                               BOOL* elevation_requested_p,
-                               BOOL check_only_p);
-    PER_HEAP_ISOLATED_METHOD int joined_generation_to_condemn (BOOL should_evaluate_elevation,
-                                      int initial_gen,
-                                      int current_gen,
-                                      BOOL* blocking_collection
-                                      STRESS_HEAP_ARG(int n_original));
-    PER_HEAP_METHOD size_t min_reclaim_fragmentation_threshold (uint32_t num_heaps);
-    PER_HEAP_ISOLATED_METHOD uint64_t min_high_fragmentation_threshold (uint64_t available_mem, uint32_t num_heaps);
-    PER_HEAP_METHOD void concurrent_print_time_delta (const char* msg);
-    PER_HEAP_METHOD void free_list_info (int gen_num, const char* msg);
-    PER_HEAP_METHOD void gc1();
-#ifdef DYNAMIC_HEAP_COUNT
-    PER_HEAP_ISOLATED_METHOD size_t get_total_soh_stable_size();
-    PER_HEAP_ISOLATED_METHOD void update_total_soh_stable_size();
-    PER_HEAP_ISOLATED_METHOD void assign_new_budget (int gen_number, size_t desired_per_heap);
-    PER_HEAP_METHOD bool prepare_rethread_fl_items();
-    PER_HEAP_METHOD void rethread_fl_items(int gen_idx);
-    PER_HEAP_ISOLATED_METHOD void merge_fl_from_other_heaps (int gen_idx, int to_n_heaps, int from_n_heaps);
-#endif //DYNAMIC_HEAP_COUNT
-    PER_HEAP_ISOLATED_METHOD void save_data_for_no_gc();
-    PER_HEAP_ISOLATED_METHOD void restore_data_for_no_gc();
-    PER_HEAP_ISOLATED_METHOD void update_collection_counts_for_no_gc();
-    PER_HEAP_ISOLATED_METHOD BOOL should_proceed_with_gc();
-    PER_HEAP_ISOLATED_METHOD void record_gcs_during_no_gc();
-    PER_HEAP_METHOD BOOL find_loh_free_for_no_gc();
-    PER_HEAP_METHOD BOOL find_loh_space_for_no_gc();
-    PER_HEAP_METHOD BOOL commit_loh_for_no_gc (heap_segment* seg);
-    PER_HEAP_ISOLATED_METHOD start_no_gc_region_status prepare_for_no_gc_region (uint64_t total_size,
-                                                        BOOL loh_size_known,
-                                                        uint64_t loh_size,
-                                                        BOOL disallow_full_blocking);
-    PER_HEAP_METHOD BOOL loh_allocated_for_no_gc();
-    PER_HEAP_ISOLATED_METHOD void release_no_gc_loh_segments();
-    PER_HEAP_ISOLATED_METHOD void thread_no_gc_loh_segments();
-    PER_HEAP_METHOD void check_and_set_no_gc_oom();
-    PER_HEAP_METHOD void allocate_for_no_gc_after_gc();
-    PER_HEAP_ISOLATED_METHOD
-    enable_no_gc_region_callback_status enable_no_gc_callback(NoGCRegionCallbackFinalizerWorkItem* callback, uint64_t callback_threshold);
-#ifdef USE_REGIONS
-    PER_HEAP_METHOD bool extend_soh_for_no_gc();
-#endif //USE_REGIONS
-    PER_HEAP_METHOD void set_loh_allocations_for_no_gc();
-    PER_HEAP_METHOD void set_soh_allocations_for_no_gc();
-    PER_HEAP_METHOD void prepare_for_no_gc_after_gc();
-    PER_HEAP_ISOLATED_METHOD void set_allocations_for_no_gc();
-    PER_HEAP_ISOLATED_METHOD BOOL should_proceed_for_no_gc();
-    PER_HEAP_ISOLATED_METHOD start_no_gc_region_status get_start_no_gc_region_status();
-    PER_HEAP_ISOLATED_METHOD end_no_gc_region_status end_no_gc_region();
-    PER_HEAP_ISOLATED_METHOD void schedule_finalizer_work(FinalizerWorkItem* callback);
-    PER_HEAP_ISOLATED_METHOD void schedule_no_gc_callback(bool abandoned);
-    PER_HEAP_ISOLATED_METHOD void handle_failure_for_no_gc();
-    PER_HEAP_METHOD void fire_mark_event (int root_type,
-                          size_t& current_promoted_bytes,
-                          size_t& last_promoted_bytes);
-    PER_HEAP_METHOD size_t limit_from_size (size_t size, uint32_t flags, size_t room, int gen_number,
-                            int align_const);
-    PER_HEAP_METHOD allocation_state try_allocate_more_space (alloc_context* acontext, size_t jsize, uint32_t flags,
-                                              int alloc_generation_number);
-    PER_HEAP_ISOLATED_METHOD BOOL allocate_more_space (alloc_context* acontext, size_t jsize, uint32_t flags,
-                              int alloc_generation_number);
-    PER_HEAP_METHOD bool should_move_heap (GCSpinLock* msl);
-    PER_HEAP_METHOD enter_msl_status enter_spin_lock_msl_helper (GCSpinLock* msl);
-    PER_HEAP_METHOD enter_msl_status enter_spin_lock_msl (GCSpinLock* msl);
-    PER_HEAP_METHOD size_t get_full_compact_gc_count();
-    PER_HEAP_METHOD BOOL short_on_end_of_seg (heap_segment* seg);
-    PER_HEAP_METHOD BOOL a_fit_free_list_p (int gen_number,
-                            size_t size,
-                            alloc_context* acontext,
-                            uint32_t flags,
-                            int align_const);
-#ifdef BACKGROUND_GC
-    PER_HEAP_METHOD enter_msl_status wait_for_background (alloc_wait_reason awr, bool loh_p);
-    PER_HEAP_METHOD bool wait_for_bgc_high_memory (alloc_wait_reason awr, bool loh_p, enter_msl_status* msl_status);
-    PER_HEAP_METHOD void bgc_uoh_alloc_clr (uint8_t* alloc_start,
-                            size_t size,
-                            alloc_context* acontext,
-                            uint32_t flags,
-                            int gen_number,
-                            int align_const,
-                            int lock_index,
-                            BOOL check_used_p,
-                            heap_segment* seg);
-#endif //BACKGROUND_GC
-#ifdef BACKGROUND_GC
-    PER_HEAP_METHOD void bgc_track_uoh_alloc();
-    PER_HEAP_METHOD void bgc_untrack_uoh_alloc();
-    PER_HEAP_METHOD BOOL bgc_loh_allocate_spin();
-    PER_HEAP_METHOD BOOL bgc_poh_allocate_spin();
-    PER_HEAP_METHOD void bgc_record_uoh_allocation(int gen_number, size_t size);
-#endif //BACKGROUND_GC
-    PER_HEAP_METHOD void add_saved_spinlock_info (
-            bool loh_p,
-            msl_enter_state enter_state,
-            msl_take_state take_state,
-            enter_msl_status msl_status);
-    PER_HEAP_METHOD enter_msl_status trigger_gc_for_alloc (int gen_number, gc_reason reason,
-                               GCSpinLock* spin_lock, bool loh_p,
-                               msl_take_state take_state);
-    PER_HEAP_METHOD BOOL a_fit_free_list_uoh_p (size_t size,
-                                  alloc_context* acontext,
-                                  uint32_t flags,
-                                  int align_const,
-                                  int gen_number);
-    PER_HEAP_METHOD BOOL a_fit_segment_end_p (int gen_number,
-                              heap_segment* seg,
-                              size_t size,
-                              alloc_context* acontext,
-                              uint32_t flags,
-                              int align_const,
-                              BOOL* commit_failed_p);
-    PER_HEAP_METHOD BOOL uoh_a_fit_segment_end_p (int gen_number,
-                                  size_t size,
-                                  alloc_context* acontext,
-                                  uint32_t flags,
-                                  int align_const,
-                                  BOOL* commit_failed_p,
-                                  oom_reason* oom_r);
-    PER_HEAP_METHOD BOOL uoh_get_new_seg (int gen_number,
-                          size_t size,
-                          BOOL* commit_failed_p,
-                          oom_reason* oom_r,
-                          enter_msl_status* msl_status);
-    PER_HEAP_ISOLATED_METHOD size_t get_uoh_seg_size (size_t size);
-    PER_HEAP_METHOD BOOL retry_full_compact_gc (size_t size);
-    PER_HEAP_METHOD BOOL check_and_wait_for_bgc (alloc_wait_reason awr,
-                                 BOOL* did_full_compact_gc,
-                                 bool loh_p,
-                                 enter_msl_status* msl_status);
-    PER_HEAP_METHOD BOOL trigger_full_compact_gc (gc_reason gr,
-                                  oom_reason* oom_r,
-                                  bool loh_p,
-                                  enter_msl_status* msl_status);
-    PER_HEAP_METHOD BOOL trigger_ephemeral_gc (gc_reason gr, enter_msl_status* msl_status);
-    PER_HEAP_METHOD BOOL soh_try_fit (int gen_number,
-                      size_t size,
-                      alloc_context* acontext,
-                      uint32_t flags,
-                      int align_const,
-                      BOOL* commit_failed_p,
-                      BOOL* short_seg_end_p);
-    PER_HEAP_METHOD BOOL uoh_try_fit (int gen_number,
-                      size_t size,
-                      alloc_context* acontext,
-                      uint32_t flags,
-                      int align_const,
-                      BOOL* commit_failed_p,
-                      oom_reason* oom_r);
-    PER_HEAP_METHOD allocation_state allocate_soh (int gen_number,
-                                     size_t size,
-                                     alloc_context* acontext,
-                                     uint32_t flags,
-                                     int align_const);
-#ifdef RECORD_LOH_STATE
-    PER_HEAP_METHOD void add_saved_loh_state (allocation_state loh_state_to_save, EEThreadId thread_id);
-#endif //RECORD_LOH_STATE
-    PER_HEAP_METHOD allocation_state allocate_uoh (int gen_number,
-                                     size_t size,
-                                     alloc_context* acontext,
-                                     uint32_t flags,
-                                     int align_const);
-    PER_HEAP_ISOLATED_METHOD int init_semi_shared();
-    PER_HEAP_METHOD int init_gc_heap (int heap_number);
-    PER_HEAP_METHOD void self_destroy();
-    PER_HEAP_ISOLATED_METHOD void destroy_semi_shared();
-    PER_HEAP_METHOD void repair_allocation_contexts (BOOL repair_p);
-    PER_HEAP_METHOD void fix_allocation_contexts (BOOL for_gc_p);
-#ifdef MULTIPLE_HEAPS
-    PER_HEAP_ISOLATED_METHOD void fix_allocation_contexts_heaps ();
-    PER_HEAP_ISOLATED_METHOD void fix_allocation_context_heaps (gc_alloc_context* acontext, void*);
-#endif //MULTIPLE_HEAPS
-    PER_HEAP_METHOD void fix_youngest_allocation_area();
-    PER_HEAP_METHOD void fix_allocation_context (alloc_context* acontext, BOOL for_gc_p,
-                                 BOOL record_ac_p);
-    PER_HEAP_METHOD void fix_older_allocation_area (generation* older_gen);
-    PER_HEAP_METHOD void set_allocation_heap_segment (generation* gen);
-    PER_HEAP_METHOD void reset_allocation_pointers (generation* gen, uint8_t* start);
-    PER_HEAP_METHOD int object_gennum (uint8_t* o);
-    PER_HEAP_METHOD int object_gennum_plan (uint8_t* o);
-    PER_HEAP_ISOLATED_METHOD void init_heap_segment (heap_segment* seg, gc_heap* hp
-#ifdef USE_REGIONS
-                            , uint8_t* start, size_t size, int gen_num, bool existing_region_p=false
-#endif //USE_REGIONS
-                           );
-    PER_HEAP_METHOD void delete_heap_segment (heap_segment* seg, BOOL consider_hoarding=FALSE);
-#ifdef FEATURE_BASICFREEZE
-    PER_HEAP_METHOD BOOL insert_ro_segment (heap_segment* seg);
-    PER_HEAP_METHOD void remove_ro_segment (heap_segment* seg);
-    PER_HEAP_METHOD void update_ro_segment (heap_segment* seg, uint8_t* allocated, uint8_t* committed);
-#endif //FEATURE_BASICFREEZE
-#ifndef USE_REGIONS
-    PER_HEAP_METHOD BOOL set_ro_segment_in_range (heap_segment* seg);
-    PER_HEAP_METHOD heap_segment* soh_get_segment_to_expand();
-    PER_HEAP_METHOD heap_segment* get_segment (size_t size, gc_oh_num oh);
-    PER_HEAP_ISOLATED_METHOD void release_segment (heap_segment* sg);
-    PER_HEAP_ISOLATED_METHOD void seg_mapping_table_add_segment (heap_segment* seg, gc_heap* hp);
-    PER_HEAP_ISOLATED_METHOD void seg_mapping_table_remove_segment (heap_segment* seg);
-#endif //!USE_REGIONS
-    PER_HEAP_METHOD heap_segment* get_uoh_segment (int gen_number, size_t size, BOOL* did_full_compact_gc, enter_msl_status* msl_status);
-    PER_HEAP_METHOD void thread_uoh_segment (int gen_number, heap_segment* new_seg);
-    PER_HEAP_ISOLATED_METHOD heap_segment* get_segment_for_uoh (int gen_number, size_t size
-#ifdef MULTIPLE_HEAPS
-                                      , gc_heap* hp
-#endif //MULTIPLE_HEAPS
-                                      );
-    PER_HEAP_METHOD void reset_heap_segment_pages (heap_segment* seg);
-    PER_HEAP_METHOD void decommit_heap_segment_pages (heap_segment* seg, size_t extra_space);
-#if defined(MULTIPLE_HEAPS)
-    PER_HEAP_METHOD size_t decommit_ephemeral_segment_pages_step ();
-#endif //MULTIPLE_HEAPS
-    PER_HEAP_METHOD size_t decommit_heap_segment_pages_worker (heap_segment* seg, uint8_t *new_committed);
-#if !defined(USE_REGIONS) || defined(MULTIPLE_HEAPS)
-    PER_HEAP_METHOD uint8_t* get_smoothed_decommit_target (uint8_t* previous_decommit_target,
-        uint8_t* new_decommit_target, heap_segment* seg);
-    PER_HEAP_METHOD void decommit_ephemeral_segment_pages();
-#endif //!USE_REGIONS || MULTIPLE_HEAPS
-#if defined(MULTIPLE_HEAPS) || defined(USE_REGIONS)
-    PER_HEAP_ISOLATED_METHOD bool decommit_step (uint64_t step_milliseconds);
-#endif //MULTIPLE_HEAPS || USE_REGIONS
-#ifdef USE_REGIONS
-    PER_HEAP_ISOLATED_METHOD size_t decommit_region (heap_segment* region, int bucket, int h_number);
-#endif //USE_REGIONS
-    PER_HEAP_METHOD void decommit_heap_segment (heap_segment* seg);
-    PER_HEAP_ISOLATED_METHOD bool virtual_alloc_commit_for_heap (void* addr, size_t size, int h_number);
-    PER_HEAP_ISOLATED_METHOD bool virtual_commit (void* address, size_t size, int bucket, int h_number=-1, bool* hard_limit_exceeded_p=NULL);
-    PER_HEAP_ISOLATED_METHOD bool virtual_decommit (void* address, size_t size, int bucket, int h_number=-1);
-    PER_HEAP_ISOLATED_METHOD void reduce_committed_bytes (void* address, size_t size, int bucket, int h_number, bool decommit_succeeded_p);
-    friend void destroy_card_table (uint32_t*);
-    PER_HEAP_ISOLATED_METHOD void destroy_card_table_helper (uint32_t* c_table);
-    PER_HEAP_ISOLATED_METHOD void virtual_free (void* add, size_t size, heap_segment* sg=NULL);
-    PER_HEAP_ISOLATED_METHOD void reset_memory(uint8_t* o, size_t sizeo);
-    PER_HEAP_METHOD void clear_gen0_bricks();
-    PER_HEAP_METHOD void check_gen0_bricks();
-#ifdef BACKGROUND_GC
-    PER_HEAP_METHOD void rearrange_small_heap_segments();
-#endif //BACKGROUND_GC
-    PER_HEAP_METHOD void rearrange_uoh_segments();
-#ifndef USE_REGIONS
-    PER_HEAP_METHOD void rearrange_heap_segments(BOOL compacting);
-#endif //!USE_REGIONS
-    PER_HEAP_METHOD void delay_free_segments();
-#ifdef BACKGROUND_GC
-    PER_HEAP_ISOLATED_METHOD void reset_write_watch_for_gc_heap(void* base_address, size_t region_size);
-    PER_HEAP_ISOLATED_METHOD void get_write_watch_for_gc_heap(bool reset, void *base_address, size_t region_size, void** dirty_pages, uintptr_t* dirty_page_count_ref, bool is_runtime_suspended);
-    PER_HEAP_METHOD void switch_one_quantum();
-    PER_HEAP_METHOD void reset_ww_by_chunk (uint8_t* start_address, size_t total_reset_size);
-    PER_HEAP_METHOD void switch_on_reset (BOOL concurrent_p, size_t* current_total_reset_size, size_t last_reset_size);
-    PER_HEAP_METHOD void reset_write_watch (BOOL concurrent_p);
-#endif //BACKGROUND_GC
-    PER_HEAP_METHOD void adjust_ephemeral_limits();
-    PER_HEAP_METHOD void make_generation (int gen_num, heap_segment* seg, uint8_t* start);
-#define USE_PADDING_FRONT 1
-#define USE_PADDING_TAIL  2
-    PER_HEAP_METHOD BOOL size_fit_p (size_t size REQD_ALIGN_AND_OFFSET_DCL, uint8_t* alloc_pointer, uint8_t* alloc_limit,
-                     uint8_t* old_loc=0, int use_padding=USE_PADDING_TAIL);
-    PER_HEAP_METHOD BOOL a_size_fit_p (size_t size, uint8_t* alloc_pointer, uint8_t* alloc_limit,
-                       int align_const);
-    PER_HEAP_METHOD void handle_oom (oom_reason reason, size_t alloc_size,
-                     uint8_t* allocated, uint8_t* reserved);
-    PER_HEAP_METHOD size_t card_of ( uint8_t* object);
-    PER_HEAP_METHOD uint8_t* brick_address (size_t brick);
-    PER_HEAP_METHOD size_t brick_of (uint8_t* add);
-    PER_HEAP_METHOD uint8_t* card_address (size_t card);
-    PER_HEAP_METHOD void clear_card (size_t card);
-    PER_HEAP_METHOD void set_card (size_t card);
-    PER_HEAP_METHOD BOOL  card_set_p (size_t card);
-    PER_HEAP_METHOD void card_table_set_bit (uint8_t* location);
-#ifdef CARD_BUNDLE
-    PER_HEAP_METHOD void update_card_table_bundle();
-    PER_HEAP_METHOD void reset_card_table_write_watch();
-    PER_HEAP_METHOD void card_bundle_clear(size_t cardb);
-    PER_HEAP_METHOD void card_bundle_set (size_t cardb);
-    PER_HEAP_METHOD void card_bundles_set (size_t start_cardb, size_t end_cardb);
-    PER_HEAP_METHOD void verify_card_bundle_bits_set(size_t first_card_word, size_t last_card_word);
-    PER_HEAP_METHOD void verify_card_bundles();
-    PER_HEAP_METHOD BOOL card_bundle_set_p (size_t cardb);
-    PER_HEAP_METHOD BOOL find_card_dword (size_t& cardw, size_t cardw_end);
-    PER_HEAP_METHOD void enable_card_bundles();
-    PER_HEAP_ISOLATED_METHOD BOOL card_bundles_enabled();
-#endif //CARD_BUNDLE
-    PER_HEAP_METHOD BOOL find_card (uint32_t* card_table, size_t& card,
-                    size_t card_word_end, size_t& end_card);
-    PER_HEAP_METHOD BOOL grow_heap_segment (heap_segment* seg, uint8_t* high_address, bool* hard_limit_exceeded_p=NULL);
-    PER_HEAP_METHOD int grow_heap_segment (heap_segment* seg, uint8_t* high_address, uint8_t* old_loc, size_t size, BOOL pad_front_p REQD_ALIGN_AND_OFFSET_DCL);
-    PER_HEAP_METHOD void clear_brick_table (uint8_t* from, uint8_t* end);
-    PER_HEAP_METHOD void set_brick (size_t index, ptrdiff_t val);
-    PER_HEAP_METHOD int get_brick_entry (size_t index);
-#ifdef BACKGROUND_GC
-    PER_HEAP_METHOD unsigned int mark_array_marked (uint8_t* add);
-    PER_HEAP_METHOD void mark_array_set_marked (uint8_t* add);
-    PER_HEAP_METHOD BOOL is_mark_bit_set (uint8_t* add);
-    PER_HEAP_METHOD void set_mark_array_bit (size_t mark_bit);
-    PER_HEAP_METHOD BOOL mark_array_bit_set (size_t mark_bit);
-    PER_HEAP_METHOD void mark_array_clear_marked (uint8_t* add);
-#ifdef FEATURE_BASICFREEZE
-    PER_HEAP_METHOD void seg_set_mark_array_bits_soh (heap_segment* seg);
-    PER_HEAP_METHOD void clear_mark_array (uint8_t* from, uint8_t* end);
-    PER_HEAP_METHOD void seg_clear_mark_array_bits_soh (heap_segment* seg);
-#endif // FEATURE_BASICFREEZE
-    PER_HEAP_METHOD void bgc_clear_batch_mark_array_bits (uint8_t* start, uint8_t* end);
-#ifdef VERIFY_HEAP
-    PER_HEAP_METHOD void set_batch_mark_array_bits (uint8_t* start, uint8_t* end);
-    PER_HEAP_METHOD void check_batch_mark_array_bits (uint8_t* start, uint8_t* end);
-#endif //VERIFY_HEAP
-#endif //BACKGROUND_GC
-    PER_HEAP_METHOD BOOL uoh_object_marked (uint8_t* o, BOOL clearp);
-#ifdef BACKGROUND_GC
-    PER_HEAP_METHOD BOOL background_allowed_p();
-#endif //BACKGROUND_GC
-    PER_HEAP_ISOLATED_METHOD void send_full_gc_notification (int gen_num, BOOL due_to_alloc_p);
-    PER_HEAP_METHOD void check_for_full_gc (int gen_num, size_t size);
-    PER_HEAP_METHOD void adjust_limit (uint8_t* start, size_t limit_size, generation* gen);
-    PER_HEAP_METHOD void adjust_limit_clr (uint8_t* start, size_t limit_size, size_t size,
-                           alloc_context* acontext, uint32_t flags, heap_segment* seg,
-                           int align_const, int gen_number);
-    PER_HEAP_METHOD void  leave_allocation_segment (generation* gen);
-    PER_HEAP_METHOD void init_free_and_plug();
-    PER_HEAP_METHOD void print_free_and_plug (const char* msg);
-    PER_HEAP_METHOD void add_gen_plug (int gen_number, size_t plug_size);
-    PER_HEAP_ISOLATED_METHOD int find_bucket (size_t size);
-    PER_HEAP_METHOD void add_gen_free (int gen_number, size_t free_size);
-    PER_HEAP_METHOD void add_gen_plug_allocated_in_free (int gen_number, size_t plug_size);
-    PER_HEAP_METHOD void add_item_to_current_pinned_free (int gen_number, size_t free_size);
-    PER_HEAP_METHOD void remove_gen_free (int gen_number, size_t free_size);
-    PER_HEAP_METHOD void thread_free_item_front (generation* gen, uint8_t* free_start, size_t free_size);
-#ifdef DOUBLY_LINKED_FL
-    PER_HEAP_METHOD void thread_item_front_added (generation* gen, uint8_t* free_start, size_t free_size);
-#endif //DOUBLY_LINKED_FL
-    PER_HEAP_METHOD void make_free_obj (generation* gen, uint8_t* free_start, size_t free_size);
-    PER_HEAP_METHOD uint8_t* allocate_in_older_generation (generation* gen, size_t size,
-                                        int from_gen_number,
-                                        uint8_t* old_loc=0
-                                        REQD_ALIGN_AND_OFFSET_DEFAULT_DCL);
-    PER_HEAP_METHOD void init_alloc_info (generation* gen, heap_segment* seg);
-    PER_HEAP_METHOD heap_segment* get_next_alloc_seg (generation* gen);
-#ifndef USE_REGIONS
-    PER_HEAP_METHOD generation*  ensure_ephemeral_heap_segment (generation* consing_gen);
-#endif //!USE_REGIONS
-    PER_HEAP_METHOD uint8_t* allocate_in_condemned_generations (generation* gen,
-                                             size_t size,
-                                             int from_gen_number,
-#ifdef SHORT_PLUGS
-                                             BOOL* convert_to_pinned_p=NULL,
-                                             uint8_t* next_pinned_plug=0,
-                                             heap_segment* current_seg=0,
-#endif //SHORT_PLUGS
-                                             uint8_t* old_loc=0
-                                             REQD_ALIGN_AND_OFFSET_DEFAULT_DCL);
-    PER_HEAP_ISOLATED_METHOD heap_segment* find_segment (uint8_t* interior, BOOL small_segment_only_p);
-    PER_HEAP_ISOLATED_METHOD gc_heap* heap_of (uint8_t* object);
-    PER_HEAP_ISOLATED_METHOD gc_heap* heap_of_gc (uint8_t* object);
-    PER_HEAP_METHOD size_t get_promoted_bytes();
-#ifdef USE_REGIONS
-    PER_HEAP_ISOLATED_METHOD void sync_promoted_bytes();
-    PER_HEAP_ISOLATED_METHOD void set_heap_for_contained_basic_regions (heap_segment* region, gc_heap* hp);
-    PER_HEAP_METHOD heap_segment* unlink_first_rw_region (int gen_idx);
-    PER_HEAP_METHOD void thread_rw_region_front (int gen_idx, heap_segment* region);
-    PER_HEAP_ISOLATED_METHOD void equalize_promoted_bytes (int condemned_gen_number);
-#ifdef DYNAMIC_HEAP_COUNT
-    PER_HEAP_METHOD void check_decommissioned_heap();
-    PER_HEAP_METHOD void decommission_heap();
-    PER_HEAP_METHOD void recommission_heap();
-    PER_HEAP_ISOLATED_METHOD void calculate_new_heap_count();
-    PER_HEAP_METHOD void check_heap_count();
-    PER_HEAP_ISOLATED_METHOD bool prepare_to_change_heap_count (int new_n_heaps);
-    PER_HEAP_METHOD bool change_heap_count (int new_n_heaps);
-    PER_HEAP_ISOLATED_METHOD void get_msl_wait_time (size_t* soh_msl_wait_time, size_t* uoh_msl_wait_time);
-    PER_HEAP_ISOLATED_METHOD void process_datas_sample();
-    PER_HEAP_METHOD void add_to_hc_history_worker (hc_history* hist, int* current_index, hc_record_stage stage, const char* msg);
-    PER_HEAP_METHOD void add_to_hc_history (hc_record_stage stage);
-#ifdef BACKGROUND_GC
-    PER_HEAP_METHOD void add_to_bgc_hc_history (hc_record_stage stage);
-    PER_HEAP_ISOLATED_METHOD void add_to_bgc_th_creation_history (size_t gc_index,
-                                                                  size_t count_created,
-                                                                  size_t  count_created_th_existed,
-                                                                  size_t count_creation_failed);
-#endif //BACKGROUND_GC
-#endif //DYNAMIC_HEAP_COUNT
-#endif //USE_REGIONS
-#if !defined(USE_REGIONS) || defined(_DEBUG)
-    PER_HEAP_METHOD void init_promoted_bytes();
-    PER_HEAP_METHOD size_t& promoted_bytes (int thread);
-#endif //!USE_REGIONS || _DEBUG
-    PER_HEAP_METHOD void add_to_promoted_bytes (uint8_t* object, int thread);
-    PER_HEAP_METHOD void add_to_promoted_bytes (uint8_t* object, size_t obj_size, int thread);
-    PER_HEAP_METHOD uint8_t* find_object (uint8_t* o);
-    PER_HEAP_METHOD dynamic_data* dynamic_data_of (int gen_number);
-    PER_HEAP_METHOD ptrdiff_t  get_desired_allocation (int gen_number);
-    PER_HEAP_METHOD ptrdiff_t  get_new_allocation (int gen_number);
-    PER_HEAP_METHOD ptrdiff_t  get_allocation (int gen_number);
-    PER_HEAP_METHOD bool new_allocation_allowed (int gen_number);
-#ifdef BACKGROUND_GC
-    PER_HEAP_ISOLATED_METHOD void allow_new_allocation (int gen_number);
-    PER_HEAP_ISOLATED_METHOD void disallow_new_allocation (int gen_number);
-#endif //BACKGROUND_GC
-    PER_HEAP_METHOD void reset_pinned_queue();
-    PER_HEAP_METHOD void reset_pinned_queue_bos();
-    PER_HEAP_METHOD void set_allocator_next_pin (generation* gen);
-    PER_HEAP_METHOD void enque_pinned_plug (generation* gen, uint8_t* plug, size_t len);
-    PER_HEAP_METHOD void enque_pinned_plug (uint8_t* plug,
-                            BOOL save_pre_plug_info_p,
-                            uint8_t* last_object_in_last_plug);
-    PER_HEAP_METHOD void merge_with_last_pinned_plug (uint8_t* last_pinned_plug, size_t plug_size);
-    PER_HEAP_METHOD void set_pinned_info (uint8_t* last_pinned_plug, size_t plug_len, generation* gen);
-    PER_HEAP_METHOD void save_post_plug_info (uint8_t* last_pinned_plug, uint8_t* last_object_in_last_plug, uint8_t* post_plug);
-    PER_HEAP_METHOD size_t deque_pinned_plug ();
-    PER_HEAP_METHOD mark* pinned_plug_of (size_t bos);
-    PER_HEAP_METHOD mark* oldest_pin ();
-    PER_HEAP_METHOD mark* before_oldest_pin();
-    PER_HEAP_METHOD BOOL pinned_plug_que_empty_p ();
-    PER_HEAP_METHOD void make_mark_stack (mark* arr);
-#ifdef MH_SC_MARK
-    PER_HEAP_METHOD int& mark_stack_busy();
-    PER_HEAP_METHOD VOLATILE(uint8_t*)& ref_mark_stack (gc_heap* hp, int index);
-#endif
-#ifdef BACKGROUND_GC
-    PER_HEAP_ISOLATED_METHOD size_t&  bpromoted_bytes (int);
-    PER_HEAP_METHOD void make_background_mark_stack (uint8_t** arr);
-    PER_HEAP_METHOD void make_c_mark_list (uint8_t** arr);
-#endif //BACKGROUND_GC
-    PER_HEAP_METHOD generation* generation_of (int  n);
-    PER_HEAP_METHOD BOOL gc_mark1 (uint8_t* o);
-    PER_HEAP_METHOD BOOL gc_mark (uint8_t* o, uint8_t* low, uint8_t* high, int condemned_gen);
-    PER_HEAP_METHOD void mark_object (uint8_t* o THREAD_NUMBER_DCL);
-#ifdef HEAP_ANALYZE
-    PER_HEAP_METHOD void ha_mark_object_simple (uint8_t** o THREAD_NUMBER_DCL);
-#endif //HEAP_ANALYZE
-    PER_HEAP_METHOD void mark_object_simple (uint8_t** o THREAD_NUMBER_DCL);
-    PER_HEAP_METHOD void mark_object_simple1 (uint8_t* o, uint8_t* start THREAD_NUMBER_DCL);
-    PER_HEAP_METHOD void drain_mark_queue();
-#ifdef MH_SC_MARK
-    PER_HEAP_METHOD void mark_steal ();
-#endif //MH_SC_MARK
-#ifdef BACKGROUND_GC
-    PER_HEAP_METHOD BOOL background_marked (uint8_t* o);
-    PER_HEAP_METHOD BOOL background_mark1 (uint8_t* o);
-    PER_HEAP_METHOD BOOL background_mark (uint8_t* o, uint8_t* low, uint8_t* high);
-    PER_HEAP_METHOD uint8_t* background_mark_object (uint8_t* o THREAD_NUMBER_DCL);
-    PER_HEAP_METHOD void background_mark_simple (uint8_t* o THREAD_NUMBER_DCL);
-    PER_HEAP_METHOD void background_mark_simple1 (uint8_t* o THREAD_NUMBER_DCL);
-    PER_HEAP_ISOLATED_METHOD void background_promote (Object**, ScanContext* , uint32_t);
-    PER_HEAP_METHOD BOOL background_object_marked (uint8_t* o, BOOL clearp);
-    PER_HEAP_METHOD void init_background_gc();
-    PER_HEAP_METHOD uint8_t* background_next_end (heap_segment*, BOOL);
-    PER_HEAP_METHOD void background_delay_delete_uoh_segments();
-    PER_HEAP_METHOD void generation_delete_heap_segment (generation*,
-                                         heap_segment*, heap_segment*, heap_segment*);
-    PER_HEAP_METHOD void set_mem_verify (uint8_t*, uint8_t*, uint8_t);
-    PER_HEAP_METHOD void process_background_segment_end (heap_segment*, generation*, uint8_t*,
-                                         heap_segment*, BOOL* delete_p,
-                                         size_t free_obj_size_last_gap);
-    PER_HEAP_METHOD BOOL fgc_should_consider_object (uint8_t* o,
-                                     heap_segment* seg,
-                                     BOOL consider_bgc_mark_p,
-                                     BOOL check_current_sweep_p,
-                                     BOOL check_saved_sweep_p);
-    PER_HEAP_METHOD void should_check_bgc_mark (heap_segment* seg,
-                                BOOL* consider_bgc_mark_p,
-                                BOOL* check_current_sweep_p,
-                                BOOL* check_saved_sweep_p);
-#ifdef DOUBLY_LINKED_FL
-    PER_HEAP_METHOD BOOL should_set_bgc_mark_bit (uint8_t* o);
-#endif //DOUBLY_LINKED_FL
-    PER_HEAP_METHOD void background_ephemeral_sweep();
-    PER_HEAP_METHOD void background_sweep ();
-    PER_HEAP_METHOD void check_bgc_mark_stack_length();
-    PER_HEAP_METHOD void grow_bgc_mark_stack (size_t new_size);
-    PER_HEAP_METHOD uint8_t* background_seg_end (heap_segment* seg, BOOL concurrent_p);
-    PER_HEAP_METHOD uint8_t* background_first_overflow (uint8_t* min_add,
-                                     heap_segment* seg,
-                                     BOOL concurrent_p,
-                                     BOOL small_object_p);
-    PER_HEAP_METHOD void background_process_mark_overflow_internal (uint8_t* min_add, uint8_t* max_add,
-                                                    BOOL concurrent_p);
-    PER_HEAP_METHOD BOOL background_process_mark_overflow (BOOL concurrent_p);
-    PER_HEAP_METHOD void scan_background_roots (promote_func* fn, int hn, ScanContext *pSC);
-    PER_HEAP_METHOD BOOL bgc_mark_array_range (heap_segment* seg,
-                               BOOL whole_seg_p,
-                               uint8_t** range_beg,
-                               uint8_t** range_end);
-    PER_HEAP_METHOD void bgc_verify_mark_array_cleared (heap_segment* seg, bool always_verify_p = false);
-    PER_HEAP_METHOD void verify_mark_array_cleared();
-    PER_HEAP_METHOD void verify_partial();
-    PER_HEAP_METHOD void verify_mark_bits_cleared (uint8_t* obj, size_t s);
-#ifdef USE_REGIONS
-    PER_HEAP_METHOD void set_background_overflow_p (uint8_t* oo);
-#endif
-#endif //BACKGROUND_GC
-    PER_HEAP_METHOD void mark_through_object (uint8_t* oo, BOOL mark_class_object_p THREAD_NUMBER_DCL);
-    PER_HEAP_METHOD BOOL process_mark_overflow (int condemned_gen_number);
-    PER_HEAP_METHOD void process_mark_overflow_internal (int condemned_gen_number,
-                                         uint8_t* min_address, uint8_t* max_address);
-#ifdef SNOOP_STATS
-    PER_HEAP_METHOD void print_snoop_stat();
-#endif //SNOOP_STATS
-#ifdef MH_SC_MARK
-    PER_HEAP_METHOD BOOL check_next_mark_stack (gc_heap* next_heap);
-#endif //MH_SC_MARK
-    PER_HEAP_METHOD void scan_dependent_handles (int condemned_gen_number, ScanContext *sc, BOOL initial_scan_p);
-    PER_HEAP_METHOD size_t get_generation_start_size (int gen_number);
-    PER_HEAP_ISOLATED_METHOD int get_num_heaps();
-    PER_HEAP_METHOD BOOL decide_on_promotion_surv (size_t threshold);
-    PER_HEAP_METHOD void mark_phase (int condemned_gen_number);
-    PER_HEAP_METHOD void pin_object (uint8_t* o, uint8_t** ppObject);
-    PER_HEAP_ISOLATED_METHOD size_t get_total_pinned_objects();
-    PER_HEAP_ISOLATED_METHOD void reinit_pinned_objects();
-    PER_HEAP_METHOD void reset_mark_stack ();
-    PER_HEAP_METHOD uint8_t* insert_node (uint8_t* new_node, size_t sequence_number,
-                       uint8_t* tree, uint8_t* last_node);
-    PER_HEAP_METHOD size_t update_brick_table (uint8_t* tree, size_t current_brick,
-                               uint8_t* x, uint8_t* plug_end);
-#ifndef USE_REGIONS
-    PER_HEAP_METHOD void plan_generation_start (generation* gen, generation* consing_gen, uint8_t* next_plug_to_allocate);
-    PER_HEAP_METHOD void realloc_plan_generation_start (generation* gen, generation* consing_gen);
-    PER_HEAP_METHOD void plan_generation_starts (generation*& consing_gen);
-    PER_HEAP_METHOD void advance_pins_for_demotion (generation* gen);
-    PER_HEAP_METHOD void process_ephemeral_boundaries(uint8_t* x, int& active_new_gen_number,
-                                      int& active_old_gen_number,
-                                      generation*& consing_gen,
-                                      BOOL& allocate_in_condemned);
-#endif //!USE_REGIONS
-#ifdef FEATURE_BASICFREEZE
-    PER_HEAP_METHOD void seg_set_mark_bits (heap_segment* seg);
-    PER_HEAP_METHOD void seg_clear_mark_bits (heap_segment* seg);
-    PER_HEAP_METHOD void mark_ro_segments();
-    PER_HEAP_METHOD void sweep_ro_segments();
-#endif // FEATURE_BASICFREEZE
-    PER_HEAP_METHOD void convert_to_pinned_plug (BOOL& last_npinned_plug_p,
-                                 BOOL& last_pinned_plug_p,
-                                 BOOL& pinned_plug_p,
-                                 size_t ps,
-                                 size_t& artificial_pinned_size);
-    PER_HEAP_METHOD void store_plug_gap_info (uint8_t* plug_start,
-                              uint8_t* plug_end,
-                              BOOL& last_npinned_plug_p,
-                              BOOL& last_pinned_plug_p,
-                              uint8_t*& last_pinned_plug,
-                              BOOL& pinned_plug_p,
-                              uint8_t* last_object_in_last_plug,
-                              BOOL& merge_with_last_pin_p,
-                              size_t last_plug_len);
-    PER_HEAP_METHOD void plan_phase (int condemned_gen_number);
-    PER_HEAP_METHOD void add_alloc_in_condemned_bucket (size_t plug_size);
-    PER_HEAP_METHOD uint8_t* find_next_marked (uint8_t* x, uint8_t* end,
-                               BOOL use_mark_list,
-                               uint8_t**& mark_list_next,
-                               uint8_t** mark_list_index);
-    PER_HEAP_METHOD void record_interesting_data_point (interesting_data_point idp);
-#ifdef GC_CONFIG_DRIVEN
-    PER_HEAP_METHOD void record_interesting_info_per_heap();
-    PER_HEAP_ISOLATED_METHOD void record_global_mechanisms();
-    PER_HEAP_ISOLATED_METHOD BOOL should_do_sweeping_gc (BOOL compact_p);
-#endif //GC_CONFIG_DRIVEN
-#ifdef FEATURE_LOH_COMPACTION
-    PER_HEAP_METHOD BOOL plan_loh();
-    PER_HEAP_METHOD void compact_loh();
-    PER_HEAP_METHOD void relocate_in_loh_compact();
-    PER_HEAP_METHOD void walk_relocation_for_loh (void* profiling_context, record_surv_fn fn);
-    PER_HEAP_METHOD BOOL loh_enque_pinned_plug (uint8_t* plug, size_t len);
-    PER_HEAP_METHOD void loh_set_allocator_next_pin();
-    PER_HEAP_METHOD BOOL loh_pinned_plug_que_empty_p();
-    PER_HEAP_METHOD size_t loh_deque_pinned_plug();
-    PER_HEAP_METHOD mark* loh_pinned_plug_of (size_t bos);
-    PER_HEAP_METHOD mark* loh_oldest_pin();
-    PER_HEAP_METHOD BOOL loh_size_fit_p (size_t size, uint8_t* alloc_pointer, uint8_t* alloc_limit, bool end_p);
-    PER_HEAP_METHOD uint8_t* loh_allocate_in_condemned (size_t size);
-    PER_HEAP_ISOLATED_METHOD BOOL loh_object_p (uint8_t* o);
-    PER_HEAP_ISOLATED_METHOD BOOL loh_compaction_requested();
-    PER_HEAP_ISOLATED_METHOD void check_loh_compact_mode  (BOOL all_heaps_compacted_p);
-#endif //FEATURE_LOH_COMPACTION
-    PER_HEAP_METHOD void fix_generation_bounds (int condemned_gen_number,
-                                generation* consing_gen);
-#ifndef USE_REGIONS
-    PER_HEAP_METHOD uint8_t* generation_limit (int gen_number);
-#endif //!USE_REGIONS
-    struct make_free_args
-    {
-        int free_list_gen_number;
-#ifndef USE_REGIONS
-        uint8_t* current_gen_limit;
-#endif //USE_REGIONS
-        generation* free_list_gen;
-        uint8_t* highest_plug;
-    };
-    PER_HEAP_METHOD uint8_t* allocate_at_end (size_t size);
-    PER_HEAP_METHOD BOOL ensure_gap_allocation (int condemned_gen_number);
-    PER_HEAP_METHOD void make_free_lists (int condemned_gen_number);
-    PER_HEAP_METHOD void make_free_list_in_brick (uint8_t* tree, make_free_args* args);
-    PER_HEAP_METHOD void thread_gap (uint8_t* gap_start, size_t size, generation*  gen);
-    PER_HEAP_METHOD void uoh_thread_gap_front (uint8_t* gap_start, size_t size, generation*  gen);
-    PER_HEAP_METHOD void make_unused_array (uint8_t* x, size_t size, BOOL clearp=FALSE, BOOL resetp=FALSE);
-    PER_HEAP_METHOD void clear_unused_array (uint8_t* x, size_t size);
-    PER_HEAP_METHOD void relocate_address (uint8_t** old_address THREAD_NUMBER_DCL);
-    struct relocate_args
-    {
-        uint8_t* last_plug;
-        BOOL is_shortened;
-        mark* pinned_plug_entry;
-    };
-    PER_HEAP_METHOD void reloc_survivor_helper (uint8_t** pval);
-    PER_HEAP_METHOD void check_class_object_demotion (uint8_t* obj);
-    PER_HEAP_METHOD void check_class_object_demotion_internal (uint8_t* obj);
-    PER_HEAP_METHOD void check_demotion_helper (uint8_t** pval, uint8_t* parent_obj);
-    PER_HEAP_METHOD void relocate_survivor_helper (uint8_t* plug, uint8_t* plug_end);
-    PER_HEAP_METHOD void verify_pins_with_post_plug_info (const char* msg);
-#ifdef COLLECTIBLE_CLASS
-    PER_HEAP_METHOD void unconditional_set_card_collectible (uint8_t* obj);
-#endif //COLLECTIBLE_CLASS
-    PER_HEAP_METHOD void relocate_shortened_survivor_helper (uint8_t* plug, uint8_t* plug_end, mark* pinned_plug_entry);
-    PER_HEAP_METHOD void relocate_obj_helper (uint8_t* x, size_t s);
-    PER_HEAP_METHOD void reloc_ref_in_shortened_obj (uint8_t** address_to_set_card, uint8_t** address_to_reloc);
-    PER_HEAP_METHOD void relocate_pre_plug_info (mark* pinned_plug_entry);
-    PER_HEAP_METHOD void relocate_shortened_obj_helper (uint8_t* x, size_t s, uint8_t* end, mark* pinned_plug_entry, BOOL is_pinned);
-    PER_HEAP_METHOD void relocate_survivors_in_plug (uint8_t* plug, uint8_t* plug_end,
-                                     BOOL check_last_object_p,
-                                     mark* pinned_plug_entry);
-    PER_HEAP_METHOD void relocate_survivors_in_brick (uint8_t* tree, relocate_args* args);
-    PER_HEAP_METHOD void update_oldest_pinned_plug();
-    PER_HEAP_METHOD heap_segment* get_start_segment (generation* gen);
-    PER_HEAP_METHOD void relocate_survivors (int condemned_gen_number,
-                             uint8_t* first_condemned_address );
-    PER_HEAP_METHOD void relocate_phase (int condemned_gen_number,
-                         uint8_t* first_condemned_address);
-    struct compact_args
-    {
-        BOOL copy_cards_p;
-        uint8_t* last_plug;
-        ptrdiff_t last_plug_relocation;
-        uint8_t* before_last_plug;
-        size_t current_compacted_brick;
-        BOOL is_shortened;
-        mark* pinned_plug_entry;
-        BOOL check_gennum_p;
-        int src_gennum;
-        void print()
-        {
-            dprintf (3, ("last plug: %Ix, last plug reloc: %Ix, before last: %Ix, b: %Ix",
-                last_plug, last_plug_relocation, before_last_plug, current_compacted_brick));
-        }
-    };
-    PER_HEAP_METHOD void copy_cards_range (uint8_t* dest, uint8_t* src, size_t len, BOOL copy_cards_p);
-    PER_HEAP_METHOD void  gcmemcopy (uint8_t* dest, uint8_t* src, size_t len, BOOL copy_cards_p);
-    PER_HEAP_METHOD void compact_plug (uint8_t* plug, size_t size, BOOL check_last_object_p, compact_args* args);
-    PER_HEAP_METHOD void compact_in_brick (uint8_t* tree, compact_args* args);
-    PER_HEAP_METHOD mark* get_next_pinned_entry (uint8_t* tree,
-                                 BOOL* has_pre_plug_info_p,
-                                 BOOL* has_post_plug_info_p,
-                                 BOOL deque_p=TRUE);
-    PER_HEAP_METHOD mark* get_oldest_pinned_entry (BOOL* has_pre_plug_info_p, BOOL* has_post_plug_info_p);
-    PER_HEAP_METHOD size_t recover_saved_pinned_info();
-    PER_HEAP_METHOD void compact_phase (int condemned_gen_number, uint8_t*
-                        first_condemned_address, BOOL clear_cards);
-    PER_HEAP_METHOD void clear_cards (size_t start_card, size_t end_card);
-    PER_HEAP_METHOD void clear_card_for_addresses (uint8_t* start_address, uint8_t* end_address);
-    PER_HEAP_METHOD void copy_cards (size_t dst_card, size_t src_card,
-                     size_t end_card, BOOL nextp);
-    PER_HEAP_METHOD void copy_cards_for_addresses (uint8_t* dest, uint8_t* src, size_t len);
-#ifdef BACKGROUND_GC
-    PER_HEAP_METHOD void copy_mark_bits (size_t dst_mark_bit, size_t src_mark_bit, size_t end_mark_bit);
-    PER_HEAP_METHOD void copy_mark_bits_for_addresses (uint8_t* dest, uint8_t* src, size_t len);
-#endif //BACKGROUND_GC
-    PER_HEAP_ISOLATED_METHOD bool is_in_find_object_range (uint8_t* o);
-#ifdef USE_REGIONS
-    PER_HEAP_ISOLATED_METHOD bool is_in_gc_range (uint8_t* o);
-    PER_HEAP_ISOLATED_METHOD bool is_in_condemned_gc (uint8_t* o);
-    PER_HEAP_ISOLATED_METHOD bool should_check_brick_for_reloc (uint8_t* o);
-#endif //USE_REGIONS
-    PER_HEAP_METHOD BOOL ephemeral_pointer_p (uint8_t* o);
-    PER_HEAP_METHOD void fix_brick_to_highest (uint8_t* o, uint8_t* next_o);
-    PER_HEAP_METHOD uint8_t* find_first_object (uint8_t* start_address, uint8_t* first_object);
-#ifndef USE_REGIONS
-    PER_HEAP_METHOD uint8_t* compute_next_boundary (int gen_number, BOOL relocating);
-#endif //!USE_REGIONS
-    PER_HEAP_METHOD void mark_through_cards_helper (uint8_t** poo, size_t& ngen,
-                                    size_t& cg_pointers_found,
-                                    card_fn fn, uint8_t* nhigh,
-                                    uint8_t* next_boundary,
-                                    int condemned_gen,
-                                    int current_gen
-                                    CARD_MARKING_STEALING_ARG(gc_heap* hpt));
-    PER_HEAP_METHOD BOOL card_transition (uint8_t* po, uint8_t* end, size_t card_word_end,
-                          size_t& cg_pointers_found,
-                          size_t& n_eph, size_t& n_card_set,
-                          size_t& card, size_t& end_card,
-                          BOOL& foundp, uint8_t*& start_address,
-                          uint8_t*& limit, size_t& n_cards_cleared
-                          CARD_MARKING_STEALING_ARGS(card_marking_enumerator& card_mark_enumerator, heap_segment* seg, size_t& card_word_end_out));
-    PER_HEAP_METHOD void mark_through_cards_for_segments(card_fn fn, BOOL relocating CARD_MARKING_STEALING_ARG(gc_heap* hpt));
-#ifndef USE_REGIONS
-    PER_HEAP_METHOD void repair_allocation_in_expanded_heap (generation* gen);
-    PER_HEAP_METHOD BOOL can_fit_in_spaces_p (size_t* ordered_blocks, int small_index, size_t* ordered_spaces, int big_index);
-    PER_HEAP_METHOD BOOL can_fit_blocks_p (size_t* ordered_blocks, int block_index, size_t* ordered_spaces, int* space_index);
-    PER_HEAP_METHOD BOOL can_fit_all_blocks_p (size_t* ordered_blocks, size_t* ordered_spaces, int count);
-#ifdef SEG_REUSE_STATS
-    PER_HEAP_METHOD size_t dump_buckets (size_t* ordered_indices, int count, size_t* total_size);
-#endif //SEG_REUSE_STATS
-    PER_HEAP_METHOD void build_ordered_free_spaces (heap_segment* seg);
-    PER_HEAP_METHOD void count_plug (size_t last_plug_size, uint8_t*& last_plug);
-    PER_HEAP_METHOD void count_plugs_in_brick (uint8_t* tree, uint8_t*& last_plug);
-    PER_HEAP_METHOD void build_ordered_plug_indices ();
-    PER_HEAP_METHOD void init_ordered_free_space_indices ();
-    PER_HEAP_METHOD void trim_free_spaces_indices ();
-    PER_HEAP_METHOD BOOL try_best_fit (BOOL end_of_segment_p);
-    PER_HEAP_METHOD BOOL best_fit (size_t free_space, size_t largest_free_space, size_t additional_space, BOOL* use_additional_space);
-    PER_HEAP_METHOD BOOL process_free_space (heap_segment* seg,
-                             size_t free_space,
-                             size_t min_free_size,
-                             size_t min_cont_size,
-                             size_t* total_free_space,
-                             size_t* largest_free_space);
-    PER_HEAP_METHOD void compute_new_ephemeral_size();
-    PER_HEAP_METHOD BOOL can_expand_into_p (heap_segment* seg, size_t min_free_size,
-                            size_t min_cont_size, allocator* al);
-    PER_HEAP_METHOD uint8_t* allocate_in_expanded_heap (generation* gen, size_t size,
-                                     BOOL& adjacentp, uint8_t* old_loc,
-#ifdef SHORT_PLUGS
-                                     BOOL set_padding_on_saved_p,
-                                     mark* pinned_plug_entry,
-#endif //SHORT_PLUGS
-                                     BOOL consider_bestfit, int active_new_gen_number
-                                     REQD_ALIGN_AND_OFFSET_DEFAULT_DCL);
-    PER_HEAP_METHOD void realloc_plug (size_t last_plug_size, uint8_t*& last_plug,
-                       generation* gen, uint8_t* start_address,
-                       unsigned int& active_new_gen_number,
-                       uint8_t*& last_pinned_gap, BOOL& leftp,
-                       BOOL shortened_p
-#ifdef SHORT_PLUGS
-                       , mark* pinned_plug_entry
-#endif //SHORT_PLUGS
-                       );
-    PER_HEAP_METHOD void realloc_in_brick (uint8_t* tree, uint8_t*& last_plug, uint8_t* start_address,
-                           generation* gen,
-                           unsigned int& active_new_gen_number,
-                           uint8_t*& last_pinned_gap, BOOL& leftp);
-    PER_HEAP_METHOD void realloc_plugs (generation* consing_gen, heap_segment* seg,
-                        uint8_t* start_address, uint8_t* end_address,
-                        unsigned active_new_gen_number);
-    PER_HEAP_METHOD void set_expand_in_full_gc (int condemned_gen_number);
-    PER_HEAP_METHOD generation* expand_heap (int condemned_generation,
-                             generation* consing_gen,
-                             heap_segment* new_heap_segment);
-    PER_HEAP_METHOD void save_ephemeral_generation_starts();
-#endif //!USE_REGIONS
-    PER_HEAP_METHOD BOOL expand_reused_seg_p();
-    PER_HEAP_METHOD void verify_no_pins (uint8_t* start, uint8_t* end);
-    PER_HEAP_ISOLATED_METHOD size_t get_gen0_min_size();
-    PER_HEAP_METHOD void set_static_data();
-    PER_HEAP_ISOLATED_METHOD void init_static_data();
-    PER_HEAP_METHOD bool init_dynamic_data ();
-    PER_HEAP_METHOD float surv_to_growth (float cst, float limit, float max_limit);
-    PER_HEAP_METHOD size_t desired_new_allocation (dynamic_data* dd, size_t out,
-                                   int gen_number, int pass);
-    PER_HEAP_METHOD void trim_youngest_desired_low_memory();
-    PER_HEAP_METHOD ptrdiff_t estimate_gen_growth (int gen);
-#ifdef HOST_64BIT
-    PER_HEAP_ISOLATED_METHOD size_t trim_youngest_desired (uint32_t memory_load,
-                                  size_t total_new_allocation,
-                                  size_t total_min_allocation);
-    PER_HEAP_ISOLATED_METHOD size_t joined_youngest_desired (size_t new_allocation);
-#endif // HOST_64BIT
-    PER_HEAP_ISOLATED_METHOD size_t get_total_heap_size ();
-    PER_HEAP_ISOLATED_METHOD size_t get_total_committed_size();
-    PER_HEAP_ISOLATED_METHOD size_t get_total_fragmentation();
-    PER_HEAP_ISOLATED_METHOD size_t get_total_gen_fragmentation (int gen_number);
-#ifdef USE_REGIONS
-    PER_HEAP_ISOLATED_METHOD int get_total_new_gen0_regions_in_plns ();
-    PER_HEAP_ISOLATED_METHOD int get_total_new_regions_in_prr ();
-    PER_HEAP_ISOLATED_METHOD int get_total_new_regions_in_threading ();
-#endif //USE_REGIONS
-    PER_HEAP_ISOLATED_METHOD size_t get_total_gen_estimated_reclaim (int gen_number);
-    PER_HEAP_ISOLATED_METHOD size_t get_total_gen_size (int gen_number);
-    PER_HEAP_ISOLATED_METHOD void get_memory_info (uint32_t* memory_load,
-                          uint64_t* available_physical=NULL,
-                          uint64_t* available_page_file=NULL);
-    PER_HEAP_METHOD size_t generation_size (int gen_number);
-    PER_HEAP_ISOLATED_METHOD size_t get_total_survived_size();
-    PER_HEAP_METHOD bool update_alloc_info (int gen_number,
-                            size_t allocated_size,
-                            size_t* etw_allocation_amount);
-    PER_HEAP_ISOLATED_METHOD void get_total_allocated_since_last_gc (size_t oh_allocated[total_oh_count]);
-    PER_HEAP_METHOD size_t get_current_allocated();
-    PER_HEAP_ISOLATED_METHOD size_t get_total_allocated();
-    PER_HEAP_ISOLATED_METHOD size_t get_total_promoted();
-#ifdef BGC_SERVO_TUNING
-    PER_HEAP_ISOLATED_METHOD size_t get_total_generation_size (int gen_number);
-    PER_HEAP_ISOLATED_METHOD size_t get_total_servo_alloc (int gen_number);
-    PER_HEAP_ISOLATED_METHOD size_t get_total_bgc_promoted();
-    PER_HEAP_ISOLATED_METHOD size_t get_total_surv_size (int gen_number);
-    PER_HEAP_ISOLATED_METHOD size_t get_total_begin_data_size (int gen_number);
-    PER_HEAP_ISOLATED_METHOD size_t get_total_generation_fl_size (int gen_number);
-    PER_HEAP_ISOLATED_METHOD size_t get_current_gc_index (int gen_number);
-#endif //BGC_SERVO_TUNING
-    PER_HEAP_METHOD size_t current_generation_size (int gen_number);
-    PER_HEAP_METHOD size_t generation_plan_size (int gen_number);
-    PER_HEAP_METHOD size_t  compute_in (int gen_number);
-    PER_HEAP_METHOD void compute_new_dynamic_data (int gen_number);
-    PER_HEAP_ISOLATED_METHOD gc_history_global* get_gc_data_global();
-    PER_HEAP_METHOD gc_history_per_heap* get_gc_data_per_heap();
-    PER_HEAP_METHOD size_t new_allocation_limit (size_t size, size_t free_size, int gen_number);
-    PER_HEAP_METHOD size_t generation_fragmentation (generation* gen,
-                                     generation* consing_gen,
-                                     uint8_t* end);
-    PER_HEAP_METHOD size_t generation_sizes (generation* gen, bool use_saved_p=FALSE);
-    PER_HEAP_METHOD size_t committed_size();
-    PER_HEAP_METHOD size_t uoh_committed_size (int gen_number, size_t* allocated);
-    PER_HEAP_METHOD size_t approximate_new_allocation();
-    PER_HEAP_METHOD size_t end_space_after_gc();
-    PER_HEAP_METHOD size_t estimated_reclaim (int gen_number);
-    PER_HEAP_METHOD bool is_full_compacting_gc_productive();
-    PER_HEAP_METHOD BOOL decide_on_compacting (int condemned_gen_number,
-                               size_t fragmentation,
-                               BOOL& should_expand);
-#ifndef USE_REGIONS
-    PER_HEAP_METHOD BOOL sufficient_space_end_seg (uint8_t* start, uint8_t* committed, uint8_t* reserved,
-                                   size_t end_space_required);
-#endif //!USE_REGIONS
-    PER_HEAP_METHOD BOOL ephemeral_gen_fit_p (gc_tuning_point tp);
-    PER_HEAP_METHOD void sweep_uoh_objects (int gen_num);
-    PER_HEAP_METHOD void relocate_in_uoh_objects (int gen_num);
-    PER_HEAP_METHOD void mark_through_cards_for_uoh_objects(card_fn fn, int oldest_gen_num, BOOL relocating
-                                              CARD_MARKING_STEALING_ARG(gc_heap* hpt));
-    PER_HEAP_METHOD void descr_generations (const char* msg);
-    PER_HEAP_ISOLATED_METHOD void descr_generations_to_profiler (gen_walk_fn fn, void *context);
-    /*------------ Multiple non isolated heaps ----------------*/
-#ifdef MULTIPLE_HEAPS
-    PER_HEAP_ISOLATED_METHOD BOOL   create_thread_support (int number_of_heaps);
-    PER_HEAP_ISOLATED_METHOD void destroy_thread_support ();
-    PER_HEAP_METHOD bool create_gc_thread();
-    PER_HEAP_METHOD void gc_thread_function();
-    PER_HEAP_METHOD size_t sort_mark_list();
-    PER_HEAP_METHOD uint8_t** equalize_mark_lists(size_t total_mark_list_size);
-    PER_HEAP_METHOD void merge_mark_lists(size_t total_mark_list_size);
-    PER_HEAP_METHOD void append_to_mark_list(uint8_t **start, uint8_t **end);
-#endif //MULTIPLE_HEAPS
-    PER_HEAP_ISOLATED_METHOD void grow_mark_list();
-#ifdef USE_REGIONS
-    PER_HEAP_METHOD uint8_t** get_region_mark_list (BOOL& use_mark_list, uint8_t* start, uint8_t* end, uint8_t*** mark_list_end);
-#endif //USE_REGIONS
-#ifdef BACKGROUND_GC
-    PER_HEAP_METHOD uint8_t* high_page (heap_segment* seg, BOOL concurrent_p);
-    PER_HEAP_METHOD void revisit_written_page (uint8_t* page, uint8_t* end,
-                               BOOL concurrent_p, uint8_t*& last_page,
-                               uint8_t*& last_object, BOOL large_objects_p,
-                               size_t& num_marked_objects);
-    PER_HEAP_METHOD void revisit_written_pages (BOOL concurrent_p, BOOL reset_only_p=FALSE);
-    PER_HEAP_ISOLATED_METHOD void bgc_suspend_EE ();
-    PER_HEAP_METHOD void background_scan_dependent_handles (ScanContext *sc);
-    PER_HEAP_METHOD void allow_fgc();
-    PER_HEAP_ISOLATED_METHOD void recover_bgc_settings();
-    PER_HEAP_ISOLATED_METHOD BOOL is_bgc_in_progress();
-    PER_HEAP_METHOD void clear_commit_flag();
-    PER_HEAP_ISOLATED_METHOD void clear_commit_flag_global();
-    PER_HEAP_ISOLATED_METHOD void verify_mark_array_cleared (uint8_t* begin, uint8_t* end, uint32_t* mark_array_addr);
-    PER_HEAP_ISOLATED_METHOD uint8_t* get_start_address (heap_segment* seg);
-    PER_HEAP_ISOLATED_METHOD BOOL commit_mark_array_by_range (uint8_t* begin,
-                                     uint8_t* end,
-                                     uint32_t* mark_array_addr);
-    PER_HEAP_ISOLATED_METHOD BOOL commit_mark_array_new_seg (gc_heap* hp,
-                                    heap_segment* seg,
-                                    uint32_t* new_card_table = 0,
-                                    uint8_t* new_lowest_address = 0);
-    PER_HEAP_ISOLATED_METHOD BOOL commit_mark_array_with_check (heap_segment* seg, uint32_t* mark_array_addr);
-    PER_HEAP_ISOLATED_METHOD BOOL commit_mark_array_by_seg (heap_segment* seg, uint32_t* mark_array_addr);
-    PER_HEAP_METHOD BOOL commit_mark_array_bgc_init();
-    PER_HEAP_METHOD BOOL commit_new_mark_array (uint32_t* new_mark_array);
-    PER_HEAP_ISOLATED_METHOD BOOL commit_new_mark_array_global (uint32_t* new_mark_array);
-    PER_HEAP_METHOD void decommit_mark_array_by_seg (heap_segment* seg);
-    PER_HEAP_ISOLATED_METHOD bool should_update_end_mark_size();
-    PER_HEAP_METHOD void background_mark_phase();
-    PER_HEAP_METHOD void background_drain_mark_list (int thread);
-    PER_HEAP_METHOD void background_grow_c_mark_list();
-    PER_HEAP_ISOLATED_METHOD void background_promote_callback(Object** object, ScanContext* sc, uint32_t flags);
-    PER_HEAP_METHOD void mark_absorb_new_alloc();
-    PER_HEAP_METHOD void restart_vm();
-    PER_HEAP_METHOD BOOL prepare_bgc_thread(gc_heap* gh);
-    PER_HEAP_METHOD BOOL create_bgc_thread(gc_heap* gh);
-    PER_HEAP_ISOLATED_METHOD BOOL create_bgc_threads_support (int number_of_heaps);
-    PER_HEAP_METHOD BOOL create_bgc_thread_support();
-    PER_HEAP_ISOLATED_METHOD int check_for_ephemeral_alloc();
-    PER_HEAP_ISOLATED_METHOD void wait_to_proceed();
-    PER_HEAP_ISOLATED_METHOD void fire_alloc_wait_event_begin (alloc_wait_reason awr);
-    PER_HEAP_ISOLATED_METHOD void fire_alloc_wait_event_end (alloc_wait_reason awr);
-    PER_HEAP_METHOD uint32_t background_gc_wait (alloc_wait_reason awr = awr_ignored, int time_out_ms = INFINITE);
-    PER_HEAP_ISOLATED_METHOD BOOL background_running_p() { return gc_background_running; }
-    PER_HEAP_ISOLATED_METHOD void start_c_gc();
-    PER_HEAP_METHOD void kill_gc_thread();
-    PER_HEAP_METHOD void bgc_thread_function();
-    PER_HEAP_ISOLATED_METHOD void do_background_gc();
-    PER_HEAP_ISOLATED_METHOD void bgc_thread_stub (void* arg);
-#endif //BACKGROUND_GC
-    PER_HEAP_METHOD void add_to_oom_history_per_heap();
-    PER_HEAP_METHOD void set_gc_done();
-    PER_HEAP_METHOD void reset_gc_done();
-    PER_HEAP_METHOD void enter_gc_done_event_lock();
-    PER_HEAP_METHOD void exit_gc_done_event_lock();
-    PER_HEAP_ISOLATED_METHOD uint32_t user_thread_wait (GCEvent *event, BOOL no_mode_change, int time_out_ms=INFINITE);
-    PER_HEAP_ISOLATED_METHOD wait_full_gc_status full_gc_wait (GCEvent *event, int time_out_ms);
-#ifdef BACKGROUND_GC
-    PER_HEAP_ISOLATED_METHOD void add_bgc_pause_duration_0();
-    PER_HEAP_ISOLATED_METHOD last_recorded_gc_info* get_completed_bgc_info();
-#endif //BACKGROUND_GC
-#ifdef SYNCHRONIZATION_STATS
-    PER_HEAP_METHOD void init_heap_sync_stats()
-    {
-        good_suspension = 0;
-        bad_suspension = 0;
-        num_msl_acquired = 0;
-        total_msl_acquire = 0;
-        num_high_msl_acquire = 0;
-        num_low_msl_acquire = 0;
-        more_space_lock.init();
-        gc_lock.init();
-    }
-    PER_HEAP_METHOD void print_heap_sync_stats(unsigned int heap_num, unsigned int gc_count_during_log)
-    {
-        printf("%2d%2d%10u%10u%12u%6u%4u%8u(%4u,%4u,%4u,%4u)\n",
-            heap_num,
-            alloc_contexts_used,
-            good_suspension,
-            bad_suspension,
-            (unsigned int)(total_msl_acquire / gc_count_during_log),
-            num_high_msl_acquire / gc_count_during_log,
-            num_low_msl_acquire / gc_count_during_log,
-            num_msl_acquired / gc_count_during_log,
-            more_space_lock.num_switch_thread / gc_count_during_log,
-            more_space_lock.num_wait_longer / gc_count_during_log,
-            more_space_lock.num_switch_thread_w / gc_count_during_log,
-            more_space_lock.num_disable_preemptive_w / gc_count_during_log);
-    }
-#endif //SYNCHRONIZATION_STATS
-#ifdef FEATURE_EVENT_TRACE
-    PER_HEAP_ISOLATED_METHOD void record_mark_time (uint64_t& mark_time,
-                           uint64_t& current_mark_time,
-                           uint64_t& last_mark_time);
-    PER_HEAP_METHOD void init_bucket_info();
-    PER_HEAP_METHOD void add_plug_in_condemned_info (generation* gen, size_t plug_size);
-    PER_HEAP_METHOD void fire_etw_allocation_event (size_t allocation_amount,
-                                    int gen_number,
-                                    uint8_t* object_address,
-                                    size_t object_size);
-    PER_HEAP_METHOD void fire_etw_pin_object_event (uint8_t* object, uint8_t** ppObject);
-#ifdef FEATURE_LOH_COMPACTION
-    PER_HEAP_METHOD void loh_reloc_survivor_helper (uint8_t** pval,
-                                    size_t& total_refs,
-                                    size_t& zero_refs);
-#endif //FEATURE_LOH_COMPACTION
-#endif //FEATURE_EVENT_TRACE
-    PER_HEAP_METHOD BOOL dt_low_ephemeral_space_p (gc_tuning_point tp);
-    PER_HEAP_METHOD BOOL dt_high_frag_p (gc_tuning_point tp, int gen_number, BOOL elevate_p=FALSE);
-    PER_HEAP_METHOD BOOL dt_estimate_reclaim_space_p (gc_tuning_point tp, int gen_number);
-    PER_HEAP_METHOD BOOL dt_estimate_high_frag_p (gc_tuning_point tp, int gen_number, uint64_t available_mem);
-    PER_HEAP_METHOD BOOL dt_low_card_table_efficiency_p (gc_tuning_point tp);
-#ifdef FEATURE_CARD_MARKING_STEALING
-    PER_HEAP_METHOD void reset_card_marking_enumerators()
-    {
-        card_mark_chunk_index_soh = ~0;
-        card_mark_done_soh = false;
-        card_mark_chunk_index_loh = ~0;
-        card_mark_chunk_index_poh = ~0;
-        card_mark_done_uoh = false;
-    }
-    PER_HEAP_METHOD bool find_next_chunk(card_marking_enumerator& card_mark_enumerator, heap_segment* seg,
-                         size_t& n_card_set, uint8_t*& start_address, uint8_t*& limit,
-                         size_t& card, size_t& end_card, size_t& card_word_end);
-#endif //FEATURE_CARD_MARKING_STEALING
-    PER_HEAP_ISOLATED_METHOD size_t exponential_smoothing (int gen, size_t collection_count, size_t desired_per_heap);
-    PER_HEAP_ISOLATED_METHOD BOOL dt_high_memory_load_p();
-    PER_HEAP_ISOLATED_METHOD bool compute_hard_limit();
-    PER_HEAP_ISOLATED_METHOD bool compute_memory_settings(bool is_initialization, uint32_t& nhp, uint32_t nhp_from_config, size_t& seg_size_from_config,
-        size_t new_current_total_committed);
-    PER_HEAP_METHOD size_t compute_committed_bytes_per_heap(int oh, size_t& committed_bookkeeping);
-    PER_HEAP_ISOLATED_METHOD void compute_committed_bytes(size_t& total_committed, size_t& committed_decommit, size_t& committed_free, 
-                                  size_t& committed_bookkeeping, size_t& new_current_total_committed, size_t& new_current_total_committed_bookkeeping, 
-                                  size_t* new_committed_by_oh);
-    PER_HEAP_METHOD void update_collection_counts ();
-    /*****************************************************************************************************************/
-    /*****************************************************************************************************************/
-    /***********************************/
-    /***********************************/
-    PER_HEAP_FIELD_SINGLE_GC GCEvent gc_done_event;
-    PER_HEAP_FIELD_SINGLE_GC VOLATILE(int32_t) gc_done_event_lock;
-    PER_HEAP_FIELD_SINGLE_GC VOLATILE(bool) gc_done_event_set;
-    PER_HEAP_FIELD_SINGLE_GC int condemned_generation_num;
-    PER_HEAP_FIELD_SINGLE_GC BOOL blocking_collection;
-    PER_HEAP_FIELD_SINGLE_GC BOOL elevation_requested;
-    PER_HEAP_FIELD_SINGLE_GC mark_queue_t mark_queue;
-    PER_HEAP_FIELD_SINGLE_GC int gc_policy;  //sweep, compact, expand
-    PER_HEAP_FIELD_SINGLE_GC size_t total_promoted_bytes;
-    PER_HEAP_FIELD_SINGLE_GC size_t finalization_promoted_bytes;
-    PER_HEAP_FIELD_SINGLE_GC size_t mark_stack_tos;
-    PER_HEAP_FIELD_SINGLE_GC size_t mark_stack_bos;
-    PER_HEAP_FIELD_SINGLE_GC uint8_t* oldest_pinned_plug;
-    PER_HEAP_FIELD_SINGLE_GC uint8_t** mark_list;
-    PER_HEAP_FIELD_SINGLE_GC uint8_t** mark_list_end;
-    PER_HEAP_FIELD_SINGLE_GC uint8_t** mark_list_index;
-    PER_HEAP_FIELD_SINGLE_GC uint8_t*** mark_list_piece_start;
-    PER_HEAP_FIELD_SINGLE_GC uint8_t*** mark_list_piece_end;
-    PER_HEAP_FIELD_SINGLE_GC uint8_t* min_overflow_address;
-    PER_HEAP_FIELD_SINGLE_GC uint8_t* max_overflow_address;
-    PER_HEAP_FIELD_SINGLE_GC size_t alloc_contexts_used;
-    PER_HEAP_FIELD_SINGLE_GC BOOL sufficient_gen0_space_p;
-    PER_HEAP_FIELD_SINGLE_GC bool no_gc_oom_p;
-    PER_HEAP_FIELD_SINGLE_GC heap_segment* saved_loh_segment_no_gc;
-#ifdef MULTIPLE_HEAPS
-#ifdef USE_REGIONS
-    PER_HEAP_FIELD_SINGLE_GC min_fl_list_info* min_fl_list;
-    PER_HEAP_FIELD_SINGLE_GC size_t num_fl_items_rethreaded_stage2;
-    PER_HEAP_FIELD_SINGLE_GC size_t* free_list_space_per_heap;
-#else //USE_REGIONS
-    PER_HEAP_FIELD_SINGLE_GC heap_segment* new_heap_segment;
-#endif //USE_REGIONS
-#else //MULTIPLE_HEAPS
-    PER_HEAP_FIELD_SINGLE_GC uint8_t* shigh; //keeps track of the highest marked object
-    PER_HEAP_FIELD_SINGLE_GC uint8_t* slow; //keeps track of the lowest marked object
-#endif //MULTIPLE_HEAPS
-#ifdef BACKGROUND_GC
-    PER_HEAP_FIELD_SINGLE_GC VOLATILE(bgc_state) current_bgc_state;
-    PER_HEAP_FIELD_SINGLE_GC size_t     bgc_begin_loh_size;
-    PER_HEAP_FIELD_SINGLE_GC size_t     bgc_begin_poh_size;
-    PER_HEAP_FIELD_SINGLE_GC size_t     end_loh_size;
-    PER_HEAP_FIELD_SINGLE_GC size_t     end_poh_size;
-    PER_HEAP_FIELD_SINGLE_GC BOOL      processed_eph_overflow_p;
-    PER_HEAP_FIELD_SINGLE_GC size_t     c_mark_list_index;
-    PER_HEAP_FIELD_SINGLE_GC uint8_t* next_sweep_obj;
-    PER_HEAP_FIELD_SINGLE_GC uint8_t* current_sweep_pos;
-    PER_HEAP_FIELD_SINGLE_GC size_t uoh_a_no_bgc[uoh_generation_count];
-    PER_HEAP_FIELD_SINGLE_GC size_t uoh_a_bgc_marking[uoh_generation_count];
-    PER_HEAP_FIELD_SINGLE_GC size_t uoh_a_bgc_planning[uoh_generation_count];
-#ifdef DOUBLY_LINKED_FL
-    PER_HEAP_FIELD_SINGLE_GC heap_segment* current_sweep_seg;
-#endif //DOUBLY_LINKED_FL
-#ifdef USE_REGIONS
-    PER_HEAP_FIELD_SINGLE_GC BOOL      background_overflow_p;
-#else
-    PER_HEAP_FIELD_SINGLE_GC uint8_t* background_min_overflow_address;
-    PER_HEAP_FIELD_SINGLE_GC uint8_t* background_max_overflow_address;
-    PER_HEAP_FIELD_SINGLE_GC uint8_t* background_min_soh_overflow_address;
-    PER_HEAP_FIELD_SINGLE_GC uint8_t* background_max_soh_overflow_address;
-    PER_HEAP_FIELD_SINGLE_GC heap_segment* saved_overflow_ephemeral_seg;
-    PER_HEAP_FIELD_SINGLE_GC heap_segment* saved_sweep_ephemeral_seg;
-    PER_HEAP_FIELD_SINGLE_GC uint8_t* saved_sweep_ephemeral_start;
-#endif //USE_REGIONS
-#ifdef WRITE_WATCH
-    PER_HEAP_FIELD_SINGLE_GC uint8_t* background_written_addresses[array_size + 2];
-#endif //WRITE_WATCH
-#ifdef SNOOP_STATS
-    PER_HEAP_FIELD_SINGLE_GC snoop_stats_data snoop_stat;
-#endif //SNOOP_STATS
-#ifdef BGC_SERVO_TUNING
-    PER_HEAP_FIELD_SINGLE_GC size_t     bgc_maxgen_end_fl_size;
-#endif //BGC_SERVO_TUNING
-#endif //BACKGROUND_GC
-#ifdef USE_REGIONS
-    PER_HEAP_FIELD_SINGLE_GC int num_regions_freed_in_sweep;
-    PER_HEAP_FIELD_SINGLE_GC int sip_maxgen_regions_per_gen[max_generation + 1];
-    PER_HEAP_FIELD_SINGLE_GC heap_segment* reserved_free_regions_sip[max_generation];
-    PER_HEAP_FIELD_SINGLE_GC int regions_per_gen[max_generation + 1];
-    PER_HEAP_FIELD_SINGLE_GC int planned_regions_per_gen[max_generation + 1];
-    PER_HEAP_FIELD_SINGLE_GC_ALLOC size_t end_gen0_region_space;
-    PER_HEAP_FIELD_SINGLE_GC_ALLOC size_t end_gen0_region_committed_space;
-    PER_HEAP_FIELD_SINGLE_GC size_t gen0_pinned_free_space;
-    PER_HEAP_FIELD_SINGLE_GC bool gen0_large_chunk_found;
-    PER_HEAP_FIELD_SINGLE_GC size_t* survived_per_region;
-    PER_HEAP_FIELD_SINGLE_GC size_t* old_card_survived_per_region;
-    PER_HEAP_FIELD_SINGLE_GC bool special_sweep_p;
-#else //USE_REGIONS
-    PER_HEAP_FIELD_SINGLE_GC BOOL ro_segments_in_range;
-    PER_HEAP_FIELD_SINGLE_GC uint8_t* ephemeral_low;
-    PER_HEAP_FIELD_SINGLE_GC uint8_t* ephemeral_high;
-    PER_HEAP_FIELD_SINGLE_GC uint8_t* gc_low; // lowest address being condemned
-    PER_HEAP_FIELD_SINGLE_GC uint8_t* gc_high; // highest address being condemned
-    PER_HEAP_FIELD_SINGLE_GC uint8_t* demotion_low;
-    PER_HEAP_FIELD_SINGLE_GC uint8_t* demotion_high;
-    PER_HEAP_FIELD_SINGLE_GC BOOL demote_gen1_p;
-    PER_HEAP_FIELD_SINGLE_GC uint8_t* last_gen1_pin_end;
-    PER_HEAP_FIELD_SINGLE_GC BOOL ephemeral_promotion;
-    PER_HEAP_FIELD_SINGLE_GC uint8_t* saved_ephemeral_plan_start[ephemeral_generation_count];
-    PER_HEAP_FIELD_SINGLE_GC size_t saved_ephemeral_plan_start_size[ephemeral_generation_count];
-    PER_HEAP_FIELD_SINGLE_GC size_t ordered_free_space_indices[MAX_NUM_BUCKETS];
-    PER_HEAP_FIELD_SINGLE_GC size_t saved_ordered_free_space_indices[MAX_NUM_BUCKETS];
-    PER_HEAP_FIELD_SINGLE_GC size_t ordered_plug_indices[MAX_NUM_BUCKETS];
-    PER_HEAP_FIELD_SINGLE_GC size_t saved_ordered_plug_indices[MAX_NUM_BUCKETS];
-    PER_HEAP_FIELD_SINGLE_GC BOOL ordered_plug_indices_init;
-    PER_HEAP_FIELD_SINGLE_GC BOOL use_bestfit;
-    PER_HEAP_FIELD_SINGLE_GC uint8_t* bestfit_first_pin;
-    PER_HEAP_FIELD_SINGLE_GC BOOL commit_end_of_seg;
-    PER_HEAP_FIELD_SINGLE_GC size_t max_free_space_items; // dynamically adjusted.
-    PER_HEAP_FIELD_SINGLE_GC size_t free_space_buckets;
-    PER_HEAP_FIELD_SINGLE_GC size_t free_space_items;
-    PER_HEAP_FIELD_SINGLE_GC int trimmed_free_space_index;
-    PER_HEAP_FIELD_SINGLE_GC size_t total_ephemeral_plugs;
-    PER_HEAP_FIELD_SINGLE_GC seg_free_spaces* bestfit_seg;
-    PER_HEAP_FIELD_SINGLE_GC size_t total_ephemeral_size;
-#endif //USE_REGIONS
-#ifdef FEATURE_CARD_MARKING_STEALING
-    PER_HEAP_FIELD_SINGLE_GC VOLATILE(uint32_t)    card_mark_chunk_index_soh;
-    PER_HEAP_FIELD_SINGLE_GC VOLATILE(bool)        card_mark_done_soh;
-    PER_HEAP_FIELD_SINGLE_GC VOLATILE(uint32_t)    card_mark_chunk_index_loh;
-    PER_HEAP_FIELD_SINGLE_GC VOLATILE(uint32_t)    card_mark_chunk_index_poh;
-    PER_HEAP_FIELD_SINGLE_GC VOLATILE(bool)        card_mark_done_uoh;
-    PER_HEAP_FIELD_SINGLE_GC VOLATILE(size_t) n_eph_soh;
-    PER_HEAP_FIELD_SINGLE_GC VOLATILE(size_t) n_gen_soh;
-    PER_HEAP_FIELD_SINGLE_GC VOLATILE(size_t) n_eph_loh;
-    PER_HEAP_FIELD_SINGLE_GC VOLATILE(size_t) n_gen_loh;
-#endif //FEATURE_CARD_MARKING_STEALING
-#ifdef DOUBLY_LINKED_FL
-    PER_HEAP_FIELD_SINGLE_GC size_t gen2_removed_no_undo;
-#define INVALID_SAVED_PINNED_PLUG_INDEX ((size_t)~0)
-    PER_HEAP_FIELD_SINGLE_GC size_t saved_pinned_plug_index;
-#endif //DOUBLY_LINKED_FL
-#ifdef FEATURE_LOH_COMPACTION
-    PER_HEAP_FIELD_SINGLE_GC size_t loh_pinned_queue_tos;
-    PER_HEAP_FIELD_SINGLE_GC size_t loh_pinned_queue_bos;
-    PER_HEAP_FIELD_SINGLE_GC BOOL loh_compacted_p;
-#endif //FEATURE_LOH_COMPACTION
-    /*****************************************/
-    /*****************************************/
-    PER_HEAP_FIELD_SINGLE_GC_ALLOC size_t allocation_quantum;
-    PER_HEAP_FIELD_SINGLE_GC_ALLOC dynamic_data dynamic_data_table[total_generation_count];
-    PER_HEAP_FIELD_SINGLE_GC_ALLOC uint64_t loh_alloc_since_cg;
-    PER_HEAP_FIELD_SINGLE_GC_ALLOC BOOL last_gc_before_oom;
-#ifdef MULTIPLE_HEAPS
-    PER_HEAP_FIELD_SINGLE_GC_ALLOC VOLATILE(int) alloc_context_count;
-    PER_HEAP_FIELD_SINGLE_GC_ALLOC bool gen0_allocated_after_gc_p;
-#endif //MULTIPLE_HEAPS
-#ifdef BACKGROUND_GC
-    PER_HEAP_FIELD_SINGLE_GC_ALLOC size_t     bgc_loh_size_increased;
-    PER_HEAP_FIELD_SINGLE_GC_ALLOC size_t     bgc_poh_size_increased;
-    PER_HEAP_FIELD_SINGLE_GC_ALLOC size_t     background_soh_alloc_count;
-    PER_HEAP_FIELD_SINGLE_GC_ALLOC size_t     background_uoh_alloc_count;
-    PER_HEAP_FIELD_SINGLE_GC_ALLOC VOLATILE(int32_t) uoh_alloc_thread_count;
-#endif //BACKGROUND_GC
-#ifdef STRESS_DYNAMIC_HEAP_COUNT
-    PER_HEAP_FIELD_SINGLE_GC_ALLOC bool uoh_msl_before_gc_p;
-#endif //STRESS_DYNAMIC_HEAP_COUNT
-    /************************************/
-    /************************************/
-    PER_HEAP_FIELD_MAINTAINED generation generation_table[total_generation_count];
-    PER_HEAP_FIELD_MAINTAINED size_t mark_stack_array_length;
-    PER_HEAP_FIELD_MAINTAINED mark* mark_stack_array;
-    PER_HEAP_FIELD_MAINTAINED int generation_skip_ratio;//in %
-    PER_HEAP_FIELD_MAINTAINED int gen0_must_clear_bricks;
-    PER_HEAP_FIELD_MAINTAINED heap_segment* freeable_uoh_segment;
-#define NUM_GEN2_ALIST (12)
-#ifdef HOST_64BIT
-#define BASE_GEN2_ALIST_BITS (7)
-#else
-#define BASE_GEN2_ALIST_BITS (6)
-#endif //HOST_64BIT
-    PER_HEAP_FIELD_MAINTAINED alloc_list gen2_alloc_list[NUM_GEN2_ALIST - 1];
-#ifdef BACKGROUND_GC
-    PER_HEAP_FIELD_MAINTAINED EEThreadId bgc_thread_id;
-    PER_HEAP_FIELD_MAINTAINED BOOL bgc_thread_running; // gc thread is its main loop
-    PER_HEAP_FIELD_MAINTAINED Thread* bgc_thread;
-    PER_HEAP_FIELD_MAINTAINED uint8_t** background_mark_stack_tos;
-    PER_HEAP_FIELD_MAINTAINED uint8_t** background_mark_stack_array;
-    PER_HEAP_FIELD_MAINTAINED size_t    background_mark_stack_array_length;
-    PER_HEAP_FIELD_MAINTAINED uint8_t** c_mark_list;
-    PER_HEAP_FIELD_MAINTAINED size_t    c_mark_list_length;
-    PER_HEAP_FIELD_MAINTAINED heap_segment* freeable_soh_segment;
-#endif //BACKGROUND_GC
-#ifdef FEATURE_LOH_COMPACTION
-    PER_HEAP_FIELD_MAINTAINED size_t loh_pinned_queue_length;
-    PER_HEAP_FIELD_MAINTAINED int    loh_pinned_queue_decay;
-    PER_HEAP_FIELD_MAINTAINED mark*  loh_pinned_queue;
-#endif //FEATURE_LOH_COMPACTION
-#ifdef DYNAMIC_HEAP_COUNT
-    PER_HEAP_FIELD_MAINTAINED GCEvent gc_idle_thread_event;
-#ifdef BACKGROUND_GC
-    PER_HEAP_FIELD_MAINTAINED GCEvent bgc_idle_thread_event;
-#endif //BACKGROUND_GC
-#endif //DYNAMIC_HEAP_COUNT
-    /******************************************/
-    /******************************************/
-    PER_HEAP_FIELD_MAINTAINED_ALLOC BOOL gen0_bricks_cleared;
-#define NUM_LOH_ALIST (7)
-#define BASE_LOH_ALIST_BITS (15)
-    PER_HEAP_FIELD_MAINTAINED_ALLOC alloc_list loh_alloc_list[NUM_LOH_ALIST - 1];
-#define NUM_POH_ALIST (19)
-#define BASE_POH_ALIST_BITS (7)
-    PER_HEAP_FIELD_MAINTAINED_ALLOC alloc_list poh_alloc_list[NUM_POH_ALIST - 1];
-    PER_HEAP_FIELD_MAINTAINED_ALLOC uint8_t* alloc_allocated;
-    PER_HEAP_FIELD_MAINTAINED_ALLOC heap_segment* ephemeral_heap_segment;
-    PER_HEAP_FIELD_MAINTAINED_ALLOC CFinalize* finalize_queue;
-#ifdef USE_REGIONS
-    PER_HEAP_FIELD_MAINTAINED_ALLOC region_free_list free_regions[count_free_region_kinds];
-#endif //USE_REGIONS
-    /*******************************/
-    /*******************************/
-    PER_HEAP_FIELD_ALLOC GCSpinLock more_space_lock_soh; //lock while allocating more space for soh
-    PER_HEAP_FIELD_ALLOC GCSpinLock more_space_lock_uoh;
-    PER_HEAP_FIELD_ALLOC size_t soh_allocation_no_gc;
-    PER_HEAP_FIELD_ALLOC size_t loh_allocation_no_gc;
-#ifdef MULTIPLE_HEAPS
-#else //MULTIPLE_HEAPS
-    PER_HEAP_FIELD_ALLOC uint64_t allocation_running_time;
-    PER_HEAP_FIELD_ALLOC size_t allocation_running_amount;
-#endif //MULTIPLE_HEAPS
-    /***********************************/
-    /***********************************/
-    PER_HEAP_FIELD_INIT_ONLY uint8_t* lowest_address;
-    PER_HEAP_FIELD_INIT_ONLY uint8_t* highest_address;
-    PER_HEAP_FIELD_INIT_ONLY uint32_t* card_table;
-    PER_HEAP_FIELD_INIT_ONLY short* brick_table;
-#ifdef CARD_BUNDLE
-    PER_HEAP_FIELD_INIT_ONLY uint32_t* card_bundle_table;
-#endif //CARD_BUNDLE
-#ifdef BACKGROUND_GC
-    PER_HEAP_FIELD_INIT_ONLY uint32_t* mark_array;
-#endif //BACKGROUND_GC
-#ifdef MULTIPLE_HEAPS
-    PER_HEAP_FIELD_INIT_ONLY GCHeap* vm_heap;
-    PER_HEAP_FIELD_INIT_ONLY int heap_number;
-#else //MULTIPLE_HEAPS
-#define vm_heap ((GCHeap*) g_theGCHeap)
-#define heap_number (0)
-#endif //MULTIPLE_HEAPS
-#ifdef BACKGROUND_GC
-    PER_HEAP_FIELD_INIT_ONLY CLRCriticalSection bgc_threads_timeout_cs;
-    PER_HEAP_FIELD_INIT_ONLY uint8_t* background_saved_lowest_address;
-    PER_HEAP_FIELD_INIT_ONLY uint8_t* background_saved_highest_address;
-    PER_HEAP_FIELD_INIT_ONLY exclusive_sync* bgc_alloc_lock;
-#endif //BACKGROUND_GC
-    /***********************************/
-    /***********************************/
-    PER_HEAP_FIELD_DIAG_ONLY uint64_t time_bgc_last;
-    PER_HEAP_FIELD_DIAG_ONLY gc_history_per_heap gc_data_per_heap;
-    PER_HEAP_FIELD_DIAG_ONLY size_t maxgen_pinned_compact_before_advance;
-    PER_HEAP_FIELD_DIAG_ONLY size_t allocated_since_last_gc[total_oh_count];
-    PER_HEAP_FIELD_DIAG_ONLY fgm_history fgm_result;
-    struct gc_history
-    {
-        size_t gc_index;
-        bgc_state current_bgc_state;
-        uint32_t gc_time_ms;
-        size_t gc_efficiency;
-#ifndef USE_REGIONS
-        uint8_t* eph_low;
-        uint8_t* gen0_start;
-        uint8_t* eph_high;
-#endif //!USE_REGIONS
-        uint8_t* bgc_highest;
-        uint8_t* bgc_lowest;
-        uint8_t* fgc_highest;
-        uint8_t* fgc_lowest;
-        uint8_t* g_highest;
-        uint8_t* g_lowest;
-    };
-#define max_history_count 64
-    PER_HEAP_FIELD_DIAG_ONLY int gchist_index_per_heap;
-    PER_HEAP_FIELD_DIAG_ONLY gc_history gchist_per_heap[max_history_count];
-#if defined(MULTIPLE_HEAPS) && defined(_DEBUG)
-    PER_HEAP_FIELD_DIAG_ONLY size_t committed_by_oh_per_heap[total_oh_count];
-    PER_HEAP_FIELD_DIAG_ONLY size_t committed_by_oh_per_heap_refresh[total_oh_count];
-#endif // MULTIPLE_HEAPS && _DEBUG
-#ifdef BACKGROUND_GC
-    PER_HEAP_FIELD_DIAG_ONLY gc_history_per_heap bgc_data_per_heap;
-    PER_HEAP_FIELD_DIAG_ONLY size_t     bgc_overflow_count;
-    PER_HEAP_FIELD_DIAG_ONLY size_t     background_soh_size_end_mark;
-#endif //BACKGROUND_GC
-#ifdef USE_REGIONS
-    PER_HEAP_FIELD_DIAG_ONLY int new_gen0_regions_in_plns;
-    PER_HEAP_FIELD_DIAG_ONLY int new_regions_in_prr;
-    PER_HEAP_FIELD_DIAG_ONLY int new_regions_in_threading;
-#ifdef STRESS_REGIONS
-#define PINNING_HANDLE_INITIAL_LENGTH 128
-    PER_HEAP_FIELD_DIAG_ONLY OBJECTHANDLE* pinning_handles_for_alloc;
-    PER_HEAP_FIELD_DIAG_ONLY int ph_index_per_heap;
-    PER_HEAP_FIELD_DIAG_ONLY int pinning_seg_interval;
-    PER_HEAP_FIELD_DIAG_ONLY size_t num_gen0_regions;
-    PER_HEAP_FIELD_DIAG_ONLY int sip_seg_interval;
-    PER_HEAP_FIELD_DIAG_ONLY int sip_seg_maxgen_interval;
-    PER_HEAP_FIELD_DIAG_ONLY size_t num_condemned_regions;
-#endif //STRESS_REGIONS
-#endif //USE_REGIONS
-#ifdef DYNAMIC_HEAP_COUNT
-#define max_hc_history_count 16
-    PER_HEAP_FIELD_DIAG_ONLY int hchist_index_per_heap;
-    PER_HEAP_FIELD_DIAG_ONLY hc_history hchist_per_heap[max_hc_history_count];
-#ifdef BACKGROUND_GC
-    PER_HEAP_FIELD_DIAG_ONLY int bgc_hchist_index_per_heap;
-    PER_HEAP_FIELD_DIAG_ONLY hc_history bgc_hchist_per_heap[max_hc_history_count];
-#endif //BACKGROUND_GC
-#endif //DYNAMIC_HEAP_COUNT
-#ifdef FEATURE_EVENT_TRACE
-#define max_etw_item_count 2000
-    enum etw_bucket_kind
-    {
-        largest_fl_items = 0,
-        plugs_in_condemned = 1
-    };
-    PER_HEAP_FIELD_DIAG_ONLY etw_bucket_info bucket_info[NUM_GEN2_ALIST];
-#endif //FEATURE_EVENT_TRACE
-#ifdef SPINLOCK_HISTORY
-#define max_saved_spinlock_info 48
-    PER_HEAP_FIELD_DIAG_ONLY int spinlock_info_index;
-    PER_HEAP_FIELD_DIAG_ONLY spinlock_info last_spinlock_info[max_saved_spinlock_info];
-    PER_HEAP_FIELD_DIAG_ONLY allocation_state current_uoh_alloc_state;
-#endif //SPINLOCK_HISTORY
-#ifdef RECORD_LOH_STATE
-#define max_saved_loh_states 48
-    struct loh_state_info
-    {
-        allocation_state alloc_state;
-        size_t gc_index;
-        EEThreadId thread_id;
-    };
-    PER_HEAP_FIELD_DIAG_ONLY int loh_state_index;
-    PER_HEAP_FIELD_DIAG_ONLY loh_state_info last_loh_states[max_saved_loh_states];
-#endif //RECORD_LOH_STATE
-    PER_HEAP_FIELD_DIAG_ONLY oom_history oom_info;
-#define max_oom_history_count 4
-    PER_HEAP_FIELD_DIAG_ONLY int oomhist_index_per_heap;
-    PER_HEAP_FIELD_DIAG_ONLY oom_history oomhist_per_heap[max_oom_history_count];
-    PER_HEAP_FIELD_DIAG_ONLY size_t interesting_data_per_gc[max_idp_count];
-    PER_HEAP_FIELD_DIAG_ONLY size_t interesting_data_per_heap[max_idp_count];
-    PER_HEAP_FIELD_DIAG_ONLY size_t compact_reasons_per_heap[max_compact_reasons_count];
-    PER_HEAP_FIELD_DIAG_ONLY size_t expand_mechanisms_per_heap[max_expand_mechanisms_count];
-    PER_HEAP_FIELD_DIAG_ONLY size_t interesting_mechanism_bits_per_heap[max_gc_mechanism_bits_count];
-    PER_HEAP_FIELD_DIAG_ONLY uint8_t** internal_root_array;
-    PER_HEAP_FIELD_DIAG_ONLY size_t internal_root_array_index;
-    PER_HEAP_FIELD_DIAG_ONLY BOOL heap_analyze_success;
-#ifdef HEAP_ANALYZE
-    PER_HEAP_FIELD_DIAG_ONLY size_t internal_root_array_length;
-    PER_HEAP_FIELD_DIAG_ONLY uint8_t* current_obj;
-    PER_HEAP_FIELD_DIAG_ONLY size_t current_obj_size;
-#endif //HEAP_ANALYZE
-    PER_HEAP_FIELD_DIAG_ONLY gen_to_condemn_tuning gen_to_condemn_reasons;
-    PER_HEAP_FIELD_DIAG_ONLY size_t etw_allocation_running_amount[total_oh_count];
-    PER_HEAP_FIELD_DIAG_ONLY uint64_t total_alloc_bytes_soh;
-    PER_HEAP_FIELD_DIAG_ONLY uint64_t total_alloc_bytes_uoh;
-    PER_HEAP_FIELD_DIAG_ONLY size_t num_pinned_objects;
-#if defined(_DEBUG) && defined(VERIFY_HEAP)
-    PER_HEAP_FIELD_DIAG_ONLY BOOL verify_pinned_queue_p;
-#endif //_DEBUG && VERIFY_HEAP
-#ifdef SYNCHRONIZATION_STATS
-    PER_HEAP_FIELD_DIAG_ONLY unsigned int good_suspension;
-    PER_HEAP_FIELD_DIAG_ONLY unsigned int bad_suspension;
-    PER_HEAP_FIELD_DIAG_ONLY unsigned int num_high_msl_acquire;
-    PER_HEAP_FIELD_DIAG_ONLY unsigned int num_low_msl_acquire;
-    PER_HEAP_FIELD_DIAG_ONLY unsigned int num_msl_acquired;
-    PER_HEAP_FIELD_DIAG_ONLY uint64_t total_msl_acquire;
-#endif //SYNCHRONIZATION_STATS
-    /*****************************************************************************************************************/
-    /*****************************************************************************************************************/
-    /********************************************/
-    /********************************************/
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC bool mark_list_overflow;
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC BOOL proceed_with_gc_p;
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC bool maxgen_size_inc_p;
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC BOOL g_low_memory_status;
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC VOLATILE(bool) internal_gc_done;
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC gc_mechanisms settings;
-#ifdef MULTIPLE_HEAPS
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC GCEvent gc_start_event;
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC GCEvent ee_suspend_event;
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC BOOL gradual_decommit_in_progress_p;
-#ifdef MH_SC_MARK
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC int* g_mark_stack_busy;
-#endif //MH_SC_MARK
-#if !defined(USE_REGIONS) || defined(_DEBUG)
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC size_t* g_promoted;
-#endif //!USE_REGIONS || _DEBUG
-#ifdef BACKGROUND_GC
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC size_t* g_bpromoted;
-#endif //BACKGROUND_GC
-#else //MULTIPLE_HEAPS
-#if !defined(USE_REGIONS) || defined(_DEBUG)
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC size_t g_promoted;
-#endif //!USE_REGIONS || _DEBUG
-#ifdef BACKGROUND_GC
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC size_t g_bpromoted;
-#endif //BACKGROUND_GC
-#endif //MULTIPLE_HEAPS
-#ifdef BACKGROUND_GC
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC VOLATILE(c_gc_state) current_c_gc_state;
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC gc_mechanisms saved_bgc_settings;
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC VOLATILE(BOOL) gc_background_running;
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC GCEvent bgc_threads_sync_event;
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC GCEvent background_gc_done_event;
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC GCEvent ee_proceed_event;
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC BOOL do_ephemeral_gc_p;
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC BOOL do_concurrent_p;
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC uint32_t cm_in_progress;
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC BOOL dont_restart_ee_p;
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC GCEvent bgc_start_event;
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC uint64_t   total_uoh_a_last_bgc;
-#endif //BACKGROUND_GC
-#ifdef USE_REGIONS
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC size_t region_count;
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC VOLATILE(uint8_t*)  ephemeral_low;
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC VOLATILE(uint8_t*)  ephemeral_high;
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC uint8_t* gc_low; // low end of the lowest region being condemned
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC uint8_t* gc_high; // high end of the highest region being condemned
-#endif //USE_REGIONS
-#ifdef DYNAMIC_HEAP_COUNT
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC uint64_t before_distribute_free_regions_time;
-#ifdef STRESS_DYNAMIC_HEAP_COUNT
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC int heaps_in_this_gc;
-#endif //STRESS_DYNAMIC_HEAP_COUNT
-#endif //DYNAMIC_HEAP_COUNT
-    /**************************************************/
-    /**************************************************/
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC_ALLOC GCEvent full_gc_approach_event;
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC_ALLOC GCEvent full_gc_end_event;
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC_ALLOC no_gc_region_info current_no_gc_region_info;
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC_ALLOC FinalizerWorkItem* finalizer_work;
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC uint64_t entry_available_physical_mem;
-#ifdef FEATURE_LOH_COMPACTION
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC gc_loh_compaction_mode loh_compaction_mode;
-#endif //FEATURE_LOH_COMPACTION
-    /*********************************************/
-    /*********************************************/
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED GCSpinLock gc_lock; //lock while doing GC
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED size_t mark_list_size;
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED size_t g_mark_list_total_size;
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED uint8_t** g_mark_list;
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED uint8_t** g_mark_list_copy;
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED size_t full_gc_counts[gc_type_max];
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED bool provisional_mode_triggered;
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED bool pm_trigger_full_gc;
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED size_t smoothed_desired_total[total_generation_count];
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED uint64_t gc_last_ephemeral_decommit_time;
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED size_t card_table_element_layout[total_bookkeeping_elements + 1];
-#ifdef BACKGROUND_GC
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED BOOL keep_bgc_threads_p;
-#endif //BACKGROUND_GC
-#ifdef USE_REGIONS
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED uint8_t* bookkeeping_covered_committed;
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED size_t bookkeeping_sizes[total_bookkeeping_elements];
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED region_info* map_region_to_generation;
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED region_info* map_region_to_generation_skewed;
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED size_t g_mark_list_piece_size;
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED size_t g_mark_list_piece_total_size;
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED uint8_t*** g_mark_list_piece;
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED region_free_list global_regions_to_decommit[count_free_region_kinds];
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED region_free_list global_free_huge_regions;
-#else //USE_REGIONS
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED heap_segment* segment_standby_list;
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED BOOL should_expand_in_full_gc;
-#endif //USE_REGIONS
-#ifdef DYNAMIC_HEAP_COUNT
-    struct dynamic_heap_count_data_t
-    {
-        float target_tcp = 2.0;
-        float target_gen2_tcp = 10.0;
-        static const int recorded_adjustment_size = 4;
-        static const int sample_size = 3;
-        static const int recorded_tcp_array_size = 64;
-        struct sample
-        {
-            uint64_t    elapsed_between_gcs;    // time between gcs in microseconds (this should really be between_pauses)
-            uint64_t    gc_pause_time;          // pause time for this GC
-            uint64_t    msl_wait_time;
-            size_t      gc_index;
-            size_t      gc_survived_size;
-            int         gen0_budget_per_heap;
-        };
-        uint32_t        sample_index;
-        sample          samples[sample_size];
-        sample& get_last_sample()
-        {
-            int last_sample_index = (sample_index + sample_size - 1) % sample_size;
-            sample& s = samples[last_sample_index];
-            return s;
-        }
-        enum adjust_metric
-        {
-            not_adjusted = 0,
-            adjust_budget = 1,
-            adjust_hc = 2
-        };
-        const char* const str_adjust_metrics[4] =
-        {
-            "no adjustment",
-            "budget",
-            "HC"
-        };
-        struct adjustment
-        {
-            adjust_metric metric;
-            int count;
-            int avg_msl_per_heap;
-            float distance;
-            int hc_change;
-            size_t gc_index;
-            bool successful;
-        };
-        adjustment adjustment_history[recorded_adjustment_size];
-        int current_adjustment_index;
-        size_t          current_samples_count;
-        size_t          processed_samples_count;
-        adjustment* get_last_nth_adjustment (int distance_to_current)
-        {
-            int adjustment_idx = (current_adjustment_index + recorded_adjustment_size + distance_to_current) % recorded_adjustment_size;
-            return &adjustment_history[adjustment_idx];
-        }
-        adjustment* get_last_adjustment()
-        {
-            return get_last_nth_adjustment (-1);
-        }
-        void record_adjustment (adjust_metric metric, float distance, int change_int, size_t current_gc_index)
-        {
-            if (metric == adjust_budget)
-            {
-                adjustment* adj = get_last_adjustment();
-                if (adj->metric == adjust_budget)
-                {
-                    (adj->count)++;
-                    dprintf (6666, ("last adjustment was also budget at GC#%Id, inc count to %d", adj->gc_index, adj->count));
-                    return;
-                }
-            }
-            adjustment* adj = &adjustment_history[current_adjustment_index];
-            adj->metric = metric;
-            adj->count = 1;
-            adj->distance = distance;
-            adj->hc_change = change_int;
-            adj->gc_index = current_gc_index;
-            dprintf (6666, ("recording adjustment %s at #%d GC#%Id - distance to target %.3f, changed %d HC",
-                str_adjust_metrics[metric], current_adjustment_index, adj->gc_index, adj->distance, adj->hc_change));
-            current_adjustment_index = (current_adjustment_index + 1) % recorded_adjustment_size;
-        }
-        bool same_action_succeeded (adjust_metric metric, int distance_to_current, int change_int)
-        {
-            int adjustment_idx = (current_adjustment_index + recorded_adjustment_size + distance_to_current) % recorded_adjustment_size;
-            adjustment* adj = &adjustment_history[adjustment_idx];
-            dprintf (6666, ("adj->metric %s, metric %s, adj#%d: hc_change > 0 = %d, change_int > 0 = %d",
-                str_adjust_metrics[adj->metric], str_adjust_metrics[metric],
-                adjustment_idx, (adj->hc_change > 0), (change_int > 0)));
-            if ((adj->metric == metric) && ((change_int > 0) == (adj->hc_change > 0)))
-            {
-                return adj->successful;
-            }
-            return false;
-        }
-        void reset_budget_adjustment()
-        {
-            adjustment* adj = get_last_adjustment();
-            if (adj->metric == adjust_budget)
-            {
-                memset (adj, 0, sizeof (adjustment));
-                int saved_current_adjustment_index = current_adjustment_index;
-                current_adjustment_index = (current_adjustment_index + recorded_adjustment_size - 1) % recorded_adjustment_size;
-                dprintf (6666, ("reset last budget adj at %d, set current adj to %d", saved_current_adjustment_index, current_adjustment_index));
-            }
-        }
-        float           recorded_tcp_rearranged[recorded_tcp_array_size];
-        float           recorded_tcp[recorded_tcp_array_size];
-        int             recorded_tcp_index;
-        int             total_recorded_tcp;
-        int             tcp_count_in_rearrange;
-        float           tcp_slope_in_rearrange;
-        float get_avg_tcp_in_rearrange (int start_idx, int end_idx)
-        {
-            float total_tcp = 0.0;
-            int count = start_idx - end_idx + 1;
-            for (int idx = start_idx; idx >= end_idx ; idx--)
-            {
-                assert ((idx > 0) && (idx < tcp_count_in_rearrange));
-                total_tcp += recorded_tcp_rearranged[idx];
-            }
-            float avg_tcp = total_tcp / count;
-            dprintf (6666, ("getting avg for entry#%d-%d, total %.3f / %d = %.3f", end_idx, start_idx, total_tcp, count, avg_tcp));
-            return avg_tcp;
-        }
-        bool is_temp_change (float* tcp_to_consider)
-        {
-            assert (tcp_count_in_rearrange >= 1);
-            int avg_count = 3;
-            int start_idx = tcp_count_in_rearrange - 1;
-            if ((tcp_count_in_rearrange <= avg_count) || (fabs (tcp_slope_in_rearrange) > 3.0))
-            {
-                dprintf (6666, ("%d tcps, slope is %.3f, returning last one %.3f",
-                    tcp_count_in_rearrange, tcp_slope_in_rearrange, recorded_tcp_rearranged[start_idx]));
-                *tcp_to_consider = recorded_tcp_rearranged[start_idx];
-                return false;
-            }
-            int end_idx = start_idx - avg_count + 1;
-            float avg = get_avg_tcp_in_rearrange (start_idx, end_idx);
-            *tcp_to_consider = avg;
-            if (tcp_count_in_rearrange > (avg_count * 3))
-            {
-                start_idx = end_idx - 1;
-                end_idx = start_idx - avg_count + 1;
-                float last_avg = get_avg_tcp_in_rearrange (start_idx, end_idx);
-                float diff_pct_in_avg = 0.0;
-                if (avg > last_avg)
-                {
-                    diff_pct_in_avg = (avg - last_avg) / last_avg;
-                }
-                else
-                {
-                    diff_pct_in_avg = (last_avg - avg) / avg;
-                }
-                dprintf (6666, ("avg of last %d tcps is %.3f, avg of the %d tcps before those is %.3f, diff (to min) is %.3f",
-                    avg_count, *tcp_to_consider, avg_count, last_avg, diff_pct_in_avg));
-                return (diff_pct_in_avg > 0.3);
-            }
-            else
-            {
-                dprintf (6666, ("we have only %d entries, consider %.3f not temporary", tcp_count_in_rearrange, *tcp_to_consider));
-                return false;
-            }
-        }
-        int add_to_recorded_tcp (float tcp)
-        {
-            total_recorded_tcp++;
-            recorded_tcp[recorded_tcp_index] = tcp;
-            recorded_tcp_index++;
-            if (recorded_tcp_index == recorded_tcp_array_size)
-            {
-                recorded_tcp_index = 0;
-            }
-            return recorded_tcp_index;
-        }
-        int rearrange_recorded_tcp ()
-        {
-            int count = recorded_tcp_array_size;
-            int copied_count = 0;
-            if (total_recorded_tcp >= recorded_tcp_array_size)
-            {
-                int earlier_entry_size = recorded_tcp_array_size - recorded_tcp_index;
-                memcpy (recorded_tcp_rearranged, (recorded_tcp + recorded_tcp_index), (earlier_entry_size * sizeof (float)));
-                copied_count = earlier_entry_size;
-            }
-            if (recorded_tcp_index)
-            {
-                memcpy ((recorded_tcp_rearranged + copied_count), recorded_tcp, (recorded_tcp_index * sizeof (float)));
-                copied_count += recorded_tcp_index;
-            }
-            return copied_count;
-        }
-        void init_recorded_tcp ()
-        {
-            total_recorded_tcp = 0;
-            recorded_tcp_index = 0;
-            dprintf (6666, ("INIT tcp buffer"));
-        }
-        int get_recorded_tcp_count () { return total_recorded_tcp; }
-        float           around_target_accumulation;
-        float           around_target_threshold;
-        bool is_tcp_in_range (float diff_pct, float slope)
-        {
-            return ((diff_pct <= 0.2) && (diff_pct >= -0.2) && (slope <= 0.1) && (slope >= -0.1));
-        }
-        bool is_close_to_max (int new_n, int max)
-        {
-            return ((max - new_n) <= (max / 10));
-        }
-        float slope (float* y, int n, float* avg);
-        int get_aggressiveness (int change_int)
-        {
-            int factor = 1;
-            adjust_metric metric = adjust_hc;
-            for (int i = -1; i >= -1; i--)
-            {
-                bool last_action_succeeded = same_action_succeeded (metric, i, change_int);
-                dprintf (6666, ("current %d adjustment of %s %s, agg factor %d",
-                    i, str_adjust_metrics[metric], (last_action_succeeded ? "succeeded" : "failed"),
-                    (factor + last_action_succeeded)));
-                if (!last_action_succeeded)
-                {
-                    break;
-                }
-                factor += 1;
-            }
-            return factor;
-        }
-        void check_success_after_adjust (size_t current_gc_index, adjustment* adj, float tcp)
-        {
-            size_t last_changed_gc_index = adj->gc_index;
-            if (!last_changed_gc_index) return;
-            bool check_p = (current_gc_index < (last_changed_gc_index + (2 * sample_size)));
-            dprintf (6666, ("last adjusted at GC#%Id, %Id GCs ago, %s",
-                last_changed_gc_index, (current_gc_index - last_changed_gc_index), (check_p ? "check success" : "already checked success")));
-            if (!check_p)
-            {
-                return;
-            }
-            adjust_metric adj_metric = adj->metric;
-            if (adj_metric == adjust_hc)
-            {
-                bool adjusted_up = (adj->hc_change > 0);
-                bool tcp_reduced_p = (tcp < (adj->distance + target_tcp));
-                adj->successful = (adjusted_up == tcp_reduced_p);
-                dprintf (6666, ("last adjust hc - %d -> %d heaps, tcp %.3f -> %.3f, %s",
-                    (n_heaps - adj->hc_change), n_heaps, (adj->distance + target_tcp), tcp,
-                    (adj->successful ? "success" : "fail")));
-            }
-        }
-        void reset_accumulation()
-        {
-            around_target_accumulation = 0.0;
-            init_recorded_tcp();
-        }
-        enum decide_change_condition
-        {
-            init_change_condition = 0x0000,
-            change = 0x0001,
-            too_few_samples = 0x0002,
-            not_enough_diff_accumulated = 0x0004,
-            already_toward_target = 0x0008,
-            tcp_in_range = 0x0010,
-            temp_change = 0x0020
-        };
-        bool should_change (float tcp, float* tcp_to_consider, size_t current_gc_index,
-                            decide_change_condition* change_decision,
-                            int* recorded_tcp_count, float* recorded_tcp_slope,
-                            size_t* num_gcs_since_last_change,
-                            float* current_around_target_accumulation)
-        {
-            *change_decision = decide_change_condition::init_change_condition;
-            adjustment* adj = get_last_adjustment();
-            size_t last_changed_gc_index = adj->gc_index;
-            *recorded_tcp_count = 0;
-            *recorded_tcp_slope = 0.0f;
-            check_success_after_adjust (current_gc_index, adj, tcp);
-            float diff_to_target = tcp - target_tcp;
-            dprintf (6666, ("accumulating %.3f + %.3f -> %.3f",
-                around_target_accumulation, diff_to_target, (around_target_accumulation + diff_to_target)));
-            around_target_accumulation += diff_to_target;
-            *current_around_target_accumulation = around_target_accumulation;
-            *num_gcs_since_last_change = current_gc_index - last_changed_gc_index;
-            dprintf (6666, ("we adjusted at GC#%Id, %Id GCs ago", last_changed_gc_index, *num_gcs_since_last_change));
-            if (last_changed_gc_index && (*num_gcs_since_last_change < (2 * sample_size)))
-            {
-                *change_decision = decide_change_condition::too_few_samples;
-                dprintf (6666, ("we just adjusted %Id GCs ago, skipping", *num_gcs_since_last_change));
-                return false;
-            }
-            if ((around_target_accumulation < around_target_threshold) && (around_target_accumulation > -around_target_threshold))
-            {
-                *change_decision = decide_change_condition::not_enough_diff_accumulated;
-                dprintf (6666, ("accumulated %.3f < %.3f and > %.3f, skipping",
-                    around_target_accumulation, around_target_threshold, -around_target_threshold));
-                return false;
-            }
-            float avg_recorded_tcp = 0.0;
-            int tcp_count = rearrange_recorded_tcp ();
-            *recorded_tcp_count = tcp_count;
-            float tcp_slope = slope (recorded_tcp_rearranged, tcp_count, &avg_recorded_tcp);
-            *recorded_tcp_slope = tcp_slope;
-            dprintf (6666, ("acc thres exceeded! %s slope of %d tcps is %.3f",
-                ((around_target_accumulation > 0.0) ? "above" : "below"), tcp_count, tcp_slope));
-            if ((tcp_count >= 5) &&
-                (((around_target_accumulation > 0.0) && (tcp_slope < -0.2)) ||
-                ((around_target_accumulation < 0.0) && (tcp_slope > 0.2))))
-            {
-                *change_decision = decide_change_condition::already_toward_target;
-                dprintf (6666, ("already trending the right direction, skipping"));
-                reset_accumulation();
-                return false;
-            }
-            float diff_pct = diff_to_target / target_tcp;
-            if (is_tcp_in_range (diff_pct, tcp_slope))
-            {
-                *change_decision = decide_change_condition::tcp_in_range;
-                dprintf (6666, ("diff %.3f, slope %.3f already in range", diff_pct, tcp_slope));
-                reset_accumulation();
-                return false;
-            }
-            tcp_count_in_rearrange = tcp_count;
-            tcp_slope_in_rearrange = tcp_slope;
-            if (is_temp_change (tcp_to_consider))
-            {
-                *change_decision = decide_change_condition::temp_change;
-                dprintf (6666, ("this is a temporary change, ignore"));
-                reset_accumulation();
-                return false;
-            }
-            return true;
-        }
-        /*
-        |      |      | max    |
-        | hc   | f    | growth |
-        | ---- | ---- | ------ |
-        | 1    | 4.00 | 4      |
-        | 2    | 2.46 | 5      |
-        | 4    | 1.52 | 6      |
-        | 6    | 1.14 | 7      |
-        | 8    | 0.93 | 7      |
-        | 10   | 0.80 | 8      |
-        | 14   | 0.63 | 9      |
-        | 16   | 0.57 | 9      |
-        | 32   | 0.35 | 11     |
-        | 64   | 0.22 | 14     |
-        | 80   | 0.19 | 15     |
-        */
-        int get_max_growth(int current_hc)
-        {
-            return (int)round(current_hc * (4.0 * pow (current_hc, -0.7)));
-        }
-        enum hc_change_freq_reason
-        {
-            default_reason = 0x0000,
-            expensive_hc_change = 0x0001,
-            dec = 0x0002,
-            dec_multiple = 0x0004,
-            fluctuation = 0x0008
-        };
-        int get_hc_change_freq_factors (int change_int, size_t last_change_gc_index, hc_change_freq_reason* reason)
-        {
-            *reason = hc_change_freq_reason::default_reason;
-            int factor = 3;
-            int inc_factor = factor;
-            if (last_change_gc_index)
-            {
-                if (change_heap_count_time == 0)
-                {
-                    dprintf (6666, ("WHAT!!! last HC change took 0us?!"));
-                    return 0;
-                }
-                assert (change_heap_count_time != 0);
-                uint64_t total_gc_pause_time = 0;
-                for (int i = 0; i < sample_size; i++)
-                {
-                    total_gc_pause_time += samples[i].gc_pause_time;
-                }
-                uint64_t avg_gc_pause_time = total_gc_pause_time / sample_size;
-                if (change_heap_count_time > avg_gc_pause_time)
-                {
-                    factor *= 2 * (int)(change_heap_count_time / avg_gc_pause_time);
-                    *reason = hc_change_freq_reason::expensive_hc_change;
-                }
-                dprintf (6666, ("last HC change took %.3fms  / avg gc pause %.3fms = %d , factor %d",
-                    (change_heap_count_time / 1000.0), (avg_gc_pause_time / 1000.0),
-                    (change_heap_count_time / avg_gc_pause_time), factor));
-            }
-            if (change_int < 0)
-            {
-                factor *= 2;
-                *reason = (hc_change_freq_reason)((int)*reason | hc_change_freq_reason::dec);
-                adjustment* adj = get_last_adjustment();
-                int last_hc_change = adj->hc_change;
-                dprintf (6666, ("dec: last HC change %d heaps at GC#%Id, factor %d", last_hc_change, last_change_gc_index, factor));
-                if (last_hc_change < 0)
-                {
-                    dprintf (6666, ("last was dec, factor %d->%d", factor, (factor * 2)));
-                    factor *= 2;
-                    *reason = (hc_change_freq_reason)((int)*reason | hc_change_freq_reason::dec_multiple);
-                }
-                else
-                {
-                    adj = get_last_nth_adjustment (-2);
-                    size_t last_2nd_change_gc_index = adj->gc_index;
-                    if (last_2nd_change_gc_index > 0)
-                    {
-                        int last_2nd_hc_change = adj->hc_change;
-                        dprintf (6666, ("before last was %d heaps at GC#%Id (%Id GCs), factor is now %d",
-                            last_2nd_hc_change, last_2nd_change_gc_index, (last_change_gc_index - last_2nd_change_gc_index), factor));
-                        if (last_2nd_hc_change < 0)
-                        {
-                            bool inc_too_quick_p = ((last_change_gc_index - last_2nd_change_gc_index) < (size_t)(inc_factor * 2 * sample_size));
-                            if (inc_too_quick_p)
-                            {
-                                dprintf (6666, ("We dec-ed and quickly followed with an inc, factor %d -> %d", factor, (factor * 4)));
-                                factor *= 4;
-                                *reason = (hc_change_freq_reason)((int)*reason | hc_change_freq_reason::fluctuation);
-                            }
-                        }
-                    }
-                }
-            }
-            return factor;
-        }
-        enum decide_adjustment_reason
-        {
-            init_adjustment_reason = 0x0000,
-            limited_by_bounds = 0x0001,
-            cannot_adjust_budget = 0x0002,
-            change_pct_too_small = 0x0004,
-            change_too_soon = 0x0008
-        };
-        adjust_metric should_change_hc (int max_hc_datas, int min_hc_datas, int max_hc_growth, int& change_int, size_t current_gc_index,
-                                        decide_adjustment_reason* adj_reason, int* hc_change_freq_factor, hc_change_freq_reason* hc_freq_reason)
-        {
-            *adj_reason = decide_adjustment_reason::init_adjustment_reason;
-            adjust_metric adj_metric = not_adjusted;
-            int saved_change_int = change_int;
-            if (change_int > 0)
-            {
-                change_int = min (max_hc_growth, change_int);
-            }
-            else if (change_int < 0)
-            {
-                if ((change_int + n_heaps) < 1)
-                {
-                    change_int = 1 - n_heaps;
-                }
-            }
-            if (saved_change_int != change_int)
-            {
-                *adj_reason = decide_adjustment_reason::limited_by_bounds;
-                dprintf (6666, ("change %d heaps instead of %d so we don't go over upper/lower limit", change_int, saved_change_int));
-            }
-            if (change_int == 0)
-            {
-                dprintf (6666, ("cannot change due to upper/lower limit!"));
-                return adj_metric;
-            }
-            if ((change_int > 0) && (n_heaps == min_hc_datas))
-            {
-                *adj_reason = (decide_adjustment_reason)((int)*adj_reason | decide_adjustment_reason::cannot_adjust_budget);
-                dprintf (6666, ("we are already at min datas heaps %d, cannot inc budget so must inc HC", n_heaps));
-                adj_metric = adjust_hc;
-            }
-            else if ((change_int < 0) && (n_heaps == max_hc_datas))
-            {
-                *adj_reason = (decide_adjustment_reason)((int)*adj_reason | decide_adjustment_reason::cannot_adjust_budget);
-                dprintf (6666, ("we are already at max datas heaps %d, cannot dec budget so must dec HC", n_heaps));
-                adj_metric = adjust_hc;
-            }
-            float hc_change_pct = fabsf ((float)change_int / n_heaps);
-            adjustment* adj = get_last_adjustment();
-            size_t last_change_gc_index = adj->gc_index;
-            adj_metric = adjust_hc;
-            if (last_change_gc_index)
-            {
-                size_t num_gcs_since_change = current_gc_index - last_change_gc_index;
-                *hc_change_freq_factor = get_hc_change_freq_factors (change_int, last_change_gc_index, hc_freq_reason);
-                dprintf (6666, ("hc would change %.3f, factor is %d", hc_change_pct, *hc_change_freq_factor));
-                if (hc_change_pct < 0.2)
-                {
-                    int delayed_hc_change_freq_factor = *hc_change_freq_factor * 3;
-                    int count = 0;
-                    if (adj->metric == adjust_budget)
-                    {
-                        count = adj->count;
-                    }
-                    dprintf (6666, ("we've changed budget instead of HC %d times from %Id GCs ago, thres %d times",
-                                    count, num_gcs_since_change, delayed_hc_change_freq_factor));
-                    if (count < delayed_hc_change_freq_factor)
-                    {
-                        *adj_reason = (decide_adjustment_reason)((int)*adj_reason | decide_adjustment_reason::change_pct_too_small);
-                        adj_metric = adjust_budget;
-                    }
-                }
-                else
-                {
-                    bool change_p = (num_gcs_since_change > (size_t)(*hc_change_freq_factor * sample_size));
-                    dprintf (6666, ("It's been %Id GCs since we changed last time, thres %d GCs, %s",
-                        num_gcs_since_change, (*hc_change_freq_factor * sample_size), (change_p ? "change" : "don't change yet")));
-                    if (!change_p)
-                    {
-                        *adj_reason = (decide_adjustment_reason)((int)*adj_reason | decide_adjustment_reason::change_too_soon);
-                        adj_metric = not_adjusted;
-                    }
-                }
-            }
-            dprintf (6666, ("conclusion: %s", str_adjust_metrics[adj_metric]));
-            if (adj_metric == adjust_hc)
-            {
-                reset_budget_adjustment();
-            }
-            return adj_metric;
-        }
-        size_t          max_gen0_new_allocation;
-        size_t          min_gen0_new_allocation;
-        size_t compute_total_gen0_budget (size_t total_soh_stable_size)
-        {
-            assert (total_soh_stable_size > 0);
-            float factor = (float)(20 - conserve_mem_setting);
-            double old_gen_growth_factor = factor / sqrt ((double)total_soh_stable_size / 1000.0 / 1000.0);
-            double saved_old_gen_growth_factor = old_gen_growth_factor;
-            old_gen_growth_factor = min (10.0, old_gen_growth_factor);
-            old_gen_growth_factor = max (0.1, old_gen_growth_factor);
-            size_t total_new_allocation_old_gen = (size_t)(old_gen_growth_factor * (double)total_soh_stable_size);
-            dprintf (6666, ("stable soh %Id (%.3fmb), factor %.3f=>%.3f -> total gen0 new_alloc %Id (%.3fmb)",
-                total_soh_stable_size, ((double)total_soh_stable_size / 1000.0 / 1000.0),
-                saved_old_gen_growth_factor, old_gen_growth_factor, total_new_allocation_old_gen,
-                ((double)total_new_allocation_old_gen  / 1000.0 / 1000.0)));
-            return total_new_allocation_old_gen;
-        }
-        size_t compute_gen0_budget_per_heap (size_t total_soh_stable_size, float tcp, size_t bcs_per_heap)
-        {
-            size_t total_budget_old_gen = compute_total_gen0_budget (total_soh_stable_size);
-            size_t budget_old_gen_per_heap = total_budget_old_gen / n_heaps;
-            budget_old_gen_per_heap = Align (budget_old_gen_per_heap, get_alignment_constant (TRUE));
-            size_t saved_budget_old_gen_per_heap = budget_old_gen_per_heap;
-            budget_old_gen_per_heap = min (max_gen0_new_allocation, budget_old_gen_per_heap);
-            budget_old_gen_per_heap = max (min_gen0_new_allocation, budget_old_gen_per_heap);
-            dprintf (6666, ("BCD: %Id/heap (%.3fmb) -> %.3fmb, BCS %Id/heap (%.3fmb)",
-                saved_budget_old_gen_per_heap, ((double)saved_budget_old_gen_per_heap / 1000.0 / 1000.0),
-                ((double)budget_old_gen_per_heap / 1000.0 / 1000.0),
-                bcs_per_heap, ((double)bcs_per_heap / 1000.0 / 1000.0)));
-            if (bcs_per_heap < budget_old_gen_per_heap)
-            {
-                sample& sample = get_last_sample();
-                size_t last_budget_per_heap = sample.gen0_budget_per_heap;
-                adjustment* adj = get_last_adjustment();
-                size_t last_changed_gc_index = adj->gc_index;
-                size_t saved_last_changed_gc_index = last_changed_gc_index;
-                size_t current_gc_index = VolatileLoadWithoutBarrier (&settings.gc_index);
-                size_t last_bgc_index = VolatileLoadWithoutBarrier (&saved_bgc_settings.gc_index);
-                if (last_bgc_index == (current_gc_index - 1))
-                {
-                    last_changed_gc_index++;
-                }
-                dprintf (6666, ("last gc gen0 budget %Id, last adjustment %s was at GC#%Id, last BGC was #%Id, this GC #%Id, %s",
-                    last_budget_per_heap, str_adjust_metrics[adj->metric], saved_last_changed_gc_index, last_bgc_index, current_gc_index,
-                    ((last_changed_gc_index < (current_gc_index - 1)) ? "didn't just change" : "did just change")));
-                if ((adj->metric == adjust_budget) || (last_changed_gc_index < (current_gc_index - 1)))
-                {
-                    float diff = tcp - target_tcp;
-                    adjustment* adj = get_last_adjustment();
-                    bool adjust_budget_p = (adj->metric == adjust_budget);
-                    dprintf (6666, ("tcp of last sample was %.3f, diff to target %.3f, pct %.3f, last adj %s budget",
-                        tcp, diff, (diff / target_tcp), (adjust_budget_p ? "was" : "was not")));
-                    if (adjust_budget_p ||
-                        ((diff > 0.0) && ((diff < 2.0) || ((diff / target_tcp) < 0.4))))
-                    {
-                        float last_alloc_time = (float)100.0 - tcp;
-                        float target_alloc_time = (float)100.0 - target_tcp;
-                        size_t new_budget_per_heap = (size_t)(last_budget_per_heap / last_alloc_time * target_alloc_time);
-                        new_budget_per_heap = Align (new_budget_per_heap, get_alignment_constant (TRUE));
-                        size_t saved_new_budget_per_heap = new_budget_per_heap;
-                        new_budget_per_heap = max (new_budget_per_heap, bcs_per_heap);
-                        new_budget_per_heap = min (new_budget_per_heap, budget_old_gen_per_heap);
-                        dprintf (6666, ("adjust last budget %Id to %Id->%Id (%.3fmb)",
-                            last_budget_per_heap, saved_new_budget_per_heap, new_budget_per_heap, (new_budget_per_heap / 1000.0 / 1000.0)));
-                        return new_budget_per_heap;
-                    }
-                }
-            }
-            dprintf (6666, ("taking min of the two: %Id, %Id", bcs_per_heap, budget_old_gen_per_heap));
-            return min (bcs_per_heap, budget_old_gen_per_heap);
-        }
-        struct gen2_sample
-        {
-            size_t gc_index;
-            uint64_t gc_duration; 
-            float gc_percent;
-        };
-        uint32_t        gen2_sample_index;
-        gen2_sample     gen2_samples[sample_size];
-        size_t          current_gen2_samples_count;
-        size_t          processed_gen2_samples_count;
-        size_t          gen2_last_changed_sample_count;
-        gen2_sample& get_last_gen2_sample()
-        {
-            int last_sample_index = (gen2_sample_index + sample_size - 1) % sample_size;
-            gen2_sample& s = gen2_samples[last_sample_index];
-            return s;
-        }
-        gen2_sample& get_current_gen2_sample()
-        {
-            gen2_sample& s = gen2_samples[gen2_sample_index];
-            return s;
-        }
-        int             new_n_heaps;
-        int             last_n_heaps;
-        VOLATILE(int32_t) idle_thread_count;
-#ifdef BACKGROUND_GC
-        VOLATILE(int32_t) idle_bgc_thread_count;
-#endif
-        bool            init_only_p;
-        bool            should_change_heap_count;
-        int             heap_count_to_change_to;
-#ifdef STRESS_DYNAMIC_HEAP_COUNT
-        int             lowest_heap_with_msl_uoh;
-#endif //STRESS_DYNAMIC_HEAP_COUNT
-        float get_median_gen2_gc_percent()
-        {
-            return median_of_3 (gen2_samples[0].gc_percent, gen2_samples[1].gc_percent, gen2_samples[2].gc_percent);
-        }
-    };
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED dynamic_heap_count_data_t dynamic_heap_count_data;
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED size_t current_total_soh_stable_size;
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED uint64_t last_suspended_end_time;
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED uint64_t change_heap_count_time;
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED size_t gc_index_full_gc_end;
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED bool trigger_initial_gen2_p;
-#ifdef BACKGROUND_GC
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED bool trigger_bgc_for_rethreading_p;
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED int total_bgc_threads;
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED int last_bgc_n_heaps;
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED int last_total_bgc_threads;
-#endif //BACKGROUND_GC
-#endif //DYNAMIC_HEAP_COUNT
-    /****************************************************/
-    /****************************************************/
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED_ALLOC size_t current_total_committed;
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED_ALLOC size_t committed_by_oh[recorded_committed_bucket_counts];
-    /********************************************/
-    /********************************************/
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY gc_latency_level latency_level;
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY uint32_t high_memory_load_th;
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY uint32_t m_high_memory_load_th;
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY uint32_t v_high_memory_load_th;
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY bool is_restricted_physical_mem;
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY uint64_t mem_one_percent;
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY uint64_t total_physical_mem;
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY int generation_skip_ratio_threshold;
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY int conserve_mem_setting;
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY bool spin_count_unit_config_p;
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY size_t soh_segment_size;
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY size_t segment_info_size;
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY bool hard_limit_config_p;
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY size_t heap_hard_limit;
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY size_t heap_hard_limit_oh[total_oh_count];
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY CLRCriticalSection check_commit_cs;
-#ifdef COMMITTED_BYTES_SHADOW
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY CLRCriticalSection decommit_lock;
-#endif
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY bool use_large_pages_p;
-#ifdef MULTIPLE_HEAPS
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY gc_heap** g_heaps;
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY bool gc_thread_no_affinitize_p;
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY size_t min_gen0_balance_delta;
-#define alloc_quantum_balance_units (16)
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY size_t min_balance_threshold;
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY size_t max_decommit_step_size;
-#else //MULTIPLE_HEAPS
-#endif //MULTIPLE_HEAPS
-#ifdef BACKGROUND_GC
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY bool gc_can_use_concurrent;
-#ifdef BGC_SERVO_TUNING
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY int saved_bgc_tuning_reason;
-#endif //BGC_SERVO_TUNING
-#endif //BACKGROUND_GC
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY uint8_t* bookkeeping_start;
-#ifdef USE_REGIONS
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY size_t regions_range;
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY bool enable_special_regions_p;
-#else //USE_REGIONS
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY size_t eph_gen_starts_size;
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY size_t min_segment_size;
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY size_t min_uoh_segment_size;
-#endif //USE_REGIONS
-#if defined(SHORT_PLUGS) && !defined(USE_REGIONS)
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY double short_plugs_pad_ratio;
-#endif //SHORT_PLUGS && !USE_REGIONS
-#ifdef FEATURE_LOH_COMPACTION
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY BOOL        loh_compaction_always_p;
-#endif //FEATURE_LOH_COMPACTION
-#ifdef HOST_64BIT
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY size_t youngest_gen_desired_th;
-#endif //HOST_64BIT
-#ifdef DYNAMIC_HEAP_COUNT
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY int dynamic_adaptation_mode;
-#ifdef STRESS_DYNAMIC_HEAP_COUNT
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY int bgc_to_ngc2_ratio;
-#endif //STRESS_DYNAMIC_HEAP_COUNT
-#endif //DYNAMIC_HEAP_COUNT
-    /********************************************/
-    /********************************************/
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY int gchist_index;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY gc_mechanisms_store gchist[max_history_count];
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY bool pm_stress_on; // init-ed by the GCProvModeStress config
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY size_t provisional_triggered_gc_count;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY size_t provisional_off_gc_count;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY size_t num_provisional_triggered;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY gc_history_global gc_data_global;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY size_t current_total_committed_bookkeeping;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY uint64_t suspended_start_time;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY uint64_t end_gc_time;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY uint64_t total_suspended_time;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY uint64_t process_start_time;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY last_recorded_gc_info last_ephemeral_gc_info;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY last_recorded_gc_info last_full_blocking_gc_info;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY uint64_t last_alloc_reset_suspended_end_time;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY size_t max_peak_heap_size;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY VOLATILE(size_t) llc_size;
-#ifdef BACKGROUND_GC
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY gc_history_global bgc_data_global;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY size_t ephemeral_fgc_counts[max_generation];
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY last_recorded_gc_info last_bgc_info[2];
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY VOLATILE(int) last_bgc_info_index;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY VOLATILE(bool) is_last_recorded_bgc;
-#endif //BACKGROUND_GC
-#ifdef DYNAMIC_HEAP_COUNT
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY size_t hc_change_cancelled_count_prep;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY uint64_t total_change_heap_count;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY uint64_t total_change_heap_count_time;
-#ifdef BACKGROUND_GC
-    struct bgc_thread_creation_history
-    {
-        size_t gc_index;
-        short n_heaps;
-        short count_created;
-        short count_created_th_existed;
-        short count_creation_failed;
-    };
-#define max_bgc_thread_creation_count 16
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY int bgc_th_creation_hist_index;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY bgc_thread_creation_history bgc_th_creation_hist[max_bgc_thread_creation_count];
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY size_t bgc_th_count_created;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY size_t bgc_th_count_created_th_existed;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY size_t bgc_th_count_creation_failed;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY size_t bgc_init_gc_index;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY VOLATILE(short) bgc_init_n_heaps;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY size_t hc_change_cancelled_count_bgc;
-#endif //BACKGROUND_GC
-#endif //DYNAMIC_HEAP_COUNT
-#ifdef FEATURE_EVENT_TRACE
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY bool informational_event_enabled_p;
-    enum etw_gc_time_info
-    {
-        time_mark_sizedref = 0,
-        time_mark_roots = 1,
-        time_mark_short_weak = 2,
-        time_mark_scan_finalization = 3,
-        time_mark_long_weak = 4,
-        max_bgc_time_type = 5,
-        time_plan = 5,
-        time_relocate = 6,
-        time_sweep = 6,
-        max_sweep_time_type = 7,
-        time_compact = 7,
-        max_compact_time_type = 8
-    };
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY uint64_t* gc_time_info;
-#ifdef BACKGROUND_GC
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY uint64_t* bgc_time_info;
-#endif //BACKGROUND_GC
-#ifdef FEATURE_LOH_COMPACTION
-    struct etw_loh_compact_info
-    {
-        uint32_t time_plan;
-        uint32_t time_compact;
-        uint32_t time_relocate;
-        size_t total_refs;
-        size_t zero_refs;
-    };
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY etw_loh_compact_info* loh_compact_info;
-#endif //FEATURE_LOH_COMPACTION
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY size_t physical_memory_from_config;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY size_t gen0_min_budget_from_config;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY size_t gen0_max_budget_from_config;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY int high_mem_percent_from_config;
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY bool use_frozen_segments_p;
-#endif //FEATURE_EVENT_TRACE
-#ifdef HEAP_BALANCE_INSTRUMENTATION
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY size_t last_gc_end_time_us;
-#endif //HEAP_BALANCE_INSTRUMENTATION
-#ifdef GC_CONFIG_DRIVEN
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY size_t compact_or_sweep_gcs[2];
-#endif //GC_CONFIG_DRIVEN
-#ifdef HEAP_ANALYZE
-    PER_HEAP_ISOLATED_FIELD_DIAG_ONLY BOOL heap_analyze_enabled;
-#endif //HEAP_ANALYZE
-    /***************************************************/
-    /***************************************************/
-    PER_HEAP_ISOLATED_FIELD BOOL reset_mm_p;
-    PER_HEAP_FIELD uint32_t fgn_maxgen_percent;
-    PER_HEAP_FIELD size_t fgn_last_alloc;
-    PER_HEAP_ISOLATED_FIELD uint32_t fgn_loh_percent;
-    PER_HEAP_ISOLATED_FIELD VOLATILE(bool) full_gc_approach_event_set;
-#ifdef BACKGROUND_GC
-    PER_HEAP_ISOLATED_FIELD BOOL fgn_last_gc_was_concurrent;
-    PER_HEAP_ISOLATED_FIELD bool temp_disable_concurrent_p;
-#endif //BACKGROUND_GC
-public:
-    /***************************************************************************************************/
-    /***************************************************************************************************/
-    PER_HEAP_ISOLATED_METHOD heap_segment* make_heap_segment(uint8_t* new_pages,
-        size_t size,
-        gc_heap* hp,
-        int gen_num);
-    PER_HEAP_ISOLATED_METHOD bool enable_preemptive();
-    PER_HEAP_ISOLATED_METHOD void disable_preemptive(bool restore_cooperative);
-    PER_HEAP_ISOLATED_METHOD uint32_t wait_for_gc_done(int32_t timeOut = INFINITE);
-    PER_HEAP_ISOLATED_METHOD int refresh_memory_limit();
-    /***************************************************************************************************/
-    /***************************************************************************************************/
-    PER_HEAP_ISOLATED_FIELD_SINGLE_GC VOLATILE(BOOL) gc_started;
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY size_t min_segment_size_shr;
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY size_t reserved_memory;
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY size_t reserved_memory_limit;
-#ifdef MULTIPLE_HEAPS
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY int n_heaps;
-    PER_HEAP_ISOLATED_FIELD_INIT_ONLY int n_max_heaps;
-#endif //MULTIPLE_HEAPS
-#ifdef FEATURE_BASICFREEZE
-    PER_HEAP_ISOLATED_FIELD_MAINTAINED sorted_table* seg_table;
-#endif //FEATURE_BASICFREEZE
-}; // class gc_heap
-#ifdef FEATURE_PREMORTEM_FINALIZATION
-class CFinalize
-{
-    friend class CFinalizeStaticAsserts;
-private:
-    static const int ExtraSegCount = 2;
-    static const int FinalizerListSeg = total_generation_count + 1;
-    static const int CriticalFinalizerListSeg = total_generation_count;
-    static const int FreeListSeg = total_generation_count + ExtraSegCount;
-    static const int FreeList = FreeListSeg;
-    static const int FinalizerStartSeg = CriticalFinalizerListSeg;
-    static const int FinalizerMaxSeg = FinalizerListSeg;
-    static const int MaxSeg = FreeListSeg;
-    PTR_PTR_Object m_FillPointers[total_generation_count + ExtraSegCount];
-    PTR_PTR_Object m_Array;
-    PTR_PTR_Object m_EndArray;
-    size_t   m_PromotedCount;
-    VOLATILE(int32_t) lock;
-#ifdef _DEBUG
-    EEThreadId lockowner_threadid;
-#endif // _DEBUG
-    BOOL GrowArray();
-    void MoveItem (Object** fromIndex,
-                   unsigned int fromSeg,
-                   unsigned int toSeg);
-    inline PTR_PTR_Object& SegQueue (unsigned int Seg)
-    {
-        return (Seg ? m_FillPointers [Seg-1] : m_Array);
-    }
-    inline PTR_PTR_Object& SegQueueLimit (unsigned int Seg)
-    {
-        return (Seg == MaxSeg ? m_EndArray : m_FillPointers[Seg]);
-    }
-    size_t UsedCount ()
-    {
-        return (SegQueue(FreeListSeg) - m_Array) + (m_EndArray - SegQueueLimit(FreeListSeg));
-    }
-    BOOL IsSegEmpty ( unsigned int i)
-    {
-        ASSERT ((int)i <= MaxSeg);
-        return (SegQueueLimit(i) == SegQueue (i));
-    }
-public:
-    ~CFinalize();
-    bool Initialize();
-    void EnterFinalizeLock();
-    void LeaveFinalizeLock();
-    bool RegisterForFinalization (int gen, Object* obj, size_t size=0);
-    Object* GetNextFinalizableObject (BOOL only_non_critical=FALSE);
-    BOOL ScanForFinalization (promote_func* fn, int gen, gc_heap* hp);
-    void RelocateFinalizationData (int gen, gc_heap* hp);
-    void WalkFReachableObjects (fq_walk_fn fn);
-    void GcScanRoots (promote_func* fn, int hn, ScanContext *pSC);
-    void UpdatePromotedGenerations (int gen, BOOL gen_0_empty_p);
-    size_t GetPromotedCount();
-    bool MergeFinalizationData (CFinalize* other_fq);
-    bool SplitFinalizationData (CFinalize* other_fq);
-    size_t GetNumberFinalizableObjects();
-    void CheckFinalizerObjects();
-};
-class CFinalizeStaticAsserts {
-    static_assert(dac_finalize_queue::ExtraSegCount == CFinalize::ExtraSegCount, "ExtraSegCount mismatch");
-    static_assert(offsetof(dac_finalize_queue, m_FillPointers) == offsetof(CFinalize, m_FillPointers), "CFinalize layout mismatch");
-};
-#endif // FEATURE_PREMORTEM_FINALIZATION
-inline
- size_t& dd_begin_data_size (dynamic_data* inst)
-{
-  return inst->begin_data_size;
-}
-inline
- size_t& dd_survived_size (dynamic_data* inst)
-{
-  return inst->survived_size;
-}
-#if defined (RESPECT_LARGE_ALIGNMENT) || defined (FEATURE_STRUCTALIGN)
-inline
- size_t& dd_num_npinned_plugs(dynamic_data* inst)
-{
-  return inst->num_npinned_plugs;
-}
-#endif //RESPECT_LARGE_ALIGNMENT || FEATURE_STRUCTALIGN
-inline
-size_t& dd_pinned_survived_size (dynamic_data* inst)
-{
-  return inst->pinned_survived_size;
-}
-inline
-size_t& dd_added_pinned_size (dynamic_data* inst)
-{
-  return inst->added_pinned_size;
-}
-inline
-size_t& dd_artificial_pinned_survived_size (dynamic_data* inst)
-{
-  return inst->artificial_pinned_survived_size;
-}
-#ifdef SHORT_PLUGS
-inline
-size_t& dd_padding_size (dynamic_data* inst)
-{
-  return inst->padding_size;
-}
-#endif //SHORT_PLUGS
-inline
- size_t& dd_current_size (dynamic_data* inst)
-{
-  return inst->current_size;
-}
-inline
-float& dd_surv (dynamic_data* inst)
-{
-  return inst->surv;
-}
-inline
-size_t& dd_freach_previous_promotion (dynamic_data* inst)
-{
-  return inst->freach_previous_promotion;
-}
-inline
-size_t& dd_desired_allocation (dynamic_data* inst)
-{
-  return inst->desired_allocation;
-}
-inline
-size_t& dd_collection_count (dynamic_data* inst)
-{
-    return inst->collection_count;
-}
-inline
-size_t& dd_promoted_size (dynamic_data* inst)
-{
-    return inst->promoted_size;
-}
-inline
-float& dd_limit (dynamic_data* inst)
-{
-  return inst->sdata->limit;
-}
-inline
-float& dd_max_limit (dynamic_data* inst)
-{
-  return inst->sdata->max_limit;
-}
-inline
-size_t& dd_max_size (dynamic_data* inst)
-{
-  return inst->sdata->max_size;
-}
-inline
-size_t& dd_min_size (dynamic_data* inst)
-{
-  return inst->min_size;
-}
-inline
-ptrdiff_t& dd_new_allocation (dynamic_data* inst)
-{
-  return inst->new_allocation;
-}
-inline
-ptrdiff_t& dd_gc_new_allocation (dynamic_data* inst)
-{
-  return inst->gc_new_allocation;
-}
-inline
-size_t& dd_fragmentation_limit (dynamic_data* inst)
-{
-  return inst->sdata->fragmentation_limit;
-}
-inline
-float& dd_fragmentation_burden_limit (dynamic_data* inst)
-{
-  return inst->sdata->fragmentation_burden_limit;
-}
-inline
-float dd_v_fragmentation_burden_limit (dynamic_data* inst)
-{
-  return (min (2*dd_fragmentation_burden_limit (inst), 0.75f));
-}
-inline
-size_t& dd_fragmentation (dynamic_data* inst)
-{
-  return inst->fragmentation;
-}
-inline
-size_t& dd_gc_clock (dynamic_data* inst)
-{
-  return inst->gc_clock;
-}
-inline
-uint64_t& dd_time_clock (dynamic_data* inst)
-{
-  return inst->time_clock;
-}
-inline
-uint64_t& dd_previous_time_clock (dynamic_data* inst)
-{
-    return inst->previous_time_clock;
-}
-inline
-size_t& dd_gc_clock_interval (dynamic_data* inst)
-{
-  return inst->sdata->gc_clock;
-}
-inline
-uint64_t& dd_time_clock_interval (dynamic_data* inst)
-{
-  return inst->sdata->time_clock;
-}
-inline
-size_t& dd_gc_elapsed_time (dynamic_data* inst)
-{
-    return inst->gc_elapsed_time;
-}
-inline
-alloc_context* generation_alloc_context (generation* inst)
-{
-    return &(inst->allocation_context);
-}
-#ifndef USE_REGIONS
-inline
-uint8_t*& generation_allocation_start (generation* inst)
-{
-  return inst->allocation_start;
-}
-#endif //!USE_REGIONS
-inline
-uint8_t*& generation_allocation_pointer (generation* inst)
-{
-  return inst->allocation_context.alloc_ptr;
-}
-inline
-uint8_t*& generation_allocation_limit (generation* inst)
-{
-  return inst->allocation_context.alloc_limit;
-}
-inline
-allocator* generation_allocator (generation* inst)
-{
-    return &inst->free_list_allocator;
-}
-inline
-PTR_heap_segment& generation_start_segment (generation* inst)
-{
-  return inst->start_segment;
-}
-#ifdef USE_REGIONS
-inline
-heap_segment*& generation_tail_region (generation* inst)
-{
-  return inst->tail_region;
-}
-inline
-heap_segment*& generation_tail_ro_region (generation* inst)
-{
-  return inst->tail_ro_region;
-}
-inline
-heap_segment* generation_start_segment_rw (generation* inst)
-{
-    return inst->tail_ro_region != nullptr ? inst->tail_ro_region : inst->start_segment;
-}
-#endif //USE_REGIONS
-inline
-heap_segment*& generation_allocation_segment (generation* inst)
-{
-  return inst->allocation_segment;
-}
-#ifndef USE_REGIONS
-inline
-uint8_t*& generation_plan_allocation_start (generation* inst)
-{
-  return inst->plan_allocation_start;
-}
-inline
-size_t& generation_plan_allocation_start_size (generation* inst)
-{
-  return inst->plan_allocation_start_size;
-}
-#endif //!USE_REGIONS
-inline
-uint8_t*& generation_allocation_context_start_region (generation* inst)
-{
-  return inst->allocation_context_start_region;
-}
-inline
-size_t& generation_free_list_space (generation* inst)
-{
-  return inst->free_list_space;
-}
-inline
-size_t& generation_free_obj_space (generation* inst)
-{
-  return inst->free_obj_space;
-}
-inline
-size_t& generation_allocation_size (generation* inst)
-{
-  return inst->allocation_size;
-}
-inline
-size_t& generation_pinned_allocation_sweep_size (generation* inst)
-{
-    return inst->pinned_allocation_sweep_size;
-}
-inline
-size_t& generation_pinned_allocation_compact_size (generation* inst)
-{
-    return inst->pinned_allocation_compact_size;
-}
-inline
-size_t&  generation_free_list_allocated (generation* inst)
-{
-    return inst->free_list_allocated;
-}
-inline
-size_t&  generation_end_seg_allocated (generation* inst)
-{
-    return inst->end_seg_allocated;
-}
-inline
-BOOL&  generation_allocate_end_seg_p (generation* inst)
-{
-    return inst->allocate_end_seg_p;
-}
-inline
-size_t& generation_condemned_allocated (generation* inst)
-{
-    return inst->condemned_allocated;
-}
-inline
-size_t& generation_sweep_allocated (generation* inst)
-{
-    return inst->sweep_allocated;
-}
-inline
-size_t generation_total_plan_allocated (generation* inst)
-{
-    return (inst->free_list_allocated + inst->end_seg_allocated + inst->condemned_allocated);
-}
-#ifdef DOUBLY_LINKED_FL
-inline
-BOOL&  generation_set_bgc_mark_bit_p (generation* inst)
-{
-    return inst->set_bgc_mark_bit_p;
-}
-inline
-uint8_t*&  generation_last_free_list_allocated (generation* inst)
-{
-    return inst->last_free_list_allocated;
-}
-#endif //DOUBLY_LINKED_FL
-#ifdef FREE_USAGE_STATS
-inline
-size_t& generation_pinned_free_obj_space (generation* inst)
-{
-    return inst->pinned_free_obj_space;
-}
-inline
-size_t& generation_allocated_in_pinned_free (generation* inst)
-{
-    return inst->allocated_in_pinned_free;
-}
-inline
-size_t& generation_allocated_since_last_pin (generation* inst)
-{
-    return inst->allocated_since_last_pin;
-}
-#endif //FREE_USAGE_STATS
-#define plug_skew           sizeof(ObjHeader)
-#define min_free_list       (2*min_obj_size)
-#define min_free_item_no_prev  (min_obj_size+sizeof(uint8_t*))
-struct plug
-{
-    uint8_t *  skew[plug_skew / sizeof(uint8_t *)];
-};
-class pair
-{
-public:
-    short left;
-    short right;
-};
-struct plug_and_pair
-{
-    pair        m_pair;
-    plug        m_plug;
-};
-struct plug_and_reloc
-{
-    ptrdiff_t   reloc;
-    pair        m_pair;
-    plug        m_plug;
-};
-struct plug_and_gap
-{
-    ptrdiff_t   gap;
-    ptrdiff_t   reloc;
-    union
-    {
-        pair    m_pair;
-        int     lr;  //for clearing the entire pair in one instruction
-    };
-    plug        m_plug;
-};
-struct gap_reloc_pair
-{
-    size_t gap;
-    size_t reloc;
-    pair   m_pair;
-};
-#define min_pre_pin_obj_size (sizeof (gap_reloc_pair) + min_obj_size)
-struct DECLSPEC_ALIGN(8) aligned_plug_and_gap
-{
-    size_t       additional_pad;
-    plug_and_gap plugandgap;
-};
-struct loh_obj_and_pad
-{
-    ptrdiff_t   reloc;
-    plug        m_plug;
-};
-struct loh_padding_obj
-{
-    uint8_t*    mt;
-    size_t      len;
-    ptrdiff_t   reloc;
-    plug        m_plug;
-};
-#define loh_padding_obj_size (sizeof(loh_padding_obj))
-#define heap_segment_flags_readonly     1
-#define heap_segment_flags_inrange      2
-#define heap_segment_flags_loh          8
-#ifdef BACKGROUND_GC
-#define heap_segment_flags_swept        16
-#define heap_segment_flags_decommitted  32
-#define heap_segment_flags_ma_committed 64
-#define heap_segment_flags_ma_pcommitted 128
-#define heap_segment_flags_uoh_delete   256
-#endif //BACKGROUND_GC
-#define heap_segment_flags_poh          512
-#if defined(BACKGROUND_GC) && defined(USE_REGIONS)
-#define heap_segment_flags_overflow      1024
-#endif //BACKGROUND_GC && USE_REGIONS
-#ifdef USE_REGIONS
-#define heap_segment_flags_demoted       2048
-struct generation_region_info
-{
-    heap_segment* head;
-    heap_segment* tail;
-};
-#endif //USE_REGIONS
-class heap_segment
-{
-    friend class allocator;
-public:
-    uint8_t*        allocated;
-    uint8_t*        committed;
-    uint8_t*        reserved;
-    uint8_t*        used;
-    uint8_t*        mem;
-    size_t          flags;
-    PTR_heap_segment next;
-    uint8_t*        background_allocated;
-#ifdef MULTIPLE_HEAPS
-    gc_heap*        heap;
-#if defined(_DEBUG) && !defined(USE_REGIONS)
-    uint8_t*        saved_committed;
-    size_t          saved_desired_allocation;
-#endif //_DEBUG && ! USE_REGIONS
-#endif //MULTIPLE_HEAPS
-#if !defined(USE_REGIONS) || defined(MULTIPLE_HEAPS)
-    uint8_t*        decommit_target;
-#endif //!USE_REGIONS || MULTIPLE_HEAPS
-    uint8_t*        plan_allocated;
-    uint8_t*        saved_allocated;
-    uint8_t*        saved_bg_allocated;
-#ifdef USE_REGIONS
-    size_t          survived;
-    uint8_t         gen_num;
-    bool            swept_in_plan_p;
-    int             plan_gen_num;
-    int             old_card_survived;
-    int             pinned_survived;
-    #define MAX_AGE_IN_FREE 99
-    #define AGE_IN_FREE_TO_DECOMMIT 20
-    int             age_in_free;
-    uint8_t*        free_list_head;
-    uint8_t*        free_list_tail;
-    size_t          free_list_size;
-    size_t          free_obj_size;
-    PTR_heap_segment prev_free_region;
-    region_free_list* containing_free_list;
-    void init_free_list()
-    {
-        free_list_head = 0;
-        free_list_tail = 0;
-        free_list_size = 0;
-        free_obj_size = 0;
-    }
-    void thread_free_obj (uint8_t* obj, size_t s);
-#else //USE_REGIONS
-#ifdef _MSC_VER
-#pragma warning(disable:4324)  // structure was padded due to __declspec(align())
-#endif
-    aligned_plug_and_gap padandplug;
-#ifdef _MSC_VER
-#pragma warning(default:4324)  // structure was padded due to __declspec(align())
-#endif
-#endif //USE_REGIONS
-};
-#ifdef USE_REGIONS
-#define LARGE_REGION_FACTOR (8)
-#define region_alloc_free_bit (1 << (sizeof (uint32_t) * 8 - 1))
-const int min_regions_per_heap = ((ephemeral_generation_count + 1) + ((total_generation_count - uoh_start_generation) * LARGE_REGION_FACTOR));
-enum allocate_direction
-{
-    allocate_forward = 1,
-    allocate_backward = -1,
-};
-typedef bool (*region_allocator_callback_fn)(uint8_t*);
-class region_allocator
-{
-private:
-    uint8_t* global_region_start;
-    uint8_t* global_region_end;
-    uint8_t* global_region_left_used;
-    uint8_t* global_region_right_used;
-    uint32_t total_free_units;
-    size_t region_alignment;
-    size_t large_region_alignment;
-    GCSpinLock region_allocator_lock;
-    uint32_t* region_map_left_start;
-    uint32_t* region_map_left_end;
-    uint32_t* region_map_right_start;
-    uint32_t* region_map_right_end;
-    uint32_t num_left_used_free_units;
-    uint32_t num_right_used_free_units;
-    uint8_t* region_address_of (uint32_t* map_index);
-    uint32_t* region_map_index_of (uint8_t* address);
-    uint8_t* allocate (uint32_t num_units, allocate_direction direction, region_allocator_callback_fn fn);
-    uint8_t* allocate_end (uint32_t num_units, allocate_direction direction);
-    void enter_spin_lock();
-    void leave_spin_lock();
-    void make_busy_block (uint32_t* index_start, uint32_t num_units);
-    void make_free_block (uint32_t* index_start, uint32_t num_units);
-    void print_map (const char* msg);
-    size_t align_region_up (size_t size)
-    {
-        return ((size + (region_alignment - 1)) & ~(region_alignment - 1));
-    }
-    size_t align_region_down (size_t size)
-    {
-        return (size & ~(region_alignment - 1));
-    }
-    size_t is_region_aligned (uint8_t* address)
-    {
-        return ((size_t)address == ((size_t)address & ~(region_alignment - 1)));
-    }
-    bool is_unit_memory_free (uint32_t val)
-    {
-        return !!(val & region_alloc_free_bit);
-    }
-    uint32_t get_num_units (uint32_t val)
-    {
-        return (val & ~region_alloc_free_bit);
-    }
-public:
-    bool init (uint8_t* start, uint8_t* end, size_t alignment, uint8_t** lowest, uint8_t** highest);
-    bool allocate_region (int gen_num, size_t size, uint8_t** start, uint8_t** end, allocate_direction direction, region_allocator_callback_fn fn);
-    bool allocate_basic_region (int gen_num, uint8_t** start, uint8_t** end, region_allocator_callback_fn fn);
-    bool allocate_large_region (int gen_num, uint8_t** start, uint8_t** end, allocate_direction direction, size_t size, region_allocator_callback_fn fn);
-    void delete_region (uint8_t* start);
-    void delete_region_impl (uint8_t* start);
-    uint32_t get_va_memory_load()
-    {
-        return (uint32_t)(((global_region_left_used - global_region_start) + ((global_region_end - global_region_right_used)))* 100.0
-                          / (global_region_end - global_region_start));
-    }
-    size_t get_free() { return (total_free_units * region_alignment) ; }
-    size_t get_region_alignment () { return region_alignment; }
-    size_t get_large_region_alignment () { return large_region_alignment; }
-    size_t get_used_region_count()
-    {
-        assert (region_map_right_start == region_map_right_end);
-        return (region_map_left_end - region_map_left_start);
-    }
-    void move_highest_free_regions (int64_t n, bool small_region_p, region_free_list to_free_list[count_free_region_kinds]);
-    uint8_t* get_start() { return global_region_start; }
-    uint8_t* get_left_used_unsafe() { return global_region_left_used; }
-};
-#endif //USE_REGIONS
-#define ro_in_entry 0x1
-struct seg_mapping
-{
-#ifdef USE_REGIONS
-    heap_segment region_info;
-#else
-    uint8_t* boundary;
-#ifdef MULTIPLE_HEAPS
-    gc_heap* h0;
-    gc_heap* h1;
-#endif //MULTIPLE_HEAPS
-    heap_segment* seg0; // this is what the seg for h0 is.
-    heap_segment* seg1; // this is what the seg for h1 is.
-#endif //USE_REGIONS
-};
-static_assert(offsetof(dac_heap_segment, allocated) == offsetof(heap_segment, allocated), "DAC heap segment layout mismatch");
-static_assert(offsetof(dac_heap_segment, committed) == offsetof(heap_segment, committed), "DAC heap segment layout mismatch");
-static_assert(offsetof(dac_heap_segment, reserved) == offsetof(heap_segment, reserved), "DAC heap segment layout mismatch");
-static_assert(offsetof(dac_heap_segment, used) == offsetof(heap_segment, used), "DAC heap segment layout mismatch");
-static_assert(offsetof(dac_heap_segment, mem) == offsetof(heap_segment, mem), "DAC heap segment layout mismatch");
-static_assert(offsetof(dac_heap_segment, flags) == offsetof(heap_segment, flags), "DAC heap segment layout mismatch");
-static_assert(offsetof(dac_heap_segment, next) == offsetof(heap_segment, next), "DAC heap segment layout mismatch");
-static_assert(offsetof(dac_heap_segment, background_allocated) == offsetof(heap_segment, background_allocated), "DAC heap segment layout mismatch");
-#ifdef MULTIPLE_HEAPS
-static_assert(offsetof(dac_heap_segment, heap) == offsetof(heap_segment, heap), "DAC heap segment layout mismatch");
-#endif // MULTIPLE_HEAPS
-inline
-uint8_t*& heap_segment_reserved (heap_segment* inst)
-{
-  return inst->reserved;
-}
-inline
-uint8_t*& heap_segment_committed (heap_segment* inst)
-{
-  return inst->committed;
-}
-#if !defined(USE_REGIONS) || defined(MULTIPLE_HEAPS)
-inline
-uint8_t*& heap_segment_decommit_target (heap_segment* inst)
-{
-    return inst->decommit_target;
-}
-#endif //!USE_REGIONS || MULTIPLE_HEAPS
-inline
-uint8_t*& heap_segment_used (heap_segment* inst)
-{
-  return inst->used;
-}
-inline
-uint8_t*& heap_segment_allocated (heap_segment* inst)
-{
-  return inst->allocated;
-}
-inline
-BOOL heap_segment_read_only_p (heap_segment* inst)
-{
-    return ((inst->flags & heap_segment_flags_readonly) != 0);
-}
-inline
-BOOL heap_segment_in_range_p (heap_segment* inst)
-{
-    return (!(inst->flags & heap_segment_flags_readonly) ||
-            ((inst->flags & heap_segment_flags_inrange) != 0));
-}
-inline
-BOOL heap_segment_loh_p (heap_segment* inst)
-{
-    return !!(inst->flags & heap_segment_flags_loh);
-}
-inline
-BOOL heap_segment_poh_p (heap_segment* inst)
-{
-    return !!(inst->flags & heap_segment_flags_poh);
-}
-inline
-BOOL heap_segment_uoh_p (heap_segment* inst)
-{
-    return !!(inst->flags & (heap_segment_flags_loh | heap_segment_flags_poh));
-}
-inline gc_oh_num heap_segment_oh (heap_segment * inst)
-{
-    if ((inst->flags & heap_segment_flags_loh) != 0)
-    {
-        return gc_oh_num::loh;
-    }
-    else if ((inst->flags & heap_segment_flags_poh) != 0)
-    {
-        return gc_oh_num::poh;
-    }
-    else
-    {
-        return gc_oh_num::soh;
-    }
-}
-#ifdef USE_REGIONS
-inline
-region_free_list*& heap_segment_containing_free_list (heap_segment* inst)
-{
-    return inst->containing_free_list;
-}
-inline
-PTR_heap_segment& heap_segment_prev_free_region (heap_segment* inst)
-{
-    return inst->prev_free_region;
-}
-#endif //USE_REGIONS
-#ifdef BACKGROUND_GC
-#ifdef USE_REGIONS
-inline
-bool heap_segment_overflow_p (heap_segment* inst)
-{
-    return ((inst->flags & heap_segment_flags_overflow) != 0);
-}
-#endif //USE_REGIONS
-inline
-BOOL heap_segment_decommitted_p (heap_segment * inst)
-{
-    return !!(inst->flags & heap_segment_flags_decommitted);
-}
-inline
-BOOL heap_segment_swept_p (heap_segment * inst)
-{
-    return !!(inst->flags & heap_segment_flags_swept);
-}
-#endif //BACKGROUND_GC
-inline
-PTR_heap_segment & heap_segment_next (heap_segment* inst)
-{
-  return inst->next;
-}
-inline
-uint8_t*& heap_segment_mem (heap_segment* inst)
-{
-  return inst->mem;
-}
-inline
-uint8_t*& heap_segment_plan_allocated (heap_segment* inst)
-{
-  return inst->plan_allocated;
-}
-inline
-uint8_t*& heap_segment_saved_allocated (heap_segment* inst)
-{
-  return inst->saved_allocated;
-}
-#ifdef BACKGROUND_GC
-inline
-uint8_t*& heap_segment_background_allocated (heap_segment* inst)
-{
-  return inst->background_allocated;
-}
-inline
-uint8_t*& heap_segment_saved_bg_allocated (heap_segment* inst)
-{
-  return inst->saved_bg_allocated;
-}
-#endif //BACKGROUND_GC
-#ifdef MULTIPLE_HEAPS
-inline
-gc_heap*& heap_segment_heap (heap_segment* inst)
-{
-    return inst->heap;
-}
-#endif //MULTIPLE_HEAPS
-#ifdef USE_REGIONS
-inline
-uint8_t& heap_segment_gen_num (heap_segment* inst)
-{
-    return inst->gen_num;
-}
-inline
-bool& heap_segment_swept_in_plan (heap_segment* inst)
-{
-    return inst->swept_in_plan_p;
-}
-inline
-int& heap_segment_plan_gen_num (heap_segment* inst)
-{
-    return inst->plan_gen_num;
-}
-inline
-int& heap_segment_age_in_free (heap_segment* inst)
-{
-    return inst->age_in_free;
-}
-inline
-size_t& heap_segment_survived (heap_segment* inst)
-{
-    return inst->survived;
-}
-inline
-int& heap_segment_old_card_survived (heap_segment* inst)
-{
-    return inst->old_card_survived;
-}
-inline
-int& heap_segment_pinned_survived (heap_segment* inst)
-{
-    return inst->pinned_survived;
-}
-inline
-uint8_t* heap_segment_free_list_head (heap_segment* inst)
-{
-    return inst->free_list_head;
-}
-inline
-uint8_t* heap_segment_free_list_tail (heap_segment* inst)
-{
-    return inst->free_list_tail;
-}
-inline
-size_t heap_segment_free_list_size (heap_segment* inst)
-{
-    return inst->free_list_size;
-}
-inline
-size_t heap_segment_free_obj_size (heap_segment* inst)
-{
-    return inst->free_obj_size;
-}
-inline
-bool heap_segment_demoted_p (heap_segment* inst)
-{
-    return ((inst->flags & heap_segment_flags_demoted) != 0);
-}
-#endif //USE_REGIONS
-inline
-generation* gc_heap::generation_of (int  n)
-{
-    assert (((n < total_generation_count) && (n >= 0)));
-    return &generation_table[n];
-}
-inline
-dynamic_data* gc_heap::dynamic_data_of (int gen_number)
-{
-    return &dynamic_data_table[gen_number];
-}
-#define GC_PAGE_SIZE 0x1000
-#define card_word_width ((size_t)32)
-#if defined (HOST_64BIT)
-#define card_size ((size_t)(2*GC_PAGE_SIZE/card_word_width))
-#else
-#define card_size ((size_t)(GC_PAGE_SIZE/card_word_width))
-#endif // HOST_64BIT
-inline
-size_t card_word (size_t card)
-{
-    return card / card_word_width;
-}
-inline
-unsigned card_bit (size_t card)
-{
-    return (unsigned)(card % card_word_width);
-}
-inline
-size_t gcard_of (uint8_t* object)
-{
-    return (size_t)(object) / card_size;
-}
-#ifdef FEATURE_CARD_MARKING_STEALING
-#define CARD_MARKING_STEALING_GRANULARITY (card_size*card_word_width*card_bundle_size*8)
-#define THIS_ARG    , __this
-class card_marking_enumerator
-{
-private:
-    heap_segment*       segment;
-    uint8_t*            gc_low;
-    uint32_t            segment_start_chunk_index;
-    VOLATILE(uint32_t)* chunk_index_counter;
-    uint8_t*            chunk_high;
-    uint32_t            old_chunk_index;
-    static const uint32_t INVALID_CHUNK_INDEX = ~0u;
-public:
-    card_marking_enumerator(heap_segment* seg, uint8_t* low, VOLATILE(uint32_t)* counter) :
-        segment(seg), gc_low(low), segment_start_chunk_index(0), chunk_index_counter(counter), chunk_high(nullptr), old_chunk_index(INVALID_CHUNK_INDEX)
-    {
-    }
-    bool move_next(heap_segment* seg, uint8_t*& low, uint8_t*& high);
-    void exhaust_segment(heap_segment* seg)
-    {
-        uint8_t* low;
-        uint8_t* high;
-        while (move_next(seg, low, high))
-            ;
-    }
-#ifdef USE_REGIONS
-    void switch_to_segment(heap_segment* seg)
-    {
-        assert(segment == nullptr);
-        segment = seg;
-    }
-#endif
-    uint8_t* get_chunk_high()
-    {
-        return chunk_high;
-    }
-};
-#else
-#define THIS_ARG
-#endif // FEATURE_CARD_MARKING_STEALING
-using std::min;
-using std::max;

--- a/src/coreclr/gc/unix/gcenv.unix.cpp
+++ b//dev/null
@@ -1,1135 +0,0 @@
-#define _WITH_GETLINE
-#include <cstdint>
-#include <cstddef>
-#include <cstdio>
-#include <cassert>
-#define __STDC_FORMAT_MACROS
-#include <cinttypes>
-#include <memory>
-#include <pthread.h>
-#include <signal.h>
-#include "config.gc.h"
-#include "common.h"
-#include "gcenv.structs.h"
-#include "gcenv.base.h"
-#include "gcenv.os.h"
-#include "gcenv.ee.h"
-#include "gcenv.unix.inl"
-#include "volatile.h"
-#include "gcconfig.h"
-#include "numasupport.h"
-#if HAVE_SWAPCTL
-#include <sys/swap.h>
-#endif
-#include <sys/resource.h>
-#undef min
-#undef max
-#ifndef __has_cpp_attribute
-#define __has_cpp_attribute(x) (0)
-#endif
-#include <algorithm>
-#if HAVE_SYS_TIME_H
- #include <sys/time.h>
-#else
- #error "sys/time.h required by GC PAL for the time being"
-#endif
-#if HAVE_SYS_MMAN_H
- #include <sys/mman.h>
-#else
- #error "sys/mman.h required by GC PAL"
-#endif
-#if HAVE_SYSCTLBYNAME
-#include <sys/types.h>
-#include <sys/sysctl.h>
-#endif
-#if HAVE_SYSINFO
-#include <sys/sysinfo.h>
-#endif
-#if HAVE_XSWDEV
-#include <vm/vm_param.h>
-#endif // HAVE_XSWDEV
-#ifdef __APPLE__
-#include <mach/vm_types.h>
-#include <mach/vm_param.h>
-#include <mach/mach_port.h>
-#include <mach/mach_host.h>
-#include <mach/task.h>
-#include <mach/vm_map.h>
-extern "C"
-{
-#  include <mach/thread_state.h>
-}
-#define CHECK_MACH(_msg, machret) do {                                      \
-        if (machret != KERN_SUCCESS)                                        \
-        {                                                                   \
-            char _szError[1024];                                            \
-            snprintf(_szError, ARRAY_SIZE(_szError), "%s: %u: %s", __FUNCTION__, __LINE__, _msg);  \
-            mach_error(_szError, machret);                                  \
-            abort();                                                        \
-        }                                                                   \
-    } while (false)
-#endif // __APPLE__
-#ifdef __linux__
-#include <sys/syscall.h> // __NR_membarrier
-# if !defined(__NR_membarrier)
-#  if defined(__amd64__)
-#   define __NR_membarrier  324
-#  elif defined(__i386__)
-#   define __NR_membarrier  375
-#  elif defined(__arm__)
-#   define __NR_membarrier  389
-#  elif defined(__aarch64__)
-#   define __NR_membarrier  283
-#  elif defined(__loongarch64)
-#   define __NR_membarrier  283
-#  else
-#   error Unknown architecture
-#  endif
-# endif
-#endif
-#if HAVE_PTHREAD_NP_H
-#include <pthread_np.h>
-#endif
-#if HAVE_CPUSET_T
-typedef cpuset_t cpu_set_t;
-#endif
-#include <time.h> // nanosleep
-#include <sched.h> // sched_yield
-#include <errno.h>
-#include <unistd.h> // sysconf
-#include "globals.h"
-#include "cgroup.h"
-#ifndef __APPLE__
-#if HAVE_SYSCONF && HAVE__SC_AVPHYS_PAGES
-#define SYSCONF_PAGES _SC_AVPHYS_PAGES
-#elif HAVE_SYSCONF && HAVE__SC_PHYS_PAGES
-#define SYSCONF_PAGES _SC_PHYS_PAGES
-#else
-#error Dont know how to get page-size on this architecture!
-#endif
-#endif // __APPLE__
-#if defined(HOST_ARM) || defined(HOST_ARM64) || defined(HOST_LOONGARCH64) || defined(HOST_RISCV64)
-#define SYSCONF_GET_NUMPROCS _SC_NPROCESSORS_CONF
-#else
-#define SYSCONF_GET_NUMPROCS _SC_NPROCESSORS_ONLN
-#endif
-static uint32_t g_totalCpuCount = 0;
-#ifdef __NR_membarrier
-# define membarrier(...)  syscall(__NR_membarrier, __VA_ARGS__)
-#else
-# define membarrier(...)  -ENOSYS
-#endif
-enum membarrier_cmd
-{
-    MEMBARRIER_CMD_QUERY                                 = 0,
-    MEMBARRIER_CMD_GLOBAL                                = (1 << 0),
-    MEMBARRIER_CMD_GLOBAL_EXPEDITED                      = (1 << 1),
-    MEMBARRIER_CMD_REGISTER_GLOBAL_EXPEDITED             = (1 << 2),
-    MEMBARRIER_CMD_PRIVATE_EXPEDITED                     = (1 << 3),
-    MEMBARRIER_CMD_REGISTER_PRIVATE_EXPEDITED            = (1 << 4),
-    MEMBARRIER_CMD_PRIVATE_EXPEDITED_SYNC_CORE           = (1 << 5),
-    MEMBARRIER_CMD_REGISTER_PRIVATE_EXPEDITED_SYNC_CORE  = (1 << 6)
-};
-bool CanFlushUsingMembarrier()
-{
-#ifdef TARGET_ANDROID
-    int apiLevel = android_get_device_api_level();
-    if (apiLevel < __ANDROID_API_Q__)
-    {
-        return false;
-    }
-#endif
-    int mask = membarrier(MEMBARRIER_CMD_QUERY, 0);
-    if (mask >= 0 &&
-        mask & MEMBARRIER_CMD_PRIVATE_EXPEDITED &&
-        membarrier(MEMBARRIER_CMD_REGISTER_PRIVATE_EXPEDITED, 0) == 0)
-    {
-        return true;
-    }
-    return false;
-}
-static int s_flushUsingMemBarrier = 0;
-static uint8_t* g_helperPage = 0;
-static pthread_mutex_t g_flushProcessWriteBuffersMutex;
-size_t GetRestrictedPhysicalMemoryLimit();
-bool GetPhysicalMemoryUsed(size_t* val);
-static size_t g_RestrictedPhysicalMemoryLimit = 0;
-uint32_t g_pageSizeUnixInl = 0;
-AffinitySet g_processAffinitySet;
-extern "C" int g_highestNumaNode;
-extern "C" bool g_numaAvailable;
-static int64_t g_totalPhysicalMemSize = 0;
-#ifdef TARGET_APPLE
-static int *g_kern_memorystatus_level_mib = NULL;
-static size_t g_kern_memorystatus_level_mib_length = 0;
-#endif
-bool GCToOSInterface::Initialize()
-{
-    int pageSize = sysconf( _SC_PAGE_SIZE );
-    g_pageSizeUnixInl = uint32_t((pageSize > 0) ? pageSize : 0x1000);
-    int cpuCount = sysconf(SYSCONF_GET_NUMPROCS);
-    if (cpuCount == -1)
-    {
-        return false;
-    }
-    g_totalCpuCount = cpuCount;
-    assert(s_flushUsingMemBarrier == 0);
-    if (CanFlushUsingMembarrier())
-    {
-        s_flushUsingMemBarrier = TRUE;
-    }
-#ifndef TARGET_APPLE
-    else
-    {
-        assert(g_helperPage == 0);
-        g_helperPage = static_cast<uint8_t*>(mmap(0, OS_PAGE_SIZE, PROT_READ | PROT_WRITE, MAP_ANONYMOUS | MAP_PRIVATE, -1, 0));
-        if (g_helperPage == MAP_FAILED)
-        {
-            return false;
-        }
-        assert((((size_t)g_helperPage) & (OS_PAGE_SIZE - 1)) == 0);
-        int status = mlock(g_helperPage, OS_PAGE_SIZE);
-        if (status != 0)
-        {
-            return false;
-        }
-        status = pthread_mutex_init(&g_flushProcessWriteBuffersMutex, NULL);
-        if (status != 0)
-        {
-            munlock(g_helperPage, OS_PAGE_SIZE);
-            return false;
-        }
-    }
-#endif // !TARGET_APPLE
-    InitializeCGroup();
-#if HAVE_SCHED_GETAFFINITY
-    cpu_set_t cpuSet;
-    int st = sched_getaffinity(getpid(), sizeof(cpu_set_t), &cpuSet);
-    if (st == 0)
-    {
-        for (size_t i = 0; i < CPU_SETSIZE; i++)
-        {
-            if (CPU_ISSET(i, &cpuSet))
-            {
-                g_processAffinitySet.Add(i);
-            }
-        }
-    }
-    else
-    {
-        assert(false);
-    }
-#else // HAVE_SCHED_GETAFFINITY
-    for (size_t i = 0; i < g_totalCpuCount; i++)
-    {
-        g_processAffinitySet.Add(i);
-    }
-#endif // HAVE_SCHED_GETAFFINITY
-    NUMASupportInitialize();
-#ifdef TARGET_APPLE
-    const char* mem_free_name = "kern.memorystatus_level";
-    int rc = sysctlnametomib(mem_free_name, NULL, &g_kern_memorystatus_level_mib_length);
-    if (rc != 0)
-    {
-        return false;
-    }
-    g_kern_memorystatus_level_mib = (int*)malloc(g_kern_memorystatus_level_mib_length * sizeof(int));
-    if (g_kern_memorystatus_level_mib == NULL)
-    {
-        return false;
-    }
-    rc = sysctlnametomib(mem_free_name, g_kern_memorystatus_level_mib, &g_kern_memorystatus_level_mib_length);
-    if (rc != 0)
-    {
-        free(g_kern_memorystatus_level_mib);
-        g_kern_memorystatus_level_mib = NULL;
-        g_kern_memorystatus_level_mib_length = 0;
-        return false;
-    }
-#endif
-#if HAVE_SYSCONF && HAVE__SC_PHYS_PAGES
-    long pages = sysconf(_SC_PHYS_PAGES);
-    if (pages == -1)
-    {
-        return false;
-    }
-    g_totalPhysicalMemSize = (uint64_t)pages * (uint64_t)g_pageSizeUnixInl;
-#elif HAVE_SYSCTL
-    int mib[2];
-    mib[0] = CTL_HW;
-    mib[1] = HW_MEMSIZE;
-    size_t length = sizeof(INT64);
-    int rc = sysctl(mib, 2, &g_totalPhysicalMemSize, &length, NULL, 0);
-    if (rc == 0)
-    {
-        return false;
-    }
-#else // HAVE_SYSCTL
-#error "Don't know how to get total physical memory on this platform"
-#endif // HAVE_SYSCTL
-    assert(g_totalPhysicalMemSize != 0);
-    return true;
-}
-void GCToOSInterface::Shutdown()
-{
-    int ret = munlock(g_helperPage, OS_PAGE_SIZE);
-    assert(ret == 0);
-    ret = pthread_mutex_destroy(&g_flushProcessWriteBuffersMutex);
-    assert(ret == 0);
-    munmap(g_helperPage, OS_PAGE_SIZE);
-    CleanupCGroup();
-}
-uint64_t GCToOSInterface::GetCurrentThreadIdForLogging()
-{
-#if defined(__linux__)
-    return (uint64_t)syscall(SYS_gettid);
-#elif HAVE_PTHREAD_GETTHREADID_NP
-    return (uint64_t)pthread_getthreadid_np();
-#elif HAVE_PTHREAD_THREADID_NP
-    unsigned long long tid;
-    pthread_threadid_np(pthread_self(), &tid);
-    return (uint64_t)tid;
-#else
-    return (uint64_t)pthread_self();
-#endif
-}
-uint32_t GCToOSInterface::GetCurrentProcessId()
-{
-    return getpid();
-}
-bool GCToOSInterface::SetCurrentThreadIdealAffinity(uint16_t srcProcNo, uint16_t dstProcNo)
-{
-    return true;
-}
-uint32_t GCToOSInterface::GetCurrentProcessorNumber()
-{
-#if HAVE_SCHED_GETCPU
-    int processorNumber = sched_getcpu();
-    assert(processorNumber != -1);
-    return processorNumber;
-#else
-    assert(false); // This method is expected to be called only if CanGetCurrentProcessorNumber is true
-    return 0;
-#endif
-}
-bool GCToOSInterface::CanGetCurrentProcessorNumber()
-{
-    return HAVE_SCHED_GETCPU;
-}
-void GCToOSInterface::FlushProcessWriteBuffers()
-{
-    if (s_flushUsingMemBarrier)
-    {
-        int status = membarrier(MEMBARRIER_CMD_PRIVATE_EXPEDITED, 0);
-        assert(status == 0 && "Failed to flush using membarrier");
-    }
-    else if (g_helperPage != 0)
-    {
-        int status = pthread_mutex_lock(&g_flushProcessWriteBuffersMutex);
-        assert(status == 0 && "Failed to lock the flushProcessWriteBuffersMutex lock");
-        status = mprotect(g_helperPage, OS_PAGE_SIZE, PROT_READ | PROT_WRITE);
-        assert(status == 0 && "Failed to change helper page protection to read / write");
-        __sync_add_and_fetch((size_t*)g_helperPage, 1);
-        status = mprotect(g_helperPage, OS_PAGE_SIZE, PROT_NONE);
-        assert(status == 0 && "Failed to change helper page protection to no access");
-        status = pthread_mutex_unlock(&g_flushProcessWriteBuffersMutex);
-        assert(status == 0 && "Failed to unlock the flushProcessWriteBuffersMutex lock");
-    }
-#ifdef TARGET_APPLE
-    else
-    {
-        mach_msg_type_number_t cThreads;
-        thread_act_t *pThreads;
-        kern_return_t machret = task_threads(mach_task_self(), &pThreads, &cThreads);
-        CHECK_MACH("task_threads()", machret);
-        uintptr_t sp;
-        uintptr_t registerValues[128];
-        for (mach_msg_type_number_t i = 0; i < cThreads; i++)
-        {
-            if (__builtin_available (macOS 10.14, iOS 12, tvOS 9, *))
-            {
-                size_t registers = 128;
-                machret = thread_get_register_pointer_values(pThreads[i], &sp, &registers, registerValues);
-            }
-            else
-            {
-#if defined(HOST_AMD64)
-                x86_thread_state64_t threadState;
-                mach_msg_type_number_t count = x86_THREAD_STATE64_COUNT;
-                machret = thread_get_state(pThreads[i], x86_THREAD_STATE64, (thread_state_t)&threadState, &count);
-#elif defined(HOST_ARM64)
-                arm_thread_state64_t threadState;
-                mach_msg_type_number_t count = ARM_THREAD_STATE64_COUNT;
-                machret = thread_get_state(pThreads[i], ARM_THREAD_STATE64, (thread_state_t)&threadState, &count);
-#else
-                #error Unexpected architecture
-#endif
-            }
-            if (machret == KERN_INSUFFICIENT_BUFFER_SIZE)
-            {
-                CHECK_MACH("thread_get_register_pointer_values()", machret);
-            }
-            machret = mach_port_deallocate(mach_task_self(), pThreads[i]);
-            CHECK_MACH("mach_port_deallocate()", machret);
-        }
-        machret = vm_deallocate(mach_task_self(), (vm_address_t)pThreads, cThreads * sizeof(thread_act_t));
-        CHECK_MACH("vm_deallocate()", machret);
-    }
-#endif // TARGET_APPLE
-}
-void GCToOSInterface::DebugBreak()
-{
-#if __has_builtin(__builtin_debugtrap)
-    __builtin_debugtrap();
-#else
-    raise(SIGTRAP);
-#endif
-}
-void GCToOSInterface::Sleep(uint32_t sleepMSec)
-{
-    if (sleepMSec == 0)
-    {
-        return;
-    }
-    timespec requested;
-    requested.tv_sec = sleepMSec / tccSecondsToMilliSeconds;
-    requested.tv_nsec = (sleepMSec - requested.tv_sec * tccSecondsToMilliSeconds) * tccMilliSecondsToNanoSeconds;
-    timespec remaining;
-    while (nanosleep(&requested, &remaining) == EINTR)
-    {
-        requested = remaining;
-    }
-}
-void GCToOSInterface::YieldThread(uint32_t switchCount)
-{
-    int ret = sched_yield();
-    assert(ret == 0);
-}
-static void* VirtualReserveInner(size_t size, size_t alignment, uint32_t flags, uint32_t hugePagesFlag, bool committing)
-{
-    assert(!(flags & VirtualReserveFlags::WriteWatch) && "WriteWatch not supported on Unix");
-    if (alignment < OS_PAGE_SIZE)
-    {
-        alignment = OS_PAGE_SIZE;
-    }
-    size_t alignedSize = size + (alignment - OS_PAGE_SIZE);
-    void * pRetVal = mmap(nullptr, alignedSize, PROT_NONE, MAP_ANON | MAP_PRIVATE | hugePagesFlag, -1, 0);
-    if (pRetVal != MAP_FAILED)
-    {
-        void * pAlignedRetVal = (void *)(((size_t)pRetVal + (alignment - 1)) & ~(alignment - 1));
-        size_t startPadding = (size_t)pAlignedRetVal - (size_t)pRetVal;
-        if (startPadding != 0)
-        {
-            int ret = munmap(pRetVal, startPadding);
-            assert(ret == 0);
-        }
-        size_t endPadding = alignedSize - (startPadding + size);
-        if (endPadding != 0)
-        {
-            int ret = munmap((void *)((size_t)pAlignedRetVal + size), endPadding);
-            assert(ret == 0);
-        }
-        pRetVal = pAlignedRetVal;
-#ifdef MADV_DONTDUMP
-        if (!committing)
-        {
-            madvise(pRetVal, size, MADV_DONTDUMP);
-        }
-#endif
-        return pRetVal;
-    }
-    return NULL; // return NULL if mmap failed
-}
-void* GCToOSInterface::VirtualReserve(size_t size, size_t alignment, uint32_t flags, uint16_t node)
-{
-    return VirtualReserveInner(size, alignment, flags, 0, /* committing */ false);
-}
-bool GCToOSInterface::VirtualRelease(void* address, size_t size)
-{
-    int ret = munmap(address, size);
-    return (ret == 0);
-}
-static bool VirtualCommitInner(void* address, size_t size, uint16_t node, bool newMemory)
-{
-    bool success = mprotect(address, size, PROT_WRITE | PROT_READ) == 0;
-#ifdef MADV_DODUMP
-    if (success && !newMemory)
-    {
-        madvise(address, size, MADV_DODUMP);
-    }
-#endif
-#ifdef TARGET_LINUX
-    if (success && g_numaAvailable && (node != NUMA_NODE_UNDEFINED))
-    {
-        if ((int)node <= g_highestNumaNode)
-        {
-            int usedNodeMaskBits = g_highestNumaNode + 1;
-            int nodeMaskLength = usedNodeMaskBits + sizeof(unsigned long) - 1;
-            unsigned long* nodeMask = (unsigned long*)alloca(nodeMaskLength);
-            memset(nodeMask, 0, nodeMaskLength);
-            int index = node / sizeof(unsigned long);
-            nodeMask[index] = ((unsigned long)1) << (node & (sizeof(unsigned long) - 1));
-            int st = BindMemoryPolicy(address, size, nodeMask, usedNodeMaskBits);
-            assert(st == 0);
-        }
-    }
-#endif // TARGET_LINUX
-    return success;
-}
-bool GCToOSInterface::VirtualCommit(void* address, size_t size, uint16_t node)
-{
-    return VirtualCommitInner(address, size, node, /* newMemory */ false);
-}
-void* GCToOSInterface::VirtualReserveAndCommitLargePages(size_t size, uint16_t node)
-{
-#if HAVE_MAP_HUGETLB
-    uint32_t largePagesFlag = MAP_HUGETLB;
-#elif HAVE_VM_FLAGS_SUPERPAGE_SIZE_ANY
-    uint32_t largePagesFlag = VM_FLAGS_SUPERPAGE_SIZE_ANY;
-#else
-    uint32_t largePagesFlag = 0;
-#endif
-    void* pRetVal = VirtualReserveInner(size, OS_PAGE_SIZE, 0, largePagesFlag, true);
-    if (VirtualCommitInner(pRetVal, size, node, /* newMemory */ true))
-    {
-        return pRetVal;
-    }
-    return nullptr;
-}
-bool GCToOSInterface::VirtualDecommit(void* address, size_t size)
-{
-    bool bRetVal = mmap(address, size, PROT_NONE, MAP_FIXED | MAP_ANON | MAP_PRIVATE, -1, 0) != MAP_FAILED;
-#ifdef MADV_DONTDUMP
-    if (bRetVal)
-    {
-        madvise(address, size, MADV_DONTDUMP);
-    }
-#endif
-    return  bRetVal;
-}
-bool GCToOSInterface::VirtualReset(void * address, size_t size, bool unlock)
-{
-    int st = EINVAL;
-#if defined(MADV_DONTDUMP) || defined(HAVE_MADV_FREE)
-    int madviseFlags = 0;
-#ifdef MADV_DONTDUMP
-    madviseFlags |= MADV_DONTDUMP;
-#endif
-#ifdef HAVE_MADV_FREE
-    madviseFlags |= MADV_FREE;
-#endif
-    st = madvise(address, size, madviseFlags);
-#endif //defined(MADV_DONTDUMP) || defined(HAVE_MADV_FREE)
-#if defined(HAVE_POSIX_MADVISE) && !defined(MADV_DONTDUMP)
-    st = posix_madvise(address, size, POSIX_MADV_DONTNEED);
-#endif //defined(HAVE_POSIX_MADVISE) && !defined(MADV_DONTDUMP)
-    return (st == 0);
-}
-bool GCToOSInterface::SupportsWriteWatch()
-{
-    return false;
-}
-void GCToOSInterface::ResetWriteWatch(void* address, size_t size)
-{
-    assert(!"should never call ResetWriteWatch on Unix");
-}
-bool GCToOSInterface::GetWriteWatch(bool resetState, void* address, size_t size, void** pageAddresses, uintptr_t* pageAddressesCount)
-{
-    assert(!"should never call GetWriteWatch on Unix");
-    return false;
-}
-bool ReadMemoryValueFromFile(const char* filename, uint64_t* val)
-{
-    bool result = false;
-    char* line = nullptr;
-    size_t lineLen = 0;
-    char* endptr = nullptr;
-    uint64_t num = 0, l, multiplier;
-    FILE* file = nullptr;
-    if (val == nullptr)
-        goto done;
-    file = fopen(filename, "r");
-    if (file == nullptr)
-        goto done;
-    if (getline(&line, &lineLen, file) == -1)
-        goto done;
-    errno = 0;
-    num = strtoull(line, &endptr, 0);
-    if (line == endptr || errno != 0)
-        goto done;
-    multiplier = 1;
-    switch (*endptr)
-    {
-    case 'g':
-    case 'G': multiplier = 1024;
-              FALLTHROUGH;
-    case 'm':
-    case 'M': multiplier = multiplier * 1024;
-              FALLTHROUGH;
-    case 'k':
-    case 'K': multiplier = multiplier * 1024;
-    }
-    *val = num * multiplier;
-    result = true;
-    if (*val / multiplier != num)
-        result = false;
-done:
-    if (file)
-        fclose(file);
-    free(line);
-    return result;
-}
-static void GetLogicalProcessorCacheSizeFromSysConf(size_t* cacheLevel, size_t* cacheSize)
-{
-    assert (cacheLevel != nullptr);
-    assert (cacheSize != nullptr);
-#if defined(_SC_LEVEL1_DCACHE_SIZE) || defined(_SC_LEVEL2_CACHE_SIZE) || defined(_SC_LEVEL3_CACHE_SIZE) || defined(_SC_LEVEL4_CACHE_SIZE)
-    const int cacheLevelNames[] =
-    {
-        _SC_LEVEL1_DCACHE_SIZE,
-        _SC_LEVEL2_CACHE_SIZE,
-        _SC_LEVEL3_CACHE_SIZE,
-        _SC_LEVEL4_CACHE_SIZE,
-    };
-    for (int i = ARRAY_SIZE(cacheLevelNames) - 1; i >= 0; i--)
-    {
-        long size = sysconf(cacheLevelNames[i]);
-        if (size > 0)
-        {
-            *cacheSize = (size_t)size;
-            *cacheLevel = i + 1;
-            break;
-        }
-    }
-#endif
-}
-static void GetLogicalProcessorCacheSizeFromSysFs(size_t* cacheLevel, size_t* cacheSize)
-{
-    assert (cacheLevel != nullptr);
-    assert (cacheSize != nullptr);
-#if defined(TARGET_LINUX) && !defined(HOST_ARM) && !defined(HOST_X86)
-    size_t level;
-    char path_to_size_file[] =  "/sys/devices/system/cpu/cpu0/cache/index-/size";
-    char path_to_level_file[] =  "/sys/devices/system/cpu/cpu0/cache/index-/level";
-    int index = 40;
-    assert(path_to_size_file[index] == '-');
-    assert(path_to_level_file[index] == '-');
-    for (int i = 0; i < 5; i++)
-    {
-        path_to_size_file[index] = (char)(48 + i);
-        uint64_t cache_size_from_sys_file = 0;
-        if (ReadMemoryValueFromFile(path_to_size_file, &cache_size_from_sys_file))
-        {
-            *cacheSize = std::max(*cacheSize, (size_t)cache_size_from_sys_file);
-            path_to_level_file[index] = (char)(48 + i);
-            if (ReadMemoryValueFromFile(path_to_level_file, &level))
-            {
-                *cacheLevel = level;
-            }
-        }
-    }
-#endif 
-}
-static void GetLogicalProcessorCacheSizeFromHeuristic(size_t* cacheLevel, size_t* cacheSize)
-{
-    assert (cacheLevel != nullptr);
-    assert (cacheSize != nullptr);
-#if (defined(TARGET_LINUX) && !defined(TARGET_APPLE))
-    {
-        DWORD logicalCPUs = g_processAffinitySet.Count();
-        if (logicalCPUs < 5)
-        {
-            *cacheSize = 4;
-        }
-        else if (logicalCPUs < 17)
-        {
-            *cacheSize = 8;
-        }
-        else if (logicalCPUs < 65)
-        {
-            *cacheSize = 16;
-        }
-        else
-        {
-            *cacheSize = 32;
-        }
-        *cacheSize *= (1024 * 1024);
-    }
-#endif
-}
-static size_t GetLogicalProcessorCacheSizeFromOS()
-{
-    size_t cacheLevel = 0;
-    size_t cacheSize = 0;
-    if (GCConfig::GetGCCacheSizeFromSysConf())
-    {
-        GetLogicalProcessorCacheSizeFromSysConf(&cacheLevel, &cacheSize);
-    }
-    if (cacheSize == 0) 
-    {
-        GetLogicalProcessorCacheSizeFromSysFs(&cacheLevel, &cacheSize);
-        if (cacheSize == 0)
-        {
-            GetLogicalProcessorCacheSizeFromHeuristic(&cacheLevel, &cacheSize);
-        }
-    }
-#if HAVE_SYSCTLBYNAME
-    if (cacheSize == 0)
-    {
-        int64_t cacheSizeFromSysctl = 0;
-        size_t sz = sizeof(cacheSizeFromSysctl);
-        const bool success = false
-            || sysctlbyname("hw.perflevel0.l3cachesize", &cacheSizeFromSysctl, &sz, nullptr, 0) == 0
-            || sysctlbyname("hw.perflevel0.l2cachesize", &cacheSizeFromSysctl, &sz, nullptr, 0) == 0
-            || sysctlbyname("hw.l3cachesize", &cacheSizeFromSysctl, &sz, nullptr, 0) == 0
-            || sysctlbyname("hw.l2cachesize", &cacheSizeFromSysctl, &sz, nullptr, 0) == 0
-            || sysctlbyname("hw.l1dcachesize", &cacheSizeFromSysctl, &sz, nullptr, 0) == 0;
-        if (success)
-        {
-            assert(cacheSizeFromSysctl > 0);
-            cacheSize = (size_t) cacheSizeFromSysctl;
-        }
-    }
-#endif
-#if (defined(HOST_ARM64) || defined(HOST_LOONGARCH64)) && !defined(TARGET_APPLE)
-    if (cacheLevel != 3)
-    {
-        GetLogicalProcessorCacheSizeFromHeuristic(&cacheLevel, &cacheSize);
-    }
-#endif
-    return cacheSize;
-}
-static uint64_t GetMemorySizeMultiplier(char units)
-{
-    switch(units)
-    {
-        case 'g':
-        case 'G': return 1024 * 1024 * 1024;
-        case 'm':
-        case 'M': return 1024 * 1024;
-        case 'k':
-        case 'K': return 1024;
-    }
-    return 1;
-}
-#ifndef __APPLE__
-static bool ReadMemAvailable(uint64_t* memAvailable)
-{
-    bool foundMemAvailable = false;
-    FILE* memInfoFile = fopen("/proc/meminfo", "r");
-    if (memInfoFile != NULL)
-    {
-        char *line = nullptr;
-        size_t lineLen = 0;
-        while (getline(&line, &lineLen, memInfoFile) != -1)
-        {
-            char units = '\0';
-            uint64_t available;
-            int fieldsParsed = sscanf(line, "MemAvailable: %" SCNu64 " %cB", &available, &units);
-            if (fieldsParsed >= 1)
-            {
-                uint64_t multiplier = GetMemorySizeMultiplier(units);
-                *memAvailable = available * multiplier;
-                foundMemAvailable = true;
-                break;
-            }
-        }
-        free(line);
-        fclose(memInfoFile);
-    }
-    return foundMemAvailable;
-}
-#endif // __APPLE__
-size_t GCToOSInterface::GetCacheSizePerLogicalCpu(bool trueSize)
-{
-    static volatile size_t s_maxSize;
-    static volatile size_t s_maxTrueSize;
-    size_t size = trueSize ? s_maxTrueSize : s_maxSize;
-    if (size != 0)
-        return size;
-    size_t maxSize, maxTrueSize;
-    maxSize = maxTrueSize = GetLogicalProcessorCacheSizeFromOS(); // Returns the size of the highest level processor cache
-    s_maxSize = maxSize;
-    s_maxTrueSize = maxTrueSize;
-    return trueSize ? maxTrueSize : maxSize;
-}
-bool GCToOSInterface::SetThreadAffinity(uint16_t procNo)
-{
-#if HAVE_SCHED_SETAFFINITY || HAVE_PTHREAD_SETAFFINITY_NP
-    cpu_set_t cpuSet;
-    CPU_ZERO(&cpuSet);
-    CPU_SET((int)procNo, &cpuSet);
-#if HAVE_SCHED_SETAFFINITY
-    int st = sched_setaffinity(0, sizeof(cpu_set_t), &cpuSet);
-#else
-    int st = pthread_setaffinity_np(pthread_self(), sizeof(cpu_set_t), &cpuSet);
-#endif
-    return (st == 0);
-#else  // !(HAVE_SCHED_SETAFFINITY || HAVE_PTHREAD_SETAFFINITY_NP)
-    return false;
-#endif // HAVE_SCHED_SETAFFINITY || HAVE_PTHREAD_SETAFFINITY_NP
-}
-bool GCToOSInterface::BoostThreadPriority()
-{
-    return false;
-}
-const AffinitySet* GCToOSInterface::SetGCThreadsAffinitySet(uintptr_t configAffinityMask, const AffinitySet* configAffinitySet)
-{
-    if (!configAffinitySet->IsEmpty())
-    {
-        for (size_t i = 0; i < MAX_SUPPORTED_CPUS; i++)
-        {
-            if (g_processAffinitySet.Contains(i) && !configAffinitySet->Contains(i))
-            {
-                g_processAffinitySet.Remove(i);
-            }
-        }
-    }
-    return &g_processAffinitySet;
-}
-#if HAVE_PROCFS_STATM
-static size_t GetCurrentVirtualMemorySize()
-{
-    size_t result = (size_t)-1;
-    size_t linelen;
-    char* line = nullptr;
-    FILE* file = fopen("/proc/self/statm", "r");
-    if (file != nullptr && getline(&line, &linelen, file) != -1)
-    {
-        char* context = nullptr;
-        char* strTok = strtok_r(line, " ", &context);
-        errno = 0;
-        result = strtoull(strTok, nullptr, 0);
-        if (errno == 0)
-        {
-            long pageSize = sysconf(_SC_PAGE_SIZE);
-            if (pageSize != -1)
-            {
-                result = result * pageSize;
-            }
-        }
-        else
-        {
-            assert(!"Failed to parse statm file contents.");
-            result = (size_t)-1;
-        }
-    }
-    if (file)
-        fclose(file);
-    free(line);
-    return result;
-}
-#endif // HAVE_PROCFS_STATM
-size_t GCToOSInterface::GetVirtualMemoryLimit()
-{
-    rlimit addressSpaceLimit;
-    if ((getrlimit(RLIMIT_AS, &addressSpaceLimit) == 0) && (addressSpaceLimit.rlim_cur != RLIM_INFINITY))
-    {
-        return addressSpaceLimit.rlim_cur;
-    }
-    return GetVirtualMemoryMaxAddress();
-}
-size_t GCToOSInterface::GetVirtualMemoryMaxAddress()
-{
-#ifdef HOST_64BIT
-#ifndef TARGET_RISCV64
-    static const uint64_t _128TB = (1ull << 47);
-    return _128TB;
-#else // TARGET_RISCV64
-    static const uint64_t _256GB = (1ull << 38);
-    return _256GB;
-#endif // TARGET_RISCV64
-#else
-    return (size_t)-1;
-#endif
-}
-uint64_t GCToOSInterface::GetPhysicalMemoryLimit(bool* is_restricted)
-{
-    size_t restricted_limit;
-    if (is_restricted)
-        *is_restricted = false;
-    restricted_limit = GetRestrictedPhysicalMemoryLimit();
-    VolatileStore(&g_RestrictedPhysicalMemoryLimit, restricted_limit);
-    if (restricted_limit != 0 && restricted_limit != SIZE_T_MAX)
-    {
-        if (is_restricted)
-            *is_restricted = true;
-        return restricted_limit;
-    }
-    return g_totalPhysicalMemSize;
-}
-uint64_t GetAvailablePhysicalMemory()
-{
-    uint64_t available = 0;
-#if defined(__APPLE__)
-    uint32_t mem_free = 0;
-    size_t mem_free_length = sizeof(uint32_t);
-    assert(g_kern_memorystatus_level_mib != NULL);
-    int rc = sysctl(g_kern_memorystatus_level_mib, g_kern_memorystatus_level_mib_length, &mem_free, &mem_free_length, NULL, 0);
-    assert(rc == 0);
-    if (rc == 0)
-    {
-        available = (int64_t)mem_free * g_totalPhysicalMemSize / 100;
-    }
-#elif defined(__FreeBSD__)
-    size_t inactive_count = 0, laundry_count = 0, free_count = 0;
-    size_t sz = sizeof(inactive_count);
-    sysctlbyname("vm.stats.vm.v_inactive_count", &inactive_count, &sz, NULL, 0);
-    sz = sizeof(laundry_count);
-    sysctlbyname("vm.stats.vm.v_laundry_count", &laundry_count, &sz, NULL, 0);
-    sz = sizeof(free_count);
-    sysctlbyname("vm.stats.vm.v_free_count", &free_count, &sz, NULL, 0);
-    available = (inactive_count + laundry_count + free_count) * sysconf(_SC_PAGESIZE);
-#else // Linux
-    static volatile bool tryReadMemInfo = true;
-    if (tryReadMemInfo)
-    {
-        tryReadMemInfo = ReadMemAvailable(&available);
-    }
-    if (!tryReadMemInfo)
-    {
-        available = sysconf(SYSCONF_PAGES) * sysconf(_SC_PAGE_SIZE);
-    }
-#endif
-    return available;
-}
-uint64_t GetAvailablePageFile()
-{
-    uint64_t available = 0;
-    int mib[3];
-    int rc;
-#if HAVE_XSW_USAGE
-    struct xsw_usage xsu;
-    mib[0] = CTL_VM;
-    mib[1] = VM_SWAPUSAGE;
-    size_t length = sizeof(xsu);
-    rc = sysctl(mib, 2, &xsu, &length, NULL, 0);
-    if (rc == 0)
-    {
-        available = xsu.xsu_avail;
-    }
-#elif HAVE_XSWDEV
-    struct xswdev xsw;
-    size_t length = 2;
-    rc = sysctlnametomib("vm.swap_info", mib, &length);
-    if (rc == 0)
-    {
-        int pagesize = getpagesize();
-        for (mib[2] = 0; ; mib[2]++)
-        {
-            length = sizeof(xsw);
-            rc = sysctl(mib, 3, &xsw, &length, NULL, 0);
-            if ((rc < 0) || (xsw.xsw_version != XSWDEV_VERSION))
-            {
-                break;
-            }
-            uint64_t avail = xsw.xsw_nblks - xsw.xsw_used;
-            available += avail * pagesize;
-        }
-    }
-#elif HAVE_SWAPCTL
-    struct anoninfo ai;
-    if (swapctl(SC_AINFO, &ai) != -1)
-    {
-        int pagesize = getpagesize();
-        available = ai.ani_free * pagesize;
-    }
-#elif HAVE_SYSINFO
-    struct sysinfo info;
-    rc = sysinfo(&info);
-    if (rc == 0)
-    {
-        available = info.freeswap;
-#if HAVE_SYSINFO_WITH_MEM_UNIT
-        available *= info.mem_unit;
-#endif // HAVE_SYSINFO_WITH_MEM_UNIT
-    }
-#endif // HAVE_SYSINFO
-    return available;
-}
-void GCToOSInterface::GetMemoryStatus(uint64_t restricted_limit, uint32_t* memory_load, uint64_t* available_physical, uint64_t* available_page_file)
-{
-    uint64_t available = 0;
-    uint32_t load = 0;
-    size_t used;
-    if (restricted_limit != 0)
-    {
-        if (GetPhysicalMemoryUsed(&used))
-        {
-            available = restricted_limit > used ? restricted_limit - used : 0;
-            load = (uint32_t)(((float)used * 100) / (float)restricted_limit);
-        }
-    }
-    else
-    {
-        available = GetAvailablePhysicalMemory();
-        if (memory_load != NULL)
-        {
-            uint64_t total;
-            if (restricted_limit != 0 && restricted_limit != SIZE_T_MAX)
-            {
-                total = restricted_limit;
-            }
-            else
-            {
-                total = g_totalPhysicalMemSize;
-            }
-            if (total > available)
-            {
-                used = total - available;
-                load = (uint32_t)(((float)used * 100) / (float)total);
-            }
-#if HAVE_PROCFS_STATM
-            rlimit addressSpaceLimit;
-            if ((getrlimit(RLIMIT_AS, &addressSpaceLimit) == 0) && (addressSpaceLimit.rlim_cur != RLIM_INFINITY))
-            {
-                size_t used_virtual = GetCurrentVirtualMemorySize();
-                if (used_virtual != (size_t)-1)
-                {
-                    uint32_t load_virtual = (uint32_t)(((float)used_virtual * 100) / (float)addressSpaceLimit.rlim_cur);
-                    if (load_virtual > load)
-                    {
-                        load = load_virtual;
-                    }
-                }
-            }
-#endif // HAVE_PROCFS_STATM
-        }
-    }
-    if (available_physical != NULL)
-        *available_physical = available;
-    if (memory_load != nullptr)
-        *memory_load = load;
-    if (available_page_file != nullptr)
-        *available_page_file = GetAvailablePageFile();
-}
-int64_t GCToOSInterface::QueryPerformanceCounter()
-{
-#if HAVE_CLOCK_GETTIME_NSEC_NP
-    return (int64_t)clock_gettime_nsec_np(CLOCK_UPTIME_RAW);
-#elif HAVE_CLOCK_MONOTONIC
-    struct timespec ts;
-    int result = clock_gettime(CLOCK_MONOTONIC, &ts);
-    if (result != 0)
-    {
-        assert(!"clock_gettime(CLOCK_MONOTONIC) failed");
-        __UNREACHABLE();
-    }
-    return ((int64_t)(ts.tv_sec) * (int64_t)(tccSecondsToNanoSeconds)) + (int64_t)(ts.tv_nsec);
-#else
-#error " clock_gettime(CLOCK_MONOTONIC) or clock_gettime_nsec_np() must be supported."
-#endif
-}
-int64_t GCToOSInterface::QueryPerformanceFrequency()
-{
-    return tccSecondsToNanoSeconds;
-}
-uint64_t GCToOSInterface::GetLowPrecisionTimeStamp()
-{
-    uint64_t retval = 0;
-#if HAVE_CLOCK_GETTIME_NSEC_NP
-    retval = clock_gettime_nsec_np(CLOCK_UPTIME_RAW) / tccMilliSecondsToNanoSeconds;
-#elif HAVE_CLOCK_MONOTONIC
-    struct timespec ts;
-#if HAVE_CLOCK_MONOTONIC_COARSE
-    clockid_t clockType = CLOCK_MONOTONIC_COARSE; // good enough resolution, fastest speed
-#else
-    clockid_t clockType = CLOCK_MONOTONIC;
-#endif
-    if (clock_gettime(clockType, &ts) != 0)
-    {
-#if HAVE_CLOCK_MONOTONIC_COARSE
-        assert(!"clock_gettime(HAVE_CLOCK_MONOTONIC_COARSE) failed\n");
-#else
-        assert(!"clock_gettime(CLOCK_MONOTONIC) failed\n");
-#endif
-    }
-    retval = (ts.tv_sec * tccSecondsToMilliSeconds) + (ts.tv_nsec / tccMilliSecondsToNanoSeconds);
-#else
-    struct timeval tv;
-    if (gettimeofday(&tv, NULL) == 0)
-    {
-        retval = (tv.tv_sec * tccSecondsToMilliSeconds) + (tv.tv_usec / tccMilliSecondsToMicroSeconds);
-    }
-    else
-    {
-        assert(!"gettimeofday() failed\n");
-    }
-#endif
-    return retval;
-}
-uint32_t GCToOSInterface::GetTotalProcessorCount()
-{
-    return g_totalCpuCount;
-}
-bool GCToOSInterface::CanEnableGCNumaAware()
-{
-    return g_numaAvailable;
-}
-bool GCToOSInterface::CanEnableGCCPUGroups()
-{
-    return false;
-}
-bool GCToOSInterface::GetProcessorForHeap(uint16_t heap_number, uint16_t* proc_no, uint16_t* node_no)
-{
-    bool success = false;
-    uint16_t availableProcNumber = 0;
-    for (size_t procNumber = 0; procNumber < MAX_SUPPORTED_CPUS; procNumber++)
-    {
-        if (g_processAffinitySet.Contains(procNumber))
-        {
-            if (availableProcNumber == heap_number)
-            {
-                *proc_no = procNumber;
-#ifdef TARGET_LINUX
-                if (GCToOSInterface::CanEnableGCNumaAware())
-                {
-                    int result = GetNumaNodeNumByCpu(procNumber);
-                    *node_no = (result >= 0) ? (uint16_t)result : NUMA_NODE_UNDEFINED;
-                }
-                else
-#endif // TARGET_LINUX
-                {
-                    *node_no = NUMA_NODE_UNDEFINED;
-                }
-                success = true;
-                break;
-            }
-            availableProcNumber++;
-        }
-    }
-    return success;
-}
-bool GCToOSInterface::ParseGCHeapAffinitizeRangesEntry(const char** config_string, size_t* start_index, size_t* end_index)
-{
-    return ParseIndexOrRange(config_string, start_index, end_index);
-}
-bool CLRCriticalSection::Initialize()
-{
-    pthread_mutexattr_t mutexAttributes;
-    int st = pthread_mutexattr_init(&mutexAttributes);
-    if (st != 0)
-    {
-        return false;
-    }
-    st = pthread_mutexattr_settype(&mutexAttributes, PTHREAD_MUTEX_RECURSIVE);
-    if (st == 0)
-    {
-        st = pthread_mutex_init(&m_cs.mutex, &mutexAttributes);
-    }
-    pthread_mutexattr_destroy(&mutexAttributes);
-    return (st == 0);
-}
-void CLRCriticalSection::Destroy()
-{
-    int st = pthread_mutex_destroy(&m_cs.mutex);
-    assert(st == 0);
-}
-void CLRCriticalSection::Enter()
-{
-    pthread_mutex_lock(&m_cs.mutex);
-}
-void CLRCriticalSection::Leave()
-{
-    pthread_mutex_unlock(&m_cs.mutex);
-}

--- a/src/coreclr/vm/prestub.cpp
+++ b//dev/null
@@ -1,3022 +0,0 @@
-#include "common.h"
-#include "vars.hpp"
-#include "eeconfig.h"
-#include "dllimport.h"
-#include "comdelegate.h"
-#include "dbginterface.h"
-#include "stubgen.h"
-#include "eventtrace.h"
-#include "array.h"
-#include "ecall.h"
-#include "virtualcallstub.h"
-#ifdef FEATURE_INTERPRETER
-#include "interpreter.h"
-#endif
-#ifdef FEATURE_COMINTEROP
-#include "clrtocomcall.h"
-#endif
-#ifdef FEATURE_PERFMAP
-#include "perfmap.h"
-#endif
-#include "methoddescbackpatchinfo.h"
-#if defined(FEATURE_GDBJIT)
-#include "gdbjit.h"
-#endif // FEATURE_GDBJIT
-#ifndef DACCESS_COMPILE
-#include "customattribute.h"
-#if defined(FEATURE_JIT_PITCHING)
-EXTERN_C void CheckStacksAndPitch();
-EXTERN_C void SavePitchingCandidate(MethodDesc* pMD, ULONG sizeOfCode);
-EXTERN_C void DeleteFromPitchingCandidate(MethodDesc* pMD);
-EXTERN_C void MarkMethodNotPitchingCandidate(MethodDesc* pMD);
-#endif
-EXTERN_C void STDCALL ThePreStubPatch();
-#if defined(HAVE_GCCOVER)
-CrstStatic MethodDesc::m_GCCoverCrst;
-void MethodDesc::Init()
-{
-    m_GCCoverCrst.Init(CrstGCCover);
-}
-#endif
-#define LOG_USING_R2R_CODE(method)  LOG((LF_ZAP, LL_INFO10000,                                                            \
-                                        "ZAP: Using R2R precompiled code" FMT_ADDR " for %s.%s sig=\"%s\" (token %x).\n", \
-                                        DBG_ADDR(pCode),                                                                  \
-                                        m_pszDebugClassName,                                                              \
-                                        m_pszDebugMethodName,                                                             \
-                                        m_pszDebugMethodSignature,                                                        \
-                                        GetMemberDef()));
-PCODE MethodDesc::DoBackpatch(MethodTable * pMT, MethodTable *pDispatchingMT, BOOL fFullBackPatch)
-{
-    CONTRACTL
-    {
-        STANDARD_VM_CHECK;
-        PRECONDITION(!ContainsGenericVariables());
-        PRECONDITION(pMT == GetMethodTable());
-    }
-    CONTRACTL_END;
-    bool isVersionableWithVtableSlotBackpatch = IsVersionableWithVtableSlotBackpatch();
-    LoaderAllocator *mdLoaderAllocator = isVersionableWithVtableSlotBackpatch ? GetLoaderAllocator() : nullptr;
-    MethodDescBackpatchInfoTracker::ConditionalLockHolder slotBackpatchLockHolder(isVersionableWithVtableSlotBackpatch);
-    PCODE pTarget = GetMethodEntryPoint();
-    PCODE pExpected;
-    if (isVersionableWithVtableSlotBackpatch)
-    {
-        _ASSERTE(pTarget == GetEntryPointToBackpatch_Locked());
-        pExpected = GetTemporaryEntryPoint();
-        if (pExpected == pTarget)
-            return pTarget;
-        _ASSERTE(!(pMT->IsInterface() && !IsStatic()));
-        _ASSERTE(!HasNonVtableSlot());
-    }
-    else
-    {
-        _ASSERTE(pTarget == GetStableEntryPoint());
-        pExpected = GetTemporaryEntryPoint();
-        if (pExpected == pTarget)
-            return pTarget;
-        if (pMT->IsInterface() && !IsStatic())
-            return pTarget;
-        if (fFullBackPatch)
-        {
-            FuncPtrStubs * pFuncPtrStubs = GetLoaderAllocator()->GetFuncPtrStubsNoCreate();
-            if (pFuncPtrStubs != NULL)
-            {
-                Precode* pFuncPtrPrecode = pFuncPtrStubs->Lookup(this);
-                if (pFuncPtrPrecode != NULL)
-                {
-                    if (pFuncPtrPrecode->SetTargetInterlocked(pTarget))
-                        return pTarget;
-                }
-            }
-            Precode::GetPrecodeFromEntryPoint(pExpected)->SetTargetInterlocked(pTarget);
-        }
-        if (HasNonVtableSlot())
-            return pTarget;
-    }
-    auto RecordAndBackpatchSlot = [&](MethodTable *patchedMT, DWORD slotIndex)
-    {
-        WRAPPER_NO_CONTRACT;
-        _ASSERTE(isVersionableWithVtableSlotBackpatch);
-        RecordAndBackpatchEntryPointSlot_Locked(
-            mdLoaderAllocator,
-            patchedMT->GetLoaderAllocator(),
-            dac_cast<TADDR>(patchedMT->GetSlotPtr(slotIndex)),
-            EntryPointSlots::SlotType_Vtable,
-            pTarget);
-    };
-    BOOL fBackpatched = FALSE;
-#define BACKPATCH(pPatchedMT)                                   \
-    do                                                          \
-    {                                                           \
-        if (pPatchedMT->GetSlot(dwSlot) == pExpected)           \
-        {                                                       \
-            if (isVersionableWithVtableSlotBackpatch)           \
-            {                                                   \
-                RecordAndBackpatchSlot(pPatchedMT, dwSlot);     \
-            }                                                   \
-            else                                                \
-            {                                                   \
-                pPatchedMT->SetSlot(dwSlot, pTarget);           \
-            }                                                   \
-            fBackpatched = TRUE;                                \
-        }                                                       \
-    }                                                           \
-    while(0)
-    _ASSERTE(pMT->GetSlot(GetSlot()) == pTarget);
-    if (pDispatchingMT != NULL && pDispatchingMT != pMT)
-    {
-        DWORD dwSlot = GetSlot();
-        BACKPATCH(pDispatchingMT);
-        if (fFullBackPatch)
-        {
-            MethodTable * pRestoredSlotMT = pDispatchingMT->GetRestoredSlotMT(dwSlot);
-            if (pRestoredSlotMT != pDispatchingMT)
-            {
-                BACKPATCH(pRestoredSlotMT);
-            }
-        }
-    }
-    if (IsMethodImpl())
-    {
-        MethodImpl::Iterator it(this);
-        while (it.IsValid())
-        {
-            DWORD dwSlot = it.GetSlot();
-            BACKPATCH(pMT);
-            if (pDispatchingMT != NULL && pDispatchingMT != pMT)
-            {
-                BACKPATCH(pDispatchingMT);
-            }
-            it.Next();
-        }
-    }
-    if (fFullBackPatch && !fBackpatched && IsDuplicate())
-    {
-        unsigned numSlots = pMT->GetNumVirtuals();
-        for (DWORD dwSlot=0; dwSlot<numSlots; dwSlot++)
-        {
-            BACKPATCH(pMT);
-            if (pDispatchingMT != NULL && pDispatchingMT != pMT)
-            {
-                BACKPATCH(pDispatchingMT);
-            }
-        }
-    }
-#undef BACKPATCH
-    return pTarget;
-}
-#ifdef _MSC_VER
-#pragma optimize("", off)
-#endif
-void DACNotifyCompilationFinished(MethodDesc *methodDesc, PCODE pCode)
-{
-    CONTRACTL
-    {
-        NOTHROW;
-        GC_NOTRIGGER;
-        MODE_PREEMPTIVE;
-    }
-    CONTRACTL_END;
-    JITNotifications jn(g_pNotificationTable);
-    if (jn.IsActive())
-    {
-        mdToken t = methodDesc->GetMemberDef();
-        Module *modulePtr = methodDesc->GetModule();
-        _ASSERTE(modulePtr);
-        USHORT jnt = jn.Requested((TADDR) modulePtr, t);
-        if (jnt & CLRDATA_METHNOTIFY_GENERATED)
-        {
-            DACNotify::DoJITNotification(methodDesc, (TADDR)pCode);
-        }
-    }
-}
-#ifdef _MSC_VER
-#pragma optimize("", on)
-#endif
-PCODE MethodDesc::PrepareInitialCode(CallerGCMode callerGCMode)
-{
-    STANDARD_VM_CONTRACT;
-    PrepareCodeConfig config(NativeCodeVersion(this), TRUE, TRUE);
-    config.SetCallerGCMode(callerGCMode);
-    return PrepareCode(&config);
-}
-PCODE MethodDesc::PrepareCode(PrepareCodeConfig* pConfig)
-{
-    STANDARD_VM_CONTRACT;
-    _ASSERTE(IsIL() || IsNoMetadata());
-    PCODE pCode = PrepareILBasedCode(pConfig);
-#if defined(FEATURE_GDBJIT) && defined(TARGET_UNIX)
-    NotifyGdb::MethodPrepared(this);
-#endif
-    return pCode;
-}
-bool MayUsePrecompiledILStub()
-{
-    if (g_pConfig->InteropValidatePinnedObjects())
-        return false;
-    if (CORProfilerTrackTransitions())
-        return false;
-    if (g_pConfig->InteropLogArguments())
-        return false;
-    return true;
-}
-PCODE MethodDesc::PrepareILBasedCode(PrepareCodeConfig* pConfig)
-{
-    STANDARD_VM_CONTRACT;
-    PCODE pCode = (PCODE)NULL;
-    bool shouldTier = false;
-#if defined(FEATURE_TIERED_COMPILATION)
-    shouldTier = pConfig->GetMethodDesc()->IsEligibleForTieredCompilation();
-    if (shouldTier
-        && (pConfig->GetCallerGCMode() == CallerGCMode::Preemptive
-            || (pConfig->GetCallerGCMode() == CallerGCMode::Unknown
-                && HasUnmanagedCallersOnlyAttribute())))
-    {
-        NativeCodeVersion codeVersion = pConfig->GetCodeVersion();
-        if (codeVersion.IsDefaultVersion())
-        {
-            pConfig->GetMethodDesc()->GetLoaderAllocator()->GetCallCountingManager()->DisableCallCounting(codeVersion);
-            _ASSERTE(codeVersion.IsFinalTier());
-        }
-        else if (!codeVersion.IsFinalTier())
-        {
-            codeVersion.SetOptimizationTier(NativeCodeVersion::OptimizationTierOptimized);
-        }
-        pConfig->SetWasTieringDisabledBeforeJitting();
-        shouldTier = false;
-    }
-#endif // FEATURE_TIERED_COMPILATION
-    NativeCodeVersion nativeCodeVersion = pConfig->GetCodeVersion();
-    if (shouldTier && !nativeCodeVersion.IsDefaultVersion())
-    {
-        CodeVersionManager::LockHolder codeVersioningLockHolder;
-        if (pConfig->GetCodeVersion().GetILCodeVersion().IsDeoptimized())
-        {
-            shouldTier = false;
-        }
-    }
-    if (pConfig->MayUsePrecompiledCode())
-    {
-#ifdef FEATURE_READYTORUN
-        if (IsDynamicMethod() && GetLoaderModule()->IsSystem() && MayUsePrecompiledILStub())
-        {
-            if (GetModule()->IsReadyToRun() && !GetModule()->GetReadyToRunInfo()->HasNonShareablePInvokeStubs())
-            {
-                DynamicMethodDesc* stubMethodDesc = this->AsDynamicMethodDesc();
-                if (stubMethodDesc->IsILStub() && stubMethodDesc->IsPInvokeStub())
-                {
-                    MethodDesc* pTargetMD = stubMethodDesc->GetILStubResolver()->GetStubTargetMethodDesc();
-                    if (pTargetMD != NULL)
-                    {
-                        pCode = pTargetMD->GetPrecompiledR2RCode(pConfig);
-                        if (pCode != (PCODE)NULL)
-                        {
-                            LOG_USING_R2R_CODE(this);
-                            pConfig->SetNativeCode(pCode, &pCode);
-                        }
-                    }
-                }
-            }
-        }
-#endif // FEATURE_READYTORUN
-        if (pCode == (PCODE)NULL)
-        {
-            pCode = GetPrecompiledCode(pConfig, shouldTier);
-        }
-#ifdef FEATURE_PERFMAP
-        if (pCode != (PCODE)NULL)
-            PerfMap::LogPreCompiledMethod(this, pCode);
-#endif
-    }
-    if (pConfig->IsForMulticoreJit() && pCode == (PCODE)NULL && pConfig->ReadyToRunRejectedPrecompiledCode())
-    {
-        return (PCODE)NULL;
-    }
-    if (pCode == (PCODE)NULL)
-    {
-        LOG((LF_CLASSLOADER, LL_INFO1000000,
-            "    In PrepareILBasedCode, calling JitCompileCode\n"));
-        pCode = JitCompileCode(pConfig);
-    }
-    else
-    {
-        DACNotifyCompilationFinished(this, pCode);
-    }
-    return pCode;
-}
-PCODE MethodDesc::GetPrecompiledCode(PrepareCodeConfig* pConfig, bool shouldTier)
-{
-    STANDARD_VM_CONTRACT;
-    PCODE pCode = (PCODE)NULL;
-#ifdef FEATURE_READYTORUN
-    pCode = GetPrecompiledR2RCode(pConfig);
-    if (pCode != (PCODE)NULL)
-    {
-        LOG_USING_R2R_CODE(this);
-#ifdef FEATURE_TIERED_COMPILATION
-        bool shouldCountCalls = shouldTier && pConfig->FinalizeOptimizationTierForTier0Load();
-#endif
-        if (pConfig->SetNativeCode(pCode, &pCode))
-        {
-#ifdef FEATURE_CODE_VERSIONING
-            pConfig->SetGeneratedOrLoadedNewCode();
-#endif
-#ifdef FEATURE_TIERED_COMPILATION
-            if (shouldCountCalls)
-            {
-                _ASSERTE(!pConfig->GetCodeVersion().IsFinalTier());
-                pConfig->SetShouldCountCalls();
-            }
-#endif
-#ifdef FEATURE_MULTICOREJIT
-            if (pConfig->NeedsMulticoreJitNotification())
-            {
-                _ASSERTE(pConfig->GetCodeVersion().IsDefaultVersion());
-                _ASSERTE(!pConfig->IsForMulticoreJit());
-                MulticoreJitManager & mcJitManager = GetAppDomain()->GetMulticoreJitManager();
-                if (mcJitManager.IsRecorderActive())
-                {
-                    if (MulticoreJitManager::IsMethodSupported(this))
-                    {
-                        mcJitManager.RecordMethodJitOrLoad(this);
-                    }
-                }
-            }
-#endif
-        }
-    }
-#endif // FEATURE_READYTORUN
-    return pCode;
-}
-PCODE MethodDesc::GetPrecompiledR2RCode(PrepareCodeConfig* pConfig)
-{
-    STANDARD_VM_CONTRACT;
-    PCODE pCode = (PCODE)NULL;
-#ifdef FEATURE_READYTORUN
-    ReadyToRunInfo* pAlreadyExaminedInfos[2] = {NULL, NULL};
-    Module * pModule = GetModule();
-    if (pModule->IsReadyToRun())
-    {
-        pAlreadyExaminedInfos[0] = pModule->GetReadyToRunInfo();
-        pCode = pAlreadyExaminedInfos[0]->GetEntryPoint(this, pConfig, TRUE /* fFixups */);
-    }
-    if (pCode == (PCODE)NULL && HasClassOrMethodInstantiation())
-    {
-        pAlreadyExaminedInfos[1] = ReadyToRunInfo::ComputeAlternateGenericLocationForR2RCode(this);
-        if (pAlreadyExaminedInfos[1] != NULL &&  pAlreadyExaminedInfos[1] != pAlreadyExaminedInfos[0])
-        {
-            pCode = pAlreadyExaminedInfos[1]->GetEntryPoint(this, pConfig, TRUE /* fFixups */);
-        }
-        if (pCode == (PCODE)NULL)
-        {
-            ReadyToRunInfo* pUnrelatedInfo = ReadyToRunInfo::GetUnrelatedR2RModules();
-            for (;pUnrelatedInfo != NULL && pCode == (PCODE)NULL; pUnrelatedInfo = pUnrelatedInfo->GetNextUnrelatedR2RModule())
-            {
-                if (pUnrelatedInfo == pAlreadyExaminedInfos[0]) continue;
-                if (pUnrelatedInfo == pAlreadyExaminedInfos[1]) continue;
-                pCode = pUnrelatedInfo->GetEntryPoint(this, pConfig, TRUE /* fFixups */);
-            }
-        }
-    }
-#endif
-    return pCode;
-}
-PCODE MethodDesc::GetMulticoreJitCode(PrepareCodeConfig* pConfig, bool* pWasTier0)
-{
-    STANDARD_VM_CONTRACT;
-    _ASSERTE(pConfig != NULL);
-    _ASSERTE(pConfig->GetMethodDesc() == this);
-    _ASSERTE(pWasTier0 != NULL);
-    _ASSERTE(!*pWasTier0);
-    MulticoreJitCodeInfo codeInfo;
-#ifdef FEATURE_MULTICOREJIT
-    MulticoreJitManager & mcJitManager = GetAppDomain()->GetMulticoreJitManager();
-    if (mcJitManager.GetMulticoreJitCodeStorage().GetRemainingMethodCount() > 0)
-    {
-        if (MulticoreJitManager::IsMethodSupported(this))
-        {
-            codeInfo = mcJitManager.RequestMethodCode(this); // Query multi-core JIT manager for compiled code
-        #ifdef FEATURE_TIERED_COMPILATION
-            if (!codeInfo.IsNull())
-            {
-                if (codeInfo.WasTier0())
-                {
-                    *pWasTier0 = true;
-                }
-                if (codeInfo.JitSwitchedToOptimized())
-                {
-                    pConfig->SetJitSwitchedToOptimized();
-                }
-            }
-        #endif
-        }
-    }
-#endif // FEATURE_MULTICOREJIT
-    return codeInfo.GetEntryPoint();
-}
-PCODE MethodDesc::JitCompileCode(PrepareCodeConfig* pConfig)
-{
-    STANDARD_VM_CONTRACT;
-    LOG((LF_JIT, LL_INFO1000000,
-        "JitCompileCode(%p, ILStub: %s) for %s::%s\n",
-        this,
-        IsILStub() ? "true" : "false",
-        GetMethodTable()->GetDebugClassName(),
-        m_pszDebugMethodName));
-#if defined(FEATURE_JIT_PITCHING)
-    CheckStacksAndPitch();
-#endif
-    PCODE pCode = (PCODE)NULL;
-    {
-        JitListLock::LockHolder pJitLock(AppDomain::GetCurrentDomain()->GetJitLock());
-        if ((pCode = pConfig->IsJitCancellationRequested()))
-        {
-            return pCode;
-        }
-        NativeCodeVersion version = pConfig->GetCodeVersion();
-        const char *description = "jit lock";
-        INDEBUG(description = m_pszDebugMethodName;)
-        ReleaseHolder<JitListLockEntry> pEntry(JitListLockEntry::Find(
-            pJitLock, version, description));
-        pJitLock.Release();
-        {
-            JitListLockEntry::LockHolder pEntryLock(pEntry, FALSE);
-            if (pEntryLock.DeadlockAwareAcquire())
-            {
-                if (pEntry->m_hrResultCode == S_FALSE)
-                {
-                }
-                else
-                {
-                }
-            }
-            else
-            {
-            }
-            if ((pCode = pConfig->IsJitCancellationRequested()))
-            {
-                return pCode;
-            }
-            NativeCodeVersion codeVersion = pConfig->GetCodeVersion();
-            if (codeVersion.IsDefaultVersion())
-            {
-                bool wasTier0 = false;
-                pCode = GetMulticoreJitCode(pConfig, &wasTier0);
-                if (pCode != (PCODE)NULL)
-                {
-                #ifdef FEATURE_TIERED_COMPILATION
-                    bool shouldCountCalls = wasTier0 && pConfig->FinalizeOptimizationTierForTier0LoadOrJit();
-                #endif
-                    if (pConfig->SetNativeCode(pCode, &pCode))
-                    {
-                    #ifdef FEATURE_CODE_VERSIONING
-                        pConfig->SetGeneratedOrLoadedNewCode();
-                    #endif
-                    #ifdef FEATURE_TIERED_COMPILATION
-                        if (shouldCountCalls)
-                        {
-                            pConfig->SetShouldCountCalls();
-                        }
-                    #endif
-                    }
-                    pEntry->m_hrResultCode = S_OK;
-                    return pCode;
-                }
-            }
-            return JitCompileCodeLockedEventWrapper(pConfig, pEntryLock);
-        }
-    }
-}
-namespace
-{
-    COR_ILMETHOD_DECODER* GetAndVerifyMetadataILHeader(MethodDesc* pMD, PrepareCodeConfig* pConfig, COR_ILMETHOD_DECODER* pDecoderMemory)
-    {
-        STANDARD_VM_CONTRACT;
-        _ASSERTE(pMD != NULL);
-        _ASSERTE(!pMD->IsNoMetadata());
-        _ASSERTE(pConfig != NULL);
-        _ASSERTE(pDecoderMemory != NULL);
-        COR_ILMETHOD_DECODER* pHeader = NULL;
-        COR_ILMETHOD* ilHeader = pConfig->GetILHeader();
-        if (ilHeader == NULL)
-            return NULL;
-        COR_ILMETHOD_DECODER::DecoderStatus status = COR_ILMETHOD_DECODER::FORMAT_ERROR;
-        {
-            AVInRuntimeImplOkayHolder AVOkay;
-            pHeader = new (pDecoderMemory) COR_ILMETHOD_DECODER(ilHeader, pMD->GetMDImport(), &status);
-        }
-        if (status == COR_ILMETHOD_DECODER::FORMAT_ERROR)
-            COMPlusThrowHR(COR_E_BADIMAGEFORMAT, BFA_BAD_IL);
-        return pHeader;
-    }
-    COR_ILMETHOD_DECODER* GetAndVerifyILHeader(MethodDesc* pMD, PrepareCodeConfig* pConfig, COR_ILMETHOD_DECODER* pIlDecoderMemory)
-    {
-        STANDARD_VM_CONTRACT;
-        _ASSERTE(pMD != NULL);
-        if (pMD->IsIL())
-        {
-            return GetAndVerifyMetadataILHeader(pMD, pConfig, pIlDecoderMemory);
-        }
-        else if (pMD->IsILStub())
-        {
-            ILStubResolver* pResolver = pMD->AsDynamicMethodDesc()->GetILStubResolver();
-            return pResolver->GetILHeader();
-        }
-        _ASSERTE(pMD->IsNoMetadata());
-        return NULL;
-    }
-}
-PCODE MethodDesc::JitCompileCodeLockedEventWrapper(PrepareCodeConfig* pConfig, JitListLockEntry* pEntry)
-{
-    STANDARD_VM_CONTRACT;
-    PCODE pCode = (PCODE)NULL;
-    ULONG sizeOfCode = 0;
-#ifdef PROFILING_SUPPORTED
-    {
-        BEGIN_PROFILER_CALLBACK(CORProfilerTrackJITInfo());
-        NativeCodeVersion nativeCodeVersion = pConfig->GetCodeVersion();
-        ReJITID rejitId = nativeCodeVersion.GetILCodeVersionId();
-        if (rejitId != 0)
-        {
-            _ASSERTE(!nativeCodeVersion.IsDefaultVersion());
-            (&g_profControlBlock)->ReJITCompilationStarted((FunctionID)this,
-                rejitId,
-                TRUE);
-        }
-        else
-        {
-            if (!IsNoMetadata())
-            {
-                (&g_profControlBlock)->JITCompilationStarted((FunctionID)this, TRUE);
-            }
-            else
-            {
-                unsigned int ilSize, unused;
-                CorInfoOptions corOptions;
-                LPCBYTE ilHeaderPointer = this->AsDynamicMethodDesc()->GetResolver()->GetCodeInfo(&ilSize, &unused, &corOptions, &unused);
-                (&g_profControlBlock)->DynamicMethodJITCompilationStarted((FunctionID)this, TRUE, ilHeaderPointer, ilSize);
-            }
-            if (nativeCodeVersion.IsDefaultVersion())
-            {
-                pConfig->SetProfilerMayHaveActivatedNonDefaultCodeVersion();
-            }
-        }
-        END_PROFILER_CALLBACK();
-    }
-#endif // PROFILING_SUPPORTED
-    COR_ILMETHOD_DECODER ilDecoderTemp;
-    COR_ILMETHOD_DECODER* pilHeader = GetAndVerifyILHeader(this, pConfig, &ilDecoderTemp);
-    if (!ETW_TRACING_CATEGORY_ENABLED(MICROSOFT_WINDOWS_DOTNETRUNTIME_PROVIDER_DOTNET_Context,
-        TRACE_LEVEL_VERBOSE,
-        CLR_JIT_KEYWORD))
-    {
-        pCode = JitCompileCodeLocked(pConfig, pilHeader, pEntry, &sizeOfCode);
-    }
-    else
-    {
-        SString namespaceOrClassName, methodName, methodSignature;
-#ifndef FEATURE_INTERPRETER
-        ETW::MethodLog::MethodJitting(this,
-            pilHeader,
-            &namespaceOrClassName,
-            &methodName,
-            &methodSignature);
-#endif
-        pCode = JitCompileCodeLocked(pConfig, pilHeader, pEntry, &sizeOfCode);
-#ifdef FEATURE_INTERPRETER
-        if (Interpreter::InterpretationStubToMethodInfo(pCode) == NULL)
-#endif
-        {
-            ETW::MethodLog::MethodJitted(this,
-                &namespaceOrClassName,
-                &methodName,
-                &methodSignature,
-                pCode,
-                pConfig);
-        }
-    }
-#ifdef PROFILING_SUPPORTED
-    {
-        BEGIN_PROFILER_CALLBACK(CORProfilerTrackJITInfo());
-        NativeCodeVersion nativeCodeVersion = pConfig->GetCodeVersion();
-        ReJITID rejitId = nativeCodeVersion.GetILCodeVersionId();
-        if (rejitId != 0)
-        {
-            _ASSERTE(!nativeCodeVersion.IsDefaultVersion());
-            (&g_profControlBlock)->ReJITCompilationFinished((FunctionID)this,
-                rejitId,
-                S_OK,
-                TRUE);
-        }
-        else
-        {
-            if (!IsNoMetadata())
-            {
-                (&g_profControlBlock)->
-                    JITCompilationFinished((FunctionID)this,
-                        pEntry->m_hrResultCode,
-                        TRUE);
-            }
-            else
-            {
-                (&g_profControlBlock)->DynamicMethodJITCompilationFinished((FunctionID)this, pEntry->m_hrResultCode, TRUE);
-            }
-            if (nativeCodeVersion.IsDefaultVersion())
-            {
-                pConfig->SetProfilerMayHaveActivatedNonDefaultCodeVersion();
-            }
-        }
-        END_PROFILER_CALLBACK();
-    }
-#endif // PROFILING_SUPPORTED
-#ifdef FEATURE_INTERPRETER
-    bool isJittedMethod = (Interpreter::InterpretationStubToMethodInfo(pCode) == NULL);
-#endif
-#ifdef FEATURE_INTERPRETER
-    if (isJittedMethod)
-#endif
-    {
-#ifdef FEATURE_PERFMAP
-        PerfMap::LogJITCompiledMethod(this, pCode, sizeOfCode, pConfig);
-#endif
-    }
-#ifdef FEATURE_INTERPRETER
-    if (isJittedMethod)
-#endif
-    {
-        DACNotifyCompilationFinished(this, pCode);
-    }
-    return pCode;
-}
-PCODE MethodDesc::JitCompileCodeLocked(PrepareCodeConfig* pConfig, COR_ILMETHOD_DECODER* pilHeader, JitListLockEntry* pEntry, ULONG* pSizeOfCode)
-{
-    STANDARD_VM_CONTRACT;
-    PCODE pCode = (PCODE)NULL;
-    CORJIT_FLAGS jitFlags;
-    PCODE pOtherCode = (PCODE)NULL;
-    EX_TRY
-    {
-        Thread::CurrentPrepareCodeConfigHolder threadPrepareCodeConfigHolder(GetThread(), pConfig);
-        pCode = UnsafeJitFunction(pConfig, pilHeader, &jitFlags, pSizeOfCode);
-    }
-    EX_CATCH
-    {
-        if (!(pOtherCode = pConfig->IsJitCancellationRequested()))
-        {
-            pEntry->m_hrResultCode = E_FAIL;
-            EX_RETHROW;
-        }
-    }
-    EX_END_CATCH(RethrowTerminalExceptions)
-    if (pOtherCode != (PCODE)NULL)
-    {
-        return pOtherCode;
-    }
-    _ASSERTE(pCode != (PCODE)NULL);
-#ifdef HAVE_GCCOVER
-    if (GCStress<cfg_instr_jit>::IsEnabled())
-    {
-        CrstHolder gcCoverLock(&m_GCCoverCrst);
-        if ((pOtherCode = pConfig->IsJitCancellationRequested()))
-        {
-            return pOtherCode;
-        }
-        SetupGcCoverage(pConfig->GetCodeVersion(), (BYTE*)pCode);
-    }
-#endif // HAVE_GCCOVER
-#ifdef FEATURE_TIERED_COMPILATION
-    bool shouldCountCalls = jitFlags.IsSet(CORJIT_FLAGS::CORJIT_FLAG_TIER0) && pConfig->FinalizeOptimizationTierForTier0LoadOrJit();
-#endif
-    if (!pConfig->SetNativeCode(pCode, &pOtherCode))
-    {
-#ifdef HAVE_GCCOVER
-        _ASSERTE(!GCStress<cfg_instr_jit>::IsEnabled() || !"GC Cover native code publish failed");
-#endif
-        return pOtherCode;
-    }
-#ifdef FEATURE_CODE_VERSIONING
-    pConfig->SetGeneratedOrLoadedNewCode();
-#endif
-#ifdef FEATURE_TIERED_COMPILATION
-    if (shouldCountCalls)
-    {
-        pConfig->SetShouldCountCalls();
-    }
-#endif
-#if defined(FEATURE_JIT_PITCHING)
-    SavePitchingCandidate(this, *pSizeOfCode);
-#endif
-#ifdef FEATURE_MULTICOREJIT
-    if (pConfig->NeedsMulticoreJitNotification())
-    {
-        _ASSERTE(pConfig->GetCodeVersion().IsDefaultVersion());
-        _ASSERTE(!pConfig->IsForMulticoreJit());
-        MulticoreJitManager & mcJitManager = GetAppDomain()->GetMulticoreJitManager();
-        if (mcJitManager.IsRecorderActive())
-        {
-            if (MulticoreJitManager::IsMethodSupported(this))
-            {
-                mcJitManager.RecordMethodJitOrLoad(this); // Tell multi-core JIT manager to record method on successful JITting
-            }
-        }
-    }
-#endif
-    pEntry->m_hrResultCode = S_OK;
-    return pCode;
-}
-namespace
-{
-    enum class UnsafeAccessorKind
-    {
-        Constructor, // call instance constructor (`newobj` in IL)
-        Method, // call instance method (`callvirt` in IL)
-        StaticMethod, // call static method (`call` in IL)
-        Field, // address of instance field (`ldflda` in IL)
-        StaticField // address of static field (`ldsflda` in IL)
-    };
-    bool TryParseUnsafeAccessorAttribute(
-        MethodDesc* pMD,
-        CustomAttributeParser& ca,
-        UnsafeAccessorKind& kind,
-        SString& name)
-    {
-        STANDARD_VM_CONTRACT;
-        _ASSERTE(pMD != NULL);
-        CaArg args[1];
-        args[0].InitEnum(SERIALIZATION_TYPE_I4, 0);
-        if (FAILED(::ParseKnownCaArgs(ca, args, ARRAY_SIZE(args))))
-            return false;
-        kind = (UnsafeAccessorKind)args[0].val.i4;
-        CaNamedArg namedArgs[1];
-        CaType namedArgTypes[1];
-        namedArgTypes[0].Init(SERIALIZATION_TYPE_STRING);
-        namedArgs[0].Init("Name", SERIALIZATION_TYPE_PROPERTY, namedArgTypes[0]);
-        if (FAILED(::ParseKnownCaNamedArgs(ca, namedArgs, ARRAY_SIZE(namedArgs))))
-            return false;
-        if (namedArgs[0].val.type.tag == SERIALIZATION_TYPE_UNDEFINED)
-        {
-            if (kind != UnsafeAccessorKind::Constructor)
-                name.SetUTF8(pMD->GetName());
-        }
-        else
-        {
-            const CaValue& val = namedArgs[0].val;
-            name.SetUTF8(val.str.pStr, val.str.cbStr);
-        }
-        return true;
-    }
-    struct GenerationContext final
-    {
-        GenerationContext(UnsafeAccessorKind kind, MethodDesc* pMD)
-            : Kind{ kind }
-            , Declaration{ pMD }
-            , DeclarationSig{ pMD }
-            , TargetTypeSig{}
-            , TargetType{}
-            , IsTargetStatic{ false }
-            , TargetMethod{}
-            , TargetField{}
-        { }
-        UnsafeAccessorKind Kind;
-        MethodDesc* Declaration;
-        MetaSig DeclarationSig;
-        SigPointer TargetTypeSig;
-        TypeHandle TargetType;
-        bool IsTargetStatic;
-        MethodDesc* TargetMethod;
-        FieldDesc* TargetField;
-    };
-    TypeHandle ValidateTargetType(TypeHandle targetTypeMaybe, CorElementType targetFromSig)
-    {
-        TypeHandle targetType = targetTypeMaybe.IsByRef()
-            ? targetTypeMaybe.GetTypeParam()
-            : targetTypeMaybe;
-        if (targetType.IsTypeDesc())
-            ThrowHR(COR_E_BADIMAGEFORMAT, BFA_INVALID_UNSAFEACCESSOR);
-        if (targetFromSig == ELEMENT_TYPE_VAR || targetFromSig == ELEMENT_TYPE_MVAR)
-        {
-            ThrowHR(COR_E_BADIMAGEFORMAT, BFA_INVALID_UNSAFEACCESSOR);
-        }
-        return targetType;
-    }
-    bool DoesMethodMatchUnsafeAccessorDeclaration(
-        GenerationContext& cxt,
-        MethodDesc* method,
-        MetaSig::CompareState& state)
-    {
-        STANDARD_VM_CONTRACT;
-        _ASSERTE(method != NULL);
-        PCCOR_SIGNATURE pSig1;
-        DWORD cSig1;
-        cxt.Declaration->GetSig(&pSig1, &cSig1);
-        PCCOR_SIGNATURE pEndSig1 = pSig1 + cSig1;
-        ModuleBase* pModule1 = cxt.Declaration->GetModule();
-        const Substitution* pSubst1 = NULL;
-        PCCOR_SIGNATURE pSig2;
-        DWORD cSig2;
-        method->GetSig(&pSig2, &cSig2);
-        PCCOR_SIGNATURE pEndSig2 = pSig2 + cSig2;
-        ModuleBase* pModule2 = method->GetModule();
-        const Substitution* pSubst2 = NULL;
-        uint32_t callConvDecl;
-        uint32_t callConvMethod;
-        IfFailThrow(CorSigUncompressCallingConv(pSig1, cSig1, &callConvDecl));
-        IfFailThrow(CorSigUncompressCallingConv(pSig2, cSig2, &callConvMethod));
-        pSig1++;
-        pSig2++;
-        if ((callConvDecl & IMAGE_CEE_CS_CALLCONV_MASK) != (callConvMethod & IMAGE_CEE_CS_CALLCONV_MASK))
-        {
-            return false;
-        }
-        DWORD declGenericCount = 0;
-        DWORD methodGenericCount = 0;
-        if (callConvDecl & IMAGE_CEE_CS_CALLCONV_GENERIC)
-            IfFailThrow(CorSigUncompressData_EndPtr(pSig1, pEndSig1, &declGenericCount));
-        if (callConvMethod & IMAGE_CEE_CS_CALLCONV_GENERIC)
-            IfFailThrow(CorSigUncompressData_EndPtr(pSig2, pEndSig2, &methodGenericCount));
-        DWORD declArgCount;
-        DWORD methodArgCount;
-        IfFailThrow(CorSigUncompressData_EndPtr(pSig1, pEndSig1, &declArgCount));
-        IfFailThrow(CorSigUncompressData_EndPtr(pSig2, pEndSig2, &methodArgCount));
-        if (cxt.Kind == UnsafeAccessorKind::Constructor)
-        {
-            if (declArgCount != methodArgCount)
-                return false;
-        }
-        else
-        {
-            if (declArgCount != (methodArgCount + 1))
-                return false;
-        }
-        for (DWORD i = 0; i <= methodArgCount; ++i)
-        {
-            if (i == 0 && cxt.Kind == UnsafeAccessorKind::Constructor)
-            {
-                SigPointer ptr1(pSig1, (DWORD)(pEndSig1 - pSig1));
-                IfFailThrow(ptr1.SkipExactlyOne());
-                pSig1 = ptr1.GetPtr();
-                CorElementType typ;
-                SigPointer ptr2(pSig2, (DWORD)(pEndSig2 - pSig2));
-                IfFailThrow(ptr2.GetElemType(&typ));
-                pSig2 = ptr2.GetPtr();
-                if (typ != ELEMENT_TYPE_VOID)
-                    return false;
-                continue;
-            }
-            else if (i == 1 && cxt.Kind != UnsafeAccessorKind::Constructor)
-            {
-                SigPointer ptr1(pSig1, (DWORD)(pEndSig1 - pSig1));
-                IfFailThrow(ptr1.SkipExactlyOne());
-                pSig1 = ptr1.GetPtr();
-            }
-            if (FALSE == MetaSig::CompareElementType(
-                pSig1,
-                pSig2,
-                pEndSig1,
-                pEndSig2,
-                pModule1,
-                pModule2,
-                pSubst1,
-                pSubst2,
-                &state))
-            {
-                return false;
-            }
-        }
-        return true;
-    }
-    void VerifyDeclarationSatisfiesTargetConstraints(MethodDesc* declaration, MethodTable* targetType, MethodDesc* targetMethod)
-    {
-        CONTRACTL
-        {
-            STANDARD_VM_CHECK;
-            PRECONDITION(declaration != NULL);
-            PRECONDITION(targetType != NULL);
-            PRECONDITION(targetMethod != NULL);
-        }
-        CONTRACTL_END;
-        if (!targetMethod->HasClassOrMethodInstantiation())
-            return;
-        Instantiation declClassInst;
-        Instantiation declMethodInst;
-        Instantiation targetClassInst;
-        Instantiation targetMethodInst;
-        if (targetType->HasInstantiation())
-        {
-            declClassInst = declaration->GetMethodTable()->GetTypicalMethodTable()->GetInstantiation();
-            targetClassInst = targetType->GetTypicalMethodTable()->GetInstantiation();
-        }
-        if (targetMethod->HasMethodInstantiation())
-        {
-            declMethodInst = declaration->LoadTypicalMethodDefinition()->GetMethodInstantiation();
-            targetMethodInst = targetMethod->LoadTypicalMethodDefinition()->GetMethodInstantiation();
-        }
-        SigTypeContext typeContext;
-        SigTypeContext::InitTypeContext(declClassInst, declMethodInst, &typeContext);
-        InstantiationContext instContext{ &typeContext };
-        DWORD typeParamCount = targetClassInst.GetNumArgs();
-        if (typeParamCount != declClassInst.GetNumArgs())
-            COMPlusThrow(kInvalidProgramException, W("Argument_GenTypeConstraintsNotEqual"));
-        for (DWORD i = 0; i < typeParamCount; ++i)
-        {
-            TypeHandle arg = declClassInst[i];
-            TypeVarTypeDesc* param = targetClassInst[i].AsGenericVariable();
-            if (!param->SatisfiesConstraints(&typeContext, arg, &instContext))
-                COMPlusThrow(kInvalidProgramException, W("Argument_GenTypeConstraintsNotEqual"));
-        }
-        DWORD methodParamCount = targetMethodInst.GetNumArgs();
-        if (methodParamCount != declMethodInst.GetNumArgs())
-            COMPlusThrow(kInvalidProgramException, W("Argument_GenMethodConstraintsNotEqual"));
-        for (DWORD i = 0; i < methodParamCount; ++i)
-        {
-            TypeHandle arg = declMethodInst[i];
-            TypeVarTypeDesc* param = targetMethodInst[i].AsGenericVariable();
-            if (!param->SatisfiesConstraints(&typeContext, arg, &instContext))
-                COMPlusThrow(kInvalidProgramException, W("Argument_GenMethodConstraintsNotEqual"));
-        }
-    }
-    bool TrySetTargetMethod(
-        GenerationContext& cxt,
-        LPCUTF8 methodName,
-        bool ignoreCustomModifiers = true)
-    {
-        STANDARD_VM_CONTRACT;
-        _ASSERTE(methodName != NULL);
-        _ASSERTE(cxt.Kind == UnsafeAccessorKind::Constructor
-                || cxt.Kind == UnsafeAccessorKind::Method
-                || cxt.Kind == UnsafeAccessorKind::StaticMethod);
-        TypeHandle targetType = cxt.TargetType;
-        _ASSERTE(!targetType.IsTypeDesc());
-        MethodTable* pMT = targetType.AsMethodTable();
-        MethodDesc* targetMaybe = NULL;
-        MethodTable::IntroducedMethodIterator iter(pMT);
-        for (; iter.IsValid(); iter.Next())
-        {
-            MethodDesc* curr = iter.GetMethodDesc();
-            if (cxt.IsTargetStatic != (!!curr->IsStatic()))
-                continue;
-            if (strcmp(methodName, curr->GetNameThrowing()) != 0)
-                continue;
-            TokenPairList list { nullptr };
-            MetaSig::CompareState state{ &list };
-            state.IgnoreCustomModifiers = ignoreCustomModifiers;
-            if (!DoesMethodMatchUnsafeAccessorDeclaration(cxt, curr, state))
-                continue;
-            if (targetMaybe != NULL)
-            {
-                if (ignoreCustomModifiers)
-                {
-                    if (TrySetTargetMethod(cxt, methodName, false /* ignoreCustomModifiers */))
-                        return true;
-                }
-                COMPlusThrow(kAmbiguousMatchException, W("Arg_AmbiguousMatchException_UnsafeAccessor"));
-            }
-            targetMaybe = curr;
-        }
-        if (targetMaybe != NULL)
-            VerifyDeclarationSatisfiesTargetConstraints(cxt.Declaration, pMT, targetMaybe);
-        cxt.TargetMethod = targetMaybe;
-        return cxt.TargetMethod != NULL;
-    }
-    bool DoesFieldMatchUnsafeAccessorDeclaration(
-        GenerationContext& cxt,
-        FieldDesc* field,
-        MetaSig::CompareState& state)
-    {
-        STANDARD_VM_CONTRACT;
-        _ASSERTE(field != NULL);
-        PCCOR_SIGNATURE pSig1;
-        DWORD cSig1;
-        cxt.Declaration->GetSig(&pSig1, &cSig1);
-        PCCOR_SIGNATURE pEndSig1 = pSig1 + cSig1;
-        ModuleBase* pModule1 = cxt.Declaration->GetModule();
-        const Substitution* pSubst1 = NULL;
-        PCCOR_SIGNATURE pSig2;
-        DWORD cSig2;
-        field->GetSig(&pSig2, &cSig2);
-        PCCOR_SIGNATURE pEndSig2 = pSig2 + cSig2;
-        ModuleBase* pModule2 = field->GetModule();
-        const Substitution* pSubst2 = NULL;
-        uint32_t callConvDecl;
-        uint32_t callConvField;
-        IfFailThrow(CorSigUncompressCallingConv(pSig1, cSig1, &callConvDecl));
-        IfFailThrow(CorSigUncompressCallingConv(pSig2, cSig2, &callConvField));
-        _ASSERTE(callConvField == IMAGE_CEE_CS_CALLCONV_FIELD);
-        pSig1++;
-        pSig2++;
-        DWORD declGenericCount = 0;
-        if (callConvDecl & IMAGE_CEE_CS_CALLCONV_GENERIC)
-            IfFailThrow(CorSigUncompressData_EndPtr(pSig1, pEndSig1, &declGenericCount));
-        DWORD declArgCount;
-        IfFailThrow(CorSigUncompressData_EndPtr(pSig1, pEndSig1, &declArgCount));
-        if (pSig1 >= pEndSig1)
-            ThrowHR(META_E_BAD_SIGNATURE);
-        CorElementType byRefType = CorSigUncompressElementType(pSig1);
-        _ASSERTE(byRefType == ELEMENT_TYPE_BYREF);
-        if (FALSE == MetaSig::CompareElementType(
-            pSig1,
-            pSig2,
-            pEndSig1,
-            pEndSig2,
-            pModule1,
-            pModule2,
-            pSubst1,
-            pSubst2,
-            &state))
-        {
-            return false;
-        }
-        return true;
-    }
-    bool TrySetTargetField(
-        GenerationContext& cxt,
-        LPCUTF8 fieldName)
-    {
-        STANDARD_VM_CONTRACT;
-        _ASSERTE(fieldName != NULL);
-        _ASSERTE(cxt.Kind == UnsafeAccessorKind::Field
-                || cxt.Kind == UnsafeAccessorKind::StaticField);
-        TypeHandle targetType = cxt.TargetType;
-        _ASSERTE(!targetType.IsTypeDesc());
-        MethodTable* pMT = targetType.AsMethodTable();
-        ApproxFieldDescIterator fdIterator(
-            pMT,
-            (cxt.IsTargetStatic ? ApproxFieldDescIterator::STATIC_FIELDS : ApproxFieldDescIterator::INSTANCE_FIELDS));
-        PTR_FieldDesc pField;
-        while ((pField = fdIterator.Next()) != NULL)
-        {
-            if (strcmp(fieldName, pField->GetName()) != 0)
-                continue;
-            TokenPairList list { nullptr };
-            MetaSig::CompareState state{ &list };
-            state.IgnoreCustomModifiers = true;
-            if (!DoesFieldMatchUnsafeAccessorDeclaration(cxt, pField, state))
-                continue;
-            if (cxt.Kind == UnsafeAccessorKind::StaticField && pMT->HasGenericsStaticsInfo())
-            {
-                MethodTable* pFieldMT = pField->GetApproxEnclosingMethodTable();
-                DWORD index = pFieldMT->GetIndexForFieldDesc(pField);
-                pField = pMT->GetFieldDescByIndex(index);
-            }
-            cxt.TargetField = pField;
-            return true;
-        }
-        return false;
-    }
-    void GenerateAccessor(
-        GenerationContext& cxt,
-        DynamicResolver** resolver,
-        COR_ILMETHOD_DECODER** methodILDecoder)
-    {
-        STANDARD_VM_CONTRACT;
-        NewHolder<ILStubResolver> ilResolver = new ILStubResolver();
-        ilResolver->SetStubMethodDesc(cxt.Declaration);
-        ilResolver->SetStubTargetMethodDesc(cxt.TargetMethod);
-        SigTypeContext genericContext;
-        if (cxt.Declaration->GetClassification() == mcInstantiated)
-            SigTypeContext::InitTypeContext(cxt.Declaration, &genericContext);
-        ILStubLinker sl(
-            cxt.Declaration->GetModule(),
-            cxt.Declaration->GetSignature(),
-            &genericContext,
-            cxt.TargetMethod,
-            (ILStubLinkerFlags)ILSTUB_LINKER_FLAG_NONE);
-        ILCodeStream* pCode = sl.NewCodeStream(ILStubLinker::kDispatch);
-        UINT beginIndex = cxt.IsTargetStatic ? 1 : 0;
-        UINT stubArgCount = cxt.DeclarationSig.NumFixedArgs();
-        for (UINT i = beginIndex; i < stubArgCount; ++i)
-            pCode->EmitLDARG(i);
-        UINT targetArgCount = stubArgCount - beginIndex;
-        UINT targetRetCount = cxt.DeclarationSig.IsReturnTypeVoid() ? 0 : 1;
-        switch (cxt.Kind)
-        {
-        case UnsafeAccessorKind::Constructor:
-        {
-            _ASSERTE(cxt.TargetMethod != NULL);
-            mdToken target;
-            if (!cxt.TargetType.HasInstantiation())
-            {
-                target = pCode->GetToken(cxt.TargetMethod);
-            }
-            else
-            {
-                PCCOR_SIGNATURE sig;
-                uint32_t sigLen;
-                cxt.TargetTypeSig.GetSignature(&sig, &sigLen);
-                mdToken targetTypeSigToken = pCode->GetSigToken(sig, sigLen);
-                target = pCode->GetToken(cxt.TargetMethod, targetTypeSigToken);
-            }
-            pCode->EmitNEWOBJ(target, targetArgCount);
-            break;
-        }
-        case UnsafeAccessorKind::Method:
-        case UnsafeAccessorKind::StaticMethod:
-        {
-            _ASSERTE(cxt.TargetMethod != NULL);
-            mdToken target;
-            if (!cxt.TargetMethod->HasClassOrMethodInstantiation())
-            {
-                target = pCode->GetToken(cxt.TargetMethod);
-            }
-            else
-            {
-                DWORD targetGenericCount = cxt.TargetMethod->GetNumGenericMethodArgs();
-                mdToken methodSpecSigToken = mdTokenNil;
-                SigBuilder sigBuilder;
-                uint32_t sigLen;
-                PCCOR_SIGNATURE sig;
-                if (targetGenericCount != 0)
-                {
-                    sigBuilder.AppendByte(IMAGE_CEE_CS_CALLCONV_GENERICINST);
-                    sigBuilder.AppendData(targetGenericCount);
-                    for (DWORD i = 0; i < targetGenericCount; ++i)
-                    {
-                        sigBuilder.AppendElementType(ELEMENT_TYPE_MVAR);
-                        sigBuilder.AppendData(i);
-                    }
-                    sigLen;
-                    sig = (PCCOR_SIGNATURE)sigBuilder.GetSignature((DWORD*)&sigLen);
-                    methodSpecSigToken = pCode->GetSigToken(sig, sigLen);
-                }
-                cxt.TargetTypeSig.GetSignature(&sig, &sigLen);
-                mdToken targetTypeSigToken = pCode->GetSigToken(sig, sigLen);
-                if (methodSpecSigToken == mdTokenNil)
-                {
-                    target = pCode->GetToken(cxt.TargetMethod, targetTypeSigToken);
-                    _ASSERTE(TypeFromToken(target) == mdtMemberRef);
-                }
-                else
-                {
-                    Instantiation methodInst = cxt.Declaration->GetMethodInstantiation();
-                    MethodDesc* instantiatedTarget = MethodDesc::FindOrCreateAssociatedMethodDesc(cxt.TargetMethod, cxt.TargetType.GetMethodTable(), FALSE, methodInst, TRUE);
-                    target = pCode->GetToken(instantiatedTarget, targetTypeSigToken, methodSpecSigToken);
-                    _ASSERTE(TypeFromToken(target) == mdtMethodSpec);
-                }
-            }
-            if (cxt.Kind == UnsafeAccessorKind::StaticMethod)
-            {
-                pCode->EmitCALL(target, targetArgCount, targetRetCount);
-            }
-            else
-            {
-                pCode->EmitCALLVIRT(target, targetArgCount, targetRetCount);
-            }
-            break;
-        }
-        case UnsafeAccessorKind::Field:
-        {
-            _ASSERTE(cxt.TargetField != NULL);
-            mdToken target;
-            if (!cxt.TargetType.HasInstantiation())
-            {
-                target = pCode->GetToken(cxt.TargetField);
-            }
-            else
-            {
-                mdToken targetTypeSigToken = mdTokenNil;
-                target = pCode->GetToken(cxt.TargetField, targetTypeSigToken);
-            }
-            pCode->EmitLDFLDA(target);
-            break;
-        }
-        case UnsafeAccessorKind::StaticField:
-            _ASSERTE(cxt.TargetField != NULL);
-            mdToken target;
-            if (!cxt.TargetType.HasInstantiation())
-            {
-                target = pCode->GetToken(cxt.TargetField);
-            }
-            else
-            {
-                PCCOR_SIGNATURE sig;
-                uint32_t sigLen;
-                cxt.TargetTypeSig.GetSignature(&sig, &sigLen);
-                mdToken targetTypeSigToken = pCode->GetSigToken(sig, sigLen);
-                target = pCode->GetToken(cxt.TargetField, targetTypeSigToken);
-            }
-            pCode->EmitLDSFLDA(target);
-            break;
-        default:
-            _ASSERTE(!"Unknown UnsafeAccessorKind");
-        }
-        pCode->EmitRET();
-        {
-            UINT maxStack;
-            size_t cbCode = sl.Link(&maxStack);
-            DWORD cbSig = sl.GetLocalSigSize();
-            COR_ILMETHOD_DECODER* pILHeader = ilResolver->AllocGeneratedIL(cbCode, cbSig, maxStack);
-            BYTE* pbBuffer = (BYTE*)pILHeader->Code;
-            BYTE* pbLocalSig = (BYTE*)pILHeader->LocalVarSig;
-            _ASSERTE(cbSig == pILHeader->cbLocalVarSig);
-            sl.GenerateCode(pbBuffer, cbCode);
-            sl.GetLocalSig(pbLocalSig, cbSig);
-            ilResolver->SetTokenLookupMap(sl.GetTokenLookupMap());
-            ilResolver->SetJitFlags(CORJIT_FLAGS(CORJIT_FLAGS::CORJIT_FLAG_IL_STUB));
-            *resolver = (DynamicResolver*)ilResolver;
-            *methodILDecoder = pILHeader;
-        }
-        ilResolver.SuppressRelease();
-    }
-}
-bool MethodDesc::TryGenerateUnsafeAccessor(DynamicResolver** resolver, COR_ILMETHOD_DECODER** methodILDecoder)
-{
-    STANDARD_VM_CONTRACT;
-    _ASSERTE(resolver != NULL);
-    _ASSERTE(methodILDecoder != NULL);
-    _ASSERTE(*resolver == NULL && *methodILDecoder == NULL);
-    _ASSERTE(IsIL());
-    _ASSERTE(GetRVA() == 0);
-    const void* data;
-    ULONG dataLen;
-    HRESULT hr = GetCustomAttribute(WellKnownAttribute::UnsafeAccessorAttribute, &data, &dataLen);
-    if (hr != S_OK)
-        return false;
-    if (!IsStatic())
-        ThrowHR(COR_E_BADIMAGEFORMAT, BFA_INVALID_UNSAFEACCESSOR);
-    UnsafeAccessorKind kind;
-    SString name;
-    CustomAttributeParser ca(data, dataLen);
-    if (!TryParseUnsafeAccessorAttribute(this, ca, kind, name))
-        ThrowHR(COR_E_BADIMAGEFORMAT, BFA_INVALID_UNSAFEACCESSOR);
-    GenerationContext context{ kind, this };
-    TypeHandle retType;
-    CorElementType retCorType;
-    TypeHandle firstArgType;
-    CorElementType firstArgCorType = ELEMENT_TYPE_END;
-    retCorType = context.DeclarationSig.GetReturnType();
-    retType = context.DeclarationSig.GetRetTypeHandleThrowing();
-    UINT argCount = context.DeclarationSig.NumFixedArgs();
-    if (argCount > 0)
-    {
-        context.DeclarationSig.NextArg();
-        context.TargetTypeSig = context.DeclarationSig.GetArgProps();
-        (void)context.TargetTypeSig.PeekElemType(&firstArgCorType);
-        firstArgType = context.DeclarationSig.GetLastTypeHandleThrowing();
-    }
-    switch (context.Kind)
-    {
-    case UnsafeAccessorKind::Constructor:
-        if (context.DeclarationSig.IsReturnTypeVoid() || retType.IsByRef() || !name.IsEmpty())
-        {
-            ThrowHR(COR_E_BADIMAGEFORMAT, BFA_INVALID_UNSAFEACCESSOR);
-        }
-        context.TargetTypeSig = context.DeclarationSig.GetReturnProps();
-        context.TargetType = ValidateTargetType(retType, retCorType);
-        if (!TrySetTargetMethod(context, ".ctor"))
-            MemberLoader::ThrowMissingMethodException(context.TargetType.AsMethodTable(), ".ctor");
-        break;
-    case UnsafeAccessorKind::Method:
-    case UnsafeAccessorKind::StaticMethod:
-        if (firstArgType.IsNull())
-            ThrowHR(COR_E_BADIMAGEFORMAT, BFA_INVALID_UNSAFEACCESSOR);
-        if (kind == UnsafeAccessorKind::Method
-            && firstArgType.IsValueType()
-            && !firstArgType.IsByRef())
-        {
-            ThrowHR(COR_E_BADIMAGEFORMAT, BFA_INVALID_UNSAFEACCESSOR);
-        }
-        context.TargetType = ValidateTargetType(firstArgType, firstArgCorType);
-        context.IsTargetStatic = kind == UnsafeAccessorKind::StaticMethod;
-        if (!TrySetTargetMethod(context, name.GetUTF8()))
-            MemberLoader::ThrowMissingMethodException(context.TargetType.AsMethodTable(), name.GetUTF8());
-        break;
-    case UnsafeAccessorKind::Field:
-    case UnsafeAccessorKind::StaticField:
-        if (argCount != 1 || firstArgType.IsNull() || context.DeclarationSig.IsReturnTypeVoid())
-        {
-            ThrowHR(COR_E_BADIMAGEFORMAT, BFA_INVALID_UNSAFEACCESSOR);
-        }
-        if (!retType.IsByRef()
-            || (kind == UnsafeAccessorKind::Field
-                && firstArgType.IsValueType()
-                && !firstArgType.IsByRef()))
-        {
-            ThrowHR(COR_E_BADIMAGEFORMAT, BFA_INVALID_UNSAFEACCESSOR);
-        }
-        context.TargetType = ValidateTargetType(firstArgType, firstArgCorType);
-        context.IsTargetStatic = kind == UnsafeAccessorKind::StaticField;
-        if (!TrySetTargetField(context, name.GetUTF8()))
-            MemberLoader::ThrowMissingFieldException(context.TargetType.AsMethodTable(), name.GetUTF8());
-        break;
-    default:
-        ThrowHR(COR_E_BADIMAGEFORMAT, BFA_INVALID_UNSAFEACCESSOR);
-    }
-    GenerateAccessor(context, resolver, methodILDecoder);
-    return true;
-}
-PrepareCodeConfig::PrepareCodeConfig() {}
-PrepareCodeConfig::PrepareCodeConfig(NativeCodeVersion codeVersion, BOOL needsMulticoreJitNotification, BOOL mayUsePrecompiledCode) :
-    m_pMethodDesc(codeVersion.GetMethodDesc()),
-    m_nativeCodeVersion(codeVersion),
-    m_needsMulticoreJitNotification(needsMulticoreJitNotification),
-    m_mayUsePrecompiledCode(mayUsePrecompiledCode),
-    m_ProfilerRejectedPrecompiledCode(FALSE),
-    m_ReadyToRunRejectedPrecompiledCode(FALSE),
-    m_callerGCMode(CallerGCMode::Unknown),
-#ifdef FEATURE_MULTICOREJIT
-    m_isForMulticoreJit(false),
-#endif
-#ifdef FEATURE_CODE_VERSIONING
-    m_profilerMayHaveActivatedNonDefaultCodeVersion(false),
-    m_generatedOrLoadedNewCode(false),
-#endif
-#ifdef FEATURE_TIERED_COMPILATION
-    m_wasTieringDisabledBeforeJitting(false),
-    m_shouldCountCalls(false),
-#endif
-    m_jitSwitchedToMinOpt(false),
-#ifdef FEATURE_TIERED_COMPILATION
-    m_jitSwitchedToOptimized(false),
-#endif
-    m_nextInSameThread(nullptr)
-{}
-PCODE PrepareCodeConfig::IsJitCancellationRequested()
-{
-    LIMITED_METHOD_CONTRACT;
-    return m_pMethodDesc->GetNativeCode();
-}
-BOOL PrepareCodeConfig::NeedsMulticoreJitNotification()
-{
-    LIMITED_METHOD_CONTRACT;
-    return m_needsMulticoreJitNotification;
-}
-BOOL PrepareCodeConfig::ProfilerRejectedPrecompiledCode()
-{
-    LIMITED_METHOD_CONTRACT;
-    return m_ProfilerRejectedPrecompiledCode;
-}
-void PrepareCodeConfig::SetProfilerRejectedPrecompiledCode()
-{
-    LIMITED_METHOD_CONTRACT;
-    m_ProfilerRejectedPrecompiledCode = TRUE;
-}
-BOOL PrepareCodeConfig::ReadyToRunRejectedPrecompiledCode()
-{
-    LIMITED_METHOD_CONTRACT;
-    return m_ReadyToRunRejectedPrecompiledCode;
-}
-void PrepareCodeConfig::SetReadyToRunRejectedPrecompiledCode()
-{
-    LIMITED_METHOD_CONTRACT;
-    m_ReadyToRunRejectedPrecompiledCode = TRUE;
-}
-CallerGCMode PrepareCodeConfig::GetCallerGCMode()
-{
-    LIMITED_METHOD_CONTRACT;
-    return m_callerGCMode;
-}
-void PrepareCodeConfig::SetCallerGCMode(CallerGCMode mode)
-{
-    LIMITED_METHOD_CONTRACT;
-    m_callerGCMode = mode;
-}
-BOOL PrepareCodeConfig::SetNativeCode(PCODE pCode, PCODE * ppAlternateCodeToUse)
-{
-    LIMITED_METHOD_CONTRACT;
-    if (m_nativeCodeVersion.SetNativeCodeInterlocked(pCode, (PCODE)NULL))
-    {
-        return TRUE;
-    }
-    *ppAlternateCodeToUse = m_nativeCodeVersion.GetNativeCode();
-    return FALSE;
-}
-COR_ILMETHOD* PrepareCodeConfig::GetILHeader()
-{
-    STANDARD_VM_CONTRACT;
-    return m_pMethodDesc->GetILHeader();
-}
-CORJIT_FLAGS PrepareCodeConfig::GetJitCompilationFlags()
-{
-    STANDARD_VM_CONTRACT;
-    CORJIT_FLAGS flags;
-#ifdef FEATURE_TIERED_COMPILATION
-    flags.Add(TieredCompilationManager::GetJitFlags(this));
-#endif
-    return flags;
-}
-BOOL PrepareCodeConfig::MayUsePrecompiledCode()
-{
-    LIMITED_METHOD_CONTRACT;
-    return m_mayUsePrecompiledCode;
-}
-PrepareCodeConfig::JitOptimizationTier PrepareCodeConfig::GetJitOptimizationTier(
-    PrepareCodeConfig *config,
-    MethodDesc *methodDesc)
-{
-    WRAPPER_NO_CONTRACT;
-    _ASSERTE(methodDesc != nullptr);
-    _ASSERTE(config == nullptr || methodDesc == config->GetMethodDesc());
-    if (config != nullptr)
-    {
-        if (config->JitSwitchedToMinOpt())
-        {
-            return JitOptimizationTier::MinOptJitted;
-        }
-    #ifdef FEATURE_TIERED_COMPILATION
-        else if (config->JitSwitchedToOptimized())
-        {
-            _ASSERTE(methodDesc->IsEligibleForTieredCompilation());
-            _ASSERTE(
-                config->IsForMulticoreJit() ||
-                config->GetCodeVersion().GetOptimizationTier() == NativeCodeVersion::OptimizationTierOptimized);
-            return JitOptimizationTier::Optimized;
-        }
-        else if (methodDesc->IsEligibleForTieredCompilation())
-        {
-            switch (config->GetCodeVersion().GetOptimizationTier())
-            {
-                case NativeCodeVersion::OptimizationTier0:
-                    return JitOptimizationTier::QuickJitted;
-                case NativeCodeVersion::OptimizationTier1:
-                    return JitOptimizationTier::OptimizedTier1;
-                case NativeCodeVersion::OptimizationTier1OSR:
-                    return JitOptimizationTier::OptimizedTier1OSR;
-                case NativeCodeVersion::OptimizationTierOptimized:
-                    return JitOptimizationTier::Optimized;
-                case NativeCodeVersion::OptimizationTier0Instrumented:
-                    return JitOptimizationTier::InstrumentedTier;
-                case NativeCodeVersion::OptimizationTier1Instrumented:
-                    return JitOptimizationTier::InstrumentedTierOptimized;
-                default:
-                    UNREACHABLE();
-            }
-        }
-    #endif
-    }
-    return methodDesc->IsJitOptimizationDisabled() ? JitOptimizationTier::MinOptJitted : JitOptimizationTier::Optimized;
-}
-const char *PrepareCodeConfig::GetJitOptimizationTierStr(PrepareCodeConfig *config, MethodDesc *methodDesc)
-{
-    WRAPPER_NO_CONTRACT;
-    switch (GetJitOptimizationTier(config, methodDesc))
-    {
-        case JitOptimizationTier::Unknown: return "Unknown";
-        case JitOptimizationTier::MinOptJitted: return "MinOptJitted";
-        case JitOptimizationTier::Optimized: return "Optimized";
-        case JitOptimizationTier::QuickJitted: return "QuickJitted";
-        case JitOptimizationTier::OptimizedTier1: return "OptimizedTier1";
-        case JitOptimizationTier::OptimizedTier1OSR: return "OptimizedTier1OSR";
-        case JitOptimizationTier::InstrumentedTier: return "InstrumentedTier";
-        case JitOptimizationTier::InstrumentedTierOptimized: return "InstrumentedTierOptimized";
-        default:
-            UNREACHABLE();
-    }
-}
-#ifdef FEATURE_TIERED_COMPILATION
-bool PrepareCodeConfig::FinalizeOptimizationTierForTier0Load()
-{
-    _ASSERTE(GetMethodDesc()->IsEligibleForTieredCompilation());
-    _ASSERTE(!JitSwitchedToOptimized());
-    if (!IsForMulticoreJit())
-    {
-        return true; // should count calls if SetNativeCode() succeeds
-    }
-    ((MulticoreJitPrepareCodeConfig *)this)->SetWasTier0();
-    return false; // don't count calls
-}
-bool PrepareCodeConfig::FinalizeOptimizationTierForTier0LoadOrJit()
-{
-    _ASSERTE(GetMethodDesc()->IsEligibleForTieredCompilation());
-    if (IsForMulticoreJit())
-    {
-        ((MulticoreJitPrepareCodeConfig *)this)->SetWasTier0();
-        return false; // don't count calls
-    }
-    if (JitSwitchedToOptimized())
-    {
-    #ifdef _DEBUG
-        NativeCodeVersion::OptimizationTier previousOptimizationTier = GetCodeVersion().GetOptimizationTier();
-        _ASSERTE(
-            previousOptimizationTier == NativeCodeVersion::OptimizationTier0 ||
-            previousOptimizationTier == NativeCodeVersion::OptimizationTier0Instrumented ||
-            previousOptimizationTier == NativeCodeVersion::OptimizationTierOptimized);
-    #endif // _DEBUG
-        NativeCodeVersion codeVersion = GetCodeVersion();
-        if (codeVersion.IsDefaultVersion())
-        {
-            GetMethodDesc()->GetLoaderAllocator()->GetCallCountingManager()->DisableCallCounting(codeVersion);
-        }
-        codeVersion.SetOptimizationTier(NativeCodeVersion::OptimizationTierOptimized);
-        return false; // don't count calls
-    }
-    return true; // should count calls if SetNativeCode() succeeds
-}
-#endif // FEATURE_TIERED_COMPILATION
-#ifdef FEATURE_CODE_VERSIONING
-VersionedPrepareCodeConfig::VersionedPrepareCodeConfig() {}
-VersionedPrepareCodeConfig::VersionedPrepareCodeConfig(NativeCodeVersion codeVersion) :
-    PrepareCodeConfig(codeVersion, FALSE, FALSE)
-{
-    LIMITED_METHOD_CONTRACT;
-    _ASSERTE(!m_nativeCodeVersion.IsDefaultVersion());
-    _ASSERTE(CodeVersionManager::IsLockOwnedByCurrentThread());
-    m_ilCodeVersion = m_nativeCodeVersion.GetILCodeVersion();
-}
-HRESULT VersionedPrepareCodeConfig::FinishConfiguration()
-{
-    STANDARD_VM_CONTRACT;
-    _ASSERTE(!CodeVersionManager::IsLockOwnedByCurrentThread());
-#ifdef FEATURE_REJIT
-    if (m_ilCodeVersion.GetRejitState() != ILCodeVersion::kStateActive)
-    {
-        ReJitManager::ConfigureILCodeVersion(m_ilCodeVersion);
-    }
-    _ASSERTE(m_ilCodeVersion.GetRejitState() == ILCodeVersion::kStateActive);
-#endif
-    return S_OK;
-}
-PCODE VersionedPrepareCodeConfig::IsJitCancellationRequested()
-{
-    LIMITED_METHOD_CONTRACT;
-    return m_nativeCodeVersion.GetNativeCode();
-}
-COR_ILMETHOD* VersionedPrepareCodeConfig::GetILHeader()
-{
-    STANDARD_VM_CONTRACT;
-    return m_ilCodeVersion.GetIL();
-}
-CORJIT_FLAGS VersionedPrepareCodeConfig::GetJitCompilationFlags()
-{
-    STANDARD_VM_CONTRACT;
-    CORJIT_FLAGS flags;
-#ifdef FEATURE_REJIT
-    DWORD profilerFlags = m_ilCodeVersion.GetJitFlags();
-    flags.Add(ReJitManager::JitFlagsFromProfCodegenFlags(profilerFlags));
-#endif
-#ifdef FEATURE_TIERED_COMPILATION
-    flags.Add(TieredCompilationManager::GetJitFlags(this));
-#endif
-    return flags;
-}
-PrepareCodeConfigBuffer::PrepareCodeConfigBuffer(NativeCodeVersion codeVersion)
-{
-    WRAPPER_NO_CONTRACT;
-    if (codeVersion.IsDefaultVersion())
-    {
-        new(m_buffer) PrepareCodeConfig(codeVersion, TRUE, TRUE);
-        return;
-    }
-    VersionedPrepareCodeConfig *config;
-    {
-        CodeVersionManager::LockHolder codeVersioningLockHolder;
-        config = new(m_buffer) VersionedPrepareCodeConfig(codeVersion);
-    }
-    config->FinishConfiguration();
-}
-#endif //FEATURE_CODE_VERSIONING
-#ifdef FEATURE_INSTANTIATINGSTUB_AS_IL
-void CreateInstantiatingILStubTargetSig(MethodDesc *pBaseMD,
-                                        SigTypeContext &typeContext,
-                                        SigBuilder *stubSigBuilder)
-{
-    STANDARD_VM_CONTRACT;
-    MetaSig msig(pBaseMD);
-    BYTE callingConvention = IMAGE_CEE_CS_CALLCONV_DEFAULT;
-    if (msig.HasThis())
-        callingConvention |= IMAGE_CEE_CS_CALLCONV_HASTHIS;
-    stubSigBuilder->AppendByte(callingConvention);
-    stubSigBuilder->AppendData(msig.NumFixedArgs() + 1); // +1 is for context param
-    SigPointer pReturn = msig.GetReturnProps();
-    pReturn.ConvertToInternalExactlyOne(msig.GetModule(), &typeContext, stubSigBuilder);
-#ifndef TARGET_X86
-    stubSigBuilder->AppendElementType(ELEMENT_TYPE_I);
-#endif // !TARGET_X86
-    msig.NextArg();
-    SigPointer pArgs = msig.GetArgProps();
-    for (unsigned i = 0; i < msig.NumFixedArgs(); i++)
-    {
-        pArgs.ConvertToInternalExactlyOne(msig.GetModule(), &typeContext, stubSigBuilder);
-    }
-#ifdef TARGET_X86
-    stubSigBuilder->AppendElementType(ELEMENT_TYPE_I);
-#endif // TARGET_X86
-}
-Stub * CreateUnboxingILStubForSharedGenericValueTypeMethods(MethodDesc* pTargetMD)
-{
-    CONTRACT(Stub*)
-    {
-        THROWS;
-        GC_TRIGGERS;
-        POSTCONDITION(CheckPointer(RETVAL));
-    }
-    CONTRACT_END;
-    SigTypeContext typeContext(pTargetMD);
-    MetaSig msig(pTargetMD);
-    _ASSERTE(msig.HasThis());
-    ILStubLinker sl(pTargetMD->GetModule(),
-                    pTargetMD->GetSignature(),
-                    &typeContext,
-                    pTargetMD,
-                    (ILStubLinkerFlags)(ILSTUB_LINKER_FLAG_STUB_HAS_THIS | ILSTUB_LINKER_FLAG_TARGET_HAS_THIS));
-    ILCodeStream *pCode = sl.NewCodeStream(ILStubLinker::kDispatch);
-    SigBuilder stubSigBuilder;
-    CreateInstantiatingILStubTargetSig(pTargetMD, typeContext, &stubSigBuilder);
-    mdToken tokRawData = pCode->GetToken(CoreLibBinder::GetField(FIELD__RAW_DATA__DATA));
-    pCode->EmitLoadThis();
-    pCode->EmitLDFLDA(tokRawData);
-#if defined(TARGET_X86)
-    for (unsigned i = 0; i < msig.NumFixedArgs();i++)
-    {
-        pCode->EmitLDARG(i);
-    }
-#endif
-    pCode->EmitLoadThis();
-    pCode->EmitLDFLDA(tokRawData);
-    pCode->EmitLDC(Object::GetOffsetOfFirstField());
-    pCode->EmitSUB();
-    pCode->EmitLDIND_I();
-#if !defined(TARGET_X86)
-    for (unsigned i = 0; i < msig.NumFixedArgs();i++)
-    {
-        pCode->EmitLDARG(i);
-    }
-#endif
-    pCode->EmitLDC((TADDR)pTargetMD->GetMultiCallableAddrOfCode(CORINFO_ACCESS_ANY));
-    pCode->EmitCALLI(TOKEN_ILSTUB_TARGET_SIG, msig.NumFixedArgs() + 1, msig.IsReturnTypeVoid() ? 0 : 1);
-    pCode->EmitRET();
-    PCCOR_SIGNATURE pSig;
-    DWORD cbSig;
-    pTargetMD->GetSig(&pSig,&cbSig);
-    PTR_Module pLoaderModule = pTargetMD->GetLoaderModule();
-    MethodDesc * pStubMD = ILStubCache::CreateAndLinkNewILStubMethodDesc(pTargetMD->GetLoaderAllocator(),
-                                                            pLoaderModule->GetILStubCache()->GetOrCreateStubMethodTable(pLoaderModule),
-                                                            ILSTUB_UNBOXINGILSTUB,
-                                                            pTargetMD->GetModule(),
-                                                            pSig, cbSig,
-                                                            &typeContext,
-                                                            &sl);
-    ILStubResolver *pResolver = pStubMD->AsDynamicMethodDesc()->GetILStubResolver();
-    DWORD cbTargetSig = 0;
-    PCCOR_SIGNATURE pTargetSig = (PCCOR_SIGNATURE) stubSigBuilder.GetSignature(&cbTargetSig);
-    pResolver->SetStubTargetMethodSig(pTargetSig, cbTargetSig);
-    pResolver->SetStubTargetMethodDesc(pTargetMD);
-    RETURN Stub::NewStub(JitILStub(pStubMD));
-}
-Stub * CreateInstantiatingILStub(MethodDesc* pTargetMD, void* pHiddenArg)
-{
-    CONTRACT(Stub*)
-    {
-        THROWS;
-        GC_TRIGGERS;
-        PRECONDITION(CheckPointer(pHiddenArg));
-        POSTCONDITION(CheckPointer(RETVAL));
-    }
-    CONTRACT_END;
-    SigTypeContext typeContext;
-    MethodTable* pStubMT;
-    if (pTargetMD->HasMethodInstantiation())
-    {
-        MethodDesc* pMD = static_cast<MethodDesc *>(pHiddenArg);
-        SigTypeContext::InitTypeContext(pMD, &typeContext);
-        pStubMT = pMD->GetMethodTable();
-    }
-    else
-    {
-        SigTypeContext::InitTypeContext(TypeHandle::FromPtr(pHiddenArg), &typeContext);
-        pStubMT = static_cast<MethodTable *>(pHiddenArg);
-    }
-    MetaSig msig(pTargetMD);
-    ILStubLinker sl(pTargetMD->GetModule(),
-                    pTargetMD->GetSignature(),
-                    &typeContext,
-                    pTargetMD,
-                    msig.HasThis()
-                        ? (ILStubLinkerFlags)(ILSTUB_LINKER_FLAG_STUB_HAS_THIS | ILSTUB_LINKER_FLAG_TARGET_HAS_THIS)
-                        : (ILStubLinkerFlags)ILSTUB_LINKER_FLAG_NONE
-                    );
-    ILCodeStream *pCode = sl.NewCodeStream(ILStubLinker::kDispatch);
-    SigBuilder stubSigBuilder;
-    CreateInstantiatingILStubTargetSig(pTargetMD, typeContext, &stubSigBuilder);
-    if (msig.HasThis())
-    {
-        pCode->EmitLoadThis();
-    }
-#if defined(TARGET_X86)
-    for (unsigned i = 0; i < msig.NumFixedArgs();i++)
-    {
-        pCode->EmitLDARG(i);
-    }
-#endif // TARGET_X86
-    pCode->EmitLDC((TADDR)pHiddenArg);
-#if !defined(TARGET_X86)
-    for (unsigned i = 0; i < msig.NumFixedArgs();i++)
-    {
-        pCode->EmitLDARG(i);
-    }
-#endif // !TARGET_X86
-    pCode->EmitLDC((TADDR)pTargetMD->GetMultiCallableAddrOfCode(CORINFO_ACCESS_ANY));
-    pCode->EmitCALLI(TOKEN_ILSTUB_TARGET_SIG, msig.NumFixedArgs() + 1, msig.IsReturnTypeVoid() ? 0 : 1);
-    pCode->EmitRET();
-    PCCOR_SIGNATURE pSig;
-    DWORD cbSig;
-    pTargetMD->GetSig(&pSig,&cbSig);
-    PTR_Module pLoaderModule = pTargetMD->GetLoaderModule();
-    MethodDesc * pStubMD = ILStubCache::CreateAndLinkNewILStubMethodDesc(pTargetMD->GetLoaderAllocator(),
-                                                            pStubMT,
-                                                            ILSTUB_INSTANTIATINGSTUB,
-                                                            pTargetMD->GetModule(),
-                                                            pSig, cbSig,
-                                                            &typeContext,
-                                                            &sl);
-    ILStubResolver *pResolver = pStubMD->AsDynamicMethodDesc()->GetILStubResolver();
-    DWORD cbTargetSig = 0;
-    PCCOR_SIGNATURE pTargetSig = (PCCOR_SIGNATURE) stubSigBuilder.GetSignature(&cbTargetSig);
-    pResolver->SetStubTargetMethodSig(pTargetSig, cbTargetSig);
-    pResolver->SetStubTargetMethodDesc(pTargetMD);
-    RETURN Stub::NewStub(JitILStub(pStubMD));
-}
-#endif
-/* Make a stub that for a value class method that expects a BOXed this pointer */
-Stub * MakeUnboxingStubWorker(MethodDesc *pMD)
-{
-    CONTRACT(Stub*)
-    {
-        THROWS;
-        GC_TRIGGERS;
-        POSTCONDITION(CheckPointer(RETVAL));
-    }
-    CONTRACT_END;
-    Stub *pstub = NULL;
-    _ASSERTE (pMD->GetMethodTable()->IsValueType());
-    _ASSERTE(!pMD->ContainsGenericVariables());
-    MethodDesc *pUnboxedMD = pMD->GetWrappedMethodDesc();
-    _ASSERTE(pUnboxedMD != NULL && pUnboxedMD != pMD);
-#ifdef FEATURE_PORTABLE_SHUFFLE_THUNKS
-    StackSArray<ShuffleEntry> portableShuffle;
-    BOOL usePortableShuffle = FALSE;
-    if (!pUnboxedMD->RequiresInstMethodTableArg())
-    {
-        ShuffleEntry entry;
-        entry.srcofs = ShuffleEntry::SENTINEL;
-        entry.dstofs = 0;
-        portableShuffle.Append(entry);
-        usePortableShuffle = TRUE;
-    }
-    else
-    {
-        usePortableShuffle = GenerateShuffleArrayPortable(pMD, pUnboxedMD, &portableShuffle, ShuffleComputationType::InstantiatingStub);
-    }
-    if (usePortableShuffle)
-    {
-        CPUSTUBLINKER sl;
-        _ASSERTE(pUnboxedMD != NULL && pUnboxedMD != pMD);
-        _ASSERTE(pUnboxedMD->RequiresInstMethodTableArg() || (portableShuffle.GetCount() == 1));
-        sl.EmitComputedInstantiatingMethodStub(pUnboxedMD, &portableShuffle[0], NULL);
-        pstub = sl.Link(pMD->GetLoaderAllocator()->GetStubHeap(), NEWSTUB_FL_INSTANTIATING_METHOD);
-    }
-    else
-#endif
-    {
-#ifdef FEATURE_INSTANTIATINGSTUB_AS_IL
-#ifndef FEATURE_PORTABLE_SHUFFLE_THUNKS
-        if (pUnboxedMD->RequiresInstMethodTableArg())
-#endif // !FEATURE_PORTABLE_SHUFFLE_THUNKS
-        {
-            _ASSERTE(pUnboxedMD->RequiresInstMethodTableArg());
-            pstub = CreateUnboxingILStubForSharedGenericValueTypeMethods(pUnboxedMD);
-        }
-#ifndef FEATURE_PORTABLE_SHUFFLE_THUNKS
-        else
-#endif // !FEATURE_PORTABLE_SHUFFLE_THUNKS
-#endif // FEATURE_INSTANTIATINGSTUB_AS_IL
-#ifndef FEATURE_PORTABLE_SHUFFLE_THUNKS
-        {
-            CPUSTUBLINKER sl;
-            sl.EmitUnboxMethodStub(pUnboxedMD);
-            pstub = sl.Link(pMD->GetLoaderAllocator()->GetStubHeap());
-        }
-#endif // !FEATURE_PORTABLE_SHUFFLE_THUNKS
-    }
-    RETURN pstub;
-}
-#if defined(FEATURE_SHARE_GENERIC_CODE)
-Stub * MakeInstantiatingStubWorker(MethodDesc *pMD)
-{
-    CONTRACT(Stub*)
-    {
-        THROWS;
-        GC_TRIGGERS;
-        PRECONDITION(pMD->IsInstantiatingStub());
-        PRECONDITION(!pMD->RequiresInstArg());
-        PRECONDITION(!pMD->IsSharedByGenericMethodInstantiations());
-        POSTCONDITION(CheckPointer(RETVAL));
-    }
-    CONTRACT_END;
-    MethodDesc *pSharedMD = NULL;
-    void* extraArg = NULL;
-    pSharedMD = pMD->GetWrappedMethodDesc();
-    _ASSERTE(pSharedMD != NULL && pSharedMD != pMD);
-    if (pMD->HasMethodInstantiation())
-    {
-        extraArg = pMD;
-    }
-    else
-    {
-        extraArg = pMD->GetMethodTable();
-    }
-    Stub *pstub = NULL;
-#ifdef FEATURE_PORTABLE_SHUFFLE_THUNKS
-    StackSArray<ShuffleEntry> portableShuffle;
-    if (GenerateShuffleArrayPortable(pMD, pSharedMD, &portableShuffle, ShuffleComputationType::InstantiatingStub))
-    {
-        CPUSTUBLINKER sl;
-        _ASSERTE(pSharedMD != NULL && pSharedMD != pMD);
-        sl.EmitComputedInstantiatingMethodStub(pSharedMD, &portableShuffle[0], extraArg);
-        pstub = sl.Link(pMD->GetLoaderAllocator()->GetStubHeap(), NEWSTUB_FL_INSTANTIATING_METHOD);
-    }
-    else
-#endif
-    {
-#ifdef FEATURE_INSTANTIATINGSTUB_AS_IL
-        pstub = CreateInstantiatingILStub(pSharedMD, extraArg);
-#else
-        CPUSTUBLINKER sl;
-        _ASSERTE(pSharedMD != NULL && pSharedMD != pMD);
-        sl.EmitInstantiatingMethodStub(pSharedMD, extraArg);
-        pstub = sl.Link(pMD->GetLoaderAllocator()->GetStubHeap());
-#endif
-    }
-    RETURN pstub;
-}
-#endif // defined(FEATURE_SHARE_GENERIC_CODE)
-static PCODE PreStubWorker_Preemptive(
-    _In_ TransitionBlock* pTransitionBlock,
-    _In_ MethodDesc* pMD,
-    _In_opt_ Thread* currentThread)
-{
-    _ASSERTE(pMD->HasUnmanagedCallersOnlyAttribute());
-    PCODE pbRetVal = (PCODE)NULL;
-    STATIC_CONTRACT_THROWS;
-    STATIC_CONTRACT_GC_TRIGGERS;
-    STATIC_CONTRACT_MODE_PREEMPTIVE;
-    if (currentThread == NULL)
-    {
-        CREATETHREAD_IF_NULL_FAILFAST(currentThread, W("Failed to setup new thread during reverse P/Invoke"));
-    }
-    MAKE_CURRENT_THREAD_AVAILABLE_EX(currentThread);
-    INSTALL_MANAGED_EXCEPTION_DISPATCHER;
-    INSTALL_UNWIND_AND_CONTINUE_HANDLER;
-    pMD->CheckRestore();
-    CONSISTENCY_CHECK(GetAppDomain()->CheckCanExecuteManagedCode(pMD));
-    pbRetVal = pMD->DoPrestub(NULL, CallerGCMode::Preemptive);
-    UNINSTALL_UNWIND_AND_CONTINUE_HANDLER;
-    UNINSTALL_MANAGED_EXCEPTION_DISPATCHER;
-    {
-        HardwareExceptionHolder;
-        ThePreStubPatch();
-    }
-    return pbRetVal;
-}
-extern "C" PCODE STDCALL PreStubWorker(TransitionBlock* pTransitionBlock, MethodDesc* pMD)
-{
-    PCODE pbRetVal = (PCODE)NULL;
-    BEGIN_PRESERVE_LAST_ERROR;
-    STATIC_CONTRACT_THROWS;
-    STATIC_CONTRACT_GC_TRIGGERS;
-    STATIC_CONTRACT_MODE_ANY;
-    STATIC_CONTRACT_ENTRY_POINT;
-    ETWOnStartup(PrestubWorker_V1, PrestubWorkerEnd_V1);
-    MAKE_CURRENT_THREAD_AVAILABLE_EX(GetThreadNULLOk());
-    if (CURRENT_THREAD == NULL
-        || !CURRENT_THREAD->PreemptiveGCDisabled())
-    {
-        pbRetVal = PreStubWorker_Preemptive(pTransitionBlock, pMD, CURRENT_THREAD);
-    }
-    else
-    {
-#ifdef _DEBUG
-        Thread::ObjectRefFlush(CURRENT_THREAD);
-#endif
-        FrameWithCookie<PrestubMethodFrame> frame(pTransitionBlock, pMD);
-        PrestubMethodFrame* pPFrame = &frame;
-        pPFrame->Push(CURRENT_THREAD);
-        INSTALL_MANAGED_EXCEPTION_DISPATCHER;
-        INSTALL_UNWIND_AND_CONTINUE_HANDLER;
-        pMD->CheckRestore();
-        CONSISTENCY_CHECK(GetAppDomain()->CheckCanExecuteManagedCode(pMD));
-        MethodTable* pDispatchingMT = NULL;
-        if (pMD->IsVtableMethod())
-        {
-            OBJECTREF curobj = pPFrame->GetThis();
-            if (curobj != NULL) // Check for virtual function called non-virtually on a NULL object
-            {
-                pDispatchingMT = curobj->GetMethodTable();
-                if (pDispatchingMT->IsICastable() || pDispatchingMT->IsIDynamicInterfaceCastable())
-                {
-                    MethodTable* pMDMT = pMD->GetMethodTable();
-                    TypeHandle objectType(pDispatchingMT);
-                    TypeHandle methodType(pMDMT);
-                    GCStress<cfg_any>::MaybeTrigger();
-                    INDEBUG(curobj = NULL); // curobj is unprotected and CanCastTo() can trigger GC
-                    if (!objectType.CanCastTo(methodType))
-                    {
-                        pDispatchingMT = pMDMT;
-                    }
-                }
-#ifdef _DEBUG
-                MethodTable* pMDMT = pMD->GetMethodTable(); // put this here to see what the MT is in debug mode
-                _ASSERTE(!pMD->GetMethodTable()->IsValueType() ||
-                (pMD->IsUnboxingStub() && (pDispatchingMT->GetCanonicalMethodTable() == pMDMT->GetCanonicalMethodTable())));
-#endif // _DEBUG
-            }
-        }
-        GCX_PREEMP_THREAD_EXISTS(CURRENT_THREAD);
-        {
-            pbRetVal = pMD->DoPrestub(pDispatchingMT, CallerGCMode::Coop);
-        }
-        UNINSTALL_UNWIND_AND_CONTINUE_HANDLER;
-        UNINSTALL_MANAGED_EXCEPTION_DISPATCHER;
-        {
-            HardwareExceptionHolder;
-            ThePreStubPatch();
-        }
-        pPFrame->Pop(CURRENT_THREAD);
-    }
-    POSTCONDITION(pbRetVal != NULL);
-    END_PRESERVE_LAST_ERROR;
-    return pbRetVal;
-}
-#ifdef _DEBUG
-static void TestSEHGuardPageRestoreOverflow()
-{
-}
-static void TestSEHGuardPageRestore()
-{
-        PAL_TRY(void *, unused, NULL)
-        {
-            TestSEHGuardPageRestoreOverflow();
-        }
-        PAL_EXCEPT(EXCEPTION_EXECUTE_HANDLER)
-        {
-            _ASSERTE(!"Got first overflow.");
-        }
-        PAL_ENDTRY;
-        PAL_TRY(void *, unused, NULL)
-        {
-            TestSEHGuardPageRestoreOverflow();
-        }
-        PAL_EXCEPT(EXCEPTION_EXECUTE_HANDLER)
-        {
-            _ASSERTE(!"Got second overflow.");
-        }
-        PAL_ENDTRY;
-}
-#endif // _DEBUG
-PCODE MethodDesc::DoPrestub(MethodTable *pDispatchingMT, CallerGCMode callerGCMode)
-{
-    CONTRACT(PCODE)
-    {
-        STANDARD_VM_CHECK;
-        POSTCONDITION(RETVAL != NULL);
-    }
-    CONTRACT_END;
-    Stub *pStub = NULL;
-    PCODE pCode = (PCODE)NULL;
-    Thread *pThread = GetThread();
-    MethodTable *pMT = GetMethodTable();
-    if (ContainsGenericVariables())
-    {
-        COMPlusThrow(kInvalidOperationException, IDS_EE_CODEEXECUTION_CONTAINSGENERICVAR);
-    }
-    /**************************   DEBUG CHECKS  *************************/
-    /*-----------------------------------------------------------------
-    */
-#ifdef _DEBUG
-    static unsigned ctr = 0;
-    ctr++;
-    if (g_pConfig->ShouldPrestubHalt(this))
-    {
-        _ASSERTE(!"PreStubHalt");
-    }
-    LOG((LF_CLASSLOADER, LL_INFO10000, "In PreStubWorker for %s::%s\n",
-                m_pszDebugClassName, m_pszDebugMethodName));
-    if (g_pConfig->InjectFatalError() == 1)
-    {
-        EEPOLICY_HANDLE_FATAL_ERROR(COR_E_EXECUTIONENGINE);
-    }
-    else if (g_pConfig->InjectFatalError() == 2)
-    {
-        EEPOLICY_HANDLE_FATAL_ERROR(COR_E_STACKOVERFLOW);
-    }
-    else if (g_pConfig->InjectFatalError() == 3)
-    {
-        TestSEHGuardPageRestore();
-    }
-    if (g_pConfig->ShouldPrestubGC(this))
-    {
-        GCX_COOP();
-        GCHeapUtilities::GetGCHeap()->GarbageCollect(-1);
-    }
-#endif // _DEBUG
-    STRESS_LOG1(LF_CLASSLOADER, LL_INFO10000, "DoPrestub: method %p\n", this);
-    GCStress<cfg_any, EeconfigFastGcSPolicy, CoopGcModePolicy>::MaybeTrigger();
-#ifdef FEATURE_COMINTEROP
-    /**************************   INTEROP   *************************/
-    /*-----------------------------------------------------------------
-    */
-    if (IsCLRToCOMCall())
-    {
-        pCode = GetStubForInteropMethod(this);
-        GetOrCreatePrecode()->SetTargetInterlocked(pCode);
-        RETURN GetStableEntryPoint();
-    }
-#endif // FEATURE_COMINTEROP
-    if (pThread->IsAbortRequested())
-    {
-        pThread->HandleThreadAbort();
-    }
-    /**************************   BACKPATCHING   *************************/
-#ifdef FEATURE_CODE_VERSIONING
-    if (IsVersionable())
-    {
-        bool doBackpatch = true;
-        bool doFullBackpatch = false;
-        pCode = GetCodeVersionManager()->PublishVersionableCodeIfNecessary(this, callerGCMode, &doBackpatch, &doFullBackpatch);
-        if (doBackpatch)
-        {
-            RETURN DoBackpatch(pMT, pDispatchingMT, doFullBackpatch);
-        }
-        _ASSERTE(pCode != (PCODE)NULL);
-        _ASSERTE(!doFullBackpatch);
-        RETURN pCode;
-    }
-#endif
-    if (!IsPointingToPrestub())
-    {
-        LOG((LF_CLASSLOADER, LL_INFO10000,
-            "    In PreStubWorker, method already jitted, backpatching call point\n"));
-        #if defined(FEATURE_JIT_PITCHING)
-            MarkMethodNotPitchingCandidate(this);
-        #endif
-        RETURN DoBackpatch(pMT, pDispatchingMT, TRUE);
-    }
-    /**************************   CODE CREATION  *************************/
-    if (IsUnboxingStub())
-    {
-        pStub = MakeUnboxingStubWorker(this);
-    }
-#if defined(FEATURE_SHARE_GENERIC_CODE)
-    else if (IsInstantiatingStub())
-    {
-        pStub = MakeInstantiatingStubWorker(this);
-    }
-#endif // defined(FEATURE_SHARE_GENERIC_CODE)
-    else if (IsIL() || IsNoMetadata())
-    {
-        if (!IsNativeCodeStableAfterInit())
-        {
-            GetOrCreatePrecode();
-        }
-        pCode = PrepareInitialCode(callerGCMode);
-    } // end else if (IsIL() || IsNoMetadata())
-    else if (IsNDirect())
-    {
-        if (GetModule()->IsReadyToRun() && GetModule()->GetReadyToRunInfo()->HasNonShareablePInvokeStubs() && MayUsePrecompiledILStub())
-        {
-            PrepareCodeConfig config(NativeCodeVersion(this), TRUE, TRUE);
-            pCode = GetPrecompiledR2RCode(&config);
-            if (pCode != (PCODE)NULL)
-            {
-                LOG_USING_R2R_CODE(this);
-            }
-        }
-        if (pCode == (PCODE)NULL)
-        {
-            pCode = GetStubForInteropMethod(this);
-        }
-        GetOrCreatePrecode();
-    }
-    else if (IsFCall())
-    {
-        BOOL fSharedOrDynamicFCallImpl;
-        pCode = ECall::GetFCallImpl(this, &fSharedOrDynamicFCallImpl);
-        if (fSharedOrDynamicFCallImpl)
-        {
-            GetOrCreatePrecode();
-        }
-    }
-    else if (IsArray())
-    {
-        pStub = GenerateArrayOpStub((ArrayMethodDesc*)this);
-    }
-    else if (IsEEImpl())
-    {
-        _ASSERTE(GetMethodTable()->IsDelegate());
-        pCode = COMDelegate::GetInvokeMethodStub((EEImplMethodDesc*)this);
-        GetOrCreatePrecode();
-    }
-    else
-    {
-        _ASSERTE(!"Unknown Method Type");
-    }
-    /**************************   POSTJIT *************************/
-    _ASSERTE(pCode == (PCODE)NULL || GetNativeCode() == (PCODE)NULL || pCode == GetNativeCode());
-    _ASSERTE((pStub != NULL) ^ (pCode != (PCODE)NULL));
-#if defined(TARGET_X86) || defined(TARGET_AMD64)
-    MemoryBarrier();
-#endif
-    if (pCode != (PCODE)NULL)
-    {
-        _ASSERTE(!MayHaveEntryPointSlotsToBackpatch()); // This path doesn't lock the MethodDescBackpatchTracker as it should only
-        SetCodeEntryPoint(pCode);
-    }
-    else
-    {
-        if (!GetOrCreatePrecode()->SetTargetInterlocked(pStub->GetEntryPoint()))
-        {
-            if (pStub->HasExternalEntryPoint())
-            {
-                pStub->DecRef();
-            }
-            else
-            {
-                ExecutableWriterHolder<Stub> stubWriterHolder(pStub, sizeof(Stub));
-                stubWriterHolder.GetRW()->DecRef();
-            }
-        }
-        else if (pStub->HasExternalEntryPoint())
-        {
-            pStub->DecRef();
-        }
-    }
-    _ASSERTE(!IsPointingToPrestub());
-    _ASSERTE(HasStableEntryPoint());
-    RETURN DoBackpatch(pMT, pDispatchingMT, FALSE);
-}
-#endif // !DACCESS_COMPILE
-#ifndef DACCESS_COMPILE
-void ThePreStubManager::Init(void)
-{
-    STANDARD_VM_CONTRACT;
-    StubManager::AddStubManager(new ThePreStubManager());
-}
-void InitPreStubManager(void)
-{
-    STANDARD_VM_CONTRACT;
-    ThePreStubManager::Init();
-}
-PCODE TheUMThunkPreStub()
-{
-    LIMITED_METHOD_CONTRACT;
-    return GetEEFuncEntryPoint(TheUMEntryPrestub);
-}
-PCODE TheVarargNDirectStub(BOOL hasRetBuffArg)
-{
-    LIMITED_METHOD_CONTRACT;
-#if !defined(TARGET_X86) && !defined(TARGET_ARM64) && !defined(TARGET_LOONGARCH64) && !defined(TARGET_RISCV64)
-    if (hasRetBuffArg)
-    {
-        return GetEEFuncEntryPoint(VarargPInvokeStub_RetBuffArg);
-    }
-    else
-#endif
-    {
-        return GetEEFuncEntryPoint(VarargPInvokeStub);
-    }
-}
-static PCODE PatchNonVirtualExternalMethod(MethodDesc * pMD, PCODE pCode, PTR_READYTORUN_IMPORT_SECTION pImportSection, TADDR pIndirection)
-{
-    STANDARD_VM_CONTRACT;
-#ifdef HAS_FIXUP_PRECODE
-    if (pMD->HasPrecode() && pMD->GetPrecode()->GetType() == PRECODE_FIXUP
-        && pMD->IsNativeCodeStableAfterInit())
-    {
-        PCODE pDirectTarget = pMD->IsFCall() ? ECall::GetFCallImpl(pMD) : pMD->GetNativeCode();
-        if (pDirectTarget != (PCODE)NULL)
-            pCode = pDirectTarget;
-    }
-#endif //HAS_FIXUP_PRECODE
-    *(TADDR *)pIndirection = pCode;
-    return pCode;
-}
-EXTERN_C PCODE STDCALL ExternalMethodFixupWorker(TransitionBlock * pTransitionBlock, TADDR pIndirection, DWORD sectionIndex, Module * pModule)
-{
-    STATIC_CONTRACT_THROWS;
-    STATIC_CONTRACT_GC_TRIGGERS;
-    STATIC_CONTRACT_MODE_COOPERATIVE;
-    STATIC_CONTRACT_ENTRY_POINT;
-    PCODE         pCode   = (PCODE)NULL;
-    BEGIN_PRESERVE_LAST_ERROR;
-    MAKE_CURRENT_THREAD_AVAILABLE();
-#ifdef _DEBUG
-    Thread::ObjectRefFlush(CURRENT_THREAD);
-#endif
-    FrameWithCookie<ExternalMethodFrame> frame(pTransitionBlock);
-    ExternalMethodFrame * pEMFrame = &frame;
-#if defined(TARGET_X86) || defined(TARGET_AMD64)
-    if (pIndirection == (PCODE)NULL)
-    {
-        PCODE retAddr = pEMFrame->GetReturnAddress();
-#ifdef TARGET_X86
-        pIndirection = *(((TADDR *)retAddr) - 1);
-#else
-        pIndirection = *(((INT32 *)retAddr) - 1) + retAddr;
-#endif
-    }
-#endif
-    _ASSERTE(pModule != NULL);
-    pEMFrame->SetCallSite(pModule, pIndirection);
-    pEMFrame->Push(CURRENT_THREAD);         // Push the new ExternalMethodFrame onto the frame stack
-    INSTALL_MANAGED_EXCEPTION_DISPATCHER;
-    INSTALL_UNWIND_AND_CONTINUE_HANDLER;
-    bool fVirtual = false;
-    MethodDesc * pMD = NULL;
-    MethodTable * pMT = NULL;
-    DWORD slot = 0;
-    {
-        GCX_PREEMP_THREAD_EXISTS(CURRENT_THREAD);
-        PEImageLayout *pNativeImage = pModule->GetReadyToRunImage();
-        RVA rva = pNativeImage->GetDataRva(pIndirection);
-        PTR_READYTORUN_IMPORT_SECTION pImportSection;
-        if (sectionIndex != (DWORD)-1)
-        {
-            pImportSection = pModule->GetImportSectionFromIndex(sectionIndex);
-            _ASSERTE(pImportSection == pModule->GetImportSectionForRVA(rva));
-        }
-        else
-        {
-            pImportSection = pModule->GetImportSectionForRVA(rva);
-        }
-        _ASSERTE(pImportSection != NULL);
-        _ASSERTE(pImportSection->EntrySize == sizeof(TADDR));
-        COUNT_T index = (rva - pImportSection->Section.VirtualAddress) / sizeof(TADDR);
-        PTR_DWORD pSignatures = dac_cast<PTR_DWORD>(pNativeImage->GetRvaData(pImportSection->Signatures));
-        PCCOR_SIGNATURE pBlob = (BYTE *)pNativeImage->GetRvaData(pSignatures[index]);
-        BYTE kind = *pBlob++;
-        ModuleBase * pInfoModule = pModule;
-        if (kind & ENCODE_MODULE_OVERRIDE)
-        {
-            DWORD moduleIndex = CorSigUncompressData(pBlob);
-            pInfoModule = pModule->GetModuleFromIndex(moduleIndex);
-            kind &= ~ENCODE_MODULE_OVERRIDE;
-        }
-        TypeHandle th;
-        switch (kind)
-        {
-        case ENCODE_METHOD_ENTRY:
-            {
-                pMD =  ZapSig::DecodeMethod(pModule,
-                                            pInfoModule,
-                                            pBlob);
-                _ASSERTE(!pMD->GetMethodTable()->IsGenericTypeDefinition() || pMD->GetMethodTable()->GetNumGenericArgs() == 0);
-                if (pModule->IsReadyToRun())
-                {
-                    pMD->EnsureActive();
-                }
-                break;
-            }
-        case ENCODE_METHOD_ENTRY_DEF_TOKEN:
-            {
-                mdToken MethodDef = TokenFromRid(CorSigUncompressData(pBlob), mdtMethodDef);
-                _ASSERTE(pInfoModule->IsFullModule());
-                pMD = MemberLoader::GetMethodDescFromMethodDef(static_cast<Module*>(pInfoModule), MethodDef, FALSE);
-                pMD->PrepareForUseAsADependencyOfANativeImage();
-                if (pModule->IsReadyToRun())
-                {
-                    pMD->EnsureActive();
-                }
-                break;
-            }
-        case ENCODE_METHOD_ENTRY_REF_TOKEN:
-            {
-                SigTypeContext typeContext;
-                mdToken MemberRef = TokenFromRid(CorSigUncompressData(pBlob), mdtMemberRef);
-                FieldDesc * pFD = NULL;
-                MemberLoader::GetDescFromMemberRef(pInfoModule, MemberRef, &pMD, &pFD, &typeContext, FALSE /* strict metadata checks */, &th);
-                _ASSERTE(pMD != NULL);
-                pMD->PrepareForUseAsADependencyOfANativeImage();
-                if (pModule->IsReadyToRun())
-                {
-                    pMD->EnsureActive();
-                }
-                break;
-            }
-        case ENCODE_VIRTUAL_ENTRY:
-            {
-                pMD = ZapSig::DecodeMethod(pModule, pInfoModule, pBlob, &th);
-        VirtualEntry:
-                pMD->PrepareForUseAsADependencyOfANativeImage();
-                if (pMD->IsVtableMethod())
-                {
-                    slot = pMD->GetSlot();
-                    pMD->GetMethodTable()->GetRestoredSlot(slot); // Ensure that the target slot has an entrypoint
-                    pMT = th.IsNull() ? pMD->GetMethodTable() : th.GetMethodTable();
-                    fVirtual = true;
-                }
-                else
-                if (pModule->IsReadyToRun())
-                {
-                    pMD->EnsureActive();
-                }
-                break;
-            }
-        case ENCODE_VIRTUAL_ENTRY_DEF_TOKEN:
-            {
-                mdToken MethodDef = TokenFromRid(CorSigUncompressData(pBlob), mdtMethodDef);
-                _ASSERTE(pInfoModule->IsFullModule());
-                pMD = MemberLoader::GetMethodDescFromMethodDef(static_cast<Module*>(pInfoModule), MethodDef, FALSE);
-                goto VirtualEntry;
-            }
-        case ENCODE_VIRTUAL_ENTRY_REF_TOKEN:
-            {
-                mdToken MemberRef = TokenFromRid(CorSigUncompressData(pBlob), mdtMemberRef);
-                FieldDesc * pFD = NULL;
-                SigTypeContext typeContext;
-                MemberLoader::GetDescFromMemberRef(pInfoModule, MemberRef, &pMD, &pFD, &typeContext, FALSE /* strict metadata checks */, &th, TRUE /* actual type required */);
-                _ASSERTE(pMD != NULL);
-                goto VirtualEntry;
-            }
-        case ENCODE_VIRTUAL_ENTRY_SLOT:
-            {
-                slot = CorSigUncompressData(pBlob);
-                pMT =  ZapSig::DecodeType(pModule, pInfoModule, pBlob).GetMethodTable();
-                fVirtual = true;
-                break;
-            }
-        default:
-            _ASSERTE(!"Unexpected CORCOMPILE_FIXUP_BLOB_KIND");
-            ThrowHR(COR_E_BADIMAGEFORMAT);
-        }
-        if (fVirtual)
-        {
-            GCX_COOP_THREAD_EXISTS(CURRENT_THREAD);
-            VirtualCallStubManager *pMgr = pModule->GetLoaderAllocator()->GetVirtualCallStubManager();
-            OBJECTREF *protectedObj = pEMFrame->GetThisPtr();
-            _ASSERTE(protectedObj != NULL);
-            if (*protectedObj == NULL) {
-                COMPlusThrow(kNullReferenceException);
-            }
-            DispatchToken token;
-            if (pMT->IsInterface())
-            {
-                if (pMT->IsInterface())
-                    token = pMT->GetLoaderAllocator()->GetDispatchToken(pMT->GetTypeID(), slot);
-                else
-                    token = DispatchToken::CreateDispatchToken(slot);
-                StubCallSite callSite(pIndirection, pEMFrame->GetReturnAddress());
-                pCode = pMgr->ResolveWorker(&callSite, protectedObj, token, STUB_CODE_BLOCK_VSD_LOOKUP_STUB);
-            }
-            else
-            {
-                pCode = pMgr->GetVTableCallStub(slot);
-                *(TADDR *)pIndirection = pCode;
-            }
-            _ASSERTE(pCode != (PCODE)NULL);
-        }
-        else
-        {
-            _ASSERTE(pMD != NULL);
-            {
-                GCX_COOP_THREAD_EXISTS(CURRENT_THREAD);
-                pEMFrame->SetFunction(pMD);
-            }
-            pCode = pMD->GetMethodEntryPoint();
-#if _DEBUG
-            if (pEMFrame->GetGCRefMap() != NULL)
-            {
-                _ASSERTE(CheckGCRefMapEqual(pEMFrame->GetGCRefMap(), pMD, false));
-            }
-#endif // _DEBUG
-            if (!DoesSlotCallPrestub(pCode))
-            {
-                if (pMD->IsVersionableWithVtableSlotBackpatch())
-                {
-                    GCX_COOP();
-                    pCode = pMD->GetLoaderAllocator()->GetFuncPtrStubs()->GetFuncPtrStub(pMD);
-                }
-                pCode = PatchNonVirtualExternalMethod(pMD, pCode, pImportSection, pIndirection);
-            }
-        }
-#if defined (FEATURE_JIT_PITCHING)
-        DeleteFromPitchingCandidate(pMD);
-#endif
-    }
-    GCStress<cfg_any>::MaybeTrigger();
-    UNINSTALL_UNWIND_AND_CONTINUE_HANDLER;
-    UNINSTALL_MANAGED_EXCEPTION_DISPATCHER;
-    pEMFrame->Pop(CURRENT_THREAD);          // Pop the ExternalMethodFrame from the frame stack
-    END_PRESERVE_LAST_ERROR;
-    return pCode;
-}
-#ifdef FEATURE_READYTORUN
-static PCODE getHelperForInitializedStatic(Module * pModule, CORCOMPILE_FIXUP_BLOB_KIND kind, MethodTable * pMT, FieldDesc * pFD)
-{
-    STANDARD_VM_CONTRACT;
-    PCODE pHelper = (PCODE)NULL;
-    switch (kind)
-    {
-    case ENCODE_STATIC_BASE_NONGC_HELPER:
-        {
-            PVOID baseNonGC;
-            {
-                GCX_COOP();
-                baseNonGC = pMT->GetNonGCStaticsBasePointer();
-            }
-            pHelper = DynamicHelpers::CreateReturnConst(pModule->GetLoaderAllocator(), (TADDR)baseNonGC);
-        }
-        break;
-    case ENCODE_STATIC_BASE_GC_HELPER:
-        {
-            PVOID baseGC;
-            {
-                GCX_COOP();
-                baseGC = pMT->GetGCStaticsBasePointer();
-            }
-            pHelper = DynamicHelpers::CreateReturnConst(pModule->GetLoaderAllocator(), (TADDR)baseGC);
-        }
-        break;
-    case ENCODE_CCTOR_TRIGGER:
-        pHelper = DynamicHelpers::CreateReturn(pModule->GetLoaderAllocator());
-        break;
-    case ENCODE_FIELD_ADDRESS:
-        {
-            _ASSERTE(pFD->IsStatic());
-            PTR_VOID pAddress;
-            {
-                GCX_COOP();
-                PTR_BYTE base = 0;
-                if (!pFD->IsRVA()) // for RVA the base is ignored
-                    base = pFD->GetBase();
-                pAddress = pFD->GetStaticAddressHandle((void *)dac_cast<TADDR>(base));
-            }
-            _ASSERTE(!pFD->GetEnclosingMethodTable()->Collectible());
-            if (pFD->GetFieldType() == ELEMENT_TYPE_VALUETYPE && !pFD->IsRVA())
-                pHelper = DynamicHelpers::CreateReturnIndirConst(pModule->GetLoaderAllocator(), (TADDR)pAddress, (INT8)Object::GetOffsetOfFirstField());
-            else
-                pHelper = DynamicHelpers::CreateReturnConst(pModule->GetLoaderAllocator(), (TADDR)pAddress);
-        }
-        break;
-    default:
-        _ASSERTE(!"Unexpected statics CORCOMPILE_FIXUP_BLOB_KIND");
-        ThrowHR(COR_E_BADIMAGEFORMAT);
-    }
-    return pHelper;
-}
-static PCODE getHelperForSharedStatic(Module * pModule, CORCOMPILE_FIXUP_BLOB_KIND kind, MethodTable * pMT, FieldDesc * pFD)
-{
-    STANDARD_VM_CONTRACT;
-    _ASSERTE(kind == ENCODE_FIELD_ADDRESS);
-    CorInfoHelpFunc helpFunc = CEEInfo::getSharedStaticsHelper(pFD, pMT);
-    bool fUnbox = (pFD->GetFieldType() == ELEMENT_TYPE_VALUETYPE);
-    AllocMemTracker amTracker;
-    StaticFieldAddressArgs * pArgs = (StaticFieldAddressArgs *)amTracker.Track(
-        pModule->GetLoaderAllocator()->GetHighFrequencyHeap()->
-            AllocMem(S_SIZE_T(sizeof(StaticFieldAddressArgs))));
-    pArgs->staticBaseHelper = (FnStaticBaseHelper)CEEJitInfo::getHelperFtnStatic((CorInfoHelpFunc)helpFunc);
-    switch(helpFunc)
-    {
-        case CORINFO_HELP_GETDYNAMIC_GCTHREADSTATIC_BASE_NOCTOR:
-        case CORINFO_HELP_GETDYNAMIC_GCTHREADSTATIC_BASE:
-        case CORINFO_HELP_GETDYNAMIC_NONGCTHREADSTATIC_BASE_NOCTOR:
-        case CORINFO_HELP_GETDYNAMIC_NONGCTHREADSTATIC_BASE:
-            pArgs->arg0 = (TADDR)pMT->GetThreadStaticsInfo();
-            break;
-        case CORINFO_HELP_GETDYNAMIC_GCSTATIC_BASE_NOCTOR:
-        case CORINFO_HELP_GETPINNED_GCSTATIC_BASE_NOCTOR:
-        case CORINFO_HELP_GETDYNAMIC_GCSTATIC_BASE:
-        case CORINFO_HELP_GETPINNED_GCSTATIC_BASE:
-        case CORINFO_HELP_GETDYNAMIC_NONGCSTATIC_BASE_NOCTOR:
-        case CORINFO_HELP_GETPINNED_NONGCSTATIC_BASE_NOCTOR:
-        case CORINFO_HELP_GETDYNAMIC_NONGCSTATIC_BASE:
-        case CORINFO_HELP_GETPINNED_NONGCSTATIC_BASE:
-            pArgs->arg0 = (TADDR)pMT->GetDynamicStaticsInfo();
-            break;
-        default:
-            _ASSERTE(!"Unexpected shared statics helper CORINFO_HELP_FUNC");
-            pArgs->arg0 = 0;
-            break;
-    }
-    pArgs->offset = pFD->GetOffset();
-    PCODE pHelper = DynamicHelpers::CreateHelper(pModule->GetLoaderAllocator(), (TADDR)pArgs,
-        fUnbox ? GetEEFuncEntryPoint(JIT_StaticFieldAddressUnbox_Dynamic) : GetEEFuncEntryPoint(JIT_StaticFieldAddress_Dynamic));
-    amTracker.SuppressRelease();
-    return pHelper;
-}
-static PCODE getHelperForStaticBase(Module * pModule, CORCOMPILE_FIXUP_BLOB_KIND kind, MethodTable * pMT)
-{
-    STANDARD_VM_CONTRACT;
-    bool GCStatic = (kind == ENCODE_STATIC_BASE_GC_HELPER || kind == ENCODE_THREAD_STATIC_BASE_GC_HELPER);
-    bool noCtor = pMT->IsClassInitedOrPreinited();
-    bool threadStatic = (kind == ENCODE_THREAD_STATIC_BASE_NONGC_HELPER || kind == ENCODE_THREAD_STATIC_BASE_GC_HELPER);
-    CorInfoHelpFunc helper;
-    if (threadStatic)
-    {
-        if (GCStatic)
-        {
-            if (noCtor)
-                helper = CORINFO_HELP_GET_GCTHREADSTATIC_BASE_NOCTOR;
-            else
-                helper = CORINFO_HELP_GET_GCTHREADSTATIC_BASE;
-        }
-        else
-        {
-            if (noCtor)
-                helper = CORINFO_HELP_GET_NONGCTHREADSTATIC_BASE_NOCTOR;
-            else
-                helper = CORINFO_HELP_GET_NONGCTHREADSTATIC_BASE;
-        }
-    }
-    else
-    {
-        if (GCStatic)
-        {
-            if (noCtor)
-                helper = CORINFO_HELP_GET_GCSTATIC_BASE_NOCTOR;
-            else
-                helper = CORINFO_HELP_GET_GCSTATIC_BASE;
-        }
-        else
-        {
-            if (noCtor)
-                helper = CORINFO_HELP_GET_NONGCSTATIC_BASE_NOCTOR;
-            else
-                helper = CORINFO_HELP_GET_NONGCSTATIC_BASE;
-        }
-    }
-    PCODE pHelper;
-    pHelper = DynamicHelpers::CreateHelper(pModule->GetLoaderAllocator(), (TADDR)pMT, CEEJitInfo::getHelperFtnStatic(helper));
-    return pHelper;
-}
-TADDR GetFirstArgumentRegisterValuePtr(TransitionBlock * pTransitionBlock)
-{
-    TADDR pArgument = (TADDR)pTransitionBlock + TransitionBlock::GetOffsetOfArgumentRegisters();
-#ifdef TARGET_X86
-    pArgument += offsetof(ArgumentRegisters, ECX);
-#endif
-    return pArgument;
-}
-void ProcessDynamicDictionaryLookup(TransitionBlock *           pTransitionBlock,
-                                    Module *                    pModule,
-                                    ModuleBase *                pInfoModule,
-                                    BYTE                        kind,
-                                    PCCOR_SIGNATURE             pBlob,
-                                    PCCOR_SIGNATURE             pBlobStart,
-                                    CORINFO_RUNTIME_LOOKUP *    pResult,
-                                    DWORD *                     pDictionaryIndexAndSlot)
-{
-    STANDARD_VM_CONTRACT;
-    TADDR genericContextPtr = *(TADDR*)GetFirstArgumentRegisterValuePtr(pTransitionBlock);
-    pResult->signature = NULL;
-    pResult->testForNull = false;
-    pResult->indirectFirstOffset = 0;
-    pResult->indirectSecondOffset = 0;
-    pResult->sizeOffset = CORINFO_NO_SIZE_CHECK;
-    pResult->indirections = CORINFO_USEHELPER;
-    DWORD numGenericArgs = 0;
-    MethodTable* pContextMT = NULL;
-    MethodDesc* pContextMD = NULL;
-    if (kind == ENCODE_DICTIONARY_LOOKUP_METHOD)
-    {
-        pContextMD = (MethodDesc*)genericContextPtr;
-        numGenericArgs = pContextMD->GetNumGenericMethodArgs();
-        pResult->helper = CORINFO_HELP_RUNTIMEHANDLE_METHOD;
-    }
-    else
-    {
-        pContextMT = (MethodTable*)genericContextPtr;
-        if (kind == ENCODE_DICTIONARY_LOOKUP_THISOBJ)
-        {
-            TypeHandle contextTypeHandle = ZapSig::DecodeType(pModule, pInfoModule, pBlob);
-            SigPointer p(pBlob);
-            p.SkipExactlyOne();
-            pBlob = p.GetPtr();
-            pContextMT = pContextMT->GetMethodTableMatchingParentClass(contextTypeHandle.AsMethodTable());
-        }
-        numGenericArgs = pContextMT->GetNumGenericArgs();
-        pResult->helper = CORINFO_HELP_RUNTIMEHANDLE_CLASS;
-    }
-    _ASSERTE(numGenericArgs > 0);
-    CORCOMPILE_FIXUP_BLOB_KIND signatureKind = (CORCOMPILE_FIXUP_BLOB_KIND)CorSigUncompressData(pBlob);
-    if (signatureKind == ENCODE_TYPE_HANDLE)
-    {
-        SigPointer sigptr(pBlob, -1);
-        CorElementType type;
-        IfFailThrow(sigptr.GetElemType(&type));
-        if ((type == ELEMENT_TYPE_MVAR) && (kind == ENCODE_DICTIONARY_LOOKUP_METHOD))
-        {
-            pResult->indirections = 2;
-            pResult->offsets[0] = offsetof(InstantiatedMethodDesc, m_pPerInstInfo);
-            uint32_t data;
-            IfFailThrow(sigptr.GetData(&data));
-            pResult->offsets[1] = sizeof(TypeHandle) * data;
-            return;
-        }
-        else if ((type == ELEMENT_TYPE_VAR) && (kind != ENCODE_DICTIONARY_LOOKUP_METHOD))
-        {
-            pResult->indirections = 3;
-            pResult->offsets[0] = MethodTable::GetOffsetOfPerInstInfo();
-            pResult->offsets[1] = sizeof(TypeHandle*) * (pContextMT->GetNumDicts() - 1);
-            uint32_t data;
-            IfFailThrow(sigptr.GetData(&data));
-            pResult->offsets[2] = sizeof(TypeHandle) * data;
-            return;
-        }
-    }
-    if (pContextMT != NULL && pContextMT->GetNumDicts() > 0xFFFF)
-        ThrowHR(COR_E_BADIMAGEFORMAT);
-    *pDictionaryIndexAndSlot = (pContextMT == NULL ? 0 : pContextMT->GetNumDicts() - 1);
-    *pDictionaryIndexAndSlot <<= 16;
-    WORD dictionarySlot;
-    if (kind == ENCODE_DICTIONARY_LOOKUP_METHOD)
-    {
-        if (DictionaryLayout::FindToken(pContextMD, pModule->GetLoaderAllocator(), 1, NULL, (BYTE*)pBlobStart, FromReadyToRunImage, pResult, &dictionarySlot))
-        {
-            pResult->testForNull = 1;
-            int minDictSize = pContextMD->GetNumGenericMethodArgs() + 1 + pContextMD->GetDictionaryLayout()->GetNumInitialSlots();
-            if (dictionarySlot >= minDictSize)
-            {
-                pResult->sizeOffset = (WORD)pContextMD->GetNumGenericMethodArgs() * sizeof(DictionaryEntry);
-            }
-            pResult->offsets[0] = offsetof(InstantiatedMethodDesc, m_pPerInstInfo);
-            *pDictionaryIndexAndSlot |= dictionarySlot;
-        }
-    }
-    else
-    {
-        if (DictionaryLayout::FindToken(pContextMT, pModule->GetLoaderAllocator(), 2, NULL, (BYTE*)pBlobStart, FromReadyToRunImage, pResult, &dictionarySlot))
-        {
-            pResult->testForNull = 1;
-            int minDictSize = pContextMT->GetNumGenericArgs() + 1 + pContextMT->GetClass()->GetDictionaryLayout()->GetNumInitialSlots();
-            if (dictionarySlot >= minDictSize)
-            {
-                pResult->sizeOffset = (WORD)pContextMT->GetNumGenericArgs() * sizeof(DictionaryEntry);
-            }
-            pResult->offsets[0] = MethodTable::GetOffsetOfPerInstInfo();
-            pResult->offsets[1] = sizeof(TypeHandle*) * (pContextMT->GetNumDicts() - 1);
-            *pDictionaryIndexAndSlot |= dictionarySlot;
-        }
-    }
-}
-PCODE DynamicHelperFixup(TransitionBlock * pTransitionBlock, TADDR * pCell, DWORD sectionIndex, Module * pModule, CORCOMPILE_FIXUP_BLOB_KIND * pKind, TypeHandle * pTH, MethodDesc ** ppMD, FieldDesc ** ppFD)
-{
-    STANDARD_VM_CONTRACT;
-    PEImageLayout *pNativeImage = pModule->GetReadyToRunImage();
-    RVA rva = pNativeImage->GetDataRva((TADDR)pCell);
-    PTR_READYTORUN_IMPORT_SECTION pImportSection = pModule->GetImportSectionFromIndex(sectionIndex);
-    _ASSERTE(pImportSection == pModule->GetImportSectionForRVA(rva));
-    _ASSERTE(pImportSection->EntrySize == sizeof(TADDR));
-    COUNT_T index = (rva - pImportSection->Section.VirtualAddress) / sizeof(TADDR);
-    PTR_DWORD pSignatures = dac_cast<PTR_DWORD>(pNativeImage->GetRvaData(pImportSection->Signatures));
-    PCCOR_SIGNATURE pBlob = (BYTE *)pNativeImage->GetRvaData(pSignatures[index]);
-    PCCOR_SIGNATURE pBlobStart = pBlob;
-    BYTE kind = *pBlob++;
-    ModuleBase * pInfoModule = pModule;
-    if (kind & ENCODE_MODULE_OVERRIDE)
-    {
-        DWORD moduleIndex = CorSigUncompressData(pBlob);
-        pInfoModule = pModule->GetModuleFromIndex(moduleIndex);
-        kind &= ~ENCODE_MODULE_OVERRIDE;
-    }
-    bool fReliable = false;
-    TypeHandle th;
-    MethodDesc * pMD = NULL;
-    FieldDesc * pFD = NULL;
-    CORINFO_RUNTIME_LOOKUP genericLookup;
-    DWORD dictionaryIndexAndSlot = -1;
-    switch (kind)
-    {
-    case ENCODE_NEW_HELPER:
-        th = ZapSig::DecodeType(pModule, pInfoModule, pBlob);
-        th.AsMethodTable()->EnsureInstanceActive();
-        break;
-    case ENCODE_ISINSTANCEOF_HELPER:
-    case ENCODE_CHKCAST_HELPER:
-        fReliable = true;
-        FALLTHROUGH;
-    case ENCODE_NEW_ARRAY_HELPER:
-        th = ZapSig::DecodeType(pModule, pInfoModule, pBlob);
-        break;
-    case ENCODE_THREAD_STATIC_BASE_NONGC_HELPER:
-    case ENCODE_THREAD_STATIC_BASE_GC_HELPER:
-    case ENCODE_STATIC_BASE_NONGC_HELPER:
-    case ENCODE_STATIC_BASE_GC_HELPER:
-    case ENCODE_CCTOR_TRIGGER:
-        th = ZapSig::DecodeType(pModule, pInfoModule, pBlob);
-    Statics:
-        th.AsMethodTable()->EnsureInstanceActive();
-        th.AsMethodTable()->CheckRunClassInitThrowing();
-        if (kind == ENCODE_THREAD_STATIC_BASE_NONGC_HELPER || kind == ENCODE_THREAD_STATIC_BASE_GC_HELPER ||
-            (kind == ENCODE_FIELD_ADDRESS && pFD->IsThreadStatic()))
-        {
-            th.AsMethodTable()->EnsureTlsIndexAllocated();
-        }
-        fReliable = true;
-        break;
-    case ENCODE_FIELD_ADDRESS:
-        pFD = ZapSig::DecodeField(pModule, pInfoModule, pBlob, &th);
-        _ASSERTE(pFD->IsStatic());
-        goto Statics;
-    case ENCODE_VIRTUAL_ENTRY:
-        fReliable = true;
-        FALLTHROUGH;
-    case ENCODE_DELEGATE_CTOR:
-        {
-            pMD = ZapSig::DecodeMethod(pModule, pInfoModule, pBlob, &th);
-            if (pMD->RequiresInstArg())
-            {
-                pMD = MethodDesc::FindOrCreateAssociatedMethodDesc(pMD,
-                    th.AsMethodTable(),
-                    FALSE /* forceBoxedEntryPoint */,
-                    pMD->GetMethodInstantiation(),
-                    FALSE /* allowInstParam */);
-            }
-            pMD->EnsureActive();
-        }
-        break;
-    case ENCODE_DICTIONARY_LOOKUP_THISOBJ:
-    case ENCODE_DICTIONARY_LOOKUP_TYPE:
-    case ENCODE_DICTIONARY_LOOKUP_METHOD:
-        ProcessDynamicDictionaryLookup(pTransitionBlock, pModule, pInfoModule, kind, pBlob, pBlobStart, &genericLookup, &dictionaryIndexAndSlot);
-        break;
-    default:
-        _ASSERTE(!"Unexpected CORCOMPILE_FIXUP_BLOB_KIND");
-        ThrowHR(COR_E_BADIMAGEFORMAT);
-    }
-    PCODE pHelper = (PCODE)NULL;
-    if (fReliable)
-    {
-        EX_TRY
-        {
-            switch (kind)
-            {
-            case ENCODE_ISINSTANCEOF_HELPER:
-            case ENCODE_CHKCAST_HELPER:
-                {
-                    CorInfoHelpFunc helpFunc = CEEInfo::getCastingHelperStatic(th, /* throwing */ (kind == ENCODE_CHKCAST_HELPER));
-                    pHelper = DynamicHelpers::CreateHelperArgMove(pModule->GetLoaderAllocator(), th.AsTAddr(), CEEJitInfo::getHelperFtnStatic(helpFunc));
-                }
-                break;
-            case ENCODE_THREAD_STATIC_BASE_NONGC_HELPER:
-            case ENCODE_THREAD_STATIC_BASE_GC_HELPER:
-            case ENCODE_STATIC_BASE_NONGC_HELPER:
-            case ENCODE_STATIC_BASE_GC_HELPER:
-            case ENCODE_CCTOR_TRIGGER:
-            case ENCODE_FIELD_ADDRESS:
-                {
-                    MethodTable * pMT = th.AsMethodTable();
-                    bool fNeedsNonTrivialHelper = false;
-                    if (pMT->Collectible() && (kind != ENCODE_CCTOR_TRIGGER))
-                    {
-                        fNeedsNonTrivialHelper = true;
-                    }
-                    else
-                    {
-                        if (pFD != NULL)
-                        {
-                            fNeedsNonTrivialHelper = !!pFD->IsSpecialStatic();
-                        }
-                        else
-                        {
-                            fNeedsNonTrivialHelper = (kind == ENCODE_THREAD_STATIC_BASE_NONGC_HELPER) || (kind == ENCODE_THREAD_STATIC_BASE_GC_HELPER);
-                        }
-                    }
-                    if (fNeedsNonTrivialHelper)
-                    {
-                        if (pFD != NULL)
-                        {
-                            if (pFD->IsRVA())
-                            {
-                                _ASSERTE(!"Fast getter for rare kinds of static fields");
-                            }
-                            else
-                            {
-                                pHelper = getHelperForSharedStatic(pModule, (CORCOMPILE_FIXUP_BLOB_KIND)kind, pMT, pFD);
-                            }
-                        }
-                        else
-                        {
-                            pHelper = getHelperForStaticBase(pModule, (CORCOMPILE_FIXUP_BLOB_KIND)kind, pMT);
-                        }
-                    }
-                    else
-                    {
-                        if (pMT->IsClassInitedOrPreinited())
-                            pHelper = getHelperForInitializedStatic(pModule, (CORCOMPILE_FIXUP_BLOB_KIND)kind, pMT, pFD);
-                    }
-                }
-                break;
-            case ENCODE_VIRTUAL_ENTRY:
-                {
-                   if (!pMD->IsVtableMethod())
-                   {
-                        pHelper = DynamicHelpers::CreateReturnConst(pModule->GetLoaderAllocator(), pMD->GetMultiCallableAddrOfCode());
-                    }
-                    else
-                    {
-                        AllocMemTracker amTracker;
-                        VirtualFunctionPointerArgs * pArgs = (VirtualFunctionPointerArgs *)amTracker.Track(
-                            pModule->GetLoaderAllocator()->GetHighFrequencyHeap()->
-                                AllocMem(S_SIZE_T(sizeof(VirtualFunctionPointerArgs))));
-                        pArgs->classHnd = (CORINFO_CLASS_HANDLE)th.AsPtr();
-                        pArgs->methodHnd = (CORINFO_METHOD_HANDLE)pMD;
-                        pHelper = DynamicHelpers::CreateHelperWithArg(pModule->GetLoaderAllocator(), (TADDR)pArgs,
-                            GetEEFuncEntryPoint(JIT_VirtualFunctionPointer_Dynamic));
-                        amTracker.SuppressRelease();
-                    }
-                }
-                break;
-            default:
-                UNREACHABLE();
-            }
-            if (pHelper != (PCODE)NULL)
-            {
-                *(TADDR *)pCell = pHelper;
-            }
-#ifdef _DEBUG
-            pHelper = (PCODE)NULL;
-#endif
-        }
-        EX_CATCH
-        {
-        }
-        EX_END_CATCH (SwallowAllExceptions);
-    }
-    else
-    {
-        switch (kind)
-        {
-        case ENCODE_NEW_HELPER:
-            {
-                bool fHasSideEffectsUnused;
-                CorInfoHelpFunc helpFunc = CEEInfo::getNewHelperStatic(th.AsMethodTable(), &fHasSideEffectsUnused);
-                pHelper = DynamicHelpers::CreateHelper(pModule->GetLoaderAllocator(), th.AsTAddr(), CEEJitInfo::getHelperFtnStatic(helpFunc));
-            }
-            break;
-        case ENCODE_NEW_ARRAY_HELPER:
-            {
-                CorInfoHelpFunc helpFunc = CEEInfo::getNewArrHelperStatic(th);
-                MethodTable *pArrayMT = th.AsMethodTable();
-                pHelper = DynamicHelpers::CreateHelperArgMove(pModule->GetLoaderAllocator(), dac_cast<TADDR>(pArrayMT), CEEJitInfo::getHelperFtnStatic(helpFunc));
-            }
-            break;
-        case ENCODE_DELEGATE_CTOR:
-            {
-                MethodTable * pDelegateType = NULL;
-                {
-                    GCX_COOP();
-                    TADDR pArgument = GetFirstArgumentRegisterValuePtr(pTransitionBlock);
-                    if (pArgument != (TADDR)NULL)
-                    {
-                        pDelegateType = (*(Object **)pArgument)->GetMethodTable();
-                        _ASSERTE(pDelegateType->IsDelegate());
-                    }
-                }
-                DelegateCtorArgs ctorData;
-                ctorData.pMethod = NULL;
-                ctorData.pArg3 = NULL;
-                ctorData.pArg4 = NULL;
-                ctorData.pArg5 = NULL;
-                MethodDesc * pDelegateCtor = NULL;
-                if (pDelegateType != NULL)
-                {
-                    pDelegateCtor = COMDelegate::GetDelegateCtor(TypeHandle(pDelegateType), pMD, &ctorData);
-                    if (ctorData.pArg4 != NULL || ctorData.pArg5 != NULL)
-                    {
-                        _ASSERTE(false);
-                        pDelegateCtor = NULL;
-                    }
-                }
-                TADDR target = (TADDR)NULL;
-                if (pDelegateCtor != NULL)
-                {
-                    target = pDelegateCtor->GetMultiCallableAddrOfCode();
-                }
-                else
-                {
-                    target = ECall::GetFCallImpl(CoreLibBinder::GetMethod(METHOD__DELEGATE__CONSTRUCT_DELEGATE));
-                    ctorData.pArg3 = NULL;
-                }
-                if (ctorData.pArg3 != NULL)
-                {
-                    pHelper = DynamicHelpers::CreateHelperWithTwoArgs(pModule->GetLoaderAllocator(), pMD->GetMultiCallableAddrOfCode(), (TADDR)ctorData.pArg3, target);
-                }
-                else
-                {
-                    pHelper = DynamicHelpers::CreateHelperWithTwoArgs(pModule->GetLoaderAllocator(), pMD->GetMultiCallableAddrOfCode(), target);
-                }
-            }
-            break;
-        case ENCODE_DICTIONARY_LOOKUP_THISOBJ:
-        case ENCODE_DICTIONARY_LOOKUP_TYPE:
-        case ENCODE_DICTIONARY_LOOKUP_METHOD:
-            {
-                pHelper = DynamicHelpers::CreateDictionaryLookupHelper(pModule->GetLoaderAllocator(), &genericLookup, dictionaryIndexAndSlot, pModule);
-            }
-            break;
-        default:
-            UNREACHABLE();
-        }
-        if (pHelper != (PCODE)NULL)
-        {
-            *(TADDR *)pCell = pHelper;
-        }
-    }
-    *pKind = (CORCOMPILE_FIXUP_BLOB_KIND)kind;
-    *pTH = th;
-    *ppMD = pMD;
-    *ppFD = pFD;
-    return pHelper;
-}
-extern "C" SIZE_T STDCALL DynamicHelperWorker(TransitionBlock * pTransitionBlock, TADDR * pCell, DWORD sectionIndex, Module * pModule, INT frameFlags)
-{
-    PCODE pHelper = (PCODE)NULL;
-    SIZE_T result = 0;
-    STATIC_CONTRACT_THROWS;
-    STATIC_CONTRACT_GC_TRIGGERS;
-    STATIC_CONTRACT_MODE_COOPERATIVE;
-    MAKE_CURRENT_THREAD_AVAILABLE();
-#ifdef _DEBUG
-    Thread::ObjectRefFlush(CURRENT_THREAD);
-#endif
-    FrameWithCookie<DynamicHelperFrame> frame(pTransitionBlock, frameFlags);
-    DynamicHelperFrame * pFrame = &frame;
-    pFrame->Push(CURRENT_THREAD);
-    INSTALL_MANAGED_EXCEPTION_DISPATCHER;
-    INSTALL_UNWIND_AND_CONTINUE_HANDLER;
-#if defined(TARGET_X86) || defined(TARGET_AMD64)
-    if (pCell == NULL)
-    {
-        PCODE retAddr = pFrame->GetReturnAddress();
-#ifdef TARGET_X86
-        pCell = *(((TADDR **)retAddr) - 1);
-#else
-        pCell = (TADDR *)(*(((INT32 *)retAddr) - 1) + retAddr);
-#endif
-    }
-#endif
-    _ASSERTE(pCell != NULL);
-    TypeHandle th;
-    MethodDesc * pMD = NULL;
-    FieldDesc * pFD = NULL;
-    CORCOMPILE_FIXUP_BLOB_KIND kind = ENCODE_NONE;
-    {
-        GCX_PREEMP_THREAD_EXISTS(CURRENT_THREAD);
-        pHelper = DynamicHelperFixup(pTransitionBlock, pCell, sectionIndex, pModule, &kind, &th, &pMD, &pFD);
-    }
-    if (pHelper == (PCODE)NULL)
-    {
-        TADDR pArgument = GetFirstArgumentRegisterValuePtr(pTransitionBlock);
-        switch (kind)
-        {
-        case ENCODE_ISINSTANCEOF_HELPER:
-        case ENCODE_CHKCAST_HELPER:
-            {
-                BOOL throwInvalidCast = (kind == ENCODE_CHKCAST_HELPER);
-                if (*(Object **)pArgument == NULL || ObjIsInstanceOf(*(Object **)pArgument, th, throwInvalidCast))
-                {
-                    result = (SIZE_T)(*(Object **)pArgument);
-                }
-                else
-                {
-                    _ASSERTE (!throwInvalidCast);
-                    result = 0;
-                }
-            }
-            break;
-        case ENCODE_STATIC_BASE_NONGC_HELPER:
-            result = (SIZE_T)th.AsMethodTable()->GetNonGCStaticsBasePointer();
-            break;
-        case ENCODE_STATIC_BASE_GC_HELPER:
-            result = (SIZE_T)th.AsMethodTable()->GetGCStaticsBasePointer();
-            break;
-        case ENCODE_THREAD_STATIC_BASE_NONGC_HELPER:
-            result = (SIZE_T)th.AsMethodTable()->GetNonGCThreadStaticsBasePointer();
-            break;
-        case ENCODE_THREAD_STATIC_BASE_GC_HELPER:
-            result = (SIZE_T)th.AsMethodTable()->GetGCThreadStaticsBasePointer();
-            break;
-        case ENCODE_CCTOR_TRIGGER:
-            break;
-        case ENCODE_FIELD_ADDRESS:
-            result = (SIZE_T)pFD->GetCurrentStaticAddress();
-            break;
-        case ENCODE_VIRTUAL_ENTRY:
-            {
-                OBJECTREF objRef = ObjectToOBJECTREF(*(Object **)pArgument);
-                GCPROTECT_BEGIN(objRef);
-                if (objRef == NULL)
-                    COMPlusThrow(kNullReferenceException);
-                if (!pMD->IsVtableMethod())
-                {
-                    result = pMD->GetMultiCallableAddrOfCode();
-                }
-                else
-                {
-                    result = pMD->GetMultiCallableAddrOfVirtualizedCode(&objRef, th);
-                }
-                GCPROTECT_END();
-            }
-            break;
-        default:
-            UNREACHABLE();
-        }
-    }
-    UNINSTALL_UNWIND_AND_CONTINUE_HANDLER;
-    UNINSTALL_MANAGED_EXCEPTION_DISPATCHER;
-    pFrame->Pop(CURRENT_THREAD);
-    if (pHelper == (PCODE)NULL)
-        *(SIZE_T *)((TADDR)pTransitionBlock + TransitionBlock::GetOffsetOfArgumentRegisters()) = result;
-    return pHelper;
-}
-#endif // FEATURE_READYTORUN
-#endif // !DACCESS_COMPILE

--- a/src/libraries/Common/src/Microsoft/Win32/SafeHandles/SafeCertContextHandleWithKeyContainerDeletion.cs
+++ b//dev/null
@@ -1,65 +0,0 @@
-using System;
-using System.Diagnostics;
-using System.Runtime.InteropServices;
-using System.Security.Cryptography;
-namespace Microsoft.Win32.SafeHandles
-{
-    internal sealed class SafeCertContextHandleWithKeyContainerDeletion : SafeCertContextHandle
-    {
-        protected sealed override bool ReleaseHandle()
-        {
-            using (SafeCertContextHandle certContext = Interop.Crypt32.CertDuplicateCertificateContext(handle))
-            {
-                DeleteKeyContainer(certContext);
-            }
-            base.ReleaseHandle();
-            return true;
-        }
-        internal static void DeleteKeyContainer(SafeCertContextHandle pCertContext)
-        {
-            if (pCertContext.IsInvalid)
-                return;
-            int cb = 0;
-            bool containsPrivateKey = Interop.Crypt32.CertGetCertificateContextProperty(pCertContext, Interop.Crypt32.CertContextPropId.CERT_KEY_PROV_INFO_PROP_ID, null, ref cb);
-            if (!containsPrivateKey)
-                return;
-            byte[] provInfoAsBytes = new byte[cb];
-            if (!Interop.Crypt32.CertGetCertificateContextProperty(pCertContext, Interop.Crypt32.CertContextPropId.CERT_KEY_PROV_INFO_PROP_ID, provInfoAsBytes, ref cb))
-                return;
-            unsafe
-            {
-                fixed (byte* pProvInfoAsBytes = provInfoAsBytes)
-                {
-                    Interop.Crypt32.CRYPT_KEY_PROV_INFO* pProvInfo = (Interop.Crypt32.CRYPT_KEY_PROV_INFO*)pProvInfoAsBytes;
-                    if (pProvInfo->dwProvType == 0)
-                    {
-                        string providerName = Marshal.PtrToStringUni((IntPtr)(pProvInfo->pwszProvName))!;
-                        string keyContainerName = Marshal.PtrToStringUni((IntPtr)(pProvInfo->pwszContainerName))!;
-                        CngKeyOpenOptions openOpts = CngKeyOpenOptions.None;
-                        if ((pProvInfo->dwFlags & Interop.Crypt32.CryptAcquireContextFlags.CRYPT_MACHINE_KEYSET) != 0)
-                        {
-                            openOpts = CngKeyOpenOptions.MachineKey;
-                        }
-                        try
-                        {
-                            using (CngKey cngKey = CngKey.Open(keyContainerName, new CngProvider(providerName), openOpts))
-                            {
-                                cngKey.Delete();
-                            }
-                        }
-                        catch (CryptographicException)
-                        {
-                        }
-                    }
-                    else
-                    {
-                        Interop.Crypt32.CryptAcquireContextFlags flags = (pProvInfo->dwFlags & Interop.Crypt32.CryptAcquireContextFlags.CRYPT_MACHINE_KEYSET) | Interop.Crypt32.CryptAcquireContextFlags.CRYPT_DELETEKEYSET;
-                        IntPtr hProv;
-                        _ = Interop.Advapi32.CryptAcquireContext(out hProv, pProvInfo->pwszContainerName, pProvInfo->pwszProvName, pProvInfo->dwProvType, flags);
-                        Debug.Assert(hProv == IntPtr.Zero);
-                    }
-                }
-            }
-        }
-    }
-}

--- a/src/libraries/System.Diagnostics.DiagnosticSource/src/System/Diagnostics/ActivitySource.cs
+++ b//dev/null
@@ -1,317 +0,0 @@
-using System.Collections.Generic;
-using System.ComponentModel;
-using System.Runtime.CompilerServices;
-using System.Threading;
-namespace System.Diagnostics
-{
-    public sealed class ActivitySource : IDisposable
-    {
-        private static readonly SynchronizedList<ActivitySource> s_activeSources = new SynchronizedList<ActivitySource>();
-        private static readonly SynchronizedList<ActivityListener> s_allListeners = new SynchronizedList<ActivityListener>();
-        private SynchronizedList<ActivityListener>? _listeners;
-        public ActivitySource(string name) : this(name, version: "", tags: null) {}
-        [EditorBrowsable(EditorBrowsableState.Never)]
-        public ActivitySource(string name, string? version = "") : this(name, version, tags: null) {}
-        public ActivitySource(string name, string? version = "", IEnumerable<KeyValuePair<string, object?>>? tags = default)
-        {
-            Name = name ?? throw new ArgumentNullException(nameof(name));
-            Version = version;
-            if (tags is not null)
-            {
-                var tagList = new List<KeyValuePair<string, object?>>(tags);
-                tagList.Sort((left, right) => string.Compare(left.Key, right.Key, StringComparison.Ordinal));
-                Tags = tagList.AsReadOnly();
-            }
-            s_activeSources.Add(this);
-            if (s_allListeners.Count > 0)
-            {
-                s_allListeners.EnumWithAction((listener, source) =>
-                {
-                    Func<ActivitySource, bool>? shouldListenTo = listener.ShouldListenTo;
-                    if (shouldListenTo != null)
-                    {
-                        var activitySource = (ActivitySource)source;
-                        if (shouldListenTo(activitySource))
-                        {
-                            activitySource.AddListener(listener);
-                        }
-                    }
-                }, this);
-            }
-            GC.KeepAlive(DiagnosticSourceEventSource.Log);
-        }
-        public string Name { get; }
-        public string? Version { get; }
-        public IEnumerable<KeyValuePair<string, object?>>? Tags { get; }
-        public bool HasListeners()
-        {
-            SynchronizedList<ActivityListener>? listeners = _listeners;
-            return listeners != null && listeners.Count > 0;
-        }
-        public Activity? CreateActivity(string name, ActivityKind kind)
-            => CreateActivity(name, kind, default, null, null, null, default, startIt: false);
-        public Activity? CreateActivity(string name, ActivityKind kind, ActivityContext parentContext, IEnumerable<KeyValuePair<string, object?>>? tags = null, IEnumerable<ActivityLink>? links = null, ActivityIdFormat idFormat = ActivityIdFormat.Unknown)
-            => CreateActivity(name, kind, parentContext, null, tags, links, default, startIt: false, idFormat);
-        public Activity? CreateActivity(string name, ActivityKind kind, string? parentId, IEnumerable<KeyValuePair<string, object?>>? tags = null, IEnumerable<ActivityLink>? links = null, ActivityIdFormat idFormat = ActivityIdFormat.Unknown)
-            => CreateActivity(name, kind, default, parentId, tags, links, default, startIt: false, idFormat);
-        public Activity? StartActivity([CallerMemberName] string name = "", ActivityKind kind = ActivityKind.Internal)
-            => CreateActivity(name, kind, default, null, null, null, default);
-        public Activity? StartActivity(string name, ActivityKind kind, ActivityContext parentContext, IEnumerable<KeyValuePair<string, object?>>? tags = null, IEnumerable<ActivityLink>? links = null, DateTimeOffset startTime = default)
-            => CreateActivity(name, kind, parentContext, null, tags, links, startTime);
-        public Activity? StartActivity(string name, ActivityKind kind, string? parentId, IEnumerable<KeyValuePair<string, object?>>? tags = null, IEnumerable<ActivityLink>? links = null, DateTimeOffset startTime = default)
-            => CreateActivity(name, kind, default, parentId, tags, links, startTime);
-        public Activity? StartActivity(ActivityKind kind, ActivityContext parentContext = default, IEnumerable<KeyValuePair<string, object?>>? tags = null, IEnumerable<ActivityLink>? links = null, DateTimeOffset startTime = default, [CallerMemberName] string name = "")
-            => CreateActivity(name, kind, parentContext, null, tags, links, startTime);
-        private Activity? CreateActivity(string name, ActivityKind kind, ActivityContext context, string? parentId, IEnumerable<KeyValuePair<string, object?>>? tags,
-                                            IEnumerable<ActivityLink>? links, DateTimeOffset startTime, bool startIt = true, ActivityIdFormat idFormat = ActivityIdFormat.Unknown)
-        {
-            SynchronizedList<ActivityListener>? listeners = _listeners;
-            if (listeners == null || listeners.Count == 0)
-            {
-                return null;
-            }
-            Activity? activity = null;
-            ActivityTagsCollection? samplerTags;
-            string? traceState;
-            ActivitySamplingResult samplingResult = ActivitySamplingResult.None;
-            if (parentId != null)
-            {
-                ActivityCreationOptions<string> aco = default;
-                ActivityCreationOptions<ActivityContext> acoContext = default;
-                aco = new ActivityCreationOptions<string>(this, name, parentId, kind, tags, links, idFormat);
-                if (aco.IdFormat == ActivityIdFormat.W3C)
-                {
-                    acoContext = new ActivityCreationOptions<ActivityContext>(this, name, aco.GetContext(), kind, tags, links, ActivityIdFormat.W3C);
-                }
-                listeners.EnumWithFunc((ActivityListener listener, ref ActivityCreationOptions<string> data, ref ActivitySamplingResult result, ref ActivityCreationOptions<ActivityContext> dataWithContext) => {
-                    SampleActivity<string>? sampleUsingParentId = listener.SampleUsingParentId;
-                    if (sampleUsingParentId != null)
-                    {
-                        ActivitySamplingResult sr = sampleUsingParentId(ref data);
-                        dataWithContext.SetTraceState(data.TraceState); // Keep the trace state in sync between data and dataWithContext
-                        if (sr > result)
-                        {
-                            result = sr;
-                        }
-                    }
-                    else if (data.IdFormat == ActivityIdFormat.W3C)
-                    {
-                        SampleActivity<ActivityContext>? sample = listener.Sample;
-                        if (sample != null)
-                        {
-                            ActivitySamplingResult sr = sample(ref dataWithContext);
-                            data.SetTraceState(dataWithContext.TraceState); // Keep the trace state in sync between data and dataWithContext
-                            if (sr > result)
-                            {
-                                result = sr;
-                            }
-                        }
-                    }
-                }, ref aco, ref samplingResult, ref acoContext);
-                if (context == default)
-                {
-                    if (aco.GetContext() != default)
-                    {
-                        context = aco.GetContext();
-                        parentId = null;
-                    }
-                    else if (acoContext.GetContext() != default)
-                    {
-                        context = acoContext.GetContext();
-                        parentId = null;
-                    }
-                }
-                samplerTags = aco.GetSamplingTags();
-                ActivityTagsCollection? atc = acoContext.GetSamplingTags();
-                if (atc != null)
-                {
-                    if (samplerTags == null)
-                    {
-                        samplerTags = atc;
-                    }
-                    else
-                    {
-                        foreach (KeyValuePair<string, object?> tag in atc)
-                        {
-                            samplerTags.Add(tag);
-                        }
-                    }
-                }
-                idFormat = aco.IdFormat;
-                traceState = aco.TraceState;
-            }
-            else
-            {
-                bool useCurrentActivityContext = context == default && Activity.Current != null;
-                var aco = new ActivityCreationOptions<ActivityContext>(this, name, useCurrentActivityContext ? Activity.Current!.Context : context, kind, tags, links, idFormat);
-                listeners.EnumWithFunc((ActivityListener listener, ref ActivityCreationOptions<ActivityContext> data, ref ActivitySamplingResult result, ref ActivityCreationOptions<ActivityContext> unused) => {
-                    SampleActivity<ActivityContext>? sample = listener.Sample;
-                    if (sample != null)
-                    {
-                        ActivitySamplingResult dr = sample(ref data);
-                        if (dr > result)
-                        {
-                            result = dr;
-                        }
-                    }
-                }, ref aco, ref samplingResult, ref aco);
-                if (!useCurrentActivityContext)
-                {
-                    context = aco.GetContext();
-                }
-                samplerTags = aco.GetSamplingTags();
-                idFormat = aco.IdFormat;
-                traceState = aco.TraceState;
-            }
-            if (samplingResult != ActivitySamplingResult.None)
-            {
-                activity = Activity.Create(this, name, kind, parentId, context, tags, links, startTime, samplerTags, samplingResult, startIt, idFormat, traceState);
-            }
-            return activity;
-        }
-        public void Dispose()
-        {
-            _listeners = null;
-            s_activeSources.Remove(this);
-        }
-        public static void AddActivityListener(ActivityListener listener)
-        {
-            if (listener is null)
-            {
-                throw new ArgumentNullException(nameof(listener));
-            }
-            if (s_allListeners.AddIfNotExist(listener))
-            {
-                s_activeSources.EnumWithAction((source, obj) => {
-                    var shouldListenTo = ((ActivityListener)obj).ShouldListenTo;
-                    if (shouldListenTo != null && shouldListenTo(source))
-                    {
-                        source.AddListener((ActivityListener)obj);
-                    }
-                }, listener);
-            }
-        }
-        internal delegate void Function<T, TParent>(T item, ref ActivityCreationOptions<TParent> data, ref ActivitySamplingResult samplingResult, ref ActivityCreationOptions<ActivityContext> dataWithContext);
-        internal void AddListener(ActivityListener listener)
-        {
-            if (_listeners == null)
-            {
-                Interlocked.CompareExchange(ref _listeners, new SynchronizedList<ActivityListener>(), null);
-            }
-            _listeners.AddIfNotExist(listener);
-        }
-        internal static void DetachListener(ActivityListener listener)
-        {
-            s_allListeners.Remove(listener);
-            s_activeSources.EnumWithAction((source, obj) => source._listeners?.Remove((ActivityListener) obj), listener);
-        }
-        internal void NotifyActivityStart(Activity activity)
-        {
-            Debug.Assert(activity != null);
-            SynchronizedList<ActivityListener>? listeners = _listeners;
-            if (listeners != null && listeners.Count > 0)
-            {
-                listeners.EnumWithAction((listener, obj) => listener.ActivityStarted?.Invoke((Activity)obj), activity);
-            }
-        }
-        internal void NotifyActivityStop(Activity activity)
-        {
-            Debug.Assert(activity != null);
-            SynchronizedList<ActivityListener>? listeners = _listeners;
-            if (listeners != null && listeners.Count > 0)
-            {
-                listeners.EnumWithAction((listener, obj) => listener.ActivityStopped?.Invoke((Activity)obj), activity);
-            }
-        }
-        internal void NotifyActivityAddException(Activity activity, Exception exception, ref TagList tags)
-        {
-            Debug.Assert(activity != null);
-            SynchronizedList<ActivityListener>? listeners = _listeners;
-            if (listeners != null && listeners.Count > 0)
-            {
-                listeners.EnumWithExceptionNotification(activity, exception, ref tags);
-            }
-        }
-    }
-    internal sealed class SynchronizedList<T>
-    {
-        private readonly object _writeLock;
-        private T[] _volatileArray;
-        public SynchronizedList()
-        {
-            _volatileArray = [];
-            _writeLock = new();
-        }
-        public void Add(T item)
-        {
-            lock (_writeLock)
-            {
-                T[] newArray = new T[_volatileArray.Length + 1];
-                Array.Copy(_volatileArray, newArray, _volatileArray.Length);// copy existing items
-                newArray[_volatileArray.Length] = item;// copy new item
-                _volatileArray = newArray;
-            }
-        }
-        public bool AddIfNotExist(T item)
-        {
-            lock (_writeLock)
-            {
-                int index = Array.IndexOf(_volatileArray, item);
-                if (index >= 0)
-                {
-                    return false;
-                }
-                T[] newArray = new T[_volatileArray.Length + 1];
-                Array.Copy(_volatileArray, newArray, _volatileArray.Length);// copy existing items
-                newArray[_volatileArray.Length] = item;// copy new item
-                _volatileArray = newArray;
-                return true;
-            }
-        }
-        public bool Remove(T item)
-        {
-            lock (_writeLock)
-            {
-                int index = Array.IndexOf(_volatileArray, item);
-                if (index < 0)
-                {
-                    return false;
-                }
-                T[] newArray = new T[_volatileArray.Length - 1];
-                Array.Copy(_volatileArray, newArray, index);// copy existing items before index
-                Array.Copy(
-                    _volatileArray, index + 1, // position after the index, skipping it
-                    newArray, index, _volatileArray.Length - index - 1// remaining items accounting for removed item
-                );
-                _volatileArray = newArray;
-                return true;
-            }
-        }
-        public int Count => _volatileArray.Length;
-        public void EnumWithFunc<TParent>(ActivitySource.Function<T, TParent> func, ref ActivityCreationOptions<TParent> data, ref ActivitySamplingResult samplingResult, ref ActivityCreationOptions<ActivityContext> dataWithContext)
-        {
-            foreach (T item in _volatileArray)
-            {
-                func(item, ref data, ref samplingResult, ref dataWithContext);
-            }
-        }
-        public void EnumWithAction(Action<T, object> action, object arg)
-        {
-            foreach (T item in _volatileArray)
-            {
-                action(item, arg);
-            }
-        }
-        public void EnumWithExceptionNotification(Activity activity, Exception exception, ref TagList tags)
-        {
-            if (typeof(T) != typeof(ActivityListener))
-            {
-                return;
-            }
-            foreach (T item in _volatileArray)
-            {
-                (item as ActivityListener)!.ExceptionRecorder?.Invoke(activity, exception, ref tags);
-            }
-        }
-    }
-}

--- a/src/libraries/System.Numerics.Tensors/src/System/Numerics/Tensors/netcore/TensorPrimitives.MinNumber.cs
+++ b//dev/null
@@ -1,80 +0,0 @@
-// Licensed to the .NET Foundation under one or more agreements.
-using System.Runtime.CompilerServices;
-using System.Runtime.InteropServices;
-using System.Runtime.Intrinsics;
-using System.Runtime.Intrinsics.Arm;
-using System.Runtime.Intrinsics.X86;
-namespace System.Numerics.Tensors
-{
-    public static partial class TensorPrimitives
-    {
-        public static T MinNumber<T>(ReadOnlySpan<T> x)
-            where T : INumber<T> =>
-            MinMaxCore<T, MinNumberOperator<T>>(x);
-        public static void MinNumber<T>(ReadOnlySpan<T> x, ReadOnlySpan<T> y, Span<T> destination)
-            where T : INumber<T> =>
-            InvokeSpanSpanIntoSpan<T, MinNumberOperator<T>>(x, y, destination);
-        public static void MinNumber<T>(ReadOnlySpan<T> x, T y, Span<T> destination)
-            where T : INumber<T> =>
-            InvokeSpanScalarIntoSpan<T, MinNumberOperator<T>>(x, y, destination);
-        internal readonly struct MinNumberOperator<T> : IAggregationOperator<T> where T : INumber<T>
-        {
-            public static bool Vectorizable => true;
-            public static T Invoke(T x, T y) => T.MinNumber(x, y);
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Vector128<T> Invoke(Vector128<T> x, Vector128<T> y)
-            {
-#if NET9_0_OR_GREATER
-                return Vector128.MinNumber(x, y);
-#else
-                if ((typeof(T) == typeof(float)) || (typeof(T) == typeof(double)))
-                {
-                    return Vector128.ConditionalSelect(
-                        (Vector128.Equals(x, y) & IsNegative(x)) | IsNaN(y) | Vector128.LessThan(x, y),
-                        x,
-                        y
-                    );
-                }
-                return Vector128.Min(x, y);
-#endif
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Vector256<T> Invoke(Vector256<T> x, Vector256<T> y)
-            {
-#if NET9_0_OR_GREATER
-                return Vector256.MinNumber(x, y);
-#else
-                if ((typeof(T) == typeof(float)) || (typeof(T) == typeof(double)))
-                {
-                    return Vector256.ConditionalSelect(
-                        (Vector256.Equals(x, y) & IsNegative(x)) | IsNaN(y) | Vector256.LessThan(x, y),
-                        x,
-                        y
-                    );
-                }
-                return Vector256.Min(x, y);
-#endif
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Vector512<T> Invoke(Vector512<T> x, Vector512<T> y)
-            {
-#if NET9_0_OR_GREATER
-                return Vector512.MinNumber(x, y);
-#else
-                if ((typeof(T) == typeof(float)) || (typeof(T) == typeof(double)))
-                {
-                    return Vector512.ConditionalSelect(
-                        (Vector512.Equals(x, y) & IsNegative(x)) | IsNaN(y) | Vector512.LessThan(x, y),
-                        x,
-                        y
-                    );
-                }
-                return Vector512.Min(x, y);
-#endif
-            }
-            public static T Invoke(Vector128<T> x) => HorizontalAggregate<T, MinNumberOperator<T>>(x);
-            public static T Invoke(Vector256<T> x) => HorizontalAggregate<T, MinNumberOperator<T>>(x);
-            public static T Invoke(Vector512<T> x) => HorizontalAggregate<T, MinNumberOperator<T>>(x);
-        }
-    }
-}

--- a/src/libraries/System.Numerics.Tensors/src/System/Numerics/Tensors/netcore/TensorPrimitives.Reciprocal.cs
+++ b//dev/null
@@ -1,146 +0,0 @@
-// Licensed to the .NET Foundation under one or more agreements.
-using System.Runtime.Intrinsics;
-using System.Runtime.Intrinsics.Arm;
-using System.Runtime.Intrinsics.X86;
-namespace System.Numerics.Tensors
-{
-    public static partial class TensorPrimitives
-    {
-        public static void Reciprocal<T>(ReadOnlySpan<T> x, Span<T> destination)
-            where T : IFloatingPoint<T> =>
-            InvokeSpanIntoSpan<T, ReciprocalOperator<T>>(x, destination);
-        public static void ReciprocalEstimate<T>(ReadOnlySpan<T> x, Span<T> destination)
-            where T : IFloatingPointIeee754<T> =>
-            InvokeSpanIntoSpan<T, ReciprocalEstimateOperator<T>>(x, destination);
-        public static void ReciprocalSqrt<T>(ReadOnlySpan<T> x, Span<T> destination)
-            where T : IFloatingPointIeee754<T> =>
-            InvokeSpanIntoSpan<T, ReciprocalSqrtOperator<T>>(x, destination);
-        public static void ReciprocalSqrtEstimate<T>(ReadOnlySpan<T> x, Span<T> destination)
-            where T : IFloatingPointIeee754<T> =>
-            InvokeSpanIntoSpan<T, ReciprocalSqrtEstimateOperator<T>>(x, destination);
-        private readonly struct ReciprocalOperator<T> : IUnaryOperator<T, T> where T : IFloatingPoint<T>
-        {
-            public static bool Vectorizable => true;
-            public static T Invoke(T x) => T.One / x;
-            public static Vector128<T> Invoke(Vector128<T> x) => Vector128<T>.One / x;
-            public static Vector256<T> Invoke(Vector256<T> x) => Vector256<T>.One / x;
-            public static Vector512<T> Invoke(Vector512<T> x) => Vector512<T>.One / x;
-        }
-        private readonly struct ReciprocalSqrtOperator<T> : IUnaryOperator<T, T> where T : IFloatingPointIeee754<T>
-        {
-            public static bool Vectorizable => true;
-            public static T Invoke(T x) => T.One / T.Sqrt(x);
-            public static Vector128<T> Invoke(Vector128<T> x) => Vector128<T>.One / Vector128.Sqrt(x);
-            public static Vector256<T> Invoke(Vector256<T> x) => Vector256<T>.One / Vector256.Sqrt(x);
-            public static Vector512<T> Invoke(Vector512<T> x) => Vector512<T>.One / Vector512.Sqrt(x);
-        }
-        private readonly struct ReciprocalEstimateOperator<T> : IUnaryOperator<T, T> where T : IFloatingPointIeee754<T>
-        {
-            public static bool Vectorizable => true;
-            public static T Invoke(T x) => T.ReciprocalEstimate(x);
-            public static Vector128<T> Invoke(Vector128<T> x)
-            {
-#if NET9_0_OR_GREATER
-                if (Avx512F.VL.IsSupported)
-                {
-                    if (typeof(T) == typeof(float)) return Avx512F.VL.Reciprocal14(x.AsSingle()).As<float, T>();
-                    if (typeof(T) == typeof(double)) return Avx512F.VL.Reciprocal14(x.AsDouble()).As<double, T>();
-                }
-#endif
-                if (Sse.IsSupported)
-                {
-                    if (typeof(T) == typeof(float)) return Sse.Reciprocal(x.AsSingle()).As<float, T>();
-                }
-                if (AdvSimd.IsSupported)
-                {
-                    if (typeof(T) == typeof(float)) return AdvSimd.ReciprocalEstimate(x.AsSingle()).As<float, T>();
-                }
-                if (AdvSimd.Arm64.IsSupported)
-                {
-                    if (typeof(T) == typeof(double)) return AdvSimd.Arm64.ReciprocalEstimate(x.AsDouble()).As<double, T>();
-                }
-                return Vector128<T>.One / x;
-            }
-            public static Vector256<T> Invoke(Vector256<T> x)
-            {
-#if NET9_0_OR_GREATER
-                if (Avx512F.VL.IsSupported)
-                {
-                    if (typeof(T) == typeof(float)) return Avx512F.VL.Reciprocal14(x.AsSingle()).As<float, T>();
-                    if (typeof(T) == typeof(double)) return Avx512F.VL.Reciprocal14(x.AsDouble()).As<double, T>();
-                }
-#endif
-                if (Avx.IsSupported)
-                {
-                    if (typeof(T) == typeof(float)) return Avx.Reciprocal(x.AsSingle()).As<float, T>();
-                }
-                return Vector256<T>.One / x;
-            }
-            public static Vector512<T> Invoke(Vector512<T> x)
-            {
-#if NET9_0_OR_GREATER
-                if (Avx512F.IsSupported)
-                {
-                    if (typeof(T) == typeof(float)) return Avx512F.Reciprocal14(x.AsSingle()).As<float, T>();
-                    if (typeof(T) == typeof(double)) return Avx512F.Reciprocal14(x.AsDouble()).As<double, T>();
-                }
-#endif
-                return Vector512<T>.One / x;
-            }
-        }
-        private readonly struct ReciprocalSqrtEstimateOperator<T> : IUnaryOperator<T, T> where T : IFloatingPointIeee754<T>
-        {
-            public static bool Vectorizable => true;
-            public static T Invoke(T x) => T.ReciprocalSqrtEstimate(x);
-            public static Vector128<T> Invoke(Vector128<T> x)
-            {
-#if NET9_0_OR_GREATER
-                if (Avx512F.VL.IsSupported)
-                {
-                    if (typeof(T) == typeof(float)) return Avx512F.VL.ReciprocalSqrt14(x.AsSingle()).As<float, T>();
-                    if (typeof(T) == typeof(double)) return Avx512F.VL.ReciprocalSqrt14(x.AsDouble()).As<double, T>();
-                }
-#endif
-                if (Sse.IsSupported)
-                {
-                    if (typeof(T) == typeof(float)) return Sse.ReciprocalSqrt(x.AsSingle()).As<float, T>();
-                }
-                if (AdvSimd.IsSupported)
-                {
-                    if (typeof(T) == typeof(float)) return AdvSimd.ReciprocalSquareRootEstimate(x.AsSingle()).As<float, T>();
-                }
-                if (AdvSimd.Arm64.IsSupported)
-                {
-                    if (typeof(T) == typeof(double)) return AdvSimd.Arm64.ReciprocalSquareRootEstimate(x.AsDouble()).As<double, T>();
-                }
-                return Vector128<T>.One / Vector128.Sqrt(x);
-            }
-            public static Vector256<T> Invoke(Vector256<T> x)
-            {
-#if NET9_0_OR_GREATER
-                if (Avx512F.VL.IsSupported)
-                {
-                    if (typeof(T) == typeof(float)) return Avx512F.VL.ReciprocalSqrt14(x.AsSingle()).As<float, T>();
-                    if (typeof(T) == typeof(double)) return Avx512F.VL.ReciprocalSqrt14(x.AsDouble()).As<double, T>();
-                }
-#endif
-                if (Avx.IsSupported)
-                {
-                    if (typeof(T) == typeof(float)) return Avx.ReciprocalSqrt(x.AsSingle()).As<float, T>();
-                }
-                return Vector256<T>.One / Vector256.Sqrt(x);
-            }
-            public static Vector512<T> Invoke(Vector512<T> x)
-            {
-#if NET9_0_OR_GREATER
-                if (Avx512F.IsSupported)
-                {
-                    if (typeof(T) == typeof(float)) return Avx512F.ReciprocalSqrt14(x.AsSingle()).As<float, T>();
-                    if (typeof(T) == typeof(double)) return Avx512F.ReciprocalSqrt14(x.AsDouble()).As<double, T>();
-                }
-#endif
-                return Vector512<T>.One / Vector512.Sqrt(x);
-            }
-        }
-    }
-}

--- a/src/libraries/System.Private.CoreLib/src/System/Convert.cs
+++ b//dev/null
@@ -1,2300 +0,0 @@
-using System.Buffers;
-using System.Buffers.Text;
-using System.Diagnostics;
-using System.Diagnostics.CodeAnalysis;
-using System.Globalization;
-using System.Runtime.CompilerServices;
-using System.Runtime.InteropServices;
-using System.Runtime.Intrinsics;
-using System.Text;
-namespace System
-{
-    [Flags]
-    public enum Base64FormattingOptions
-    {
-        None = 0,
-        InsertLineBreaks = 1
-    }
-    public static partial class Convert
-    {
-        private const int Base64LineBreakPosition = 76;
-        private const int Base64VectorizationLengthThreshold = 16;
-        public static readonly object DBNull = System.DBNull.Value;
-        public static TypeCode GetTypeCode(object? value)
-        {
-            if (value == null) return TypeCode.Empty;
-            if (value is IConvertible temp)
-            {
-                return temp.GetTypeCode();
-            }
-            return TypeCode.Object;
-        }
-        public static bool IsDBNull([NotNullWhen(true)] object? value)
-        {
-            if (value == System.DBNull.Value) return true;
-            return value is IConvertible convertible ? convertible.GetTypeCode() == TypeCode.DBNull : false;
-        }
-        [return: NotNullIfNotNull(nameof(value))]
-        public static object? ChangeType(object? value, TypeCode typeCode)
-        {
-            return ChangeType(value, typeCode, CultureInfo.CurrentCulture);
-        }
-        [return: NotNullIfNotNull(nameof(value))]
-        public static object? ChangeType(object? value, TypeCode typeCode, IFormatProvider? provider)
-        {
-            if (value == null && (typeCode == TypeCode.Empty || typeCode == TypeCode.String || typeCode == TypeCode.Object))
-            {
-                return null;
-            }
-            if (value is not IConvertible v)
-            {
-                throw new InvalidCastException(SR.InvalidCast_IConvertible);
-            }
-            return typeCode switch
-            {
-                TypeCode.Boolean => v.ToBoolean(provider),
-                TypeCode.Char => v.ToChar(provider),
-                TypeCode.SByte => v.ToSByte(provider),
-                TypeCode.Byte => v.ToByte(provider),
-                TypeCode.Int16 => v.ToInt16(provider),
-                TypeCode.UInt16 => v.ToUInt16(provider),
-                TypeCode.Int32 => v.ToInt32(provider),
-                TypeCode.UInt32 => v.ToUInt32(provider),
-                TypeCode.Int64 => v.ToInt64(provider),
-                TypeCode.UInt64 => v.ToUInt64(provider),
-                TypeCode.Single => v.ToSingle(provider),
-                TypeCode.Double => v.ToDouble(provider),
-                TypeCode.Decimal => v.ToDecimal(provider),
-                TypeCode.DateTime => v.ToDateTime(provider),
-                TypeCode.String => v.ToString(provider),
-                TypeCode.Object => value,
-                TypeCode.DBNull => throw new InvalidCastException(SR.InvalidCast_DBNull),
-                TypeCode.Empty => throw new InvalidCastException(SR.InvalidCast_Empty),
-                _ => throw new ArgumentException(SR.Arg_UnknownTypeCode),
-            };
-        }
-        internal static object DefaultToType(IConvertible value, Type targetType, IFormatProvider? provider)
-        {
-            ArgumentNullException.ThrowIfNull(targetType);
-            Debug.Assert(value != null, "[Convert.DefaultToType]value!=null");
-            if (ReferenceEquals(value.GetType(), targetType))
-            {
-                return value;
-            }
-            if (ReferenceEquals(targetType, typeof(bool)))
-                return value.ToBoolean(provider);
-            if (ReferenceEquals(targetType, typeof(char)))
-                return value.ToChar(provider);
-            if (ReferenceEquals(targetType, typeof(sbyte)))
-                return value.ToSByte(provider);
-            if (ReferenceEquals(targetType, typeof(byte)))
-                return value.ToByte(provider);
-            if (ReferenceEquals(targetType, typeof(short)))
-                return value.ToInt16(provider);
-            if (ReferenceEquals(targetType, typeof(ushort)))
-                return value.ToUInt16(provider);
-            if (ReferenceEquals(targetType, typeof(int)))
-                return value.ToInt32(provider);
-            if (ReferenceEquals(targetType, typeof(uint)))
-                return value.ToUInt32(provider);
-            if (ReferenceEquals(targetType, typeof(long)))
-                return value.ToInt64(provider);
-            if (ReferenceEquals(targetType, typeof(ulong)))
-                return value.ToUInt64(provider);
-            if (ReferenceEquals(targetType, typeof(float)))
-                return value.ToSingle(provider);
-            if (ReferenceEquals(targetType, typeof(double)))
-                return value.ToDouble(provider);
-            if (ReferenceEquals(targetType, typeof(decimal)))
-                return value.ToDecimal(provider);
-            if (ReferenceEquals(targetType, typeof(DateTime)))
-                return value.ToDateTime(provider);
-            if (ReferenceEquals(targetType, typeof(string)))
-                return value.ToString(provider);
-            if (ReferenceEquals(targetType, typeof(object)))
-                return (object)value;
-            if (ReferenceEquals(targetType, typeof(Enum)))
-                return (Enum)value;
-            if (ReferenceEquals(targetType, typeof(DBNull)))
-                throw new InvalidCastException(SR.InvalidCast_DBNull);
-            if (ReferenceEquals(targetType, typeof(Empty)))
-                throw new InvalidCastException(SR.InvalidCast_Empty);
-            throw new InvalidCastException(SR.Format(SR.InvalidCast_FromTo, value.GetType().FullName, targetType.FullName));
-        }
-        [return: NotNullIfNotNull(nameof(value))]
-        public static object? ChangeType(object? value, Type conversionType)
-        {
-            return ChangeType(value, conversionType, CultureInfo.CurrentCulture);
-        }
-        [return: NotNullIfNotNull(nameof(value))]
-        public static object? ChangeType(object? value, Type conversionType, IFormatProvider? provider)
-        {
-            ArgumentNullException.ThrowIfNull(conversionType);
-            if (value == null)
-            {
-                if (conversionType.IsValueType)
-                {
-                    throw new InvalidCastException(SR.InvalidCast_CannotCastNullToValueType);
-                }
-                return null;
-            }
-            if (value is not IConvertible ic)
-            {
-                if (value.GetType() == conversionType)
-                {
-                    return value;
-                }
-                throw new InvalidCastException(SR.InvalidCast_IConvertible);
-            }
-            if (ReferenceEquals(conversionType, typeof(bool)))
-                return ic.ToBoolean(provider);
-            if (ReferenceEquals(conversionType, typeof(char)))
-                return ic.ToChar(provider);
-            if (ReferenceEquals(conversionType, typeof(sbyte)))
-                return ic.ToSByte(provider);
-            if (ReferenceEquals(conversionType, typeof(byte)))
-                return ic.ToByte(provider);
-            if (ReferenceEquals(conversionType, typeof(short)))
-                return ic.ToInt16(provider);
-            if (ReferenceEquals(conversionType, typeof(ushort)))
-                return ic.ToUInt16(provider);
-            if (ReferenceEquals(conversionType, typeof(int)))
-                return ic.ToInt32(provider);
-            if (ReferenceEquals(conversionType, typeof(uint)))
-                return ic.ToUInt32(provider);
-            if (ReferenceEquals(conversionType, typeof(long)))
-                return ic.ToInt64(provider);
-            if (ReferenceEquals(conversionType, typeof(ulong)))
-                return ic.ToUInt64(provider);
-            if (ReferenceEquals(conversionType, typeof(float)))
-                return ic.ToSingle(provider);
-            if (ReferenceEquals(conversionType, typeof(double)))
-                return ic.ToDouble(provider);
-            if (ReferenceEquals(conversionType, typeof(decimal)))
-                return ic.ToDecimal(provider);
-            if (ReferenceEquals(conversionType, typeof(DateTime)))
-                return ic.ToDateTime(provider);
-            if (ReferenceEquals(conversionType, typeof(string)))
-                return ic.ToString(provider);
-            if (ReferenceEquals(conversionType, typeof(object)))
-                return (object)value;
-            return ic.ToType(conversionType, provider);
-        }
-        [DoesNotReturn]
-        private static void ThrowCharOverflowException() { throw new OverflowException(SR.Overflow_Char); }
-        [DoesNotReturn]
-        private static void ThrowByteOverflowException() { throw new OverflowException(SR.Overflow_Byte); }
-        [DoesNotReturn]
-        private static void ThrowSByteOverflowException() { throw new OverflowException(SR.Overflow_SByte); }
-        [DoesNotReturn]
-        private static void ThrowInt16OverflowException() { throw new OverflowException(SR.Overflow_Int16); }
-        [DoesNotReturn]
-        private static void ThrowUInt16OverflowException() { throw new OverflowException(SR.Overflow_UInt16); }
-        [DoesNotReturn]
-        private static void ThrowInt32OverflowException() { throw new OverflowException(SR.Overflow_Int32); }
-        [DoesNotReturn]
-        private static void ThrowUInt32OverflowException() { throw new OverflowException(SR.Overflow_UInt32); }
-        [DoesNotReturn]
-        private static void ThrowInt64OverflowException() { throw new OverflowException(SR.Overflow_Int64); }
-        [DoesNotReturn]
-        private static void ThrowUInt64OverflowException() { throw new OverflowException(SR.Overflow_UInt64); }
-        public static bool ToBoolean([NotNullWhen(true)] object? value)
-        {
-            return value == null ? false : ((IConvertible)value).ToBoolean(null);
-        }
-        public static bool ToBoolean([NotNullWhen(true)] object? value, IFormatProvider? provider)
-        {
-            return value == null ? false : ((IConvertible)value).ToBoolean(provider);
-        }
-        public static bool ToBoolean(bool value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static bool ToBoolean(sbyte value)
-        {
-            return value != 0;
-        }
-        public static bool ToBoolean(char value)
-        {
-            return ((IConvertible)value).ToBoolean(null);
-        }
-        public static bool ToBoolean(byte value)
-        {
-            return value != 0;
-        }
-        public static bool ToBoolean(short value)
-        {
-            return value != 0;
-        }
-        [CLSCompliant(false)]
-        public static bool ToBoolean(ushort value)
-        {
-            return value != 0;
-        }
-        public static bool ToBoolean(int value)
-        {
-            return value != 0;
-        }
-        [CLSCompliant(false)]
-        public static bool ToBoolean(uint value)
-        {
-            return value != 0;
-        }
-        public static bool ToBoolean(long value)
-        {
-            return value != 0;
-        }
-        [CLSCompliant(false)]
-        public static bool ToBoolean(ulong value)
-        {
-            return value != 0;
-        }
-        public static bool ToBoolean([NotNullWhen(true)] string? value)
-        {
-            if (value == null)
-                return false;
-            return bool.Parse(value);
-        }
-        public static bool ToBoolean([NotNullWhen(true)] string? value, IFormatProvider? provider)
-        {
-            if (value == null)
-                return false;
-            return bool.Parse(value);
-        }
-        public static bool ToBoolean(float value)
-        {
-            return value != 0;
-        }
-        public static bool ToBoolean(double value)
-        {
-            return value != 0;
-        }
-        public static bool ToBoolean(decimal value)
-        {
-            return value != 0;
-        }
-        public static bool ToBoolean(DateTime value)
-        {
-            return ((IConvertible)value).ToBoolean(null);
-        }
-        public static char ToChar(object? value)
-        {
-            return value == null ? (char)0 : ((IConvertible)value).ToChar(null);
-        }
-        public static char ToChar(object? value, IFormatProvider? provider)
-        {
-            return value == null ? (char)0 : ((IConvertible)value).ToChar(provider);
-        }
-        public static char ToChar(bool value)
-        {
-            return ((IConvertible)value).ToChar(null);
-        }
-        public static char ToChar(char value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static char ToChar(sbyte value)
-        {
-            if (value < 0) ThrowCharOverflowException();
-            return (char)value;
-        }
-        public static char ToChar(byte value)
-        {
-            return (char)value;
-        }
-        public static char ToChar(short value)
-        {
-            if (value < 0) ThrowCharOverflowException();
-            return (char)value;
-        }
-        [CLSCompliant(false)]
-        public static char ToChar(ushort value)
-        {
-            return (char)value;
-        }
-        public static char ToChar(int value) => ToChar((uint)value);
-        [CLSCompliant(false)]
-        public static char ToChar(uint value)
-        {
-            if (value > char.MaxValue) ThrowCharOverflowException();
-            return (char)value;
-        }
-        public static char ToChar(long value) => ToChar((ulong)value);
-        [CLSCompliant(false)]
-        public static char ToChar(ulong value)
-        {
-            if (value > char.MaxValue) ThrowCharOverflowException();
-            return (char)value;
-        }
-        public static char ToChar(string value)
-        {
-            return ToChar(value, null);
-        }
-        public static char ToChar(string value, IFormatProvider? provider)
-        {
-            ArgumentNullException.ThrowIfNull(value);
-            if (value.Length != 1)
-                throw new FormatException(SR.Format_NeedSingleChar);
-            return value[0];
-        }
-        public static char ToChar(float value)
-        {
-            return ((IConvertible)value).ToChar(null);
-        }
-        public static char ToChar(double value)
-        {
-            return ((IConvertible)value).ToChar(null);
-        }
-        public static char ToChar(decimal value)
-        {
-            return ((IConvertible)value).ToChar(null);
-        }
-        public static char ToChar(DateTime value)
-        {
-            return ((IConvertible)value).ToChar(null);
-        }
-        [CLSCompliant(false)]
-        public static sbyte ToSByte(object? value)
-        {
-            return value == null ? (sbyte)0 : ((IConvertible)value).ToSByte(null);
-        }
-        [CLSCompliant(false)]
-        public static sbyte ToSByte(object? value, IFormatProvider? provider)
-        {
-            return value == null ? (sbyte)0 : ((IConvertible)value).ToSByte(provider);
-        }
-        [CLSCompliant(false)]
-        public static sbyte ToSByte(bool value)
-        {
-            return value ? (sbyte)bool.True : (sbyte)bool.False;
-        }
-        [CLSCompliant(false)]
-        public static sbyte ToSByte(sbyte value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static sbyte ToSByte(char value)
-        {
-            if (value > sbyte.MaxValue) ThrowSByteOverflowException();
-            return (sbyte)value;
-        }
-        [CLSCompliant(false)]
-        public static sbyte ToSByte(byte value)
-        {
-            if (value > sbyte.MaxValue) ThrowSByteOverflowException();
-            return (sbyte)value;
-        }
-        [CLSCompliant(false)]
-        public static sbyte ToSByte(short value)
-        {
-            if (value < sbyte.MinValue || value > sbyte.MaxValue) ThrowSByteOverflowException();
-            return (sbyte)value;
-        }
-        [CLSCompliant(false)]
-        public static sbyte ToSByte(ushort value)
-        {
-            if (value > sbyte.MaxValue) ThrowSByteOverflowException();
-            return (sbyte)value;
-        }
-        [CLSCompliant(false)]
-        public static sbyte ToSByte(int value)
-        {
-            if (value < sbyte.MinValue || value > sbyte.MaxValue) ThrowSByteOverflowException();
-            return (sbyte)value;
-        }
-        [CLSCompliant(false)]
-        public static sbyte ToSByte(uint value)
-        {
-            if (value > (uint)sbyte.MaxValue) ThrowSByteOverflowException();
-            return (sbyte)value;
-        }
-        [CLSCompliant(false)]
-        public static sbyte ToSByte(long value)
-        {
-            if (value < sbyte.MinValue || value > sbyte.MaxValue) ThrowSByteOverflowException();
-            return (sbyte)value;
-        }
-        [CLSCompliant(false)]
-        public static sbyte ToSByte(ulong value)
-        {
-            if (value > (ulong)sbyte.MaxValue) ThrowSByteOverflowException();
-            return (sbyte)value;
-        }
-        [CLSCompliant(false)]
-        public static sbyte ToSByte(float value)
-        {
-            return ToSByte((double)value);
-        }
-        [CLSCompliant(false)]
-        public static sbyte ToSByte(double value)
-        {
-            return ToSByte(ToInt32(value));
-        }
-        [CLSCompliant(false)]
-        public static sbyte ToSByte(decimal value)
-        {
-            return decimal.ToSByte(decimal.Round(value, 0));
-        }
-        [CLSCompliant(false)]
-        public static sbyte ToSByte(string? value)
-        {
-            if (value == null)
-                return 0;
-            return sbyte.Parse(value);
-        }
-        [CLSCompliant(false)]
-        public static sbyte ToSByte(string value, IFormatProvider? provider)
-        {
-            return sbyte.Parse(value, provider);
-        }
-        [CLSCompliant(false)]
-        public static sbyte ToSByte(DateTime value)
-        {
-            return ((IConvertible)value).ToSByte(null);
-        }
-        public static byte ToByte(object? value)
-        {
-            return value == null ? (byte)0 : ((IConvertible)value).ToByte(null);
-        }
-        public static byte ToByte(object? value, IFormatProvider? provider)
-        {
-            return value == null ? (byte)0 : ((IConvertible)value).ToByte(provider);
-        }
-        public static byte ToByte(bool value)
-        {
-            return value ? (byte)bool.True : (byte)bool.False;
-        }
-        public static byte ToByte(byte value)
-        {
-            return value;
-        }
-        public static byte ToByte(char value)
-        {
-            if (value > byte.MaxValue) ThrowByteOverflowException();
-            return (byte)value;
-        }
-        [CLSCompliant(false)]
-        public static byte ToByte(sbyte value)
-        {
-            if (value < 0) ThrowByteOverflowException();
-            return (byte)value;
-        }
-        public static byte ToByte(short value)
-        {
-            if ((uint)value > byte.MaxValue) ThrowByteOverflowException();
-            return (byte)value;
-        }
-        [CLSCompliant(false)]
-        public static byte ToByte(ushort value)
-        {
-            if (value > byte.MaxValue) ThrowByteOverflowException();
-            return (byte)value;
-        }
-        public static byte ToByte(int value) => ToByte((uint)value);
-        [CLSCompliant(false)]
-        public static byte ToByte(uint value)
-        {
-            if (value > byte.MaxValue) ThrowByteOverflowException();
-            return (byte)value;
-        }
-        public static byte ToByte(long value) => ToByte((ulong)value);
-        [CLSCompliant(false)]
-        public static byte ToByte(ulong value)
-        {
-            if (value > byte.MaxValue) ThrowByteOverflowException();
-            return (byte)value;
-        }
-        public static byte ToByte(float value)
-        {
-            return ToByte((double)value);
-        }
-        public static byte ToByte(double value)
-        {
-            return ToByte(ToInt32(value));
-        }
-        public static byte ToByte(decimal value)
-        {
-            return decimal.ToByte(decimal.Round(value, 0));
-        }
-        public static byte ToByte(string? value)
-        {
-            if (value == null)
-                return 0;
-            return byte.Parse(value);
-        }
-        public static byte ToByte(string? value, IFormatProvider? provider)
-        {
-            if (value == null)
-                return 0;
-            return byte.Parse(value, provider);
-        }
-        public static byte ToByte(DateTime value)
-        {
-            return ((IConvertible)value).ToByte(null);
-        }
-        public static short ToInt16(object? value)
-        {
-            return value == null ? (short)0 : ((IConvertible)value).ToInt16(null);
-        }
-        public static short ToInt16(object? value, IFormatProvider? provider)
-        {
-            return value == null ? (short)0 : ((IConvertible)value).ToInt16(provider);
-        }
-        public static short ToInt16(bool value)
-        {
-            return value ? (short)bool.True : (short)bool.False;
-        }
-        public static short ToInt16(char value)
-        {
-            if (value > short.MaxValue) ThrowInt16OverflowException();
-            return (short)value;
-        }
-        [CLSCompliant(false)]
-        public static short ToInt16(sbyte value)
-        {
-            return value;
-        }
-        public static short ToInt16(byte value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static short ToInt16(ushort value)
-        {
-            if (value > short.MaxValue) ThrowInt16OverflowException();
-            return (short)value;
-        }
-        public static short ToInt16(int value)
-        {
-            if (value < short.MinValue || value > short.MaxValue) ThrowInt16OverflowException();
-            return (short)value;
-        }
-        [CLSCompliant(false)]
-        public static short ToInt16(uint value)
-        {
-            if (value > (uint)short.MaxValue) ThrowInt16OverflowException();
-            return (short)value;
-        }
-        public static short ToInt16(short value)
-        {
-            return value;
-        }
-        public static short ToInt16(long value)
-        {
-            if (value < short.MinValue || value > short.MaxValue) ThrowInt16OverflowException();
-            return (short)value;
-        }
-        [CLSCompliant(false)]
-        public static short ToInt16(ulong value)
-        {
-            if (value > (ulong)short.MaxValue) ThrowInt16OverflowException();
-            return (short)value;
-        }
-        public static short ToInt16(float value)
-        {
-            return ToInt16((double)value);
-        }
-        public static short ToInt16(double value)
-        {
-            return ToInt16(ToInt32(value));
-        }
-        public static short ToInt16(decimal value)
-        {
-            return decimal.ToInt16(decimal.Round(value, 0));
-        }
-        public static short ToInt16(string? value)
-        {
-            if (value == null)
-                return 0;
-            return short.Parse(value);
-        }
-        public static short ToInt16(string? value, IFormatProvider? provider)
-        {
-            if (value == null)
-                return 0;
-            return short.Parse(value, provider);
-        }
-        public static short ToInt16(DateTime value)
-        {
-            return ((IConvertible)value).ToInt16(null);
-        }
-        [CLSCompliant(false)]
-        public static ushort ToUInt16(object? value)
-        {
-            return value == null ? (ushort)0 : ((IConvertible)value).ToUInt16(null);
-        }
-        [CLSCompliant(false)]
-        public static ushort ToUInt16(object? value, IFormatProvider? provider)
-        {
-            return value == null ? (ushort)0 : ((IConvertible)value).ToUInt16(provider);
-        }
-        [CLSCompliant(false)]
-        public static ushort ToUInt16(bool value)
-        {
-            return value ? (ushort)bool.True : (ushort)bool.False;
-        }
-        [CLSCompliant(false)]
-        public static ushort ToUInt16(char value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static ushort ToUInt16(sbyte value)
-        {
-            if (value < 0) ThrowUInt16OverflowException();
-            return (ushort)value;
-        }
-        [CLSCompliant(false)]
-        public static ushort ToUInt16(byte value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static ushort ToUInt16(short value)
-        {
-            if (value < 0) ThrowUInt16OverflowException();
-            return (ushort)value;
-        }
-        [CLSCompliant(false)]
-        public static ushort ToUInt16(int value) => ToUInt16((uint)value);
-        [CLSCompliant(false)]
-        public static ushort ToUInt16(ushort value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static ushort ToUInt16(uint value)
-        {
-            if (value > ushort.MaxValue) ThrowUInt16OverflowException();
-            return (ushort)value;
-        }
-        [CLSCompliant(false)]
-        public static ushort ToUInt16(long value) => ToUInt16((ulong)value);
-        [CLSCompliant(false)]
-        public static ushort ToUInt16(ulong value)
-        {
-            if (value > ushort.MaxValue) ThrowUInt16OverflowException();
-            return (ushort)value;
-        }
-        [CLSCompliant(false)]
-        public static ushort ToUInt16(float value)
-        {
-            return ToUInt16((double)value);
-        }
-        [CLSCompliant(false)]
-        public static ushort ToUInt16(double value)
-        {
-            return ToUInt16(ToInt32(value));
-        }
-        [CLSCompliant(false)]
-        public static ushort ToUInt16(decimal value)
-        {
-            return decimal.ToUInt16(decimal.Round(value, 0));
-        }
-        [CLSCompliant(false)]
-        public static ushort ToUInt16(string? value)
-        {
-            if (value == null)
-                return 0;
-            return ushort.Parse(value);
-        }
-        [CLSCompliant(false)]
-        public static ushort ToUInt16(string? value, IFormatProvider? provider)
-        {
-            if (value == null)
-                return 0;
-            return ushort.Parse(value, provider);
-        }
-        [CLSCompliant(false)]
-        public static ushort ToUInt16(DateTime value)
-        {
-            return ((IConvertible)value).ToUInt16(null);
-        }
-        public static int ToInt32(object? value)
-        {
-            return value == null ? 0 : ((IConvertible)value).ToInt32(null);
-        }
-        public static int ToInt32(object? value, IFormatProvider? provider)
-        {
-            return value == null ? 0 : ((IConvertible)value).ToInt32(provider);
-        }
-        public static int ToInt32(bool value)
-        {
-            return value ? bool.True : bool.False;
-        }
-        public static int ToInt32(char value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static int ToInt32(sbyte value)
-        {
-            return value;
-        }
-        public static int ToInt32(byte value)
-        {
-            return value;
-        }
-        public static int ToInt32(short value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static int ToInt32(ushort value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static int ToInt32(uint value)
-        {
-            if ((int)value < 0) ThrowInt32OverflowException();
-            return (int)value;
-        }
-        public static int ToInt32(int value)
-        {
-            return value;
-        }
-        public static int ToInt32(long value)
-        {
-            if (value < int.MinValue || value > int.MaxValue) ThrowInt32OverflowException();
-            return (int)value;
-        }
-        [CLSCompliant(false)]
-        public static int ToInt32(ulong value)
-        {
-            if (value > int.MaxValue) ThrowInt32OverflowException();
-            return (int)value;
-        }
-        public static int ToInt32(float value)
-        {
-            return ToInt32((double)value);
-        }
-        public static int ToInt32(double value)
-        {
-            if (value >= 0)
-            {
-                if (value < 2147483647.5)
-                {
-                    int result = (int)value;
-                    double dif = value - result;
-                    if (dif > 0.5 || dif == 0.5 && (result & 1) != 0) result++;
-                    return result;
-                }
-            }
-            else
-            {
-                if (value >= -2147483648.5)
-                {
-                    int result = (int)value;
-                    double dif = value - result;
-                    if (dif < -0.5 || dif == -0.5 && (result & 1) != 0) result--;
-                    return result;
-                }
-            }
-            throw new OverflowException(SR.Overflow_Int32);
-        }
-        public static int ToInt32(decimal value)
-        {
-            return decimal.ToInt32(decimal.Round(value, 0));
-        }
-        public static int ToInt32(string? value)
-        {
-            if (value == null)
-                return 0;
-            return int.Parse(value);
-        }
-        public static int ToInt32(string? value, IFormatProvider? provider)
-        {
-            if (value == null)
-                return 0;
-            return int.Parse(value, provider);
-        }
-        public static int ToInt32(DateTime value)
-        {
-            return ((IConvertible)value).ToInt32(null);
-        }
-        [CLSCompliant(false)]
-        public static uint ToUInt32(object? value)
-        {
-            return value == null ? 0 : ((IConvertible)value).ToUInt32(null);
-        }
-        [CLSCompliant(false)]
-        public static uint ToUInt32(object? value, IFormatProvider? provider)
-        {
-            return value == null ? 0 : ((IConvertible)value).ToUInt32(provider);
-        }
-        [CLSCompliant(false)]
-        public static uint ToUInt32(bool value)
-        {
-            return value ? (uint)bool.True : (uint)bool.False;
-        }
-        [CLSCompliant(false)]
-        public static uint ToUInt32(char value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static uint ToUInt32(sbyte value)
-        {
-            if (value < 0) ThrowUInt32OverflowException();
-            return (uint)value;
-        }
-        [CLSCompliant(false)]
-        public static uint ToUInt32(byte value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static uint ToUInt32(short value)
-        {
-            if (value < 0) ThrowUInt32OverflowException();
-            return (uint)value;
-        }
-        [CLSCompliant(false)]
-        public static uint ToUInt32(ushort value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static uint ToUInt32(int value)
-        {
-            if (value < 0) ThrowUInt32OverflowException();
-            return (uint)value;
-        }
-        [CLSCompliant(false)]
-        public static uint ToUInt32(uint value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static uint ToUInt32(long value) => ToUInt32((ulong)value);
-        [CLSCompliant(false)]
-        public static uint ToUInt32(ulong value)
-        {
-            if (value > uint.MaxValue) ThrowUInt32OverflowException();
-            return (uint)value;
-        }
-        [CLSCompliant(false)]
-        public static uint ToUInt32(float value)
-        {
-            return ToUInt32((double)value);
-        }
-        [CLSCompliant(false)]
-        public static uint ToUInt32(double value)
-        {
-            if (value >= -0.5 && value < 4294967295.5)
-            {
-                uint result = (uint)value;
-                double dif = value - result;
-                if (dif > 0.5 || dif == 0.5 && (result & 1) != 0) result++;
-                return result;
-            }
-            throw new OverflowException(SR.Overflow_UInt32);
-        }
-        [CLSCompliant(false)]
-        public static uint ToUInt32(decimal value)
-        {
-            return decimal.ToUInt32(decimal.Round(value, 0));
-        }
-        [CLSCompliant(false)]
-        public static uint ToUInt32(string? value)
-        {
-            if (value == null)
-                return 0;
-            return uint.Parse(value);
-        }
-        [CLSCompliant(false)]
-        public static uint ToUInt32(string? value, IFormatProvider? provider)
-        {
-            if (value == null)
-                return 0;
-            return uint.Parse(value, provider);
-        }
-        [CLSCompliant(false)]
-        public static uint ToUInt32(DateTime value)
-        {
-            return ((IConvertible)value).ToUInt32(null);
-        }
-        public static long ToInt64(object? value)
-        {
-            return value == null ? 0 : ((IConvertible)value).ToInt64(null);
-        }
-        public static long ToInt64(object? value, IFormatProvider? provider)
-        {
-            return value == null ? 0 : ((IConvertible)value).ToInt64(provider);
-        }
-        public static long ToInt64(bool value)
-        {
-            return value ? bool.True : bool.False;
-        }
-        public static long ToInt64(char value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static long ToInt64(sbyte value)
-        {
-            return value;
-        }
-        public static long ToInt64(byte value)
-        {
-            return value;
-        }
-        public static long ToInt64(short value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static long ToInt64(ushort value)
-        {
-            return value;
-        }
-        public static long ToInt64(int value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static long ToInt64(uint value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static long ToInt64(ulong value)
-        {
-            if ((long)value < 0) ThrowInt64OverflowException();
-            return (long)value;
-        }
-        public static long ToInt64(long value)
-        {
-            return value;
-        }
-        public static long ToInt64(float value)
-        {
-            return ToInt64((double)value);
-        }
-        public static long ToInt64(double value)
-        {
-            return checked((long)Math.Round(value));
-        }
-        public static long ToInt64(decimal value)
-        {
-            return decimal.ToInt64(decimal.Round(value, 0));
-        }
-        public static long ToInt64(string? value)
-        {
-            if (value == null)
-                return 0;
-            return long.Parse(value);
-        }
-        public static long ToInt64(string? value, IFormatProvider? provider)
-        {
-            if (value == null)
-                return 0;
-            return long.Parse(value, provider);
-        }
-        public static long ToInt64(DateTime value)
-        {
-            return ((IConvertible)value).ToInt64(null);
-        }
-        [CLSCompliant(false)]
-        public static ulong ToUInt64(object? value)
-        {
-            return value == null ? 0 : ((IConvertible)value).ToUInt64(null);
-        }
-        [CLSCompliant(false)]
-        public static ulong ToUInt64(object? value, IFormatProvider? provider)
-        {
-            return value == null ? 0 : ((IConvertible)value).ToUInt64(provider);
-        }
-        [CLSCompliant(false)]
-        public static ulong ToUInt64(bool value)
-        {
-            return value ? (ulong)bool.True : (ulong)bool.False;
-        }
-        [CLSCompliant(false)]
-        public static ulong ToUInt64(char value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static ulong ToUInt64(sbyte value)
-        {
-            if (value < 0) ThrowUInt64OverflowException();
-            return (ulong)value;
-        }
-        [CLSCompliant(false)]
-        public static ulong ToUInt64(byte value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static ulong ToUInt64(short value)
-        {
-            if (value < 0) ThrowUInt64OverflowException();
-            return (ulong)value;
-        }
-        [CLSCompliant(false)]
-        public static ulong ToUInt64(ushort value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static ulong ToUInt64(int value)
-        {
-            if (value < 0) ThrowUInt64OverflowException();
-            return (ulong)value;
-        }
-        [CLSCompliant(false)]
-        public static ulong ToUInt64(uint value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static ulong ToUInt64(long value)
-        {
-            if (value < 0) ThrowUInt64OverflowException();
-            return (ulong)value;
-        }
-        [CLSCompliant(false)]
-        public static ulong ToUInt64(ulong value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static ulong ToUInt64(float value)
-        {
-            return ToUInt64((double)value);
-        }
-        [CLSCompliant(false)]
-        public static ulong ToUInt64(double value)
-        {
-            return checked((ulong)Math.Round(value));
-        }
-        [CLSCompliant(false)]
-        public static ulong ToUInt64(decimal value)
-        {
-            return decimal.ToUInt64(decimal.Round(value, 0));
-        }
-        [CLSCompliant(false)]
-        public static ulong ToUInt64(string? value)
-        {
-            if (value == null)
-                return 0;
-            return ulong.Parse(value);
-        }
-        [CLSCompliant(false)]
-        public static ulong ToUInt64(string? value, IFormatProvider? provider)
-        {
-            if (value == null)
-                return 0;
-            return ulong.Parse(value, provider);
-        }
-        [CLSCompliant(false)]
-        public static ulong ToUInt64(DateTime value)
-        {
-            return ((IConvertible)value).ToUInt64(null);
-        }
-        public static float ToSingle(object? value)
-        {
-            return value == null ? 0 : ((IConvertible)value).ToSingle(null);
-        }
-        public static float ToSingle(object? value, IFormatProvider? provider)
-        {
-            return value == null ? 0 : ((IConvertible)value).ToSingle(provider);
-        }
-        [CLSCompliant(false)]
-        public static float ToSingle(sbyte value)
-        {
-            return value;
-        }
-        public static float ToSingle(byte value)
-        {
-            return value;
-        }
-        public static float ToSingle(char value)
-        {
-            return ((IConvertible)value).ToSingle(null);
-        }
-        public static float ToSingle(short value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static float ToSingle(ushort value)
-        {
-            return value;
-        }
-        public static float ToSingle(int value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static float ToSingle(uint value)
-        {
-            return value;
-        }
-        public static float ToSingle(long value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static float ToSingle(ulong value)
-        {
-            return value;
-        }
-        public static float ToSingle(float value)
-        {
-            return value;
-        }
-        public static float ToSingle(double value)
-        {
-            return (float)value;
-        }
-        public static float ToSingle(decimal value)
-        {
-            return (float)value;
-        }
-        public static float ToSingle(string? value)
-        {
-            if (value == null)
-                return 0;
-            return float.Parse(value);
-        }
-        public static float ToSingle(string? value, IFormatProvider? provider)
-        {
-            if (value == null)
-                return 0;
-            return float.Parse(value, provider);
-        }
-        public static float ToSingle(bool value)
-        {
-            return value ? bool.True : bool.False;
-        }
-        public static float ToSingle(DateTime value)
-        {
-            return ((IConvertible)value).ToSingle(null);
-        }
-        public static double ToDouble(object? value)
-        {
-            return value == null ? 0 : ((IConvertible)value).ToDouble(null);
-        }
-        public static double ToDouble(object? value, IFormatProvider? provider)
-        {
-            return value == null ? 0 : ((IConvertible)value).ToDouble(provider);
-        }
-        [CLSCompliant(false)]
-        public static double ToDouble(sbyte value)
-        {
-            return value;
-        }
-        public static double ToDouble(byte value)
-        {
-            return value;
-        }
-        public static double ToDouble(short value)
-        {
-            return value;
-        }
-        public static double ToDouble(char value)
-        {
-            return ((IConvertible)value).ToDouble(null);
-        }
-        [CLSCompliant(false)]
-        public static double ToDouble(ushort value)
-        {
-            return value;
-        }
-        public static double ToDouble(int value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static double ToDouble(uint value)
-        {
-            return value;
-        }
-        public static double ToDouble(long value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static double ToDouble(ulong value)
-        {
-            return value;
-        }
-        public static double ToDouble(float value)
-        {
-            return value;
-        }
-        public static double ToDouble(double value)
-        {
-            return value;
-        }
-        public static double ToDouble(decimal value)
-        {
-            return (double)value;
-        }
-        public static double ToDouble(string? value)
-        {
-            if (value == null)
-                return 0;
-            return double.Parse(value);
-        }
-        public static double ToDouble(string? value, IFormatProvider? provider)
-        {
-            if (value == null)
-                return 0;
-            return double.Parse(value, provider);
-        }
-        public static double ToDouble(bool value)
-        {
-            return value ? bool.True : bool.False;
-        }
-        public static double ToDouble(DateTime value)
-        {
-            return ((IConvertible)value).ToDouble(null);
-        }
-        public static decimal ToDecimal(object? value)
-        {
-            return value == null ? 0 : ((IConvertible)value).ToDecimal(null);
-        }
-        public static decimal ToDecimal(object? value, IFormatProvider? provider)
-        {
-            return value == null ? 0 : ((IConvertible)value).ToDecimal(provider);
-        }
-        [CLSCompliant(false)]
-        public static decimal ToDecimal(sbyte value)
-        {
-            return value;
-        }
-        public static decimal ToDecimal(byte value)
-        {
-            return value;
-        }
-        public static decimal ToDecimal(char value)
-        {
-            return ((IConvertible)value).ToDecimal(null);
-        }
-        public static decimal ToDecimal(short value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static decimal ToDecimal(ushort value)
-        {
-            return value;
-        }
-        public static decimal ToDecimal(int value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static decimal ToDecimal(uint value)
-        {
-            return value;
-        }
-        public static decimal ToDecimal(long value)
-        {
-            return value;
-        }
-        [CLSCompliant(false)]
-        public static decimal ToDecimal(ulong value)
-        {
-            return value;
-        }
-        public static decimal ToDecimal(float value)
-        {
-            return (decimal)value;
-        }
-        public static decimal ToDecimal(double value)
-        {
-            return (decimal)value;
-        }
-        public static decimal ToDecimal(string? value)
-        {
-            if (value == null)
-                return 0m;
-            return decimal.Parse(value);
-        }
-        public static decimal ToDecimal(string? value, IFormatProvider? provider)
-        {
-            if (value == null)
-                return 0m;
-            return decimal.Parse(value, provider);
-        }
-        public static decimal ToDecimal(decimal value)
-        {
-            return value;
-        }
-        public static decimal ToDecimal(bool value)
-        {
-            return value ? bool.True : bool.False;
-        }
-        public static decimal ToDecimal(DateTime value)
-        {
-            return ((IConvertible)value).ToDecimal(null);
-        }
-        public static DateTime ToDateTime(DateTime value)
-        {
-            return value;
-        }
-        public static DateTime ToDateTime(object? value)
-        {
-            return value == null ? DateTime.MinValue : ((IConvertible)value).ToDateTime(null);
-        }
-        public static DateTime ToDateTime(object? value, IFormatProvider? provider)
-        {
-            return value == null ? DateTime.MinValue : ((IConvertible)value).ToDateTime(provider);
-        }
-        public static DateTime ToDateTime(string? value)
-        {
-            if (value == null)
-                return new DateTime(0);
-            return DateTime.Parse(value);
-        }
-        public static DateTime ToDateTime(string? value, IFormatProvider? provider)
-        {
-            if (value == null)
-                return new DateTime(0);
-            return DateTime.Parse(value, provider);
-        }
-        [CLSCompliant(false)]
-        public static DateTime ToDateTime(sbyte value)
-        {
-            return ((IConvertible)value).ToDateTime(null);
-        }
-        public static DateTime ToDateTime(byte value)
-        {
-            return ((IConvertible)value).ToDateTime(null);
-        }
-        public static DateTime ToDateTime(short value)
-        {
-            return ((IConvertible)value).ToDateTime(null);
-        }
-        [CLSCompliant(false)]
-        public static DateTime ToDateTime(ushort value)
-        {
-            return ((IConvertible)value).ToDateTime(null);
-        }
-        public static DateTime ToDateTime(int value)
-        {
-            return ((IConvertible)value).ToDateTime(null);
-        }
-        [CLSCompliant(false)]
-        public static DateTime ToDateTime(uint value)
-        {
-            return ((IConvertible)value).ToDateTime(null);
-        }
-        public static DateTime ToDateTime(long value)
-        {
-            return ((IConvertible)value).ToDateTime(null);
-        }
-        [CLSCompliant(false)]
-        public static DateTime ToDateTime(ulong value)
-        {
-            return ((IConvertible)value).ToDateTime(null);
-        }
-        public static DateTime ToDateTime(bool value)
-        {
-            return ((IConvertible)value).ToDateTime(null);
-        }
-        public static DateTime ToDateTime(char value)
-        {
-            return ((IConvertible)value).ToDateTime(null);
-        }
-        public static DateTime ToDateTime(float value)
-        {
-            return ((IConvertible)value).ToDateTime(null);
-        }
-        public static DateTime ToDateTime(double value)
-        {
-            return ((IConvertible)value).ToDateTime(null);
-        }
-        public static DateTime ToDateTime(decimal value)
-        {
-            return ((IConvertible)value).ToDateTime(null);
-        }
-        public static string? ToString(object? value)
-        {
-            return ToString(value, null);
-        }
-        public static string? ToString(object? value, IFormatProvider? provider)
-        {
-            if (value is IConvertible ic)
-                return ic.ToString(provider);
-            if (value is IFormattable formattable)
-                return formattable.ToString(null, provider);
-            return value == null ? string.Empty : value.ToString();
-        }
-        public static string ToString(bool value)
-        {
-            return value.ToString();
-        }
-        public static string ToString(bool value, IFormatProvider? provider)
-        {
-            return value.ToString();
-        }
-        public static string ToString(char value)
-        {
-            return char.ToString(value);
-        }
-        public static string ToString(char value, IFormatProvider? provider)
-        {
-            return value.ToString();
-        }
-        [CLSCompliant(false)]
-        public static string ToString(sbyte value)
-        {
-            return value.ToString();
-        }
-        [CLSCompliant(false)]
-        public static string ToString(sbyte value, IFormatProvider? provider)
-        {
-            return value.ToString(provider);
-        }
-        public static string ToString(byte value)
-        {
-            return value.ToString();
-        }
-        public static string ToString(byte value, IFormatProvider? provider)
-        {
-            return value.ToString(provider);
-        }
-        public static string ToString(short value)
-        {
-            return value.ToString();
-        }
-        public static string ToString(short value, IFormatProvider? provider)
-        {
-            return value.ToString(provider);
-        }
-        [CLSCompliant(false)]
-        public static string ToString(ushort value)
-        {
-            return value.ToString();
-        }
-        [CLSCompliant(false)]
-        public static string ToString(ushort value, IFormatProvider? provider)
-        {
-            return value.ToString(provider);
-        }
-        public static string ToString(int value)
-        {
-            return value.ToString();
-        }
-        public static string ToString(int value, IFormatProvider? provider)
-        {
-            return value.ToString(provider);
-        }
-        [CLSCompliant(false)]
-        public static string ToString(uint value)
-        {
-            return value.ToString();
-        }
-        [CLSCompliant(false)]
-        public static string ToString(uint value, IFormatProvider? provider)
-        {
-            return value.ToString(provider);
-        }
-        public static string ToString(long value)
-        {
-            return value.ToString();
-        }
-        public static string ToString(long value, IFormatProvider? provider)
-        {
-            return value.ToString(provider);
-        }
-        [CLSCompliant(false)]
-        public static string ToString(ulong value)
-        {
-            return value.ToString();
-        }
-        [CLSCompliant(false)]
-        public static string ToString(ulong value, IFormatProvider? provider)
-        {
-            return value.ToString(provider);
-        }
-        public static string ToString(float value)
-        {
-            return value.ToString();
-        }
-        public static string ToString(float value, IFormatProvider? provider)
-        {
-            return value.ToString(provider);
-        }
-        public static string ToString(double value)
-        {
-            return value.ToString();
-        }
-        public static string ToString(double value, IFormatProvider? provider)
-        {
-            return value.ToString(provider);
-        }
-        public static string ToString(decimal value)
-        {
-            return value.ToString();
-        }
-        public static string ToString(decimal value, IFormatProvider? provider)
-        {
-            return value.ToString(provider);
-        }
-        public static string ToString(DateTime value)
-        {
-            return value.ToString();
-        }
-        public static string ToString(DateTime value, IFormatProvider? provider)
-        {
-            return value.ToString(provider);
-        }
-        [return: NotNullIfNotNull(nameof(value))]
-        public static string? ToString(string? value)
-        {
-            return value;
-        }
-        [return: NotNullIfNotNull(nameof(value))]
-        public static string? ToString(string? value, IFormatProvider? provider)
-        {
-            return value;
-        }
-        public static byte ToByte(string? value, int fromBase)
-        {
-            if (fromBase != 2 && fromBase != 8 && fromBase != 10 && fromBase != 16)
-            {
-                ThrowInvalidBase();
-            }
-            if (value == null)
-            {
-                return 0;
-            }
-            int r = ParseNumbers.StringToInt(value.AsSpan(), fromBase, ParseNumbers.IsTight | ParseNumbers.TreatAsUnsigned);
-            if ((uint)r > byte.MaxValue)
-                ThrowByteOverflowException();
-            return (byte)r;
-        }
-        [CLSCompliant(false)]
-        public static sbyte ToSByte(string? value, int fromBase)
-        {
-            if (fromBase != 2 && fromBase != 8 && fromBase != 10 && fromBase != 16)
-            {
-                ThrowInvalidBase();
-            }
-            if (value == null)
-            {
-                return 0;
-            }
-            int r = ParseNumbers.StringToInt(value.AsSpan(), fromBase, ParseNumbers.IsTight | ParseNumbers.TreatAsI1);
-            if (fromBase != 10 && r <= byte.MaxValue)
-                return (sbyte)r;
-            if (r < sbyte.MinValue || r > sbyte.MaxValue)
-                ThrowSByteOverflowException();
-            return (sbyte)r;
-        }
-        public static short ToInt16(string? value, int fromBase)
-        {
-            if (fromBase != 2 && fromBase != 8 && fromBase != 10 && fromBase != 16)
-            {
-                ThrowInvalidBase();
-            }
-            if (value == null)
-            {
-                return 0;
-            }
-            int r = ParseNumbers.StringToInt(value.AsSpan(), fromBase, ParseNumbers.IsTight | ParseNumbers.TreatAsI2);
-            if (fromBase != 10 && r <= ushort.MaxValue)
-                return (short)r;
-            if (r < short.MinValue || r > short.MaxValue)
-                ThrowInt16OverflowException();
-            return (short)r;
-        }
-        [CLSCompliant(false)]
-        public static ushort ToUInt16(string? value, int fromBase)
-        {
-            if (fromBase != 2 && fromBase != 8 && fromBase != 10 && fromBase != 16)
-            {
-                ThrowInvalidBase();
-            }
-            if (value == null)
-            {
-                return 0;
-            }
-            int r = ParseNumbers.StringToInt(value.AsSpan(), fromBase, ParseNumbers.IsTight | ParseNumbers.TreatAsUnsigned);
-            if ((uint)r > ushort.MaxValue)
-                ThrowUInt16OverflowException();
-            return (ushort)r;
-        }
-        public static int ToInt32(string? value, int fromBase)
-        {
-            if (fromBase != 2 && fromBase != 8 && fromBase != 10 && fromBase != 16)
-            {
-                ThrowInvalidBase();
-            }
-            return value != null ?
-                ParseNumbers.StringToInt(value.AsSpan(), fromBase, ParseNumbers.IsTight) :
-                0;
-        }
-        [CLSCompliant(false)]
-        public static uint ToUInt32(string? value, int fromBase)
-        {
-            if (fromBase != 2 && fromBase != 8 && fromBase != 10 && fromBase != 16)
-            {
-                ThrowInvalidBase();
-            }
-            return value != null ?
-                (uint)ParseNumbers.StringToInt(value.AsSpan(), fromBase, ParseNumbers.TreatAsUnsigned | ParseNumbers.IsTight) :
-                0;
-        }
-        public static long ToInt64(string? value, int fromBase)
-        {
-            if (fromBase != 2 && fromBase != 8 && fromBase != 10 && fromBase != 16)
-            {
-                ThrowInvalidBase();
-            }
-            return value != null ?
-                ParseNumbers.StringToLong(value.AsSpan(), fromBase, ParseNumbers.IsTight) :
-                0;
-        }
-        [CLSCompliant(false)]
-        public static ulong ToUInt64(string? value, int fromBase)
-        {
-            if (fromBase != 2 && fromBase != 8 && fromBase != 10 && fromBase != 16)
-            {
-                ThrowInvalidBase();
-            }
-            return value != null ?
-                (ulong)ParseNumbers.StringToLong(value.AsSpan(), fromBase, ParseNumbers.TreatAsUnsigned | ParseNumbers.IsTight) :
-                0;
-        }
-        public static string ToString(byte value, int toBase) =>
-            ToString((int)value, toBase);
-        public static string ToString(short value, int toBase)
-        {
-            string format = "d";
-            switch (toBase)
-            {
-                case 2:
-                    format = "b";
-                    break;
-                case 8:
-                    return ToOctalString((ushort)value);
-                case 10:
-                    break;
-                case 16:
-                    format = "x";
-                    break;
-                default:
-                    ThrowInvalidBase();
-                    break;
-            };
-            return value.ToString(format, CultureInfo.InvariantCulture);
-        }
-        public static string ToString(int value, int toBase)
-        {
-            string format = "d";
-            switch (toBase)
-            {
-                case 2:
-                    format = "b";
-                    break;
-                case 8:
-                    return ToOctalString((uint)value);
-                case 10:
-                    break;
-                case 16:
-                    format = "x";
-                    break;
-                default:
-                    ThrowInvalidBase();
-                    break;
-            };
-            return value.ToString(format, CultureInfo.InvariantCulture);
-        }
-        public static string ToString(long value, int toBase)
-        {
-            string format = "d";
-            switch (toBase)
-            {
-                case 2:
-                    format = "b";
-                    break;
-                case 8:
-                    return ToOctalString((ulong)value);
-                case 10:
-                    break;
-                case 16:
-                    format = "x";
-                    break;
-                default:
-                    ThrowInvalidBase();
-                    break;
-            };
-            return value.ToString(format, CultureInfo.InvariantCulture);
-        }
-        private static void ThrowInvalidBase() => throw new ArgumentException(SR.Arg_InvalidBase);
-        private static string ToOctalString(ulong value)
-        {
-            Span<char> chars = stackalloc char[22]; // max length of a ulong in octal
-            int i = chars.Length;
-            do
-            {
-                chars[--i] = (char)('0' + (value & 7));
-                value >>= 3;
-            }
-            while (value != 0);
-            return chars.Slice(i).ToString();
-        }
-        public static string ToBase64String(byte[] inArray)
-        {
-            ArgumentNullException.ThrowIfNull(inArray);
-            return ToBase64String(new ReadOnlySpan<byte>(inArray), Base64FormattingOptions.None);
-        }
-        public static string ToBase64String(byte[] inArray, Base64FormattingOptions options)
-        {
-            ArgumentNullException.ThrowIfNull(inArray);
-            return ToBase64String(new ReadOnlySpan<byte>(inArray), options);
-        }
-        public static string ToBase64String(byte[] inArray, int offset, int length)
-        {
-            return ToBase64String(inArray, offset, length, Base64FormattingOptions.None);
-        }
-        public static string ToBase64String(byte[] inArray, int offset, int length, Base64FormattingOptions options)
-        {
-            ArgumentNullException.ThrowIfNull(inArray);
-            ArgumentOutOfRangeException.ThrowIfNegative(length);
-            ArgumentOutOfRangeException.ThrowIfNegative(offset);
-            ArgumentOutOfRangeException.ThrowIfGreaterThan(offset, inArray.Length - length);
-            return ToBase64String(new ReadOnlySpan<byte>(inArray, offset, length), options);
-        }
-        public static string ToBase64String(ReadOnlySpan<byte> bytes, Base64FormattingOptions options = Base64FormattingOptions.None)
-        {
-            if ((uint)options > (uint)Base64FormattingOptions.InsertLineBreaks)
-            {
-                throw new ArgumentException(SR.Format(SR.Arg_EnumIllegalVal, (int)options), nameof(options));
-            }
-            if (bytes.Length == 0)
-            {
-                return string.Empty;
-            }
-            bool insertLineBreaks = (options == Base64FormattingOptions.InsertLineBreaks);
-            int outputLength = ToBase64_CalculateAndValidateOutputLength(bytes.Length, insertLineBreaks);
-            string result = string.FastAllocateString(outputLength);
-            if (Vector128.IsHardwareAccelerated && !insertLineBreaks && bytes.Length >= Base64VectorizationLengthThreshold)
-            {
-                ToBase64CharsLargeNoLineBreaks(bytes, new Span<char>(ref result.GetRawStringData(), result.Length), result.Length);
-            }
-            else
-            {
-                unsafe
-                {
-                    fixed (byte* bytesPtr = &MemoryMarshal.GetReference(bytes))
-                    fixed (char* charsPtr = result)
-                    {
-                        int charsWritten = ConvertToBase64Array(charsPtr, bytesPtr, 0, bytes.Length, insertLineBreaks);
-                        Debug.Assert(result.Length == charsWritten, $"Expected {result.Length} == {charsWritten}");
-                    }
-                }
-            }
-            return result;
-        }
-        public static int ToBase64CharArray(byte[] inArray, int offsetIn, int length, char[] outArray, int offsetOut)
-        {
-            return ToBase64CharArray(inArray, offsetIn, length, outArray, offsetOut, Base64FormattingOptions.None);
-        }
-        public static unsafe int ToBase64CharArray(byte[] inArray, int offsetIn, int length, char[] outArray, int offsetOut, Base64FormattingOptions options)
-        {
-            ArgumentNullException.ThrowIfNull(inArray);
-            ArgumentNullException.ThrowIfNull(outArray);
-            ArgumentOutOfRangeException.ThrowIfNegative(length);
-            ArgumentOutOfRangeException.ThrowIfNegative(offsetIn);
-            ArgumentOutOfRangeException.ThrowIfNegative(offsetOut);
-            if (options < Base64FormattingOptions.None || options > Base64FormattingOptions.InsertLineBreaks)
-                throw new ArgumentException(SR.Format(SR.Arg_EnumIllegalVal, (int)options), nameof(options));
-            int inArrayLength = inArray.Length;
-            ArgumentOutOfRangeException.ThrowIfGreaterThan(offsetIn, inArrayLength - length);
-            if (length == 0)
-                return 0;
-            int outArrayLength = outArray.Length;
-            bool insertLineBreaks = options == Base64FormattingOptions.InsertLineBreaks;
-            int charLengthRequired = ToBase64_CalculateAndValidateOutputLength(length, insertLineBreaks);
-            ArgumentOutOfRangeException.ThrowIfGreaterThan(offsetOut, outArrayLength - charLengthRequired);
-            if (Vector128.IsHardwareAccelerated && !insertLineBreaks && length >= Base64VectorizationLengthThreshold)
-            {
-                ToBase64CharsLargeNoLineBreaks(new ReadOnlySpan<byte>(inArray, offsetIn, length), outArray.AsSpan(offsetOut), charLengthRequired);
-            }
-            else
-            {
-                fixed (char* outChars = &outArray[offsetOut])
-                fixed (byte* inData = &inArray[0])
-                {
-                    int converted = ConvertToBase64Array(outChars, inData, offsetIn, length, insertLineBreaks);
-                    Debug.Assert(converted == charLengthRequired);
-                }
-            }
-            return charLengthRequired;
-        }
-        public static unsafe bool TryToBase64Chars(ReadOnlySpan<byte> bytes, Span<char> chars, out int charsWritten, Base64FormattingOptions options = Base64FormattingOptions.None)
-        {
-            if ((uint)options > (uint)Base64FormattingOptions.InsertLineBreaks)
-            {
-                throw new ArgumentException(SR.Format(SR.Arg_EnumIllegalVal, (int)options), nameof(options));
-            }
-            if (bytes.Length == 0)
-            {
-                charsWritten = 0;
-                return true;
-            }
-            bool insertLineBreaks = options == Base64FormattingOptions.InsertLineBreaks;
-            int charLengthRequired = ToBase64_CalculateAndValidateOutputLength(bytes.Length, insertLineBreaks);
-            if (charLengthRequired > chars.Length)
-            {
-                charsWritten = 0;
-                return false;
-            }
-            if (Vector128.IsHardwareAccelerated && !insertLineBreaks && bytes.Length >= Base64VectorizationLengthThreshold)
-            {
-                ToBase64CharsLargeNoLineBreaks(bytes, chars, charLengthRequired);
-            }
-            else
-            {
-                fixed (char* outChars = &MemoryMarshal.GetReference(chars))
-                fixed (byte* inData = &MemoryMarshal.GetReference(bytes))
-                {
-                    int converted = ConvertToBase64Array(outChars, inData, 0, bytes.Length, insertLineBreaks);
-                    Debug.Assert(converted == charLengthRequired);
-                }
-            }
-            charsWritten = charLengthRequired;
-            return true;
-        }
-        private static unsafe void ToBase64CharsLargeNoLineBreaks(ReadOnlySpan<byte> bytes, Span<char> chars, int charLengthRequired)
-        {
-            Debug.Assert(bytes.Length >= Base64VectorizationLengthThreshold);
-            Debug.Assert(chars.Length >= charLengthRequired);
-            Debug.Assert(charLengthRequired % 4 == 0);
-            OperationStatus status = Base64.EncodeToUtf8(bytes, MemoryMarshal.AsBytes(chars), out _, out int bytesWritten);
-            Debug.Assert(status == OperationStatus.Done && charLengthRequired == bytesWritten);
-            ref ushort dest = ref Unsafe.As<char, ushort>(ref MemoryMarshal.GetReference(chars));
-            ref byte src = ref Unsafe.As<ushort, byte>(ref dest);
-            ref byte srcBeginning = ref src;
-            dest = ref Unsafe.Add(ref dest, charLengthRequired);
-            src = ref Unsafe.Add(ref src, charLengthRequired);
-            if (Vector256.IsHardwareAccelerated)
-            {
-                ref byte srcBeginningPlus31 = ref Unsafe.Add(ref srcBeginning, 31);
-                while (Unsafe.IsAddressGreaterThan(ref src, ref srcBeginningPlus31))
-                {
-                    src = ref Unsafe.Subtract(ref src, 32);
-                    dest = ref Unsafe.Subtract(ref dest, 32);
-                    (Vector256<ushort> utf16Lower, Vector256<ushort> utf16Upper) = Vector256.Widen(Vector256.LoadUnsafe(ref src));
-                    utf16Lower.StoreUnsafe(ref dest);
-                    utf16Upper.StoreUnsafe(ref dest, 16);
-                }
-            }
-            if (Vector128.IsHardwareAccelerated)
-            {
-                ref byte srcBeginningPlus15 = ref Unsafe.Add(ref srcBeginning, 15);
-                while (Unsafe.IsAddressGreaterThan(ref src, ref srcBeginningPlus15))
-                {
-                    src = ref Unsafe.Subtract(ref src, 16);
-                    dest = ref Unsafe.Subtract(ref dest, 16);
-                    (Vector128<ushort> utf16Lower, Vector128<ushort> utf16Upper) = Vector128.Widen(Vector128.LoadUnsafe(ref src));
-                    utf16Lower.StoreUnsafe(ref dest);
-                    utf16Upper.StoreUnsafe(ref dest, 8);
-                }
-            }
-            ref byte srcBeginningPlus3 = ref Unsafe.Add(ref srcBeginning, 3);
-            while (Unsafe.IsAddressGreaterThan(ref src, ref srcBeginningPlus3))
-            {
-                dest = ref Unsafe.Subtract(ref dest, 4);
-                src = ref Unsafe.Subtract(ref src, 4);
-                Ascii.WidenFourAsciiBytesToUtf16AndWriteToBuffer(ref Unsafe.As<ushort, char>(ref dest), Unsafe.ReadUnaligned<uint>(ref src));
-            }
-            Debug.Assert(Unsafe.AreSame(ref srcBeginning, ref src));
-            Debug.Assert(Unsafe.AreSame(ref srcBeginning, ref Unsafe.As<ushort, byte>(ref dest)),
-                "The two references should have ended up exactly at the beginning");
-        }
-        private static unsafe int ConvertToBase64Array(char* outChars, byte* inData, int offset, int length, bool insertLineBreaks)
-        {
-            int lengthmod3 = length % 3;
-            int calcLength = offset + (length - lengthmod3);
-            int j = 0;
-            int charcount = 0;
-            int i;
-            fixed (byte* base64 = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/="u8)
-            {
-                for (i = offset; i < calcLength; i += 3)
-                {
-                    if (insertLineBreaks)
-                    {
-                        if (charcount == Base64LineBreakPosition)
-                        {
-                            outChars[j++] = '\r';
-                            outChars[j++] = '\n';
-                            charcount = 0;
-                        }
-                        charcount += 4;
-                    }
-                    outChars[j] = (char)base64[(inData[i] & 0xfc) >> 2];
-                    outChars[j + 1] = (char)base64[((inData[i] & 0x03) << 4) | ((inData[i + 1] & 0xf0) >> 4)];
-                    outChars[j + 2] = (char)base64[((inData[i + 1] & 0x0f) << 2) | ((inData[i + 2] & 0xc0) >> 6)];
-                    outChars[j + 3] = (char)base64[inData[i + 2] & 0x3f];
-                    j += 4;
-                }
-                i = calcLength;
-                if (insertLineBreaks && (lengthmod3 != 0) && (charcount == Base64LineBreakPosition))
-                {
-                    outChars[j++] = '\r';
-                    outChars[j++] = '\n';
-                }
-                switch (lengthmod3)
-                {
-                    case 2: // One character padding needed
-                        outChars[j] = (char)base64[(inData[i] & 0xfc) >> 2];
-                        outChars[j + 1] = (char)base64[((inData[i] & 0x03) << 4) | ((inData[i + 1] & 0xf0) >> 4)];
-                        outChars[j + 2] = (char)base64[(inData[i + 1] & 0x0f) << 2];
-                        outChars[j + 3] = (char)base64[64]; // Pad
-                        j += 4;
-                        break;
-                    case 1: // Two character padding needed
-                        outChars[j] = (char)base64[(inData[i] & 0xfc) >> 2];
-                        outChars[j + 1] = (char)base64[(inData[i] & 0x03) << 4];
-                        outChars[j + 2] = (char)base64[64]; // Pad
-                        outChars[j + 3] = (char)base64[64]; // Pad
-                        j += 4;
-                        break;
-                }
-            }
-            return j;
-        }
-        private static int ToBase64_CalculateAndValidateOutputLength(int inputLength, bool insertLineBreaks)
-        {
-            uint outlen = ((uint)inputLength + 2) / 3 * 4;
-            if (outlen == 0)
-                return 0;
-            if (insertLineBreaks)
-            {
-                (uint newLines, uint remainder) = Math.DivRem(outlen, Base64LineBreakPosition);
-                if (remainder == 0)
-                {
-                    --newLines;
-                }
-                outlen += newLines * 2;              // the number of line break chars we'll add, "\r\n"
-            }
-            if (outlen > int.MaxValue)
-                throw new OutOfMemoryException();
-            return (int)outlen;
-        }
-        public static byte[] FromBase64String(string s)
-        {
-            if (s == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.s);
-            }
-            unsafe
-            {
-                fixed (char* sPtr = s)
-                {
-                    return FromBase64CharPtr(sPtr, s.Length);
-                }
-            }
-        }
-        public static bool TryFromBase64String(string s, Span<byte> bytes, out int bytesWritten)
-        {
-            if (s == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.s);
-            }
-            return TryFromBase64Chars(s.AsSpan(), bytes, out bytesWritten);
-        }
-        public static bool TryFromBase64Chars(ReadOnlySpan<char> chars, Span<byte> bytes, out int bytesWritten)
-        {
-            Span<char> tempBuffer = stackalloc char[4];  // Note: The tempBuffer size could be made larger than 4 but the size must be a multiple of 4.
-            bytesWritten = 0;
-            while (chars.Length != 0)
-            {
-                bool complete = TryDecodeFromUtf16(chars, bytes, out int consumedInThisIteration, out int bytesWrittenInThisIteration);
-                bytesWritten += bytesWrittenInThisIteration;
-                if (complete)
-                    return true;
-                chars = chars.Slice(consumedInThisIteration);
-                bytes = bytes.Slice(bytesWrittenInThisIteration);
-                Debug.Assert(chars.Length != 0); // If TryDecodeFromUtf16() consumed the entire buffer, it could not have returned false.
-                if (chars[0].IsSpace())
-                {
-                    int indexOfFirstNonSpace = 1;
-                    while (true)
-                    {
-                        if (indexOfFirstNonSpace == chars.Length)
-                            break;
-                        if (!chars[indexOfFirstNonSpace].IsSpace())
-                            break;
-                        indexOfFirstNonSpace++;
-                    }
-                    chars = chars.Slice(indexOfFirstNonSpace);
-                    if ((bytesWrittenInThisIteration % 3) != 0 && chars.Length != 0)
-                    {
-                        bytesWritten = default;
-                        return false;
-                    }
-                }
-                else
-                {
-                    Debug.Assert(chars.Length != 0 && !chars[0].IsSpace());
-                    CopyToTempBufferWithoutWhiteSpace(chars, tempBuffer, out int consumedFromChars, out int charsWritten);
-                    if ((charsWritten & 0x3) != 0)
-                    {
-                        bytesWritten = default;
-                        return false;
-                    }
-                    tempBuffer = tempBuffer.Slice(0, charsWritten);
-                    if (!TryDecodeFromUtf16(tempBuffer, bytes, out int consumedFromTempBuffer, out int bytesWrittenFromTempBuffer))
-                    {
-                        bytesWritten = default;
-                        return false;
-                    }
-                    bytesWritten += bytesWrittenFromTempBuffer;
-                    chars = chars.Slice(consumedFromChars);
-                    bytes = bytes.Slice(bytesWrittenFromTempBuffer);
-                    if ((bytesWrittenFromTempBuffer % 3) != 0)
-                    {
-                        for (int i = 0; i < chars.Length; i++)
-                        {
-                            if (!chars[i].IsSpace())
-                            {
-                                bytesWritten = default;
-                                return false;
-                            }
-                        }
-                        return true;
-                    }
-                }
-            }
-            return true;
-        }
-        private static void CopyToTempBufferWithoutWhiteSpace(ReadOnlySpan<char> chars, Span<char> tempBuffer, out int consumed, out int charsWritten)
-        {
-            Debug.Assert(tempBuffer.Length != 0); // We only bound-check after writing a character to the tempBuffer.
-            charsWritten = 0;
-            for (int i = 0; i < chars.Length; i++)
-            {
-                char c = chars[i];
-                if (!c.IsSpace())
-                {
-                    tempBuffer[charsWritten++] = c;
-                    if (charsWritten == tempBuffer.Length)
-                    {
-                        consumed = i + 1;
-                        return;
-                    }
-                }
-            }
-            consumed = chars.Length;
-        }
-        [MethodImpl(MethodImplOptions.AggressiveInlining)]
-        private static bool IsSpace(this char c) => c == ' ' || c == '\t' || c == '\r' || c == '\n';
-        public static byte[] FromBase64CharArray(char[] inArray, int offset, int length)
-        {
-            ArgumentNullException.ThrowIfNull(inArray);
-            ArgumentOutOfRangeException.ThrowIfNegative(length);
-            ArgumentOutOfRangeException.ThrowIfNegative(offset);
-            ArgumentOutOfRangeException.ThrowIfGreaterThan(offset, inArray.Length - length);
-            if (length == 0)
-            {
-                return Array.Empty<byte>();
-            }
-            unsafe
-            {
-                fixed (char* inArrayPtr = &inArray[0])
-                {
-                    return FromBase64CharPtr(inArrayPtr + offset, length);
-                }
-            }
-        }
-        private static unsafe byte[] FromBase64CharPtr(char* inputPtr, int inputLength)
-        {
-            Debug.Assert(0 <= inputLength);
-            while (inputLength > 0)
-            {
-                int lastChar = inputPtr[inputLength - 1];
-                if (lastChar != (int)' ' && lastChar != (int)'\n' && lastChar != (int)'\r' && lastChar != (int)'\t')
-                    break;
-                inputLength--;
-            }
-            int resultLength = FromBase64_ComputeResultLength(inputPtr, inputLength);
-            Debug.Assert(0 <= resultLength);
-            byte[] decodedBytes = new byte[resultLength];
-            if (!TryFromBase64Chars(new ReadOnlySpan<char>(inputPtr, inputLength), decodedBytes, out int _))
-                throw new FormatException(SR.Format_BadBase64Char);
-            return decodedBytes;
-        }
-        private static unsafe int FromBase64_ComputeResultLength(char* inputPtr, int inputLength)
-        {
-            const uint intEq = (uint)'=';
-            const uint intSpace = (uint)' ';
-            Debug.Assert(0 <= inputLength);
-            char* inputEndPtr = inputPtr + inputLength;
-            int usefulInputLength = inputLength;
-            int padding = 0;
-            while (inputPtr < inputEndPtr)
-            {
-                uint c = (uint)(*inputPtr);
-                inputPtr++;
-                if (c <= intSpace)
-                    usefulInputLength--;
-                else if (c == intEq)
-                {
-                    usefulInputLength--;
-                    padding++;
-                }
-            }
-            Debug.Assert(0 <= usefulInputLength);
-            Debug.Assert(0 <= padding);
-            if (padding != 0)
-            {
-                if (padding == 1)
-                    padding = 2;
-                else if (padding == 2)
-                    padding = 1;
-                else
-                    throw new FormatException(SR.Format_BadBase64Char);
-            }
-            return (usefulInputLength / 4) * 3 + padding;
-        }
-        public static byte[] FromHexString(string s)
-        {
-            if (s == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.s);
-            }
-            return FromHexString(s.AsSpan());
-        }
-        public static byte[] FromHexString(ReadOnlySpan<char> chars)
-        {
-            if (chars.Length == 0)
-                return Array.Empty<byte>();
-            if ((uint)chars.Length % 2 != 0)
-                throw new FormatException(SR.Format_BadHexLength);
-            byte[] result = GC.AllocateUninitializedArray<byte>(chars.Length >> 1);
-            if (!HexConverter.TryDecodeFromUtf16(chars, result, out _))
-                throw new FormatException(SR.Format_BadHexChar);
-            return result;
-        }
-        public static OperationStatus FromHexString(string source, Span<byte> destination, out int charsConsumed, out int bytesWritten)
-        {
-            ArgumentNullException.ThrowIfNull(source);
-            return FromHexString(source.AsSpan(), destination, out charsConsumed, out bytesWritten);
-        }
-        public static OperationStatus FromHexString(ReadOnlySpan<char> source, Span<byte> destination, out int charsConsumed, out int bytesWritten)
-        {
-            (int quotient, int remainder) = Math.DivRem(source.Length, 2);
-            if (quotient == 0)
-            {
-                charsConsumed = 0;
-                bytesWritten = 0;
-                return remainder == 1 ? OperationStatus.NeedMoreData : OperationStatus.Done;
-            }
-            OperationStatus result;
-            if (destination.Length < quotient)
-            {
-                source = source.Slice(0, destination.Length * 2);
-                quotient = destination.Length;
-                result = OperationStatus.DestinationTooSmall;
-            }
-            else
-            {
-                if (remainder == 1)
-                {
-                    source = source.Slice(0, source.Length - 1);
-                    result = OperationStatus.NeedMoreData;
-                }
-                else
-                {
-                    result = OperationStatus.Done;
-                }
-                destination = destination.Slice(0, quotient);
-            }
-            if (!HexConverter.TryDecodeFromUtf16(source, destination, out charsConsumed))
-            {
-                bytesWritten = charsConsumed / 2;
-                return OperationStatus.InvalidData;
-            }
-            bytesWritten = quotient;
-            charsConsumed = source.Length;
-            return result;
-        }
-        public static string ToHexString(byte[] inArray)
-        {
-            ArgumentNullException.ThrowIfNull(inArray);
-            return ToHexString(new ReadOnlySpan<byte>(inArray));
-        }
-        public static string ToHexString(byte[] inArray, int offset, int length)
-        {
-            ArgumentNullException.ThrowIfNull(inArray);
-            ArgumentOutOfRangeException.ThrowIfNegative(length);
-            ArgumentOutOfRangeException.ThrowIfNegative(offset);
-            ArgumentOutOfRangeException.ThrowIfGreaterThan(offset, inArray.Length - length);
-            return ToHexString(new ReadOnlySpan<byte>(inArray, offset, length));
-        }
-        public static string ToHexString(ReadOnlySpan<byte> bytes)
-        {
-            if (bytes.Length == 0)
-                return string.Empty;
-            ArgumentOutOfRangeException.ThrowIfGreaterThan(bytes.Length, int.MaxValue / 2, nameof(bytes));
-            return HexConverter.ToString(bytes, HexConverter.Casing.Upper);
-        }
-        public static bool TryToHexString(ReadOnlySpan<byte> source, Span<char> destination, out int charsWritten)
-        {
-            if (source.Length == 0)
-            {
-                charsWritten = 0;
-                return true;
-            }
-            else if (source.Length > int.MaxValue / 2 || destination.Length < source.Length * 2)
-            {
-                charsWritten = 0;
-                return false;
-            }
-            HexConverter.EncodeToUtf16(source, destination);
-            charsWritten = source.Length * 2;
-            return true;
-        }
-        public static string ToHexStringLower(byte[] inArray)
-        {
-            ArgumentNullException.ThrowIfNull(inArray);
-            return ToHexStringLower(new ReadOnlySpan<byte>(inArray));
-        }
-        public static string ToHexStringLower(byte[] inArray, int offset, int length)
-        {
-            ArgumentNullException.ThrowIfNull(inArray);
-            ArgumentOutOfRangeException.ThrowIfNegative(length);
-            ArgumentOutOfRangeException.ThrowIfNegative(offset);
-            ArgumentOutOfRangeException.ThrowIfGreaterThan(offset, inArray.Length - length);
-            return ToHexStringLower(new ReadOnlySpan<byte>(inArray, offset, length));
-        }
-        public static string ToHexStringLower(ReadOnlySpan<byte> bytes)
-        {
-            if (bytes.Length == 0)
-                return string.Empty;
-            ArgumentOutOfRangeException.ThrowIfGreaterThan(bytes.Length, int.MaxValue / 2, nameof(bytes));
-            return HexConverter.ToString(bytes, HexConverter.Casing.Lower);
-        }
-        public static bool TryToHexStringLower(ReadOnlySpan<byte> source, Span<char> destination, out int charsWritten)
-        {
-            if (source.Length == 0)
-            {
-                charsWritten = 0;
-                return true;
-            }
-            else if (source.Length > int.MaxValue / 2 || destination.Length < source.Length * 2)
-            {
-                charsWritten = 0;
-                return false;
-            }
-            HexConverter.EncodeToUtf16(source, destination, HexConverter.Casing.Lower);
-            charsWritten = source.Length * 2;
-            return true;
-        }
-    }  // class Convert
-}  // namespace

--- a/src/libraries/System.Private.CoreLib/src/System/Numerics/Matrix4x4.Impl.cs
+++ b//dev/null
@@ -1,1146 +0,0 @@
-using System.Diagnostics.CodeAnalysis;
-using System.Runtime.CompilerServices;
-using System.Runtime.Intrinsics;
-using System.Runtime.Intrinsics.Arm;
-using System.Runtime.Intrinsics.X86;
-namespace System.Numerics
-{
-    public partial struct Matrix4x4
-    {
-        internal const uint RowCount = 4;
-        internal const uint ColumnCount = 4;
-        [UnscopedRef]
-        [MethodImpl(MethodImplOptions.AggressiveInlining)]
-        internal ref Impl AsImpl() => ref Unsafe.As<Matrix4x4, Impl>(ref this);
-        [UnscopedRef]
-        [MethodImpl(MethodImplOptions.AggressiveInlining)]
-        internal readonly ref readonly Impl AsROImpl() => ref Unsafe.As<Matrix4x4, Impl>(ref Unsafe.AsRef(in this));
-        internal struct Impl : IEquatable<Impl>
-        {
-            [UnscopedRef]
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public ref Matrix4x4 AsM4x4() => ref Unsafe.As<Impl, Matrix4x4>(ref this);
-            private const float BillboardEpsilon = 1e-4f;
-            private const float BillboardMinAngle = 1.0f - (0.1f * (float.Pi / 180.0f)); // 0.1 degrees
-            private const float DecomposeEpsilon = 0.0001f;
-            public Vector4 X;
-            public Vector4 Y;
-            public Vector4 Z;
-            public Vector4 W;
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public void Init(float m11, float m12, float m13, float m14,
-                             float m21, float m22, float m23, float m24,
-                             float m31, float m32, float m33, float m34,
-                             float m41, float m42, float m43, float m44)
-            {
-                X = Vector4.Create(m11, m12, m13, m14);
-                Y = Vector4.Create(m21, m22, m23, m24);
-                Z = Vector4.Create(m31, m32, m33, m34);
-                W = Vector4.Create(m41, m42, m43, m44);
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public void Init(in Matrix3x2.Impl value)
-            {
-                X = Vector4.Create(value.X, 0, 0);
-                Y = Vector4.Create(value.Y, 0, 0);
-                Z = Vector4.UnitZ;
-                W = Vector4.Create(value.Z, 0, 1);
-            }
-            public static Impl Identity
-            {
-                [MethodImpl(MethodImplOptions.AggressiveInlining)]
-                get
-                {
-                    Impl result;
-                    result.X = Vector4.UnitX;
-                    result.Y = Vector4.UnitY;
-                    result.Z = Vector4.UnitZ;
-                    result.W = Vector4.UnitW;
-                    return result;
-                }
-            }
-            public float this[int row, int column]
-            {
-                [MethodImpl(MethodImplOptions.AggressiveInlining)]
-                readonly get
-                {
-                    if ((uint)row >= RowCount)
-                    {
-                        ThrowHelper.ThrowArgumentOutOfRangeException();
-                    }
-                    return Unsafe.Add(ref Unsafe.AsRef(in X), row)[column];
-                }
-                [MethodImpl(MethodImplOptions.AggressiveInlining)]
-                set
-                {
-                    if ((uint)row >= RowCount)
-                    {
-                        ThrowHelper.ThrowArgumentOutOfRangeException();
-                    }
-                    Unsafe.Add(ref X, row)[column] = value;
-                }
-            }
-            public readonly bool IsIdentity
-            {
-                [MethodImpl(MethodImplOptions.AggressiveInlining)]
-                get
-                {
-                    return (X == Vector4.UnitX)
-                        && (Y == Vector4.UnitY)
-                        && (Z == Vector4.UnitZ)
-                        && (W == Vector4.UnitW);
-                }
-            }
-            public Vector3 Translation
-            {
-                [MethodImpl(MethodImplOptions.AggressiveInlining)]
-                readonly get => W.AsVector3();
-                [MethodImpl(MethodImplOptions.AggressiveInlining)]
-                set
-                {
-                    W = Vector4.Create(value, W.W);
-                }
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl operator +(in Impl left, in Impl right)
-            {
-                Impl result;
-                result.X = left.X + right.X;
-                result.Y = left.Y + right.Y;
-                result.Z = left.Z + right.Z;
-                result.W = left.W + right.W;
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static bool operator ==(in Impl left, in Impl right)
-            {
-                return (left.X == right.X)
-                    && (left.Y == right.Y)
-                    && (left.Z == right.Z)
-                    && (left.W == right.W);
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static bool operator !=(in Impl left, in Impl right)
-            {
-                return (left.X != right.X)
-                    || (left.Y != right.Y)
-                    || (left.Z != right.Z)
-                    || (left.W != right.W);
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl operator *(in Impl left, in Impl right)
-            {
-                Impl result;
-                result.X = Vector4.Transform(left.X, in right);
-                result.Y = Vector4.Transform(left.Y, in right);
-                result.Z = Vector4.Transform(left.Z, in right);
-                result.W = Vector4.Transform(left.W, in right);
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl operator *(in Impl left, float right)
-            {
-                Impl result;
-                result.X = left.X * right;
-                result.Y = left.Y * right;
-                result.Z = left.Z * right;
-                result.W = left.W * right;
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl operator -(in Impl left, in Impl right)
-            {
-                Impl result;
-                result.X = left.X - right.X;
-                result.Y = left.Y - right.Y;
-                result.Z = left.Z - right.Z;
-                result.W = left.W - right.W;
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl operator -(in Impl value)
-            {
-                Impl result;
-                result.X = -value.X;
-                result.Y = -value.Y;
-                result.Z = -value.Z;
-                result.W = -value.W;
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateBillboard(in Vector3 objectPosition, in Vector3 cameraPosition, in Vector3 cameraUpVector, in Vector3 cameraForwardVector)
-            {
-                Vector3 axisZ = objectPosition - cameraPosition;
-                if (axisZ.LengthSquared() < BillboardEpsilon)
-                {
-                    axisZ = -cameraForwardVector;
-                }
-                else
-                {
-                    axisZ = Vector3.Normalize(axisZ);
-                }
-                Vector3 axisX = Vector3.Normalize(Vector3.Cross(cameraUpVector, axisZ));
-                Vector3 axisY = Vector3.Cross(axisZ, axisX);
-                Impl result;
-                result.X = axisX.AsVector4();
-                result.Y = axisY.AsVector4();
-                result.Z = axisZ.AsVector4();;
-                result.W = Vector4.Create(objectPosition, 1);
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateConstrainedBillboard(in Vector3 objectPosition, in Vector3 cameraPosition, in Vector3 rotateAxis, in Vector3 cameraForwardVector, in Vector3 objectForwardVector)
-            {
-                Vector3 faceDir = objectPosition - cameraPosition;
-                if (faceDir.LengthSquared() < BillboardEpsilon)
-                {
-                    faceDir = -cameraForwardVector;
-                }
-                else
-                {
-                    faceDir = Vector3.Normalize(faceDir);
-                }
-                Vector3 axisY = rotateAxis;
-                float dot = Vector3.Dot(axisY, faceDir);
-                if (float.Abs(dot) > BillboardMinAngle)
-                {
-                    faceDir = objectForwardVector;
-                    dot = Vector3.Dot(axisY, faceDir);
-                    if (float.Abs(dot) > BillboardMinAngle)
-                    {
-                        faceDir = (float.Abs(axisY.Z) > BillboardMinAngle) ? Vector3.UnitX : Vector3.Create(0, 0, -1);
-                    }
-                }
-                Vector3 axisX = Vector3.Normalize(Vector3.Cross(axisY, faceDir));
-                Vector3 axisZ = Vector3.Normalize(Vector3.Cross(axisX, axisY));
-                Impl result;
-                result.X = axisX.AsVector4();
-                result.Y = axisY.AsVector4();
-                result.Z = axisZ.AsVector4();
-                result.W = Vector4.Create(objectPosition, 1);
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateFromAxisAngle(in Vector3 axis, float angle)
-            {
-                Quaternion q = Quaternion.CreateFromAxisAngle(axis, angle);
-                return CreateFromQuaternion(q);
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateFromQuaternion(in Quaternion quaternion)
-            {
-                float xx = quaternion.X * quaternion.X;
-                float yy = quaternion.Y * quaternion.Y;
-                float zz = quaternion.Z * quaternion.Z;
-                float xy = quaternion.X * quaternion.Y;
-                float wz = quaternion.Z * quaternion.W;
-                float xz = quaternion.Z * quaternion.X;
-                float wy = quaternion.Y * quaternion.W;
-                float yz = quaternion.Y * quaternion.Z;
-                float wx = quaternion.X * quaternion.W;
-                Impl result;
-                result.X = Vector4.Create(
-                    1.0f - 2.0f * (yy + zz),
-                    2.0f * (xy + wz),
-                    2.0f * (xz - wy),
-                    0
-                );
-                result.Y = Vector4.Create(
-                    2.0f * (xy - wz),
-                    1.0f - 2.0f * (zz + xx),
-                    2.0f * (yz + wx),
-                    0
-                );
-                result.Z = Vector4.Create(
-                    2.0f * (xz + wy),
-                    2.0f * (yz - wx),
-                    1.0f - 2.0f * (yy + xx),
-                    0
-                );
-                result.W = Vector4.UnitW;
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateFromYawPitchRoll(float yaw, float pitch, float roll)
-            {
-                Quaternion q = Quaternion.CreateFromYawPitchRoll(yaw, pitch, roll);
-                return CreateFromQuaternion(q);
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateLookTo(in Vector3 cameraPosition, in Vector3 cameraDirection, in Vector3 cameraUpVector)
-            {
-                return CreateLookToLeftHanded(cameraPosition, -cameraDirection, cameraUpVector);
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateLookToLeftHanded(in Vector3 cameraPosition, in Vector3 cameraDirection, in Vector3 cameraUpVector)
-            {
-                Vector3 axisZ = Vector3.Normalize(cameraDirection);
-                Vector3 axisX = Vector3.Normalize(Vector3.Cross(cameraUpVector, axisZ));
-                Vector3 axisY = Vector3.Cross(axisZ, axisX);
-                Vector3 negativeCameraPosition = -cameraPosition;
-                Impl result;
-                result.X = Vector4.Create(axisX, Vector3.Dot(axisX, negativeCameraPosition));
-                result.Y = Vector4.Create(axisY, Vector3.Dot(axisY, negativeCameraPosition));
-                result.Z = Vector4.Create(axisZ, Vector3.Dot(axisZ, negativeCameraPosition));
-                result.W = Vector4.UnitW;
-                return Transpose(result);
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateOrthographic(float width, float height, float zNearPlane, float zFarPlane)
-            {
-                float range = 1.0f / (zNearPlane - zFarPlane);
-                Impl result;
-                result.X = Vector4.Create(2.0f / width, 0, 0, 0);
-                result.Y = Vector4.Create(0, 2.0f / height, 0, 0);
-                result.Z = Vector4.Create(0, 0, range, 0);
-                result.W = Vector4.Create(0, 0, range * zNearPlane, 1);
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateOrthographicLeftHanded(float width, float height, float zNearPlane, float zFarPlane)
-            {
-                float range = 1.0f / (zFarPlane - zNearPlane);
-                Impl result;
-                result.X = Vector4.Create(2.0f / width, 0, 0, 0);
-                result.Y = Vector4.Create(0, 2.0f / height, 0, 0);
-                result.Z = Vector4.Create(0, 0, range, 0);
-                result.W = Vector4.Create(0, 0, -range * zNearPlane, 1);
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateOrthographicOffCenter(float left, float right, float bottom, float top, float zNearPlane, float zFarPlane)
-            {
-                float reciprocalWidth = 1.0f / (right - left);
-                float reciprocalHeight = 1.0f / (top - bottom);
-                float range = 1.0f / (zNearPlane - zFarPlane);
-                Impl result;
-                result.X = Vector4.Create(reciprocalWidth + reciprocalWidth, 0, 0, 0);
-                result.Y = Vector4.Create(0, reciprocalHeight + reciprocalHeight, 0, 0);
-                result.Z = Vector4.Create(0, 0, range, 0);
-                result.W = Vector4.Create(
-                    -(left + right) * reciprocalWidth,
-                    -(top + bottom) * reciprocalHeight,
-                    range * zNearPlane,
-                    1
-                );
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateOrthographicOffCenterLeftHanded(float left, float right, float bottom, float top, float zNearPlane, float zFarPlane)
-            {
-                float reciprocalWidth = 1.0f / (right - left);
-                float reciprocalHeight = 1.0f / (top - bottom);
-                float range = 1.0f / (zFarPlane - zNearPlane);
-                Impl result;
-                result.X = Vector4.Create(reciprocalWidth + reciprocalWidth, 0, 0, 0);
-                result.Y = Vector4.Create(0, reciprocalHeight + reciprocalHeight, 0, 0);
-                result.Z = Vector4.Create(0, 0, range, 0);
-                result.W = Vector4.Create(
-                    -(left + right) * reciprocalWidth,
-                    -(top + bottom) * reciprocalHeight,
-                    -range * zNearPlane,
-                    1
-                );
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreatePerspective(float width, float height, float nearPlaneDistance, float farPlaneDistance)
-            {
-                ArgumentOutOfRangeException.ThrowIfLessThanOrEqual(nearPlaneDistance, 0.0f);
-                ArgumentOutOfRangeException.ThrowIfLessThanOrEqual(farPlaneDistance, 0.0f);
-                ArgumentOutOfRangeException.ThrowIfGreaterThanOrEqual(nearPlaneDistance, farPlaneDistance);
-                float dblNearPlaneDistance = nearPlaneDistance + nearPlaneDistance;
-                float range = float.IsPositiveInfinity(farPlaneDistance) ? -1.0f : farPlaneDistance / (nearPlaneDistance - farPlaneDistance);
-                Impl result;
-                result.X = Vector4.Create(dblNearPlaneDistance / width, 0, 0, 0);
-                result.Y = Vector4.Create(0, dblNearPlaneDistance / height, 0, 0);
-                result.Z = Vector4.Create(0, 0, range, -1.0f);
-                result.W = Vector4.Create(0, 0, range * nearPlaneDistance, 0);
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreatePerspectiveLeftHanded(float width, float height, float nearPlaneDistance, float farPlaneDistance)
-            {
-                ArgumentOutOfRangeException.ThrowIfLessThanOrEqual(nearPlaneDistance, 0.0f);
-                ArgumentOutOfRangeException.ThrowIfLessThanOrEqual(farPlaneDistance, 0.0f);
-                ArgumentOutOfRangeException.ThrowIfGreaterThanOrEqual(nearPlaneDistance, farPlaneDistance);
-                float dblNearPlaneDistance = nearPlaneDistance + nearPlaneDistance;
-                float range = float.IsPositiveInfinity(farPlaneDistance) ? 1.0f : farPlaneDistance / (farPlaneDistance - nearPlaneDistance);
-                Impl result;
-                result.X = Vector4.Create(dblNearPlaneDistance / width, 0, 0, 0);
-                result.Y = Vector4.Create(0, dblNearPlaneDistance / height, 0, 0);
-                result.Z = Vector4.Create(0, 0, range, 1.0f);
-                result.W = Vector4.Create(0, 0, -range * nearPlaneDistance, 0);
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreatePerspectiveFieldOfView(float fieldOfView, float aspectRatio, float nearPlaneDistance, float farPlaneDistance)
-            {
-                ArgumentOutOfRangeException.ThrowIfLessThanOrEqual(fieldOfView, 0.0f);
-                ArgumentOutOfRangeException.ThrowIfGreaterThanOrEqual(fieldOfView, float.Pi);
-                ArgumentOutOfRangeException.ThrowIfLessThanOrEqual(nearPlaneDistance, 0.0f);
-                ArgumentOutOfRangeException.ThrowIfLessThanOrEqual(farPlaneDistance, 0.0f);
-                ArgumentOutOfRangeException.ThrowIfGreaterThanOrEqual(nearPlaneDistance, farPlaneDistance);
-                float height = 1.0f / float.Tan(fieldOfView * 0.5f);
-                float width = height / aspectRatio;
-                float range = float.IsPositiveInfinity(farPlaneDistance) ? -1.0f : farPlaneDistance / (nearPlaneDistance - farPlaneDistance);
-                Impl result;
-                result.X = Vector4.Create(width, 0, 0, 0);
-                result.Y = Vector4.Create(0, height, 0, 0);
-                result.Z = Vector4.Create(0, 0, range, -1.0f);
-                result.W = Vector4.Create(0, 0, range * nearPlaneDistance, 0);
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreatePerspectiveFieldOfViewLeftHanded(float fieldOfView, float aspectRatio, float nearPlaneDistance, float farPlaneDistance)
-            {
-                ArgumentOutOfRangeException.ThrowIfLessThanOrEqual(fieldOfView, 0.0f);
-                ArgumentOutOfRangeException.ThrowIfGreaterThanOrEqual(fieldOfView, float.Pi);
-                ArgumentOutOfRangeException.ThrowIfLessThanOrEqual(nearPlaneDistance, 0.0f);
-                ArgumentOutOfRangeException.ThrowIfLessThanOrEqual(farPlaneDistance, 0.0f);
-                ArgumentOutOfRangeException.ThrowIfGreaterThanOrEqual(nearPlaneDistance, farPlaneDistance);
-                float height = 1.0f / float.Tan(fieldOfView * 0.5f);
-                float width = height / aspectRatio;
-                float range = float.IsPositiveInfinity(farPlaneDistance) ? 1.0f : farPlaneDistance / (farPlaneDistance - nearPlaneDistance);
-                Impl result;
-                result.X = Vector4.Create(width, 0, 0, 0);
-                result.Y = Vector4.Create(0, height, 0, 0);
-                result.Z = Vector4.Create(0, 0, range, 1.0f);
-                result.W = Vector4.Create(0, 0, -range * nearPlaneDistance, 0);
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreatePerspectiveOffCenter(float left, float right, float bottom, float top, float nearPlaneDistance, float farPlaneDistance)
-            {
-                ArgumentOutOfRangeException.ThrowIfLessThanOrEqual(nearPlaneDistance, 0.0f);
-                ArgumentOutOfRangeException.ThrowIfLessThanOrEqual(farPlaneDistance, 0.0f);
-                ArgumentOutOfRangeException.ThrowIfGreaterThanOrEqual(nearPlaneDistance, farPlaneDistance);
-                float dblNearPlaneDistance = nearPlaneDistance + nearPlaneDistance;
-                float reciprocalWidth = 1.0f / (right - left);
-                float reciprocalHeight = 1.0f / (top - bottom);
-                float range = float.IsPositiveInfinity(farPlaneDistance) ? -1.0f : farPlaneDistance / (nearPlaneDistance - farPlaneDistance);
-                Impl result;
-                result.X = Vector4.Create(dblNearPlaneDistance * reciprocalWidth, 0, 0, 0);
-                result.Y = Vector4.Create(0, dblNearPlaneDistance * reciprocalHeight, 0, 0);
-                result.Z = Vector4.Create(
-                    (left + right) * reciprocalWidth,
-                    (top + bottom) * reciprocalHeight,
-                    range,
-                    -1.0f
-                );
-                result.W = Vector4.Create(0, 0, range * nearPlaneDistance, 0);
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreatePerspectiveOffCenterLeftHanded(float left, float right, float bottom, float top, float nearPlaneDistance, float farPlaneDistance)
-            {
-                ArgumentOutOfRangeException.ThrowIfLessThanOrEqual(nearPlaneDistance, 0.0f);
-                ArgumentOutOfRangeException.ThrowIfLessThanOrEqual(farPlaneDistance, 0.0f);
-                ArgumentOutOfRangeException.ThrowIfGreaterThanOrEqual(nearPlaneDistance, farPlaneDistance);
-                float dblNearPlaneDistance = nearPlaneDistance + nearPlaneDistance;
-                float reciprocalWidth = 1.0f / (right - left);
-                float reciprocalHeight = 1.0f / (top - bottom);
-                float range = float.IsPositiveInfinity(farPlaneDistance) ? 1.0f : farPlaneDistance / (farPlaneDistance - nearPlaneDistance);
-                Impl result;
-                result.X = Vector4.Create(dblNearPlaneDistance * reciprocalWidth, 0, 0, 0);
-                result.Y = Vector4.Create(0, dblNearPlaneDistance * reciprocalHeight, 0, 0);
-                result.Z = Vector4.Create(
-                    -(left + right) * reciprocalWidth,
-                    -(top + bottom) * reciprocalHeight,
-                    range,
-                    1.0f
-                );
-                result.W = Vector4.Create(0, 0, -range * nearPlaneDistance, 0);
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateReflection(in Plane value)
-            {
-                Vector4 p = Plane.Normalize(value).AsVector4();
-                Vector4 s = p * Vector4.Create(-2.0f, -2.0f, -2.0f, 0.0f);
-                Impl result;
-                result.X = Vector4.MultiplyAddEstimate(Vector4.Create(p.X), s, Vector4.UnitX);
-                result.Y = Vector4.MultiplyAddEstimate(Vector4.Create(p.Y), s, Vector4.UnitY);
-                result.Z = Vector4.MultiplyAddEstimate(Vector4.Create(p.Z), s, Vector4.UnitZ);
-                result.W = Vector4.MultiplyAddEstimate(Vector4.Create(p.W), s, Vector4.UnitW);
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateRotationX(float radians)
-            {
-                (float s, float c) = float.SinCos(radians);
-                Impl result;
-                result.X = Vector4.UnitX;
-                result.Y = Vector4.Create(0,  c, s, 0);
-                result.Z = Vector4.Create(0, -s, c, 0);
-                result.W = Vector4.UnitW;
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateRotationX(float radians, in Vector3 centerPoint)
-            {
-                (float s, float c) = float.SinCos(radians);
-                float y = float.MultiplyAddEstimate(centerPoint.Y, 1 - c, +centerPoint.Z * s);
-                float z = float.MultiplyAddEstimate(centerPoint.Z, 1 - c, -centerPoint.Y * s);
-                Impl result;
-                result.X = Vector4.UnitX;
-                result.Y = Vector4.Create(0,  c, s, 0);
-                result.Z = Vector4.Create(0, -s, c, 0);
-                result.W = Vector4.Create(0,  y, z, 1);
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateRotationY(float radians)
-            {
-                (float s, float c) = float.SinCos(radians);
-                Impl result;
-                result.X = Vector4.Create(c, 0, -s, 0);
-                result.Y = Vector4.UnitY;
-                result.Z = Vector4.Create(s, 0,  c, 0);
-                result.W = Vector4.UnitW;
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateRotationY(float radians, in Vector3 centerPoint)
-            {
-                (float s, float c) = float.SinCos(radians);
-                float x = float.MultiplyAddEstimate(centerPoint.X, 1 - c, -centerPoint.Z * s);
-                float z = float.MultiplyAddEstimate(centerPoint.Z, 1 - c, +centerPoint.X * s);
-                Impl result;
-                result.X = Vector4.Create(c, 0, -s, 0);
-                result.Y = Vector4.UnitY;
-                result.Z = Vector4.Create(s, 0,  c, 0);
-                result.W = Vector4.Create(x, 0,  z, 1);
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateRotationZ(float radians)
-            {
-                (float s, float c) = float.SinCos(radians);
-                Impl result;
-                result.X = Vector4.Create( c, s, 0, 0);
-                result.Y = Vector4.Create(-s, c, 0, 0);
-                result.Z = Vector4.UnitZ;
-                result.W = Vector4.UnitW;
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateRotationZ(float radians, in Vector3 centerPoint)
-            {
-                (float s, float c) = float.SinCos(radians);
-                float x = float.MultiplyAddEstimate(centerPoint.X, 1 - c, +centerPoint.Y * s);
-                float y = float.MultiplyAddEstimate(centerPoint.Y, 1 - c, -centerPoint.X * s);
-                Impl result;
-                result.X = Vector4.Create( c, s, 0, 0);
-                result.Y = Vector4.Create(-s, c, 0, 0);
-                result.Z = Vector4.UnitZ;
-                result.W = Vector4.Create(x, y, 0, 1);
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateScale(float scaleX, float scaleY, float scaleZ)
-            {
-                Impl result;
-                result.X = Vector4.Create(scaleX, 0, 0, 0);
-                result.Y = Vector4.Create(0, scaleY, 0, 0);
-                result.Z = Vector4.Create(0, 0, scaleZ, 0);
-                result.W = Vector4.UnitW;
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateScale(float scaleX, float scaleY, float scaleZ, in Vector3 centerPoint)
-            {
-                Impl result;
-                result.X = Vector4.Create(scaleX, 0, 0, 0);
-                result.Y = Vector4.Create(0, scaleY, 0, 0);
-                result.Z = Vector4.Create(0, 0, scaleZ, 0);
-                result.W = Vector4.Create(centerPoint * (Vector3.One - Vector3.Create(scaleX, scaleY, scaleZ)), 1);
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateScale(in Vector3 scales)
-            {
-                Impl result;
-                result.X = Vector4.Create(scales.X, 0, 0, 0);
-                result.Y = Vector4.Create(0, scales.Y, 0, 0);
-                result.Z = Vector4.Create(0, 0, scales.Z, 0);
-                result.W = Vector4.UnitW;
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateScale(in Vector3 scales, in Vector3 centerPoint)
-            {
-                Impl result;
-                result.X = Vector4.Create(scales.X, 0, 0, 0);
-                result.Y = Vector4.Create(0, scales.Y, 0, 0);
-                result.Z = Vector4.Create(0, 0, scales.Z, 0);
-                result.W = Vector4.Create(centerPoint * (Vector3.One - scales), 1);
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateScale(float scale)
-            {
-                Impl result;
-                result.X = Vector4.Create(scale, 0, 0, 0);
-                result.Y = Vector4.Create(0, scale, 0, 0);
-                result.Z = Vector4.Create(0, 0, scale, 0);
-                result.W = Vector4.UnitW;
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateScale(float scale, in Vector3 centerPoint)
-            {
-                Impl result;
-                result.X = Vector4.Create(scale, 0, 0, 0);
-                result.Y = Vector4.Create(0, scale, 0, 0);
-                result.Z = Vector4.Create(0, 0, scale, 0);
-                result.W = Vector4.Create(centerPoint * (Vector3.One - Vector3.Create(scale)), 1);
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateShadow(in Vector3 lightDirection, in Plane plane)
-            {
-                Vector4 p = Plane.Normalize(plane).AsVector4();
-                Vector4 l = lightDirection.AsVector4();
-                float dot = Vector4.Dot(p, l);
-                p = -p;
-                Impl result;
-                result.X = Vector4.MultiplyAddEstimate(l, Vector4.Create(p.X), Vector4.Create(dot, 0, 0, 0));
-                result.Y = Vector4.MultiplyAddEstimate(l, Vector4.Create(p.Y), Vector4.Create(0, dot, 0, 0));
-                result.Z = Vector4.MultiplyAddEstimate(l, Vector4.Create(p.Z), Vector4.Create(0, 0, dot, 0));
-                result.W = Vector4.MultiplyAddEstimate(l, Vector4.Create(p.W), Vector4.Create(0, 0, 0, dot));
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateTranslation(in Vector3 position)
-            {
-                Impl result;
-                result.X = Vector4.UnitX;
-                result.Y = Vector4.UnitY;
-                result.Z = Vector4.UnitZ;
-                result.W = Vector4.Create(position, 1);
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateTranslation(float positionX, float positionY, float positionZ)
-            {
-                Impl result;
-                result.X = Vector4.UnitX;
-                result.Y = Vector4.UnitY;
-                result.Z = Vector4.UnitZ;
-                result.W = Vector4.Create(positionX, positionY, positionZ, 1);
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateViewport(float x, float y, float width, float height, float minDepth, float maxDepth)
-            {
-                Impl result;
-                result.W = Vector4.Create(width, height, 0f, 0f);
-                result.W *= Vector4.Create(0.5f, 0.5f, 0f, 0f);
-                result.X = Vector4.Create(result.W.X, 0f, 0f, 0f);
-                result.Y = Vector4.Create(0f, -result.W.Y, 0f, 0f);
-                result.Z = Vector4.Create(0f, 0f, minDepth - maxDepth, 0f);
-                result.W += Vector4.Create(x, y, minDepth, 1f);
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateViewportLeftHanded(float x, float y, float width, float height, float minDepth, float maxDepth)
-            {
-                Impl result;
-                result.W = Vector4.Create(width, height, 0f, 0f);
-                result.W *= Vector4.Create(0.5f, 0.5f, 0f, 0f);
-                result.X = Vector4.Create(result.W.X, 0f, 0f, 0f);
-                result.Y = Vector4.Create(0f, -result.W.Y, 0f, 0f);
-                result.Z = Vector4.Create(0f, 0f, maxDepth - minDepth, 0f);
-                result.W += Vector4.Create(x, y, minDepth, 1f);
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl CreateWorld(in Vector3 position, in Vector3 forward, in Vector3 up)
-            {
-                Vector3 axisZ = Vector3.Normalize(-forward);
-                Vector3 axisX = Vector3.Normalize(Vector3.Cross(up, axisZ));
-                Vector3 axisY = Vector3.Cross(axisZ, axisX);
-                Impl result;
-                result.X = axisX.AsVector4();
-                result.Y = axisY.AsVector4();
-                result.Z = axisZ.AsVector4();
-                result.W = Vector4.Create(position, 1);
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static unsafe bool Decompose(in Impl matrix, out Vector3 scale, out Quaternion rotation, out Vector3 translation)
-            {
-                Impl matTemp = Identity;
-                Vector3* canonicalBasis = stackalloc Vector3[3] {
-                    Vector3.UnitX,
-                    Vector3.UnitY,
-                    Vector3.UnitZ,
-                };
-                translation = matrix.W.AsVector3();
-                Vector3** vectorBasis = stackalloc Vector3*[3] {
-                    (Vector3*)&matTemp.X,
-                    (Vector3*)&matTemp.Y,
-                    (Vector3*)&matTemp.Z,
-                };
-                *(vectorBasis[0]) = matrix.X.AsVector3();
-                *(vectorBasis[1]) = matrix.Y.AsVector3();
-                *(vectorBasis[2]) = matrix.Z.AsVector3();
-                float* scales = stackalloc float[3] {
-                    vectorBasis[0]->Length(),
-                    vectorBasis[1]->Length(),
-                    vectorBasis[2]->Length(),
-                };
-                uint a, b, c;
-                #region Ranking
-                float x = scales[0];
-                float y = scales[1];
-                float z = scales[2];
-                if (x < y)
-                {
-                    if (y < z)
-                    {
-                        a = 2;
-                        b = 1;
-                        c = 0;
-                    }
-                    else
-                    {
-                        a = 1;
-                        if (x < z)
-                        {
-                            b = 2;
-                            c = 0;
-                        }
-                        else
-                        {
-                            b = 0;
-                            c = 2;
-                        }
-                    }
-                }
-                else
-                {
-                    if (x < z)
-                    {
-                        a = 2;
-                        b = 0;
-                        c = 1;
-                    }
-                    else
-                    {
-                        a = 0;
-                        if (y < z)
-                        {
-                            b = 2;
-                            c = 1;
-                        }
-                        else
-                        {
-                            b = 1;
-                            c = 2;
-                        }
-                    }
-                }
-                #endregion
-                if (scales[a] < DecomposeEpsilon)
-                {
-                    *(vectorBasis[a]) = canonicalBasis[a];
-                }
-                *vectorBasis[a] = Vector3.Normalize(*vectorBasis[a]);
-                if (scales[b] < DecomposeEpsilon)
-                {
-                    uint cc;
-                    float fAbsX, fAbsY, fAbsZ;
-                    fAbsX = float.Abs(vectorBasis[a]->X);
-                    fAbsY = float.Abs(vectorBasis[a]->Y);
-                    fAbsZ = float.Abs(vectorBasis[a]->Z);
-                    #region Ranking
-                    if (fAbsX < fAbsY)
-                    {
-                        if (fAbsY < fAbsZ)
-                        {
-                            cc = 0;
-                        }
-                        else
-                        {
-                            if (fAbsX < fAbsZ)
-                            {
-                                cc = 0;
-                            }
-                            else
-                            {
-                                cc = 2;
-                            }
-                        }
-                    }
-                    else
-                    {
-                        if (fAbsX < fAbsZ)
-                        {
-                            cc = 1;
-                        }
-                        else
-                        {
-                            if (fAbsY < fAbsZ)
-                            {
-                                cc = 1;
-                            }
-                            else
-                            {
-                                cc = 2;
-                            }
-                        }
-                    }
-                    #endregion
-                    *vectorBasis[b] = Vector3.Cross(*vectorBasis[a], canonicalBasis[cc]);
-                }
-                *vectorBasis[b] = Vector3.Normalize(*vectorBasis[b]);
-                if (scales[c] < DecomposeEpsilon)
-                {
-                    *vectorBasis[c] = Vector3.Cross(*vectorBasis[a], *vectorBasis[b]);
-                }
-                *vectorBasis[c] = Vector3.Normalize(*vectorBasis[c]);
-                float det = matTemp.GetDeterminant();
-                if (det < 0.0f)
-                {
-                    scales[a] = -scales[a];
-                    *vectorBasis[a] = -(*vectorBasis[a]);
-                    det = -det;
-                }
-                det -= 1.0f;
-                det *= det;
-                bool result;
-                if (DecomposeEpsilon < det)
-                {
-                    rotation = Quaternion.Identity;
-                    result = false;
-                }
-                else
-                {
-                    rotation = Quaternion.CreateFromRotationMatrix(matTemp.AsM4x4());
-                    result = true;
-                }
-                scale = Unsafe.ReadUnaligned<Vector3>(scales);
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static bool Invert(in Impl matrix, out Impl result)
-            {
-                if (Sse.IsSupported)
-                {
-                    return SseImpl(in matrix, out result);
-                }
-                return SoftwareFallback(in matrix, out result);
-                [CompExactlyDependsOn(typeof(Sse))]
-                static bool SseImpl(in Impl matrix, out Impl result)
-                {
-                    if (!Sse.IsSupported)
-                    {
-                        ThrowPlatformNotSupportedException();
-                    }
-                    Vector128<float> row1 = matrix.X.AsVector128();
-                    Vector128<float> row2 = matrix.Y.AsVector128();
-                    Vector128<float> row3 = matrix.Z.AsVector128();
-                    Vector128<float> row4 = matrix.W.AsVector128();
-                    Vector128<float> vTemp1 = Sse.Shuffle(row1, row2, 0b01_00_01_00); //_MM_SHUFFLE(1, 0, 1, 0)
-                    Vector128<float> vTemp3 = Sse.Shuffle(row1, row2, 0b11_10_11_10); //_MM_SHUFFLE(3, 2, 3, 2)
-                    Vector128<float> vTemp2 = Sse.Shuffle(row3, row4, 0b01_00_01_00); //_MM_SHUFFLE(1, 0, 1, 0)
-                    Vector128<float> vTemp4 = Sse.Shuffle(row3, row4, 0b11_10_11_10); //_MM_SHUFFLE(3, 2, 3, 2)
-                    row1 = Sse.Shuffle(vTemp1, vTemp2, 0b10_00_10_00); //_MM_SHUFFLE(2, 0, 2, 0)
-                    row2 = Sse.Shuffle(vTemp1, vTemp2, 0b11_01_11_01); //_MM_SHUFFLE(3, 1, 3, 1)
-                    row3 = Sse.Shuffle(vTemp3, vTemp4, 0b10_00_10_00); //_MM_SHUFFLE(2, 0, 2, 0)
-                    row4 = Sse.Shuffle(vTemp3, vTemp4, 0b11_01_11_01); //_MM_SHUFFLE(3, 1, 3, 1)
-                    Vector128<float> V00 = Vector128.Shuffle(row3, Vector128.Create(0, 0, 1, 1));
-                    Vector128<float> V10 = Vector128.Shuffle(row4, Vector128.Create(2, 3, 2, 3));
-                    Vector128<float> V01 = Vector128.Shuffle(row1, Vector128.Create(0, 0, 1, 1));
-                    Vector128<float> V11 = Vector128.Shuffle(row2, Vector128.Create(2, 3, 2, 3));
-                    Vector128<float> V02 = Sse.Shuffle(row3, row1, 0b10_00_10_00); //_MM_SHUFFLE(2, 0, 2, 0)
-                    Vector128<float> V12 = Sse.Shuffle(row4, row2, 0b11_01_11_01); //_MM_SHUFFLE(3, 1, 3, 1)
-                    Vector128<float> D0 = V00 * V10;
-                    Vector128<float> D1 = V01 * V11;
-                    Vector128<float> D2 = V02 * V12;
-                    V00 = Vector128.Shuffle(row3, Vector128.Create(2, 3, 2, 3));
-                    V10 = Vector128.Shuffle(row4, Vector128.Create(0, 0, 1, 1));
-                    V01 = Vector128.Shuffle(row1, Vector128.Create(2, 3, 2, 3));
-                    V11 = Vector128.Shuffle(row2, Vector128.Create(0, 0, 1, 1));
-                    V02 = Sse.Shuffle(row3, row1, 0b11_01_11_01); //_MM_SHUFFLE(3, 1, 3, 1)
-                    V12 = Sse.Shuffle(row4, row2, 0b10_00_10_00); //_MM_SHUFFLE(2, 0, 2, 0)
-                    D0 = Vector128.MultiplyAddEstimate(-V00, V10, D0);
-                    D1 = Vector128.MultiplyAddEstimate(-V01, V11, D1);
-                    D2 = Vector128.MultiplyAddEstimate(-V02, V12, D2);
-                    V11 = Sse.Shuffle(D0, D2, 0b01_01_11_01);  //_MM_SHUFFLE(1, 1, 3, 1)
-                    V00 = Vector128.Shuffle(row2, Vector128.Create(1, 2, 0, 1));
-                    V10 = Sse.Shuffle(V11, D0, 0b00_11_00_10); //_MM_SHUFFLE(0, 3, 0, 2)
-                    V01 = Vector128.Shuffle(row1, Vector128.Create(2, 0, 1, 0));
-                    V11 = Sse.Shuffle(V11, D0, 0b10_01_10_01); //_MM_SHUFFLE(2, 1, 2, 1)
-                    Vector128<float> V13 = Sse.Shuffle(D1, D2, 0b11_11_11_01); //_MM_SHUFFLE(3, 3, 3, 1)
-                    V02 = Vector128.Shuffle(row4, Vector128.Create(1, 2, 0, 1));
-                    V12 = Sse.Shuffle(V13, D1, 0b00_11_00_10);                 //_MM_SHUFFLE(0, 3, 0, 2)
-                    Vector128<float> V03 = Vector128.Shuffle(row3, Vector128.Create(2, 0, 1, 0));
-                    V13 = Sse.Shuffle(V13, D1, 0b10_01_10_01);                 //_MM_SHUFFLE(2, 1, 2, 1)
-                    Vector128<float> C0 = V00 * V10;
-                    Vector128<float> C2 = V01 * V11;
-                    Vector128<float> C4 = V02 * V12;
-                    Vector128<float> C6 = V03 * V13;
-                    V11 = Sse.Shuffle(D0, D2, 0b00_00_01_00);   //_MM_SHUFFLE(0, 0, 1, 0)
-                    V00 = Vector128.Shuffle(row2, Vector128.Create(2, 3, 1, 2));
-                    V10 = Sse.Shuffle(D0, V11, 0b10_01_00_11);  //_MM_SHUFFLE(2, 1, 0, 3)
-                    V01 = Vector128.Shuffle(row1, Vector128.Create(3, 2, 3, 1));
-                    V11 = Sse.Shuffle(D0, V11, 0b00_10_01_10);  //_MM_SHUFFLE(0, 2, 1, 2)
-                    V13 = Sse.Shuffle(D1, D2, 0b10_10_01_00);   //_MM_SHUFFLE(2, 2, 1, 0)
-                    V02 = Vector128.Shuffle(row4, Vector128.Create(2, 3, 1, 2));
-                    V12 = Sse.Shuffle(D1, V13, 0b10_01_00_11);  //_MM_SHUFFLE(2, 1, 0, 3)
-                    V03 = Vector128.Shuffle(row3, Vector128.Create(3, 2, 3, 1));
-                    V13 = Sse.Shuffle(D1, V13, 0b_00_10_01_10); //_MM_SHUFFLE(0, 2, 1, 2)
-                    C0 = Vector128.MultiplyAddEstimate(-V00, V10, C0);
-                    C2 = Vector128.MultiplyAddEstimate(-V01, V11, C2);
-                    C4 = Vector128.MultiplyAddEstimate(-V02, V12, C4);
-                    C6 = Vector128.MultiplyAddEstimate(-V03, V13, C6);
-                    V00 = Vector128.Shuffle(row2, Vector128.Create(3, 0, 3, 0));
-                    V10 = Sse.Shuffle(D0, D2, 0b01_00_10_10); //_MM_SHUFFLE(1, 0, 2, 2)
-                    V10 = Vector128.Shuffle(V10, Vector128.Create(0, 3, 2, 0));
-                    V01 = Vector128.Shuffle(row1, Vector128.Create(1, 3, 0, 2));
-                    V11 = Sse.Shuffle(D0, D2, 0b01_00_11_00); //_MM_SHUFFLE(1, 0, 3, 0)
-                    V11 = Vector128.Shuffle(V11, Vector128.Create(3, 0, 1, 2));
-                    V02 = Vector128.Shuffle(row4, Vector128.Create(3, 0, 3, 0));
-                    V12 = Sse.Shuffle(D1, D2, 0b11_10_10_10); //_MM_SHUFFLE(3, 2, 2, 2)
-                    V12 = Vector128.Shuffle(V12, Vector128.Create(0, 3, 2, 0));
-                    V03 = Vector128.Shuffle(row3, Vector128.Create(1, 3, 0, 2));
-                    V13 = Sse.Shuffle(D1, D2, 0b11_10_11_00); //_MM_SHUFFLE(3, 2, 3, 0)
-                    V13 = Vector128.Shuffle(V13, Vector128.Create(3, 0, 1, 2));
-                    V00 *= V10;
-                    V01 *= V11;
-                    V02 *= V12;
-                    V03 *= V13;
-                    Vector128<float> C1 = C0 - V00;
-                    C0 += V00;
-                    Vector128<float> C3 = C2 + V01;
-                    C2 -= V01;
-                    Vector128<float> C5 = C4 - V02;
-                    C4 += V02;
-                    Vector128<float> C7 = C6 + V03;
-                    C6 -= V03;
-                    C0 = Sse.Shuffle(C0, C1, 0b11_01_10_00); //_MM_SHUFFLE(3, 1, 2, 0)
-                    C2 = Sse.Shuffle(C2, C3, 0b11_01_10_00); //_MM_SHUFFLE(3, 1, 2, 0)
-                    C4 = Sse.Shuffle(C4, C5, 0b11_01_10_00); //_MM_SHUFFLE(3, 1, 2, 0)
-                    C6 = Sse.Shuffle(C6, C7, 0b11_01_10_00); //_MM_SHUFFLE(3, 1, 2, 0)
-                    C0 = Vector128.Shuffle(C0, Vector128.Create(0, 2, 1, 3));
-                    C2 = Vector128.Shuffle(C2, Vector128.Create(0, 2, 1, 3));
-                    C4 = Vector128.Shuffle(C4, Vector128.Create(0, 2, 1, 3));
-                    C6 = Vector128.Shuffle(C6, Vector128.Create(0, 2, 1, 3));
-                    float det = Vector4.Dot(C0.AsVector4(), row1.AsVector4());
-                    if (float.Abs(det) < float.Epsilon)
-                    {
-                        Vector4 vNaN = Vector4.Create(float.NaN);
-                        result.X = vNaN;
-                        result.Y = vNaN;
-                        result.Z = vNaN;
-                        result.W = vNaN;
-                        return false;
-                    }
-                    Vector128<float> vTemp = Vector128<float>.One / det;
-                    result.X = (C0 * vTemp).AsVector4();
-                    result.Y = (C2 * vTemp).AsVector4();
-                    result.Z = (C4 * vTemp).AsVector4();
-                    result.W = (C6 * vTemp).AsVector4();
-                    return true;
-                }
-                static bool SoftwareFallback(in Impl matrix, out Impl result)
-                {
-                    float a = matrix.X.X, b = matrix.X.Y, c = matrix.X.Z, d = matrix.X.W;
-                    float e = matrix.Y.X, f = matrix.Y.Y, g = matrix.Y.Z, h = matrix.Y.W;
-                    float i = matrix.Z.X, j = matrix.Z.Y, k = matrix.Z.Z, l = matrix.Z.W;
-                    float m = matrix.W.X, n = matrix.W.Y, o = matrix.W.Z, p = matrix.W.W;
-                    float kp_lo = k * p - l * o;
-                    float jp_ln = j * p - l * n;
-                    float jo_kn = j * o - k * n;
-                    float ip_lm = i * p - l * m;
-                    float io_km = i * o - k * m;
-                    float in_jm = i * n - j * m;
-                    float a11 = +(f * kp_lo - g * jp_ln + h * jo_kn);
-                    float a12 = -(e * kp_lo - g * ip_lm + h * io_km);
-                    float a13 = +(e * jp_ln - f * ip_lm + h * in_jm);
-                    float a14 = -(e * jo_kn - f * io_km + g * in_jm);
-                    float det = a * a11 + b * a12 + c * a13 + d * a14;
-                    if (float.Abs(det) < float.Epsilon)
-                    {
-                        Vector4 vNaN = Vector4.Create(float.NaN);
-                        result.X = vNaN;
-                        result.Y = vNaN;
-                        result.Z = vNaN;
-                        result.W = vNaN;
-                        return false;
-                    }
-                    float invDet = 1.0f / det;
-                    result.X.X = a11 * invDet;
-                    result.Y.X = a12 * invDet;
-                    result.Z.X = a13 * invDet;
-                    result.W.X = a14 * invDet;
-                    result.X.Y = -(b * kp_lo - c * jp_ln + d * jo_kn) * invDet;
-                    result.Y.Y = +(a * kp_lo - c * ip_lm + d * io_km) * invDet;
-                    result.Z.Y = -(a * jp_ln - b * ip_lm + d * in_jm) * invDet;
-                    result.W.Y = +(a * jo_kn - b * io_km + c * in_jm) * invDet;
-                    float gp_ho = g * p - h * o;
-                    float fp_hn = f * p - h * n;
-                    float fo_gn = f * o - g * n;
-                    float ep_hm = e * p - h * m;
-                    float eo_gm = e * o - g * m;
-                    float en_fm = e * n - f * m;
-                    result.X.Z = +(b * gp_ho - c * fp_hn + d * fo_gn) * invDet;
-                    result.Y.Z = -(a * gp_ho - c * ep_hm + d * eo_gm) * invDet;
-                    result.Z.Z = +(a * fp_hn - b * ep_hm + d * en_fm) * invDet;
-                    result.W.Z = -(a * fo_gn - b * eo_gm + c * en_fm) * invDet;
-                    float gl_hk = g * l - h * k;
-                    float fl_hj = f * l - h * j;
-                    float fk_gj = f * k - g * j;
-                    float el_hi = e * l - h * i;
-                    float ek_gi = e * k - g * i;
-                    float ej_fi = e * j - f * i;
-                    result.X.W = -(b * gl_hk - c * fl_hj + d * fk_gj) * invDet;
-                    result.Y.W = +(a * gl_hk - c * el_hi + d * ek_gi) * invDet;
-                    result.Z.W = -(a * fl_hj - b * el_hi + d * ej_fi) * invDet;
-                    result.W.W = +(a * fk_gj - b * ek_gi + c * ej_fi) * invDet;
-                    return true;
-                }
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl Lerp(in Impl left, in Impl right, float amount)
-            {
-                Impl result;
-                result.X = Vector4.Lerp(left.X, right.X, amount);
-                result.Y = Vector4.Lerp(left.Y, right.Y, amount);
-                result.Z = Vector4.Lerp(left.Z, right.Z, amount);
-                result.W = Vector4.Lerp(left.W, right.W, amount);
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl Transform(in Impl value, in Quaternion rotation)
-            {
-                float x2 = rotation.X + rotation.X;
-                float y2 = rotation.Y + rotation.Y;
-                float z2 = rotation.Z + rotation.Z;
-                float wx2 = rotation.W * x2;
-                float wy2 = rotation.W * y2;
-                float wz2 = rotation.W * z2;
-                float xx2 = rotation.X * x2;
-                float xy2 = rotation.X * y2;
-                float xz2 = rotation.X * z2;
-                float yy2 = rotation.Y * y2;
-                float yz2 = rotation.Y * z2;
-                float zz2 = rotation.Z * z2;
-                float q11 = 1.0f - yy2 - zz2;
-                float q21 = xy2 - wz2;
-                float q31 = xz2 + wy2;
-                float q12 = xy2 + wz2;
-                float q22 = 1.0f - xx2 - zz2;
-                float q32 = yz2 - wx2;
-                float q13 = xz2 - wy2;
-                float q23 = yz2 + wx2;
-                float q33 = 1.0f - xx2 - yy2;
-                Impl result;
-                result.X = Vector4.Create(
-                    value.X.X * q11 + value.X.Y * q21 + value.X.Z * q31,
-                    value.X.X * q12 + value.X.Y * q22 + value.X.Z * q32,
-                    value.X.X * q13 + value.X.Y * q23 + value.X.Z * q33,
-                    value.X.W
-                );
-                result.Y = Vector4.Create(
-                    value.Y.X * q11 + value.Y.Y * q21 + value.Y.Z * q31,
-                    value.Y.X * q12 + value.Y.Y * q22 + value.Y.Z * q32,
-                    value.Y.X * q13 + value.Y.Y * q23 + value.Y.Z * q33,
-                    value.Y.W
-                );
-                result.Z = Vector4.Create(
-                    value.Z.X * q11 + value.Z.Y * q21 + value.Z.Z * q31,
-                    value.Z.X * q12 + value.Z.Y * q22 + value.Z.Z * q32,
-                    value.Z.X * q13 + value.Z.Y * q23 + value.Z.Z * q33,
-                    value.Z.W
-                );
-                result.W = Vector4.Create(
-                    value.W.X * q11 + value.W.Y * q21 + value.W.Z * q31,
-                    value.W.X * q12 + value.W.Y * q22 + value.W.Z * q32,
-                    value.W.X * q13 + value.W.Y * q23 + value.W.Z * q33,
-                    value.W.W
-                );
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public static Impl Transpose(in Impl matrix)
-            {
-                Impl result;
-                if (AdvSimd.Arm64.IsSupported)
-                {
-                    Vector128<float> x = matrix.X.AsVector128();
-                    Vector128<float> y = matrix.Y.AsVector128();
-                    Vector128<float> z = matrix.Z.AsVector128();
-                    Vector128<float> w = matrix.W.AsVector128();
-                    Vector128<float> lowerXZ = AdvSimd.Arm64.ZipLow(x, z);          // x[0], z[0], x[1], z[1]
-                    Vector128<float> lowerYW = AdvSimd.Arm64.ZipLow(y, w);          // y[0], w[0], y[1], w[1]
-                    Vector128<float> upperXZ = AdvSimd.Arm64.ZipHigh(x, z);         // x[2], z[2], x[3], z[3]
-                    Vector128<float> upperYW = AdvSimd.Arm64.ZipHigh(y, w);         // y[2], w[2], y[3], z[3]
-                    result.X = AdvSimd.Arm64.ZipLow(lowerXZ, lowerYW).AsVector4();  // x[0], y[0], z[0], w[0]
-                    result.Y = AdvSimd.Arm64.ZipHigh(lowerXZ, lowerYW).AsVector4(); // x[1], y[1], z[1], w[1]
-                    result.Z = AdvSimd.Arm64.ZipLow(upperXZ, upperYW).AsVector4();  // x[2], y[2], z[2], w[2]
-                    result.W = AdvSimd.Arm64.ZipHigh(upperXZ, upperYW).AsVector4(); // x[3], y[3], z[3], w[3]
-                }
-                else if (Sse.IsSupported)
-                {
-                    Vector128<float> x = matrix.X.AsVector128();
-                    Vector128<float> y = matrix.Y.AsVector128();
-                    Vector128<float> z = matrix.Z.AsVector128();
-                    Vector128<float> w = matrix.W.AsVector128();
-                    Vector128<float> lowerXZ = Sse.UnpackLow(x, z);                 // x[0], z[0], x[1], z[1]
-                    Vector128<float> lowerYW = Sse.UnpackLow(y, w);                 // y[0], w[0], y[1], w[1]
-                    Vector128<float> upperXZ = Sse.UnpackHigh(x, z);                // x[2], z[2], x[3], z[3]
-                    Vector128<float> upperYW = Sse.UnpackHigh(y, w);                // y[2], w[2], y[3], z[3]
-                    result.X = Sse.UnpackLow(lowerXZ, lowerYW).AsVector4();         // x[0], y[0], z[0], w[0]
-                    result.Y = Sse.UnpackHigh(lowerXZ, lowerYW).AsVector4();        // x[1], y[1], z[1], w[1]
-                    result.Z = Sse.UnpackLow(upperXZ, upperYW).AsVector4();         // x[2], y[2], z[2], w[2]
-                    result.W = Sse.UnpackHigh(upperXZ, upperYW).AsVector4();        // x[3], y[3], z[3], w[3]
-                }
-                else
-                {
-                    result.X = Vector4.Create(matrix.X.X, matrix.Y.X, matrix.Z.X, matrix.W.X);
-                    result.Y = Vector4.Create(matrix.X.Y, matrix.Y.Y, matrix.Z.Y, matrix.W.Y);
-                    result.Z = Vector4.Create(matrix.X.Z, matrix.Y.Z, matrix.Z.Z, matrix.W.Z);
-                    result.W = Vector4.Create(matrix.X.W, matrix.Y.W, matrix.Z.W, matrix.W.W);
-                }
-                return result;
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public override readonly bool Equals([NotNullWhen(true)] object? obj)
-                => (obj is Matrix4x4 other) && Equals(in other.AsImpl());
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public readonly bool Equals(in Impl other)
-            {
-                return X.Equals(other.X)
-                    && Y.Equals(other.Y)
-                    && Z.Equals(other.Z)
-                    && W.Equals(other.W);
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public readonly float GetDeterminant()
-            {
-                float a = X.X, b = X.Y, c = X.Z, d = X.W;
-                float e = Y.X, f = Y.Y, g = Y.Z, h = Y.W;
-                float i = Z.X, j = Z.Y, k = Z.Z, l = Z.W;
-                float m = W.X, n = W.Y, o = W.Z, p = W.W;
-                float kp_lo = k * p - l * o;
-                float jp_ln = j * p - l * n;
-                float jo_kn = j * o - k * n;
-                float ip_lm = i * p - l * m;
-                float io_km = i * o - k * m;
-                float in_jm = i * n - j * m;
-                return a * (f * kp_lo - g * jp_ln + h * jo_kn) -
-                       b * (e * kp_lo - g * ip_lm + h * io_km) +
-                       c * (e * jp_ln - f * ip_lm + h * in_jm) -
-                       d * (e * jo_kn - f * io_km + g * in_jm);
-            }
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            public override readonly int GetHashCode() => HashCode.Combine(X, Y, Z, W);
-            readonly bool IEquatable<Impl>.Equals(Impl other) => Equals(in other);
-            private static void ThrowPlatformNotSupportedException() => throw new PlatformNotSupportedException();
-        }
-    }
-}

--- a/src/libraries/System.Private.CoreLib/src/System/Threading/Tasks/Task.cs
+++ b//dev/null
@@ -1,3608 +0,0 @@
-using System.Collections.Generic;
-using System.Diagnostics;
-using System.Diagnostics.CodeAnalysis;
-using System.Diagnostics.Tracing;
-using System.Runtime.CompilerServices;
-using System.Runtime.ExceptionServices;
-using System.Runtime.InteropServices;
-using System.Runtime.Versioning;
-using System.Threading.Tasks.Sources;
-namespace System.Threading.Tasks
-{
-    public enum TaskStatus
-    {
-        Created,
-        WaitingForActivation,
-        WaitingToRun,
-        Running,
-        WaitingForChildrenToComplete,
-        RanToCompletion,
-        Canceled,
-        Faulted
-    }
-    [DebuggerTypeProxy(typeof(SystemThreadingTasks_TaskDebugView))]
-    [DebuggerDisplay("Id = {Id}, Status = {Status}, Method = {DebuggerDisplayMethodDescription}")]
-    public class Task : IAsyncResult, IDisposable
-    {
-        [ThreadStatic]
-        internal static Task? t_currentTask;  // The currently executing task.
-        private static int s_taskIdCounter; // static counter used to generate unique task IDs
-        private int m_taskId; // this task's unique ID. initialized only if it is ever requested
-        internal Delegate? m_action;
-        private protected object? m_stateObject; // A state object that can be optionally supplied, passed to action.
-        internal TaskScheduler? m_taskScheduler; // The task scheduler this task runs under.
-        internal volatile int m_stateFlags; // SOS DumpAsync command depends on this name
-        private Task? ParentForDebugger => m_contingentProperties?.m_parent; // Private property used by a debugger to access this Task's parent
-        private int StateFlagsForDebugger => m_stateFlags; // Private property used by a debugger to access this Task's state flags
-        private TaskStateFlags StateFlags => (TaskStateFlags)(m_stateFlags & ~(int)TaskStateFlags.OptionsMask); // Private property used to help with debugging
-        [Flags]
-        internal enum TaskStateFlags
-        {
-            Started = 0x10000,                       // bin: 0000 0000 0000 0001 0000 0000 0000 0000
-            DelegateInvoked = 0x20000,               // bin: 0000 0000 0000 0010 0000 0000 0000 0000
-            Disposed = 0x40000,                      // bin: 0000 0000 0000 0100 0000 0000 0000 0000
-            ExceptionObservedByParent = 0x80000,     // bin: 0000 0000 0000 1000 0000 0000 0000 0000
-            CancellationAcknowledged = 0x100000,     // bin: 0000 0000 0001 0000 0000 0000 0000 0000
-            Faulted = 0x200000,                      // bin: 0000 0000 0010 0000 0000 0000 0000 0000
-            Canceled = 0x400000,                     // bin: 0000 0000 0100 0000 0000 0000 0000 0000
-            WaitingOnChildren = 0x800000,            // bin: 0000 0000 1000 0000 0000 0000 0000 0000
-            RanToCompletion = 0x1000000,             // bin: 0000 0001 0000 0000 0000 0000 0000 0000
-            WaitingForActivation = 0x2000000,        // bin: 0000 0010 0000 0000 0000 0000 0000 0000
-            CompletionReserved = 0x4000000,          // bin: 0000 0100 0000 0000 0000 0000 0000 0000
-            WaitCompletionNotification = 0x10000000, // bin: 0001 0000 0000 0000 0000 0000 0000 0000
-            ExecutionContextIsNull = 0x20000000,     // bin: 0010 0000 0000 0000 0000 0000 0000 0000
-            TaskScheduledWasFired = 0x40000000,      // bin: 0100 0000 0000 0000 0000 0000 0000 0000
-            CompletedMask = Canceled | Faulted | RanToCompletion, // A mask for all of the final states a task may be in. SOS DumpAsync command depends on these values.
-            OptionsMask = 0xFFFF,                    // signifies the Options portion of m_stateFlags bin: 0000 0000 0000 0000 1111 1111 1111 1111
-        }
-        private const int CANCELLATION_REQUESTED = 0x1;
-        private volatile object? m_continuationObject; // SOS DumpAsync command depends on this name
-        private static readonly object s_taskCompletionSentinel = new object();
-        internal static bool s_asyncDebuggingEnabled; // false by default
-        private static Dictionary<int, Task>? s_currentActiveTasks;
-        internal static bool AddToActiveTasks(Task task)
-        {
-            Debug.Assert(task != null, "Null Task objects can't be added to the ActiveTasks collection");
-            Dictionary<int, Task> activeTasks =
-                Volatile.Read(ref s_currentActiveTasks) ??
-                Interlocked.CompareExchange(ref s_currentActiveTasks, new Dictionary<int, Task>(), null) ??
-                s_currentActiveTasks;
-            int taskId = task.Id;
-            lock (activeTasks)
-            {
-                activeTasks[taskId] = task;
-            }
-            return true;
-        }
-        internal static void RemoveFromActiveTasks(Task task)
-        {
-            Dictionary<int, Task>? activeTasks = s_currentActiveTasks;
-            if (activeTasks is null)
-                return;
-            int taskId = task.Id;
-            lock (activeTasks)
-            {
-                activeTasks.Remove(taskId);
-            }
-        }
-        internal sealed class ContingentProperties
-        {
-            internal ExecutionContext? m_capturedContext; // The execution context to run the task within, if any. Only set from non-concurrent contexts.
-            internal volatile ManualResetEventSlim? m_completionEvent; // Lazily created if waiting is required.
-            internal volatile TaskExceptionHolder? m_exceptionsHolder; // Tracks exceptions, if any have occurred
-            internal CancellationToken m_cancellationToken; // Task's cancellation token, if it has one
-            internal StrongBox<CancellationTokenRegistration>? m_cancellationRegistration; // Task's registration with the cancellation token
-            internal volatile int m_internalCancellationRequested; // Its own field because multiple threads legally try to set it.
-            internal volatile int m_completionCountdown = 1;
-            internal volatile List<Task>? m_exceptionalChildren;
-            internal Task? m_parent;
-            internal void SetCompleted()
-            {
-                ManualResetEventSlim? mres = m_completionEvent;
-                if (mres != null) SetEvent(mres);
-            }
-            internal static void SetEvent(ManualResetEventSlim mres)
-            {
-                try
-                {
-                    mres.Set();
-                }
-                catch (ObjectDisposedException)
-                {
-                }
-            }
-            internal void UnregisterCancellationCallback()
-            {
-                if (m_cancellationRegistration != null)
-                {
-                    try { m_cancellationRegistration.Value.Dispose(); }
-                    catch (ObjectDisposedException) { }
-                    m_cancellationRegistration = null;
-                }
-            }
-        }
-        internal ContingentProperties? m_contingentProperties;
-        internal Task(bool canceled, TaskCreationOptions creationOptions, CancellationToken ct)
-        {
-            int optionFlags = (int)creationOptions;
-            if (canceled)
-            {
-                m_stateFlags = (int)TaskStateFlags.Canceled | (int)TaskStateFlags.CancellationAcknowledged | optionFlags;
-                m_contingentProperties = new ContingentProperties() // can't have children, so just instantiate directly
-                {
-                    m_cancellationToken = ct,
-                    m_internalCancellationRequested = CANCELLATION_REQUESTED,
-                };
-            }
-            else
-            {
-                m_stateFlags = (int)TaskStateFlags.RanToCompletion | optionFlags;
-            }
-        }
-        internal Task()
-        {
-            m_stateFlags = (int)TaskStateFlags.WaitingForActivation | (int)InternalTaskOptions.PromiseTask;
-        }
-        internal Task(object? state, TaskCreationOptions creationOptions, bool promiseStyle)
-        {
-            Debug.Assert(promiseStyle, "Promise CTOR: promiseStyle was false");
-            if ((creationOptions & ~(TaskCreationOptions.AttachedToParent | TaskCreationOptions.RunContinuationsAsynchronously)) != 0)
-            {
-                ThrowHelper.ThrowArgumentOutOfRangeException(ExceptionArgument.creationOptions);
-            }
-            if ((creationOptions & TaskCreationOptions.AttachedToParent) != 0)
-            {
-                Task? parent = InternalCurrent;
-                if (parent != null)
-                {
-                    EnsureContingentPropertiesInitializedUnsafe().m_parent = parent;
-                }
-            }
-            TaskConstructorCore(null, state, default, creationOptions, InternalTaskOptions.PromiseTask, null);
-        }
-        public Task(Action action)
-            : this(action, null, null, default, TaskCreationOptions.None, InternalTaskOptions.None, null)
-        {
-        }
-        public Task(Action action, CancellationToken cancellationToken)
-            : this(action, null, null, cancellationToken, TaskCreationOptions.None, InternalTaskOptions.None, null)
-        {
-        }
-        public Task(Action action, TaskCreationOptions creationOptions)
-            : this(action, null, InternalCurrentIfAttached(creationOptions), default, creationOptions, InternalTaskOptions.None, null)
-        {
-        }
-        public Task(Action action, CancellationToken cancellationToken, TaskCreationOptions creationOptions)
-            : this(action, null, InternalCurrentIfAttached(creationOptions), cancellationToken, creationOptions, InternalTaskOptions.None, null)
-        {
-        }
-        public Task(Action<object?> action, object? state)
-            : this(action, state, null, default, TaskCreationOptions.None, InternalTaskOptions.None, null)
-        {
-        }
-        public Task(Action<object?> action, object? state, CancellationToken cancellationToken)
-            : this(action, state, null, cancellationToken, TaskCreationOptions.None, InternalTaskOptions.None, null)
-        {
-        }
-        public Task(Action<object?> action, object? state, TaskCreationOptions creationOptions)
-            : this(action, state, InternalCurrentIfAttached(creationOptions), default, creationOptions, InternalTaskOptions.None, null)
-        {
-        }
-        public Task(Action<object?> action, object? state, CancellationToken cancellationToken, TaskCreationOptions creationOptions)
-            : this(action, state, InternalCurrentIfAttached(creationOptions), cancellationToken, creationOptions, InternalTaskOptions.None, null)
-        {
-        }
-        internal Task(Delegate action, object? state, Task? parent, CancellationToken cancellationToken,
-            TaskCreationOptions creationOptions, InternalTaskOptions internalOptions, TaskScheduler? scheduler)
-        {
-            if (action == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.action);
-            }
-            if (parent != null && (creationOptions & TaskCreationOptions.AttachedToParent) != 0)
-            {
-                EnsureContingentPropertiesInitializedUnsafe().m_parent = parent;
-            }
-            TaskConstructorCore(action, state, cancellationToken, creationOptions, internalOptions, scheduler);
-            Debug.Assert(m_contingentProperties == null || m_contingentProperties.m_capturedContext == null,
-                "Captured an ExecutionContext when one was already captured.");
-            CapturedContext = ExecutionContext.Capture();
-        }
-        internal void TaskConstructorCore(Delegate? action, object? state, CancellationToken cancellationToken,
-            TaskCreationOptions creationOptions, InternalTaskOptions internalOptions, TaskScheduler? scheduler)
-        {
-            m_action = action;
-            m_stateObject = state;
-            m_taskScheduler = scheduler;
-            if ((creationOptions &
-                    ~(TaskCreationOptions.AttachedToParent |
-                      TaskCreationOptions.LongRunning |
-                      TaskCreationOptions.DenyChildAttach |
-                      TaskCreationOptions.HideScheduler |
-                      TaskCreationOptions.PreferFairness |
-                      TaskCreationOptions.RunContinuationsAsynchronously)) != 0)
-            {
-                ThrowHelper.ThrowArgumentOutOfRangeException(ExceptionArgument.creationOptions);
-            }
-#if DEBUG
-            int illegalInternalOptions =
-                    (int)(internalOptions &
-                            ~(InternalTaskOptions.PromiseTask |
-                              InternalTaskOptions.HiddenState |
-                              InternalTaskOptions.ContinuationTask |
-                              InternalTaskOptions.LazyCancellation |
-                              InternalTaskOptions.QueuedByRuntime));
-            Debug.Assert(illegalInternalOptions == 0, "TaskConstructorCore: Illegal internal options");
-#endif
-            Debug.Assert(m_stateFlags == 0, "TaskConstructorCore: non-zero m_stateFlags");
-            Debug.Assert((((int)creationOptions) | (int)TaskStateFlags.OptionsMask) == (int)TaskStateFlags.OptionsMask, "TaskConstructorCore: options take too many bits");
-            int tmpFlags = (int)creationOptions | (int)internalOptions; // one write to the volatile m_stateFlags instead of two when setting the above options
-            m_stateFlags = m_action == null || (internalOptions & InternalTaskOptions.ContinuationTask) != 0 ?
-                tmpFlags | (int)TaskStateFlags.WaitingForActivation :
-                tmpFlags;
-            ContingentProperties? props = m_contingentProperties;
-            if (props != null)
-            {
-                Task? parent = props.m_parent;
-                if (parent != null
-                    && ((creationOptions & TaskCreationOptions.AttachedToParent) != 0)
-                    && ((parent.CreationOptions & TaskCreationOptions.DenyChildAttach) == 0))
-                {
-                    parent.AddNewChild();
-                }
-            }
-            if (cancellationToken.CanBeCanceled)
-            {
-                Debug.Assert((internalOptions & InternalTaskOptions.ContinuationTask) == 0, "TaskConstructorCore: Did not expect to see cancelable token for continuation task.");
-                AssignCancellationToken(cancellationToken, null, null);
-            }
-        }
-        private void AssignCancellationToken(CancellationToken cancellationToken, Task? antecedent, TaskContinuation? continuation)
-        {
-            ContingentProperties props = EnsureContingentPropertiesInitializedUnsafe();
-            props.m_cancellationToken = cancellationToken;
-            try
-            {
-                if (((InternalTaskOptions)Options &
-                    (InternalTaskOptions.QueuedByRuntime | InternalTaskOptions.PromiseTask | InternalTaskOptions.LazyCancellation)) == 0)
-                {
-                    if (cancellationToken.IsCancellationRequested)
-                    {
-                        InternalCancel();
-                    }
-                    else
-                    {
-                        CancellationTokenRegistration ctr;
-                        if (antecedent == null)
-                        {
-                            ctr = cancellationToken.UnsafeRegister(static t => ((Task)t!).InternalCancel(), this);
-                        }
-                        else
-                        {
-                            Debug.Assert(continuation != null);
-                            ctr = cancellationToken.UnsafeRegister(static t =>
-                            {
-                                var tuple = (TupleSlim<Task, Task, TaskContinuation>)t!;
-                                Task targetTask = tuple.Item1;
-                                Task antecedentTask = tuple.Item2;
-                                antecedentTask.RemoveContinuation(tuple.Item3);
-                                targetTask.InternalCancel();
-                            }, new TupleSlim<Task, Task, TaskContinuation>(this, antecedent, continuation));
-                        }
-                        props.m_cancellationRegistration = new StrongBox<CancellationTokenRegistration>(ctr);
-                    }
-                }
-            }
-            catch
-            {
-                Task? parent = m_contingentProperties?.m_parent;
-                if ((parent != null) &&
-                    ((Options & TaskCreationOptions.AttachedToParent) != 0)
-                     && ((parent.Options & TaskCreationOptions.DenyChildAttach) == 0))
-                {
-                    parent.DisregardChild();
-                }
-                throw;
-            }
-        }
-        private string DebuggerDisplayMethodDescription => m_action?.Method.ToString() ?? "{null}";
-        internal TaskCreationOptions Options => OptionsMethod(m_stateFlags);
-        internal static TaskCreationOptions OptionsMethod(int flags)
-        {
-            Debug.Assert(((int)TaskStateFlags.OptionsMask & 1) == 1, "OptionsMask needs a shift in Options.get");
-            return (TaskCreationOptions)(flags & (int)TaskStateFlags.OptionsMask);
-        }
-        internal bool AtomicStateUpdate(int newBits, int illegalBits)
-        {
-            int oldFlags = m_stateFlags;
-            return
-                (oldFlags & illegalBits) == 0 &&
-                (Interlocked.CompareExchange(ref m_stateFlags, oldFlags | newBits, oldFlags) == oldFlags ||
-                 AtomicStateUpdateSlow(newBits, illegalBits));
-        }
-        private bool AtomicStateUpdateSlow(int newBits, int illegalBits)
-        {
-            int flags = m_stateFlags;
-            while (true)
-            {
-                if ((flags & illegalBits) != 0) return false;
-                int oldFlags = Interlocked.CompareExchange(ref m_stateFlags, flags | newBits, flags);
-                if (oldFlags == flags)
-                {
-                    return true;
-                }
-                flags = oldFlags;
-            }
-        }
-        internal bool AtomicStateUpdate(int newBits, int illegalBits, ref int oldFlags)
-        {
-            int flags = oldFlags = m_stateFlags;
-            while (true)
-            {
-                if ((flags & illegalBits) != 0) return false;
-                oldFlags = Interlocked.CompareExchange(ref m_stateFlags, flags | newBits, flags);
-                if (oldFlags == flags)
-                {
-                    return true;
-                }
-                flags = oldFlags;
-            }
-        }
-        internal void SetNotificationForWaitCompletion(bool enabled)
-        {
-            Debug.Assert((Options & (TaskCreationOptions)InternalTaskOptions.PromiseTask) != 0,
-                "Should only be used for promise-style tasks"); // hasn't been vetted on other kinds as there hasn't been a need
-            if (enabled)
-            {
-                bool success = AtomicStateUpdate((int)TaskStateFlags.WaitCompletionNotification,
-                                  (int)TaskStateFlags.CompletedMask | (int)TaskStateFlags.CompletionReserved);
-                Debug.Assert(success, "Tried to set enabled on completed Task");
-            }
-            else
-            {
-                Interlocked.And(ref m_stateFlags, ~(int)TaskStateFlags.WaitCompletionNotification);
-            }
-        }
-        internal bool NotifyDebuggerOfWaitCompletionIfNecessary()
-        {
-            if (IsWaitNotificationEnabled && ShouldNotifyDebuggerOfWaitCompletion)
-            {
-                NotifyDebuggerOfWaitCompletion();
-                return true;
-            }
-            return false;
-        }
-        internal static bool AnyTaskRequiresNotifyDebuggerOfWaitCompletion(Task?[] tasks)
-        {
-            Debug.Assert(tasks != null, "Expected non-null array of tasks");
-            foreach (Task? task in tasks)
-            {
-                if (task != null &&
-                    task.IsWaitNotificationEnabled &&
-                    task.ShouldNotifyDebuggerOfWaitCompletion) // potential recursion
-                {
-                    return true;
-                }
-            }
-            return false;
-        }
-        internal bool IsWaitNotificationEnabledOrNotRanToCompletion
-        {
-            [MethodImpl(MethodImplOptions.AggressiveInlining)]
-            get => (m_stateFlags & ((int)TaskStateFlags.WaitCompletionNotification | (int)TaskStateFlags.RanToCompletion))
-                        != (int)TaskStateFlags.RanToCompletion;
-        }
-        private protected virtual bool ShouldNotifyDebuggerOfWaitCompletion
-        {
-            get
-            {
-                bool isWaitNotificationEnabled = IsWaitNotificationEnabled;
-                Debug.Assert(isWaitNotificationEnabled, "Should only be called if the wait completion bit is set.");
-                return isWaitNotificationEnabled;
-            }
-        }
-        internal bool IsWaitNotificationEnabled => // internal only to enable unit tests; would otherwise be private
-            (m_stateFlags & (int)TaskStateFlags.WaitCompletionNotification) != 0;
-        [MethodImpl(MethodImplOptions.NoOptimization | MethodImplOptions.NoInlining)]
-        private void NotifyDebuggerOfWaitCompletion()
-        {
-            Debug.Assert(IsWaitNotificationEnabled, "Should only be called if the wait completion bit is set.");
-            SetNotificationForWaitCompletion(enabled: false);
-        }
-        internal bool MarkStarted()
-        {
-            return AtomicStateUpdate((int)TaskStateFlags.Started, (int)TaskStateFlags.Canceled | (int)TaskStateFlags.Started);
-        }
-        internal void FireTaskScheduledIfNeeded(TaskScheduler ts)
-        {
-            if ((m_stateFlags & (int)TaskStateFlags.TaskScheduledWasFired) == 0)
-            {
-                m_stateFlags |= (int)TaskStateFlags.TaskScheduledWasFired;
-                if (TplEventSource.Log.IsEnabled())
-                {
-                    Task? currentTask = InternalCurrent;
-                    Task? parentTask = m_contingentProperties?.m_parent;
-                    TplEventSource.Log.TaskScheduled(ts.Id, currentTask == null ? 0 : currentTask.Id,
-                                        this.Id, parentTask == null ? 0 : parentTask.Id, (int)this.Options);
-                }
-            }
-        }
-        internal void AddNewChild()
-        {
-            Debug.Assert(InternalCurrent == this, "Task.AddNewChild(): Called from an external context");
-            ContingentProperties props = EnsureContingentPropertiesInitialized();
-            if (props.m_completionCountdown == 1)
-            {
-                props.m_completionCountdown++;
-            }
-            else
-            {
-                Interlocked.Increment(ref props.m_completionCountdown);
-            }
-        }
-        internal void DisregardChild()
-        {
-            Debug.Assert(InternalCurrent == this, "Task.DisregardChild(): Called from an external context");
-            ContingentProperties props = EnsureContingentPropertiesInitialized();
-            Debug.Assert(props.m_completionCountdown >= 2, "Task.DisregardChild(): Expected parent count to be >= 2");
-            Interlocked.Decrement(ref props.m_completionCountdown);
-        }
-        public void Start()
-        {
-            Start(TaskScheduler.Current);
-        }
-        public void Start(TaskScheduler scheduler)
-        {
-            int flags = m_stateFlags;
-            if (IsCompletedMethod(flags))
-            {
-                ThrowHelper.ThrowInvalidOperationException(ExceptionResource.Task_Start_TaskCompleted);
-            }
-            if (scheduler == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.scheduler);
-            }
-            TaskCreationOptions options = OptionsMethod(flags);
-            if ((options & (TaskCreationOptions)InternalTaskOptions.PromiseTask) != 0)
-            {
-                ThrowHelper.ThrowInvalidOperationException(ExceptionResource.Task_Start_Promise);
-            }
-            if ((options & (TaskCreationOptions)InternalTaskOptions.ContinuationTask) != 0)
-            {
-                ThrowHelper.ThrowInvalidOperationException(ExceptionResource.Task_Start_ContinuationTask);
-            }
-            if (Interlocked.CompareExchange(ref m_taskScheduler, scheduler, null) != null)
-            {
-                ThrowHelper.ThrowInvalidOperationException(ExceptionResource.Task_Start_AlreadyStarted);
-            }
-            ScheduleAndStart(true);
-        }
-        public void RunSynchronously()
-        {
-            InternalRunSynchronously(TaskScheduler.Current, waitForCompletion: true);
-        }
-        public void RunSynchronously(TaskScheduler scheduler)
-        {
-            if (scheduler == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.scheduler);
-            }
-            InternalRunSynchronously(scheduler, waitForCompletion: true);
-        }
-        internal void InternalRunSynchronously(TaskScheduler scheduler, bool waitForCompletion)
-        {
-            Debug.Assert(scheduler != null, "Task.InternalRunSynchronously(): null TaskScheduler");
-            int flags = m_stateFlags;
-            TaskCreationOptions options = OptionsMethod(flags);
-            if ((options & (TaskCreationOptions)InternalTaskOptions.ContinuationTask) != 0)
-            {
-                ThrowHelper.ThrowInvalidOperationException(ExceptionResource.Task_RunSynchronously_Continuation);
-            }
-            if ((options & (TaskCreationOptions)InternalTaskOptions.PromiseTask) != 0)
-            {
-                ThrowHelper.ThrowInvalidOperationException(ExceptionResource.Task_RunSynchronously_Promise);
-            }
-            if (IsCompletedMethod(flags))
-            {
-                ThrowHelper.ThrowInvalidOperationException(ExceptionResource.Task_RunSynchronously_TaskCompleted);
-            }
-            if (Interlocked.CompareExchange(ref m_taskScheduler, scheduler, null) != null)
-            {
-                ThrowHelper.ThrowInvalidOperationException(ExceptionResource.Task_RunSynchronously_AlreadyStarted);
-            }
-            if (MarkStarted())
-            {
-                bool taskQueued = false;
-                try
-                {
-                    if (!scheduler.TryRunInline(this, false))
-                    {
-                        scheduler.InternalQueueTask(this);
-                        taskQueued = true; // only mark this after successfully queuing the task.
-                    }
-                    if (waitForCompletion && !IsCompleted)
-                    {
-                        SpinThenBlockingWait(Timeout.Infinite, default);
-                    }
-                }
-                catch (Exception e)
-                {
-                    if (!taskQueued)
-                    {
-                        TaskSchedulerException tse = new TaskSchedulerException(e);
-                        AddException(tse);
-                        Finish(false);
-                        Debug.Assert(
-                            (m_contingentProperties != null) &&
-                            (m_contingentProperties.m_exceptionsHolder != null) &&
-                            (m_contingentProperties.m_exceptionsHolder.ContainsFaultList),
-                            "Task.InternalRunSynchronously(): Expected m_contingentProperties.m_exceptionsHolder to exist " +
-                            "and to have faults recorded.");
-                        m_contingentProperties.m_exceptionsHolder.MarkAsHandled(false);
-                        throw tse;
-                    }
-                    else throw;
-                }
-            }
-            else
-            {
-                Debug.Assert((m_stateFlags & (int)TaskStateFlags.Canceled) != 0, "Task.RunSynchronously: expected TaskStateFlags.Canceled to be set");
-                ThrowHelper.ThrowInvalidOperationException(ExceptionResource.Task_RunSynchronously_TaskCompleted);
-            }
-        }
-        internal static Task InternalStartNew(
-            Task? creatingTask, Delegate action, object? state, CancellationToken cancellationToken, TaskScheduler scheduler,
-            TaskCreationOptions options, InternalTaskOptions internalOptions)
-        {
-            if (scheduler == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.scheduler);
-            }
-            Task t = new Task(action, state, creatingTask, cancellationToken, options, internalOptions | InternalTaskOptions.QueuedByRuntime, scheduler);
-            t.ScheduleAndStart(false);
-            return t;
-        }
-        internal static int NewId()
-        {
-            int newId;
-            do
-            {
-                newId = Interlocked.Increment(ref s_taskIdCounter);
-            }
-            while (newId == 0);
-            if (TplEventSource.Log.IsEnabled())
-                TplEventSource.Log.NewID(newId);
-            return newId;
-        }
-        public int Id
-        {
-            get
-            {
-                if (Volatile.Read(ref m_taskId) == 0)
-                {
-                    int newId = NewId();
-                    Interlocked.CompareExchange(ref m_taskId, newId, 0);
-                }
-                return m_taskId;
-            }
-        }
-        public static int? CurrentId
-        {
-            get
-            {
-                Task? currentTask = InternalCurrent;
-                if (currentTask != null)
-                    return currentTask.Id;
-                else
-                    return null;
-            }
-        }
-        internal static Task? InternalCurrent => t_currentTask;
-        internal static Task? InternalCurrentIfAttached(TaskCreationOptions creationOptions)
-        {
-            return (creationOptions & TaskCreationOptions.AttachedToParent) != 0 ? InternalCurrent : null;
-        }
-        public AggregateException? Exception
-        {
-            get
-            {
-                AggregateException? e = null;
-                if (IsFaulted) e = GetExceptions(false);
-                Debug.Assert((e == null) || IsFaulted, "Task.Exception_get(): returning non-null value when not Faulted");
-                return e;
-            }
-        }
-        public TaskStatus Status
-        {
-            get
-            {
-                TaskStatus rval;
-                int sf = m_stateFlags;
-                if ((sf & (int)TaskStateFlags.Faulted) != 0) rval = TaskStatus.Faulted;
-                else if ((sf & (int)TaskStateFlags.Canceled) != 0) rval = TaskStatus.Canceled;
-                else if ((sf & (int)TaskStateFlags.RanToCompletion) != 0) rval = TaskStatus.RanToCompletion;
-                else if ((sf & (int)TaskStateFlags.WaitingOnChildren) != 0) rval = TaskStatus.WaitingForChildrenToComplete;
-                else if ((sf & (int)TaskStateFlags.DelegateInvoked) != 0) rval = TaskStatus.Running;
-                else if ((sf & (int)TaskStateFlags.Started) != 0) rval = TaskStatus.WaitingToRun;
-                else if ((sf & (int)TaskStateFlags.WaitingForActivation) != 0) rval = TaskStatus.WaitingForActivation;
-                else rval = TaskStatus.Created;
-                return rval;
-            }
-        }
-        public bool IsCanceled =>
-                (m_stateFlags & ((int)TaskStateFlags.Canceled | (int)TaskStateFlags.Faulted)) == (int)TaskStateFlags.Canceled;
-        internal bool IsCancellationRequested
-        {
-            get
-            {
-                ContingentProperties? props = Volatile.Read(ref m_contingentProperties);
-                return props != null &&
-                    (props.m_internalCancellationRequested == CANCELLATION_REQUESTED ||
-                     props.m_cancellationToken.IsCancellationRequested);
-            }
-        }
-        internal ContingentProperties EnsureContingentPropertiesInitialized()
-        {
-            return Volatile.Read(ref m_contingentProperties) ?? InitializeContingentProperties();
-            ContingentProperties InitializeContingentProperties()
-            {
-                Interlocked.CompareExchange(ref m_contingentProperties, new ContingentProperties(), null);
-                return m_contingentProperties;
-            }
-        }
-        internal ContingentProperties EnsureContingentPropertiesInitializedUnsafe() =>
-            m_contingentProperties ??= new ContingentProperties();
-        internal CancellationToken CancellationToken
-        {
-            get
-            {
-                ContingentProperties? props = Volatile.Read(ref m_contingentProperties);
-                return (props == null) ? default : props.m_cancellationToken;
-            }
-        }
-        internal bool IsCancellationAcknowledged => (m_stateFlags & (int)TaskStateFlags.CancellationAcknowledged) != 0;
-        public bool IsCompleted
-        {
-            get
-            {
-                int stateFlags = m_stateFlags; // enable inlining of IsCompletedMethod by "cast"ing away the volatility
-                return IsCompletedMethod(stateFlags);
-            }
-        }
-        private static bool IsCompletedMethod(int flags)
-        {
-            return (flags & (int)TaskStateFlags.CompletedMask) != 0;
-        }
-        public bool IsCompletedSuccessfully => (m_stateFlags & (int)TaskStateFlags.CompletedMask) == (int)TaskStateFlags.RanToCompletion;
-        public TaskCreationOptions CreationOptions => Options & (TaskCreationOptions)(~InternalTaskOptions.InternalOptionsMask);
-        internal void SpinUntilCompleted()
-        {
-            SpinWait sw = default;
-            while (!IsCompleted)
-            {
-                sw.SpinOnce();
-            }
-        }
-        WaitHandle IAsyncResult.AsyncWaitHandle
-        {
-            get
-            {
-                bool isDisposed = (m_stateFlags & (int)TaskStateFlags.Disposed) != 0;
-                if (isDisposed)
-                {
-                    ThrowHelper.ThrowObjectDisposedException(ExceptionResource.Task_ThrowIfDisposed);
-                }
-                return CompletedEvent.WaitHandle;
-            }
-        }
-        public object? AsyncState => (m_stateFlags & (int)InternalTaskOptions.HiddenState) == 0 ? m_stateObject : null;
-        bool IAsyncResult.CompletedSynchronously => false;
-        internal TaskScheduler? ExecutingTaskScheduler => m_taskScheduler;
-        public static TaskFactory Factory { get; } = new TaskFactory();
-        internal static readonly Task<VoidTaskResult> s_cachedCompleted = new Task<VoidTaskResult>(false, default, (TaskCreationOptions)InternalTaskOptions.DoNotDispose, default);
-        public static Task CompletedTask => s_cachedCompleted;
-        internal ManualResetEventSlim CompletedEvent
-        {
-            get
-            {
-                ContingentProperties contingentProps = EnsureContingentPropertiesInitialized();
-                if (contingentProps.m_completionEvent == null)
-                {
-                    bool wasCompleted = IsCompleted;
-                    ManualResetEventSlim newMre = new ManualResetEventSlim(wasCompleted);
-                    if (Interlocked.CompareExchange(ref contingentProps.m_completionEvent, newMre, null) != null)
-                    {
-                        newMre.Dispose();
-                    }
-                    else if (!wasCompleted && IsCompleted)
-                    {
-                        ContingentProperties.SetEvent(newMre);
-                    }
-                }
-                return contingentProps.m_completionEvent;
-            }
-        }
-        internal bool ExceptionRecorded
-        {
-            get
-            {
-                ContingentProperties? props = Volatile.Read(ref m_contingentProperties);
-                return (props != null) && (props.m_exceptionsHolder != null) && (props.m_exceptionsHolder.ContainsFaultList);
-            }
-        }
-        [MemberNotNullWhen(true, nameof(Exception))]
-        public bool IsFaulted =>
-            (m_stateFlags & (int)TaskStateFlags.Faulted) != 0;
-        internal ExecutionContext? CapturedContext
-        {
-            get
-            {
-                if ((m_stateFlags & (int)TaskStateFlags.ExecutionContextIsNull) == (int)TaskStateFlags.ExecutionContextIsNull)
-                {
-                    return null;
-                }
-                else
-                {
-                    return m_contingentProperties?.m_capturedContext ?? ExecutionContext.Default;
-                }
-            }
-            set
-            {
-                if (value == null)
-                {
-                    m_stateFlags |= (int)TaskStateFlags.ExecutionContextIsNull;
-                }
-                else if (value != ExecutionContext.Default) // not the default context, then inflate the contingent properties and set it
-                {
-                    EnsureContingentPropertiesInitializedUnsafe().m_capturedContext = value;
-                }
-            }
-        }
-        public void Dispose()
-        {
-            Dispose(true);
-            GC.SuppressFinalize(this);
-        }
-        protected virtual void Dispose(bool disposing)
-        {
-            if (disposing)
-            {
-                if ((Options & (TaskCreationOptions)InternalTaskOptions.DoNotDispose) != 0)
-                {
-                    return;
-                }
-                if (!IsCompleted)
-                {
-                    ThrowHelper.ThrowInvalidOperationException(ExceptionResource.Task_Dispose_NotCompleted);
-                }
-                ContingentProperties? cp = Volatile.Read(ref m_contingentProperties);
-                if (cp != null)
-                {
-                    ManualResetEventSlim? ev = cp.m_completionEvent;
-                    if (ev != null)
-                    {
-                        cp.m_completionEvent = null;
-                        ContingentProperties.SetEvent(ev);
-                        ev.Dispose();
-                    }
-                }
-            }
-            m_stateFlags |= (int)TaskStateFlags.Disposed;
-        }
-        internal void ScheduleAndStart(bool needsProtection)
-        {
-            Debug.Assert(m_taskScheduler != null, "expected a task scheduler to have been selected");
-            Debug.Assert((m_stateFlags & (int)TaskStateFlags.Started) == 0, "task has already started");
-            if (needsProtection)
-            {
-                if (!MarkStarted())
-                {
-                    return;
-                }
-            }
-            else
-            {
-                m_stateFlags |= (int)TaskStateFlags.Started;
-            }
-            if (s_asyncDebuggingEnabled)
-                AddToActiveTasks(this);
-            if (TplEventSource.Log.IsEnabled() && (Options & (TaskCreationOptions)InternalTaskOptions.ContinuationTask) == 0)
-            {
-                Debug.Assert(m_action != null, "Must have a delegate to be in ScheduleAndStart");
-                TplEventSource.Log.TraceOperationBegin(this.Id, "Task: " + m_action.GetMethodName(), 0);
-            }
-            try
-            {
-                m_taskScheduler.InternalQueueTask(this);
-            }
-            catch (Exception e)
-            {
-                TaskSchedulerException tse = new TaskSchedulerException(e);
-                AddException(tse);
-                Finish(false);
-                if ((Options & (TaskCreationOptions)InternalTaskOptions.ContinuationTask) == 0)
-                {
-                    Debug.Assert(
-                        (m_contingentProperties != null) &&
-                        (m_contingentProperties.m_exceptionsHolder != null) &&
-                        (m_contingentProperties.m_exceptionsHolder.ContainsFaultList),
-                            "Task.ScheduleAndStart(): Expected m_contingentProperties.m_exceptionsHolder to exist " +
-                            "and to have faults recorded.");
-                    m_contingentProperties.m_exceptionsHolder.MarkAsHandled(false);
-                }
-                throw tse;
-            }
-        }
-        internal void AddException(object exceptionObject)
-        {
-            Debug.Assert(exceptionObject != null, "Task.AddException: Expected a non-null exception object");
-            AddException(exceptionObject, representsCancellation: false);
-        }
-        internal void AddException(object exceptionObject, bool representsCancellation)
-        {
-            Debug.Assert(exceptionObject != null, "Task.AddException: Expected a non-null exception object");
-#if DEBUG
-            var eoAsException = exceptionObject as Exception;
-            var eoAsEnumerableException = exceptionObject as IEnumerable<Exception>;
-            var eoAsEdi = exceptionObject as ExceptionDispatchInfo;
-            var eoAsEnumerableEdi = exceptionObject as IEnumerable<ExceptionDispatchInfo>;
-            Debug.Assert(
-                eoAsException != null || eoAsEnumerableException != null || eoAsEdi != null || eoAsEnumerableEdi != null,
-                "Task.AddException: Expected an Exception, ExceptionDispatchInfo, or an IEnumerable<> of one of those");
-            var eoAsOce = exceptionObject as OperationCanceledException;
-            Debug.Assert(
-                !representsCancellation ||
-                eoAsOce != null ||
-                (eoAsEdi != null && eoAsEdi.SourceException is OperationCanceledException),
-                "representsCancellation should be true only if an OCE was provided.");
-#endif
-            ContingentProperties props = EnsureContingentPropertiesInitialized();
-            if (props.m_exceptionsHolder == null)
-            {
-                TaskExceptionHolder holder = new TaskExceptionHolder(this);
-                if (Interlocked.CompareExchange(ref props.m_exceptionsHolder, holder, null) != null)
-                {
-                    holder.MarkAsHandled(false);
-                }
-            }
-            lock (props)
-            {
-                props.m_exceptionsHolder.Add(exceptionObject, representsCancellation);
-            }
-        }
-        private AggregateException? GetExceptions(bool includeTaskCanceledExceptions)
-        {
-            Exception? canceledException = null;
-            if (includeTaskCanceledExceptions && IsCanceled)
-            {
-                canceledException = new TaskCanceledException(this);
-                canceledException.SetCurrentStackTrace();
-            }
-            if (ExceptionRecorded)
-            {
-                Debug.Assert(m_contingentProperties != null && m_contingentProperties.m_exceptionsHolder != null, "ExceptionRecorded should imply this");
-                return m_contingentProperties.m_exceptionsHolder.CreateExceptionObject(false, canceledException);
-            }
-            else if (canceledException != null)
-            {
-                return new AggregateException(canceledException);
-            }
-            return null;
-        }
-        internal List<ExceptionDispatchInfo> GetExceptionDispatchInfos()
-        {
-            Debug.Assert(IsFaulted && ExceptionRecorded, "Must only be used when the task has faulted with exceptions.");
-            return m_contingentProperties!.m_exceptionsHolder!.GetExceptionDispatchInfos();
-        }
-        internal ExceptionDispatchInfo? GetCancellationExceptionDispatchInfo()
-        {
-            Debug.Assert(IsCanceled, "Must only be used when the task has canceled.");
-            return Volatile.Read(ref m_contingentProperties)?.m_exceptionsHolder?.GetCancellationExceptionDispatchInfo(); // may be null
-        }
-        internal void MarkExceptionsAsHandled()
-        {
-            Volatile.Read(ref m_contingentProperties)?.m_exceptionsHolder?.MarkAsHandled(calledFromFinalizer: false);
-        }
-        internal void ThrowIfExceptional(bool includeTaskCanceledExceptions)
-        {
-            Debug.Assert(IsCompleted, "ThrowIfExceptional(): Expected IsCompleted == true");
-            Exception? exception = GetExceptions(includeTaskCanceledExceptions);
-            if (exception != null)
-            {
-                UpdateExceptionObservedStatus();
-                throw exception;
-            }
-        }
-        internal static void ThrowAsync(Exception exception, SynchronizationContext? targetContext)
-        {
-            var edi = ExceptionDispatchInfo.Capture(exception);
-            if (targetContext != null)
-            {
-                try
-                {
-                    targetContext.Post(static state => ((ExceptionDispatchInfo)state!).Throw(), edi);
-                    return;
-                }
-                catch (Exception postException)
-                {
-                    edi = ExceptionDispatchInfo.Capture(new AggregateException(exception, postException));
-                }
-            }
-#if NATIVEAOT
-            RuntimeExceptionHelpers.ReportUnhandledException(edi.SourceException);
-#else
-            ThreadPool.QueueUserWorkItem(static state => ((ExceptionDispatchInfo)state!).Throw(), edi);
-#endif // NATIVEAOT
-        }
-        internal void UpdateExceptionObservedStatus()
-        {
-            Task? parent = m_contingentProperties?.m_parent;
-            if ((parent != null)
-                && ((Options & TaskCreationOptions.AttachedToParent) != 0)
-                && ((parent.CreationOptions & TaskCreationOptions.DenyChildAttach) == 0)
-                && InternalCurrent == parent)
-            {
-                m_stateFlags |= (int)TaskStateFlags.ExceptionObservedByParent;
-            }
-        }
-        internal bool IsExceptionObservedByParent => (m_stateFlags & (int)TaskStateFlags.ExceptionObservedByParent) != 0;
-        internal bool IsDelegateInvoked => (m_stateFlags & (int)TaskStateFlags.DelegateInvoked) != 0;
-        internal void Finish(bool userDelegateExecute)
-        {
-            if (m_contingentProperties == null)
-            {
-                FinishStageTwo();
-            }
-            else
-            {
-                FinishSlow(userDelegateExecute);
-            }
-        }
-        private void FinishSlow(bool userDelegateExecute)
-        {
-            Debug.Assert(userDelegateExecute || m_contingentProperties != null);
-            if (!userDelegateExecute)
-            {
-                FinishStageTwo();
-            }
-            else
-            {
-                ContingentProperties props = m_contingentProperties!;
-                if ((props.m_completionCountdown == 1) ||
-                    Interlocked.Decrement(ref props.m_completionCountdown) == 0) // Reaching this sub clause means there may be remaining active children,
-                {
-                    FinishStageTwo();
-                }
-                else
-                {
-                    AtomicStateUpdate((int)TaskStateFlags.WaitingOnChildren, (int)TaskStateFlags.Faulted | (int)TaskStateFlags.Canceled | (int)TaskStateFlags.RanToCompletion);
-                }
-                List<Task>? exceptionalChildren = props.m_exceptionalChildren;
-                if (exceptionalChildren != null)
-                {
-                    lock (exceptionalChildren)
-                    {
-                        exceptionalChildren.RemoveAll(t => t.IsExceptionObservedByParent); // RemoveAll has better performance than doing it ourselves
-                    }
-                }
-            }
-        }
-        private void FinishStageTwo()
-        {
-            ContingentProperties? cp = Volatile.Read(ref m_contingentProperties);
-            if (cp != null)
-            {
-                AddExceptionsFromChildren(cp);
-            }
-            int completionState;
-            if (ExceptionRecorded)
-            {
-                completionState = (int)TaskStateFlags.Faulted;
-                if (TplEventSource.Log.IsEnabled())
-                    TplEventSource.Log.TraceOperationEnd(this.Id, AsyncCausalityStatus.Error);
-                if (s_asyncDebuggingEnabled)
-                    RemoveFromActiveTasks(this);
-            }
-            else if (IsCancellationRequested && IsCancellationAcknowledged)
-            {
-                completionState = (int)TaskStateFlags.Canceled;
-                if (TplEventSource.Log.IsEnabled())
-                    TplEventSource.Log.TraceOperationEnd(this.Id, AsyncCausalityStatus.Canceled);
-                if (s_asyncDebuggingEnabled)
-                    RemoveFromActiveTasks(this);
-            }
-            else
-            {
-                completionState = (int)TaskStateFlags.RanToCompletion;
-                if (TplEventSource.Log.IsEnabled())
-                    TplEventSource.Log.TraceOperationEnd(this.Id, AsyncCausalityStatus.Completed);
-                if (s_asyncDebuggingEnabled)
-                    RemoveFromActiveTasks(this);
-            }
-            Interlocked.Exchange(ref m_stateFlags, m_stateFlags | completionState);
-            cp = Volatile.Read(ref m_contingentProperties); // need to re-read after updating state
-            if (cp != null)
-            {
-                cp.SetCompleted();
-                cp.UnregisterCancellationCallback();
-            }
-            FinishStageThree();
-        }
-        internal void FinishStageThree()
-        {
-            m_action = null;
-            ContingentProperties? cp = m_contingentProperties;
-            if (cp != null)
-            {
-                cp.m_capturedContext = null;
-                NotifyParentIfPotentiallyAttachedTask();
-            }
-            FinishContinuations();
-        }
-        internal void NotifyParentIfPotentiallyAttachedTask()
-        {
-            Task? parent = m_contingentProperties?.m_parent;
-            if (parent != null
-                 && ((parent.CreationOptions & TaskCreationOptions.DenyChildAttach) == 0)
-                 && (((TaskCreationOptions)(m_stateFlags & (int)TaskStateFlags.OptionsMask)) & TaskCreationOptions.AttachedToParent) != 0)
-            {
-                parent.ProcessChildCompletion(this);
-            }
-        }
-        internal void ProcessChildCompletion(Task childTask)
-        {
-            Debug.Assert(childTask != null);
-            Debug.Assert(childTask.IsCompleted, "ProcessChildCompletion was called for an uncompleted task");
-            Debug.Assert(childTask.m_contingentProperties?.m_parent == this, "ProcessChildCompletion should only be called for a child of this task");
-            ContingentProperties? props = Volatile.Read(ref m_contingentProperties);
-            if (childTask.IsFaulted && !childTask.IsExceptionObservedByParent)
-            {
-                if (props!.m_exceptionalChildren == null)
-                {
-                    Interlocked.CompareExchange(ref props.m_exceptionalChildren, new List<Task>(), null);
-                }
-                List<Task>? tmp = props.m_exceptionalChildren;
-                if (tmp != null)
-                {
-                    lock (tmp)
-                    {
-                        tmp.Add(childTask);
-                    }
-                }
-            }
-            if (Interlocked.Decrement(ref props!.m_completionCountdown) == 0)
-            {
-                FinishStageTwo();
-            }
-        }
-        internal void AddExceptionsFromChildren(ContingentProperties props)
-        {
-            Debug.Assert(props != null);
-            List<Task>? exceptionalChildren = props.m_exceptionalChildren;
-            if (exceptionalChildren != null)
-            {
-                lock (exceptionalChildren)
-                {
-                    foreach (Task task in exceptionalChildren)
-                    {
-                        Debug.Assert(task.IsCompleted, "Expected all tasks in list to be completed");
-                        if (task.IsFaulted && !task.IsExceptionObservedByParent)
-                        {
-                            TaskExceptionHolder? exceptionHolder = Volatile.Read(ref task.m_contingentProperties)!.m_exceptionsHolder;
-                            Debug.Assert(exceptionHolder != null);
-                            AddException(exceptionHolder.CreateExceptionObject(false, null));
-                        }
-                    }
-                }
-                props.m_exceptionalChildren = null;
-            }
-        }
-        internal bool ExecuteEntry()
-        {
-            int previousState = 0;
-            if (!AtomicStateUpdate((int)TaskStateFlags.DelegateInvoked,
-                                    (int)TaskStateFlags.DelegateInvoked | (int)TaskStateFlags.CompletedMask,
-                                    ref previousState) && (previousState & (int)TaskStateFlags.Canceled) == 0)
-            {
-                return false;
-            }
-            if (!IsCancellationRequested & !IsCanceled)
-            {
-                ExecuteWithThreadLocal(ref t_currentTask);
-            }
-            else
-            {
-                ExecuteEntryCancellationRequestedOrCanceled();
-            }
-            return true;
-        }
-        internal virtual void ExecuteFromThreadPool(Thread threadPoolThread) => ExecuteEntryUnsafe(threadPoolThread);
-        internal void ExecuteEntryUnsafe(Thread? threadPoolThread) // used instead of ExecuteEntry() when we don't have to worry about double-execution prevent
-        {
-            m_stateFlags |= (int)TaskStateFlags.DelegateInvoked;
-            if (!IsCancellationRequested & !IsCanceled)
-            {
-                ExecuteWithThreadLocal(ref t_currentTask, threadPoolThread);
-            }
-            else
-            {
-                ExecuteEntryCancellationRequestedOrCanceled();
-            }
-        }
-        internal void ExecuteEntryCancellationRequestedOrCanceled()
-        {
-            if (!IsCanceled)
-            {
-                int prevState = Interlocked.Exchange(ref m_stateFlags, m_stateFlags | (int)TaskStateFlags.Canceled);
-                if ((prevState & (int)TaskStateFlags.Canceled) == 0)
-                {
-                    CancellationCleanupLogic();
-                }
-            }
-        }
-        private void ExecuteWithThreadLocal(ref Task? currentTaskSlot, Thread? threadPoolThread = null)
-        {
-            Task? previousTask = currentTaskSlot;
-            TplEventSource log = TplEventSource.Log;
-            Guid savedActivityID = default;
-            bool etwIsEnabled = log.IsEnabled();
-            if (etwIsEnabled)
-            {
-                if (log.TasksSetActivityIds)
-                    EventSource.SetCurrentThreadActivityId(TplEventSource.CreateGuidForTaskID(this.Id), out savedActivityID);
-                if (previousTask != null)
-                    log.TaskStarted(previousTask.m_taskScheduler!.Id, previousTask.Id, this.Id);
-                else
-                    log.TaskStarted(TaskScheduler.Current.Id, 0, this.Id);
-                log.TraceSynchronousWorkBegin(this.Id, CausalitySynchronousWork.Execution);
-            }
-            try
-            {
-                currentTaskSlot = this;
-                try
-                {
-                    ExecutionContext? ec = CapturedContext;
-                    if (ec == null)
-                    {
-                        InnerInvoke();
-                    }
-                    else
-                    {
-                        if (threadPoolThread is null)
-                        {
-                            ExecutionContext.RunInternal(ec, s_ecCallback, this);
-                        }
-                        else
-                        {
-                            ExecutionContext.RunFromThreadPoolDispatchLoop(threadPoolThread, ec, s_ecCallback, this);
-                        }
-                    }
-                }
-                catch (Exception exn)
-                {
-                    HandleException(exn);
-                }
-                if (etwIsEnabled)
-                    log.TraceSynchronousWorkEnd(CausalitySynchronousWork.Execution);
-                Finish(true);
-            }
-            finally
-            {
-                currentTaskSlot = previousTask;
-                if (etwIsEnabled)
-                {
-                    if (previousTask != null)
-                        log.TaskCompleted(previousTask.m_taskScheduler!.Id, previousTask.Id, this.Id, IsFaulted);
-                    else
-                        log.TaskCompleted(TaskScheduler.Current.Id, 0, this.Id, IsFaulted);
-                    if (log.TasksSetActivityIds)
-                        EventSource.SetCurrentThreadActivityId(savedActivityID);
-                }
-            }
-        }
-        private static readonly ContextCallback s_ecCallback = obj =>
-        {
-            Debug.Assert(obj is Task);
-            Unsafe.As<Task>(obj).InnerInvoke();
-        };
-        internal virtual void InnerInvoke()
-        {
-            Debug.Assert(m_action != null, "Null action in InnerInvoke()");
-            if (m_action is Action action)
-            {
-                action();
-                return;
-            }
-            if (m_action is Action<object?> actionWithState)
-            {
-                actionWithState(m_stateObject);
-                return;
-            }
-            Debug.Fail("Invalid m_action in Task");
-        }
-        private void HandleException(Exception unhandledException)
-        {
-            Debug.Assert(unhandledException != null);
-            if (unhandledException is OperationCanceledException exceptionAsOce && IsCancellationRequested &&
-                m_contingentProperties!.m_cancellationToken == exceptionAsOce.CancellationToken)
-            {
-                SetCancellationAcknowledged();
-                AddException(exceptionAsOce, representsCancellation: true);
-            }
-            else
-            {
-                AddException(unhandledException);
-            }
-        }
-        #region Await Support
-        public TaskAwaiter GetAwaiter()
-        {
-            return new TaskAwaiter(this);
-        }
-        public ConfiguredTaskAwaitable ConfigureAwait(bool continueOnCapturedContext)
-        {
-            return new ConfiguredTaskAwaitable(this, continueOnCapturedContext ? ConfigureAwaitOptions.ContinueOnCapturedContext : ConfigureAwaitOptions.None);
-        }
-        public ConfiguredTaskAwaitable ConfigureAwait(ConfigureAwaitOptions options)
-        {
-            if ((options & ~(ConfigureAwaitOptions.ContinueOnCapturedContext |
-                             ConfigureAwaitOptions.SuppressThrowing |
-                             ConfigureAwaitOptions.ForceYielding)) != 0)
-            {
-                ThrowHelper.ThrowArgumentOutOfRangeException(ExceptionArgument.options);
-            }
-            return new ConfiguredTaskAwaitable(this, options);
-        }
-        internal void SetContinuationForAwait(
-            Action continuationAction, bool continueOnCapturedContext, bool flowExecutionContext)
-        {
-            Debug.Assert(continuationAction != null);
-            TaskContinuation? tc;
-            if (continueOnCapturedContext)
-            {
-                if (SynchronizationContext.Current is SynchronizationContext syncCtx && syncCtx.GetType() != typeof(SynchronizationContext))
-                {
-                    tc = new SynchronizationContextAwaitTaskContinuation(syncCtx, continuationAction, flowExecutionContext);
-                    goto HaveTaskContinuation;
-                }
-                if (TaskScheduler.InternalCurrent is TaskScheduler scheduler && scheduler != TaskScheduler.Default)
-                {
-                    tc = new TaskSchedulerAwaitTaskContinuation(scheduler, continuationAction, flowExecutionContext);
-                    goto HaveTaskContinuation;
-                }
-            }
-            if (flowExecutionContext)
-            {
-                tc = new AwaitTaskContinuation(continuationAction, flowExecutionContext: true);
-                goto HaveTaskContinuation;
-            }
-            Debug.Assert(!flowExecutionContext, "We already determined we're not required to flow context.");
-            if (!AddTaskContinuation(continuationAction, addBeforeOthers: false))
-            {
-                AwaitTaskContinuation.UnsafeScheduleAction(continuationAction, this);
-            }
-            return;
-            HaveTaskContinuation:
-            if (!AddTaskContinuation(tc, addBeforeOthers: false))
-            {
-                tc.Run(this, canInlineContinuationTask: false);
-            }
-        }
-        internal void UnsafeSetContinuationForAwait(IAsyncStateMachineBox stateMachineBox, bool continueOnCapturedContext)
-        {
-            Debug.Assert(stateMachineBox != null);
-            TaskContinuation? tc;
-            if (continueOnCapturedContext)
-            {
-                if (SynchronizationContext.Current is SynchronizationContext syncCtx && syncCtx.GetType() != typeof(SynchronizationContext))
-                {
-                    tc = new SynchronizationContextAwaitTaskContinuation(syncCtx, stateMachineBox.MoveNextAction, flowExecutionContext: false);
-                    goto HaveTaskContinuation;
-                }
-                if (TaskScheduler.InternalCurrent is TaskScheduler scheduler && scheduler != TaskScheduler.Default)
-                {
-                    tc = new TaskSchedulerAwaitTaskContinuation(scheduler, stateMachineBox.MoveNextAction, flowExecutionContext: false);
-                    goto HaveTaskContinuation;
-                }
-            }
-            if (!AddTaskContinuation(stateMachineBox, addBeforeOthers: false))
-            {
-                ThreadPool.UnsafeQueueUserWorkItemInternal(stateMachineBox, preferLocal: true);
-            }
-            return;
-            HaveTaskContinuation:
-            if (!AddTaskContinuation(tc, addBeforeOthers: false))
-            {
-                tc.Run(this, canInlineContinuationTask: false);
-            }
-        }
-        public static YieldAwaitable Yield()
-        {
-            return default;
-        }
-        #endregion
-        public void Wait()
-        {
-#if DEBUG
-            bool waitResult =
-#endif
-            Wait(Timeout.Infinite, default);
-#if DEBUG
-            Debug.Assert(waitResult, "expected wait to succeed");
-#endif
-        }
-        public bool Wait(TimeSpan timeout) => Wait(timeout, default);
-        public bool Wait(TimeSpan timeout, CancellationToken cancellationToken)
-        {
-            long totalMilliseconds = (long)timeout.TotalMilliseconds;
-            if (totalMilliseconds < -1 || totalMilliseconds > int.MaxValue)
-            {
-                ThrowHelper.ThrowArgumentOutOfRangeException(ExceptionArgument.timeout);
-            }
-            cancellationToken.ThrowIfCancellationRequested();
-            return Wait((int)totalMilliseconds, cancellationToken);
-        }
-        public void Wait(CancellationToken cancellationToken)
-        {
-            Wait(Timeout.Infinite, cancellationToken);
-        }
-        public bool Wait(int millisecondsTimeout)
-        {
-            return Wait(millisecondsTimeout, default);
-        }
-        public bool Wait(int millisecondsTimeout, CancellationToken cancellationToken)
-        {
-            if (millisecondsTimeout < -1)
-            {
-                ThrowHelper.ThrowArgumentOutOfRangeException(ExceptionArgument.millisecondsTimeout);
-            }
-            if (!IsWaitNotificationEnabledOrNotRanToCompletion) // (!DebuggerBitSet && RanToCompletion)
-                return true;
-            if (!InternalWait(millisecondsTimeout, cancellationToken))
-                return false;
-            if (IsWaitNotificationEnabledOrNotRanToCompletion) // avoid a few unnecessary volatile reads if we completed successfully
-            {
-                NotifyDebuggerOfWaitCompletionIfNecessary();
-                if (IsCanceled) cancellationToken.ThrowIfCancellationRequested();
-                ThrowIfExceptional(true);
-            }
-            Debug.Assert((m_stateFlags & (int)TaskStateFlags.Faulted) == 0, "Task.Wait() completing when in Faulted state.");
-            return true;
-        }
-        public Task WaitAsync(CancellationToken cancellationToken) => WaitAsync(Timeout.UnsignedInfinite, TimeProvider.System, cancellationToken);
-        public Task WaitAsync(TimeSpan timeout) => WaitAsync(ValidateTimeout(timeout, ExceptionArgument.timeout), TimeProvider.System, default);
-        public Task WaitAsync(TimeSpan timeout, TimeProvider timeProvider)
-        {
-            ArgumentNullException.ThrowIfNull(timeProvider);
-            return WaitAsync(ValidateTimeout(timeout, ExceptionArgument.timeout), timeProvider, default);
-        }
-        public Task WaitAsync(TimeSpan timeout, CancellationToken cancellationToken) =>
-            WaitAsync(ValidateTimeout(timeout, ExceptionArgument.timeout), TimeProvider.System, cancellationToken);
-        public Task WaitAsync(TimeSpan timeout, TimeProvider timeProvider, CancellationToken cancellationToken)
-        {
-            ArgumentNullException.ThrowIfNull(timeProvider);
-            return WaitAsync(ValidateTimeout(timeout, ExceptionArgument.timeout), timeProvider, cancellationToken);
-        }
-        private Task WaitAsync(uint millisecondsTimeout, TimeProvider timeProvider, CancellationToken cancellationToken)
-        {
-            if (IsCompleted || (!cancellationToken.CanBeCanceled && millisecondsTimeout == Timeout.UnsignedInfinite))
-            {
-                return this;
-            }
-            if (cancellationToken.IsCancellationRequested)
-            {
-                return FromCanceled(cancellationToken);
-            }
-            if (millisecondsTimeout == 0)
-            {
-                return FromException(new TimeoutException());
-            }
-            return new CancellationPromise<VoidTaskResult>(this, millisecondsTimeout, timeProvider, cancellationToken);
-        }
-        private protected sealed class CancellationPromise<TResult> : Task<TResult>, ITaskCompletionAction
-        {
-            private readonly Task _task;
-            private readonly CancellationTokenRegistration _registration;
-            private readonly ITimer? _timer;
-            internal CancellationPromise(Task source, uint millisecondsDelay, TimeProvider timeProvider, CancellationToken token)
-            {
-                Debug.Assert(source != null);
-                Debug.Assert(millisecondsDelay != 0);
-                _task = source;
-                source.AddCompletionAction(this);
-                if (millisecondsDelay != Timeout.UnsignedInfinite)
-                {
-                    TimerCallback callback = static state =>
-                    {
-                        var thisRef = (CancellationPromise<TResult>)state!;
-                        if (thisRef.TrySetException(new TimeoutException()))
-                        {
-                            thisRef.Cleanup();
-                        }
-                    };
-                    if (timeProvider == TimeProvider.System)
-                    {
-                        _timer = new TimerQueueTimer(callback, this, millisecondsDelay, Timeout.UnsignedInfinite, flowExecutionContext: false);
-                    }
-                    else
-                    {
-                        using (ExecutionContext.SuppressFlow())
-                        {
-                            _timer = timeProvider.CreateTimer(callback, this, TimeSpan.FromMilliseconds(millisecondsDelay), Timeout.InfiniteTimeSpan);
-                        }
-                    }
-                }
-                _registration = token.UnsafeRegister(static (state, cancellationToken) =>
-                {
-                    var thisRef = (CancellationPromise<TResult>)state!;
-                    if (thisRef.TrySetCanceled(cancellationToken))
-                    {
-                        thisRef.Cleanup();
-                    }
-                }, this);
-                if (IsCompleted)
-                {
-                    Cleanup();
-                }
-            }
-            bool ITaskCompletionAction.InvokeMayRunArbitraryCode => true;
-            void ITaskCompletionAction.Invoke(Task completingTask)
-            {
-                Debug.Assert(completingTask.IsCompleted);
-                bool set = completingTask.Status switch
-                {
-                    TaskStatus.Canceled => TrySetCanceled(completingTask.CancellationToken, completingTask.GetCancellationExceptionDispatchInfo()),
-                    TaskStatus.Faulted => TrySetException(completingTask.GetExceptionDispatchInfos()),
-                    _ => completingTask is Task<TResult> taskTResult ? TrySetResult(taskTResult.Result) : TrySetResult(),
-                };
-                if (set)
-                {
-                    Cleanup();
-                }
-            }
-            private void Cleanup()
-            {
-                _registration.Dispose();
-                _timer?.Dispose();
-                _task.RemoveContinuation(this);
-            }
-        }
-        private bool WrappedTryRunInline()
-        {
-            if (m_taskScheduler == null)
-                return false;
-            try
-            {
-                return m_taskScheduler.TryRunInline(this, true);
-            }
-            catch (Exception e)
-            {
-                throw new TaskSchedulerException(e);
-            }
-        }
-        [MethodImpl(MethodImplOptions.NoOptimization)]  // this is needed for the parallel debugger
-        internal bool InternalWait(int millisecondsTimeout, CancellationToken cancellationToken) =>
-            InternalWaitCore(millisecondsTimeout, cancellationToken);
-        private bool InternalWaitCore(int millisecondsTimeout, CancellationToken cancellationToken)
-        {
-            bool returnValue = IsCompleted;
-            if (returnValue)
-            {
-                return true;
-            }
-            TplEventSource log = TplEventSource.Log;
-            bool etwIsEnabled = log.IsEnabled();
-            if (etwIsEnabled)
-            {
-                Task? currentTask = InternalCurrent;
-                log.TaskWaitBegin(
-                    currentTask != null ? currentTask.m_taskScheduler!.Id : TaskScheduler.Default.Id, currentTask != null ? currentTask.Id : 0,
-                    this.Id, TplEventSource.TaskWaitBehavior.Synchronous, 0);
-            }
-            Debugger.NotifyOfCrossThreadDependency();
-            if (millisecondsTimeout == Timeout.Infinite && !cancellationToken.CanBeCanceled &&
-                WrappedTryRunInline() && IsCompleted) // TryRunInline doesn't guarantee completion, as there may be unfinished children.
-            {
-                returnValue = true;
-            }
-            else
-            {
-                returnValue = SpinThenBlockingWait(millisecondsTimeout, cancellationToken);
-            }
-            Debug.Assert(IsCompleted || millisecondsTimeout != Timeout.Infinite);
-            if (etwIsEnabled)
-            {
-                Task? currentTask = InternalCurrent;
-                if (currentTask != null)
-                {
-                    log.TaskWaitEnd(currentTask.m_taskScheduler!.Id, currentTask.Id, this.Id);
-                }
-                else
-                {
-                    log.TaskWaitEnd(TaskScheduler.Default.Id, 0, this.Id);
-                }
-                log.TaskWaitContinuationComplete(this.Id);
-            }
-            return returnValue;
-        }
-        private sealed class SetOnInvokeMres : ManualResetEventSlim, ITaskCompletionAction
-        {
-            internal SetOnInvokeMres() : base(false, 0) { }
-            public void Invoke(Task completingTask) { Set(); }
-            public bool InvokeMayRunArbitraryCode => false;
-        }
-        private bool SpinThenBlockingWait(int millisecondsTimeout, CancellationToken cancellationToken)
-        {
-            bool infiniteWait = millisecondsTimeout == Timeout.Infinite;
-            uint startTimeTicks = infiniteWait ? 0 : (uint)Environment.TickCount;
-            bool returnValue = SpinWait(millisecondsTimeout);
-            if (!returnValue)
-            {
-#if CORECLR
-                if (ThreadPoolWorkQueue.s_prioritizationExperiment)
-                {
-                    ThreadPoolWorkQueue.TransferAllLocalWorkItemsToHighPriorityGlobalQueue();
-                }
-#endif
-                var mres = new SetOnInvokeMres();
-                try
-                {
-                    AddCompletionAction(mres, addBeforeOthers: true);
-#pragma warning disable CA1416 // Validate platform compatibility, issue: https://github.com/dotnet/runtime/issues/44622
-                    if (infiniteWait)
-                    {
-                        bool notifyWhenUnblocked = ThreadPool.NotifyThreadBlocked();
-                        try
-                        {
-                            returnValue = mres.Wait(Timeout.Infinite, cancellationToken);
-                        }
-                        finally
-                        {
-                            if (notifyWhenUnblocked)
-                            {
-                                ThreadPool.NotifyThreadUnblocked();
-                            }
-                        }
-                    }
-                    else
-                    {
-                        uint elapsedTimeTicks = ((uint)Environment.TickCount) - startTimeTicks;
-                        if (elapsedTimeTicks < millisecondsTimeout)
-                        {
-                            bool notifyWhenUnblocked = ThreadPool.NotifyThreadBlocked();
-                            try
-                            {
-                                returnValue = mres.Wait((int)(millisecondsTimeout - elapsedTimeTicks), cancellationToken);
-                            }
-                            finally
-                            {
-                                if (notifyWhenUnblocked)
-                                {
-                                    ThreadPool.NotifyThreadUnblocked();
-                                }
-                            }
-                        }
-                    }
-#pragma warning restore CA1416
-                }
-                finally
-                {
-                    if (!IsCompleted) RemoveContinuation(mres);
-                }
-            }
-            return returnValue;
-        }
-        private bool SpinWait(int millisecondsTimeout)
-        {
-            if (IsCompleted) return true;
-            if (millisecondsTimeout == 0)
-            {
-                return false;
-            }
-            int spinCount = Threading.SpinWait.SpinCountforSpinBeforeWait;
-            SpinWait spinner = default;
-            while (spinner.Count < spinCount)
-            {
-                spinner.SpinOnce(sleep1Threshold: -1);
-                if (IsCompleted)
-                {
-                    return true;
-                }
-            }
-            return false;
-        }
-        internal void InternalCancel()
-        {
-            Debug.Assert((Options & (TaskCreationOptions)InternalTaskOptions.PromiseTask) == 0, "Task.InternalCancel() did not expect promise-style task");
-            TaskSchedulerException? tse = null;
-            bool popped = false;
-            if ((m_stateFlags & (int)TaskStateFlags.Started) != 0)
-            {
-                TaskScheduler? ts = m_taskScheduler;
-                try
-                {
-                    popped = (ts != null) && ts.TryDequeue(this);
-                }
-                catch (Exception e)
-                {
-                    tse = new TaskSchedulerException(e);
-                }
-            }
-            RecordInternalCancellationRequest();
-            bool mustCleanup = false;
-            if (popped)
-            {
-                mustCleanup = AtomicStateUpdate((int)TaskStateFlags.Canceled, (int)TaskStateFlags.Canceled | (int)TaskStateFlags.DelegateInvoked);
-            }
-            else if ((m_stateFlags & (int)TaskStateFlags.Started) == 0)
-            {
-                mustCleanup = AtomicStateUpdate((int)TaskStateFlags.Canceled,
-                    (int)TaskStateFlags.Canceled | (int)TaskStateFlags.Started | (int)TaskStateFlags.RanToCompletion |
-                    (int)TaskStateFlags.Faulted | (int)TaskStateFlags.DelegateInvoked);
-            }
-            if (mustCleanup)
-            {
-                CancellationCleanupLogic();
-            }
-            if (tse != null)
-            {
-                throw tse;
-            }
-        }
-        internal void InternalCancelContinueWithInitialState()
-        {
-            const int IllegalFlags = (int)TaskStateFlags.Started | (int)TaskStateFlags.CompletedMask | (int)TaskStateFlags.DelegateInvoked;
-            Debug.Assert((m_stateFlags & IllegalFlags) == 0, "The continuation was in an invalid state.");
-            Debug.Assert((m_stateFlags & (int)TaskStateFlags.WaitingForActivation) != 0, "Expected continuation to be waiting for activation");
-            Debug.Assert(m_contingentProperties is null || m_contingentProperties.m_cancellationToken == default);
-            m_stateFlags |= (int)TaskStateFlags.Canceled; // no synchronization necessary, per above comment
-            CancellationCleanupLogic();
-        }
-        internal void RecordInternalCancellationRequest()
-        {
-            EnsureContingentPropertiesInitialized().m_internalCancellationRequested = CANCELLATION_REQUESTED;
-        }
-        internal void RecordInternalCancellationRequest(CancellationToken tokenToRecord, object? cancellationException)
-        {
-            Debug.Assert((Options & (TaskCreationOptions)InternalTaskOptions.PromiseTask) != 0, "Task.RecordInternalCancellationRequest(CancellationToken) only valid for promise-style task");
-            RecordInternalCancellationRequest();
-            Debug.Assert(m_contingentProperties!.m_cancellationToken == default);
-            if (tokenToRecord != default)
-            {
-                m_contingentProperties.m_cancellationToken = tokenToRecord;
-            }
-            if (cancellationException != null)
-            {
-#if DEBUG
-                var oce = cancellationException as OperationCanceledException;
-                if (oce == null)
-                {
-                    var edi = cancellationException as ExceptionDispatchInfo;
-                    Debug.Assert(edi != null, "Expected either an OCE or an EDI");
-                    oce = edi.SourceException as OperationCanceledException;
-                    Debug.Assert(oce != null, "Expected EDI to contain an OCE");
-                }
-                Debug.Assert(oce.CancellationToken == tokenToRecord,
-                                "Expected OCE's token to match the provided token.");
-#endif
-                AddException(cancellationException, representsCancellation: true);
-            }
-        }
-        internal void CancellationCleanupLogic()
-        {
-            Debug.Assert((m_stateFlags & ((int)TaskStateFlags.Canceled | (int)TaskStateFlags.CompletionReserved)) != 0, "Task.CancellationCleanupLogic(): Task not canceled or reserved.");
-            Interlocked.Exchange(ref m_stateFlags, m_stateFlags | (int)TaskStateFlags.Canceled);
-            ContingentProperties? cp = Volatile.Read(ref m_contingentProperties);
-            if (cp != null)
-            {
-                cp.SetCompleted();
-                cp.UnregisterCancellationCallback();
-            }
-            if (TplEventSource.Log.IsEnabled())
-                TplEventSource.Log.TraceOperationEnd(this.Id, AsyncCausalityStatus.Canceled);
-            if (s_asyncDebuggingEnabled)
-                RemoveFromActiveTasks(this);
-            FinishStageThree();
-        }
-        private void SetCancellationAcknowledged()
-        {
-            Debug.Assert(this == InternalCurrent, "SetCancellationAcknowledged() should only be called while this is still the current task");
-            Debug.Assert(IsCancellationRequested, "SetCancellationAcknowledged() should not be called if the task's CT wasn't signaled");
-            m_stateFlags |= (int)TaskStateFlags.CancellationAcknowledged;
-        }
-        internal bool TrySetResult()
-        {
-            if (AtomicStateUpdate(
-                (int)TaskStateFlags.CompletionReserved | (int)TaskStateFlags.RanToCompletion,
-                (int)TaskStateFlags.CompletionReserved | (int)TaskStateFlags.RanToCompletion | (int)TaskStateFlags.Faulted | (int)TaskStateFlags.Canceled))
-            {
-                ContingentProperties? props = m_contingentProperties;
-                if (props != null)
-                {
-                    NotifyParentIfPotentiallyAttachedTask();
-                    props.SetCompleted();
-                }
-                FinishContinuations();
-                return true;
-            }
-            return false;
-        }
-        internal bool TrySetException(object exceptionObject)
-        {
-            Debug.Assert(exceptionObject != null, "Expected non-null exceptionObject argument");
-            Debug.Assert(
-                (exceptionObject is Exception) || (exceptionObject is IEnumerable<Exception>) ||
-                (exceptionObject is ExceptionDispatchInfo) || (exceptionObject is IEnumerable<ExceptionDispatchInfo>),
-                "Expected exceptionObject to be either Exception, ExceptionDispatchInfo, or IEnumerable<> of one of those");
-            bool returnValue = false;
-            EnsureContingentPropertiesInitialized();
-            if (AtomicStateUpdate(
-                (int)TaskStateFlags.CompletionReserved,
-                (int)TaskStateFlags.CompletionReserved | (int)TaskStateFlags.RanToCompletion | (int)TaskStateFlags.Faulted | (int)TaskStateFlags.Canceled))
-            {
-                AddException(exceptionObject); // handles singleton exception or exception collection
-                Finish(false);
-                returnValue = true;
-            }
-            return returnValue;
-        }
-        internal bool TrySetCanceled(CancellationToken tokenToRecord)
-        {
-            return TrySetCanceled(tokenToRecord, null);
-        }
-        internal bool TrySetCanceled(CancellationToken tokenToRecord, object? cancellationException)
-        {
-            Debug.Assert(
-                cancellationException == null ||
-                cancellationException is OperationCanceledException ||
-                (cancellationException as ExceptionDispatchInfo)?.SourceException is OperationCanceledException,
-                "Expected null or an OperationCanceledException");
-            bool returnValue = false;
-            if (AtomicStateUpdate(
-                (int)TaskStateFlags.CompletionReserved,
-                (int)TaskStateFlags.CompletionReserved | (int)TaskStateFlags.Canceled | (int)TaskStateFlags.Faulted | (int)TaskStateFlags.RanToCompletion))
-            {
-                RecordInternalCancellationRequest(tokenToRecord, cancellationException);
-                CancellationCleanupLogic(); // perform cancellation cleanup actions
-                returnValue = true;
-            }
-            return returnValue;
-        }
-        internal void FinishContinuations()
-        {
-            object? continuationObject = Interlocked.Exchange(ref m_continuationObject, s_taskCompletionSentinel);
-            if (continuationObject != null)
-            {
-                RunContinuations(continuationObject);
-            }
-        }
-        private void RunContinuations(object continuationObject) // separated out of FinishContinuations to enable it to be inlined
-        {
-            Debug.Assert(continuationObject != null);
-            TplEventSource log = TplEventSource.Log;
-            bool etwIsEnabled = log.IsEnabled();
-            if (etwIsEnabled)
-                log.TraceSynchronousWorkBegin(this.Id, CausalitySynchronousWork.CompletionNotification);
-            bool canInlineContinuations =
-                (m_stateFlags & (int)TaskCreationOptions.RunContinuationsAsynchronously) == 0 &&
-                RuntimeHelpers.TryEnsureSufficientExecutionStack();
-            switch (continuationObject)
-            {
-                case IAsyncStateMachineBox stateMachineBox:
-                    AwaitTaskContinuation.RunOrScheduleAction(stateMachineBox, canInlineContinuations);
-                    LogFinishCompletionNotification();
-                    return;
-                case Action action:
-                    AwaitTaskContinuation.RunOrScheduleAction(action, canInlineContinuations);
-                    LogFinishCompletionNotification();
-                    return;
-                case TaskContinuation tc:
-                    tc.Run(this, canInlineContinuations);
-                    LogFinishCompletionNotification();
-                    return;
-                case ITaskCompletionAction completionAction:
-                    RunOrQueueCompletionAction(completionAction, canInlineContinuations);
-                    LogFinishCompletionNotification();
-                    return;
-            }
-            List<object?> list = (List<object?>)continuationObject;
-            Monitor.Enter(list);
-            Monitor.Exit(list);
-            Span<object?> continuations = CollectionsMarshal.AsSpan(list);
-            if (canInlineContinuations)
-            {
-                bool forceContinuationsAsync = false;
-                for (int i = 0; i < continuations.Length; i++)
-                {
-                    object? currentContinuation = continuations[i];
-                    if (currentContinuation == null)
-                    {
-                        continue;
-                    }
-                    else if (currentContinuation is ContinueWithTaskContinuation stc)
-                    {
-                        if ((stc.m_options & TaskContinuationOptions.ExecuteSynchronously) == 0)
-                        {
-                            continuations[i] = null; // so that we can skip this later
-                            if (etwIsEnabled)
-                                log.RunningContinuationList(Id, i, stc);
-                            stc.Run(this, canInlineContinuationTask: false);
-                        }
-                    }
-                    else if (currentContinuation is not ITaskCompletionAction)
-                    {
-                        if (forceContinuationsAsync)
-                        {
-                            continuations[i] = null;
-                            if (etwIsEnabled)
-                                log.RunningContinuationList(Id, i, currentContinuation);
-                            switch (currentContinuation)
-                            {
-                                case IAsyncStateMachineBox stateMachineBox:
-                                    AwaitTaskContinuation.RunOrScheduleAction(stateMachineBox, allowInlining: false);
-                                    break;
-                                case Action action:
-                                    AwaitTaskContinuation.RunOrScheduleAction(action, allowInlining: false);
-                                    break;
-                                default:
-                                    Debug.Assert(currentContinuation is TaskContinuation);
-                                    ((TaskContinuation)currentContinuation).Run(this, canInlineContinuationTask: false);
-                                    break;
-                            }
-                        }
-                        forceContinuationsAsync = true;
-                    }
-                }
-            }
-            for (int i = 0; i < continuations.Length; i++)
-            {
-                object? currentContinuation = continuations[i];
-                if (currentContinuation == null)
-                {
-                    continue;
-                }
-                continuations[i] = null; // to enable free'ing up memory earlier
-                if (etwIsEnabled)
-                    log.RunningContinuationList(Id, i, currentContinuation);
-                switch (currentContinuation)
-                {
-                    case IAsyncStateMachineBox stateMachineBox:
-                        AwaitTaskContinuation.RunOrScheduleAction(stateMachineBox, canInlineContinuations);
-                        break;
-                    case Action action:
-                        AwaitTaskContinuation.RunOrScheduleAction(action, canInlineContinuations);
-                        break;
-                    case TaskContinuation tc:
-                        tc.Run(this, canInlineContinuations);
-                        break;
-                    default:
-                        Debug.Assert(currentContinuation is ITaskCompletionAction);
-                        RunOrQueueCompletionAction((ITaskCompletionAction)currentContinuation, canInlineContinuations);
-                        break;
-                }
-            }
-            LogFinishCompletionNotification();
-        }
-        private void RunOrQueueCompletionAction(ITaskCompletionAction completionAction, bool allowInlining)
-        {
-            if (allowInlining || !completionAction.InvokeMayRunArbitraryCode)
-            {
-                completionAction.Invoke(this);
-            }
-            else
-            {
-                ThreadPool.UnsafeQueueUserWorkItemInternal(new CompletionActionInvoker(completionAction, this), preferLocal: true);
-            }
-        }
-        private static void LogFinishCompletionNotification()
-        {
-            if (TplEventSource.Log.IsEnabled())
-                TplEventSource.Log.TraceSynchronousWorkEnd(CausalitySynchronousWork.CompletionNotification);
-        }
-        #region Continuation methods
-        #region Action<Task> continuation
-        public Task ContinueWith(Action<Task> continuationAction)
-        {
-            return ContinueWith(continuationAction, TaskScheduler.Current, default, TaskContinuationOptions.None);
-        }
-        public Task ContinueWith(Action<Task> continuationAction, CancellationToken cancellationToken)
-        {
-            return ContinueWith(continuationAction, TaskScheduler.Current, cancellationToken, TaskContinuationOptions.None);
-        }
-        public Task ContinueWith(Action<Task> continuationAction, TaskScheduler scheduler)
-        {
-            return ContinueWith(continuationAction, scheduler, default, TaskContinuationOptions.None);
-        }
-        public Task ContinueWith(Action<Task> continuationAction, TaskContinuationOptions continuationOptions)
-        {
-            return ContinueWith(continuationAction, TaskScheduler.Current, default, continuationOptions);
-        }
-        public Task ContinueWith(Action<Task> continuationAction, CancellationToken cancellationToken,
-                                 TaskContinuationOptions continuationOptions, TaskScheduler scheduler)
-        {
-            return ContinueWith(continuationAction, scheduler, cancellationToken, continuationOptions);
-        }
-        private Task ContinueWith(Action<Task> continuationAction, TaskScheduler scheduler,
-            CancellationToken cancellationToken, TaskContinuationOptions continuationOptions)
-        {
-            if (continuationAction == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.continuationAction);
-            }
-            if (scheduler == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.scheduler);
-            }
-            CreationOptionsFromContinuationOptions(continuationOptions, out TaskCreationOptions creationOptions, out InternalTaskOptions internalOptions);
-            Task continuationTask = new ContinuationTaskFromTask(
-                this, continuationAction, null,
-                creationOptions, internalOptions
-            );
-            ContinueWithCore(continuationTask, scheduler, cancellationToken, continuationOptions);
-            return continuationTask;
-        }
-        #endregion
-        #region Action<Task, Object> continuation
-        public Task ContinueWith(Action<Task, object?> continuationAction, object? state)
-        {
-            return ContinueWith(continuationAction, state, TaskScheduler.Current, default, TaskContinuationOptions.None);
-        }
-        public Task ContinueWith(Action<Task, object?> continuationAction, object? state, CancellationToken cancellationToken)
-        {
-            return ContinueWith(continuationAction, state, TaskScheduler.Current, cancellationToken, TaskContinuationOptions.None);
-        }
-        public Task ContinueWith(Action<Task, object?> continuationAction, object? state, TaskScheduler scheduler)
-        {
-            return ContinueWith(continuationAction, state, scheduler, default, TaskContinuationOptions.None);
-        }
-        public Task ContinueWith(Action<Task, object?> continuationAction, object? state, TaskContinuationOptions continuationOptions)
-        {
-            return ContinueWith(continuationAction, state, TaskScheduler.Current, default, continuationOptions);
-        }
-        public Task ContinueWith(Action<Task, object?> continuationAction, object? state, CancellationToken cancellationToken,
-                                 TaskContinuationOptions continuationOptions, TaskScheduler scheduler)
-        {
-            return ContinueWith(continuationAction, state, scheduler, cancellationToken, continuationOptions);
-        }
-        private Task ContinueWith(Action<Task, object?> continuationAction, object? state, TaskScheduler scheduler,
-            CancellationToken cancellationToken, TaskContinuationOptions continuationOptions)
-        {
-            if (continuationAction == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.continuationAction);
-            }
-            if (scheduler == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.scheduler);
-            }
-            CreationOptionsFromContinuationOptions(continuationOptions, out TaskCreationOptions creationOptions, out InternalTaskOptions internalOptions);
-            Task continuationTask = new ContinuationTaskFromTask(
-                this, continuationAction, state,
-                creationOptions, internalOptions
-            );
-            ContinueWithCore(continuationTask, scheduler, cancellationToken, continuationOptions);
-            return continuationTask;
-        }
-        #endregion
-        #region Func<Task, TResult> continuation
-        public Task<TResult> ContinueWith<TResult>(Func<Task, TResult> continuationFunction)
-        {
-            return ContinueWith(continuationFunction, TaskScheduler.Current, default,
-                TaskContinuationOptions.None);
-        }
-        public Task<TResult> ContinueWith<TResult>(Func<Task, TResult> continuationFunction, CancellationToken cancellationToken)
-        {
-            return ContinueWith(continuationFunction, TaskScheduler.Current, cancellationToken, TaskContinuationOptions.None);
-        }
-        public Task<TResult> ContinueWith<TResult>(Func<Task, TResult> continuationFunction, TaskScheduler scheduler)
-        {
-            return ContinueWith(continuationFunction, scheduler, default, TaskContinuationOptions.None);
-        }
-        public Task<TResult> ContinueWith<TResult>(Func<Task, TResult> continuationFunction, TaskContinuationOptions continuationOptions)
-        {
-            return ContinueWith(continuationFunction, TaskScheduler.Current, default, continuationOptions);
-        }
-        public Task<TResult> ContinueWith<TResult>(Func<Task, TResult> continuationFunction, CancellationToken cancellationToken,
-                                                   TaskContinuationOptions continuationOptions, TaskScheduler scheduler)
-        {
-            return ContinueWith(continuationFunction, scheduler, cancellationToken, continuationOptions);
-        }
-        private Task<TResult> ContinueWith<TResult>(Func<Task, TResult> continuationFunction, TaskScheduler scheduler,
-            CancellationToken cancellationToken, TaskContinuationOptions continuationOptions)
-        {
-            if (continuationFunction == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.continuationFunction);
-            }
-            if (scheduler == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.scheduler);
-            }
-            CreationOptionsFromContinuationOptions(continuationOptions, out TaskCreationOptions creationOptions, out InternalTaskOptions internalOptions);
-            Task<TResult> continuationTask = new ContinuationResultTaskFromTask<TResult>(
-                this, continuationFunction, null,
-                creationOptions, internalOptions
-            );
-            ContinueWithCore(continuationTask, scheduler, cancellationToken, continuationOptions);
-            return continuationTask;
-        }
-        #endregion
-        #region Func<Task, Object, TResult> continuation
-        public Task<TResult> ContinueWith<TResult>(Func<Task, object?, TResult> continuationFunction, object? state)
-        {
-            return ContinueWith(continuationFunction, state, TaskScheduler.Current, default,
-                TaskContinuationOptions.None);
-        }
-        public Task<TResult> ContinueWith<TResult>(Func<Task, object?, TResult> continuationFunction, object? state, CancellationToken cancellationToken)
-        {
-            return ContinueWith(continuationFunction, state, TaskScheduler.Current, cancellationToken, TaskContinuationOptions.None);
-        }
-        public Task<TResult> ContinueWith<TResult>(Func<Task, object?, TResult> continuationFunction, object? state, TaskScheduler scheduler)
-        {
-            return ContinueWith(continuationFunction, state, scheduler, default, TaskContinuationOptions.None);
-        }
-        public Task<TResult> ContinueWith<TResult>(Func<Task, object?, TResult> continuationFunction, object? state, TaskContinuationOptions continuationOptions)
-        {
-            return ContinueWith(continuationFunction, state, TaskScheduler.Current, default, continuationOptions);
-        }
-        public Task<TResult> ContinueWith<TResult>(Func<Task, object?, TResult> continuationFunction, object? state, CancellationToken cancellationToken,
-                                                   TaskContinuationOptions continuationOptions, TaskScheduler scheduler)
-        {
-            return ContinueWith(continuationFunction, state, scheduler, cancellationToken, continuationOptions);
-        }
-        private Task<TResult> ContinueWith<TResult>(Func<Task, object?, TResult> continuationFunction, object? state, TaskScheduler scheduler,
-            CancellationToken cancellationToken, TaskContinuationOptions continuationOptions)
-        {
-            if (continuationFunction == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.continuationFunction);
-            }
-            if (scheduler == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.scheduler);
-            }
-            CreationOptionsFromContinuationOptions(continuationOptions, out TaskCreationOptions creationOptions, out InternalTaskOptions internalOptions);
-            Task<TResult> continuationTask = new ContinuationResultTaskFromTask<TResult>(
-                this, continuationFunction, state,
-                creationOptions, internalOptions
-            );
-            ContinueWithCore(continuationTask, scheduler, cancellationToken, continuationOptions);
-            return continuationTask;
-        }
-        #endregion
-        internal static void CreationOptionsFromContinuationOptions(
-            TaskContinuationOptions continuationOptions,
-            out TaskCreationOptions creationOptions,
-            out InternalTaskOptions internalOptions)
-        {
-            const TaskContinuationOptions NotOnAnything =
-                TaskContinuationOptions.NotOnCanceled |
-                TaskContinuationOptions.NotOnFaulted |
-                TaskContinuationOptions.NotOnRanToCompletion;
-            const TaskContinuationOptions CreationOptionsMask =
-                TaskContinuationOptions.PreferFairness |
-                TaskContinuationOptions.LongRunning |
-                TaskContinuationOptions.DenyChildAttach |
-                TaskContinuationOptions.HideScheduler |
-                TaskContinuationOptions.AttachedToParent |
-                TaskContinuationOptions.RunContinuationsAsynchronously;
-            const TaskContinuationOptions IllegalMask = TaskContinuationOptions.ExecuteSynchronously | TaskContinuationOptions.LongRunning;
-            if ((continuationOptions & IllegalMask) == IllegalMask)
-            {
-                ThrowHelper.ThrowArgumentOutOfRangeException(ExceptionArgument.continuationOptions, ExceptionResource.Task_ContinueWith_ESandLR);
-            }
-            if ((continuationOptions &
-                ~(CreationOptionsMask | NotOnAnything |
-                    TaskContinuationOptions.LazyCancellation | TaskContinuationOptions.ExecuteSynchronously)) != 0)
-            {
-                ThrowHelper.ThrowArgumentOutOfRangeException(ExceptionArgument.continuationOptions);
-            }
-            if ((continuationOptions & NotOnAnything) == NotOnAnything)
-            {
-                ThrowHelper.ThrowArgumentOutOfRangeException(ExceptionArgument.continuationOptions, ExceptionResource.Task_ContinueWith_NotOnAnything);
-            }
-            creationOptions = (TaskCreationOptions)(continuationOptions & CreationOptionsMask);
-            internalOptions = (continuationOptions & TaskContinuationOptions.LazyCancellation) != 0 ?
-                InternalTaskOptions.ContinuationTask | InternalTaskOptions.LazyCancellation :
-                InternalTaskOptions.ContinuationTask;
-        }
-        internal void ContinueWithCore(Task continuationTask,
-                                       TaskScheduler scheduler,
-                                       CancellationToken cancellationToken,
-                                       TaskContinuationOptions options)
-        {
-            Debug.Assert(continuationTask != null, "Task.ContinueWithCore(): null continuationTask");
-            Debug.Assert(scheduler != null, "Task.ContinueWithCore(): null scheduler");
-            Debug.Assert(!continuationTask.IsCompleted, "Did not expect continuationTask to be completed");
-            var continuation = new ContinueWithTaskContinuation(continuationTask, options, scheduler);
-            if (cancellationToken.CanBeCanceled)
-            {
-                if (IsCompleted || cancellationToken.IsCancellationRequested)
-                {
-                    continuationTask.AssignCancellationToken(cancellationToken, null, null);
-                }
-                else
-                {
-                    continuationTask.AssignCancellationToken(cancellationToken, this, continuation);
-                }
-            }
-            if (!continuationTask.IsCompleted)
-            {
-                if ((this.Options & (TaskCreationOptions)InternalTaskOptions.PromiseTask) != 0 &&
-                    this is not ITaskCompletionAction)
-                {
-                    TplEventSource log = TplEventSource.Log;
-                    if (log.IsEnabled())
-                    {
-                        log.AwaitTaskContinuationScheduled(TaskScheduler.Current.Id, CurrentId ?? 0, continuationTask.Id);
-                    }
-                }
-                bool continuationQueued = AddTaskContinuation(continuation, addBeforeOthers: false);
-                if (!continuationQueued) continuation.Run(this, canInlineContinuationTask: true);
-            }
-        }
-        #endregion
-        internal void AddCompletionAction(ITaskCompletionAction action, bool addBeforeOthers = false)
-        {
-            if (!AddTaskContinuation(action, addBeforeOthers))
-                action.Invoke(this); // run the action directly if we failed to queue the continuation (i.e., the task completed)
-        }
-        private bool AddTaskContinuationComplex(object tc, bool addBeforeOthers)
-        {
-            Debug.Assert(tc != null, "Expected non-null tc object in AddTaskContinuationComplex");
-            object? oldValue = m_continuationObject;
-            Debug.Assert(oldValue is not null, "Expected non-null m_continuationObject object");
-            if (oldValue == s_taskCompletionSentinel)
-            {
-                return false;
-            }
-            List<object?>? list = oldValue as List<object?>;
-            if (list is null)
-            {
-                list = new List<object?>();
-                if (addBeforeOthers)
-                {
-                    list.Add(tc);
-                    list.Add(oldValue);
-                }
-                else
-                {
-                    list.Add(oldValue);
-                    list.Add(tc);
-                }
-                object? expected = oldValue;
-                oldValue = Interlocked.CompareExchange(ref m_continuationObject, list, expected);
-                if (oldValue == expected)
-                {
-                    return true;
-                }
-                list = oldValue as List<object?>;
-                if (list is null)
-                {
-                    Debug.Assert(oldValue == s_taskCompletionSentinel, "Expected m_continuationObject to be list or sentinel");
-                    return false;
-                }
-            }
-            lock (list)
-            {
-                if (m_continuationObject == s_taskCompletionSentinel)
-                {
-                    return false;
-                }
-                if (list.Count == list.Capacity)
-                {
-                    list.RemoveAll(l => l == null);
-                }
-                if (addBeforeOthers)
-                {
-                    list.Insert(0, tc);
-                }
-                else
-                {
-                    list.Add(tc);
-                }
-            }
-            return true; // continuation successfully queued, so return true.
-        }
-        private bool AddTaskContinuation(object tc, bool addBeforeOthers)
-        {
-            Debug.Assert(tc != null);
-            if (IsCompleted) return false;
-            if ((m_continuationObject != null) || (Interlocked.CompareExchange(ref m_continuationObject, tc, null) != null))
-            {
-                return AddTaskContinuationComplex(tc, addBeforeOthers);
-            }
-            else return true;
-        }
-        internal void RemoveContinuation(object continuationObject) // could be TaskContinuation or Action<Task>
-        {
-            object? continuationsLocalRef = m_continuationObject;
-            if (continuationsLocalRef == s_taskCompletionSentinel) return;
-            List<object?>? continuationsLocalListRef = continuationsLocalRef as List<object?>;
-            if (continuationsLocalListRef is null)
-            {
-                continuationsLocalRef = Interlocked.CompareExchange(ref m_continuationObject, new List<object?>(), continuationObject);
-                if (continuationsLocalRef != continuationObject)
-                {
-                    continuationsLocalListRef = continuationsLocalRef as List<object?>;
-                    if (continuationsLocalListRef is null)
-                        return;
-                }
-                else
-                {
-                    return;
-                }
-            }
-            lock (continuationsLocalListRef)
-            {
-                if (m_continuationObject == s_taskCompletionSentinel) return;
-                int index = continuationsLocalListRef.IndexOf(continuationObject);
-                if (index >= 0)
-                {
-                    continuationsLocalListRef[index] = null;
-                }
-            }
-        }
-        [UnsupportedOSPlatform("browser")]
-        [MethodImpl(MethodImplOptions.NoOptimization)]  // this is needed for the parallel debugger
-        public static void WaitAll(params Task[] tasks)
-        {
-            if (tasks is null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.tasks);
-            }
-            bool waitResult = WaitAllCore(tasks, Timeout.Infinite, default);
-            Debug.Assert(waitResult, "expected wait to succeed");
-        }
-        [UnsupportedOSPlatform("browser")]
-        public static void WaitAll(params ReadOnlySpan<Task> tasks)
-        {
-            bool waitResult = WaitAllCore(tasks, Timeout.Infinite, default);
-            Debug.Assert(waitResult, "expected wait to succeed");
-        }
-        [UnsupportedOSPlatform("browser")]
-        [MethodImpl(MethodImplOptions.NoOptimization)]  // this is needed for the parallel debugger
-        public static bool WaitAll(Task[] tasks, TimeSpan timeout)
-        {
-            long totalMilliseconds = (long)timeout.TotalMilliseconds;
-            if (totalMilliseconds is < -1 or > int.MaxValue)
-            {
-                ThrowHelper.ThrowArgumentOutOfRangeException(ExceptionArgument.timeout);
-            }
-            if (tasks is null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.tasks);
-            }
-            return WaitAllCore(tasks, (int)totalMilliseconds, default);
-        }
-        [UnsupportedOSPlatform("browser")]
-        [MethodImpl(MethodImplOptions.NoOptimization)]  // this is needed for the parallel debugger
-        public static bool WaitAll(Task[] tasks, int millisecondsTimeout)
-        {
-            if (tasks is null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.tasks);
-            }
-            return WaitAllCore(tasks, millisecondsTimeout, default);
-        }
-        [UnsupportedOSPlatform("browser")]
-        [MethodImpl(MethodImplOptions.NoOptimization)]  // this is needed for the parallel debugger
-        public static void WaitAll(Task[] tasks, CancellationToken cancellationToken)
-        {
-            if (tasks is null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.tasks);
-            }
-            WaitAllCore(tasks, Timeout.Infinite, cancellationToken);
-        }
-        [UnsupportedOSPlatform("browser")]
-        [MethodImpl(MethodImplOptions.NoOptimization)]  // this is needed for the parallel debugger
-        public static bool WaitAll(Task[] tasks, int millisecondsTimeout, CancellationToken cancellationToken)
-        {
-            if (tasks is null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.tasks);
-            }
-            return WaitAllCore(tasks, millisecondsTimeout, cancellationToken);
-        }
-        [UnsupportedOSPlatform("browser")]
-        public static void WaitAll(IEnumerable<Task> tasks, CancellationToken cancellationToken = default)
-        {
-            if (tasks is null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.tasks);
-            }
-            ReadOnlySpan<Task> span =
-                tasks is List<Task> list ? CollectionsMarshal.AsSpan(list) :
-                tasks is Task[] array ? array :
-                CollectionsMarshal.AsSpan(new List<Task>(tasks));
-            WaitAllCore(span, Timeout.Infinite, cancellationToken);
-        }
-        [UnsupportedOSPlatform("browser")]
-        private static bool WaitAllCore(ReadOnlySpan<Task> tasks, int millisecondsTimeout, CancellationToken cancellationToken)
-        {
-            if (millisecondsTimeout < -1)
-            {
-                ThrowHelper.ThrowArgumentOutOfRangeException(ExceptionArgument.millisecondsTimeout);
-            }
-            cancellationToken.ThrowIfCancellationRequested(); // early check before we make any allocations
-            List<Exception>? exceptions = null;
-            List<Task>? waitedOnTaskList = null;
-            List<Task>? notificationTasks = null;
-            bool exceptionSeen = false, cancellationSeen = false;
-            bool returnValue = true;
-            for (int i = tasks.Length - 1; i >= 0; i--)
-            {
-                Task task = tasks[i];
-                if (task == null)
-                {
-                    ThrowHelper.ThrowArgumentException(ExceptionResource.Task_WaitMulti_NullTask, ExceptionArgument.tasks);
-                }
-                bool taskIsCompleted = task.IsCompleted;
-                if (!taskIsCompleted)
-                {
-                    if (millisecondsTimeout != Timeout.Infinite || cancellationToken.CanBeCanceled)
-                    {
-                        AddToList(task, ref waitedOnTaskList, initSize: tasks.Length);
-                    }
-                    else
-                    {
-                        taskIsCompleted = task.WrappedTryRunInline() && task.IsCompleted; // A successful TryRunInline doesn't guarantee completion
-                        if (!taskIsCompleted) AddToList(task, ref waitedOnTaskList, initSize: tasks.Length);
-                    }
-                }
-                if (taskIsCompleted)
-                {
-                    if (task.IsFaulted) exceptionSeen = true;
-                    else if (task.IsCanceled) cancellationSeen = true;
-                    if (task.IsWaitNotificationEnabled) AddToList(task, ref notificationTasks, initSize: 1);
-                }
-            }
-            if (waitedOnTaskList != null)
-            {
-                returnValue = WaitAllBlockingCore(waitedOnTaskList, millisecondsTimeout, cancellationToken);
-                if (returnValue)
-                {
-                    foreach (Task task in waitedOnTaskList)
-                    {
-                        if (task.IsFaulted) exceptionSeen = true;
-                        else if (task.IsCanceled) cancellationSeen = true;
-                        if (task.IsWaitNotificationEnabled) AddToList(task, ref notificationTasks, initSize: 1);
-                    }
-                }
-            }
-            if (returnValue && notificationTasks != null)
-            {
-                foreach (Task task in notificationTasks)
-                {
-                    if (task.NotifyDebuggerOfWaitCompletionIfNecessary()) break;
-                }
-            }
-            if (returnValue && (exceptionSeen || cancellationSeen))
-            {
-                if (!exceptionSeen) cancellationToken.ThrowIfCancellationRequested();
-                foreach (Task task in tasks) AddExceptionsForCompletedTask(ref exceptions, task);
-                Debug.Assert(exceptions != null, "Should have seen at least one exception");
-                ThrowHelper.ThrowAggregateException(exceptions);
-            }
-            return returnValue;
-        }
-        private static void AddToList<T>(T item, ref List<T>? list, int initSize)
-        {
-            list ??= new List<T>(initSize);
-            list.Add(item);
-        }
-        [UnsupportedOSPlatform("browser")]
-        private static bool WaitAllBlockingCore(List<Task> tasks, int millisecondsTimeout, CancellationToken cancellationToken)
-        {
-            Debug.Assert(tasks != null, "Expected a non-null list of tasks");
-            Debug.Assert(tasks.Count > 0, "Expected at least one task");
-            bool waitCompleted = false;
-            var mres = new SetOnCountdownMres(tasks.Count);
-            try
-            {
-                foreach (Task task in tasks)
-                {
-                    task.AddCompletionAction(mres, addBeforeOthers: true);
-                }
-                waitCompleted = mres.Wait(millisecondsTimeout, cancellationToken);
-            }
-            finally
-            {
-                if (!waitCompleted)
-                {
-                    foreach (Task task in tasks)
-                    {
-                        if (!task.IsCompleted) task.RemoveContinuation(mres);
-                    }
-                }
-            }
-            return waitCompleted;
-        }
-        private sealed class SetOnCountdownMres : ManualResetEventSlim, ITaskCompletionAction
-        {
-            private int _count;
-            internal SetOnCountdownMres(int count)
-            {
-                Debug.Assert(count > 0, "Expected count > 0");
-                _count = count;
-            }
-            public void Invoke(Task completingTask)
-            {
-                if (Interlocked.Decrement(ref _count) == 0) Set();
-                Debug.Assert(_count >= 0, "Count should never go below 0");
-            }
-            public bool InvokeMayRunArbitraryCode => false;
-        }
-        internal static void AddExceptionsForCompletedTask(ref List<Exception>? exceptions, Task t)
-        {
-            AggregateException? ex = t.GetExceptions(true);
-            if (ex != null)
-            {
-                t.UpdateExceptionObservedStatus();
-                exceptions ??= new List<Exception>(ex.InnerExceptionCount);
-                exceptions.AddRange(ex.InternalInnerExceptions);
-            }
-        }
-        [MethodImpl(MethodImplOptions.NoOptimization)]  // this is needed for the parallel debugger
-        public static int WaitAny(params Task[] tasks)
-        {
-            int waitResult = WaitAnyCore(tasks, Timeout.Infinite, default);
-            Debug.Assert(tasks.Length == 0 || waitResult != -1, "expected wait to succeed");
-            return waitResult;
-        }
-        [MethodImpl(MethodImplOptions.NoOptimization)]  // this is needed for the parallel debugger
-        public static int WaitAny(Task[] tasks, TimeSpan timeout)
-        {
-            long totalMilliseconds = (long)timeout.TotalMilliseconds;
-            if (totalMilliseconds < -1 || totalMilliseconds > int.MaxValue)
-            {
-                ThrowHelper.ThrowArgumentOutOfRangeException(ExceptionArgument.timeout);
-            }
-            return WaitAnyCore(tasks, (int)totalMilliseconds, default);
-        }
-        [MethodImpl(MethodImplOptions.NoOptimization)]  // this is needed for the parallel debugger
-        public static int WaitAny(Task[] tasks, CancellationToken cancellationToken)
-        {
-            return WaitAnyCore(tasks, Timeout.Infinite, cancellationToken);
-        }
-        [MethodImpl(MethodImplOptions.NoOptimization)]  // this is needed for the parallel debugger
-        public static int WaitAny(Task[] tasks, int millisecondsTimeout)
-        {
-            return WaitAnyCore(tasks, millisecondsTimeout, default);
-        }
-        [MethodImpl(MethodImplOptions.NoOptimization)]  // this is needed for the parallel debugger
-        public static int WaitAny(Task[] tasks, int millisecondsTimeout, CancellationToken cancellationToken) =>
-            WaitAnyCore(tasks, millisecondsTimeout, cancellationToken);
-        private static int WaitAnyCore(Task[] tasks, int millisecondsTimeout, CancellationToken cancellationToken)
-        {
-            if (tasks == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.tasks);
-            }
-            if (millisecondsTimeout < -1)
-            {
-                ThrowHelper.ThrowArgumentOutOfRangeException(ExceptionArgument.millisecondsTimeout);
-            }
-            cancellationToken.ThrowIfCancellationRequested(); // early check before we make any allocations
-            int signaledTaskIndex = -1;
-            for (int taskIndex = 0; taskIndex < tasks.Length; taskIndex++)
-            {
-                Task task = tasks[taskIndex];
-                if (task == null)
-                {
-                    ThrowHelper.ThrowArgumentException(ExceptionResource.Task_WaitMulti_NullTask, ExceptionArgument.tasks);
-                }
-                if (signaledTaskIndex == -1 && task.IsCompleted)
-                {
-                    signaledTaskIndex = taskIndex;
-                }
-            }
-            if (signaledTaskIndex == -1 && tasks.Length != 0)
-            {
-                Task<Task> firstCompleted = TaskFactory.CommonCWAnyLogic(tasks, isSyncBlocking: true);
-                bool waitCompleted = firstCompleted.Wait(millisecondsTimeout, cancellationToken);
-                if (waitCompleted)
-                {
-                    Debug.Assert(firstCompleted.Status == TaskStatus.RanToCompletion);
-                    signaledTaskIndex = Array.IndexOf(tasks, firstCompleted.Result);
-                    Debug.Assert(signaledTaskIndex >= 0);
-                }
-                else
-                {
-                    TaskFactory.CommonCWAnyLogicCleanup(firstCompleted);
-                }
-            }
-            GC.KeepAlive(tasks);
-            return signaledTaskIndex;
-        }
-        #region FromResult / FromException / FromCanceled
-        [MethodImpl(MethodImplOptions.AggressiveInlining)] // method looks long, but for a given TResult it results in a relatively small amount of asm
-        public static unsafe Task<TResult> FromResult<TResult>(TResult result)
-        {
-            if (result is null)
-            {
-                return Task<TResult>.s_defaultResultTask;
-            }
-            if (typeof(TResult) == typeof(bool)) // only the relevant branches are kept for each value-type generic instantiation
-            {
-                Task<bool> task = *(bool*)&result ? TaskCache.s_trueTask : TaskCache.s_falseTask;
-                return *(Task<TResult>*)&task;
-            }
-            if (typeof(TResult) == typeof(int))
-            {
-                int value = *(int*)&result;
-                if ((uint)(value - TaskCache.InclusiveInt32Min) < (TaskCache.ExclusiveInt32Max - TaskCache.InclusiveInt32Min))
-                {
-                    Task<int> task = TaskCache.s_int32Tasks[value - TaskCache.InclusiveInt32Min];
-                    return *(Task<TResult>*)&task;
-                }
-            }
-            else if (!RuntimeHelpers.IsReferenceOrContainsReferences<TResult>())
-            {
-                if ((sizeof(TResult) == sizeof(byte) && *(byte*)&result == default(byte)) ||
-                    (sizeof(TResult) == sizeof(ushort) && *(ushort*)&result == default(ushort)) ||
-                    (sizeof(TResult) == sizeof(uint) && *(uint*)&result == default) ||
-                    (sizeof(TResult) == sizeof(ulong) && *(ulong*)&result == default) ||
-                    (sizeof(TResult) == sizeof(UInt128) && *(UInt128*)&result == default))
-                {
-                    return Task<TResult>.s_defaultResultTask;
-                }
-            }
-            return new Task<TResult>(result);
-        }
-        public static Task FromException(Exception exception)
-        {
-            if (exception == null) ThrowHelper.ThrowArgumentNullException(ExceptionArgument.exception);
-            var task = new Task();
-            bool succeeded = task.TrySetException(exception);
-            Debug.Assert(succeeded, "This should always succeed on a new task.");
-            return task;
-        }
-        public static Task<TResult> FromException<TResult>(Exception exception)
-        {
-            if (exception == null) ThrowHelper.ThrowArgumentNullException(ExceptionArgument.exception);
-            var task = new Task<TResult>();
-            bool succeeded = task.TrySetException(exception);
-            Debug.Assert(succeeded, "This should always succeed on a new task.");
-            return task;
-        }
-        public static Task FromCanceled(CancellationToken cancellationToken)
-        {
-            if (!cancellationToken.IsCancellationRequested)
-                ThrowHelper.ThrowArgumentOutOfRangeException(ExceptionArgument.cancellationToken);
-            return new Task(true, TaskCreationOptions.None, cancellationToken);
-        }
-        public static Task<TResult> FromCanceled<TResult>(CancellationToken cancellationToken)
-        {
-            if (!cancellationToken.IsCancellationRequested)
-                ThrowHelper.ThrowArgumentOutOfRangeException(ExceptionArgument.cancellationToken);
-            return new Task<TResult>(true, default, TaskCreationOptions.None, cancellationToken);
-        }
-        internal static Task FromCanceled(OperationCanceledException exception)
-        {
-            Debug.Assert(exception != null);
-            var task = new Task();
-            bool succeeded = task.TrySetCanceled(exception.CancellationToken, exception);
-            Debug.Assert(succeeded, "This should always succeed on a new task.");
-            return task;
-        }
-        internal static Task<TResult> FromCanceled<TResult>(OperationCanceledException exception)
-        {
-            Debug.Assert(exception != null);
-            var task = new Task<TResult>();
-            bool succeeded = task.TrySetCanceled(exception.CancellationToken, exception);
-            Debug.Assert(succeeded, "This should always succeed on a new task.");
-            return task;
-        }
-        #endregion
-        #region Run methods
-        public static Task Run(Action action)
-        {
-            return InternalStartNew(null, action, null, default, TaskScheduler.Default,
-                TaskCreationOptions.DenyChildAttach, InternalTaskOptions.None);
-        }
-        public static Task Run(Action action, CancellationToken cancellationToken)
-        {
-            return InternalStartNew(null, action, null, cancellationToken, TaskScheduler.Default,
-                TaskCreationOptions.DenyChildAttach, InternalTaskOptions.None);
-        }
-        public static Task<TResult> Run<TResult>(Func<TResult> function)
-        {
-            return Task<TResult>.StartNew(null, function, default,
-                TaskCreationOptions.DenyChildAttach, InternalTaskOptions.None, TaskScheduler.Default);
-        }
-        public static Task<TResult> Run<TResult>(Func<TResult> function, CancellationToken cancellationToken)
-        {
-            return Task<TResult>.StartNew(null, function, cancellationToken,
-                TaskCreationOptions.DenyChildAttach, InternalTaskOptions.None, TaskScheduler.Default);
-        }
-        public static Task Run(Func<Task?> function)
-        {
-            return Run(function, default);
-        }
-        public static Task Run(Func<Task?> function, CancellationToken cancellationToken)
-        {
-            if (function == null) ThrowHelper.ThrowArgumentNullException(ExceptionArgument.function);
-            if (cancellationToken.IsCancellationRequested)
-                return FromCanceled(cancellationToken);
-            Task<Task?> task1 = Task<Task?>.Factory.StartNew(function, cancellationToken, TaskCreationOptions.DenyChildAttach, TaskScheduler.Default);
-            UnwrapPromise<VoidTaskResult> promise = new UnwrapPromise<VoidTaskResult>(task1, lookForOce: true);
-            return promise;
-        }
-        public static Task<TResult> Run<TResult>(Func<Task<TResult>?> function)
-        {
-            return Run(function, default);
-        }
-        public static Task<TResult> Run<TResult>(Func<Task<TResult>?> function, CancellationToken cancellationToken)
-        {
-            if (function == null) ThrowHelper.ThrowArgumentNullException(ExceptionArgument.function);
-            if (cancellationToken.IsCancellationRequested)
-                return FromCanceled<TResult>(cancellationToken);
-            Task<Task<TResult>?> task1 = Task<Task<TResult>?>.Factory.StartNew(function, cancellationToken, TaskCreationOptions.DenyChildAttach, TaskScheduler.Default);
-            UnwrapPromise<TResult> promise = new UnwrapPromise<TResult>(task1, lookForOce: true);
-            return promise;
-        }
-        #endregion
-        #region Delay methods
-        public static Task Delay(TimeSpan delay) => Delay(delay, TimeProvider.System, default);
-        public static Task Delay(TimeSpan delay, TimeProvider timeProvider) => Delay(delay, timeProvider, default);
-        public static Task Delay(TimeSpan delay, CancellationToken cancellationToken) =>
-            Delay(delay, TimeProvider.System, cancellationToken);
-        public static Task Delay(TimeSpan delay, TimeProvider timeProvider, CancellationToken cancellationToken)
-        {
-            ArgumentNullException.ThrowIfNull(timeProvider);
-            return Delay(ValidateTimeout(delay, ExceptionArgument.delay), timeProvider, cancellationToken);
-        }
-        public static Task Delay(int millisecondsDelay) => Delay(millisecondsDelay, default);
-        public static Task Delay(int millisecondsDelay, CancellationToken cancellationToken)
-        {
-            if (millisecondsDelay < -1)
-            {
-                ThrowHelper.ThrowArgumentOutOfRangeException(ExceptionArgument.millisecondsDelay, ExceptionResource.Task_Delay_InvalidMillisecondsDelay);
-            }
-            return Delay((uint)millisecondsDelay, TimeProvider.System, cancellationToken);
-        }
-        private static Task Delay(uint millisecondsDelay, TimeProvider timeProvider, CancellationToken cancellationToken) =>
-            cancellationToken.IsCancellationRequested ? FromCanceled(cancellationToken) :
-            millisecondsDelay == 0 ? CompletedTask :
-            cancellationToken.CanBeCanceled ? new DelayPromiseWithCancellation(millisecondsDelay, timeProvider, cancellationToken) :
-            new DelayPromise(millisecondsDelay, timeProvider);
-        internal static uint ValidateTimeout(TimeSpan timeout, ExceptionArgument argument)
-        {
-            long totalMilliseconds = (long)timeout.TotalMilliseconds;
-            if (totalMilliseconds < -1 || totalMilliseconds > Timer.MaxSupportedTimeout)
-            {
-                ThrowHelper.ThrowArgumentOutOfRangeException(argument, ExceptionResource.Task_InvalidTimerTimeSpan);
-            }
-            return (uint)totalMilliseconds;
-        }
-        private class DelayPromise : Task
-        {
-            private static readonly TimerCallback s_timerCallback = TimerCallback;
-            private readonly ITimer? _timer;
-            internal DelayPromise(uint millisecondsDelay, TimeProvider timeProvider)
-            {
-                Debug.Assert(millisecondsDelay != 0);
-                if (TplEventSource.Log.IsEnabled())
-                    TplEventSource.Log.TraceOperationBegin(this.Id, "Task.Delay", 0);
-                if (s_asyncDebuggingEnabled)
-                    AddToActiveTasks(this);
-                if (millisecondsDelay != Timeout.UnsignedInfinite) // no need to create the timer if it's an infinite timeout
-                {
-                    if (timeProvider == TimeProvider.System)
-                    {
-                        _timer = new TimerQueueTimer(s_timerCallback, this, millisecondsDelay, Timeout.UnsignedInfinite, flowExecutionContext: false);
-                    }
-                    else
-                    {
-                        using (ExecutionContext.SuppressFlow())
-                        {
-                            _timer = timeProvider.CreateTimer(s_timerCallback, this, TimeSpan.FromMilliseconds(millisecondsDelay), Timeout.InfiniteTimeSpan);
-                        }
-                    }
-                    if (IsCompleted)
-                    {
-                        _timer.Dispose();
-                    }
-                }
-            }
-            private static void TimerCallback(object? state) => ((DelayPromise)state!).CompleteTimedOut();
-            private void CompleteTimedOut()
-            {
-                if (TrySetResult())
-                {
-                    Cleanup();
-                    if (s_asyncDebuggingEnabled)
-                        RemoveFromActiveTasks(this);
-                    if (TplEventSource.Log.IsEnabled())
-                        TplEventSource.Log.TraceOperationEnd(this.Id, AsyncCausalityStatus.Completed);
-                }
-            }
-            protected virtual void Cleanup() => _timer?.Dispose();
-        }
-        private sealed class DelayPromiseWithCancellation : DelayPromise
-        {
-            private readonly CancellationTokenRegistration _registration;
-            internal DelayPromiseWithCancellation(uint millisecondsDelay, TimeProvider timeProvider, CancellationToken token) : base(millisecondsDelay, timeProvider)
-            {
-                Debug.Assert(token.CanBeCanceled);
-                _registration = token.UnsafeRegister(static (state, cancellationToken) =>
-                {
-                    var thisRef = (DelayPromiseWithCancellation)state!;
-                    thisRef.AtomicStateUpdate((int)TaskCreationOptions.RunContinuationsAsynchronously, 0);
-                    if (thisRef.TrySetCanceled(cancellationToken))
-                    {
-                        thisRef.Cleanup();
-                    }
-                }, this);
-                if (IsCompleted)
-                {
-                    _registration.Dispose();
-                }
-            }
-            protected override void Cleanup()
-            {
-                _registration.Dispose();
-                base.Cleanup();
-            }
-        }
-        #endregion
-        #region WhenAll
-        public static Task WhenAll(IEnumerable<Task> tasks)
-        {
-            if (tasks is null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.tasks);
-            }
-            if (tasks is ICollection<Task> taskCollection)
-            {
-                if (tasks is Task[] taskArray)
-                {
-                    return WhenAll((ReadOnlySpan<Task>)taskArray);
-                }
-                if (tasks is List<Task> taskList)
-                {
-                    return WhenAll(CollectionsMarshal.AsSpan(taskList));
-                }
-                taskArray = new Task[taskCollection.Count];
-                taskCollection.CopyTo(taskArray, 0);
-                return WhenAll((ReadOnlySpan<Task>)taskArray);
-            }
-            else
-            {
-                var taskList = new List<Task>();
-                foreach (Task task in tasks)
-                {
-                    taskList.Add(task);
-                }
-                return WhenAll(CollectionsMarshal.AsSpan(taskList));
-            }
-        }
-        public static Task WhenAll(params Task[] tasks)
-        {
-            if (tasks is null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.tasks);
-            }
-            return WhenAll((ReadOnlySpan<Task>)tasks);
-        }
-        public static Task WhenAll(params ReadOnlySpan<Task> tasks) =>
-            tasks.Length != 0 ? new WhenAllPromise(tasks) : CompletedTask;
-        private sealed class WhenAllPromise : Task, ITaskCompletionAction
-        {
-            private int _remainingToComplete;
-            internal WhenAllPromise(ReadOnlySpan<Task> tasks)
-            {
-                Debug.Assert(tasks.Length != 0, "Expected a non-zero length task array");
-                Debug.Assert(m_stateObject is null, "Expected to be able to use the state object field for faulted/canceled tasks.");
-                m_stateFlags |= (int)InternalTaskOptions.HiddenState;
-                foreach (Task task in tasks)
-                {
-                    if (task is null)
-                    {
-                        ThrowHelper.ThrowArgumentException(ExceptionResource.Task_MultiTaskContinuation_NullTask, ExceptionArgument.tasks);
-                    }
-                }
-                if (TplEventSource.Log.IsEnabled())
-                {
-                    TplEventSource.Log.TraceOperationBegin(Id, "Task.WhenAll", 0);
-                }
-                if (s_asyncDebuggingEnabled)
-                {
-                    AddToActiveTasks(this);
-                }
-                _remainingToComplete = tasks.Length;
-                foreach (Task task in tasks)
-                {
-                    if (task is null || task.IsCompleted)
-                    {
-                        Invoke(task); // short-circuit the completion action, if possible
-                    }
-                    else
-                    {
-                        task.AddCompletionAction(this); // simple completion action
-                    }
-                }
-            }
-            public void Invoke(Task? completedTask)
-            {
-                if (TplEventSource.Log.IsEnabled())
-                {
-                    TplEventSource.Log.TraceOperationRelation(Id, CausalityRelation.Join);
-                }
-                if (completedTask is not null)
-                {
-                    if (completedTask.IsWaitNotificationEnabled)
-                    {
-                        SetNotificationForWaitCompletion(enabled: true);
-                    }
-                    if (!completedTask.IsCompletedSuccessfully)
-                    {
-                        object? failedOrCanceled = Interlocked.CompareExchange(ref m_stateObject, completedTask, null);
-                        if (failedOrCanceled != null)
-                        {
-                            while (true)
-                            {
-                                if (failedOrCanceled is List<Task> list)
-                                {
-                                    lock (list)
-                                    {
-                                        list.Add(completedTask);
-                                    }
-                                    break;
-                                }
-                                Debug.Assert(failedOrCanceled is Task, $"Expected Task, got {failedOrCanceled}");
-                                Task first = (Task)failedOrCanceled;
-                                failedOrCanceled = Interlocked.CompareExchange(ref m_stateObject, new List<Task> { first, completedTask }, first);
-                                if (failedOrCanceled == first)
-                                {
-                                    break;
-                                }
-                                Debug.Assert(failedOrCanceled is List<Task>);
-                            }
-                        }
-                    }
-                }
-                if (Interlocked.Decrement(ref _remainingToComplete) == 0)
-                {
-                    object? failedOrCanceled = m_stateObject;
-                    if (failedOrCanceled is null)
-                    {
-                        if (TplEventSource.Log.IsEnabled())
-                        {
-                            TplEventSource.Log.TraceOperationEnd(Id, AsyncCausalityStatus.Completed);
-                        }
-                        if (s_asyncDebuggingEnabled)
-                        {
-                            RemoveFromActiveTasks(this);
-                        }
-                        bool completed = TrySetResult();
-                        Debug.Assert(completed);
-                    }
-                    else
-                    {
-                        List<ExceptionDispatchInfo>? observedExceptions = null;
-                        Task? canceledTask = null;
-                        void HandleTask(Task task)
-                        {
-                            if (task.IsFaulted)
-                            {
-                                (observedExceptions ??= new()).AddRange(task.GetExceptionDispatchInfos());
-                            }
-                            else if (task.IsCanceled)
-                            {
-                                canceledTask ??= task; // use the first task that's canceled
-                            }
-                        }
-                        if (failedOrCanceled is List<Task> list)
-                        {
-                            foreach (Task task in list)
-                            {
-                                HandleTask(task);
-                            }
-                        }
-                        else
-                        {
-                            Debug.Assert(failedOrCanceled is Task);
-                            HandleTask((Task)failedOrCanceled);
-                        }
-                        if (observedExceptions != null)
-                        {
-                            Debug.Assert(observedExceptions.Count > 0, "Expected at least one exception");
-                            TrySetException(observedExceptions);
-                        }
-                        else if (canceledTask != null)
-                        {
-                            TrySetCanceled(canceledTask.CancellationToken, canceledTask.GetCancellationExceptionDispatchInfo());
-                        }
-                    }
-                    Debug.Assert(IsCompleted);
-                }
-                Debug.Assert(_remainingToComplete >= 0, "Count should never go below 0");
-            }
-            public bool InvokeMayRunArbitraryCode => true;
-        }
-        public static Task<TResult[]> WhenAll<TResult>(IEnumerable<Task<TResult>> tasks)
-        {
-            if (tasks is Task<TResult>[] taskArray)
-            {
-                return WhenAll(taskArray);
-            }
-            if (tasks is ICollection<Task<TResult>> taskCollection)
-            {
-                int count = taskCollection.Count;
-                if (count == 0)
-                {
-                    return new Task<TResult[]>(false, Array.Empty<TResult>(), TaskCreationOptions.None, default);
-                }
-                taskArray = new Task<TResult>[count];
-                taskCollection.CopyTo(taskArray, 0);
-                foreach (Task<TResult> task in taskArray)
-                {
-                    if (task is null)
-                    {
-                        ThrowHelper.ThrowArgumentException(ExceptionResource.Task_MultiTaskContinuation_NullTask, ExceptionArgument.tasks);
-                    }
-                }
-                return new WhenAllPromise<TResult>(taskArray);
-            }
-            if (tasks is null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.tasks);
-            }
-            List<Task<TResult>> taskList = new List<Task<TResult>>();
-            foreach (Task<TResult> task in tasks)
-            {
-                if (task is null)
-                {
-                    ThrowHelper.ThrowArgumentException(ExceptionResource.Task_MultiTaskContinuation_NullTask, ExceptionArgument.tasks);
-                }
-                taskList.Add(task);
-            }
-            return taskList.Count == 0 ?
-                new Task<TResult[]>(false, Array.Empty<TResult>(), TaskCreationOptions.None, default) :
-                new WhenAllPromise<TResult>(taskList.ToArray());
-        }
-        public static Task<TResult[]> WhenAll<TResult>(params Task<TResult>[] tasks)
-        {
-            if (tasks is null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.tasks);
-            }
-            return WhenAll((ReadOnlySpan<Task<TResult>>)tasks);
-        }
-        public static Task<TResult[]> WhenAll<TResult>(params ReadOnlySpan<Task<TResult>> tasks)
-        {
-            if (tasks.IsEmpty)
-            {
-                return new Task<TResult[]>(false, Array.Empty<TResult>(), TaskCreationOptions.None, default);
-            }
-            Task<TResult>[] tasksCopy = tasks.ToArray();
-            foreach (Task<TResult> task in tasksCopy)
-            {
-                if (task is null)
-                {
-                    ThrowHelper.ThrowArgumentException(ExceptionResource.Task_MultiTaskContinuation_NullTask, ExceptionArgument.tasks);
-                }
-            }
-            return new WhenAllPromise<TResult>(tasksCopy);
-        }
-        private sealed class WhenAllPromise<T> : Task<T[]>, ITaskCompletionAction
-        {
-            private readonly Task<T>?[] m_tasks;
-            private int m_count;
-            internal WhenAllPromise(Task<T>[] tasks)
-            {
-                Debug.Assert(tasks != null, "Expected a non-null task array");
-                Debug.Assert(tasks.Length > 0, "Expected a non-zero length task array");
-                m_tasks = tasks;
-                m_count = tasks.Length;
-                if (TplEventSource.Log.IsEnabled())
-                    TplEventSource.Log.TraceOperationBegin(this.Id, "Task.WhenAll", 0);
-                if (s_asyncDebuggingEnabled)
-                    AddToActiveTasks(this);
-                foreach (Task<T> task in tasks)
-                {
-                    if (task.IsCompleted) this.Invoke(task); // short-circuit the completion action, if possible
-                    else task.AddCompletionAction(this); // simple completion action
-                }
-            }
-            public void Invoke(Task ignored)
-            {
-                if (TplEventSource.Log.IsEnabled())
-                    TplEventSource.Log.TraceOperationRelation(this.Id, CausalityRelation.Join);
-                if (Interlocked.Decrement(ref m_count) == 0)
-                {
-                    T[] results = new T[m_tasks.Length];
-                    List<ExceptionDispatchInfo>? observedExceptions = null;
-                    Task? canceledTask = null;
-                    for (int i = 0; i < m_tasks.Length; i++)
-                    {
-                        Task<T>? task = m_tasks[i];
-                        Debug.Assert(task != null, "Constituent task in WhenAll should never be null");
-                        if (task.IsFaulted)
-                        {
-                            observedExceptions ??= new List<ExceptionDispatchInfo>();
-                            observedExceptions.AddRange(task.GetExceptionDispatchInfos());
-                        }
-                        else if (task.IsCanceled)
-                        {
-                            canceledTask ??= task; // use the first task that's canceled
-                        }
-                        else
-                        {
-                            Debug.Assert(task.Status == TaskStatus.RanToCompletion);
-                            results[i] = task.GetResultCore(waitCompletionNotification: false); // avoid Result, which would triggering debug notification
-                        }
-                        if (task.IsWaitNotificationEnabled) this.SetNotificationForWaitCompletion(enabled: true);
-                        else m_tasks[i] = null; // avoid holding onto tasks unnecessarily
-                    }
-                    if (observedExceptions != null)
-                    {
-                        Debug.Assert(observedExceptions.Count > 0, "Expected at least one exception");
-                        TrySetException(observedExceptions);
-                    }
-                    else if (canceledTask != null)
-                    {
-                        TrySetCanceled(canceledTask.CancellationToken, canceledTask.GetCancellationExceptionDispatchInfo());
-                    }
-                    else
-                    {
-                        if (TplEventSource.Log.IsEnabled())
-                            TplEventSource.Log.TraceOperationEnd(this.Id, AsyncCausalityStatus.Completed);
-                        if (s_asyncDebuggingEnabled)
-                            RemoveFromActiveTasks(this);
-                        TrySetResult(results);
-                    }
-                }
-                Debug.Assert(m_count >= 0, "Count should never go below 0");
-            }
-            public bool InvokeMayRunArbitraryCode => true;
-            private protected override bool ShouldNotifyDebuggerOfWaitCompletion =>
-                base.ShouldNotifyDebuggerOfWaitCompletion &&
-                AnyTaskRequiresNotifyDebuggerOfWaitCompletion(m_tasks);
-        }
-        #endregion
-        #region WhenAny
-        public static Task<Task> WhenAny(params Task[] tasks)
-        {
-            ArgumentNullException.ThrowIfNull(tasks);
-            return WhenAnyCore((ReadOnlySpan<Task>)tasks);
-        }
-        public static Task<Task> WhenAny(params ReadOnlySpan<Task> tasks) =>
-            WhenAnyCore(tasks);
-        private static Task<TTask> WhenAnyCore<TTask>(ReadOnlySpan<TTask> tasks) where TTask : Task
-        {
-            if (tasks.Length == 2)
-            {
-                return WhenAny(tasks[0], tasks[1]);
-            }
-            if (tasks.IsEmpty)
-            {
-                ThrowHelper.ThrowArgumentException(ExceptionResource.Task_MultiTaskContinuation_EmptyTaskList, ExceptionArgument.tasks);
-            }
-            TTask[] tasksCopy = tasks.ToArray();
-            foreach (TTask task in tasksCopy)
-            {
-                if (task is null)
-                {
-                    ThrowHelper.ThrowArgumentException(ExceptionResource.Task_MultiTaskContinuation_NullTask, ExceptionArgument.tasks);
-                }
-            }
-            return TaskFactory.CommonCWAnyLogic(tasksCopy);
-        }
-        public static Task<Task> WhenAny(Task task1, Task task2) =>
-            WhenAny<Task>(task1, task2);
-        private static Task<TTask> WhenAny<TTask>(TTask task1, TTask task2) where TTask : Task
-        {
-            ArgumentNullException.ThrowIfNull(task1);
-            ArgumentNullException.ThrowIfNull(task2);
-            return
-                task1.IsCompleted ? FromResult(task1) :
-                task2.IsCompleted ? FromResult(task2) :
-                new TwoTaskWhenAnyPromise<TTask>(task1, task2);
-        }
-        private sealed class TwoTaskWhenAnyPromise<TTask> : Task<TTask>, ITaskCompletionAction where TTask : Task
-        {
-            private TTask? _task1, _task2;
-            public TwoTaskWhenAnyPromise(TTask task1, TTask task2)
-            {
-                Debug.Assert(task1 != null && task2 != null);
-                _task1 = task1;
-                _task2 = task2;
-                if (TplEventSource.Log.IsEnabled())
-                {
-                    TplEventSource.Log.TraceOperationBegin(this.Id, "Task.WhenAny", 0);
-                }
-                if (s_asyncDebuggingEnabled)
-                {
-                    AddToActiveTasks(this);
-                }
-                task1.AddCompletionAction(this);
-                task2.AddCompletionAction(this);
-                if (task1.IsCompleted)
-                {
-                    task2.RemoveContinuation(this);
-                }
-            }
-            public void Invoke(Task completingTask)
-            {
-                Task? task1;
-                if ((task1 = Interlocked.Exchange(ref _task1, null)) != null)
-                {
-                    Task? task2 = _task2;
-                    _task2 = null;
-                    Debug.Assert(task1 != null && task2 != null);
-                    Debug.Assert(task1.IsCompleted || task2.IsCompleted);
-                    if (TplEventSource.Log.IsEnabled())
-                    {
-                        TplEventSource.Log.TraceOperationRelation(this.Id, CausalityRelation.Choice);
-                        TplEventSource.Log.TraceOperationEnd(this.Id, AsyncCausalityStatus.Completed);
-                    }
-                    if (s_asyncDebuggingEnabled)
-                    {
-                        RemoveFromActiveTasks(this);
-                    }
-                    if (!task1.IsCompleted)
-                    {
-                        task1.RemoveContinuation(this);
-                    }
-                    else
-                    {
-                        task2.RemoveContinuation(this);
-                    }
-                    bool success = TrySetResult((TTask)completingTask);
-                    Debug.Assert(success, "Only one task should have gotten to this point, and thus this must be successful.");
-                }
-            }
-            public bool InvokeMayRunArbitraryCode => true;
-        }
-        public static Task<Task> WhenAny(IEnumerable<Task> tasks) =>
-            WhenAny<Task>(tasks);
-        private static Task<TTask> WhenAny<TTask>(IEnumerable<TTask> tasks) where TTask : Task
-        {
-            if (tasks is ICollection<TTask> tasksAsCollection)
-            {
-                if (tasks.GetType() == typeof(List<TTask>))
-                {
-                    return WhenAnyCore((ReadOnlySpan<TTask>)CollectionsMarshal.AsSpan(Unsafe.As<List<TTask>>(tasks)));
-                }
-                if (tasks is TTask[] tasksAsArray)
-                {
-                    return WhenAnyCore((ReadOnlySpan<TTask>)tasksAsArray);
-                }
-                int count = tasksAsCollection.Count;
-                if (count <= 0)
-                {
-                    ThrowHelper.ThrowArgumentException(ExceptionResource.Task_MultiTaskContinuation_EmptyTaskList, ExceptionArgument.tasks);
-                }
-                var taskArray = new TTask[count];
-                tasksAsCollection.CopyTo(taskArray, 0);
-                foreach (TTask task in taskArray)
-                {
-                    if (task is null)
-                    {
-                        ThrowHelper.ThrowArgumentException(ExceptionResource.Task_MultiTaskContinuation_NullTask, ExceptionArgument.tasks);
-                    }
-                }
-                return TaskFactory.CommonCWAnyLogic(taskArray);
-            }
-            if (tasks is null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.tasks);
-            }
-            var taskList = new List<TTask>();
-            foreach (TTask task in tasks)
-            {
-                if (task is null)
-                {
-                    ThrowHelper.ThrowArgumentException(ExceptionResource.Task_MultiTaskContinuation_NullTask, ExceptionArgument.tasks);
-                }
-                taskList.Add(task);
-            }
-            if (taskList.Count == 0)
-            {
-                ThrowHelper.ThrowArgumentException(ExceptionResource.Task_MultiTaskContinuation_EmptyTaskList, ExceptionArgument.tasks);
-            }
-            return TaskFactory.CommonCWAnyLogic(taskList);
-        }
-        public static Task<Task<TResult>> WhenAny<TResult>(params Task<TResult>[] tasks)
-        {
-            ArgumentNullException.ThrowIfNull(tasks);
-            return WhenAnyCore((ReadOnlySpan<Task<TResult>>)tasks);
-        }
-        public static Task<Task<TResult>> WhenAny<TResult>(params ReadOnlySpan<Task<TResult>> tasks) =>
-            WhenAnyCore(tasks);
-        public static Task<Task<TResult>> WhenAny<TResult>(Task<TResult> task1, Task<TResult> task2) =>
-            WhenAny<Task<TResult>>(task1, task2);
-        public static Task<Task<TResult>> WhenAny<TResult>(IEnumerable<Task<TResult>> tasks) =>
-            WhenAny<Task<TResult>>(tasks);
-        #endregion
-        #region WhenEach
-        public static IAsyncEnumerable<Task> WhenEach(params Task[] tasks)
-        {
-            ArgumentNullException.ThrowIfNull(tasks);
-            return WhenEach((ReadOnlySpan<Task>)tasks);
-        }
-        public static IAsyncEnumerable<Task> WhenEach(ReadOnlySpan<Task> tasks) => // TODO https://github.com/dotnet/runtime/issues/77873: Add params
-            WhenEachState.Iterate<Task>(WhenEachState.Create(tasks));
-        public static IAsyncEnumerable<Task> WhenEach(IEnumerable<Task> tasks) =>
-            WhenEachState.Iterate<Task>(WhenEachState.Create(tasks));
-        public static IAsyncEnumerable<Task<TResult>> WhenEach<TResult>(params Task<TResult>[] tasks)
-        {
-            ArgumentNullException.ThrowIfNull(tasks);
-            return WhenEach((ReadOnlySpan<Task<TResult>>)tasks);
-        }
-        public static IAsyncEnumerable<Task<TResult>> WhenEach<TResult>(ReadOnlySpan<Task<TResult>> tasks) => // TODO https://github.com/dotnet/runtime/issues/77873: Add params
-            WhenEachState.Iterate<Task<TResult>>(WhenEachState.Create(ReadOnlySpan<Task>.CastUp(tasks)));
-        public static IAsyncEnumerable<Task<TResult>> WhenEach<TResult>(IEnumerable<Task<TResult>> tasks) =>
-            WhenEachState.Iterate<Task<TResult>>(WhenEachState.Create(tasks));
-        private sealed class WhenEachState : Queue<Task>, IValueTaskSource, ITaskCompletionAction
-        {
-            private ManualResetValueTaskSourceCore<bool> _waitForNextCompletedTask = new() { RunContinuationsAsynchronously = true }; // _waitForNextCompletedTask.Set is called while holding a lock
-            private int _enumerated;
-            public bool TryStart() => Interlocked.Exchange(ref _enumerated, 1) == 0;
-            public int Remaining { get; set; }
-            void ITaskCompletionAction.Invoke(Task completingTask)
-            {
-                lock (this)
-                {
-                    Enqueue(completingTask);
-                    if (Count == 1)
-                    {
-                        Debug.Assert(_waitForNextCompletedTask.GetStatus(_waitForNextCompletedTask.Version) == ValueTaskSourceStatus.Pending);
-                        _waitForNextCompletedTask.SetResult(default);
-                    }
-                }
-            }
-            bool ITaskCompletionAction.InvokeMayRunArbitraryCode => false;
-            void IValueTaskSource.GetResult(short token) => _waitForNextCompletedTask.GetResult(token);
-            ValueTaskSourceStatus IValueTaskSource.GetStatus(short token) => _waitForNextCompletedTask.GetStatus(token);
-            void IValueTaskSource.OnCompleted(Action<object?> continuation, object? state, short token, ValueTaskSourceOnCompletedFlags flags) =>
-                _waitForNextCompletedTask.OnCompleted(continuation, state, token, flags);
-            public static WhenEachState? Create(ReadOnlySpan<Task> tasks)
-            {
-                WhenEachState? waiter = null;
-                if (tasks.Length != 0)
-                {
-                    waiter = new();
-                    foreach (Task task in tasks)
-                    {
-                        if (task is null)
-                        {
-                            ThrowHelper.ThrowArgumentException(ExceptionResource.Task_MultiTaskContinuation_NullTask, ExceptionArgument.tasks);
-                        }
-                        waiter.Remaining++;
-                        task.AddCompletionAction(waiter);
-                    }
-                }
-                return waiter;
-            }
-            public static WhenEachState? Create(IEnumerable<Task> tasks)
-            {
-                ArgumentNullException.ThrowIfNull(tasks);
-                WhenEachState? waiter = null;
-                IEnumerator<Task> e = tasks.GetEnumerator();
-                if (e.MoveNext())
-                {
-                    waiter = new();
-                    do
-                    {
-                        Task task = e.Current;
-                        if (task is null)
-                        {
-                            ThrowHelper.ThrowArgumentException(ExceptionResource.Task_MultiTaskContinuation_NullTask, ExceptionArgument.tasks);
-                        }
-                        waiter.Remaining++;
-                        task.AddCompletionAction(waiter);
-                    }
-                    while (e.MoveNext());
-                }
-                return waiter;
-            }
-            public static async IAsyncEnumerable<T> Iterate<T>(WhenEachState? waiter, [EnumeratorCancellation] CancellationToken cancellationToken = default) where T : Task
-            {
-                if (waiter?.TryStart() is not true)
-                {
-                    yield break;
-                }
-                while (waiter.Remaining > 0)
-                {
-                    Task? next;
-                    ValueTask waitTask = default;
-                    lock (waiter)
-                    {
-                        waiter._waitForNextCompletedTask.Reset();
-                        if (!waiter.TryDequeue(out next))
-                        {
-                            waitTask = new(waiter, waiter._waitForNextCompletedTask.Version);
-                        }
-                    }
-                    if (next is not null)
-                    {
-                        cancellationToken.ThrowIfCancellationRequested();
-                        waiter.Remaining--;
-                        yield return (T)next;
-                        continue;
-                    }
-                    if (cancellationToken.CanBeCanceled && !waitTask.IsCompleted)
-                    {
-                        waitTask = new ValueTask(waitTask.AsTask().WaitAsync(cancellationToken));
-                    }
-                    await waitTask.ConfigureAwait(false);
-                }
-            }
-        }
-        #endregion
-        internal static Task<TResult> CreateUnwrapPromise<TResult>(Task outerTask, bool lookForOce)
-        {
-            Debug.Assert(outerTask != null);
-            return new UnwrapPromise<TResult>(outerTask, lookForOce);
-        }
-        internal virtual Delegate[]? GetDelegateContinuationsForDebugger()
-        {
-            if (m_continuationObject != this)
-                return GetDelegatesFromContinuationObject(m_continuationObject);
-            else
-                return null;
-        }
-        private static Delegate[]? GetDelegatesFromContinuationObject(object? continuationObject)
-        {
-            if (continuationObject != null)
-            {
-                if (continuationObject is Action singleAction)
-                {
-                    return [AsyncMethodBuilderCore.TryGetStateMachineForDebugger(singleAction)];
-                }
-                if (continuationObject is TaskContinuation taskContinuation)
-                {
-                    return taskContinuation.GetDelegateContinuationsForDebugger();
-                }
-                if (continuationObject is Task continuationTask)
-                {
-                    Delegate[]? delegates = continuationTask.GetDelegateContinuationsForDebugger();
-                    if (delegates != null)
-                        return delegates;
-                }
-                if (continuationObject is ITaskCompletionAction singleCompletionAction)
-                {
-                    return [new Action<Task>(singleCompletionAction.Invoke)];
-                }
-                if (continuationObject is List<object?> continuationList)
-                {
-                    List<Delegate> result = new List<Delegate>();
-                    foreach (object? obj in continuationList)
-                    {
-                        Delegate[]? innerDelegates = GetDelegatesFromContinuationObject(obj);
-                        if (innerDelegates != null)
-                        {
-                            foreach (Delegate del in innerDelegates)
-                            {
-                                if (del != null)
-                                    result.Add(del);
-                            }
-                        }
-                    }
-                    return result.ToArray();
-                }
-            }
-            return null;
-        }
-        private static Task? GetActiveTaskFromId(int taskId)
-        {
-            Task? task = null;
-            s_currentActiveTasks?.TryGetValue(taskId, out task);
-            return task;
-        }
-    }
-    internal sealed class CompletionActionInvoker : IThreadPoolWorkItem
-    {
-        private readonly ITaskCompletionAction m_action;
-        private readonly Task m_completingTask;
-        internal CompletionActionInvoker(ITaskCompletionAction action, Task completingTask)
-        {
-            m_action = action;
-            m_completingTask = completingTask;
-        }
-        void IThreadPoolWorkItem.Execute()
-        {
-            m_action.Invoke(m_completingTask);
-        }
-    }
-    internal sealed class SystemThreadingTasks_TaskDebugView
-    {
-        private readonly Task m_task;
-        public SystemThreadingTasks_TaskDebugView(Task task)
-        {
-            m_task = task;
-        }
-        public object? AsyncState => m_task.AsyncState;
-        public TaskCreationOptions CreationOptions => m_task.CreationOptions;
-        public Exception? Exception => m_task.Exception;
-        public int Id => m_task.Id;
-        public bool CancellationPending => (m_task.Status == TaskStatus.WaitingToRun) && m_task.CancellationToken.IsCancellationRequested;
-        public TaskStatus Status => m_task.Status;
-    }
-    [Flags]
-    public enum TaskCreationOptions
-    {
-        None = 0x0,
-        PreferFairness = 0x01,
-        LongRunning = 0x02,
-        AttachedToParent = 0x04,
-        DenyChildAttach = 0x08,
-        HideScheduler = 0x10,
-        RunContinuationsAsynchronously = 0x40
-    }
-    [Flags]
-    internal enum InternalTaskOptions
-    {
-        None,
-        InternalOptionsMask = 0x0000FF00,
-        ContinuationTask = 0x0200,
-        PromiseTask = 0x0400,
-        HiddenState = 0x0800,
-        LazyCancellation = 0x1000,
-        QueuedByRuntime = 0x2000,
-        DoNotDispose = 0x4000
-    }
-    [Flags]
-    public enum TaskContinuationOptions
-    {
-        None = 0,
-        PreferFairness = 0x01,
-        LongRunning = 0x02,
-        AttachedToParent = 0x04,
-        DenyChildAttach = 0x08,
-        HideScheduler = 0x10,
-        LazyCancellation = 0x20,
-        RunContinuationsAsynchronously = 0x40,
-        NotOnRanToCompletion = 0x10000,
-        NotOnFaulted = 0x20000,
-        NotOnCanceled = 0x40000,
-        OnlyOnRanToCompletion = NotOnFaulted | NotOnCanceled,
-        OnlyOnFaulted = NotOnRanToCompletion | NotOnCanceled,
-        OnlyOnCanceled = NotOnRanToCompletion | NotOnFaulted,
-        ExecuteSynchronously = 0x80000
-    }
-    internal readonly struct VoidTaskResult { }
-    internal interface ITaskCompletionAction
-    {
-        void Invoke(Task completingTask);
-        bool InvokeMayRunArbitraryCode { get; }
-    }
-    internal sealed class UnwrapPromise<TResult> : Task<TResult>, ITaskCompletionAction
-    {
-        private const byte STATE_WAITING_ON_OUTER_TASK = 0; // Invoke() means "process completed outer task"
-        private const byte STATE_WAITING_ON_INNER_TASK = 1; // Invoke() means "process completed inner task"
-        private const byte STATE_DONE = 2;                  // Invoke() means "something went wrong and we are hosed!"
-        private byte _state;
-        private readonly bool _lookForOce;
-        public UnwrapPromise(Task outerTask, bool lookForOce)
-            : base((object?)null, outerTask.CreationOptions & TaskCreationOptions.AttachedToParent)
-        {
-            Debug.Assert(outerTask != null, "Expected non-null outerTask");
-            _lookForOce = lookForOce;
-            if (TplEventSource.Log.IsEnabled())
-                TplEventSource.Log.TraceOperationBegin(this.Id, "Task.Unwrap", 0);
-            if (s_asyncDebuggingEnabled)
-                AddToActiveTasks(this);
-            if (outerTask.IsCompleted)
-            {
-                ProcessCompletedOuterTask(outerTask);
-            }
-            else // Otherwise, process its completion asynchronously.
-            {
-                outerTask.AddCompletionAction(this);
-            }
-        }
-        public void Invoke(Task completingTask)
-        {
-            if (RuntimeHelpers.TryEnsureSufficientExecutionStack())
-            {
-                InvokeCore(completingTask);
-            }
-            else
-            {
-                InvokeCoreAsync(completingTask);
-            }
-        }
-        private void InvokeCore(Task completingTask)
-        {
-            switch (_state)
-            {
-                case STATE_WAITING_ON_OUTER_TASK:
-                    ProcessCompletedOuterTask(completingTask);
-                    break;
-                case STATE_WAITING_ON_INNER_TASK:
-                    bool result = TrySetFromTask(completingTask, lookForOce: false);
-                    _state = STATE_DONE; // bump the state
-                    Debug.Assert(result, "Expected TrySetFromTask from inner task to succeed");
-                    break;
-                default:
-                    Debug.Fail("UnwrapPromise in illegal state");
-                    break;
-            }
-        }
-        private void InvokeCoreAsync(Task completingTask)
-        {
-            ThreadPool.UnsafeQueueUserWorkItem(static state =>
-            {
-                var tuple = (TupleSlim<UnwrapPromise<TResult>, Task>)state!;
-                tuple.Item1.InvokeCore(tuple.Item2);
-            }, new TupleSlim<UnwrapPromise<TResult>, Task>(this, completingTask));
-        }
-        private void ProcessCompletedOuterTask(Task task)
-        {
-            Debug.Assert(task != null && task.IsCompleted, "Expected non-null, completed outer task");
-            Debug.Assert(_state == STATE_WAITING_ON_OUTER_TASK, "We're in the wrong state!");
-            _state = STATE_WAITING_ON_INNER_TASK;
-            switch (task.Status)
-            {
-                case TaskStatus.Canceled:
-                case TaskStatus.Faulted:
-                    bool result = TrySetFromTask(task, _lookForOce);
-                    Debug.Assert(result, "Expected TrySetFromTask from outer task to succeed");
-                    break;
-                case TaskStatus.RanToCompletion:
-                    ProcessInnerTask(task is Task<Task<TResult>> taskOfTaskOfTResult ? // it's either a Task<Task> or Task<Task<TResult>>
-                        taskOfTaskOfTResult.Result : ((Task<Task>)task).Result);
-                    break;
-            }
-        }
-        private bool TrySetFromTask(Task task, bool lookForOce)
-        {
-            Debug.Assert(task != null && task.IsCompleted, "TrySetFromTask: Expected task to have completed.");
-            if (TplEventSource.Log.IsEnabled())
-                TplEventSource.Log.TraceOperationRelation(this.Id, CausalityRelation.Join);
-            bool result = false;
-            switch (task.Status)
-            {
-                case TaskStatus.Canceled:
-                    result = TrySetCanceled(task.CancellationToken, task.GetCancellationExceptionDispatchInfo());
-                    break;
-                case TaskStatus.Faulted:
-                    List<ExceptionDispatchInfo> edis = task.GetExceptionDispatchInfos();
-                    ExceptionDispatchInfo oceEdi;
-                    if (lookForOce && edis.Count > 0 &&
-                        (oceEdi = edis[0]) != null &&
-                        oceEdi.SourceException is OperationCanceledException oce)
-                    {
-                        result = TrySetCanceled(oce.CancellationToken, oceEdi);
-                    }
-                    else
-                    {
-                        result = TrySetException(edis);
-                    }
-                    break;
-                case TaskStatus.RanToCompletion:
-                    if (TplEventSource.Log.IsEnabled())
-                        TplEventSource.Log.TraceOperationEnd(this.Id, AsyncCausalityStatus.Completed);
-                    if (s_asyncDebuggingEnabled)
-                        RemoveFromActiveTasks(this);
-                    result = TrySetResult(task is Task<TResult> taskTResult ? taskTResult.Result : default);
-                    break;
-            }
-            return result;
-        }
-        private void ProcessInnerTask(Task? task)
-        {
-            if (task == null)
-            {
-                TrySetCanceled(default);
-                _state = STATE_DONE; // ... and record that we are done
-            }
-            else if (task.IsCompleted)
-            {
-                TrySetFromTask(task, lookForOce: false);
-                _state = STATE_DONE; // ... and record that we are done
-            }
-            else
-            {
-                task.AddCompletionAction(this);
-            }
-        }
-        public bool InvokeMayRunArbitraryCode => true;
-    }
-}

--- a/src/libraries/System.Private.CoreLib/src/System/Threading/ThreadPoolWorkQueue.cs
+++ b//dev/null
@@ -1,1427 +0,0 @@
-using System.Collections.Concurrent;
-using System.Collections.Generic;
-using System.Diagnostics;
-using System.Diagnostics.CodeAnalysis;
-using System.Diagnostics.Tracing;
-using System.Runtime.CompilerServices;
-using System.Runtime.InteropServices;
-using System.Runtime.Versioning;
-using System.Threading.Tasks;
-namespace System.Threading
-{
-    internal sealed partial class ThreadPoolWorkQueue
-    {
-        internal static class WorkStealingQueueList
-        {
-#pragma warning disable CA1825, IDE0300 // avoid the extra generic instantiation for Array.Empty<T>(); this is the only place we'll ever create this array
-            private static WorkStealingQueue[] s_queues = new WorkStealingQueue[0];
-#pragma warning restore CA1825, IDE0300
-            public static WorkStealingQueue[] Queues => s_queues;
-            public static void Add(WorkStealingQueue queue)
-            {
-                Debug.Assert(queue != null);
-                while (true)
-                {
-                    WorkStealingQueue[] oldQueues = s_queues;
-                    Debug.Assert(Array.IndexOf(oldQueues, queue) < 0);
-                    var newQueues = new WorkStealingQueue[oldQueues.Length + 1];
-                    Array.Copy(oldQueues, newQueues, oldQueues.Length);
-                    newQueues[^1] = queue;
-                    if (Interlocked.CompareExchange(ref s_queues, newQueues, oldQueues) == oldQueues)
-                    {
-                        break;
-                    }
-                }
-            }
-            public static void Remove(WorkStealingQueue queue)
-            {
-                Debug.Assert(queue != null);
-                while (true)
-                {
-                    WorkStealingQueue[] oldQueues = s_queues;
-                    if (oldQueues.Length == 0)
-                    {
-                        return;
-                    }
-                    int pos = Array.IndexOf(oldQueues, queue);
-                    if (pos < 0)
-                    {
-                        Debug.Fail("Should have found the queue");
-                        return;
-                    }
-                    var newQueues = new WorkStealingQueue[oldQueues.Length - 1];
-                    if (pos == 0)
-                    {
-                        Array.Copy(oldQueues, 1, newQueues, 0, newQueues.Length);
-                    }
-                    else if (pos == oldQueues.Length - 1)
-                    {
-                        Array.Copy(oldQueues, newQueues, newQueues.Length);
-                    }
-                    else
-                    {
-                        Array.Copy(oldQueues, newQueues, pos);
-                        Array.Copy(oldQueues, pos + 1, newQueues, pos, newQueues.Length - pos);
-                    }
-                    if (Interlocked.CompareExchange(ref s_queues, newQueues, oldQueues) == oldQueues)
-                    {
-                        break;
-                    }
-                }
-            }
-        }
-        internal sealed class WorkStealingQueue
-        {
-            private const int INITIAL_SIZE = 32;
-            internal volatile object?[] m_array = new object[INITIAL_SIZE]; // SOS's ThreadPool command depends on this name
-            private volatile int m_mask = INITIAL_SIZE - 1;
-#if DEBUG
-            private const int START_INDEX = int.MaxValue;
-#else
-            private const int START_INDEX = 0;
-#endif
-            private volatile int m_headIndex = START_INDEX;
-            private volatile int m_tailIndex = START_INDEX;
-            private SpinLock m_foreignLock = new SpinLock(enableThreadOwnerTracking: false);
-            public void LocalPush(object obj)
-            {
-                int tail = m_tailIndex;
-                if (tail == int.MaxValue)
-                {
-                    tail = LocalPush_HandleTailOverflow();
-                }
-                if (tail < m_headIndex + m_mask)
-                {
-                    Volatile.Write(ref m_array[tail & m_mask], obj);
-                    m_tailIndex = tail + 1;
-                }
-                else
-                {
-                    bool lockTaken = false;
-                    try
-                    {
-                        m_foreignLock.Enter(ref lockTaken);
-                        int head = m_headIndex;
-                        int count = m_tailIndex - m_headIndex;
-                        if (count >= m_mask)
-                        {
-                            var newArray = new object?[m_array.Length << 1];
-                            for (int i = 0; i < m_array.Length; i++)
-                                newArray[i] = m_array[(i + head) & m_mask];
-                            m_array = newArray;
-                            m_headIndex = 0;
-                            m_tailIndex = tail = count;
-                            m_mask = (m_mask << 1) | 1;
-                        }
-                        Volatile.Write(ref m_array[tail & m_mask], obj);
-                        m_tailIndex = tail + 1;
-                    }
-                    finally
-                    {
-                        if (lockTaken)
-                            m_foreignLock.Exit(useMemoryBarrier: false);
-                    }
-                }
-            }
-            [MethodImpl(MethodImplOptions.NoInlining)]
-            private int LocalPush_HandleTailOverflow()
-            {
-                bool lockTaken = false;
-                try
-                {
-                    m_foreignLock.Enter(ref lockTaken);
-                    int tail = m_tailIndex;
-                    if (tail == int.MaxValue)
-                    {
-                        m_headIndex &= m_mask;
-                        m_tailIndex = tail = m_tailIndex & m_mask;
-                        Debug.Assert(m_headIndex <= m_tailIndex);
-                    }
-                    return tail;
-                }
-                finally
-                {
-                    if (lockTaken)
-                        m_foreignLock.Exit(useMemoryBarrier: true);
-                }
-            }
-            public bool LocalFindAndPop(object obj)
-            {
-                if (m_array[(m_tailIndex - 1) & m_mask] == obj)
-                {
-                    object? unused = LocalPop();
-                    Debug.Assert(unused == null || unused == obj);
-                    return unused != null;
-                }
-                for (int i = m_tailIndex - 2; i >= m_headIndex; i--)
-                {
-                    if (m_array[i & m_mask] == obj)
-                    {
-                        bool lockTaken = false;
-                        try
-                        {
-                            m_foreignLock.Enter(ref lockTaken);
-                            if (m_array[i & m_mask] == null)
-                                return false;
-                            Volatile.Write(ref m_array[i & m_mask], null);
-                            if (i == m_tailIndex)
-                                m_tailIndex--;
-                            else if (i == m_headIndex)
-                                m_headIndex++;
-                            return true;
-                        }
-                        finally
-                        {
-                            if (lockTaken)
-                                m_foreignLock.Exit(useMemoryBarrier: false);
-                        }
-                    }
-                }
-                return false;
-            }
-            public object? LocalPop() => m_headIndex < m_tailIndex ? LocalPopCore() : null;
-            private object? LocalPopCore()
-            {
-                while (true)
-                {
-                    int tail = m_tailIndex;
-                    if (m_headIndex >= tail)
-                    {
-                        return null;
-                    }
-                    tail--;
-                    Interlocked.Exchange(ref m_tailIndex, tail);
-                    if (m_headIndex <= tail)
-                    {
-                        int idx = tail & m_mask;
-                        object? obj = Volatile.Read(ref m_array[idx]);
-                        if (obj == null) continue;
-                        m_array[idx] = null;
-                        return obj;
-                    }
-                    else
-                    {
-                        bool lockTaken = false;
-                        try
-                        {
-                            m_foreignLock.Enter(ref lockTaken);
-                            if (m_headIndex <= tail)
-                            {
-                                int idx = tail & m_mask;
-                                object? obj = Volatile.Read(ref m_array[idx]);
-                                if (obj == null) continue;
-                                m_array[idx] = null;
-                                return obj;
-                            }
-                            else
-                            {
-                                m_tailIndex = tail + 1;
-                                return null;
-                            }
-                        }
-                        finally
-                        {
-                            if (lockTaken)
-                                m_foreignLock.Exit(useMemoryBarrier: false);
-                        }
-                    }
-                }
-            }
-            public bool CanSteal => m_headIndex < m_tailIndex;
-            public object? TrySteal(ref bool missedSteal)
-            {
-                while (true)
-                {
-                    if (CanSteal)
-                    {
-                        bool taken = false;
-                        try
-                        {
-                            m_foreignLock.TryEnter(ref taken);
-                            if (taken)
-                            {
-                                int head = m_headIndex;
-                                Interlocked.Exchange(ref m_headIndex, head + 1);
-                                if (head < m_tailIndex)
-                                {
-                                    int idx = head & m_mask;
-                                    object? obj = Volatile.Read(ref m_array[idx]);
-                                    if (obj == null) continue;
-                                    m_array[idx] = null;
-                                    return obj;
-                                }
-                                else
-                                {
-                                    m_headIndex = head;
-                                }
-                            }
-                        }
-                        finally
-                        {
-                            if (taken)
-                                m_foreignLock.Exit(useMemoryBarrier: false);
-                        }
-                        missedSteal = true;
-                    }
-                    return null;
-                }
-            }
-            public int Count
-            {
-                get
-                {
-                    bool lockTaken = false;
-                    try
-                    {
-                        m_foreignLock.Enter(ref lockTaken);
-                        return Math.Max(0, m_tailIndex - m_headIndex);
-                    }
-                    finally
-                    {
-                        if (lockTaken)
-                        {
-                            m_foreignLock.Exit(useMemoryBarrier: false);
-                        }
-                    }
-                }
-            }
-        }
-#if CORECLR
-        internal static readonly bool s_prioritizationExperiment =
-            AppContextConfigHelper.GetBooleanConfig(
-                "System.Threading.ThreadPool.PrioritizationExperiment",
-                "DOTNET_ThreadPool_PrioritizationExperiment",
-                defaultValue: false);
-#endif
-        private const int ProcessorsPerAssignableWorkItemQueue = 16;
-        private static readonly int s_assignableWorkItemQueueCount =
-            Environment.ProcessorCount <= 32 ? 0 :
-                (Environment.ProcessorCount + (ProcessorsPerAssignableWorkItemQueue - 1)) / ProcessorsPerAssignableWorkItemQueue;
-        private bool _loggingEnabled;
-        private bool _dispatchNormalPriorityWorkFirst;
-        private bool _mayHaveHighPriorityWorkItems;
-        internal readonly ConcurrentQueue<object> workItems = new ConcurrentQueue<object>();
-        internal readonly ConcurrentQueue<object> highPriorityWorkItems = new ConcurrentQueue<object>();
-#if CORECLR
-        internal readonly ConcurrentQueue<object> lowPriorityWorkItems =
-            s_prioritizationExperiment ? new ConcurrentQueue<object>() : null!;
-#endif
-        internal readonly ConcurrentQueue<object>[] _assignableWorkItemQueues =
-            new ConcurrentQueue<object>[s_assignableWorkItemQueueCount];
-        private readonly LowLevelLock _queueAssignmentLock = new();
-        private readonly int[] _assignedWorkItemQueueThreadCounts =
-            s_assignableWorkItemQueueCount > 0 ? new int[s_assignableWorkItemQueueCount] : Array.Empty<int>();
-        private object? _nextWorkItemToProcess;
-        private enum QueueProcessingStage
-        {
-            NotScheduled,
-            Determining,
-            Scheduled
-        }
-        [StructLayout(LayoutKind.Sequential)]
-        private struct CacheLineSeparated
-        {
-            private readonly Internal.PaddingFor32 pad1;
-            public QueueProcessingStage queueProcessingStage;
-            private readonly Internal.PaddingFor32 pad2;
-        }
-        private CacheLineSeparated _separated;
-        public ThreadPoolWorkQueue()
-        {
-            for (int i = 0; i < s_assignableWorkItemQueueCount; i++)
-            {
-                _assignableWorkItemQueues[i] = new ConcurrentQueue<object>();
-            }
-            RefreshLoggingEnabled();
-        }
-        private void AssignWorkItemQueue(ThreadPoolWorkQueueThreadLocals tl)
-        {
-            Debug.Assert(s_assignableWorkItemQueueCount > 0);
-            _queueAssignmentLock.Acquire();
-            int queueIndex = -1;
-            int minCount = int.MaxValue;
-            int minCountQueueIndex = 0;
-            for (int i = 0; i < s_assignableWorkItemQueueCount; i++)
-            {
-                int count = _assignedWorkItemQueueThreadCounts[i];
-                Debug.Assert(count >= 0);
-                if (count < ProcessorsPerAssignableWorkItemQueue)
-                {
-                    queueIndex = i;
-                    _assignedWorkItemQueueThreadCounts[queueIndex] = count + 1;
-                    break;
-                }
-                if (count < minCount)
-                {
-                    minCount = count;
-                    minCountQueueIndex = i;
-                }
-            }
-            if (queueIndex < 0)
-            {
-                queueIndex = minCountQueueIndex;
-                _assignedWorkItemQueueThreadCounts[queueIndex]++;
-            }
-            _queueAssignmentLock.Release();
-            tl.queueIndex = queueIndex;
-            tl.assignedGlobalWorkItemQueue = _assignableWorkItemQueues[queueIndex];
-        }
-        private void TryReassignWorkItemQueue(ThreadPoolWorkQueueThreadLocals tl)
-        {
-            Debug.Assert(s_assignableWorkItemQueueCount > 0);
-            int queueIndex = tl.queueIndex;
-            if (queueIndex == 0)
-            {
-                return;
-            }
-            if (!_queueAssignmentLock.TryAcquire())
-            {
-                return;
-            }
-            Debug.Assert(_assignedWorkItemQueueThreadCounts[queueIndex] >= 0);
-            if (_assignedWorkItemQueueThreadCounts[queueIndex] > 1)
-            {
-                for (int i = 0; i < queueIndex; i++)
-                {
-                    if (_assignedWorkItemQueueThreadCounts[i] < ProcessorsPerAssignableWorkItemQueue)
-                    {
-                        _assignedWorkItemQueueThreadCounts[queueIndex]--;
-                        queueIndex = i;
-                        _assignedWorkItemQueueThreadCounts[queueIndex]++;
-                        break;
-                    }
-                }
-            }
-            _queueAssignmentLock.Release();
-            tl.queueIndex = queueIndex;
-            tl.assignedGlobalWorkItemQueue = _assignableWorkItemQueues[queueIndex];
-        }
-        private void UnassignWorkItemQueue(ThreadPoolWorkQueueThreadLocals tl)
-        {
-            Debug.Assert(s_assignableWorkItemQueueCount > 0);
-            int queueIndex = tl.queueIndex;
-            _queueAssignmentLock.Acquire();
-            int newCount = --_assignedWorkItemQueueThreadCounts[queueIndex];
-            _queueAssignmentLock.Release();
-            Debug.Assert(newCount >= 0);
-            if (newCount > 0)
-            {
-                return;
-            }
-            bool movedWorkItem = false;
-            ConcurrentQueue<object> queue = tl.assignedGlobalWorkItemQueue;
-            while (_assignedWorkItemQueueThreadCounts[queueIndex] <= 0 && queue.TryDequeue(out object? workItem))
-            {
-                workItems.Enqueue(workItem);
-                movedWorkItem = true;
-            }
-            if (movedWorkItem)
-            {
-                EnsureThreadRequested();
-            }
-        }
-        public ThreadPoolWorkQueueThreadLocals GetOrCreateThreadLocals() =>
-            ThreadPoolWorkQueueThreadLocals.threadLocals ?? CreateThreadLocals();
-        [MethodImpl(MethodImplOptions.NoInlining)]
-        private ThreadPoolWorkQueueThreadLocals CreateThreadLocals()
-        {
-            Debug.Assert(ThreadPoolWorkQueueThreadLocals.threadLocals == null);
-            return ThreadPoolWorkQueueThreadLocals.threadLocals = new ThreadPoolWorkQueueThreadLocals(this);
-        }
-        [MethodImpl(MethodImplOptions.AggressiveInlining)]
-        public void RefreshLoggingEnabled()
-        {
-            if (!FrameworkEventSource.Log.IsEnabled())
-            {
-                if (_loggingEnabled)
-                {
-                    _loggingEnabled = false;
-                }
-                return;
-            }
-            RefreshLoggingEnabledFull();
-        }
-        [MethodImpl(MethodImplOptions.NoInlining)]
-        public void RefreshLoggingEnabledFull()
-        {
-            _loggingEnabled = FrameworkEventSource.Log.IsEnabled(EventLevel.Verbose, FrameworkEventSource.Keywords.ThreadPool | FrameworkEventSource.Keywords.ThreadTransfer);
-        }
-        [MethodImpl(MethodImplOptions.AggressiveInlining)]
-        internal void EnsureThreadRequested()
-        {
-            if (Interlocked.Exchange(
-                ref _separated.queueProcessingStage,
-                QueueProcessingStage.Scheduled) == QueueProcessingStage.NotScheduled)
-            {
-                ThreadPool.RequestWorkerThread();
-            }
-        }
-        public void Enqueue(object callback, bool forceGlobal)
-        {
-            Debug.Assert((callback is IThreadPoolWorkItem) ^ (callback is Task));
-            if (_loggingEnabled && FrameworkEventSource.Log.IsEnabled())
-                FrameworkEventSource.Log.ThreadPoolEnqueueWorkObject(callback);
-#if CORECLR
-            if (s_prioritizationExperiment)
-            {
-                EnqueueForPrioritizationExperiment(callback, forceGlobal);
-            }
-            else
-#endif
-            {
-                ThreadPoolWorkQueueThreadLocals? tl;
-                if (!forceGlobal && (tl = ThreadPoolWorkQueueThreadLocals.threadLocals) != null)
-                {
-                    tl.workStealingQueue.LocalPush(callback);
-                }
-                else
-                {
-                    ConcurrentQueue<object> queue =
-                        s_assignableWorkItemQueueCount > 0 && (tl = ThreadPoolWorkQueueThreadLocals.threadLocals) != null
-                            ? tl.assignedGlobalWorkItemQueue
-                            : workItems;
-                    queue.Enqueue(callback);
-                }
-            }
-            EnsureThreadRequested();
-        }
-#if CORECLR
-        [MethodImpl(MethodImplOptions.NoInlining)]
-        private void EnqueueForPrioritizationExperiment(object callback, bool forceGlobal)
-        {
-            ThreadPoolWorkQueueThreadLocals? tl = ThreadPoolWorkQueueThreadLocals.threadLocals;
-            if (!forceGlobal && tl != null)
-            {
-                tl.workStealingQueue.LocalPush(callback);
-                return;
-            }
-            ConcurrentQueue<object> queue;
-            if (tl == null && callback is QueueUserWorkItemCallbackBase)
-            {
-                queue = lowPriorityWorkItems;
-            }
-            else if (s_assignableWorkItemQueueCount > 0 && tl != null)
-            {
-                queue = tl.assignedGlobalWorkItemQueue;
-            }
-            else
-            {
-                queue = workItems;
-            }
-            queue.Enqueue(callback);
-        }
-#endif
-        public void EnqueueAtHighPriority(object workItem)
-        {
-            Debug.Assert((workItem is IThreadPoolWorkItem) ^ (workItem is Task));
-            if (_loggingEnabled && FrameworkEventSource.Log.IsEnabled())
-                FrameworkEventSource.Log.ThreadPoolEnqueueWorkObject(workItem);
-            highPriorityWorkItems.Enqueue(workItem);
-            Volatile.Write(ref _mayHaveHighPriorityWorkItems, true);
-            EnsureThreadRequested();
-        }
-        internal static void TransferAllLocalWorkItemsToHighPriorityGlobalQueue()
-        {
-            if (ThreadPoolWorkQueueThreadLocals.threadLocals is not ThreadPoolWorkQueueThreadLocals tl)
-            {
-                return;
-            }
-            ThreadPoolWorkQueue queue = ThreadPool.s_workQueue;
-            while (tl.workStealingQueue.LocalPop() is object workItem)
-            {
-                queue.highPriorityWorkItems.Enqueue(workItem);
-            }
-            Volatile.Write(ref queue._mayHaveHighPriorityWorkItems, true);
-            queue.EnsureThreadRequested();
-        }
-        internal static bool LocalFindAndPop(object callback)
-        {
-            ThreadPoolWorkQueueThreadLocals? tl = ThreadPoolWorkQueueThreadLocals.threadLocals;
-            return tl != null && tl.workStealingQueue.LocalFindAndPop(callback);
-        }
-        public object? Dequeue(ThreadPoolWorkQueueThreadLocals tl, ref bool missedSteal)
-        {
-            object? workItem = tl.workStealingQueue.LocalPop();
-            if (workItem != null)
-            {
-                return workItem;
-            }
-            if (_nextWorkItemToProcess != null)
-            {
-                workItem = Interlocked.Exchange(ref _nextWorkItemToProcess, null);
-                if (workItem != null)
-                {
-                    return workItem;
-                }
-            }
-            if (tl.isProcessingHighPriorityWorkItems)
-            {
-                if (highPriorityWorkItems.TryDequeue(out workItem))
-                {
-                    return workItem;
-                }
-                tl.isProcessingHighPriorityWorkItems = false;
-            }
-            else if (
-                _mayHaveHighPriorityWorkItems &&
-                Interlocked.CompareExchange(ref _mayHaveHighPriorityWorkItems, false, true) &&
-                TryStartProcessingHighPriorityWorkItemsAndDequeue(tl, out workItem))
-            {
-                return workItem;
-            }
-            if (s_assignableWorkItemQueueCount > 0 && tl.assignedGlobalWorkItemQueue.TryDequeue(out workItem))
-            {
-                return workItem;
-            }
-            if (workItems.TryDequeue(out workItem))
-            {
-                return workItem;
-            }
-            uint randomValue = tl.random.NextUInt32();
-            if (s_assignableWorkItemQueueCount > 0)
-            {
-                int queueIndex = tl.queueIndex;
-                int c = s_assignableWorkItemQueueCount;
-                int maxIndex = c - 1;
-                for (int i = (int)(randomValue % (uint)c); c > 0; i = i < maxIndex ? i + 1 : 0, c--)
-                {
-                    if (i != queueIndex && _assignableWorkItemQueues[i].TryDequeue(out workItem))
-                    {
-                        return workItem;
-                    }
-                }
-            }
-#if CORECLR
-            if (s_prioritizationExperiment && lowPriorityWorkItems.TryDequeue(out workItem))
-            {
-                return workItem;
-            }
-#endif
-            {
-                WorkStealingQueue localWsq = tl.workStealingQueue;
-                WorkStealingQueue[] queues = WorkStealingQueueList.Queues;
-                int c = queues.Length;
-                Debug.Assert(c > 0, "There must at least be a queue for this thread.");
-                int maxIndex = c - 1;
-                for (int i = (int)(randomValue % (uint)c); c > 0; i = i < maxIndex ? i + 1 : 0, c--)
-                {
-                    WorkStealingQueue otherQueue = queues[i];
-                    if (otherQueue != localWsq && otherQueue.CanSteal)
-                    {
-                        workItem = otherQueue.TrySteal(ref missedSteal);
-                        if (workItem != null)
-                        {
-                            return workItem;
-                        }
-                    }
-                }
-            }
-            return null;
-        }
-        [MethodImpl(MethodImplOptions.NoInlining)]
-        private bool TryStartProcessingHighPriorityWorkItemsAndDequeue(
-            ThreadPoolWorkQueueThreadLocals tl,
-            [MaybeNullWhen(false)] out object workItem)
-        {
-            Debug.Assert(!tl.isProcessingHighPriorityWorkItems);
-            if (!highPriorityWorkItems.TryDequeue(out workItem))
-            {
-                return false;
-            }
-            tl.isProcessingHighPriorityWorkItems = true;
-            _mayHaveHighPriorityWorkItems = true;
-            return true;
-        }
-        public static long LocalCount
-        {
-            get
-            {
-                long count = 0;
-                foreach (WorkStealingQueue workStealingQueue in WorkStealingQueueList.Queues)
-                {
-                    count += workStealingQueue.Count;
-                }
-                return count;
-            }
-        }
-        public long GlobalCount
-        {
-            get
-            {
-                long count = (long)highPriorityWorkItems.Count + workItems.Count;
-#if CORECLR
-                if (s_prioritizationExperiment)
-                {
-                    count += lowPriorityWorkItems.Count;
-                }
-#endif
-                for (int i = 0; i < s_assignableWorkItemQueueCount; i++)
-                {
-                    count += _assignableWorkItemQueues[i].Count;
-                }
-                return count;
-            }
-        }
-        public const uint DispatchQuantumMs = 30;
-        private static object? DequeueWithPriorityAlternation(ThreadPoolWorkQueue workQueue, ThreadPoolWorkQueueThreadLocals tl, out bool missedSteal)
-        {
-            object? workItem = null;
-            bool dispatchNormalPriorityWorkFirst = workQueue._dispatchNormalPriorityWorkFirst;
-            if (dispatchNormalPriorityWorkFirst && !tl.workStealingQueue.CanSteal)
-            {
-                workQueue._dispatchNormalPriorityWorkFirst = !dispatchNormalPriorityWorkFirst;
-                ConcurrentQueue<object> queue =
-                    s_assignableWorkItemQueueCount > 0 ? tl.assignedGlobalWorkItemQueue : workQueue.workItems;
-                if (!queue.TryDequeue(out workItem) && s_assignableWorkItemQueueCount > 0)
-                {
-                    workQueue.workItems.TryDequeue(out workItem);
-                }
-            }
-            missedSteal = false;
-            workItem ??= workQueue.Dequeue(tl, ref missedSteal);
-            return workItem;
-        }
-        internal static bool Dispatch()
-        {
-            ThreadPoolWorkQueue workQueue = ThreadPool.s_workQueue;
-            ThreadPoolWorkQueueThreadLocals tl = workQueue.GetOrCreateThreadLocals();
-            if (s_assignableWorkItemQueueCount > 0)
-            {
-                workQueue.AssignWorkItemQueue(tl);
-            }
-#if !TARGET_WASI
-            Debug.Assert(workQueue._separated.queueProcessingStage == QueueProcessingStage.Scheduled);
-#endif
-            workQueue._separated.queueProcessingStage = QueueProcessingStage.Determining;
-            Interlocked.MemoryBarrier();
-            object? workItem = null;
-            if (workQueue._nextWorkItemToProcess != null)
-            {
-                workItem = Interlocked.Exchange(ref workQueue._nextWorkItemToProcess, null);
-            }
-            if (workItem == null)
-            {
-                while ((workItem = DequeueWithPriorityAlternation(workQueue, tl, out bool missedSteal)) == null)
-                {
-                    if (missedSteal)
-                    {
-                        if (s_assignableWorkItemQueueCount > 0)
-                        {
-                            workQueue.UnassignWorkItemQueue(tl);
-                        }
-                        Debug.Assert(workQueue._separated.queueProcessingStage != QueueProcessingStage.NotScheduled);
-                        workQueue._separated.queueProcessingStage = QueueProcessingStage.Scheduled;
-                        ThreadPool.RequestWorkerThread();
-                        return true;
-                    }
-                    QueueProcessingStage stageBeforeUpdate =
-                        Interlocked.CompareExchange(
-                            ref workQueue._separated.queueProcessingStage,
-                            QueueProcessingStage.NotScheduled,
-                            QueueProcessingStage.Determining);
-                    Debug.Assert(stageBeforeUpdate != QueueProcessingStage.NotScheduled);
-                    if (stageBeforeUpdate == QueueProcessingStage.Determining)
-                    {
-                        if (s_assignableWorkItemQueueCount > 0)
-                        {
-                            workQueue.UnassignWorkItemQueue(tl);
-                        }
-                        return true;
-                    }
-                    workQueue._separated.queueProcessingStage = QueueProcessingStage.Determining;
-                    Interlocked.MemoryBarrier();
-                }
-            }
-            {
-                workQueue._separated.queueProcessingStage = QueueProcessingStage.Determining;
-                Interlocked.MemoryBarrier();
-                object? secondWorkItem = DequeueWithPriorityAlternation(workQueue, tl, out bool missedSteal);
-                if (secondWorkItem != null)
-                {
-                    Debug.Assert(workQueue._nextWorkItemToProcess == null);
-                    workQueue._nextWorkItemToProcess = secondWorkItem;
-                }
-                if (secondWorkItem != null || missedSteal)
-                {
-                    Debug.Assert(workQueue._separated.queueProcessingStage != QueueProcessingStage.NotScheduled);
-                    workQueue._separated.queueProcessingStage = QueueProcessingStage.Scheduled;
-                    ThreadPool.RequestWorkerThread();
-                }
-                else
-                {
-                    QueueProcessingStage stageBeforeUpdate =
-                        Interlocked.CompareExchange(
-                            ref workQueue._separated.queueProcessingStage,
-                            QueueProcessingStage.NotScheduled,
-                            QueueProcessingStage.Determining);
-                    Debug.Assert(stageBeforeUpdate != QueueProcessingStage.NotScheduled);
-                    if (stageBeforeUpdate == QueueProcessingStage.Scheduled)
-                    {
-                        ThreadPool.RequestWorkerThread();
-                    }
-                }
-            }
-            workQueue.RefreshLoggingEnabled();
-            object? threadLocalCompletionCountObject = tl.threadLocalCompletionCountObject;
-            Thread currentThread = tl.currentThread;
-            currentThread._executionContext = null;
-            currentThread._synchronizationContext = null;
-            int startTickCount = Environment.TickCount;
-            while (true)
-            {
-                if (workItem == null)
-                {
-                    bool missedSteal = false;
-                    workItem = workQueue.Dequeue(tl, ref missedSteal);
-                    if (workItem == null)
-                    {
-                        if (s_assignableWorkItemQueueCount > 0)
-                        {
-                            workQueue.UnassignWorkItemQueue(tl);
-                        }
-                        if (missedSteal)
-                        {
-                            workQueue.EnsureThreadRequested();
-                        }
-                        return true;
-                    }
-                }
-                if (workQueue._loggingEnabled && FrameworkEventSource.Log.IsEnabled())
-                {
-                    FrameworkEventSource.Log.ThreadPoolDequeueWorkObject(workItem);
-                }
-#if FEATURE_OBJCMARSHAL
-                if (AutoreleasePool.EnableAutoreleasePool)
-                {
-                    DispatchItemWithAutoreleasePool(workItem, currentThread);
-                }
-                else
-#endif
-#pragma warning disable CS0162 // Unreachable code detected. EnableWorkerTracking may be a constant in some runtimes.
-                if (ThreadPool.EnableWorkerTracking)
-                {
-                    DispatchWorkItemWithWorkerTracking(workItem, currentThread);
-                }
-                else
-                {
-                    DispatchWorkItem(workItem, currentThread);
-                }
-#pragma warning restore CS0162
-                workItem = null;
-                ExecutionContext.ResetThreadPoolThread(currentThread);
-                currentThread.ResetThreadPoolThread();
-                int currentTickCount = Environment.TickCount;
-                if (!ThreadPool.NotifyWorkItemComplete(threadLocalCompletionCountObject!, currentTickCount))
-                {
-                    tl.TransferLocalWork();
-                    tl.isProcessingHighPriorityWorkItems = false;
-                    if (s_assignableWorkItemQueueCount > 0)
-                    {
-                        workQueue.UnassignWorkItemQueue(tl);
-                    }
-                    return false;
-                }
-                if ((uint)(currentTickCount - startTickCount) < DispatchQuantumMs)
-                {
-                    continue;
-                }
-                if (ThreadPool.YieldFromDispatchLoop)
-                {
-                    tl.isProcessingHighPriorityWorkItems = false;
-                    if (s_assignableWorkItemQueueCount > 0)
-                    {
-                        workQueue.UnassignWorkItemQueue(tl);
-                    }
-                    return true;
-                }
-                if (s_assignableWorkItemQueueCount > 0)
-                {
-                    workQueue.TryReassignWorkItemQueue(tl);
-                }
-                startTickCount = currentTickCount;
-                workQueue.RefreshLoggingEnabled();
-            }
-        }
-        [MethodImpl(MethodImplOptions.NoInlining)]
-        private static void DispatchWorkItemWithWorkerTracking(object workItem, Thread currentThread)
-        {
-            Debug.Assert(ThreadPool.EnableWorkerTracking);
-            Debug.Assert(currentThread == Thread.CurrentThread);
-            bool reportedStatus = false;
-            try
-            {
-                ThreadPool.ReportThreadStatus(isWorking: true);
-                reportedStatus = true;
-                DispatchWorkItem(workItem, currentThread);
-            }
-            finally
-            {
-                if (reportedStatus)
-                    ThreadPool.ReportThreadStatus(isWorking: false);
-            }
-        }
-        [MethodImpl(MethodImplOptions.AggressiveInlining)]
-        private static void DispatchWorkItem(object workItem, Thread currentThread)
-        {
-            if (workItem is Task task)
-            {
-                task.ExecuteFromThreadPool(currentThread);
-            }
-            else
-            {
-                Debug.Assert(workItem is IThreadPoolWorkItem);
-                Unsafe.As<IThreadPoolWorkItem>(workItem).Execute();
-            }
-        }
-    }
-    internal sealed class ThreadPoolWorkQueueThreadLocals
-    {
-        [ThreadStatic]
-        public static ThreadPoolWorkQueueThreadLocals? threadLocals;
-        public bool isProcessingHighPriorityWorkItems;
-        public int queueIndex;
-        public ConcurrentQueue<object> assignedGlobalWorkItemQueue;
-        public readonly ThreadPoolWorkQueue workQueue;
-        public readonly ThreadPoolWorkQueue.WorkStealingQueue workStealingQueue;
-        public readonly Thread currentThread;
-        public readonly object? threadLocalCompletionCountObject;
-        public readonly Random.XoshiroImpl random = new Random.XoshiroImpl();
-        public ThreadPoolWorkQueueThreadLocals(ThreadPoolWorkQueue tpq)
-        {
-            assignedGlobalWorkItemQueue = tpq.workItems;
-            workQueue = tpq;
-            workStealingQueue = new ThreadPoolWorkQueue.WorkStealingQueue();
-            ThreadPoolWorkQueue.WorkStealingQueueList.Add(workStealingQueue);
-            currentThread = Thread.CurrentThread;
-            threadLocalCompletionCountObject = ThreadPool.GetOrCreateThreadLocalCompletionCountObject();
-        }
-        public void TransferLocalWork()
-        {
-            while (workStealingQueue.LocalPop() is object cb)
-            {
-                workQueue.Enqueue(cb, forceGlobal: true);
-            }
-        }
-        ~ThreadPoolWorkQueueThreadLocals()
-        {
-            if (null != workStealingQueue)
-            {
-                TransferLocalWork();
-                ThreadPoolWorkQueue.WorkStealingQueueList.Remove(workStealingQueue);
-            }
-        }
-    }
-    internal interface IThreadPoolTypedWorkItemQueueCallback<T>
-    {
-        static abstract void Invoke(T item);
-    }
-    internal sealed class ThreadPoolTypedWorkItemQueue<T, TCallback> : IThreadPoolWorkItem
-        where T : struct
-        where TCallback : struct, IThreadPoolTypedWorkItemQueueCallback<T>
-    {
-        private enum QueueProcessingStage
-        {
-            NotScheduled,
-            Determining,
-            Scheduled
-        }
-        private QueueProcessingStage _queueProcessingStage;
-        private readonly ConcurrentQueue<T> _workItems = new ConcurrentQueue<T>();
-        public int Count => _workItems.Count;
-        public void Enqueue(T workItem)
-        {
-            BatchEnqueue(workItem);
-            CompleteBatchEnqueue();
-        }
-        public void BatchEnqueue(T workItem) => _workItems.Enqueue(workItem);
-        public void CompleteBatchEnqueue()
-        {
-            if (Interlocked.Exchange(
-                ref _queueProcessingStage,
-                QueueProcessingStage.Scheduled) == QueueProcessingStage.NotScheduled)
-            {
-                ThreadPool.UnsafeQueueHighPriorityWorkItemInternal(this);
-            }
-        }
-        private void UpdateQueueProcessingStage(bool isQueueEmpty)
-        {
-            if (!isQueueEmpty)
-            {
-                _queueProcessingStage = QueueProcessingStage.Scheduled;
-            }
-            else
-            {
-                QueueProcessingStage stageBeforeUpdate =
-                    Interlocked.CompareExchange(
-                        ref _queueProcessingStage,
-                        QueueProcessingStage.NotScheduled,
-                        QueueProcessingStage.Determining);
-                Debug.Assert(stageBeforeUpdate != QueueProcessingStage.NotScheduled);
-                if (stageBeforeUpdate == QueueProcessingStage.Determining)
-                {
-                    return;
-                }
-            }
-            ThreadPool.UnsafeQueueHighPriorityWorkItemInternal(this);
-        }
-        void IThreadPoolWorkItem.Execute()
-        {
-            T workItem;
-            while (true)
-            {
-                Debug.Assert(_queueProcessingStage == QueueProcessingStage.Scheduled);
-                _queueProcessingStage = QueueProcessingStage.Determining;
-                Interlocked.MemoryBarrier();
-                if (_workItems.TryDequeue(out workItem))
-                {
-                    break;
-                }
-                QueueProcessingStage stageBeforeUpdate =
-                    Interlocked.CompareExchange(
-                        ref _queueProcessingStage,
-                        QueueProcessingStage.NotScheduled,
-                        QueueProcessingStage.Determining);
-                Debug.Assert(stageBeforeUpdate != QueueProcessingStage.NotScheduled);
-                if (stageBeforeUpdate == QueueProcessingStage.Determining)
-                {
-                    return;
-                }
-            }
-            UpdateQueueProcessingStage(_workItems.IsEmpty);
-            ThreadPoolWorkQueueThreadLocals tl = ThreadPoolWorkQueueThreadLocals.threadLocals!;
-            Debug.Assert(tl != null);
-            Thread currentThread = tl.currentThread;
-            Debug.Assert(currentThread == Thread.CurrentThread);
-            uint completedCount = 0;
-            int startTimeMs = Environment.TickCount;
-            while (true)
-            {
-                TCallback.Invoke(workItem);
-                if (++completedCount == uint.MaxValue ||
-                    tl.workStealingQueue.CanSteal ||
-                    (uint)(Environment.TickCount - startTimeMs) >= ThreadPoolWorkQueue.DispatchQuantumMs / 2 ||
-                    !_workItems.TryDequeue(out workItem))
-                {
-                    break;
-                }
-                ExecutionContext.ResetThreadPoolThread(currentThread);
-                currentThread.ResetThreadPoolThread();
-            }
-            ThreadInt64PersistentCounter.Add(tl.threadLocalCompletionCountObject!, completedCount);
-        }
-    }
-    public delegate void WaitCallback(object? state);
-    public delegate void WaitOrTimerCallback(object? state, bool timedOut);  // signaled or timed out
-    internal abstract class QueueUserWorkItemCallbackBase : IThreadPoolWorkItem
-    {
-#if DEBUG
-        private bool _executed;
-        ~QueueUserWorkItemCallbackBase()
-        {
-            Interlocked.MemoryBarrier(); // ensure that an old cached value is not read below
-            Debug.Assert(_executed, "A QueueUserWorkItemCallback was never called!");
-        }
-#endif
-        public virtual void Execute()
-        {
-#if DEBUG
-            GC.SuppressFinalize(this);
-            Debug.Assert(!Interlocked.Exchange(ref _executed, true), "A QueueUserWorkItemCallback was called twice!");
-#endif
-        }
-    }
-    internal sealed class QueueUserWorkItemCallback : QueueUserWorkItemCallbackBase
-    {
-        private WaitCallback? _callback; // SOS's ThreadPool command depends on this name
-        private readonly object? _state;
-        private readonly ExecutionContext _context;
-        private static readonly Action<QueueUserWorkItemCallback> s_executionContextShim = quwi =>
-        {
-            Debug.Assert(quwi._callback != null);
-            WaitCallback callback = quwi._callback;
-            quwi._callback = null;
-            callback(quwi._state);
-        };
-        internal QueueUserWorkItemCallback(WaitCallback callback, object? state, ExecutionContext context)
-        {
-            Debug.Assert(context != null);
-            _callback = callback;
-            _state = state;
-            _context = context;
-        }
-        public override void Execute()
-        {
-            base.Execute();
-            ExecutionContext.RunForThreadPoolUnsafe(_context, s_executionContextShim, this);
-        }
-    }
-    internal sealed class QueueUserWorkItemCallback<TState> : QueueUserWorkItemCallbackBase
-    {
-        private Action<TState>? _callback; // SOS's ThreadPool command depends on this name
-        private readonly TState _state;
-        private readonly ExecutionContext _context;
-        internal QueueUserWorkItemCallback(Action<TState> callback, TState state, ExecutionContext context)
-        {
-            Debug.Assert(callback != null);
-            _callback = callback;
-            _state = state;
-            _context = context;
-        }
-        public override void Execute()
-        {
-            base.Execute();
-            Debug.Assert(_callback != null);
-            Action<TState> callback = _callback;
-            _callback = null;
-            ExecutionContext.RunForThreadPoolUnsafe(_context, callback, in _state);
-        }
-    }
-    internal sealed class QueueUserWorkItemCallbackDefaultContext : QueueUserWorkItemCallbackBase
-    {
-        private WaitCallback? _callback; // SOS's ThreadPool command depends on this name
-        private readonly object? _state;
-        internal QueueUserWorkItemCallbackDefaultContext(WaitCallback callback, object? state)
-        {
-            Debug.Assert(callback != null);
-            _callback = callback;
-            _state = state;
-        }
-        public override void Execute()
-        {
-            ExecutionContext.CheckThreadPoolAndContextsAreDefault();
-            base.Execute();
-            Debug.Assert(_callback != null);
-            WaitCallback callback = _callback;
-            _callback = null;
-            callback(_state);
-        }
-    }
-    internal sealed class QueueUserWorkItemCallbackDefaultContext<TState> : QueueUserWorkItemCallbackBase
-    {
-        private Action<TState>? _callback; // SOS's ThreadPool command depends on this name
-        private readonly TState _state;
-        internal QueueUserWorkItemCallbackDefaultContext(Action<TState> callback, TState state)
-        {
-            Debug.Assert(callback != null);
-            _callback = callback;
-            _state = state;
-        }
-        public override void Execute()
-        {
-            ExecutionContext.CheckThreadPoolAndContextsAreDefault();
-            base.Execute();
-            Debug.Assert(_callback != null);
-            Action<TState> callback = _callback;
-            _callback = null;
-            callback(_state);
-        }
-    }
-    internal sealed class _ThreadPoolWaitOrTimerCallback
-    {
-        private readonly WaitOrTimerCallback _waitOrTimerCallback;
-        private readonly ExecutionContext? _executionContext;
-        private readonly object? _state;
-        private static readonly ContextCallback _ccbt = new ContextCallback(WaitOrTimerCallback_Context_t);
-        private static readonly ContextCallback _ccbf = new ContextCallback(WaitOrTimerCallback_Context_f);
-        internal _ThreadPoolWaitOrTimerCallback(WaitOrTimerCallback waitOrTimerCallback, object? state, bool flowExecutionContext)
-        {
-            _waitOrTimerCallback = waitOrTimerCallback;
-            _state = state;
-            if (flowExecutionContext)
-            {
-                _executionContext = ExecutionContext.Capture();
-            }
-        }
-        private static void WaitOrTimerCallback_Context_t(object? state) =>
-            WaitOrTimerCallback_Context(state, timedOut: true);
-        private static void WaitOrTimerCallback_Context_f(object? state) =>
-            WaitOrTimerCallback_Context(state, timedOut: false);
-        private static void WaitOrTimerCallback_Context(object? state, bool timedOut)
-        {
-            _ThreadPoolWaitOrTimerCallback helper = (_ThreadPoolWaitOrTimerCallback)state!;
-            helper._waitOrTimerCallback(helper._state, timedOut);
-        }
-        internal static void PerformWaitOrTimerCallback(_ThreadPoolWaitOrTimerCallback helper, bool timedOut)
-        {
-            Debug.Assert(helper != null, "Null state passed to PerformWaitOrTimerCallback!");
-            ExecutionContext? context = helper._executionContext;
-            if (context == null)
-            {
-                WaitOrTimerCallback callback = helper._waitOrTimerCallback;
-                callback(helper._state, timedOut);
-            }
-            else
-            {
-                ExecutionContext.Run(context, timedOut ? _ccbt : _ccbf, helper);
-            }
-        }
-    }
-    public static partial class ThreadPool
-    {
-        internal const string WorkerThreadName = ".NET TP Worker";
-        internal static readonly ThreadPoolWorkQueue s_workQueue = new ThreadPoolWorkQueue();
-        internal static readonly Action<object?> s_invokeAsyncStateMachineBox = static state =>
-        {
-            if (state is IAsyncStateMachineBox box)
-            {
-                box.MoveNext();
-            }
-            else
-            {
-                ThrowHelper.ThrowUnexpectedStateForKnownCallback(state);
-            }
-        };
-        internal static bool EnableWorkerTracking => IsWorkerTrackingEnabledInConfig && EventSource.IsSupported;
-#if !FEATURE_WASM_MANAGED_THREADS
-        [UnsupportedOSPlatform("browser")]
-#endif
-        [CLSCompliant(false)]
-        public static RegisteredWaitHandle RegisterWaitForSingleObject(
-             WaitHandle waitObject,
-             WaitOrTimerCallback callBack,
-             object? state,
-             uint millisecondsTimeOutInterval,
-             bool executeOnlyOnce    // NOTE: we do not allow other options that allow the callback to be queued as an APC
-             )
-        {
-            if (millisecondsTimeOutInterval > (uint)int.MaxValue && millisecondsTimeOutInterval != uint.MaxValue)
-                throw new ArgumentOutOfRangeException(nameof(millisecondsTimeOutInterval), SR.ArgumentOutOfRange_LessEqualToIntegerMaxVal);
-            return RegisterWaitForSingleObject(waitObject, callBack, state, millisecondsTimeOutInterval, executeOnlyOnce, true);
-        }
-#if !FEATURE_WASM_MANAGED_THREADS
-        [UnsupportedOSPlatform("browser")]
-#endif
-        [CLSCompliant(false)]
-        public static RegisteredWaitHandle UnsafeRegisterWaitForSingleObject(
-             WaitHandle waitObject,
-             WaitOrTimerCallback callBack,
-             object? state,
-             uint millisecondsTimeOutInterval,
-             bool executeOnlyOnce    // NOTE: we do not allow other options that allow the callback to be queued as an APC
-             )
-        {
-            if (millisecondsTimeOutInterval > (uint)int.MaxValue && millisecondsTimeOutInterval != uint.MaxValue)
-                throw new ArgumentOutOfRangeException(nameof(millisecondsTimeOutInterval), SR.ArgumentOutOfRange_NeedNonNegOrNegative1);
-            return RegisterWaitForSingleObject(waitObject, callBack, state, millisecondsTimeOutInterval, executeOnlyOnce, false);
-        }
-#if !FEATURE_WASM_MANAGED_THREADS
-        [UnsupportedOSPlatform("browser")]
-#endif
-        public static RegisteredWaitHandle RegisterWaitForSingleObject(
-             WaitHandle waitObject,
-             WaitOrTimerCallback callBack,
-             object? state,
-             int millisecondsTimeOutInterval,
-             bool executeOnlyOnce    // NOTE: we do not allow other options that allow the callback to be queued as an APC
-             )
-        {
-            ArgumentOutOfRangeException.ThrowIfLessThan(millisecondsTimeOutInterval, -1);
-            return RegisterWaitForSingleObject(waitObject, callBack, state, (uint)millisecondsTimeOutInterval, executeOnlyOnce, true);
-        }
-#if !FEATURE_WASM_MANAGED_THREADS
-        [UnsupportedOSPlatform("browser")]
-#endif
-        public static RegisteredWaitHandle UnsafeRegisterWaitForSingleObject(
-             WaitHandle waitObject,
-             WaitOrTimerCallback callBack,
-             object? state,
-             int millisecondsTimeOutInterval,
-             bool executeOnlyOnce    // NOTE: we do not allow other options that allow the callback to be queued as an APC
-             )
-        {
-            ArgumentOutOfRangeException.ThrowIfLessThan(millisecondsTimeOutInterval, -1);
-            return RegisterWaitForSingleObject(waitObject, callBack, state, (uint)millisecondsTimeOutInterval, executeOnlyOnce, false);
-        }
-#if !FEATURE_WASM_MANAGED_THREADS
-        [UnsupportedOSPlatform("browser")]
-#endif
-        public static RegisteredWaitHandle RegisterWaitForSingleObject(
-            WaitHandle waitObject,
-            WaitOrTimerCallback callBack,
-            object? state,
-            long millisecondsTimeOutInterval,
-            bool executeOnlyOnce    // NOTE: we do not allow other options that allow the callback to be queued as an APC
-        )
-        {
-            ArgumentOutOfRangeException.ThrowIfLessThan(millisecondsTimeOutInterval, -1);
-            ArgumentOutOfRangeException.ThrowIfGreaterThan(millisecondsTimeOutInterval, int.MaxValue);
-            return RegisterWaitForSingleObject(waitObject, callBack, state, (uint)millisecondsTimeOutInterval, executeOnlyOnce, true);
-        }
-#if !FEATURE_WASM_MANAGED_THREADS
-        [UnsupportedOSPlatform("browser")]
-#endif
-        public static RegisteredWaitHandle UnsafeRegisterWaitForSingleObject(
-            WaitHandle waitObject,
-            WaitOrTimerCallback callBack,
-            object? state,
-            long millisecondsTimeOutInterval,
-            bool executeOnlyOnce    // NOTE: we do not allow other options that allow the callback to be queued as an APC
-        )
-        {
-            ArgumentOutOfRangeException.ThrowIfLessThan(millisecondsTimeOutInterval, -1);
-            ArgumentOutOfRangeException.ThrowIfGreaterThan(millisecondsTimeOutInterval, int.MaxValue);
-            return RegisterWaitForSingleObject(waitObject, callBack, state, (uint)millisecondsTimeOutInterval, executeOnlyOnce, false);
-        }
-#if !FEATURE_WASM_MANAGED_THREADS
-        [UnsupportedOSPlatform("browser")]
-#endif
-        public static RegisteredWaitHandle RegisterWaitForSingleObject(
-                          WaitHandle waitObject,
-                          WaitOrTimerCallback callBack,
-                          object? state,
-                          TimeSpan timeout,
-                          bool executeOnlyOnce
-                          )
-        {
-            long tm = (long)timeout.TotalMilliseconds;
-            ArgumentOutOfRangeException.ThrowIfLessThan(tm, -1, nameof(timeout));
-            ArgumentOutOfRangeException.ThrowIfGreaterThan(tm, int.MaxValue, nameof(timeout));
-            return RegisterWaitForSingleObject(waitObject, callBack, state, (uint)tm, executeOnlyOnce, true);
-        }
-#if !FEATURE_WASM_MANAGED_THREADS
-        [UnsupportedOSPlatform("browser")]
-#endif
-        public static RegisteredWaitHandle UnsafeRegisterWaitForSingleObject(
-                          WaitHandle waitObject,
-                          WaitOrTimerCallback callBack,
-                          object? state,
-                          TimeSpan timeout,
-                          bool executeOnlyOnce
-                          )
-        {
-            long tm = (long)timeout.TotalMilliseconds;
-            ArgumentOutOfRangeException.ThrowIfLessThan(tm, -1, nameof(timeout));
-            ArgumentOutOfRangeException.ThrowIfGreaterThan(tm, int.MaxValue, nameof(timeout));
-            return RegisterWaitForSingleObject(waitObject, callBack, state, (uint)tm, executeOnlyOnce, false);
-        }
-        public static bool QueueUserWorkItem(WaitCallback callBack) =>
-            QueueUserWorkItem(callBack, null);
-        public static bool QueueUserWorkItem(WaitCallback callBack, object? state)
-        {
-            if (callBack == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.callBack);
-            }
-            ExecutionContext? context = ExecutionContext.Capture();
-            object tpcallBack = (context == null || context.IsDefault) ?
-                new QueueUserWorkItemCallbackDefaultContext(callBack!, state) :
-                (object)new QueueUserWorkItemCallback(callBack!, state, context);
-            s_workQueue.Enqueue(tpcallBack, forceGlobal: true);
-            return true;
-        }
-        public static bool QueueUserWorkItem<TState>(Action<TState> callBack, TState state, bool preferLocal)
-        {
-            if (callBack == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.callBack);
-            }
-            ExecutionContext? context = ExecutionContext.Capture();
-            object tpcallBack = (context == null || context.IsDefault) ?
-                new QueueUserWorkItemCallbackDefaultContext<TState>(callBack!, state) :
-                (object)new QueueUserWorkItemCallback<TState>(callBack!, state, context);
-            s_workQueue.Enqueue(tpcallBack, forceGlobal: !preferLocal);
-            return true;
-        }
-        public static bool UnsafeQueueUserWorkItem<TState>(Action<TState> callBack, TState state, bool preferLocal)
-        {
-            if (callBack == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.callBack);
-            }
-            if (ReferenceEquals(callBack, s_invokeAsyncStateMachineBox))
-            {
-                if (state is not IAsyncStateMachineBox)
-                {
-                    ThrowHelper.ThrowUnexpectedStateForKnownCallback(state);
-                }
-                UnsafeQueueUserWorkItemInternal((object)state!, preferLocal);
-                return true;
-            }
-            s_workQueue.Enqueue(
-                new QueueUserWorkItemCallbackDefaultContext<TState>(callBack!, state), forceGlobal: !preferLocal);
-            return true;
-        }
-        public static bool UnsafeQueueUserWorkItem(WaitCallback callBack, object? state)
-        {
-            if (callBack == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.callBack);
-            }
-            object tpcallBack = new QueueUserWorkItemCallbackDefaultContext(callBack!, state);
-            s_workQueue.Enqueue(tpcallBack, forceGlobal: true);
-            return true;
-        }
-        public static bool UnsafeQueueUserWorkItem(IThreadPoolWorkItem callBack, bool preferLocal)
-        {
-            if (callBack == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(ExceptionArgument.callBack);
-            }
-            if (callBack is Task)
-            {
-                ThrowHelper.ThrowArgumentOutOfRangeException(ExceptionArgument.callBack);
-            }
-            UnsafeQueueUserWorkItemInternal(callBack!, preferLocal);
-            return true;
-        }
-        internal static void UnsafeQueueUserWorkItemInternal(object callBack, bool preferLocal) =>
-            s_workQueue.Enqueue(callBack, forceGlobal: !preferLocal);
-        internal static void UnsafeQueueHighPriorityWorkItemInternal(IThreadPoolWorkItem callBack) =>
-            s_workQueue.EnqueueAtHighPriority(callBack);
-        internal static bool TryPopCustomWorkItem(object workItem)
-        {
-            Debug.Assert(null != workItem);
-            return ThreadPoolWorkQueue.LocalFindAndPop(workItem);
-        }
-        internal static IEnumerable<object> GetQueuedWorkItems()
-        {
-            foreach (object workItem in s_workQueue.highPriorityWorkItems)
-            {
-                yield return workItem;
-            }
-            foreach (ConcurrentQueue<object> queue in s_workQueue._assignableWorkItemQueues)
-            {
-                foreach (object workItem in queue)
-                {
-                    yield return workItem;
-                }
-            }
-            foreach (object workItem in s_workQueue.workItems)
-            {
-                yield return workItem;
-            }
-#if CORECLR
-            if (ThreadPoolWorkQueue.s_prioritizationExperiment)
-            {
-                foreach (object workItem in s_workQueue.lowPriorityWorkItems)
-                {
-                    yield return workItem;
-                }
-            }
-#endif
-            foreach (ThreadPoolWorkQueue.WorkStealingQueue wsq in ThreadPoolWorkQueue.WorkStealingQueueList.Queues)
-            {
-                if (wsq != null && wsq.m_array != null)
-                {
-                    object?[] items = wsq.m_array;
-                    for (int i = 0; i < items.Length; i++)
-                    {
-                        object? item = items[i];
-                        if (item != null)
-                        {
-                            yield return item;
-                        }
-                    }
-                }
-            }
-        }
-        public static long PendingWorkItemCount
-        {
-            get
-            {
-                ThreadPoolWorkQueue workQueue = s_workQueue;
-                return ThreadPoolWorkQueue.LocalCount + workQueue.GlobalCount;
-            }
-        }
-    }
-}

--- a/src/libraries/System.Runtime.Numerics/src/System/Numerics/BigInteger.cs
+++ b//dev/null
@@ -1,4096 +0,0 @@
-using System.Buffers;
-using System.Buffers.Binary;
-using System.Diagnostics;
-using System.Diagnostics.CodeAnalysis;
-using System.Globalization;
-using System.Runtime.CompilerServices;
-using System.Runtime.InteropServices;
-namespace System.Numerics
-{
-    [Serializable]
-    [TypeForwardedFrom("System.Numerics, Version=4.0.0.0, PublicKeyToken=b77a5c561934e089")]
-    [DebuggerDisplay("{DebuggerDisplay,nq}")]
-    public readonly struct BigInteger
-        : ISpanFormattable,
-          IComparable,
-          IComparable<BigInteger>,
-          IEquatable<BigInteger>,
-          IBinaryInteger<BigInteger>,
-          ISignedNumber<BigInteger>
-    {
-        internal const uint kuMaskHighBit = unchecked((uint)int.MinValue);
-        internal const int kcbitUint = 32;
-        internal const int kcbitUlong = 64;
-        internal const int DecimalScaleFactorMask = 0x00FF0000;
-        internal static int MaxLength => Array.MaxLength / kcbitUint;
-        internal readonly int _sign; // Do not rename (binary serialization)
-        internal readonly uint[]? _bits; // Do not rename (binary serialization)
-        private static readonly BigInteger s_bnMinInt = new BigInteger(-1, new uint[] { kuMaskHighBit });
-        private static readonly BigInteger s_bnOneInt = new BigInteger(1);
-        private static readonly BigInteger s_bnZeroInt = new BigInteger(0);
-        private static readonly BigInteger s_bnMinusOneInt = new BigInteger(-1);
-        public BigInteger(int value)
-        {
-            if (value == int.MinValue)
-                this = s_bnMinInt;
-            else
-            {
-                _sign = value;
-                _bits = null;
-            }
-            AssertValid();
-        }
-        [CLSCompliant(false)]
-        public BigInteger(uint value)
-        {
-            if (value <= int.MaxValue)
-            {
-                _sign = (int)value;
-                _bits = null;
-            }
-            else
-            {
-                _sign = +1;
-                _bits = new uint[1];
-                _bits[0] = value;
-            }
-            AssertValid();
-        }
-        public BigInteger(long value)
-        {
-            if (int.MinValue < value && value <= int.MaxValue)
-            {
-                _sign = (int)value;
-                _bits = null;
-            }
-            else if (value == int.MinValue)
-            {
-                this = s_bnMinInt;
-            }
-            else
-            {
-                ulong x;
-                if (value < 0)
-                {
-                    x = unchecked((ulong)-value);
-                    _sign = -1;
-                }
-                else
-                {
-                    x = (ulong)value;
-                    _sign = +1;
-                }
-                if (x <= uint.MaxValue)
-                {
-                    _bits = new uint[1];
-                    _bits[0] = (uint)x;
-                }
-                else
-                {
-                    _bits = new uint[2];
-                    _bits[0] = unchecked((uint)x);
-                    _bits[1] = (uint)(x >> kcbitUint);
-                }
-            }
-            AssertValid();
-        }
-        [CLSCompliant(false)]
-        public BigInteger(ulong value)
-        {
-            if (value <= int.MaxValue)
-            {
-                _sign = (int)value;
-                _bits = null;
-            }
-            else if (value <= uint.MaxValue)
-            {
-                _sign = +1;
-                _bits = new uint[1];
-                _bits[0] = (uint)value;
-            }
-            else
-            {
-                _sign = +1;
-                _bits = new uint[2];
-                _bits[0] = unchecked((uint)value);
-                _bits[1] = (uint)(value >> kcbitUint);
-            }
-            AssertValid();
-        }
-        public BigInteger(float value) : this((double)value)
-        {
-        }
-        public BigInteger(double value)
-        {
-            if (!double.IsFinite(value))
-            {
-                if (double.IsInfinity(value))
-                {
-                    throw new OverflowException(SR.Overflow_BigIntInfinity);
-                }
-                else // NaN
-                {
-                    throw new OverflowException(SR.Overflow_NotANumber);
-                }
-            }
-            _sign = 0;
-            _bits = null;
-            int sign, exp;
-            ulong man;
-            NumericsHelpers.GetDoubleParts(value, out sign, out exp, out man, out _);
-            Debug.Assert(sign == +1 || sign == -1);
-            if (man == 0)
-            {
-                this = Zero;
-                return;
-            }
-            Debug.Assert(man < (1UL << 53));
-            Debug.Assert(exp <= 0 || man >= (1UL << 52));
-            if (exp <= 0)
-            {
-                if (exp <= -kcbitUlong)
-                {
-                    this = Zero;
-                    return;
-                }
-                this = man >> -exp;
-                if (sign < 0)
-                    _sign = -_sign;
-            }
-            else if (exp <= 11)
-            {
-                this = man << exp;
-                if (sign < 0)
-                    _sign = -_sign;
-            }
-            else
-            {
-                man <<= 11;
-                exp -= 11;
-                int cu = (exp - 1) / kcbitUint + 1;
-                int cbit = cu * kcbitUint - exp;
-                Debug.Assert(0 <= cbit && cbit < kcbitUint);
-                Debug.Assert(cu >= 1);
-                _bits = new uint[cu + 2];
-                _bits[cu + 1] = (uint)(man >> (cbit + kcbitUint));
-                _bits[cu] = unchecked((uint)(man >> cbit));
-                if (cbit > 0)
-                    _bits[cu - 1] = unchecked((uint)man) << (kcbitUint - cbit);
-                _sign = sign;
-            }
-            AssertValid();
-        }
-        public BigInteger(decimal value)
-        {
-            Span<int> bits = stackalloc int[4];
-            decimal.GetBits(decimal.Truncate(value), bits);
-            Debug.Assert(bits.Length == 4 && (bits[3] & DecimalScaleFactorMask) == 0);
-            const int signMask = unchecked((int)kuMaskHighBit);
-            int size = 3;
-            while (size > 0 && bits[size - 1] == 0)
-                size--;
-            if (size == 0)
-            {
-                this = s_bnZeroInt;
-            }
-            else if (size == 1 && bits[0] > 0)
-            {
-                _sign = bits[0];
-                _sign *= ((bits[3] & signMask) != 0) ? -1 : +1;
-                _bits = null;
-            }
-            else
-            {
-                _bits = new uint[size];
-                unchecked
-                {
-                    _bits[0] = (uint)bits[0];
-                    if (size > 1)
-                        _bits[1] = (uint)bits[1];
-                    if (size > 2)
-                        _bits[2] = (uint)bits[2];
-                }
-                _sign = ((bits[3] & signMask) != 0) ? -1 : +1;
-            }
-            AssertValid();
-        }
-        [CLSCompliant(false)]
-        public BigInteger(byte[] value) :
-            this(new ReadOnlySpan<byte>(value ?? throw new ArgumentNullException(nameof(value))))
-        {
-        }
-        public BigInteger(ReadOnlySpan<byte> value, bool isUnsigned = false, bool isBigEndian = false)
-        {
-            int byteCount = value.Length;
-            bool isNegative;
-            if (byteCount > 0)
-            {
-                byte mostSignificantByte = isBigEndian ? value[0] : value[byteCount - 1];
-                isNegative = (mostSignificantByte & 0x80) != 0 && !isUnsigned;
-                if (mostSignificantByte == 0)
-                {
-                    if (isBigEndian)
-                    {
-                        int offset = 1;
-                        while (offset < byteCount && value[offset] == 0)
-                        {
-                            offset++;
-                        }
-                        value = value.Slice(offset);
-                        byteCount = value.Length;
-                    }
-                    else
-                    {
-                        byteCount -= 2;
-                        while (byteCount >= 0 && value[byteCount] == 0)
-                        {
-                            byteCount--;
-                        }
-                        byteCount++;
-                    }
-                }
-            }
-            else
-            {
-                isNegative = false;
-            }
-            if (byteCount == 0)
-            {
-                _sign = 0;
-                _bits = null;
-                AssertValid();
-                return;
-            }
-            if (byteCount <= 4)
-            {
-                _sign = isNegative ? unchecked((int)0xffffffff) : 0;
-                if (isBigEndian)
-                {
-                    for (int i = 0; i < byteCount; i++)
-                    {
-                        _sign = (_sign << 8) | value[i];
-                    }
-                }
-                else
-                {
-                    for (int i = byteCount - 1; i >= 0; i--)
-                    {
-                        _sign = (_sign << 8) | value[i];
-                    }
-                }
-                _bits = null;
-                if (_sign < 0 && !isNegative)
-                {
-                    _bits = new uint[1] { unchecked((uint)_sign) };
-                    _sign = +1;
-                }
-                if (_sign == int.MinValue)
-                {
-                    this = s_bnMinInt;
-                }
-            }
-            else
-            {
-                int wholeUInt32Count = Math.DivRem(byteCount, 4, out int unalignedBytes);
-                uint[] val = new uint[wholeUInt32Count + (unalignedBytes == 0 ? 0 : 1)];
-                if (isBigEndian)
-                {
-                    Span<byte> uintBytes = MemoryMarshal.AsBytes(val.AsSpan(0, wholeUInt32Count));
-                    value.Slice(unalignedBytes).CopyTo(uintBytes);
-                    uintBytes.Reverse();
-                }
-                else
-                {
-                    value.Slice(0, wholeUInt32Count * 4).CopyTo(MemoryMarshal.AsBytes<uint>(val));
-                }
-                if (!BitConverter.IsLittleEndian)
-                {
-                    BinaryPrimitives.ReverseEndianness(val.AsSpan(0, wholeUInt32Count), val);
-                }
-                if (unalignedBytes != 0)
-                {
-                    if (isNegative)
-                    {
-                        val[wholeUInt32Count] = 0xffffffff;
-                    }
-                    if (isBigEndian)
-                    {
-                        for (int curByte = 0; curByte < unalignedBytes; curByte++)
-                        {
-                            byte curByteValue = value[curByte];
-                            val[wholeUInt32Count] = (val[wholeUInt32Count] << 8) | curByteValue;
-                        }
-                    }
-                    else
-                    {
-                        for (int curByte = byteCount - 1; curByte >= byteCount - unalignedBytes; curByte--)
-                        {
-                            byte curByteValue = value[curByte];
-                            val[wholeUInt32Count] = (val[wholeUInt32Count] << 8) | curByteValue;
-                        }
-                    }
-                }
-                if (isNegative)
-                {
-                    NumericsHelpers.DangerousMakeTwosComplement(val); // Mutates val
-                    int len = val.Length - 1;
-                    while (len >= 0 && val[len] == 0) len--;
-                    len++;
-                    if (len == 1)
-                    {
-                        switch (val[0])
-                        {
-                            case 1: // abs(-1)
-                                this = s_bnMinusOneInt;
-                                return;
-                            case kuMaskHighBit: // abs(Int32.MinValue)
-                                this = s_bnMinInt;
-                                return;
-                            default:
-                                if (unchecked((int)val[0]) > 0)
-                                {
-                                    _sign = (-1) * ((int)val[0]);
-                                    _bits = null;
-                                    AssertValid();
-                                    return;
-                                }
-                                break;
-                        }
-                    }
-                    if (len != val.Length)
-                    {
-                        _sign = -1;
-                        _bits = new uint[len];
-                        Array.Copy(val, _bits, len);
-                    }
-                    else
-                    {
-                        _sign = -1;
-                        _bits = val;
-                    }
-                }
-                else
-                {
-                    _sign = +1;
-                    _bits = val;
-                }
-            }
-            AssertValid();
-        }
-        internal BigInteger(int n, uint[]? rgu)
-        {
-            if ((rgu is not null) && (rgu.Length > MaxLength))
-            {
-                ThrowHelper.ThrowOverflowException();
-            }
-            _sign = n;
-            _bits = rgu;
-            AssertValid();
-        }
-        internal BigInteger(ReadOnlySpan<uint> value, bool negative)
-        {
-            int length = value.LastIndexOfAnyExcept(0u) + 1;
-            value = value[..length];
-            if (value.Length > MaxLength)
-            {
-                ThrowHelper.ThrowOverflowException();
-            }
-            if (value.Length == 0)
-            {
-                this = default;
-            }
-            else if (value.Length == 1 && value[0] < kuMaskHighBit)
-            {
-                _sign = negative ? -(int)value[0] : (int)value[0];
-                _bits = null;
-                if (_sign == int.MinValue)
-                {
-                    this = s_bnMinInt;
-                }
-            }
-            else
-            {
-                _sign = negative ? -1 : +1;
-                _bits = value.ToArray();
-            }
-            AssertValid();
-        }
-        private BigInteger(Span<uint> value)
-        {
-            bool isNegative;
-            int length;
-            if ((value.Length > 0) && ((int)value[^1] < 0))
-            {
-                isNegative = true;
-                length = value.LastIndexOfAnyExcept(uint.MaxValue) + 1;
-                if ((length == 0) || ((int)value[length - 1] >= 0))
-                {
-                    length++;
-                }
-                Debug.Assert((int)value[length - 1] < 0);
-            }
-            else
-            {
-                isNegative = false;
-                length = value.LastIndexOfAnyExcept(0u) + 1;
-            }
-            value = value[..length];
-            if (value.Length > MaxLength)
-            {
-                ThrowHelper.ThrowOverflowException();
-            }
-            if (value.Length == 0)
-            {
-                this = s_bnZeroInt;
-            }
-            else if (value.Length == 1)
-            {
-                if (isNegative)
-                {
-                    if (value[0] == uint.MaxValue)
-                    {
-                        this = s_bnMinusOneInt;
-                    }
-                    else if (value[0] == kuMaskHighBit)
-                    {
-                        this = s_bnMinInt;
-                    }
-                    else
-                    {
-                        _sign = unchecked((int)value[0]);
-                        _bits = null;
-                    }
-                }
-                else if (unchecked((int)value[0]) < 0)
-                {
-                    _sign = +1;
-                    _bits = [value[0]];
-                }
-                else
-                {
-                    _sign = unchecked((int)value[0]);
-                    _bits = null;
-                }
-            }
-            else
-            {
-                if (isNegative)
-                {
-                    NumericsHelpers.DangerousMakeTwosComplement(value);
-                    length = value.LastIndexOfAnyExcept(0u) + 1;
-                    value = value[..length];
-                    _sign = -1;
-                }
-                else
-                {
-                    _sign = +1;
-                }
-                _bits = value.ToArray();
-            }
-            AssertValid();
-        }
-        public static BigInteger Zero { get { return s_bnZeroInt; } }
-        public static BigInteger One { get { return s_bnOneInt; } }
-        public static BigInteger MinusOne { get { return s_bnMinusOneInt; } }
-        public bool IsPowerOfTwo
-        {
-            get
-            {
-                AssertValid();
-                if (_bits == null)
-                    return BitOperations.IsPow2(_sign);
-                if (_sign != 1)
-                    return false;
-                int iu = _bits.Length - 1;
-                return BitOperations.IsPow2(_bits[iu]) && !_bits.AsSpan(0, iu).ContainsAnyExcept(0u);
-            }
-        }
-        public bool IsZero { get { AssertValid(); return _sign == 0; } }
-        public bool IsOne { get { AssertValid(); return _sign == 1 && _bits == null; } }
-        public bool IsEven { get { AssertValid(); return _bits == null ? (_sign & 1) == 0 : (_bits[0] & 1) == 0; } }
-        public int Sign
-        {
-            get { AssertValid(); return (_sign >> (kcbitUint - 1)) - (-_sign >> (kcbitUint - 1)); }
-        }
-        public static BigInteger Parse(string value)
-        {
-            return Parse(value, NumberStyles.Integer);
-        }
-        public static BigInteger Parse(string value, NumberStyles style)
-        {
-            return Parse(value, style, NumberFormatInfo.CurrentInfo);
-        }
-        public static BigInteger Parse(string value, IFormatProvider? provider)
-        {
-            return Parse(value, NumberStyles.Integer, NumberFormatInfo.GetInstance(provider));
-        }
-        public static BigInteger Parse(string value, NumberStyles style, IFormatProvider? provider)
-        {
-            ArgumentNullException.ThrowIfNull(value);
-            return Parse(value.AsSpan(), style, NumberFormatInfo.GetInstance(provider));
-        }
-        public static bool TryParse([NotNullWhen(true)] string? value, out BigInteger result)
-        {
-            return TryParse(value, NumberStyles.Integer, NumberFormatInfo.CurrentInfo, out result);
-        }
-        public static bool TryParse([NotNullWhen(true)] string? value, NumberStyles style, IFormatProvider? provider, out BigInteger result)
-        {
-            return TryParse(value.AsSpan(), style, NumberFormatInfo.GetInstance(provider), out result);
-        }
-        public static BigInteger Parse(ReadOnlySpan<char> value, NumberStyles style = NumberStyles.Integer, IFormatProvider? provider = null)
-        {
-            return Number.ParseBigInteger(value, style, NumberFormatInfo.GetInstance(provider));
-        }
-        public static bool TryParse(ReadOnlySpan<char> value, out BigInteger result)
-        {
-            return TryParse(value, NumberStyles.Integer, NumberFormatInfo.CurrentInfo, out result);
-        }
-        public static bool TryParse(ReadOnlySpan<char> value, NumberStyles style, IFormatProvider? provider, out BigInteger result)
-        {
-            return Number.TryParseBigInteger(value, style, NumberFormatInfo.GetInstance(provider), out result) == Number.ParsingStatus.OK;
-        }
-        public static int Compare(BigInteger left, BigInteger right)
-        {
-            return left.CompareTo(right);
-        }
-        public static BigInteger Abs(BigInteger value)
-        {
-            return (value >= Zero) ? value : -value;
-        }
-        public static BigInteger Add(BigInteger left, BigInteger right)
-        {
-            return left + right;
-        }
-        public static BigInteger Subtract(BigInteger left, BigInteger right)
-        {
-            return left - right;
-        }
-        public static BigInteger Multiply(BigInteger left, BigInteger right)
-        {
-            return left * right;
-        }
-        public static BigInteger Divide(BigInteger dividend, BigInteger divisor)
-        {
-            return dividend / divisor;
-        }
-        public static BigInteger Remainder(BigInteger dividend, BigInteger divisor)
-        {
-            return dividend % divisor;
-        }
-        public static BigInteger DivRem(BigInteger dividend, BigInteger divisor, out BigInteger remainder)
-        {
-            dividend.AssertValid();
-            divisor.AssertValid();
-            bool trivialDividend = dividend._bits == null;
-            bool trivialDivisor = divisor._bits == null;
-            if (trivialDividend && trivialDivisor)
-            {
-                BigInteger quotient;
-                (quotient, remainder) = Math.DivRem(dividend._sign, divisor._sign);
-                return quotient;
-            }
-            if (trivialDividend)
-            {
-                remainder = dividend;
-                return s_bnZeroInt;
-            }
-            Debug.Assert(dividend._bits != null);
-            if (trivialDivisor)
-            {
-                uint rest;
-                uint[]? bitsFromPool = null;
-                int size = dividend._bits.Length;
-                Span<uint> quotient = ((uint)size <= BigIntegerCalculator.StackAllocThreshold
-                                    ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                                    : bitsFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-                try
-                {
-                    BigIntegerCalculator.Divide(dividend._bits, NumericsHelpers.Abs(divisor._sign), quotient, out rest);
-                    remainder = dividend._sign < 0 ? -1 * rest : rest;
-                    return new BigInteger(quotient, (dividend._sign < 0) ^ (divisor._sign < 0));
-                }
-                finally
-                {
-                    if (bitsFromPool != null)
-                        ArrayPool<uint>.Shared.Return(bitsFromPool);
-                }
-            }
-            Debug.Assert(divisor._bits != null);
-            if (dividend._bits.Length < divisor._bits.Length)
-            {
-                remainder = dividend;
-                return s_bnZeroInt;
-            }
-            else
-            {
-                uint[]? remainderFromPool = null;
-                int size = dividend._bits.Length;
-                Span<uint> rest = ((uint)size <= BigIntegerCalculator.StackAllocThreshold
-                                ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                                : remainderFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-                uint[]? quotientFromPool = null;
-                size = dividend._bits.Length - divisor._bits.Length + 1;
-                Span<uint> quotient = ((uint)size <= BigIntegerCalculator.StackAllocThreshold
-                                    ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                                    : quotientFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-                BigIntegerCalculator.Divide(dividend._bits, divisor._bits, quotient, rest);
-                remainder = new BigInteger(rest, dividend._sign < 0);
-                var result = new BigInteger(quotient, (dividend._sign < 0) ^ (divisor._sign < 0));
-                if (remainderFromPool != null)
-                    ArrayPool<uint>.Shared.Return(remainderFromPool);
-                if (quotientFromPool != null)
-                    ArrayPool<uint>.Shared.Return(quotientFromPool);
-                return result;
-            }
-        }
-        public static BigInteger Negate(BigInteger value)
-        {
-            return -value;
-        }
-        public static double Log(BigInteger value)
-        {
-            return Log(value, Math.E);
-        }
-        public static double Log(BigInteger value, double baseValue)
-        {
-            if (value._sign < 0 || baseValue == 1.0D)
-                return double.NaN;
-            if (baseValue == double.PositiveInfinity)
-                return value.IsOne ? 0.0D : double.NaN;
-            if (baseValue == 0.0D && !value.IsOne)
-                return double.NaN;
-            if (value._bits == null)
-                return Math.Log(value._sign, baseValue);
-            ulong h = value._bits[value._bits.Length - 1];
-            ulong m = value._bits.Length > 1 ? value._bits[value._bits.Length - 2] : 0;
-            ulong l = value._bits.Length > 2 ? value._bits[value._bits.Length - 3] : 0;
-            int c = BitOperations.LeadingZeroCount((uint)h);
-            long b = (long)value._bits.Length * 32 - c;
-            ulong x = (h << 32 + c) | (m << c) | (l >> 32 - c);
-            return Math.Log(x, baseValue) + (b - 64) / Math.Log(baseValue, 2);
-        }
-        public static double Log10(BigInteger value)
-        {
-            return Log(value, 10);
-        }
-        public static BigInteger GreatestCommonDivisor(BigInteger left, BigInteger right)
-        {
-            left.AssertValid();
-            right.AssertValid();
-            bool trivialLeft = left._bits == null;
-            bool trivialRight = right._bits == null;
-            if (trivialLeft && trivialRight)
-            {
-                return BigIntegerCalculator.Gcd(NumericsHelpers.Abs(left._sign), NumericsHelpers.Abs(right._sign));
-            }
-            if (trivialLeft)
-            {
-                Debug.Assert(right._bits != null);
-                return left._sign != 0
-                    ? BigIntegerCalculator.Gcd(right._bits, NumericsHelpers.Abs(left._sign))
-                    : new BigInteger(right._bits, negative: false);
-            }
-            if (trivialRight)
-            {
-                Debug.Assert(left._bits != null);
-                return right._sign != 0
-                    ? BigIntegerCalculator.Gcd(left._bits, NumericsHelpers.Abs(right._sign))
-                    : new BigInteger(left._bits, negative: false);
-            }
-            Debug.Assert(left._bits != null && right._bits != null);
-            if (BigIntegerCalculator.Compare(left._bits, right._bits) < 0)
-            {
-                return GreatestCommonDivisor(right._bits, left._bits);
-            }
-            else
-            {
-                return GreatestCommonDivisor(left._bits, right._bits);
-            }
-        }
-        private static BigInteger GreatestCommonDivisor(ReadOnlySpan<uint> leftBits, ReadOnlySpan<uint> rightBits)
-        {
-            Debug.Assert(BigIntegerCalculator.Compare(leftBits, rightBits) >= 0);
-            uint[]? bitsFromPool = null;
-            BigInteger result;
-            if (rightBits.Length == 1)
-            {
-                uint temp = BigIntegerCalculator.Remainder(leftBits, rightBits[0]);
-                result = BigIntegerCalculator.Gcd(rightBits[0], temp);
-            }
-            else if (rightBits.Length == 2)
-            {
-                Span<uint> bits = (leftBits.Length <= BigIntegerCalculator.StackAllocThreshold
-                                ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                                : bitsFromPool = ArrayPool<uint>.Shared.Rent(leftBits.Length)).Slice(0, leftBits.Length);
-                BigIntegerCalculator.Remainder(leftBits, rightBits, bits);
-                ulong left = ((ulong)rightBits[1] << 32) | rightBits[0];
-                ulong right = ((ulong)bits[1] << 32) | bits[0];
-                result = BigIntegerCalculator.Gcd(left, right);
-            }
-            else
-            {
-                Span<uint> bits = (leftBits.Length <= BigIntegerCalculator.StackAllocThreshold
-                                ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                                : bitsFromPool = ArrayPool<uint>.Shared.Rent(leftBits.Length)).Slice(0, leftBits.Length);
-                BigIntegerCalculator.Gcd(leftBits, rightBits, bits);
-                result = new BigInteger(bits, negative: false);
-            }
-            if (bitsFromPool != null)
-                ArrayPool<uint>.Shared.Return(bitsFromPool);
-            return result;
-        }
-        public static BigInteger Max(BigInteger left, BigInteger right)
-        {
-            if (left.CompareTo(right) < 0)
-                return right;
-            return left;
-        }
-        public static BigInteger Min(BigInteger left, BigInteger right)
-        {
-            if (left.CompareTo(right) <= 0)
-                return left;
-            return right;
-        }
-        public static BigInteger ModPow(BigInteger value, BigInteger exponent, BigInteger modulus)
-        {
-            ArgumentOutOfRangeException.ThrowIfNegative(exponent.Sign, nameof(exponent));
-            value.AssertValid();
-            exponent.AssertValid();
-            modulus.AssertValid();
-            bool trivialValue = value._bits == null;
-            bool trivialExponent = exponent._bits == null;
-            bool trivialModulus = modulus._bits == null;
-            BigInteger result;
-            if (trivialModulus)
-            {
-                uint bits = trivialValue && trivialExponent ? BigIntegerCalculator.Pow(NumericsHelpers.Abs(value._sign), NumericsHelpers.Abs(exponent._sign), NumericsHelpers.Abs(modulus._sign)) :
-                            trivialValue ? BigIntegerCalculator.Pow(NumericsHelpers.Abs(value._sign), exponent._bits!, NumericsHelpers.Abs(modulus._sign)) :
-                            trivialExponent ? BigIntegerCalculator.Pow(value._bits!, NumericsHelpers.Abs(exponent._sign), NumericsHelpers.Abs(modulus._sign)) :
-                            BigIntegerCalculator.Pow(value._bits!, exponent._bits!, NumericsHelpers.Abs(modulus._sign));
-                result = value._sign < 0 && !exponent.IsEven ? -1 * bits : bits;
-            }
-            else
-            {
-                int size = (modulus._bits?.Length ?? 1) << 1;
-                uint[]? bitsFromPool = null;
-                Span<uint> bits = ((uint)size <= BigIntegerCalculator.StackAllocThreshold
-                                ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                                : bitsFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-                bits.Clear();
-                if (trivialValue)
-                {
-                    if (trivialExponent)
-                    {
-                        BigIntegerCalculator.Pow(NumericsHelpers.Abs(value._sign), NumericsHelpers.Abs(exponent._sign), modulus._bits!, bits);
-                    }
-                    else
-                    {
-                        BigIntegerCalculator.Pow(NumericsHelpers.Abs(value._sign), exponent._bits!, modulus._bits!, bits);
-                    }
-                }
-                else if (trivialExponent)
-                {
-                    BigIntegerCalculator.Pow(value._bits!, NumericsHelpers.Abs(exponent._sign), modulus._bits!, bits);
-                }
-                else
-                {
-                    BigIntegerCalculator.Pow(value._bits!, exponent._bits!, modulus._bits!, bits);
-                }
-                result = new BigInteger(bits, value._sign < 0 && !exponent.IsEven);
-                if (bitsFromPool != null)
-                    ArrayPool<uint>.Shared.Return(bitsFromPool);
-            }
-            return result;
-        }
-        public static BigInteger Pow(BigInteger value, int exponent)
-        {
-            ArgumentOutOfRangeException.ThrowIfNegative(exponent);
-            value.AssertValid();
-            if (exponent == 0)
-                return s_bnOneInt;
-            if (exponent == 1)
-                return value;
-            bool trivialValue = value._bits == null;
-            uint power = NumericsHelpers.Abs(exponent);
-            uint[]? bitsFromPool = null;
-            BigInteger result;
-            if (trivialValue)
-            {
-                if (value._sign == 1)
-                    return value;
-                if (value._sign == -1)
-                    return (exponent & 1) != 0 ? value : s_bnOneInt;
-                if (value._sign == 0)
-                    return value;
-                int size = BigIntegerCalculator.PowBound(power, 1);
-                Span<uint> bits = ((uint)size <= BigIntegerCalculator.StackAllocThreshold
-                                ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                                : bitsFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-                bits.Clear();
-                BigIntegerCalculator.Pow(NumericsHelpers.Abs(value._sign), power, bits);
-                result = new BigInteger(bits, value._sign < 0 && (exponent & 1) != 0);
-            }
-            else
-            {
-                int size = BigIntegerCalculator.PowBound(power, value._bits!.Length);
-                Span<uint> bits = ((uint)size <= BigIntegerCalculator.StackAllocThreshold
-                                ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                                : bitsFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-                bits.Clear();
-                BigIntegerCalculator.Pow(value._bits, power, bits);
-                result = new BigInteger(bits, value._sign < 0 && (exponent & 1) != 0);
-            }
-            if (bitsFromPool != null)
-                ArrayPool<uint>.Shared.Return(bitsFromPool);
-            return result;
-        }
-        public override int GetHashCode()
-        {
-            AssertValid();
-            if (_bits is null)
-                return _sign;
-            HashCode hash = default;
-            hash.AddBytes(MemoryMarshal.AsBytes(_bits.AsSpan()));
-            hash.Add(_sign);
-            return hash.ToHashCode();
-        }
-        public override bool Equals([NotNullWhen(true)] object? obj)
-        {
-            AssertValid();
-            return obj is BigInteger other && Equals(other);
-        }
-        public bool Equals(long other)
-        {
-            AssertValid();
-            if (_bits == null)
-                return _sign == other;
-            int cu;
-            if ((_sign ^ other) < 0 || (cu = _bits.Length) > 2)
-                return false;
-            ulong uu = other < 0 ? (ulong)-other : (ulong)other;
-            if (cu == 1)
-                return _bits[0] == uu;
-            return NumericsHelpers.MakeUInt64(_bits[1], _bits[0]) == uu;
-        }
-        [CLSCompliant(false)]
-        public bool Equals(ulong other)
-        {
-            AssertValid();
-            if (_sign < 0)
-                return false;
-            if (_bits == null)
-                return (ulong)_sign == other;
-            int cu = _bits.Length;
-            if (cu > 2)
-                return false;
-            if (cu == 1)
-                return _bits[0] == other;
-            return NumericsHelpers.MakeUInt64(_bits[1], _bits[0]) == other;
-        }
-        public bool Equals(BigInteger other)
-        {
-            AssertValid();
-            other.AssertValid();
-            return _sign == other._sign && _bits.AsSpan().SequenceEqual(other._bits);
-        }
-        public int CompareTo(long other)
-        {
-            AssertValid();
-            if (_bits == null)
-                return ((long)_sign).CompareTo(other);
-            int cu;
-            if ((_sign ^ other) < 0 || (cu = _bits.Length) > 2)
-                return _sign;
-            ulong uu = other < 0 ? (ulong)-other : (ulong)other;
-            ulong uuTmp = cu == 2 ? NumericsHelpers.MakeUInt64(_bits[1], _bits[0]) : _bits[0];
-            return _sign * uuTmp.CompareTo(uu);
-        }
-        [CLSCompliant(false)]
-        public int CompareTo(ulong other)
-        {
-            AssertValid();
-            if (_sign < 0)
-                return -1;
-            if (_bits == null)
-                return ((ulong)_sign).CompareTo(other);
-            int cu = _bits.Length;
-            if (cu > 2)
-                return +1;
-            ulong uuTmp = cu == 2 ? NumericsHelpers.MakeUInt64(_bits[1], _bits[0]) : _bits[0];
-            return uuTmp.CompareTo(other);
-        }
-        public int CompareTo(BigInteger other)
-        {
-            AssertValid();
-            other.AssertValid();
-            if ((_sign ^ other._sign) < 0)
-            {
-                return _sign < 0 ? -1 : +1;
-            }
-            if (_bits == null)
-            {
-                if (other._bits == null)
-                    return _sign < other._sign ? -1 : _sign > other._sign ? +1 : 0;
-                return -other._sign;
-            }
-            if (other._bits == null)
-                return _sign;
-            int bitsResult = BigIntegerCalculator.Compare(_bits, other._bits);
-            return _sign < 0 ? -bitsResult : bitsResult;
-        }
-        public int CompareTo(object? obj)
-        {
-            if (obj == null)
-                return 1;
-            if (obj is not BigInteger bigInt)
-                throw new ArgumentException(SR.Argument_MustBeBigInt, nameof(obj));
-            return CompareTo(bigInt);
-        }
-        public byte[] ToByteArray() => ToByteArray(isUnsigned: false, isBigEndian: false);
-        public byte[] ToByteArray(bool isUnsigned = false, bool isBigEndian = false)
-        {
-            int ignored = 0;
-            return TryGetBytes(GetBytesMode.AllocateArray, default, isUnsigned, isBigEndian, ref ignored)!;
-        }
-        public bool TryWriteBytes(Span<byte> destination, out int bytesWritten, bool isUnsigned = false, bool isBigEndian = false)
-        {
-            bytesWritten = 0;
-            if (TryGetBytes(GetBytesMode.Span, destination, isUnsigned, isBigEndian, ref bytesWritten) == null)
-            {
-                bytesWritten = 0;
-                return false;
-            }
-            return true;
-        }
-        internal bool TryWriteOrCountBytes(Span<byte> destination, out int bytesWritten, bool isUnsigned = false, bool isBigEndian = false)
-        {
-            bytesWritten = 0;
-            return TryGetBytes(GetBytesMode.Span, destination, isUnsigned, isBigEndian, ref bytesWritten) != null;
-        }
-        public int GetByteCount(bool isUnsigned = false)
-        {
-            int count = 0;
-            const bool IsBigEndian = false;
-            TryGetBytes(GetBytesMode.Count, default(Span<byte>), isUnsigned, IsBigEndian, ref count);
-            return count;
-        }
-        private enum GetBytesMode
-        {
-            AllocateArray,
-            Count,
-            Span
-        }
-        private byte[]? TryGetBytes(GetBytesMode mode, Span<byte> destination, bool isUnsigned, bool isBigEndian, ref int bytesWritten)
-        {
-            Debug.Assert(mode == GetBytesMode.AllocateArray || mode == GetBytesMode.Count || mode == GetBytesMode.Span, $"Unexpected mode {mode}.");
-            Debug.Assert(mode == GetBytesMode.Span || destination.IsEmpty, $"If we're not in span mode, we shouldn't have been passed a destination.");
-            int sign = _sign;
-            if (sign == 0)
-            {
-                switch (mode)
-                {
-                    case GetBytesMode.AllocateArray:
-                        return new byte[] { 0 };
-                    case GetBytesMode.Count:
-                        bytesWritten = 1;
-                        return null;
-                    default: // case GetBytesMode.Span:
-                        bytesWritten = 1;
-                        if (destination.Length != 0)
-                        {
-                            destination[0] = 0;
-                            return Array.Empty<byte>();
-                        }
-                        return null;
-                }
-            }
-            if (isUnsigned && sign < 0)
-            {
-                throw new OverflowException(SR.Overflow_Negative_Unsigned);
-            }
-            byte highByte;
-            int nonZeroDwordIndex = 0;
-            uint highDword;
-            uint[]? bits = _bits;
-            if (bits == null)
-            {
-                highByte = (byte)((sign < 0) ? 0xff : 0x00);
-                highDword = unchecked((uint)sign);
-            }
-            else if (sign == -1)
-            {
-                highByte = 0xff;
-                Debug.Assert(bits.Length > 0);
-                Debug.Assert(bits[bits.Length - 1] != 0);
-                while (bits[nonZeroDwordIndex] == 0U)
-                {
-                    nonZeroDwordIndex++;
-                }
-                highDword = ~bits[bits.Length - 1];
-                if (bits.Length - 1 == nonZeroDwordIndex)
-                {
-                    Debug.Assert(highDword <= uint.MaxValue - 1);
-                    highDword += 1U;
-                }
-            }
-            else
-            {
-                Debug.Assert(sign == 1);
-                highByte = 0x00;
-                highDword = bits[bits.Length - 1];
-            }
-            byte msb;
-            int msbIndex;
-            if ((msb = unchecked((byte)(highDword >> 24))) != highByte)
-            {
-                msbIndex = 3;
-            }
-            else if ((msb = unchecked((byte)(highDword >> 16))) != highByte)
-            {
-                msbIndex = 2;
-            }
-            else if ((msb = unchecked((byte)(highDword >> 8))) != highByte)
-            {
-                msbIndex = 1;
-            }
-            else
-            {
-                msb = unchecked((byte)highDword);
-                msbIndex = 0;
-            }
-            bool needExtraByte = (msb & 0x80) != (highByte & 0x80) && !isUnsigned;
-            int length = msbIndex + 1 + (needExtraByte ? 1 : 0);
-            if (bits != null)
-            {
-                length = checked(4 * (bits.Length - 1) + length);
-            }
-            byte[] array;
-            switch (mode)
-            {
-                case GetBytesMode.AllocateArray:
-                    destination = array = new byte[length];
-                    break;
-                case GetBytesMode.Count:
-                    bytesWritten = length;
-                    return null;
-                default: // case GetBytesMode.Span:
-                    bytesWritten = length;
-                    if (destination.Length < length)
-                    {
-                        return null;
-                    }
-                    array = Array.Empty<byte>();
-                    break;
-            }
-            int curByte = isBigEndian ? length - 1 : 0;
-            int increment = isBigEndian ? -1 : 1;
-            if (bits != null)
-            {
-                for (int i = 0; i < bits.Length - 1; i++)
-                {
-                    uint dword = bits[i];
-                    if (sign == -1)
-                    {
-                        dword = ~dword;
-                        if (i <= nonZeroDwordIndex)
-                        {
-                            dword = unchecked(dword + 1U);
-                        }
-                    }
-                    destination[curByte] = unchecked((byte)dword);
-                    curByte += increment;
-                    destination[curByte] = unchecked((byte)(dword >> 8));
-                    curByte += increment;
-                    destination[curByte] = unchecked((byte)(dword >> 16));
-                    curByte += increment;
-                    destination[curByte] = unchecked((byte)(dword >> 24));
-                    curByte += increment;
-                }
-            }
-            Debug.Assert(msbIndex >= 0 && msbIndex <= 3);
-            destination[curByte] = unchecked((byte)highDword);
-            if (msbIndex != 0)
-            {
-                curByte += increment;
-                destination[curByte] = unchecked((byte)(highDword >> 8));
-                if (msbIndex != 1)
-                {
-                    curByte += increment;
-                    destination[curByte] = unchecked((byte)(highDword >> 16));
-                    if (msbIndex != 2)
-                    {
-                        curByte += increment;
-                        destination[curByte] = unchecked((byte)(highDword >> 24));
-                    }
-                }
-            }
-            Debug.Assert(isBigEndian || (!needExtraByte && curByte == length - 1) || (needExtraByte && curByte == length - 2));
-            Debug.Assert(!isBigEndian || (!needExtraByte && curByte == 0) || (needExtraByte && curByte == 1));
-            if (needExtraByte)
-            {
-                curByte += increment;
-                destination[curByte] = highByte;
-            }
-            return array;
-        }
-        private int WriteTo(Span<uint> buffer)
-        {
-            Debug.Assert(_bits is null || _sign == 0 ? buffer.Length == 2 : buffer.Length >= _bits.Length + 1);
-            uint highDWord;
-            if (_bits is null)
-            {
-                buffer[0] = unchecked((uint)_sign);
-                highDWord = (_sign < 0) ? uint.MaxValue : 0;
-            }
-            else
-            {
-                _bits.CopyTo(buffer);
-                buffer = buffer.Slice(0, _bits.Length + 1);
-                if (_sign == -1)
-                {
-                    NumericsHelpers.DangerousMakeTwosComplement(buffer.Slice(0, buffer.Length - 1));  // Mutates dwords
-                    highDWord = uint.MaxValue;
-                }
-                else
-                    highDWord = 0;
-            }
-            int msb = buffer.Length - 2;
-            while (msb > 0 && buffer[msb] == highDWord)
-            {
-                msb--;
-            }
-            bool needExtraByte = (buffer[msb] & 0x80000000) != (highDWord & 0x80000000);
-            int count;
-            if (needExtraByte)
-            {
-                count = msb + 2;
-                buffer = buffer.Slice(0, count);
-                buffer[buffer.Length - 1] = highDWord;
-            }
-            else
-            {
-                count = msb + 1;
-            }
-            return count;
-        }
-        public override string ToString()
-        {
-            return Number.FormatBigInteger(this, null, NumberFormatInfo.CurrentInfo);
-        }
-        public string ToString(IFormatProvider? provider)
-        {
-            return Number.FormatBigInteger(this, null, NumberFormatInfo.GetInstance(provider));
-        }
-        public string ToString([StringSyntax(StringSyntaxAttribute.NumericFormat)] string? format)
-        {
-            return Number.FormatBigInteger(this, format, NumberFormatInfo.CurrentInfo);
-        }
-        public string ToString([StringSyntax(StringSyntaxAttribute.NumericFormat)] string? format, IFormatProvider? provider)
-        {
-            return Number.FormatBigInteger(this, format, NumberFormatInfo.GetInstance(provider));
-        }
-        private string DebuggerDisplay
-        {
-            get
-            {
-                if ((_bits is null) || (_bits.Length <= 4))
-                {
-                    return ToString();
-                }
-                const double log10Of2 = 0.3010299956639812; // Log10(2)
-                ulong highBits = ((ulong)_bits[^1] << kcbitUint) + _bits[^2];
-                double lowBitsCount32 = _bits.Length - 2; // if Length > int.MaxValue/32, counting in bits can cause overflow
-                double exponentLow = lowBitsCount32 * kcbitUint * log10Of2;
-                long exponent = (long)exponentLow;
-                double significand = (double)highBits * Math.Pow(10, exponentLow - exponent);
-                double log10 = Math.Log10(significand);
-                if (log10 >= 1)
-                {
-                    exponent += (long)log10;
-                    significand /= Math.Pow(10, Math.Floor(log10));
-                }
-                significand = Math.Round(significand, 8);
-                if (significand >= 10.0)
-                {
-                    significand /= 10.0;
-                    exponent++;
-                }
-                string signStr = _sign < 0 ? NumberFormatInfo.CurrentInfo.NegativeSign : "";
-                return $"{signStr}{significand:F8}e+{exponent}";
-            }
-        }
-        public bool TryFormat(Span<char> destination, out int charsWritten, [StringSyntax(StringSyntaxAttribute.NumericFormat)] ReadOnlySpan<char> format = default, IFormatProvider? provider = null)
-        {
-            return Number.TryFormatBigInteger(this, format, NumberFormatInfo.GetInstance(provider), destination, out charsWritten);
-        }
-        private static BigInteger Add(ReadOnlySpan<uint> leftBits, int leftSign, ReadOnlySpan<uint> rightBits, int rightSign)
-        {
-            bool trivialLeft = leftBits.IsEmpty;
-            bool trivialRight = rightBits.IsEmpty;
-            Debug.Assert(!(trivialLeft && trivialRight), "Trivial cases should be handled on the caller operator");
-            BigInteger result;
-            uint[]? bitsFromPool = null;
-            if (trivialLeft)
-            {
-                Debug.Assert(!rightBits.IsEmpty);
-                int size = rightBits.Length + 1;
-                Span<uint> bits = ((uint)size <= BigIntegerCalculator.StackAllocThreshold
-                                ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                                : bitsFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-                BigIntegerCalculator.Add(rightBits, NumericsHelpers.Abs(leftSign), bits);
-                result = new BigInteger(bits, leftSign < 0);
-            }
-            else if (trivialRight)
-            {
-                Debug.Assert(!leftBits.IsEmpty);
-                int size = leftBits.Length + 1;
-                Span<uint> bits = ((uint)size <= BigIntegerCalculator.StackAllocThreshold
-                                ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                                : bitsFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-                BigIntegerCalculator.Add(leftBits, NumericsHelpers.Abs(rightSign), bits);
-                result = new BigInteger(bits, leftSign < 0);
-            }
-            else if (leftBits.Length < rightBits.Length)
-            {
-                Debug.Assert(!leftBits.IsEmpty && !rightBits.IsEmpty);
-                int size = rightBits.Length + 1;
-                Span<uint> bits = ((uint)size <= BigIntegerCalculator.StackAllocThreshold
-                                ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                                : bitsFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-                BigIntegerCalculator.Add(rightBits, leftBits, bits);
-                result = new BigInteger(bits, leftSign < 0);
-            }
-            else
-            {
-                Debug.Assert(!leftBits.IsEmpty && !rightBits.IsEmpty);
-                int size = leftBits.Length + 1;
-                Span<uint> bits = ((uint)size <= BigIntegerCalculator.StackAllocThreshold
-                                ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                                : bitsFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-                BigIntegerCalculator.Add(leftBits, rightBits, bits);
-                result = new BigInteger(bits, leftSign < 0);
-            }
-            if (bitsFromPool != null)
-                    ArrayPool<uint>.Shared.Return(bitsFromPool);
-            return result;
-        }
-        public static BigInteger operator -(BigInteger left, BigInteger right)
-        {
-            left.AssertValid();
-            right.AssertValid();
-            if (left._bits == null && right._bits == null)
-                return (long)left._sign - right._sign;
-            if (left._sign < 0 != right._sign < 0)
-                return Add(left._bits, left._sign, right._bits, -1 * right._sign);
-            return Subtract(left._bits, left._sign, right._bits, right._sign);
-        }
-        private static BigInteger Subtract(ReadOnlySpan<uint> leftBits, int leftSign, ReadOnlySpan<uint> rightBits, int rightSign)
-        {
-            bool trivialLeft = leftBits.IsEmpty;
-            bool trivialRight = rightBits.IsEmpty;
-            Debug.Assert(!(trivialLeft && trivialRight), "Trivial cases should be handled on the caller operator");
-            BigInteger result;
-            uint[]? bitsFromPool = null;
-            if (trivialLeft)
-            {
-                Debug.Assert(!rightBits.IsEmpty);
-                int size = rightBits.Length;
-                Span<uint> bits = (size <= BigIntegerCalculator.StackAllocThreshold
-                                ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                                : bitsFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-                BigIntegerCalculator.Subtract(rightBits, NumericsHelpers.Abs(leftSign), bits);
-                result = new BigInteger(bits, leftSign >= 0);
-            }
-            else if (trivialRight)
-            {
-                Debug.Assert(!leftBits.IsEmpty);
-                int size = leftBits.Length;
-                Span<uint> bits = (size <= BigIntegerCalculator.StackAllocThreshold
-                                ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                                : bitsFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-                BigIntegerCalculator.Subtract(leftBits, NumericsHelpers.Abs(rightSign), bits);
-                result = new BigInteger(bits, leftSign < 0);
-            }
-            else if (BigIntegerCalculator.Compare(leftBits, rightBits) < 0)
-            {
-                int size = rightBits.Length;
-                Span<uint> bits = (size <= BigIntegerCalculator.StackAllocThreshold
-                                ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                                : bitsFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-                BigIntegerCalculator.Subtract(rightBits, leftBits, bits);
-                result = new BigInteger(bits, leftSign >= 0);
-            }
-            else
-            {
-                Debug.Assert(!leftBits.IsEmpty && !rightBits.IsEmpty);
-                int size = leftBits.Length;
-                Span<uint> bits = (size <= BigIntegerCalculator.StackAllocThreshold
-                                ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                                : bitsFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-                BigIntegerCalculator.Subtract(leftBits, rightBits, bits);
-                result = new BigInteger(bits, leftSign < 0);
-            }
-            if (bitsFromPool != null)
-                ArrayPool<uint>.Shared.Return(bitsFromPool);
-            return result;
-        }
-        public static explicit operator byte(BigInteger value)
-        {
-            return checked((byte)((int)value));
-        }
-        public static explicit operator char(BigInteger value)
-        {
-            return checked((char)((int)value));
-        }
-        public static explicit operator decimal(BigInteger value)
-        {
-            value.AssertValid();
-            if (value._bits == null)
-                return value._sign;
-            int length = value._bits.Length;
-            if (length > 3) throw new OverflowException(SR.Overflow_Decimal);
-            int lo = 0, mi = 0, hi = 0;
-            unchecked
-            {
-                if (length > 2) hi = (int)value._bits[2];
-                if (length > 1) mi = (int)value._bits[1];
-                if (length > 0) lo = (int)value._bits[0];
-            }
-            return new decimal(lo, mi, hi, value._sign < 0, 0);
-        }
-        public static explicit operator double(BigInteger value)
-        {
-            value.AssertValid();
-            int sign = value._sign;
-            uint[]? bits = value._bits;
-            if (bits == null)
-                return sign;
-            int length = bits.Length;
-            const int InfinityLength = 1024 / kcbitUint;
-            if (length > InfinityLength)
-            {
-                if (sign == 1)
-                    return double.PositiveInfinity;
-                else
-                    return double.NegativeInfinity;
-            }
-            ulong h = bits[length - 1];
-            ulong m = length > 1 ? bits[length - 2] : 0;
-            ulong l = length > 2 ? bits[length - 3] : 0;
-            int z = BitOperations.LeadingZeroCount((uint)h);
-            int exp = (length - 2) * 32 - z;
-            ulong man = (h << 32 + z) | (m << z) | (l >> 32 - z);
-            return NumericsHelpers.GetDoubleFromParts(sign, exp, man);
-        }
-        public static explicit operator Half(BigInteger value)
-        {
-            return (Half)(double)value;
-        }
-        public static explicit operator short(BigInteger value)
-        {
-            return checked((short)((int)value));
-        }
-        public static explicit operator int(BigInteger value)
-        {
-            value.AssertValid();
-            if (value._bits == null)
-            {
-                return value._sign;  // Value packed into int32 sign
-            }
-            if (value._bits.Length > 1)
-            {
-                throw new OverflowException(SR.Overflow_Int32);
-            }
-            if (value._sign > 0)
-            {
-                return checked((int)value._bits[0]);
-            }
-            if (value._bits[0] > kuMaskHighBit)
-            {
-                throw new OverflowException(SR.Overflow_Int32);
-            }
-            return unchecked(-(int)value._bits[0]);
-        }
-        public static explicit operator long(BigInteger value)
-        {
-            value.AssertValid();
-            if (value._bits == null)
-            {
-                return value._sign;
-            }
-            int len = value._bits.Length;
-            if (len > 2)
-            {
-                throw new OverflowException(SR.Overflow_Int64);
-            }
-            ulong uu;
-            if (len > 1)
-            {
-                uu = NumericsHelpers.MakeUInt64(value._bits[1], value._bits[0]);
-            }
-            else
-            {
-                uu = value._bits[0];
-            }
-            long ll = value._sign > 0 ? unchecked((long)uu) : unchecked(-(long)uu);
-            if ((ll > 0 && value._sign > 0) || (ll < 0 && value._sign < 0))
-            {
-                return ll;
-            }
-            throw new OverflowException(SR.Overflow_Int64);
-        }
-        public static explicit operator Int128(BigInteger value)
-        {
-            value.AssertValid();
-            if (value._bits is null)
-            {
-                return value._sign;
-            }
-            int len = value._bits.Length;
-            if (len > 4)
-            {
-                throw new OverflowException(SR.Overflow_Int128);
-            }
-            UInt128 uu;
-            if (len > 2)
-            {
-                uu = new UInt128(
-                    NumericsHelpers.MakeUInt64((len > 3) ? value._bits[3] : 0, value._bits[2]),
-                    NumericsHelpers.MakeUInt64(value._bits[1], value._bits[0])
-                );
-            }
-            else if (len > 1)
-            {
-                uu = NumericsHelpers.MakeUInt64(value._bits[1], value._bits[0]);
-            }
-            else
-            {
-                uu = value._bits[0];
-            }
-            Int128 ll = (value._sign > 0) ? unchecked((Int128)uu) : unchecked(-(Int128)uu);
-            if (((ll > 0) && (value._sign > 0)) || ((ll < 0) && (value._sign < 0)))
-            {
-                return ll;
-            }
-            throw new OverflowException(SR.Overflow_Int128);
-        }
-        public static explicit operator nint(BigInteger value)
-        {
-            if (Environment.Is64BitProcess)
-            {
-                return (nint)(long)value;
-            }
-            else
-            {
-                return (int)value;
-            }
-        }
-        [CLSCompliant(false)]
-        public static explicit operator sbyte(BigInteger value)
-        {
-            return checked((sbyte)((int)value));
-        }
-        public static explicit operator float(BigInteger value)
-        {
-            return (float)((double)value);
-        }
-        [CLSCompliant(false)]
-        public static explicit operator ushort(BigInteger value)
-        {
-            return checked((ushort)((int)value));
-        }
-        [CLSCompliant(false)]
-        public static explicit operator uint(BigInteger value)
-        {
-            value.AssertValid();
-            if (value._bits == null)
-            {
-                return checked((uint)value._sign);
-            }
-            else if (value._bits.Length > 1 || value._sign < 0)
-            {
-                throw new OverflowException(SR.Overflow_UInt32);
-            }
-            else
-            {
-                return value._bits[0];
-            }
-        }
-        [CLSCompliant(false)]
-        public static explicit operator ulong(BigInteger value)
-        {
-            value.AssertValid();
-            if (value._bits == null)
-            {
-                return checked((ulong)value._sign);
-            }
-            int len = value._bits.Length;
-            if (len > 2 || value._sign < 0)
-            {
-                throw new OverflowException(SR.Overflow_UInt64);
-            }
-            if (len > 1)
-            {
-                return NumericsHelpers.MakeUInt64(value._bits[1], value._bits[0]);
-            }
-            return value._bits[0];
-        }
-        [CLSCompliant(false)]
-        public static explicit operator UInt128(BigInteger value)
-        {
-            value.AssertValid();
-            if (value._bits is null)
-            {
-                return checked((UInt128)value._sign);
-            }
-            int len = value._bits.Length;
-            if ((len > 4) || (value._sign < 0))
-            {
-                throw new OverflowException(SR.Overflow_UInt128);
-            }
-            if (len > 2)
-            {
-                return new UInt128(
-                    NumericsHelpers.MakeUInt64((len > 3) ? value._bits[3] : 0, value._bits[2]),
-                    NumericsHelpers.MakeUInt64(value._bits[1], value._bits[0])
-                );
-            }
-            else if (len > 1)
-            {
-                return NumericsHelpers.MakeUInt64(value._bits[1], value._bits[0]);
-            }
-            return value._bits[0];
-        }
-        [CLSCompliant(false)]
-        public static explicit operator nuint(BigInteger value)
-        {
-            if (Environment.Is64BitProcess)
-            {
-                return (nuint)(ulong)value;
-            }
-            else
-            {
-                return (uint)value;
-            }
-        }
-        public static explicit operator BigInteger(decimal value)
-        {
-            return new BigInteger(value);
-        }
-        public static explicit operator BigInteger(double value)
-        {
-            return new BigInteger(value);
-        }
-        public static explicit operator BigInteger(Half value)
-        {
-            return new BigInteger((float)value);
-        }
-        public static explicit operator BigInteger(Complex value)
-        {
-            if (value.Imaginary != 0)
-            {
-                ThrowHelper.ThrowOverflowException();
-            }
-            return (BigInteger)value.Real;
-        }
-        public static explicit operator BigInteger(float value)
-        {
-            return new BigInteger(value);
-        }
-        public static implicit operator BigInteger(byte value)
-        {
-            return new BigInteger(value);
-        }
-        public static implicit operator BigInteger(char value)
-        {
-            return new BigInteger(value);
-        }
-        public static implicit operator BigInteger(short value)
-        {
-            return new BigInteger(value);
-        }
-        public static implicit operator BigInteger(int value)
-        {
-            return new BigInteger(value);
-        }
-        public static implicit operator BigInteger(long value)
-        {
-            return new BigInteger(value);
-        }
-        public static implicit operator BigInteger(Int128 value)
-        {
-            int sign;
-            uint[]? bits;
-            if ((int.MinValue < value) && (value <= int.MaxValue))
-            {
-                sign = (int)value;
-                bits = null;
-            }
-            else if (value == int.MinValue)
-            {
-                return s_bnMinInt;
-            }
-            else
-            {
-                UInt128 x;
-                if (value < 0)
-                {
-                    x = unchecked((UInt128)(-value));
-                    sign = -1;
-                }
-                else
-                {
-                    x = (UInt128)value;
-                    sign = +1;
-                }
-                if (x <= uint.MaxValue)
-                {
-                    bits = new uint[1];
-                    bits[0] = (uint)(x >> (kcbitUint * 0));
-                }
-                else if (x <= ulong.MaxValue)
-                {
-                    bits = new uint[2];
-                    bits[0] = (uint)(x >> (kcbitUint * 0));
-                    bits[1] = (uint)(x >> (kcbitUint * 1));
-                }
-                else if (x <= new UInt128(0x0000_0000_FFFF_FFFF, 0xFFFF_FFFF_FFFF_FFFF))
-                {
-                    bits = new uint[3];
-                    bits[0] = (uint)(x >> (kcbitUint * 0));
-                    bits[1] = (uint)(x >> (kcbitUint * 1));
-                    bits[2] = (uint)(x >> (kcbitUint * 2));
-                }
-                else
-                {
-                    bits = new uint[4];
-                    bits[0] = (uint)(x >> (kcbitUint * 0));
-                    bits[1] = (uint)(x >> (kcbitUint * 1));
-                    bits[2] = (uint)(x >> (kcbitUint * 2));
-                    bits[3] = (uint)(x >> (kcbitUint * 3));
-                }
-            }
-            return new BigInteger(sign, bits);
-        }
-        public static implicit operator BigInteger(nint value)
-        {
-            if (Environment.Is64BitProcess)
-            {
-                return new BigInteger(value);
-            }
-            else
-            {
-                return new BigInteger((int)value);
-            }
-        }
-        [CLSCompliant(false)]
-        public static implicit operator BigInteger(sbyte value)
-        {
-            return new BigInteger(value);
-        }
-        [CLSCompliant(false)]
-        public static implicit operator BigInteger(ushort value)
-        {
-            return new BigInteger(value);
-        }
-        [CLSCompliant(false)]
-        public static implicit operator BigInteger(uint value)
-        {
-            return new BigInteger(value);
-        }
-        [CLSCompliant(false)]
-        public static implicit operator BigInteger(ulong value)
-        {
-            return new BigInteger(value);
-        }
-        [CLSCompliant(false)]
-        public static implicit operator BigInteger(UInt128 value)
-        {
-            int sign = +1;
-            uint[]? bits;
-            if (value <= (uint)int.MaxValue)
-            {
-                sign = (int)value;
-                bits = null;
-            }
-            else if (value <= uint.MaxValue)
-            {
-                bits = new uint[1];
-                bits[0] = (uint)(value >> (kcbitUint * 0));
-            }
-            else if (value <= ulong.MaxValue)
-            {
-                bits = new uint[2];
-                bits[0] = (uint)(value >> (kcbitUint * 0));
-                bits[1] = (uint)(value >> (kcbitUint * 1));
-            }
-            else if (value <= new UInt128(0x0000_0000_FFFF_FFFF, 0xFFFF_FFFF_FFFF_FFFF))
-            {
-                bits = new uint[3];
-                bits[0] = (uint)(value >> (kcbitUint * 0));
-                bits[1] = (uint)(value >> (kcbitUint * 1));
-                bits[2] = (uint)(value >> (kcbitUint * 2));
-            }
-            else
-            {
-                bits = new uint[4];
-                bits[0] = (uint)(value >> (kcbitUint * 0));
-                bits[1] = (uint)(value >> (kcbitUint * 1));
-                bits[2] = (uint)(value >> (kcbitUint * 2));
-                bits[3] = (uint)(value >> (kcbitUint * 3));
-            }
-            return new BigInteger(sign, bits);
-        }
-        [CLSCompliant(false)]
-        public static implicit operator BigInteger(nuint value)
-        {
-            if (Environment.Is64BitProcess)
-            {
-                return new BigInteger(value);
-            }
-            else
-            {
-                return new BigInteger((uint)value);
-            }
-        }
-        public static BigInteger operator &(BigInteger left, BigInteger right)
-        {
-            if (left.IsZero || right.IsZero)
-            {
-                return Zero;
-            }
-            if (left._bits is null && right._bits is null)
-            {
-                return left._sign & right._sign;
-            }
-            uint xExtend = (left._sign < 0) ? uint.MaxValue : 0;
-            uint yExtend = (right._sign < 0) ? uint.MaxValue : 0;
-            uint[]? leftBufferFromPool = null;
-            int size = (left._bits?.Length ?? 1) + 1;
-            Span<uint> x = ((uint)size <= BigIntegerCalculator.StackAllocThreshold
-                         ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                         : leftBufferFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-            x = x.Slice(0, left.WriteTo(x));
-            uint[]? rightBufferFromPool = null;
-            size = (right._bits?.Length ?? 1) + 1;
-            Span<uint> y = ((uint)size <= BigIntegerCalculator.StackAllocThreshold
-                         ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                         : rightBufferFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-            y = y.Slice(0, right.WriteTo(y));
-            uint[]? resultBufferFromPool = null;
-            size = Math.Max(x.Length, y.Length);
-            Span<uint> z = (size <= BigIntegerCalculator.StackAllocThreshold
-                         ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                         : resultBufferFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-            for (int i = 0; i < z.Length; i++)
-            {
-                uint xu = ((uint)i < (uint)x.Length) ? x[i] : xExtend;
-                uint yu = ((uint)i < (uint)y.Length) ? y[i] : yExtend;
-                z[i] = xu & yu;
-            }
-            if (leftBufferFromPool != null)
-                ArrayPool<uint>.Shared.Return(leftBufferFromPool);
-            if (rightBufferFromPool != null)
-                ArrayPool<uint>.Shared.Return(rightBufferFromPool);
-            var result = new BigInteger(z);
-            if (resultBufferFromPool != null)
-                ArrayPool<uint>.Shared.Return(resultBufferFromPool);
-            return result;
-        }
-        public static BigInteger operator |(BigInteger left, BigInteger right)
-        {
-            if (left.IsZero)
-                return right;
-            if (right.IsZero)
-                return left;
-            if (left._bits is null && right._bits is null)
-            {
-                return left._sign | right._sign;
-            }
-            uint xExtend = (left._sign < 0) ? uint.MaxValue : 0;
-            uint yExtend = (right._sign < 0) ? uint.MaxValue : 0;
-            uint[]? leftBufferFromPool = null;
-            int size = (left._bits?.Length ?? 1) + 1;
-            Span<uint> x = ((uint)size <= BigIntegerCalculator.StackAllocThreshold
-                         ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                         : leftBufferFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-            x = x.Slice(0, left.WriteTo(x));
-            uint[]? rightBufferFromPool = null;
-            size = (right._bits?.Length ?? 1) + 1;
-            Span<uint> y = ((uint)size <= BigIntegerCalculator.StackAllocThreshold
-                         ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                         : rightBufferFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-            y = y.Slice(0, right.WriteTo(y));
-            uint[]? resultBufferFromPool = null;
-            size = Math.Max(x.Length, y.Length);
-            Span<uint> z = (size <= BigIntegerCalculator.StackAllocThreshold
-                         ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                         : resultBufferFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-            for (int i = 0; i < z.Length; i++)
-            {
-                uint xu = ((uint)i < (uint)x.Length) ? x[i] : xExtend;
-                uint yu = ((uint)i < (uint)y.Length) ? y[i] : yExtend;
-                z[i] = xu | yu;
-            }
-            if (leftBufferFromPool != null)
-                ArrayPool<uint>.Shared.Return(leftBufferFromPool);
-            if (rightBufferFromPool != null)
-                ArrayPool<uint>.Shared.Return(rightBufferFromPool);
-            var result = new BigInteger(z);
-            if (resultBufferFromPool != null)
-                ArrayPool<uint>.Shared.Return(resultBufferFromPool);
-            return result;
-        }
-        public static BigInteger operator ^(BigInteger left, BigInteger right)
-        {
-            if (left._bits is null && right._bits is null)
-            {
-                return left._sign ^ right._sign;
-            }
-            uint xExtend = (left._sign < 0) ? uint.MaxValue : 0;
-            uint yExtend = (right._sign < 0) ? uint.MaxValue : 0;
-            uint[]? leftBufferFromPool = null;
-            int size = (left._bits?.Length ?? 1) + 1;
-            Span<uint> x = ((uint)size <= BigIntegerCalculator.StackAllocThreshold
-                         ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                         : leftBufferFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-            x = x.Slice(0, left.WriteTo(x));
-            uint[]? rightBufferFromPool = null;
-            size = (right._bits?.Length ?? 1) + 1;
-            Span<uint> y = ((uint)size <= BigIntegerCalculator.StackAllocThreshold
-                         ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                         : rightBufferFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-            y = y.Slice(0, right.WriteTo(y));
-            uint[]? resultBufferFromPool = null;
-            size = Math.Max(x.Length, y.Length);
-            Span<uint> z = (size <= BigIntegerCalculator.StackAllocThreshold
-                         ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                         : resultBufferFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-            for (int i = 0; i < z.Length; i++)
-            {
-                uint xu = ((uint)i < (uint)x.Length) ? x[i] : xExtend;
-                uint yu = ((uint)i < (uint)y.Length) ? y[i] : yExtend;
-                z[i] = xu ^ yu;
-            }
-            if (leftBufferFromPool != null)
-                ArrayPool<uint>.Shared.Return(leftBufferFromPool);
-            if (rightBufferFromPool != null)
-                ArrayPool<uint>.Shared.Return(rightBufferFromPool);
-            var result = new BigInteger(z);
-            if (resultBufferFromPool != null)
-                ArrayPool<uint>.Shared.Return(resultBufferFromPool);
-            return result;
-        }
-        public static BigInteger operator <<(BigInteger value, int shift)
-        {
-            if (shift == 0)
-                return value;
-            if (shift == int.MinValue)
-                return ((value >> int.MaxValue) >> 1);
-            if (shift < 0)
-                return value >> -shift;
-            (int digitShift, int smallShift) = Math.DivRem(shift, kcbitUint);
-            uint[]? xdFromPool = null;
-            int xl = value._bits?.Length ?? 1;
-            Span<uint> xd = (xl <= BigIntegerCalculator.StackAllocThreshold
-                          ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                          : xdFromPool = ArrayPool<uint>.Shared.Rent(xl)).Slice(0, xl);
-            bool negx = value.GetPartsForBitManipulation(xd);
-            int zl = xl + digitShift + 1;
-            uint[]? zdFromPool = null;
-            Span<uint> zd = ((uint)zl <= BigIntegerCalculator.StackAllocThreshold
-                          ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                          : zdFromPool = ArrayPool<uint>.Shared.Rent(zl)).Slice(0, zl);
-            zd.Clear();
-            uint carry = 0;
-            if (smallShift == 0)
-            {
-                for (int i = 0; i < xd.Length; i++)
-                {
-                    zd[i + digitShift] = xd[i];
-                }
-            }
-            else
-            {
-                int carryShift = kcbitUint - smallShift;
-                int i;
-                for (i = 0; i < xd.Length; i++)
-                {
-                    uint rot = xd[i];
-                    zd[i + digitShift] = rot << smallShift | carry;
-                    carry = rot >> carryShift;
-                }
-            }
-            zd[zd.Length - 1] = carry;
-            var result = new BigInteger(zd, negx);
-            if (xdFromPool != null)
-                ArrayPool<uint>.Shared.Return(xdFromPool);
-            if (zdFromPool != null)
-                ArrayPool<uint>.Shared.Return(zdFromPool);
-            return result;
-        }
-        public static BigInteger operator >>(BigInteger value, int shift)
-        {
-            if (shift == 0)
-                return value;
-            if (shift == int.MinValue)
-                return ((value << int.MaxValue) << 1);
-            if (shift < 0)
-                return value << -shift;
-            (int digitShift, int smallShift) = Math.DivRem(shift, kcbitUint);
-            BigInteger result;
-            uint[]? xdFromPool = null;
-            int xl = value._bits?.Length ?? 1;
-            Span<uint> xd = (xl <= BigIntegerCalculator.StackAllocThreshold
-                          ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                          : xdFromPool = ArrayPool<uint>.Shared.Rent(xl)).Slice(0, xl);
-            bool negx = value.GetPartsForBitManipulation(xd);
-            bool trackSignBit = false;
-            if (negx)
-            {
-                if (shift >= ((long)kcbitUint * xd.Length))
-                {
-                    result = MinusOne;
-                    goto exit;
-                }
-                NumericsHelpers.DangerousMakeTwosComplement(xd); // Mutates xd
-                trackSignBit = smallShift == 0 && xd[xd.Length - 1] == 0;
-            }
-            uint[]? zdFromPool = null;
-            int zl = Math.Max(xl - digitShift, 0) + (trackSignBit ? 1 : 0);
-            Span<uint> zd = ((uint)zl <= BigIntegerCalculator.StackAllocThreshold
-                          ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                          : zdFromPool = ArrayPool<uint>.Shared.Rent(zl)).Slice(0, zl);
-            zd.Clear();
-            if (smallShift == 0)
-            {
-                for (int i = xd.Length - 1; i >= digitShift; i--)
-                {
-                    zd[i - digitShift] = xd[i];
-                }
-            }
-            else
-            {
-                int carryShift = kcbitUint - smallShift;
-                uint carry = 0;
-                for (int i = xd.Length - 1; i >= digitShift; i--)
-                {
-                    uint rot = xd[i];
-                    if (negx && i == xd.Length - 1)
-                        zd[i - digitShift] = (rot >> smallShift) | (0xFFFFFFFF << carryShift);
-                    else
-                        zd[i - digitShift] = (rot >> smallShift) | carry;
-                    carry = rot << carryShift;
-                }
-            }
-            if (negx)
-            {
-                if (trackSignBit)
-                    zd[zd.Length - 1] = 0xFFFFFFFF;
-                NumericsHelpers.DangerousMakeTwosComplement(zd); // Mutates zd
-            }
-            result = new BigInteger(zd, negx);
-            if (zdFromPool != null)
-                ArrayPool<uint>.Shared.Return(zdFromPool);
-        exit:
-            if (xdFromPool != null)
-                ArrayPool<uint>.Shared.Return(xdFromPool);
-            return result;
-        }
-        public static BigInteger operator ~(BigInteger value)
-        {
-            return -(value + One);
-        }
-        public static BigInteger operator -(BigInteger value)
-        {
-            value.AssertValid();
-            return new BigInteger(-value._sign, value._bits);
-        }
-        public static BigInteger operator +(BigInteger value)
-        {
-            value.AssertValid();
-            return value;
-        }
-        public static BigInteger operator ++(BigInteger value)
-        {
-            return value + One;
-        }
-        public static BigInteger operator --(BigInteger value)
-        {
-            return value - One;
-        }
-        public static BigInteger operator +(BigInteger left, BigInteger right)
-        {
-            left.AssertValid();
-            right.AssertValid();
-            if (left._bits == null && right._bits == null)
-                return (long)left._sign + right._sign;
-            if (left._sign < 0 != right._sign < 0)
-                return Subtract(left._bits, left._sign, right._bits, -1 * right._sign);
-            return Add(left._bits, left._sign, right._bits, right._sign);
-        }
-        public static BigInteger operator *(BigInteger left, BigInteger right)
-        {
-            left.AssertValid();
-            right.AssertValid();
-            if (left._bits == null && right._bits == null)
-                return (long)left._sign * right._sign;
-            return Multiply(left._bits, left._sign, right._bits, right._sign);
-        }
-        private static BigInteger Multiply(ReadOnlySpan<uint> left, int leftSign, ReadOnlySpan<uint> right, int rightSign)
-        {
-            bool trivialLeft = left.IsEmpty;
-            bool trivialRight = right.IsEmpty;
-            Debug.Assert(!(trivialLeft && trivialRight), "Trivial cases should be handled on the caller operator");
-            BigInteger result;
-            uint[]? bitsFromPool = null;
-            if (trivialLeft)
-            {
-                Debug.Assert(!right.IsEmpty);
-                int size = right.Length + 1;
-                Span<uint> bits = ((uint)size <= BigIntegerCalculator.StackAllocThreshold
-                                ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                                : bitsFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-                BigIntegerCalculator.Multiply(right, NumericsHelpers.Abs(leftSign), bits);
-                result = new BigInteger(bits, (leftSign < 0) ^ (rightSign < 0));
-            }
-            else if (trivialRight)
-            {
-                Debug.Assert(!left.IsEmpty);
-                int size = left.Length + 1;
-                Span<uint> bits = ((uint)size <= BigIntegerCalculator.StackAllocThreshold
-                                ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                                : bitsFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-                BigIntegerCalculator.Multiply(left, NumericsHelpers.Abs(rightSign), bits);
-                result = new BigInteger(bits, (leftSign < 0) ^ (rightSign < 0));
-            }
-            else if (left == right)
-            {
-                int size = left.Length + right.Length;
-                Span<uint> bits = ((uint)size <= BigIntegerCalculator.StackAllocThreshold
-                                ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                                : bitsFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-                BigIntegerCalculator.Square(left, bits);
-                result = new BigInteger(bits, (leftSign < 0) ^ (rightSign < 0));
-            }
-            else if (left.Length < right.Length)
-            {
-                Debug.Assert(!left.IsEmpty && !right.IsEmpty);
-                int size = left.Length + right.Length;
-                Span<uint> bits = ((uint)size <= BigIntegerCalculator.StackAllocThreshold
-                                ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                                : bitsFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-                bits.Clear();
-                BigIntegerCalculator.Multiply(right, left, bits);
-                result = new BigInteger(bits, (leftSign < 0) ^ (rightSign < 0));
-            }
-            else
-            {
-                Debug.Assert(!left.IsEmpty && !right.IsEmpty);
-                int size = left.Length + right.Length;
-                Span<uint> bits = ((uint)size <= BigIntegerCalculator.StackAllocThreshold
-                                ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                                : bitsFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-                bits.Clear();
-                BigIntegerCalculator.Multiply(left, right, bits);
-                result = new BigInteger(bits, (leftSign < 0) ^ (rightSign < 0));
-            }
-            if (bitsFromPool != null)
-                ArrayPool<uint>.Shared.Return(bitsFromPool);
-            return result;
-        }
-        public static BigInteger operator /(BigInteger dividend, BigInteger divisor)
-        {
-            dividend.AssertValid();
-            divisor.AssertValid();
-            bool trivialDividend = dividend._bits == null;
-            bool trivialDivisor = divisor._bits == null;
-            if (trivialDividend && trivialDivisor)
-            {
-                return dividend._sign / divisor._sign;
-            }
-            if (trivialDividend)
-            {
-                return s_bnZeroInt;
-            }
-            uint[]? quotientFromPool = null;
-            if (trivialDivisor)
-            {
-                Debug.Assert(dividend._bits != null);
-                int size = dividend._bits.Length;
-                Span<uint> quotient = ((uint)size <= BigIntegerCalculator.StackAllocThreshold
-                                    ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                                    : quotientFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-                try
-                {
-                    BigIntegerCalculator.Divide(dividend._bits, NumericsHelpers.Abs(divisor._sign), quotient);
-                    return new BigInteger(quotient, (dividend._sign < 0) ^ (divisor._sign < 0));
-                }
-                finally
-                {
-                    if (quotientFromPool != null)
-                        ArrayPool<uint>.Shared.Return(quotientFromPool);
-                }
-            }
-            Debug.Assert(dividend._bits != null && divisor._bits != null);
-            if (dividend._bits.Length < divisor._bits.Length)
-            {
-                return s_bnZeroInt;
-            }
-            else
-            {
-                int size = dividend._bits.Length - divisor._bits.Length + 1;
-                Span<uint> quotient = ((uint)size < BigIntegerCalculator.StackAllocThreshold
-                                    ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                                    : quotientFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-                BigIntegerCalculator.Divide(dividend._bits, divisor._bits, quotient);
-                var result = new BigInteger(quotient, (dividend._sign < 0) ^ (divisor._sign < 0));
-                if (quotientFromPool != null)
-                    ArrayPool<uint>.Shared.Return(quotientFromPool);
-                return result;
-            }
-        }
-        public static BigInteger operator %(BigInteger dividend, BigInteger divisor)
-        {
-            dividend.AssertValid();
-            divisor.AssertValid();
-            bool trivialDividend = dividend._bits == null;
-            bool trivialDivisor = divisor._bits == null;
-            if (trivialDividend && trivialDivisor)
-            {
-                return dividend._sign % divisor._sign;
-            }
-            if (trivialDividend)
-            {
-                return dividend;
-            }
-            if (trivialDivisor)
-            {
-                Debug.Assert(dividend._bits != null);
-                uint remainder = BigIntegerCalculator.Remainder(dividend._bits, NumericsHelpers.Abs(divisor._sign));
-                return dividend._sign < 0 ? -1 * remainder : remainder;
-            }
-            Debug.Assert(dividend._bits != null && divisor._bits != null);
-            if (dividend._bits.Length < divisor._bits.Length)
-            {
-                return dividend;
-            }
-            uint[]? bitsFromPool = null;
-            int size = dividend._bits.Length;
-            Span<uint> bits = (size <= BigIntegerCalculator.StackAllocThreshold
-                            ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                            : bitsFromPool = ArrayPool<uint>.Shared.Rent(size)).Slice(0, size);
-            BigIntegerCalculator.Remainder(dividend._bits, divisor._bits, bits);
-            var result = new BigInteger(bits, dividend._sign < 0);
-            if (bitsFromPool != null)
-                ArrayPool<uint>.Shared.Return(bitsFromPool);
-            return result;
-        }
-        public static bool operator <(BigInteger left, BigInteger right)
-        {
-            return left.CompareTo(right) < 0;
-        }
-        public static bool operator <=(BigInteger left, BigInteger right)
-        {
-            return left.CompareTo(right) <= 0;
-        }
-        public static bool operator >(BigInteger left, BigInteger right)
-        {
-            return left.CompareTo(right) > 0;
-        }
-        public static bool operator >=(BigInteger left, BigInteger right)
-        {
-            return left.CompareTo(right) >= 0;
-        }
-        public static bool operator ==(BigInteger left, BigInteger right)
-        {
-            return left.Equals(right);
-        }
-        public static bool operator !=(BigInteger left, BigInteger right)
-        {
-            return !left.Equals(right);
-        }
-        public static bool operator <(BigInteger left, long right)
-        {
-            return left.CompareTo(right) < 0;
-        }
-        public static bool operator <=(BigInteger left, long right)
-        {
-            return left.CompareTo(right) <= 0;
-        }
-        public static bool operator >(BigInteger left, long right)
-        {
-            return left.CompareTo(right) > 0;
-        }
-        public static bool operator >=(BigInteger left, long right)
-        {
-            return left.CompareTo(right) >= 0;
-        }
-        public static bool operator ==(BigInteger left, long right)
-        {
-            return left.Equals(right);
-        }
-        public static bool operator !=(BigInteger left, long right)
-        {
-            return !left.Equals(right);
-        }
-        public static bool operator <(long left, BigInteger right)
-        {
-            return right.CompareTo(left) > 0;
-        }
-        public static bool operator <=(long left, BigInteger right)
-        {
-            return right.CompareTo(left) >= 0;
-        }
-        public static bool operator >(long left, BigInteger right)
-        {
-            return right.CompareTo(left) < 0;
-        }
-        public static bool operator >=(long left, BigInteger right)
-        {
-            return right.CompareTo(left) <= 0;
-        }
-        public static bool operator ==(long left, BigInteger right)
-        {
-            return right.Equals(left);
-        }
-        public static bool operator !=(long left, BigInteger right)
-        {
-            return !right.Equals(left);
-        }
-        [CLSCompliant(false)]
-        public static bool operator <(BigInteger left, ulong right)
-        {
-            return left.CompareTo(right) < 0;
-        }
-        [CLSCompliant(false)]
-        public static bool operator <=(BigInteger left, ulong right)
-        {
-            return left.CompareTo(right) <= 0;
-        }
-        [CLSCompliant(false)]
-        public static bool operator >(BigInteger left, ulong right)
-        {
-            return left.CompareTo(right) > 0;
-        }
-        [CLSCompliant(false)]
-        public static bool operator >=(BigInteger left, ulong right)
-        {
-            return left.CompareTo(right) >= 0;
-        }
-        [CLSCompliant(false)]
-        public static bool operator ==(BigInteger left, ulong right)
-        {
-            return left.Equals(right);
-        }
-        [CLSCompliant(false)]
-        public static bool operator !=(BigInteger left, ulong right)
-        {
-            return !left.Equals(right);
-        }
-        [CLSCompliant(false)]
-        public static bool operator <(ulong left, BigInteger right)
-        {
-            return right.CompareTo(left) > 0;
-        }
-        [CLSCompliant(false)]
-        public static bool operator <=(ulong left, BigInteger right)
-        {
-            return right.CompareTo(left) >= 0;
-        }
-        [CLSCompliant(false)]
-        public static bool operator >(ulong left, BigInteger right)
-        {
-            return right.CompareTo(left) < 0;
-        }
-        [CLSCompliant(false)]
-        public static bool operator >=(ulong left, BigInteger right)
-        {
-            return right.CompareTo(left) <= 0;
-        }
-        [CLSCompliant(false)]
-        public static bool operator ==(ulong left, BigInteger right)
-        {
-            return right.Equals(left);
-        }
-        [CLSCompliant(false)]
-        public static bool operator !=(ulong left, BigInteger right)
-        {
-            return !right.Equals(left);
-        }
-        public long GetBitLength()
-        {
-            AssertValid();
-            uint highValue;
-            int bitsArrayLength;
-            int sign = _sign;
-            uint[]? bits = _bits;
-            if (bits == null)
-            {
-                bitsArrayLength = 1;
-                highValue = (uint)(sign < 0 ? -sign : sign);
-            }
-            else
-            {
-                bitsArrayLength = bits.Length;
-                highValue = bits[bitsArrayLength - 1];
-            }
-            long bitLength = bitsArrayLength * 32L - BitOperations.LeadingZeroCount(highValue);
-            if (sign >= 0)
-                return bitLength;
-            if ((highValue & (highValue - 1)) != 0)
-                return bitLength;
-            for (int i = bitsArrayLength - 2; i >= 0; i--)
-            {
-                if (bits![i] == 0)
-                    continue;
-                return bitLength;
-            }
-            return bitLength - 1;
-        }
-        private bool GetPartsForBitManipulation(Span<uint> xd)
-        {
-            Debug.Assert(_bits is null ? xd.Length == 1 : xd.Length == _bits.Length);
-            if (_bits is null)
-            {
-                xd[0] = (uint)(_sign < 0 ? -_sign : _sign);
-            }
-            else
-            {
-                _bits.CopyTo(xd);
-            }
-            return _sign < 0;
-        }
-        [Conditional("DEBUG")]
-        private void AssertValid()
-        {
-            if (_bits != null)
-            {
-                Debug.Assert(_sign == 1 || _sign == -1);
-                Debug.Assert(_bits.Length > 0);
-                Debug.Assert(_bits.Length > 1 || _bits[0] >= kuMaskHighBit);
-                Debug.Assert(_bits[_bits.Length - 1] != 0);
-                Debug.Assert(_bits.Length <= MaxLength);
-            }
-            else
-            {
-                Debug.Assert(_sign > int.MinValue);
-            }
-        }
-        static BigInteger IAdditiveIdentity<BigInteger, BigInteger>.AdditiveIdentity => Zero;
-        public static (BigInteger Quotient, BigInteger Remainder) DivRem(BigInteger left, BigInteger right)
-        {
-            BigInteger quotient = DivRem(left, right, out BigInteger remainder);
-            return (quotient, remainder);
-        }
-        public static BigInteger LeadingZeroCount(BigInteger value)
-        {
-            value.AssertValid();
-            if (value._bits is null)
-            {
-                return int.LeadingZeroCount(value._sign);
-            }
-            return (value._sign >= 0) ? uint.LeadingZeroCount(value._bits[^1]) : 0;
-        }
-        public static BigInteger PopCount(BigInteger value)
-        {
-            value.AssertValid();
-            if (value._bits is null)
-            {
-                return int.PopCount(value._sign);
-            }
-            ulong result = 0;
-            if (value._sign >= 0)
-            {
-                for (int i = 0; i < value._bits.Length; i++)
-                {
-                    uint part = value._bits[i];
-                    result += uint.PopCount(part);
-                }
-            }
-            else
-            {
-                int i = 0;
-                uint part;
-                do
-                {
-                    part = ~value._bits[i] + 1;
-                    result += uint.PopCount(part);
-                    i++;
-                }
-                while ((part == 0) && (i < value._bits.Length));
-                while (i < value._bits.Length)
-                {
-                    part = ~value._bits[i];
-                    result += uint.PopCount(part);
-                    i++;
-                }
-            }
-            return result;
-        }
-        public static BigInteger RotateLeft(BigInteger value, int rotateAmount)
-        {
-            value.AssertValid();
-            int byteCount = (value._bits is null) ? sizeof(int) : (value._bits.Length * 4);
-            rotateAmount = (int)(rotateAmount % (byteCount * 8L));
-            if (rotateAmount == 0)
-                return value;
-            if (rotateAmount == int.MinValue)
-                return RotateRight(RotateRight(value, int.MaxValue), 1);
-            if (rotateAmount < 0)
-                return RotateRight(value, -rotateAmount);
-            (int digitShift, int smallShift) = Math.DivRem(rotateAmount, kcbitUint);
-            uint[]? xdFromPool = null;
-            int xl = value._bits?.Length ?? 1;
-            Span<uint> xd = (xl <= BigIntegerCalculator.StackAllocThreshold)
-                          ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                          : xdFromPool = ArrayPool<uint>.Shared.Rent(xl);
-            xd = xd.Slice(0, xl);
-            bool negx = value.GetPartsForBitManipulation(xd);
-            int zl = xl;
-            uint[]? zdFromPool = null;
-            Span<uint> zd = (zl <= BigIntegerCalculator.StackAllocThreshold)
-                          ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                          : zdFromPool = ArrayPool<uint>.Shared.Rent(zl);
-            zd = zd.Slice(0, zl);
-            zd.Clear();
-            if (negx)
-            {
-                NumericsHelpers.DangerousMakeTwosComplement(xd);
-            }
-            if (smallShift == 0)
-            {
-                int dstIndex = 0;
-                int srcIndex = xd.Length - digitShift;
-                do
-                {
-                    zd[dstIndex] = xd[srcIndex];
-                    dstIndex++;
-                    srcIndex++;
-                }
-                while (srcIndex < xd.Length);
-                srcIndex = 0;
-                while (dstIndex < zd.Length)
-                {
-                    zd[dstIndex] = xd[srcIndex];
-                    dstIndex++;
-                    srcIndex++;
-                }
-            }
-            else
-            {
-                int carryShift = kcbitUint - smallShift;
-                int dstIndex = 0;
-                int srcIndex = 0;
-                uint carry = 0;
-                if (digitShift == 0)
-                {
-                    carry = xd[^1] >> carryShift;
-                }
-                else
-                {
-                    srcIndex = xd.Length - digitShift;
-                    carry = xd[srcIndex - 1] >> carryShift;
-                }
-                do
-                {
-                    uint part = xd[srcIndex];
-                    zd[dstIndex] = (part << smallShift) | carry;
-                    carry = part >> carryShift;
-                    dstIndex++;
-                    srcIndex++;
-                }
-                while (srcIndex < xd.Length);
-                srcIndex = 0;
-                while (dstIndex < zd.Length)
-                {
-                    uint part = xd[srcIndex];
-                    zd[dstIndex] = (part << smallShift) | carry;
-                    carry = part >> carryShift;
-                    dstIndex++;
-                    srcIndex++;
-                }
-            }
-            if (negx && (int)zd[^1] < 0)
-            {
-                NumericsHelpers.DangerousMakeTwosComplement(zd);
-            }
-            else
-            {
-                negx = false;
-            }
-            var result = new BigInteger(zd, negx);
-            if (xdFromPool != null)
-                ArrayPool<uint>.Shared.Return(xdFromPool);
-            if (zdFromPool != null)
-                ArrayPool<uint>.Shared.Return(zdFromPool);
-            return result;
-        }
-        public static BigInteger RotateRight(BigInteger value, int rotateAmount)
-        {
-            value.AssertValid();
-            int byteCount = (value._bits is null) ? sizeof(int) : (value._bits.Length * 4);
-            rotateAmount = (int)(rotateAmount % (byteCount * 8L));
-            if (rotateAmount == 0)
-                return value;
-            if (rotateAmount == int.MinValue)
-                return RotateLeft(RotateLeft(value, int.MaxValue), 1);
-            if (rotateAmount < 0)
-                return RotateLeft(value, -rotateAmount);
-            (int digitShift, int smallShift) = Math.DivRem(rotateAmount, kcbitUint);
-            uint[]? xdFromPool = null;
-            int xl = value._bits?.Length ?? 1;
-            Span<uint> xd = (xl <= BigIntegerCalculator.StackAllocThreshold)
-                          ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                          : xdFromPool = ArrayPool<uint>.Shared.Rent(xl);
-            xd = xd.Slice(0, xl);
-            bool negx = value.GetPartsForBitManipulation(xd);
-            int zl = xl;
-            uint[]? zdFromPool = null;
-            Span<uint> zd = (zl <= BigIntegerCalculator.StackAllocThreshold)
-                          ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                          : zdFromPool = ArrayPool<uint>.Shared.Rent(zl);
-            zd = zd.Slice(0, zl);
-            zd.Clear();
-            if (negx)
-            {
-                NumericsHelpers.DangerousMakeTwosComplement(xd);
-            }
-            if (smallShift == 0)
-            {
-                int dstIndex = 0;
-                int srcIndex = digitShift;
-                do
-                {
-                    zd[dstIndex] = xd[srcIndex];
-                    dstIndex++;
-                    srcIndex++;
-                }
-                while (srcIndex < xd.Length);
-                srcIndex = 0;
-                while (dstIndex < zd.Length)
-                {
-                    zd[dstIndex] = xd[srcIndex];
-                    dstIndex++;
-                    srcIndex++;
-                }
-            }
-            else
-            {
-                int carryShift = kcbitUint - smallShift;
-                int dstIndex = 0;
-                int srcIndex = digitShift;
-                uint carry = 0;
-                if (digitShift == 0)
-                {
-                    carry = xd[^1] << carryShift;
-                }
-                else
-                {
-                    carry = xd[srcIndex - 1] << carryShift;
-                }
-                do
-                {
-                    uint part = xd[srcIndex];
-                    zd[dstIndex] = (part >> smallShift) | carry;
-                    carry = part << carryShift;
-                    dstIndex++;
-                    srcIndex++;
-                }
-                while (srcIndex < xd.Length);
-                srcIndex = 0;
-                while (dstIndex < zd.Length)
-                {
-                    uint part = xd[srcIndex];
-                    zd[dstIndex] = (part >> smallShift) | carry;
-                    carry = part << carryShift;
-                    dstIndex++;
-                    srcIndex++;
-                }
-            }
-            if (negx && (int)zd[^1] < 0)
-            {
-                NumericsHelpers.DangerousMakeTwosComplement(zd);
-            }
-            else
-            {
-                negx = false;
-            }
-            var result = new BigInteger(zd, negx);
-            if (xdFromPool != null)
-                ArrayPool<uint>.Shared.Return(xdFromPool);
-            if (zdFromPool != null)
-                ArrayPool<uint>.Shared.Return(zdFromPool);
-            return result;
-        }
-        public static BigInteger TrailingZeroCount(BigInteger value)
-        {
-            value.AssertValid();
-            if (value._bits is null)
-            {
-                return int.TrailingZeroCount(value._sign);
-            }
-            ulong result = 0;
-            uint part = value._bits[0];
-            for (int i = 1; (part == 0) && (i < value._bits.Length); i++)
-            {
-                part = value._bits[i];
-                result += (sizeof(uint) * 8);
-            }
-            result += uint.TrailingZeroCount(part);
-            return result;
-        }
-        static bool IBinaryInteger<BigInteger>.TryReadBigEndian(ReadOnlySpan<byte> source, bool isUnsigned, out BigInteger value)
-        {
-            value = new BigInteger(source, isUnsigned, isBigEndian: true);
-            return true;
-        }
-        static bool IBinaryInteger<BigInteger>.TryReadLittleEndian(ReadOnlySpan<byte> source, bool isUnsigned, out BigInteger value)
-        {
-            value = new BigInteger(source, isUnsigned, isBigEndian: false);
-            return true;
-        }
-        int IBinaryInteger<BigInteger>.GetShortestBitLength()
-        {
-            AssertValid();
-            uint[]? bits = _bits;
-            if (bits is null)
-            {
-                int value = _sign;
-                if (value >= 0)
-                {
-                    return (sizeof(int) * 8) - BitOperations.LeadingZeroCount((uint)(value));
-                }
-                else
-                {
-                    return (sizeof(int) * 8) + 1 - BitOperations.LeadingZeroCount((uint)(~value));
-                }
-            }
-            int result = (bits.Length - 1) * 32;
-            if (_sign >= 0)
-            {
-                result += (sizeof(uint) * 8) - BitOperations.LeadingZeroCount(bits[^1]);
-            }
-            else
-            {
-                uint part = ~bits[^1] + 1;
-                for (int index = 0; index < bits.Length - 1; index++)
-                {
-                    if (bits[index] != 0)
-                    {
-                        part -= 1;
-                        break;
-                    }
-                }
-                result += (sizeof(uint) * 8) + 1 - BitOperations.LeadingZeroCount(~part);
-            }
-            return result;
-        }
-        int IBinaryInteger<BigInteger>.GetByteCount() => GetGenericMathByteCount();
-        bool IBinaryInteger<BigInteger>.TryWriteBigEndian(Span<byte> destination, out int bytesWritten)
-        {
-            AssertValid();
-            uint[]? bits = _bits;
-            int byteCount = GetGenericMathByteCount();
-            if (destination.Length >= byteCount)
-            {
-                if (bits is null)
-                {
-                    int value = BitConverter.IsLittleEndian ? BinaryPrimitives.ReverseEndianness(_sign) : _sign;
-                    Unsafe.WriteUnaligned(ref MemoryMarshal.GetReference(destination), value);
-                }
-                else if (_sign >= 0)
-                {
-                    ref byte startAddress = ref MemoryMarshal.GetReference(destination);
-                    ref byte address = ref Unsafe.Add(ref startAddress, (bits.Length - 1) * sizeof(uint));
-                    for (int i = 0; i < bits.Length; i++)
-                    {
-                        uint part = bits[i];
-                        if (BitConverter.IsLittleEndian)
-                        {
-                            part = BinaryPrimitives.ReverseEndianness(part);
-                        }
-                        Unsafe.WriteUnaligned(ref address, part);
-                        address = ref Unsafe.Subtract(ref address, sizeof(uint));
-                    }
-                }
-                else
-                {
-                    ref byte startAddress = ref MemoryMarshal.GetReference(destination);
-                    ref byte address = ref Unsafe.Add(ref startAddress, byteCount - sizeof(uint));
-                    int i = 0;
-                    uint part;
-                    do
-                    {
-                        part = ~bits[i] + 1;
-                        if (BitConverter.IsLittleEndian)
-                        {
-                            part = BinaryPrimitives.ReverseEndianness(part);
-                        }
-                        Unsafe.WriteUnaligned(ref address, part);
-                        address = ref Unsafe.Subtract(ref address, sizeof(uint));
-                        i++;
-                    }
-                    while ((part == 0) && (i < bits.Length));
-                    while (i < bits.Length)
-                    {
-                        part = ~bits[i];
-                        if (BitConverter.IsLittleEndian)
-                        {
-                            part = BinaryPrimitives.ReverseEndianness(part);
-                        }
-                        Unsafe.WriteUnaligned(ref address, part);
-                        address = ref Unsafe.Subtract(ref address, sizeof(uint));
-                        i++;
-                    }
-                    if (Unsafe.AreSame(ref address, ref startAddress))
-                    {
-                        Unsafe.WriteUnaligned(ref address, uint.MaxValue);
-                    }
-                    else
-                    {
-                        Debug.Assert(Unsafe.AreSame(ref startAddress, ref Unsafe.Add(ref address, sizeof(uint))));
-                    }
-                }
-                bytesWritten = byteCount;
-                return true;
-            }
-            else
-            {
-                bytesWritten = 0;
-                return false;
-            }
-        }
-        bool IBinaryInteger<BigInteger>.TryWriteLittleEndian(Span<byte> destination, out int bytesWritten)
-        {
-            AssertValid();
-            uint[]? bits = _bits;
-            int byteCount = GetGenericMathByteCount();
-            if (destination.Length >= byteCount)
-            {
-                if (bits is null)
-                {
-                    int value = BitConverter.IsLittleEndian ? _sign : BinaryPrimitives.ReverseEndianness(_sign);
-                    Unsafe.WriteUnaligned(ref MemoryMarshal.GetReference(destination), value);
-                }
-                else if (_sign >= 0)
-                {
-                    ref byte address = ref MemoryMarshal.GetReference(destination);
-                    for (int i = 0; i < bits.Length; i++)
-                    {
-                        uint part = bits[i];
-                        if (!BitConverter.IsLittleEndian)
-                        {
-                            part = BinaryPrimitives.ReverseEndianness(part);
-                        }
-                        Unsafe.WriteUnaligned(ref address, part);
-                        address = ref Unsafe.Add(ref address, sizeof(uint));
-                    }
-                }
-                else
-                {
-                    ref byte address = ref MemoryMarshal.GetReference(destination);
-                    ref byte lastAddress = ref Unsafe.Add(ref address, byteCount - sizeof(uint));
-                    int i = 0;
-                    uint part;
-                    do
-                    {
-                        part = ~bits[i] + 1;
-                        if (!BitConverter.IsLittleEndian)
-                        {
-                            part = BinaryPrimitives.ReverseEndianness(part);
-                        }
-                        Unsafe.WriteUnaligned(ref address, part);
-                        address = ref Unsafe.Add(ref address, sizeof(uint));
-                        i++;
-                    }
-                    while ((part == 0) && (i < bits.Length));
-                    while (i < bits.Length)
-                    {
-                        part = ~bits[i];
-                        if (!BitConverter.IsLittleEndian)
-                        {
-                            part = BinaryPrimitives.ReverseEndianness(part);
-                        }
-                        Unsafe.WriteUnaligned(ref address, part);
-                        address = ref Unsafe.Add(ref address, sizeof(uint));
-                        i++;
-                    }
-                    if (Unsafe.AreSame(ref address, ref lastAddress))
-                    {
-                        Unsafe.WriteUnaligned(ref address, uint.MaxValue);
-                    }
-                    else
-                    {
-                        Debug.Assert(Unsafe.AreSame(ref lastAddress, ref Unsafe.Subtract(ref address, sizeof(uint))));
-                    }
-                }
-                bytesWritten = byteCount;
-                return true;
-            }
-            else
-            {
-                bytesWritten = 0;
-                return false;
-            }
-        }
-        private int GetGenericMathByteCount()
-        {
-            AssertValid();
-            uint[]? bits = _bits;
-            if (bits is null)
-            {
-                return sizeof(int);
-            }
-            int result = bits.Length * 4;
-            if (_sign < 0)
-            {
-                uint part = ~bits[^1] + 1;
-                for (int index = 0; index < bits.Length - 1; index++)
-                {
-                    if (bits[index] != 0)
-                    {
-                        part -= 1;
-                        break;
-                    }
-                }
-                if ((int)part >= 0)
-                {
-                    result += sizeof(uint);
-                }
-            }
-            return result;
-        }
-        static BigInteger IBinaryNumber<BigInteger>.AllBitsSet => MinusOne;
-        public static bool IsPow2(BigInteger value) => value.IsPowerOfTwo;
-        public static BigInteger Log2(BigInteger value)
-        {
-            value.AssertValid();
-            if (IsNegative(value))
-            {
-                ThrowHelper.ThrowValueArgumentOutOfRange_NeedNonNegNumException();
-            }
-            if (value._bits is null)
-            {
-                return 31 ^ uint.LeadingZeroCount((uint)(value._sign | 1));
-            }
-            return ((value._bits.Length * 32) - 1) ^ uint.LeadingZeroCount(value._bits[^1]);
-        }
-        static BigInteger IMultiplicativeIdentity<BigInteger, BigInteger>.MultiplicativeIdentity => One;
-        public static BigInteger Clamp(BigInteger value, BigInteger min, BigInteger max)
-        {
-            value.AssertValid();
-            min.AssertValid();
-            max.AssertValid();
-            if (min > max)
-            {
-                ThrowMinMaxException(min, max);
-            }
-            if (value < min)
-            {
-                return min;
-            }
-            else if (value > max)
-            {
-                return max;
-            }
-            return value;
-            [DoesNotReturn]
-            static void ThrowMinMaxException<T>(T min, T max)
-            {
-                throw new ArgumentException(SR.Format(SR.Argument_MinMaxValue, min, max));
-            }
-        }
-        public static BigInteger CopySign(BigInteger value, BigInteger sign)
-        {
-            value.AssertValid();
-            sign.AssertValid();
-            int currentSign = value._sign;
-            if (value._bits is null)
-            {
-                currentSign = (currentSign >= 0) ? 1 : -1;
-            }
-            int targetSign = sign._sign;
-            if (sign._bits is null)
-            {
-                targetSign = (targetSign >= 0) ? 1 : -1;
-            }
-            return (currentSign == targetSign) ? value : -value;
-        }
-        static BigInteger INumber<BigInteger>.MaxNumber(BigInteger x, BigInteger y) => Max(x, y);
-        static BigInteger INumber<BigInteger>.MinNumber(BigInteger x, BigInteger y) => Min(x, y);
-        static int INumber<BigInteger>.Sign(BigInteger value)
-        {
-            value.AssertValid();
-            if (value._bits is null)
-            {
-                return int.Sign(value._sign);
-            }
-            return value._sign;
-        }
-        static int INumberBase<BigInteger>.Radix => 2;
-        [MethodImpl(MethodImplOptions.AggressiveInlining)]
-        public static BigInteger CreateChecked<TOther>(TOther value)
-            where TOther : INumberBase<TOther>
-        {
-            BigInteger result;
-            if (typeof(TOther) == typeof(BigInteger))
-            {
-                result = (BigInteger)(object)value;
-            }
-            else if (!TryConvertFromChecked(value, out result) && !TOther.TryConvertToChecked(value, out result))
-            {
-                ThrowHelper.ThrowNotSupportedException();
-            }
-            return result;
-        }
-        [MethodImpl(MethodImplOptions.AggressiveInlining)]
-        public static BigInteger CreateSaturating<TOther>(TOther value)
-            where TOther : INumberBase<TOther>
-        {
-            BigInteger result;
-            if (typeof(TOther) == typeof(BigInteger))
-            {
-                result = (BigInteger)(object)value;
-            }
-            else if (!TryConvertFromSaturating(value, out result) && !TOther.TryConvertToSaturating(value, out result))
-            {
-                ThrowHelper.ThrowNotSupportedException();
-            }
-            return result;
-        }
-        [MethodImpl(MethodImplOptions.AggressiveInlining)]
-        public static BigInteger CreateTruncating<TOther>(TOther value)
-            where TOther : INumberBase<TOther>
-        {
-            BigInteger result;
-            if (typeof(TOther) == typeof(BigInteger))
-            {
-                result = (BigInteger)(object)value;
-            }
-            else if (!TryConvertFromTruncating(value, out result) && !TOther.TryConvertToTruncating(value, out result))
-            {
-                ThrowHelper.ThrowNotSupportedException();
-            }
-            return result;
-        }
-        static bool INumberBase<BigInteger>.IsCanonical(BigInteger value) => true;
-        static bool INumberBase<BigInteger>.IsComplexNumber(BigInteger value) => false;
-        public static bool IsEvenInteger(BigInteger value)
-        {
-            value.AssertValid();
-            if (value._bits is null)
-            {
-                return (value._sign & 1) == 0;
-            }
-            return (value._bits[0] & 1) == 0;
-        }
-        static bool INumberBase<BigInteger>.IsFinite(BigInteger value) => true;
-        static bool INumberBase<BigInteger>.IsImaginaryNumber(BigInteger value) => false;
-        static bool INumberBase<BigInteger>.IsInfinity(BigInteger value) => false;
-        static bool INumberBase<BigInteger>.IsInteger(BigInteger value) => true;
-        static bool INumberBase<BigInteger>.IsNaN(BigInteger value) => false;
-        public static bool IsNegative(BigInteger value)
-        {
-            value.AssertValid();
-            return value._sign < 0;
-        }
-        static bool INumberBase<BigInteger>.IsNegativeInfinity(BigInteger value) => false;
-        static bool INumberBase<BigInteger>.IsNormal(BigInteger value) => (value != 0);
-        public static bool IsOddInteger(BigInteger value)
-        {
-            value.AssertValid();
-            if (value._bits is null)
-            {
-                return (value._sign & 1) != 0;
-            }
-            return (value._bits[0] & 1) != 0;
-        }
-        public static bool IsPositive(BigInteger value)
-        {
-            value.AssertValid();
-            return value._sign >= 0;
-        }
-        static bool INumberBase<BigInteger>.IsPositiveInfinity(BigInteger value) => false;
-        static bool INumberBase<BigInteger>.IsRealNumber(BigInteger value) => true;
-        static bool INumberBase<BigInteger>.IsSubnormal(BigInteger value) => false;
-        static bool INumberBase<BigInteger>.IsZero(BigInteger value)
-        {
-            value.AssertValid();
-            return value._sign == 0;
-        }
-        public static BigInteger MaxMagnitude(BigInteger x, BigInteger y)
-        {
-            x.AssertValid();
-            y.AssertValid();
-            BigInteger ax = Abs(x);
-            BigInteger ay = Abs(y);
-            if (ax > ay)
-            {
-                return x;
-            }
-            if (ax == ay)
-            {
-                return IsNegative(x) ? y : x;
-            }
-            return y;
-        }
-        static BigInteger INumberBase<BigInteger>.MaxMagnitudeNumber(BigInteger x, BigInteger y) => MaxMagnitude(x, y);
-        public static BigInteger MinMagnitude(BigInteger x, BigInteger y)
-        {
-            x.AssertValid();
-            y.AssertValid();
-            BigInteger ax = Abs(x);
-            BigInteger ay = Abs(y);
-            if (ax < ay)
-            {
-                return x;
-            }
-            if (ax == ay)
-            {
-                return IsNegative(x) ? x : y;
-            }
-            return y;
-        }
-        static BigInteger INumberBase<BigInteger>.MinMagnitudeNumber(BigInteger x, BigInteger y) => MinMagnitude(x, y);
-        static BigInteger INumberBase<BigInteger>.MultiplyAddEstimate(BigInteger left, BigInteger right, BigInteger addend) => (left * right) + addend;
-        [MethodImpl(MethodImplOptions.AggressiveInlining)]
-        static bool INumberBase<BigInteger>.TryConvertFromChecked<TOther>(TOther value, out BigInteger result) => TryConvertFromChecked(value, out result);
-        [MethodImpl(MethodImplOptions.AggressiveInlining)]
-        private static bool TryConvertFromChecked<TOther>(TOther value, out BigInteger result)
-            where TOther : INumberBase<TOther>
-        {
-            if (typeof(TOther) == typeof(byte))
-            {
-                byte actualValue = (byte)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(char))
-            {
-                char actualValue = (char)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(decimal))
-            {
-                decimal actualValue = (decimal)(object)value;
-                result = (BigInteger)actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(double))
-            {
-                double actualValue = (double)(object)value;
-                result = checked((BigInteger)actualValue);
-                return true;
-            }
-            else if (typeof(TOther) == typeof(Half))
-            {
-                Half actualValue = (Half)(object)value;
-                result = checked((BigInteger)actualValue);
-                return true;
-            }
-            else if (typeof(TOther) == typeof(short))
-            {
-                short actualValue = (short)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(int))
-            {
-                int actualValue = (int)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(long))
-            {
-                long actualValue = (long)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(Int128))
-            {
-                Int128 actualValue = (Int128)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(nint))
-            {
-                nint actualValue = (nint)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(sbyte))
-            {
-                sbyte actualValue = (sbyte)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(float))
-            {
-                float actualValue = (float)(object)value;
-                result = checked((BigInteger)actualValue);
-                return true;
-            }
-            else if (typeof(TOther) == typeof(ushort))
-            {
-                ushort actualValue = (ushort)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(uint))
-            {
-                uint actualValue = (uint)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(ulong))
-            {
-                ulong actualValue = (ulong)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(UInt128))
-            {
-                UInt128 actualValue = (UInt128)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(nuint))
-            {
-                nuint actualValue = (nuint)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else
-            {
-                result = default;
-                return false;
-            }
-        }
-        [MethodImpl(MethodImplOptions.AggressiveInlining)]
-        static bool INumberBase<BigInteger>.TryConvertFromSaturating<TOther>(TOther value, out BigInteger result) => TryConvertFromSaturating(value, out result);
-        [MethodImpl(MethodImplOptions.AggressiveInlining)]
-        private static bool TryConvertFromSaturating<TOther>(TOther value, out BigInteger result)
-            where TOther : INumberBase<TOther>
-        {
-            if (typeof(TOther) == typeof(byte))
-            {
-                byte actualValue = (byte)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(char))
-            {
-                char actualValue = (char)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(decimal))
-            {
-                decimal actualValue = (decimal)(object)value;
-                result = (BigInteger)actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(double))
-            {
-                double actualValue = (double)(object)value;
-                result = double.IsNaN(actualValue) ? Zero : (BigInteger)actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(Half))
-            {
-                Half actualValue = (Half)(object)value;
-                result = Half.IsNaN(actualValue) ? Zero : (BigInteger)actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(short))
-            {
-                short actualValue = (short)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(int))
-            {
-                int actualValue = (int)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(long))
-            {
-                long actualValue = (long)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(Int128))
-            {
-                Int128 actualValue = (Int128)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(nint))
-            {
-                nint actualValue = (nint)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(sbyte))
-            {
-                sbyte actualValue = (sbyte)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(float))
-            {
-                float actualValue = (float)(object)value;
-                result = float.IsNaN(actualValue) ? Zero : (BigInteger)actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(ushort))
-            {
-                ushort actualValue = (ushort)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(uint))
-            {
-                uint actualValue = (uint)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(ulong))
-            {
-                ulong actualValue = (ulong)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(UInt128))
-            {
-                UInt128 actualValue = (UInt128)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(nuint))
-            {
-                nuint actualValue = (nuint)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else
-            {
-                result = default;
-                return false;
-            }
-        }
-        [MethodImpl(MethodImplOptions.AggressiveInlining)]
-        static bool INumberBase<BigInteger>.TryConvertFromTruncating<TOther>(TOther value, out BigInteger result) => TryConvertFromTruncating(value, out result);
-        [MethodImpl(MethodImplOptions.AggressiveInlining)]
-        private static bool TryConvertFromTruncating<TOther>(TOther value, out BigInteger result)
-            where TOther : INumberBase<TOther>
-        {
-            if (typeof(TOther) == typeof(byte))
-            {
-                byte actualValue = (byte)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(char))
-            {
-                char actualValue = (char)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(decimal))
-            {
-                decimal actualValue = (decimal)(object)value;
-                result = (BigInteger)actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(double))
-            {
-                double actualValue = (double)(object)value;
-                result = double.IsNaN(actualValue) ? Zero : (BigInteger)actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(Half))
-            {
-                Half actualValue = (Half)(object)value;
-                result = Half.IsNaN(actualValue) ? Zero : (BigInteger)actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(short))
-            {
-                short actualValue = (short)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(int))
-            {
-                int actualValue = (int)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(long))
-            {
-                long actualValue = (long)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(Int128))
-            {
-                Int128 actualValue = (Int128)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(nint))
-            {
-                nint actualValue = (nint)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(sbyte))
-            {
-                sbyte actualValue = (sbyte)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(float))
-            {
-                float actualValue = (float)(object)value;
-                result = float.IsNaN(actualValue) ? Zero : (BigInteger)actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(ushort))
-            {
-                ushort actualValue = (ushort)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(uint))
-            {
-                uint actualValue = (uint)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(ulong))
-            {
-                ulong actualValue = (ulong)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(UInt128))
-            {
-                UInt128 actualValue = (UInt128)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(nuint))
-            {
-                nuint actualValue = (nuint)(object)value;
-                result = actualValue;
-                return true;
-            }
-            else
-            {
-                result = default;
-                return false;
-            }
-        }
-        [MethodImpl(MethodImplOptions.AggressiveInlining)]
-        static bool INumberBase<BigInteger>.TryConvertToChecked<TOther>(BigInteger value, [MaybeNullWhen(false)] out TOther result)
-        {
-            if (typeof(TOther) == typeof(byte))
-            {
-                byte actualResult = checked((byte)value);
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(char))
-            {
-                char actualResult = checked((char)value);
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(decimal))
-            {
-                decimal actualResult = checked((decimal)value);
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(double))
-            {
-                double actualResult = (double)value;
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(Half))
-            {
-                Half actualResult = (Half)value;
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(short))
-            {
-                short actualResult = checked((short)value);
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(int))
-            {
-                int actualResult = checked((int)value);
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(long))
-            {
-                long actualResult = checked((long)value);
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(Int128))
-            {
-                Int128 actualResult = checked((Int128)value);
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(nint))
-            {
-                nint actualResult = checked((nint)value);
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(Complex))
-            {
-                Complex actualResult = (Complex)value;
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(sbyte))
-            {
-                sbyte actualResult = checked((sbyte)value);
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(float))
-            {
-                float actualResult = checked((float)value);
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(ushort))
-            {
-                ushort actualResult = checked((ushort)value);
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(uint))
-            {
-                uint actualResult = checked((uint)value);
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(ulong))
-            {
-                ulong actualResult = checked((ulong)value);
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(UInt128))
-            {
-                UInt128 actualResult = checked((UInt128)value);
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(nuint))
-            {
-                nuint actualResult = checked((nuint)value);
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else
-            {
-                result = default;
-                return false;
-            }
-        }
-        [MethodImpl(MethodImplOptions.AggressiveInlining)]
-        static bool INumberBase<BigInteger>.TryConvertToSaturating<TOther>(BigInteger value, [MaybeNullWhen(false)] out TOther result)
-        {
-            if (typeof(TOther) == typeof(byte))
-            {
-                byte actualResult;
-                if (value._bits is not null)
-                {
-                    actualResult = IsNegative(value) ? byte.MinValue : byte.MaxValue;
-                }
-                else
-                {
-                    actualResult = (value._sign >= byte.MaxValue) ? byte.MaxValue :
-                                   (value._sign <= byte.MinValue) ? byte.MinValue : (byte)value._sign;
-                }
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(char))
-            {
-                char actualResult;
-                if (value._bits is not null)
-                {
-                    actualResult = IsNegative(value) ? char.MinValue : char.MaxValue;
-                }
-                else
-                {
-                    actualResult = (value._sign >= char.MaxValue) ? char.MaxValue :
-                                   (value._sign <= char.MinValue) ? char.MinValue : (char)value._sign;
-                }
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(decimal))
-            {
-                decimal actualResult = (value >= new Int128(0x0000_0000_FFFF_FFFF, 0xFFFF_FFFF_FFFF_FFFF)) ? decimal.MaxValue :
-                                       (value <= new Int128(0xFFFF_FFFF_0000_0000, 0x0000_0000_0000_0001)) ? decimal.MinValue : (decimal)value;
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(double))
-            {
-                double actualResult = (double)value;
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(Half))
-            {
-                Half actualResult = (Half)value;
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(short))
-            {
-                short actualResult;
-                if (value._bits is not null)
-                {
-                    actualResult = IsNegative(value) ? short.MinValue : short.MaxValue;
-                }
-                else
-                {
-                    actualResult = (value._sign >= short.MaxValue) ? short.MaxValue :
-                                   (value._sign <= short.MinValue) ? short.MinValue : (short)value._sign;
-                }
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(int))
-            {
-                int actualResult;
-                if (value._bits is not null)
-                {
-                    actualResult = IsNegative(value) ? int.MinValue : int.MaxValue;
-                }
-                else
-                {
-                    actualResult = (value._sign >= int.MaxValue) ? int.MaxValue :
-                                   (value._sign <= int.MinValue) ? int.MinValue : (int)value._sign;
-                }
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(long))
-            {
-                long actualResult = (value >= long.MaxValue) ? long.MaxValue :
-                                    (value <= long.MinValue) ? long.MinValue : (long)value;
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(Int128))
-            {
-                Int128 actualResult = (value >= Int128.MaxValue) ? Int128.MaxValue :
-                                      (value <= Int128.MinValue) ? Int128.MinValue : (Int128)value;
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(nint))
-            {
-                nint actualResult = (value >= nint.MaxValue) ? nint.MaxValue :
-                                    (value <= nint.MinValue) ? nint.MinValue : (nint)value;
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(Complex))
-            {
-                Complex actualResult = (Complex)value;
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(sbyte))
-            {
-                sbyte actualResult;
-                if (value._bits is not null)
-                {
-                    actualResult = IsNegative(value) ? sbyte.MinValue : sbyte.MaxValue;
-                }
-                else
-                {
-                    actualResult = (value._sign >= sbyte.MaxValue) ? sbyte.MaxValue :
-                                   (value._sign <= sbyte.MinValue) ? sbyte.MinValue : (sbyte)value._sign;
-                }
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(float))
-            {
-                float actualResult = (float)value;
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(ushort))
-            {
-                ushort actualResult;
-                if (value._bits is not null)
-                {
-                    actualResult = IsNegative(value) ? ushort.MinValue : ushort.MaxValue;
-                }
-                else
-                {
-                    actualResult = (value._sign >= ushort.MaxValue) ? ushort.MaxValue :
-                                   (value._sign <= ushort.MinValue) ? ushort.MinValue : (ushort)value._sign;
-                }
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(uint))
-            {
-                uint actualResult = (value >= uint.MaxValue) ? uint.MaxValue :
-                                    IsNegative(value) ? uint.MinValue : (uint)value;
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(ulong))
-            {
-                ulong actualResult = (value >= ulong.MaxValue) ? ulong.MaxValue :
-                                     IsNegative(value) ? ulong.MinValue : (ulong)value;
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(UInt128))
-            {
-                UInt128 actualResult = (value >= UInt128.MaxValue) ? UInt128.MaxValue :
-                                       IsNegative(value) ? UInt128.MinValue : (UInt128)value;
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(nuint))
-            {
-                nuint actualResult = (value >= nuint.MaxValue) ? nuint.MaxValue :
-                                     IsNegative(value) ? nuint.MinValue : (nuint)value;
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else
-            {
-                result = default;
-                return false;
-            }
-        }
-        [MethodImpl(MethodImplOptions.AggressiveInlining)]
-        static bool INumberBase<BigInteger>.TryConvertToTruncating<TOther>(BigInteger value, [MaybeNullWhen(false)] out TOther result)
-        {
-            if (typeof(TOther) == typeof(byte))
-            {
-                byte actualResult;
-                if (value._bits is not null)
-                {
-                    uint bits = value._bits[0];
-                    if (IsNegative(value))
-                    {
-                        bits = ~bits + 1;
-                    }
-                    actualResult = (byte)bits;
-                }
-                else
-                {
-                    actualResult = (byte)value._sign;
-                }
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(char))
-            {
-                char actualResult;
-                if (value._bits is not null)
-                {
-                    uint bits = value._bits[0];
-                    if (IsNegative(value))
-                    {
-                        bits = ~bits + 1;
-                    }
-                    actualResult = (char)bits;
-                }
-                else
-                {
-                    actualResult = (char)value._sign;
-                }
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(decimal))
-            {
-                decimal actualResult = (value >= new Int128(0x0000_0000_FFFF_FFFF, 0xFFFF_FFFF_FFFF_FFFF)) ? decimal.MaxValue :
-                                       (value <= new Int128(0xFFFF_FFFF_0000_0000, 0x0000_0000_0000_0001)) ? decimal.MinValue : (decimal)value;
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(double))
-            {
-                double actualResult = (double)value;
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(Half))
-            {
-                Half actualResult = (Half)value;
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(short))
-            {
-                short actualResult;
-                if (value._bits is not null)
-                {
-                    actualResult = IsNegative(value) ? (short)(~value._bits[0] + 1) : (short)value._bits[0];
-                }
-                else
-                {
-                    actualResult = (short)value._sign;
-                }
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(int))
-            {
-                int actualResult;
-                if (value._bits is not null)
-                {
-                    actualResult = IsNegative(value) ? (int)(~value._bits[0] + 1) : (int)value._bits[0];
-                }
-                else
-                {
-                    actualResult = value._sign;
-                }
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(long))
-            {
-                long actualResult;
-                if (value._bits is not null)
-                {
-                    ulong bits = 0;
-                    if (value._bits.Length >= 2)
-                    {
-                        bits = value._bits[1];
-                        bits <<= 32;
-                    }
-                    bits |= value._bits[0];
-                    if (IsNegative(value))
-                    {
-                        bits = ~bits + 1;
-                    }
-                    actualResult = (long)bits;
-                }
-                else
-                {
-                    actualResult = value._sign;
-                }
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(Int128))
-            {
-                Int128 actualResult;
-                if (value._bits is not null)
-                {
-                    ulong lowerBits = 0;
-                    ulong upperBits = 0;
-                    if (value._bits.Length >= 4)
-                    {
-                        upperBits = value._bits[3];
-                        upperBits <<= 32;
-                    }
-                    if (value._bits.Length >= 3)
-                    {
-                        upperBits |= value._bits[2];
-                    }
-                    if (value._bits.Length >= 2)
-                    {
-                        lowerBits = value._bits[1];
-                        lowerBits <<= 32;
-                    }
-                    lowerBits |= value._bits[0];
-                    UInt128 bits = new UInt128(upperBits, lowerBits);
-                    if (IsNegative(value))
-                    {
-                        bits = ~bits + 1;
-                    }
-                    actualResult = (Int128)bits;
-                }
-                else
-                {
-                    actualResult = value._sign;
-                }
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(nint))
-            {
-                nint actualResult;
-                if (value._bits is not null)
-                {
-                    nuint bits = 0;
-                    if (Environment.Is64BitProcess && (value._bits.Length >= 2))
-                    {
-                        bits = value._bits[1];
-                        bits <<= 32;
-                    }
-                    bits |= value._bits[0];
-                    if (IsNegative(value))
-                    {
-                        bits = ~bits + 1;
-                    }
-                    actualResult = (nint)bits;
-                }
-                else
-                {
-                    actualResult = value._sign;
-                }
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(Complex))
-            {
-                Complex actualResult = (Complex)value;
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(sbyte))
-            {
-                sbyte actualResult;
-                if (value._bits is not null)
-                {
-                    actualResult = IsNegative(value) ? (sbyte)(~value._bits[0] + 1) : (sbyte)value._bits[0];
-                }
-                else
-                {
-                    actualResult = (sbyte)value._sign;
-                }
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(float))
-            {
-                float actualResult = (float)value;
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(ushort))
-            {
-                ushort actualResult;
-                if (value._bits is not null)
-                {
-                    uint bits = value._bits[0];
-                    if (IsNegative(value))
-                    {
-                        bits = ~bits + 1;
-                    }
-                    actualResult = (ushort)bits;
-                }
-                else
-                {
-                    actualResult = (ushort)value._sign;
-                }
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(uint))
-            {
-                uint actualResult;
-                if (value._bits is not null)
-                {
-                    uint bits = value._bits[0];
-                    if (IsNegative(value))
-                    {
-                        bits = ~bits + 1;
-                    }
-                    actualResult = bits;
-                }
-                else
-                {
-                    actualResult = (uint)value._sign;
-                }
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(ulong))
-            {
-                ulong actualResult;
-                if (value._bits is not null)
-                {
-                    ulong bits = 0;
-                    if (value._bits.Length >= 2)
-                    {
-                        bits = value._bits[1];
-                        bits <<= 32;
-                    }
-                    bits |= value._bits[0];
-                    if (IsNegative(value))
-                    {
-                        bits = ~bits + 1;
-                    }
-                    actualResult = bits;
-                }
-                else
-                {
-                    actualResult = (ulong)value._sign;
-                }
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(UInt128))
-            {
-                UInt128 actualResult;
-                if (value._bits is not null)
-                {
-                    ulong lowerBits = 0;
-                    ulong upperBits = 0;
-                    if (value._bits.Length >= 4)
-                    {
-                        upperBits = value._bits[3];
-                        upperBits <<= 32;
-                    }
-                    if (value._bits.Length >= 3)
-                    {
-                        upperBits |= value._bits[2];
-                    }
-                    if (value._bits.Length >= 2)
-                    {
-                        lowerBits = value._bits[1];
-                        lowerBits <<= 32;
-                    }
-                    lowerBits |= value._bits[0];
-                    UInt128 bits = new UInt128(upperBits, lowerBits);
-                    if (IsNegative(value))
-                    {
-                        bits = ~bits + 1;
-                    }
-                    actualResult = bits;
-                }
-                else
-                {
-                    actualResult = (UInt128)value._sign;
-                }
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else if (typeof(TOther) == typeof(nuint))
-            {
-                nuint actualResult;
-                if (value._bits is not null)
-                {
-                    nuint bits = 0;
-                    if (Environment.Is64BitProcess && (value._bits.Length >= 2))
-                    {
-                        bits = value._bits[1];
-                        bits <<= 32;
-                    }
-                    bits |= value._bits[0];
-                    if (IsNegative(value))
-                    {
-                        bits = ~bits + 1;
-                    }
-                    actualResult = bits;
-                }
-                else
-                {
-                    actualResult = (nuint)value._sign;
-                }
-                result = (TOther)(object)actualResult;
-                return true;
-            }
-            else
-            {
-                result = default;
-                return false;
-            }
-        }
-        public static bool TryParse([NotNullWhen(true)] string? s, IFormatProvider? provider, out BigInteger result) => TryParse(s, NumberStyles.Integer, provider, out result);
-        public static BigInteger operator >>>(BigInteger value, int shiftAmount)
-        {
-            value.AssertValid();
-            if (shiftAmount == 0)
-                return value;
-            if (shiftAmount == int.MinValue)
-                return ((value << int.MaxValue) << 1);
-            if (shiftAmount < 0)
-                return value << -shiftAmount;
-            (int digitShift, int smallShift) = Math.DivRem(shiftAmount, kcbitUint);
-            BigInteger result;
-            uint[]? xdFromPool = null;
-            int xl = value._bits?.Length ?? 1;
-            Span<uint> xd = (xl <= BigIntegerCalculator.StackAllocThreshold
-                          ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                          : xdFromPool = ArrayPool<uint>.Shared.Rent(xl)).Slice(0, xl);
-            bool negx = value.GetPartsForBitManipulation(xd);
-            if (negx)
-            {
-                if (shiftAmount >= ((long)kcbitUint * xd.Length))
-                {
-                    result = MinusOne;
-                    goto exit;
-                }
-                NumericsHelpers.DangerousMakeTwosComplement(xd); // Mutates xd
-            }
-            uint[]? zdFromPool = null;
-            int zl = Math.Max(xl - digitShift, 0);
-            Span<uint> zd = ((uint)zl <= BigIntegerCalculator.StackAllocThreshold
-                          ? stackalloc uint[BigIntegerCalculator.StackAllocThreshold]
-                          : zdFromPool = ArrayPool<uint>.Shared.Rent(zl)).Slice(0, zl);
-            zd.Clear();
-            if (smallShift == 0)
-            {
-                for (int i = xd.Length - 1; i >= digitShift; i--)
-                {
-                    zd[i - digitShift] = xd[i];
-                }
-            }
-            else
-            {
-                int carryShift = kcbitUint - smallShift;
-                uint carry = 0;
-                for (int i = xd.Length - 1; i >= digitShift; i--)
-                {
-                    uint rot = xd[i];
-                    zd[i - digitShift] = (rot >>> smallShift) | carry;
-                    carry = rot << carryShift;
-                }
-            }
-            if (negx && (int)zd[^1] < 0)
-            {
-                NumericsHelpers.DangerousMakeTwosComplement(zd);
-            }
-            else
-            {
-                negx = false;
-            }
-            result = new BigInteger(zd, negx);
-            if (zdFromPool != null)
-                ArrayPool<uint>.Shared.Return(zdFromPool);
-            exit:
-            if (xdFromPool != null)
-                ArrayPool<uint>.Shared.Return(xdFromPool);
-            return result;
-        }
-        static BigInteger ISignedNumber<BigInteger>.NegativeOne => MinusOne;
-        public static BigInteger Parse(ReadOnlySpan<char> s, IFormatProvider? provider) => Parse(s, NumberStyles.Integer, provider);
-        public static bool TryParse(ReadOnlySpan<char> s, IFormatProvider? provider, out BigInteger result) => TryParse(s, NumberStyles.Integer, provider, out result);
-    }
-}

--- a/src/libraries/System.Text.Json/src/System/Text/Json/Schema/JsonSchema.cs
+++ b//dev/null
@@ -1,273 +0,0 @@
-// Licensed to the .NET Foundation under one or more agreements.
-using System.Collections.Generic;
-using System.Diagnostics;
-using System.Text.Json.Nodes;
-namespace System.Text.Json.Schema
-{
-    internal sealed class JsonSchema
-    {
-        internal const string RefPropertyName = "$ref";
-        internal const string CommentPropertyName = "$comment";
-        internal const string TypePropertyName = "type";
-        internal const string FormatPropertyName = "format";
-        internal const string PatternPropertyName = "pattern";
-        internal const string PropertiesPropertyName = "properties";
-        internal const string RequiredPropertyName = "required";
-        internal const string ItemsPropertyName = "items";
-        internal const string AdditionalPropertiesPropertyName = "additionalProperties";
-        internal const string EnumPropertyName = "enum";
-        internal const string NotPropertyName = "not";
-        internal const string AnyOfPropertyName = "anyOf";
-        internal const string ConstPropertyName = "const";
-        internal const string DefaultPropertyName = "default";
-        internal const string MinLengthPropertyName = "minLength";
-        internal const string MaxLengthPropertyName = "maxLength";
-        public static JsonSchema CreateFalseSchema() => new(false);
-        public static JsonSchema CreateTrueSchema() => new(true);
-        public JsonSchema() { }
-        private JsonSchema(bool trueOrFalse) { _trueOrFalse = trueOrFalse; }
-        public bool IsTrue => _trueOrFalse is true;
-        public bool IsFalse => _trueOrFalse is false;
-        private readonly bool? _trueOrFalse;
-        public string? Ref { get => _ref; set { VerifyMutable(); _ref = value; } }
-        private string? _ref;
-        public string? Comment { get => _comment; set { VerifyMutable(); _comment = value; } }
-        private string? _comment;
-        public JsonSchemaType Type { get => _type; set { VerifyMutable(); _type = value; } }
-        private JsonSchemaType _type = JsonSchemaType.Any;
-        public string? Format { get => _format; set { VerifyMutable(); _format = value; } }
-        private string? _format;
-        public string? Pattern { get => _pattern; set { VerifyMutable(); _pattern = value; } }
-        private string? _pattern;
-        public JsonNode? Constant { get => _constant; set { VerifyMutable(); _constant = value; } }
-        private JsonNode? _constant;
-        public List<KeyValuePair<string, JsonSchema>>? Properties { get => _properties; set { VerifyMutable(); _properties = value; } }
-        private List<KeyValuePair<string, JsonSchema>>? _properties;
-        public List<string>? Required { get => _required; set { VerifyMutable(); _required = value; } }
-        private List<string>? _required;
-        public JsonSchema? Items { get => _items; set { VerifyMutable(); _items = value; } }
-        private JsonSchema? _items;
-        public JsonSchema? AdditionalProperties { get => _additionalProperties; set { VerifyMutable(); _additionalProperties = value; } }
-        private JsonSchema? _additionalProperties;
-        public JsonArray? Enum { get => _enum; set { VerifyMutable(); _enum = value; } }
-        private JsonArray? _enum;
-        public JsonSchema? Not { get => _not; set { VerifyMutable(); _not = value; } }
-        private JsonSchema? _not;
-        public List<JsonSchema>? AnyOf { get => _anyOf; set { VerifyMutable(); _anyOf = value; } }
-        private List<JsonSchema>? _anyOf;
-        public bool HasDefaultValue { get => _hasDefaultValue; set { VerifyMutable(); _hasDefaultValue = value; } }
-        private bool _hasDefaultValue;
-        public JsonNode? DefaultValue { get => _defaultValue; set { VerifyMutable(); _defaultValue = value; } }
-        private JsonNode? _defaultValue;
-        public int? MinLength { get => _minLength; set { VerifyMutable(); _minLength = value; } }
-        private int? _minLength;
-        public int? MaxLength { get => _maxLength; set { VerifyMutable(); _maxLength = value; } }
-        private int? _maxLength;
-        public JsonSchemaExporterContext? ExporterContext { get; set; }
-        public int KeywordCount
-        {
-            get
-            {
-                if (_trueOrFalse != null)
-                {
-                    return 0;
-                }
-                int count = 0;
-                Count(Ref != null);
-                Count(Comment != null);
-                Count(Type != JsonSchemaType.Any);
-                Count(Format != null);
-                Count(Pattern != null);
-                Count(Constant != null);
-                Count(Properties != null);
-                Count(Required != null);
-                Count(Items != null);
-                Count(AdditionalProperties != null);
-                Count(Enum != null);
-                Count(Not != null);
-                Count(AnyOf != null);
-                Count(HasDefaultValue);
-                Count(MinLength != null);
-                Count(MaxLength != null);
-                return count;
-                void Count(bool isKeywordSpecified)
-                {
-                    count += isKeywordSpecified ? 1 : 0;
-                }
-            }
-        }
-        public void MakeNullable()
-        {
-            if (_trueOrFalse != null)
-            {
-                return;
-            }
-            if (Type != JsonSchemaType.Any)
-            {
-                Type |= JsonSchemaType.Null;
-            }
-        }
-        public JsonNode ToJsonNode(JsonSchemaExporterOptions options)
-        {
-            if (_trueOrFalse is { } boolSchema)
-            {
-                return CompleteSchema((JsonNode)boolSchema);
-            }
-            var objSchema = new JsonObject();
-            if (Ref != null)
-            {
-                objSchema.Add(RefPropertyName, Ref);
-            }
-            if (Comment != null)
-            {
-                objSchema.Add(CommentPropertyName, Comment);
-            }
-            if (MapSchemaType(Type) is JsonNode type)
-            {
-                objSchema.Add(TypePropertyName, type);
-            }
-            if (Format != null)
-            {
-                objSchema.Add(FormatPropertyName, Format);
-            }
-            if (Pattern != null)
-            {
-                objSchema.Add(PatternPropertyName, Pattern);
-            }
-            if (Constant != null)
-            {
-                objSchema.Add(ConstPropertyName, Constant);
-            }
-            if (Properties != null)
-            {
-                var properties = new JsonObject();
-                foreach (KeyValuePair<string, JsonSchema> property in Properties)
-                {
-                    properties.Add(property.Key, property.Value.ToJsonNode(options));
-                }
-                objSchema.Add(PropertiesPropertyName, properties);
-            }
-            if (Required != null)
-            {
-                var requiredArray = new JsonArray();
-                foreach (string requiredProperty in Required)
-                {
-                    requiredArray.Add((JsonNode)requiredProperty);
-                }
-                objSchema.Add(RequiredPropertyName, requiredArray);
-            }
-            if (Items != null)
-            {
-                objSchema.Add(ItemsPropertyName, Items.ToJsonNode(options));
-            }
-            if (AdditionalProperties != null)
-            {
-                objSchema.Add(AdditionalPropertiesPropertyName, AdditionalProperties.ToJsonNode(options));
-            }
-            if (Enum != null)
-            {
-                objSchema.Add(EnumPropertyName, Enum);
-            }
-            if (Not != null)
-            {
-                objSchema.Add(NotPropertyName, Not.ToJsonNode(options));
-            }
-            if (AnyOf != null)
-            {
-                JsonArray anyOfArray = [];
-                foreach (JsonSchema schema in AnyOf)
-                {
-                    anyOfArray.Add(schema.ToJsonNode(options));
-                }
-                objSchema.Add(AnyOfPropertyName, anyOfArray);
-            }
-            if (HasDefaultValue)
-            {
-                objSchema.Add(DefaultPropertyName, DefaultValue);
-            }
-            if (MinLength is int minLength)
-            {
-                objSchema.Add(MinLengthPropertyName, (JsonNode)minLength);
-            }
-            if (MaxLength is int maxLength)
-            {
-                objSchema.Add(MaxLengthPropertyName, (JsonNode)maxLength);
-            }
-            return CompleteSchema(objSchema);
-            JsonNode CompleteSchema(JsonNode schema)
-            {
-                if (ExporterContext is { } context)
-                {
-                    Debug.Assert(options.TransformSchemaNode != null, "context should only be populated if a callback is present.");
-                    return options.TransformSchemaNode(context, schema);
-                }
-                return schema;
-            }
-        }
-        public static void EnsureMutable(ref JsonSchema schema)
-        {
-            switch (schema._trueOrFalse)
-            {
-                case false:
-                    schema = new JsonSchema { Not = CreateTrueSchema() };
-                    break;
-                case true:
-                    schema = new JsonSchema();
-                    break;
-            }
-        }
-        private static ReadOnlySpan<JsonSchemaType> s_schemaValues =>
-        [
-            JsonSchemaType.String,
-            JsonSchemaType.Integer,
-            JsonSchemaType.Number,
-            JsonSchemaType.Boolean,
-            JsonSchemaType.Array,
-            JsonSchemaType.Object,
-            JsonSchemaType.Null,
-        ];
-        private void VerifyMutable()
-        {
-            Debug.Assert(_trueOrFalse is null, "Schema is not mutable");
-            if (_trueOrFalse is not null)
-            {
-                Throw();
-                static void Throw() => throw new InvalidOperationException();
-            }
-        }
-        public static JsonNode? MapSchemaType(JsonSchemaType schemaType)
-        {
-            if (schemaType is JsonSchemaType.Any)
-            {
-                return null;
-            }
-            if (ToIdentifier(schemaType) is string identifier)
-            {
-                return identifier;
-            }
-            var array = new JsonArray();
-            foreach (JsonSchemaType type in s_schemaValues)
-            {
-                if ((schemaType & type) != 0)
-                {
-                    array.Add((JsonNode)ToIdentifier(type)!);
-                }
-            }
-            return array;
-            static string? ToIdentifier(JsonSchemaType schemaType)
-            {
-                return schemaType switch
-                {
-                    JsonSchemaType.Null => "null",
-                    JsonSchemaType.Boolean => "boolean",
-                    JsonSchemaType.Integer => "integer",
-                    JsonSchemaType.Number => "number",
-                    JsonSchemaType.String => "string",
-                    JsonSchemaType.Array => "array",
-                    JsonSchemaType.Object => "object",
-                    _ => null,
-                };
-            }
-        }
-    }
-}

--- a/src/libraries/System.Text.Json/src/System/Text/Json/Schema/JsonSchemaExporter.cs
+++ b//dev/null
@@ -1,385 +0,0 @@
-// Licensed to the .NET Foundation under one or more agreements.
-using System.Collections.Generic;
-using System.Diagnostics;
-using System.Diagnostics.CodeAnalysis;
-using System.Globalization;
-using System.Runtime.InteropServices;
-using System.Text.Json.Nodes;
-using System.Text.Json.Serialization;
-using System.Text.Json.Serialization.Metadata;
-namespace System.Text.Json.Schema
-{
-    public static class JsonSchemaExporter
-    {
-        public static JsonNode GetJsonSchemaAsNode(this JsonSerializerOptions options, Type type, JsonSchemaExporterOptions? exporterOptions = null)
-        {
-            if (options is null)
-            {
-                ThrowHelper.ThrowArgumentNullException(nameof(options));
-            }
-            if (type is null)
-            {
-                ThrowHelper.ThrowArgumentNullException(nameof(type));
-            }
-            ValidateOptions(options);
-            JsonTypeInfo typeInfo = options.GetTypeInfoInternal(type);
-            return typeInfo.GetJsonSchemaAsNode(exporterOptions);
-        }
-        public static JsonNode GetJsonSchemaAsNode(this JsonTypeInfo typeInfo, JsonSchemaExporterOptions? exporterOptions = null)
-        {
-            if (typeInfo is null)
-            {
-                ThrowHelper.ThrowArgumentNullException(nameof(typeInfo));
-            }
-            ValidateOptions(typeInfo.Options);
-            exporterOptions ??= JsonSchemaExporterOptions.Default;
-            typeInfo.EnsureConfigured();
-            GenerationState state = new(typeInfo.Options, exporterOptions);
-            JsonSchema schema = MapJsonSchemaCore(ref state, typeInfo);
-            return schema.ToJsonNode(exporterOptions);
-        }
-        private static JsonSchema MapJsonSchemaCore(
-            ref GenerationState state,
-            JsonTypeInfo typeInfo,
-            JsonPropertyInfo? propertyInfo = null,
-            JsonConverter? customConverter = null,
-            JsonNumberHandling? customNumberHandling = null,
-            JsonTypeInfo? parentPolymorphicTypeInfo = null,
-            bool parentPolymorphicTypeContainsTypesWithoutDiscriminator = false,
-            bool parentPolymorphicTypeIsNonNullable = false,
-            KeyValuePair<string, JsonSchema>? typeDiscriminator = null,
-            bool cacheResult = true)
-        {
-            Debug.Assert(typeInfo.IsConfigured);
-            JsonSchemaExporterContext exporterContext = state.CreateContext(typeInfo, propertyInfo, parentPolymorphicTypeInfo);
-            if (cacheResult && typeInfo.Kind is not JsonTypeInfoKind.None &&
-                state.TryGetExistingJsonPointer(exporterContext, out string? existingJsonPointer))
-            {
-                return CompleteSchema(ref state, new JsonSchema { Ref = existingJsonPointer });
-            }
-            JsonConverter effectiveConverter = customConverter ?? typeInfo.Converter;
-            JsonNumberHandling effectiveNumberHandling = customNumberHandling ?? typeInfo.NumberHandling ?? typeInfo.Options.NumberHandling;
-            if (effectiveConverter.GetSchema(effectiveNumberHandling) is { } schema)
-            {
-                return CompleteSchema(ref state, schema);
-            }
-            if (parentPolymorphicTypeInfo is null && typeInfo.PolymorphismOptions is { DerivedTypes.Count: > 0 } polyOptions)
-            {
-                string typeDiscriminatorKey = polyOptions.TypeDiscriminatorPropertyName;
-                List<JsonDerivedType> derivedTypes = new(polyOptions.DerivedTypes);
-                if (!typeInfo.Type.IsAbstract && !IsPolymorphicTypeThatSpecifiesItselfAsDerivedType(typeInfo))
-                {
-                    derivedTypes.Add(new JsonDerivedType(typeInfo.Type));
-                }
-                bool containsTypesWithoutDiscriminator = derivedTypes.Exists(static derivedTypes => derivedTypes.TypeDiscriminator is null);
-                JsonSchemaType schemaType = JsonSchemaType.Any;
-                List<JsonSchema>? anyOf = new(derivedTypes.Count);
-                state.PushSchemaNode(JsonSchema.AnyOfPropertyName);
-                foreach (JsonDerivedType derivedType in derivedTypes)
-                {
-                    Debug.Assert(derivedType.TypeDiscriminator is null or int or string);
-                    KeyValuePair<string, JsonSchema>? derivedTypeDiscriminator = null;
-                    if (derivedType.TypeDiscriminator is { } discriminatorValue)
-                    {
-                        JsonNode discriminatorNode = discriminatorValue switch
-                        {
-                            string stringId => (JsonNode)stringId,
-                            _ => (JsonNode)(int)discriminatorValue,
-                        };
-                        JsonSchema discriminatorSchema = new() { Constant = discriminatorNode };
-                        derivedTypeDiscriminator = new(typeDiscriminatorKey, discriminatorSchema);
-                    }
-                    JsonTypeInfo derivedTypeInfo = typeInfo.Options.GetTypeInfoInternal(derivedType.DerivedType);
-                    state.PushSchemaNode(anyOf.Count.ToString(CultureInfo.InvariantCulture));
-                    JsonSchema derivedSchema = MapJsonSchemaCore(
-                        ref state,
-                        derivedTypeInfo,
-                        parentPolymorphicTypeInfo: typeInfo,
-                        typeDiscriminator: derivedTypeDiscriminator,
-                        parentPolymorphicTypeContainsTypesWithoutDiscriminator: containsTypesWithoutDiscriminator,
-                        parentPolymorphicTypeIsNonNullable: propertyInfo is { IsGetNullable: false, IsSetNullable: false },
-                        cacheResult: false);
-                    state.PopSchemaNode();
-                    if (anyOf.Count == 0)
-                    {
-                        schemaType = derivedSchema.Type;
-                    }
-                    else if (schemaType != derivedSchema.Type)
-                    {
-                        schemaType = JsonSchemaType.Any;
-                    }
-                    anyOf.Add(derivedSchema);
-                }
-                state.PopSchemaNode();
-                if (schemaType is not JsonSchemaType.Any)
-                {
-                    foreach (JsonSchema derivedSchema in anyOf)
-                    {
-                        derivedSchema.Type = JsonSchemaType.Any;
-                        if (derivedSchema.KeywordCount == 0)
-                        {
-                            anyOf = null;
-                            break;
-                        }
-                    }
-                }
-                return CompleteSchema(ref state, new()
-                {
-                    Type = schemaType,
-                    AnyOf = anyOf,
-                    Required = containsTypesWithoutDiscriminator ? null : [typeDiscriminatorKey]
-                });
-            }
-            if (effectiveConverter.NullableElementConverter is { } elementConverter)
-            {
-                JsonTypeInfo elementTypeInfo = typeInfo.Options.GetTypeInfo(elementConverter.Type!);
-                schema = MapJsonSchemaCore(ref state, elementTypeInfo, customConverter: elementConverter, cacheResult: false);
-                if (schema.Enum != null)
-                {
-                    Debug.Assert(elementTypeInfo.Type.IsEnum, "The enum keyword should only be populated by schemas for enum types.");
-                    schema.Enum.Add(null); // Append null to the enum array.
-                }
-                return CompleteSchema(ref state, schema);
-            }
-            switch (typeInfo.Kind)
-            {
-                case JsonTypeInfoKind.Object:
-                    List<KeyValuePair<string, JsonSchema>>? properties = null;
-                    List<string>? required = null;
-                    JsonSchema? additionalProperties = null;
-                    JsonUnmappedMemberHandling effectiveUnmappedMemberHandling = typeInfo.UnmappedMemberHandling ?? typeInfo.Options.UnmappedMemberHandling;
-                    if (effectiveUnmappedMemberHandling is JsonUnmappedMemberHandling.Disallow)
-                    {
-                        additionalProperties = JsonSchema.CreateFalseSchema();
-                    }
-                    if (typeDiscriminator is { } typeDiscriminatorPair)
-                    {
-                        (properties ??= []).Add(typeDiscriminatorPair);
-                        if (parentPolymorphicTypeContainsTypesWithoutDiscriminator)
-                        {
-                            (required ??= []).Add(typeDiscriminatorPair.Key);
-                        }
-                    }
-                    state.PushSchemaNode(JsonSchema.PropertiesPropertyName);
-                    foreach (JsonPropertyInfo property in typeInfo.Properties)
-                    {
-                        if (property is { Get: null, Set: null } or { IsExtensionData: true })
-                        {
-                            continue; // Skip JsonIgnored properties and extension data
-                        }
-                        state.PushSchemaNode(property.Name);
-                        JsonSchema propertySchema = MapJsonSchemaCore(
-                            ref state,
-                            property.JsonTypeInfo,
-                            propertyInfo: property,
-                            customConverter: property.EffectiveConverter,
-                            customNumberHandling: property.EffectiveNumberHandling);
-                        state.PopSchemaNode();
-                        if (property.AssociatedParameter is { HasDefaultValue: true } parameterInfo)
-                        {
-                            JsonSchema.EnsureMutable(ref propertySchema);
-                            propertySchema.DefaultValue = JsonSerializer.SerializeToNode(parameterInfo.DefaultValue, property.JsonTypeInfo);
-                            propertySchema.HasDefaultValue = true;
-                        }
-                        (properties ??= []).Add(new(property.Name, propertySchema));
-                        if (property is { IsRequired: true } or { AssociatedParameter.IsRequiredParameter: true })
-                        {
-                            (required ??= []).Add(property.Name);
-                        }
-                    }
-                    state.PopSchemaNode();
-                    return CompleteSchema(ref state, new()
-                    {
-                        Type = JsonSchemaType.Object,
-                        Properties = properties,
-                        Required = required,
-                        AdditionalProperties = additionalProperties,
-                    });
-                case JsonTypeInfoKind.Enumerable:
-                    Debug.Assert(typeInfo.ElementTypeInfo != null);
-                    if (typeDiscriminator is null)
-                    {
-                        state.PushSchemaNode(JsonSchema.ItemsPropertyName);
-                        JsonSchema items = MapJsonSchemaCore(ref state, typeInfo.ElementTypeInfo, customNumberHandling: effectiveNumberHandling);
-                        state.PopSchemaNode();
-                        return CompleteSchema(ref state, new()
-                        {
-                            Type = JsonSchemaType.Array,
-                            Items = items.IsTrue ? null : items,
-                        });
-                    }
-                    else
-                    {
-                        const string ValuesKeyword = JsonSerializer.ValuesPropertyName;
-                        state.PushSchemaNode(JsonSchema.PropertiesPropertyName);
-                        state.PushSchemaNode(ValuesKeyword);
-                        state.PushSchemaNode(JsonSchema.ItemsPropertyName);
-                        JsonSchema items = MapJsonSchemaCore(ref state, typeInfo.ElementTypeInfo, customNumberHandling: effectiveNumberHandling);
-                        state.PopSchemaNode();
-                        state.PopSchemaNode();
-                        state.PopSchemaNode();
-                        return CompleteSchema(ref state, new()
-                        {
-                            Type = JsonSchemaType.Object,
-                            Properties =
-                            [
-                                typeDiscriminator.Value,
-                                new(ValuesKeyword,
-                                    new JsonSchema()
-                                    {
-                                        Type = JsonSchemaType.Array,
-                                        Items = items.IsTrue ? null : items,
-                                    }),
-                            ],
-                            Required = parentPolymorphicTypeContainsTypesWithoutDiscriminator ? [typeDiscriminator.Value.Key] : null,
-                        });
-                    }
-                case JsonTypeInfoKind.Dictionary:
-                    Debug.Assert(typeInfo.ElementTypeInfo != null);
-                    List<KeyValuePair<string, JsonSchema>>? dictProps = null;
-                    List<string>? dictRequired = null;
-                    if (typeDiscriminator is { } dictDiscriminator)
-                    {
-                        dictProps = [dictDiscriminator];
-                        if (parentPolymorphicTypeContainsTypesWithoutDiscriminator)
-                        {
-                            dictRequired = [dictDiscriminator.Key];
-                        }
-                    }
-                    state.PushSchemaNode(JsonSchema.AdditionalPropertiesPropertyName);
-                    JsonSchema valueSchema = MapJsonSchemaCore(ref state, typeInfo.ElementTypeInfo, customNumberHandling: effectiveNumberHandling);
-                    state.PopSchemaNode();
-                    return CompleteSchema(ref state, new()
-                    {
-                        Type = JsonSchemaType.Object,
-                        Properties = dictProps,
-                        Required = dictRequired,
-                        AdditionalProperties = valueSchema.IsTrue ? null : valueSchema,
-                    });
-                default:
-                    Debug.Assert(typeInfo.Kind is JsonTypeInfoKind.None);
-                    return CompleteSchema(ref state, JsonSchema.CreateTrueSchema());
-            }
-            JsonSchema CompleteSchema(ref GenerationState state, JsonSchema schema)
-            {
-                if (schema.Ref is null)
-                {
-                    bool isNullableSchema = propertyInfo != null
-                        ? propertyInfo.IsGetNullable || propertyInfo.IsSetNullable
-                        : typeInfo.CanBeNull && !parentPolymorphicTypeIsNonNullable && !state.ExporterOptions.TreatNullObliviousAsNonNullable;
-                    if (isNullableSchema)
-                    {
-                        schema.MakeNullable();
-                    }
-                }
-                if (state.ExporterOptions.TransformSchemaNode != null)
-                {
-                    schema.ExporterContext = exporterContext;
-                }
-                return schema;
-            }
-        }
-        private static void ValidateOptions(JsonSerializerOptions options)
-        {
-            if (options.ReferenceHandler == ReferenceHandler.Preserve)
-            {
-                ThrowHelper.ThrowNotSupportedException_JsonSchemaExporterDoesNotSupportReferenceHandlerPreserve();
-            }
-            options.MakeReadOnly();
-        }
-        private static bool IsPolymorphicTypeThatSpecifiesItselfAsDerivedType(JsonTypeInfo typeInfo)
-        {
-            Debug.Assert(typeInfo.PolymorphismOptions is not null);
-            foreach (JsonDerivedType derivedType in typeInfo.PolymorphismOptions.DerivedTypes)
-            {
-                if (derivedType.DerivedType == typeInfo.Type)
-                {
-                    return true;
-                }
-            }
-            return false;
-        }
-        private readonly ref struct GenerationState(JsonSerializerOptions options, JsonSchemaExporterOptions exporterOptions)
-        {
-            private readonly List<string> _currentPath = [];
-            private readonly Dictionary<(JsonTypeInfo, JsonPropertyInfo?), string[]> _generated = new();
-            public int CurrentDepth => _currentPath.Count;
-            public JsonSerializerOptions Options { get; } = options;
-            public JsonSchemaExporterOptions ExporterOptions { get; } = exporterOptions;
-            public void PushSchemaNode(string nodeId)
-            {
-                if (CurrentDepth == Options.EffectiveMaxDepth)
-                {
-                    ThrowHelper.ThrowInvalidOperationException_JsonSchemaExporterDepthTooLarge();
-                }
-                _currentPath.Add(nodeId);
-            }
-            public void PopSchemaNode()
-            {
-                Debug.Assert(CurrentDepth > 0);
-                _currentPath.RemoveAt(_currentPath.Count - 1);
-            }
-            public bool TryGetExistingJsonPointer(in JsonSchemaExporterContext context, [NotNullWhen(true)] out string? existingJsonPointer)
-            {
-                (JsonTypeInfo TypeInfo, JsonPropertyInfo? PropertyInfo) key = (context.TypeInfo, context.PropertyInfo);
-#if NET
-                ref string[]? pathToSchema = ref CollectionsMarshal.GetValueRefOrAddDefault(_generated, key, out bool exists);
-#else
-                bool exists = _generated.TryGetValue(key, out string[]? pathToSchema);
-#endif
-                if (exists)
-                {
-                    existingJsonPointer = FormatJsonPointer(pathToSchema);
-                    return true;
-                }
-#if NET
-                pathToSchema = context._path;
-#else
-                _generated[key] = context._path;
-#endif
-                existingJsonPointer = null;
-                return false;
-            }
-            public JsonSchemaExporterContext CreateContext(JsonTypeInfo typeInfo, JsonPropertyInfo? propertyInfo, JsonTypeInfo? baseTypeInfo)
-            {
-                return new JsonSchemaExporterContext(typeInfo, propertyInfo, baseTypeInfo, [.. _currentPath]);
-            }
-            private static string FormatJsonPointer(ReadOnlySpan<string> path)
-            {
-                if (path.IsEmpty)
-                {
-                    return "#";
-                }
-                using ValueStringBuilder sb = new(initialCapacity: path.Length * 10);
-                sb.Append('#');
-                foreach (string segment in path)
-                {
-                    ReadOnlySpan<char> span = segment.AsSpan();
-                    sb.Append('/');
-                    do
-                    {
-                        int pos = span.IndexOfAny('~', '/');
-                        if (pos < 0)
-                        {
-                            sb.Append(span);
-                            break;
-                        }
-                        sb.Append(span.Slice(0, pos));
-                        if (span[pos] == '~')
-                        {
-                            sb.Append("~0");
-                        }
-                        else
-                        {
-                            Debug.Assert(span[pos] == '/');
-                            sb.Append("~1");
-                        }
-                        span = span.Slice(pos + 1);
-                    }
-                    while (!span.IsEmpty);
-                }
-                return sb.ToString();
-            }
-        }
-    }
-}

--- a/src/libraries/System.Text.Json/src/System/Text/Json/Serialization/Converters/Node/JsonNodeConverter.cs
+++ b//dev/null
@@ -1,71 +0,0 @@
-// Licensed to the .NET Foundation under one or more agreements.
-using System.Diagnostics;
-using System.Text.Json.Nodes;
-using System.Text.Json.Schema;
-using System.Text.Json.Serialization.Metadata;
-namespace System.Text.Json.Serialization.Converters
-{
-    internal sealed class JsonNodeConverter : JsonConverter<JsonNode?>
-    {
-        private static JsonNodeConverter? s_nodeConverter;
-        private static JsonArrayConverter? s_arrayConverter;
-        private static JsonObjectConverter? s_objectConverter;
-        private static JsonValueConverter? s_valueConverter;
-        public static JsonNodeConverter Instance => s_nodeConverter ??= new JsonNodeConverter();
-        public static JsonArrayConverter ArrayConverter => s_arrayConverter ??= new JsonArrayConverter();
-        public static JsonObjectConverter ObjectConverter => s_objectConverter ??= new JsonObjectConverter();
-        public static JsonValueConverter ValueConverter => s_valueConverter ??= new JsonValueConverter();
-        public override void Write(Utf8JsonWriter writer, JsonNode? value, JsonSerializerOptions options)
-        {
-            if (value is null)
-            {
-                writer.WriteNullValue();
-            }
-            else
-            {
-                value.WriteTo(writer, options);
-            }
-        }
-        public override JsonNode? Read(ref Utf8JsonReader reader, Type typeToConvert, JsonSerializerOptions options)
-        {
-            switch (reader.TokenType)
-            {
-                case JsonTokenType.String:
-                case JsonTokenType.False:
-                case JsonTokenType.True:
-                case JsonTokenType.Number:
-                    return ValueConverter.Read(ref reader, typeToConvert, options);
-                case JsonTokenType.StartObject:
-                    return ObjectConverter.Read(ref reader, typeToConvert, options);
-                case JsonTokenType.StartArray:
-                    return ArrayConverter.Read(ref reader, typeToConvert, options);
-                case JsonTokenType.Null:
-                    return null;
-                default:
-                    Debug.Assert(false);
-                    throw new JsonException();
-            }
-        }
-        public static JsonNode? Create(JsonElement element, JsonNodeOptions? options)
-        {
-            JsonNode? node;
-            switch (element.ValueKind)
-            {
-                case JsonValueKind.Null:
-                    node = null;
-                    break;
-                case JsonValueKind.Object:
-                    node = new JsonObject(element, options);
-                    break;
-                case JsonValueKind.Array:
-                    node = new JsonArray(element, options);
-                    break;
-                default:
-                    node = new JsonValueOfElement(element, options);
-                    break;
-            }
-            return node;
-        }
-        internal override JsonSchema? GetSchema(JsonNumberHandling _) => JsonSchema.CreateTrueSchema();
-    }
-}

--- a/src/libraries/System.Text.Json/src/System/Text/Json/Serialization/Converters/Node/JsonValueConverter.cs
+++ b//dev/null
@@ -1,29 +0,0 @@
-// Licensed to the .NET Foundation under one or more agreements.
-using System.Text.Json.Nodes;
-using System.Text.Json.Schema;
-using System.Text.Json.Serialization.Metadata;
-namespace System.Text.Json.Serialization.Converters
-{
-    internal sealed class JsonValueConverter : JsonConverter<JsonValue?>
-    {
-        public override void Write(Utf8JsonWriter writer, JsonValue? value, JsonSerializerOptions options)
-        {
-            if (value is null)
-            {
-                writer.WriteNullValue();
-                return;
-            }
-            value.WriteTo(writer, options);
-        }
-        public override JsonValue? Read(ref Utf8JsonReader reader, Type typeToConvert, JsonSerializerOptions options)
-        {
-            if (reader.TokenType is JsonTokenType.Null)
-            {
-                return null;
-            }
-            JsonElement element = JsonElement.ParseValue(ref reader);
-            return JsonValue.CreateFromElement(ref element, options.GetNodeOptions());
-        }
-        internal override JsonSchema? GetSchema(JsonNumberHandling _) => JsonSchema.CreateTrueSchema();
-    }
-}

--- a/src/libraries/System.Text.Json/src/System/Text/Json/Serialization/Converters/Object/ObjectConverter.cs
+++ b//dev/null
@@ -1,111 +0,0 @@
-using System.Diagnostics;
-using System.Text.Json.Nodes;
-using System.Text.Json.Schema;
-using System.Text.Json.Serialization.Metadata;
-namespace System.Text.Json.Serialization.Converters
-{
-    internal abstract class ObjectConverter : JsonConverter<object?>
-    {
-        private protected override ConverterStrategy GetDefaultConverterStrategy() => ConverterStrategy.Object;
-        public ObjectConverter()
-        {
-            CanBePolymorphic = true;
-        }
-        public sealed override object ReadAsPropertyName(ref Utf8JsonReader reader, Type typeToConvert, JsonSerializerOptions options)
-        {
-            ThrowHelper.ThrowNotSupportedException_DictionaryKeyTypeNotSupported(Type, this);
-            return null!;
-        }
-        internal sealed override object ReadAsPropertyNameCore(ref Utf8JsonReader reader, Type typeToConvert, JsonSerializerOptions options)
-        {
-            ThrowHelper.ThrowNotSupportedException_DictionaryKeyTypeNotSupported(Type, this);
-            return null!;
-        }
-        public sealed override void Write(Utf8JsonWriter writer, object? value, JsonSerializerOptions options)
-        {
-            if (value is null)
-            {
-                writer.WriteNullValue();
-                return;
-            }
-            writer.WriteStartObject();
-            writer.WriteEndObject();
-        }
-        public sealed override void WriteAsPropertyName(Utf8JsonWriter writer, object value, JsonSerializerOptions options)
-        {
-            WriteAsPropertyNameCore(writer, value, options, isWritingExtensionDataProperty: false);
-        }
-        internal sealed override void WriteAsPropertyNameCore(Utf8JsonWriter writer, object value, JsonSerializerOptions options, bool isWritingExtensionDataProperty)
-        {
-            if (value is null)
-            {
-                ThrowHelper.ThrowArgumentNullException(nameof(value));
-            }
-            Type runtimeType = value.GetType();
-            if (runtimeType == Type)
-            {
-                ThrowHelper.ThrowNotSupportedException_DictionaryKeyTypeNotSupported(runtimeType, this);
-            }
-            JsonConverter runtimeConverter = options.GetConverterInternal(runtimeType);
-            runtimeConverter.WriteAsPropertyNameCoreAsObject(writer, value, options, isWritingExtensionDataProperty);
-        }
-    }
-    internal sealed class SlimObjectConverter : ObjectConverter
-    {
-        private readonly IJsonTypeInfoResolver _originatingResolver;
-        public SlimObjectConverter(IJsonTypeInfoResolver originatingResolver)
-            => _originatingResolver = originatingResolver;
-        public override object? Read(ref Utf8JsonReader reader, Type typeToConvert, JsonSerializerOptions options)
-        {
-            ThrowHelper.ThrowNotSupportedException_NoMetadataForType(typeToConvert, _originatingResolver);
-            return null;
-        }
-    }
-    internal sealed class DefaultObjectConverter : ObjectConverter
-    {
-        public DefaultObjectConverter()
-        {
-            RequiresReadAhead = true;
-        }
-        public override object? Read(ref Utf8JsonReader reader, Type typeToConvert, JsonSerializerOptions options)
-        {
-            if (options.UnknownTypeHandling == JsonUnknownTypeHandling.JsonElement)
-            {
-                return JsonElement.ParseValue(ref reader);
-            }
-            Debug.Assert(options.UnknownTypeHandling == JsonUnknownTypeHandling.JsonNode);
-            return JsonNodeConverter.Instance.Read(ref reader, typeToConvert, options);
-        }
-        internal override bool OnTryRead(ref Utf8JsonReader reader, Type typeToConvert, JsonSerializerOptions options, scoped ref ReadStack state, out object? value)
-        {
-            object? referenceValue;
-            if (options.UnknownTypeHandling == JsonUnknownTypeHandling.JsonElement)
-            {
-                JsonElement element = JsonElement.ParseValue(ref reader);
-                if (options.ReferenceHandlingStrategy == ReferenceHandlingStrategy.Preserve &&
-                    JsonSerializer.TryHandleReferenceFromJsonElement(ref reader, ref state, element, out referenceValue))
-                {
-                    value = referenceValue;
-                }
-                else
-                {
-                    value = element;
-                }
-                return true;
-            }
-            Debug.Assert(options.UnknownTypeHandling == JsonUnknownTypeHandling.JsonNode);
-            JsonNode? node = JsonNodeConverter.Instance.Read(ref reader, typeToConvert, options);
-            if (options.ReferenceHandlingStrategy == ReferenceHandlingStrategy.Preserve &&
-                JsonSerializer.TryHandleReferenceFromJsonNode(ref reader, ref state, node, out referenceValue))
-            {
-                value = referenceValue;
-            }
-            else
-            {
-                value = node;
-            }
-            return true;
-        }
-        internal override JsonSchema? GetSchema(JsonNumberHandling _) => JsonSchema.CreateTrueSchema();
-    }
-}

--- a/src/libraries/System.Text.Json/src/System/Text/Json/Serialization/Converters/Value/JsonDocumentConverter.cs
+++ b//dev/null
@@ -1,23 +0,0 @@
-using System.Text.Json.Schema;
-using System.Text.Json.Nodes;
-namespace System.Text.Json.Serialization.Converters
-{
-    internal sealed class JsonDocumentConverter : JsonConverter<JsonDocument?>
-    {
-        public override bool HandleNull => true;
-        public override JsonDocument Read(ref Utf8JsonReader reader, Type typeToConvert, JsonSerializerOptions options)
-        {
-            return JsonDocument.ParseValue(ref reader);
-        }
-        public override void Write(Utf8JsonWriter writer, JsonDocument? value, JsonSerializerOptions options)
-        {
-            if (value is null)
-            {
-                writer.WriteNullValue();
-                return;
-            }
-            value.WriteTo(writer);
-        }
-        internal override JsonSchema? GetSchema(JsonNumberHandling _) => JsonSchema.CreateTrueSchema();
-    }
-}

--- a/src/libraries/System.Text.Json/src/System/Text/Json/Serialization/Converters/Value/JsonElementConverter.cs
+++ b//dev/null
@@ -1,17 +0,0 @@
-using System.Text.Json.Schema;
-using System.Text.Json.Nodes;
-namespace System.Text.Json.Serialization.Converters
-{
-    internal sealed class JsonElementConverter : JsonConverter<JsonElement>
-    {
-        public override JsonElement Read(ref Utf8JsonReader reader, Type typeToConvert, JsonSerializerOptions options)
-        {
-            return JsonElement.ParseValue(ref reader);
-        }
-        public override void Write(Utf8JsonWriter writer, JsonElement value, JsonSerializerOptions options)
-        {
-            value.WriteTo(writer);
-        }
-        internal override JsonSchema? GetSchema(JsonNumberHandling _) => JsonSchema.CreateTrueSchema();
-    }
-}

--- a/src/libraries/System.Text.Json/src/System/Text/Json/Serialization/Converters/Value/UnsupportedTypeConverter.cs
+++ b//dev/null
@@ -1,17 +0,0 @@
-using System.Text.Json.Schema;
-using System.Text.Json.Nodes;
-namespace System.Text.Json.Serialization.Converters
-{
-    internal sealed class UnsupportedTypeConverter<T> : JsonConverter<T>
-    {
-        private readonly string? _errorMessage;
-        public UnsupportedTypeConverter(string? errorMessage = null) => _errorMessage = errorMessage;
-        public string ErrorMessage => _errorMessage ?? SR.Format(SR.SerializeTypeInstanceNotSupported, typeof(T).FullName);
-        public override T Read(ref Utf8JsonReader reader, Type typeToConvert, JsonSerializerOptions options) =>
-            throw new NotSupportedException(ErrorMessage);
-        public override void Write(Utf8JsonWriter writer, T value, JsonSerializerOptions options) =>
-            throw new NotSupportedException(ErrorMessage);
-        internal override JsonSchema? GetSchema(JsonNumberHandling _) =>
-            new JsonSchema { Comment = "Unsupported .NET type", Not = JsonSchema.CreateTrueSchema() };
-    }
-}

--- a/src/libraries/System.Text.Json/src/System/Text/Json/Serialization/Metadata/JsonTypeInfo.cs
+++ b//dev/null
@@ -1,873 +0,0 @@
-using System.Collections.Generic;
-using System.ComponentModel;
-using System.Diagnostics;
-using System.Diagnostics.CodeAnalysis;
-using System.IO;
-using System.IO.Pipelines;
-using System.Reflection;
-using System.Runtime.CompilerServices;
-using System.Runtime.ExceptionServices;
-using System.Text.Json.Reflection;
-using System.Text.Json.Serialization.Converters;
-using System.Threading;
-using System.Threading.Tasks;
-namespace System.Text.Json.Serialization.Metadata
-{
-    [DebuggerDisplay("{DebuggerDisplay,nq}")]
-    public abstract partial class JsonTypeInfo
-    {
-        internal const string MetadataFactoryRequiresUnreferencedCode = "JSON serialization and deserialization might require types that cannot be statically analyzed and might need runtime code generation. Use System.Text.Json source generation for native AOT applications.";
-        internal const string JsonObjectTypeName = "System.Text.Json.Nodes.JsonObject";
-        internal delegate T ParameterizedConstructorDelegate<T, TArg0, TArg1, TArg2, TArg3>(TArg0? arg0, TArg1? arg1, TArg2? arg2, TArg3? arg3);
-        internal int NumberOfRequiredProperties { get; private set; }
-        private Action<object>? _onSerializing;
-        private Action<object>? _onSerialized;
-        private Action<object>? _onDeserializing;
-        private Action<object>? _onDeserialized;
-        internal JsonTypeInfo(Type type, JsonConverter converter, JsonSerializerOptions options)
-        {
-            Type = type;
-            Options = options;
-            Converter = converter;
-            Kind = GetTypeInfoKind(type, converter);
-            PropertyInfoForTypeInfo = CreatePropertyInfoForTypeInfo();
-            ElementType = converter.ElementType;
-            KeyType = converter.KeyType;
-        }
-        public Type? ElementType { get; }
-        public Type? KeyType { get; }
-        public Func<object>? CreateObject
-        {
-            get => _createObject;
-            set
-            {
-                SetCreateObject(value);
-            }
-        }
-        private protected abstract void SetCreateObject(Delegate? createObject);
-        private protected Func<object>? _createObject;
-        internal Func<object>? CreateObjectForExtensionDataProperty { get; set; }
-        public Action<object>? OnSerializing
-        {
-            get => _onSerializing;
-            set
-            {
-                VerifyMutable();
-                if (Kind is not (JsonTypeInfoKind.Object or JsonTypeInfoKind.Enumerable or JsonTypeInfoKind.Dictionary))
-                {
-                    ThrowHelper.ThrowInvalidOperationException_JsonTypeInfoOperationNotPossibleForKind(Kind);
-                }
-                _onSerializing = value;
-            }
-        }
-        public Action<object>? OnSerialized
-        {
-            get => _onSerialized;
-            set
-            {
-                VerifyMutable();
-                if (Kind is not (JsonTypeInfoKind.Object or JsonTypeInfoKind.Enumerable or JsonTypeInfoKind.Dictionary))
-                {
-                    ThrowHelper.ThrowInvalidOperationException_JsonTypeInfoOperationNotPossibleForKind(Kind);
-                }
-                _onSerialized = value;
-            }
-        }
-        public Action<object>? OnDeserializing
-        {
-            get => _onDeserializing;
-            set
-            {
-                VerifyMutable();
-                if (Kind is not (JsonTypeInfoKind.Object or JsonTypeInfoKind.Enumerable or JsonTypeInfoKind.Dictionary))
-                {
-                    ThrowHelper.ThrowInvalidOperationException_JsonTypeInfoOperationNotPossibleForKind(Kind);
-                }
-                if (Converter.IsConvertibleCollection)
-                {
-                    ThrowHelper.ThrowInvalidOperationException_JsonTypeInfoOnDeserializingCallbacksNotSupported(Type);
-                }
-                _onDeserializing = value;
-            }
-        }
-        public Action<object>? OnDeserialized
-        {
-            get => _onDeserialized;
-            set
-            {
-                VerifyMutable();
-                if (Kind is not (JsonTypeInfoKind.Object or JsonTypeInfoKind.Enumerable or JsonTypeInfoKind.Dictionary))
-                {
-                    ThrowHelper.ThrowInvalidOperationException_JsonTypeInfoOperationNotPossibleForKind(Kind);
-                }
-                _onDeserialized = value;
-            }
-        }
-        public IList<JsonPropertyInfo> Properties => PropertyList;
-        [DebuggerBrowsable(DebuggerBrowsableState.Never)]
-        internal JsonPropertyInfoList PropertyList
-        {
-            get
-            {
-                return _properties ?? CreatePropertyList();
-                JsonPropertyInfoList CreatePropertyList()
-                {
-                    var list = new JsonPropertyInfoList(this);
-                    if (_sourceGenDelayedPropertyInitializer is { } propInit)
-                    {
-                        JsonMetadataServices.PopulateProperties(this, list, propInit);
-                    }
-                    JsonPropertyInfoList? result = Interlocked.CompareExchange(ref _properties, list, null);
-                    _sourceGenDelayedPropertyInitializer = null;
-                    return result ?? list;
-                }
-            }
-        }
-        internal Func<JsonSerializerContext, JsonPropertyInfo[]>? SourceGenDelayedPropertyInitializer
-        {
-            get => _sourceGenDelayedPropertyInitializer;
-            set
-            {
-                Debug.Assert(!IsReadOnly);
-                Debug.Assert(_properties is null, "must not be set if a property list has been initialized.");
-                _sourceGenDelayedPropertyInitializer = value;
-            }
-        }
-        private Func<JsonSerializerContext, JsonPropertyInfo[]>? _sourceGenDelayedPropertyInitializer;
-        private JsonPropertyInfoList? _properties;
-        public JsonPolymorphismOptions? PolymorphismOptions
-        {
-            get => _polymorphismOptions;
-            set
-            {
-                VerifyMutable();
-                if (value != null)
-                {
-                    if (Kind == JsonTypeInfoKind.None)
-                    {
-                        ThrowHelper.ThrowInvalidOperationException_JsonTypeInfoOperationNotPossibleForKind(Kind);
-                    }
-                    if (value.DeclaringTypeInfo != null && value.DeclaringTypeInfo != this)
-                    {
-                        ThrowHelper.ThrowArgumentException_JsonPolymorphismOptionsAssociatedWithDifferentJsonTypeInfo(nameof(value));
-                    }
-                    value.DeclaringTypeInfo = this;
-                }
-                _polymorphismOptions = value;
-            }
-        }
-        public bool IsReadOnly { get; private set; }
-        public void MakeReadOnly() => IsReadOnly = true;
-        private protected JsonPolymorphismOptions? _polymorphismOptions;
-        internal object? CreateObjectWithArgs { get; set; }
-        internal object? AddMethodDelegate { get; set; }
-        internal JsonPropertyInfo? ExtensionDataProperty { get; private set; }
-        internal PolymorphicTypeResolver? PolymorphicTypeResolver { get; private set; }
-        internal bool HasSerializeHandler { get; private protected set; }
-        internal bool CanUseSerializeHandler { get; private set; }
-        internal bool PropertyMetadataSerializationNotSupported { get; set; }
-        internal bool IsNullable => Converter.NullableElementConverter is not null;
-        internal bool CanBeNull => PropertyInfoForTypeInfo.PropertyTypeCanBeNull;
-        [MethodImpl(MethodImplOptions.AggressiveInlining)]
-        internal void ValidateCanBeUsedForPropertyMetadataSerialization()
-        {
-            if (PropertyMetadataSerializationNotSupported)
-            {
-                ThrowHelper.ThrowInvalidOperationException_NoMetadataForTypeProperties(Options.TypeInfoResolver, Type);
-            }
-        }
-        [DebuggerBrowsable(DebuggerBrowsableState.Never)]
-        internal JsonTypeInfo? ElementTypeInfo
-        {
-            get
-            {
-                Debug.Assert(IsConfigured);
-                Debug.Assert(_elementTypeInfo is null or { IsConfigurationStarted: true });
-                JsonTypeInfo? elementTypeInfo = _elementTypeInfo;
-                elementTypeInfo?.EnsureConfigured();
-                return elementTypeInfo;
-            }
-            set
-            {
-                Debug.Assert(!IsReadOnly);
-                Debug.Assert(value is null || value.Type == ElementType);
-                _elementTypeInfo = value;
-            }
-        }
-        [DebuggerBrowsable(DebuggerBrowsableState.Never)]
-        internal JsonTypeInfo? KeyTypeInfo
-        {
-            get
-            {
-                Debug.Assert(IsConfigured);
-                Debug.Assert(_keyTypeInfo is null or { IsConfigurationStarted: true });
-                JsonTypeInfo? keyTypeInfo = _keyTypeInfo;
-                keyTypeInfo?.EnsureConfigured();
-                return keyTypeInfo;
-            }
-            set
-            {
-                Debug.Assert(!IsReadOnly);
-                Debug.Assert(value is null || value.Type == KeyType);
-                _keyTypeInfo = value;
-            }
-        }
-        private JsonTypeInfo? _elementTypeInfo;
-        private JsonTypeInfo? _keyTypeInfo;
-        public JsonSerializerOptions Options { get; }
-        public Type Type { get; }
-        public JsonConverter Converter { get; }
-        public JsonTypeInfoKind Kind { get; }
-        internal JsonPropertyInfo PropertyInfoForTypeInfo { get; }
-        private protected abstract JsonPropertyInfo CreatePropertyInfoForTypeInfo();
-        public JsonNumberHandling? NumberHandling
-        {
-            get => _numberHandling;
-            set
-            {
-                VerifyMutable();
-                if (value is not null && !JsonSerializer.IsValidNumberHandlingValue(value.Value))
-                {
-                    throw new ArgumentOutOfRangeException(nameof(value));
-                }
-                _numberHandling = value;
-            }
-        }
-        internal JsonNumberHandling EffectiveNumberHandling => _numberHandling ?? Options.NumberHandling;
-        private JsonNumberHandling? _numberHandling;
-        public JsonUnmappedMemberHandling? UnmappedMemberHandling
-        {
-            get => _unmappedMemberHandling;
-            set
-            {
-                VerifyMutable();
-                if (Kind != JsonTypeInfoKind.Object)
-                {
-                    ThrowHelper.ThrowInvalidOperationException_JsonTypeInfoOperationNotPossibleForKind(Kind);
-                }
-                if (value is not null && !JsonSerializer.IsValidUnmappedMemberHandlingValue(value.Value))
-                {
-                    throw new ArgumentOutOfRangeException(nameof(value));
-                }
-                _unmappedMemberHandling = value;
-            }
-        }
-        private JsonUnmappedMemberHandling? _unmappedMemberHandling;
-        internal JsonUnmappedMemberHandling EffectiveUnmappedMemberHandling { get; private set; }
-        private JsonObjectCreationHandling? _preferredPropertyObjectCreationHandling;
-        public JsonObjectCreationHandling? PreferredPropertyObjectCreationHandling
-        {
-            get => _preferredPropertyObjectCreationHandling;
-            set
-            {
-                VerifyMutable();
-                if (Kind != JsonTypeInfoKind.Object)
-                {
-                    ThrowHelper.ThrowInvalidOperationException_JsonTypeInfoOperationNotPossibleForKind(Kind);
-                }
-                if (value is not null && !JsonSerializer.IsValidCreationHandlingValue(value.Value))
-                {
-                    throw new ArgumentOutOfRangeException(nameof(value));
-                }
-                _preferredPropertyObjectCreationHandling = value;
-            }
-        }
-        [EditorBrowsable(EditorBrowsableState.Never)]
-        public IJsonTypeInfoResolver? OriginatingResolver
-        {
-            get => _originatingResolver;
-            set
-            {
-                VerifyMutable();
-                if (value is JsonSerializerContext)
-                {
-                    IsCustomized = false;
-                }
-                _originatingResolver = value;
-            }
-        }
-        private IJsonTypeInfoResolver? _originatingResolver;
-        public ICustomAttributeProvider? ConstructorAttributeProvider
-        {
-            get
-            {
-                Func<ICustomAttributeProvider>? ctorAttrProviderFactory = Volatile.Read(ref ConstructorAttributeProviderFactory);
-                ICustomAttributeProvider? ctorAttrProvider = _constructorAttributeProvider;
-                if (ctorAttrProvider is null && ctorAttrProviderFactory is not null)
-                {
-                    _constructorAttributeProvider = ctorAttrProvider = ctorAttrProviderFactory();
-                    Volatile.Write(ref ConstructorAttributeProviderFactory, null);
-                }
-                return ctorAttrProvider;
-            }
-            internal set
-            {
-                Debug.Assert(!IsReadOnly);
-                _constructorAttributeProvider = value;
-                Volatile.Write(ref ConstructorAttributeProviderFactory, null);
-            }
-        }
-        internal Func<ICustomAttributeProvider>? ConstructorAttributeProviderFactory;
-        private ICustomAttributeProvider? _constructorAttributeProvider;
-        internal void VerifyMutable()
-        {
-            if (IsReadOnly)
-            {
-                ThrowHelper.ThrowInvalidOperationException_TypeInfoImmutable();
-            }
-            IsCustomized = true;
-        }
-        internal bool IsCustomized { get; set; } = true;
-        internal bool IsConfigured => _configurationState == ConfigurationState.Configured;
-        internal bool IsConfigurationStarted => _configurationState is not ConfigurationState.NotConfigured;
-        private volatile ConfigurationState _configurationState;
-        private enum ConfigurationState : byte
-        {
-            NotConfigured = 0,
-            Configuring = 1,
-            Configured = 2
-        };
-        private ExceptionDispatchInfo? _cachedConfigureError;
-        internal void EnsureConfigured()
-        {
-            if (!IsConfigured)
-                ConfigureSynchronized();
-            void ConfigureSynchronized()
-            {
-                Options.MakeReadOnly();
-                MakeReadOnly();
-                _cachedConfigureError?.Throw();
-                lock (Options.CacheContext)
-                {
-                    if (_configurationState != ConfigurationState.NotConfigured)
-                    {
-                        return;
-                    }
-                    _cachedConfigureError?.Throw();
-                    try
-                    {
-                        _configurationState = ConfigurationState.Configuring;
-                        Configure();
-                        _configurationState = ConfigurationState.Configured;
-                    }
-                    catch (Exception e)
-                    {
-                        _cachedConfigureError = ExceptionDispatchInfo.Capture(e);
-                        _configurationState = ConfigurationState.NotConfigured;
-                        throw;
-                    }
-                }
-            }
-        }
-        private void Configure()
-        {
-            Debug.Assert(Monitor.IsEntered(Options.CacheContext), "Configure called directly, use EnsureConfigured which synchronizes access to this method");
-            Debug.Assert(Options.IsReadOnly);
-            Debug.Assert(IsReadOnly);
-            PropertyInfoForTypeInfo.Configure();
-            if (PolymorphismOptions != null)
-            {
-                PolymorphicTypeResolver = new PolymorphicTypeResolver(Options, PolymorphismOptions, Type, Converter.CanHaveMetadata);
-            }
-            if (Kind == JsonTypeInfoKind.Object)
-            {
-                ConfigureProperties();
-                if (DetermineUsesParameterizedConstructor())
-                {
-                    ConfigureConstructorParameters();
-                }
-            }
-            if (ElementType != null)
-            {
-                _elementTypeInfo ??= Options.GetTypeInfoInternal(ElementType);
-                _elementTypeInfo.EnsureConfigured();
-            }
-            if (KeyType != null)
-            {
-                _keyTypeInfo ??= Options.GetTypeInfoInternal(KeyType);
-                _keyTypeInfo.EnsureConfigured();
-            }
-            DetermineIsCompatibleWithCurrentOptions();
-            CanUseSerializeHandler = HasSerializeHandler && IsCompatibleWithCurrentOptions;
-        }
-        [DebuggerBrowsable(DebuggerBrowsableState.Never)]
-        internal JsonTypeInfo? AncestorPolymorphicType
-        {
-            get
-            {
-                Debug.Assert(IsConfigured);
-                Debug.Assert(Type != typeof(object));
-                if (!_isAncestorPolymorphicTypeResolved)
-                {
-                    _ancestorPolymorhicType = PolymorphicTypeResolver.FindNearestPolymorphicBaseType(this);
-                    _isAncestorPolymorphicTypeResolved = true;
-                }
-                return _ancestorPolymorhicType;
-            }
-        }
-        private JsonTypeInfo? _ancestorPolymorhicType;
-        private volatile bool _isAncestorPolymorphicTypeResolved;
-        private void DetermineIsCompatibleWithCurrentOptions()
-        {
-            Debug.Assert(IsReadOnly);
-            Debug.Assert(!IsConfigured);
-            if (!IsCurrentNodeCompatible())
-            {
-                IsCompatibleWithCurrentOptions = false;
-                return;
-            }
-            if (_properties != null)
-            {
-                foreach (JsonPropertyInfo property in _properties)
-                {
-                    Debug.Assert(property.IsConfigured);
-                    if (!property.IsPropertyTypeInfoConfigured)
-                    {
-                        continue;
-                    }
-                    if (!property.JsonTypeInfo.IsCompatibleWithCurrentOptions)
-                    {
-                        IsCompatibleWithCurrentOptions = false;
-                        return;
-                    }
-                }
-            }
-            if (_elementTypeInfo?.IsCompatibleWithCurrentOptions == false ||
-                _keyTypeInfo?.IsCompatibleWithCurrentOptions == false)
-            {
-                IsCompatibleWithCurrentOptions = false;
-                return;
-            }
-            Debug.Assert(IsCompatibleWithCurrentOptions);
-            bool IsCurrentNodeCompatible()
-            {
-                if (IsCustomized)
-                {
-                    return false;
-                }
-                if (Options.CanUseFastPathSerializationLogic)
-                {
-                    return true;
-                }
-                return OriginatingResolver.IsCompatibleWithOptions(Options);
-            }
-        }
-        private bool IsCompatibleWithCurrentOptions { get; set; } = true;
-        internal bool DetermineUsesParameterizedConstructor()
-            => Converter.ConstructorIsParameterized && CreateObject is null;
-        [RequiresUnreferencedCode(MetadataFactoryRequiresUnreferencedCode)]
-        [RequiresDynamicCode(MetadataFactoryRequiresUnreferencedCode)]
-        public static JsonTypeInfo<T> CreateJsonTypeInfo<T>(JsonSerializerOptions options)
-        {
-            if (options == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(nameof(options));
-            }
-            JsonConverter converter = DefaultJsonTypeInfoResolver.GetConverterForType(typeof(T), options, resolveJsonConverterAttribute: false);
-            return new JsonTypeInfo<T>(converter, options);
-        }
-        [RequiresUnreferencedCode(MetadataFactoryRequiresUnreferencedCode)]
-        [RequiresDynamicCode(MetadataFactoryRequiresUnreferencedCode)]
-        public static JsonTypeInfo CreateJsonTypeInfo(Type type, JsonSerializerOptions options)
-        {
-            if (type == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(nameof(type));
-            }
-            if (options == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(nameof(options));
-            }
-            if (IsInvalidForSerialization(type))
-            {
-                ThrowHelper.ThrowArgumentException_CannotSerializeInvalidType(nameof(type), type, null, null);
-            }
-            JsonConverter converter = DefaultJsonTypeInfoResolver.GetConverterForType(type, options, resolveJsonConverterAttribute: false);
-            return CreateJsonTypeInfo(type, converter, options);
-        }
-        [RequiresUnreferencedCode(MetadataFactoryRequiresUnreferencedCode)]
-        [RequiresDynamicCode(MetadataFactoryRequiresUnreferencedCode)]
-        internal static JsonTypeInfo CreateJsonTypeInfo(Type type, JsonConverter converter, JsonSerializerOptions options)
-        {
-            JsonTypeInfo jsonTypeInfo;
-            if (converter.Type == type)
-            {
-                jsonTypeInfo = converter.CreateJsonTypeInfo(options);
-            }
-            else
-            {
-                Type jsonTypeInfoType = typeof(JsonTypeInfo<>).MakeGenericType(type);
-                jsonTypeInfo = (JsonTypeInfo)jsonTypeInfoType.CreateInstanceNoWrapExceptions(
-                    parameterTypes: [typeof(JsonConverter), typeof(JsonSerializerOptions)],
-                    parameters: new object[] { converter, options })!;
-            }
-            Debug.Assert(jsonTypeInfo.Type == type);
-            return jsonTypeInfo;
-        }
-        [RequiresUnreferencedCode(MetadataFactoryRequiresUnreferencedCode)]
-        [RequiresDynamicCode(MetadataFactoryRequiresUnreferencedCode)]
-        public JsonPropertyInfo CreateJsonPropertyInfo(Type propertyType, string name)
-        {
-            if (propertyType == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(nameof(propertyType));
-            }
-            if (name == null)
-            {
-                ThrowHelper.ThrowArgumentNullException(nameof(name));
-            }
-            if (IsInvalidForSerialization(propertyType))
-            {
-                ThrowHelper.ThrowArgumentException_CannotSerializeInvalidType(nameof(propertyType), propertyType, Type, name);
-            }
-            VerifyMutable();
-            JsonPropertyInfo propertyInfo = CreatePropertyUsingReflection(propertyType, declaringType: null);
-            propertyInfo.Name = name;
-            return propertyInfo;
-        }
-        [RequiresDynamicCode(JsonSerializer.SerializationRequiresDynamicCodeMessage)]
-        [RequiresUnreferencedCode(JsonSerializer.SerializationUnreferencedCodeMessage)]
-        internal JsonPropertyInfo CreatePropertyUsingReflection(Type propertyType, Type? declaringType)
-        {
-            JsonPropertyInfo jsonPropertyInfo;
-            if (Options.TryGetTypeInfoCached(propertyType, out JsonTypeInfo? jsonTypeInfo))
-            {
-                jsonPropertyInfo = jsonTypeInfo.CreateJsonPropertyInfo(declaringTypeInfo: this, declaringType, Options);
-            }
-            else
-            {
-                Type propertyInfoType = typeof(JsonPropertyInfo<>).MakeGenericType(propertyType);
-                jsonPropertyInfo = (JsonPropertyInfo)propertyInfoType.CreateInstanceNoWrapExceptions(
-                    parameterTypes: [typeof(Type), typeof(JsonTypeInfo), typeof(JsonSerializerOptions)],
-                    parameters: new object[] { declaringType ?? Type, this, Options })!;
-            }
-            Debug.Assert(jsonPropertyInfo.PropertyType == propertyType);
-            return jsonPropertyInfo;
-        }
-        private protected abstract JsonPropertyInfo CreateJsonPropertyInfo(JsonTypeInfo declaringTypeInfo, Type? declaringType, JsonSerializerOptions options);
-        private protected Dictionary<ParameterLookupKey, JsonParameterInfoValues>? _parameterInfoValuesIndex;
-        internal abstract void SerializeAsObject(Utf8JsonWriter writer, object? rootValue);
-        internal abstract Task SerializeAsObjectAsync(PipeWriter pipeWriter, object? rootValue, int flushThreshold, CancellationToken cancellationToken);
-        internal abstract Task SerializeAsObjectAsync(Stream utf8Json, object? rootValue, CancellationToken cancellationToken);
-        internal abstract Task SerializeAsObjectAsync(PipeWriter utf8Json, object? rootValue, CancellationToken cancellationToken);
-        internal abstract void SerializeAsObject(Stream utf8Json, object? rootValue);
-        internal abstract object? DeserializeAsObject(ref Utf8JsonReader reader, ref ReadStack state);
-        internal abstract ValueTask<object?> DeserializeAsObjectAsync(Stream utf8Json, CancellationToken cancellationToken);
-        internal abstract object? DeserializeAsObject(Stream utf8Json);
-        internal ref struct PropertyHierarchyResolutionState(JsonSerializerOptions options)
-        {
-            public Dictionary<string, (JsonPropertyInfo, int index)> AddedProperties = new(options.PropertyNameCaseInsensitive ? StringComparer.OrdinalIgnoreCase : StringComparer.Ordinal);
-            public Dictionary<string, JsonPropertyInfo>? IgnoredProperties;
-            public bool IsPropertyOrderSpecified;
-        }
-        private protected readonly struct ParameterLookupKey(Type type, string name) : IEquatable<ParameterLookupKey>
-        {
-            public Type Type { get; } = type;
-            public string Name { get; } = name;
-            public override int GetHashCode() => StringComparer.OrdinalIgnoreCase.GetHashCode(Name);
-            public bool Equals(ParameterLookupKey other) => Type == other.Type && string.Equals(Name, other.Name, StringComparison.OrdinalIgnoreCase);
-            public override bool Equals([NotNullWhen(true)] object? obj) => obj is ParameterLookupKey key && Equals(key);
-        }
-        internal void ConfigureProperties()
-        {
-            Debug.Assert(Kind == JsonTypeInfoKind.Object);
-            Debug.Assert(_propertyCache is null);
-            Debug.Assert(_propertyIndex is null);
-            Debug.Assert(ExtensionDataProperty is null);
-            JsonPropertyInfoList properties = PropertyList;
-            StringComparer comparer = Options.PropertyNameCaseInsensitive ? StringComparer.OrdinalIgnoreCase : StringComparer.Ordinal;
-            Dictionary<string, JsonPropertyInfo> propertyIndex = new(properties.Count, comparer);
-            List<JsonPropertyInfo> propertyCache = new(properties.Count);
-            int numberOfRequiredProperties = 0;
-            bool arePropertiesSorted = true;
-            int previousPropertyOrder = int.MinValue;
-            foreach (JsonPropertyInfo property in properties)
-            {
-                Debug.Assert(property.DeclaringTypeInfo == this);
-                if (property.IsExtensionData)
-                {
-                    if (UnmappedMemberHandling is JsonUnmappedMemberHandling.Disallow)
-                    {
-                        ThrowHelper.ThrowInvalidOperationException_ExtensionDataConflictsWithUnmappedMemberHandling(Type, property);
-                    }
-                    if (ExtensionDataProperty != null)
-                    {
-                        ThrowHelper.ThrowInvalidOperationException_SerializationDuplicateTypeAttribute(Type, typeof(JsonExtensionDataAttribute));
-                    }
-                    ExtensionDataProperty = property;
-                }
-                else
-                {
-                    if (property.IsRequired)
-                    {
-                        property.RequiredPropertyIndex = numberOfRequiredProperties++;
-                    }
-                    if (arePropertiesSorted)
-                    {
-                        arePropertiesSorted = previousPropertyOrder <= property.Order;
-                        previousPropertyOrder = property.Order;
-                    }
-                    if (!propertyIndex.TryAdd(property.Name, property))
-                    {
-                        ThrowHelper.ThrowInvalidOperationException_SerializerPropertyNameConflict(Type, property.Name);
-                    }
-                    propertyCache.Add(property);
-                }
-                property.Configure();
-            }
-            if (!arePropertiesSorted)
-            {
-                properties.SortProperties();
-                propertyCache.StableSortByKey(static propInfo => propInfo.Order);
-            }
-            NumberOfRequiredProperties = numberOfRequiredProperties;
-            _propertyCache = propertyCache.ToArray();
-            _propertyIndex = propertyIndex;
-            EffectiveUnmappedMemberHandling = UnmappedMemberHandling ??
-                (ExtensionDataProperty is null
-                    ? Options.UnmappedMemberHandling
-                    : JsonUnmappedMemberHandling.Skip);
-        }
-        internal void PopulateParameterInfoValues(JsonParameterInfoValues[] parameterInfoValues)
-        {
-            if (parameterInfoValues.Length == 0)
-            {
-                return;
-            }
-            Dictionary<ParameterLookupKey, JsonParameterInfoValues> parameterIndex = new(parameterInfoValues.Length);
-            foreach (JsonParameterInfoValues parameterInfoValue in parameterInfoValues)
-            {
-                ParameterLookupKey paramKey = new(parameterInfoValue.ParameterType, parameterInfoValue.Name);
-                parameterIndex.TryAdd(paramKey, parameterInfoValue); // Ignore conflicts since they are reported at serialization time.
-            }
-            ParameterCount = parameterInfoValues.Length;
-            _parameterInfoValuesIndex = parameterIndex;
-        }
-        internal void ResolveMatchingParameterInfo(JsonPropertyInfo propertyInfo)
-        {
-            Debug.Assert(
-                CreateObjectWithArgs is null || _parameterInfoValuesIndex is not null,
-                "Metadata with parameterized constructors must have populated parameter info metadata.");
-            if (_parameterInfoValuesIndex is not { } index)
-            {
-                return;
-            }
-            string propertyName = propertyInfo.MemberName ?? propertyInfo.Name;
-            ParameterLookupKey propKey = new(propertyInfo.PropertyType, propertyName);
-            if (index.TryGetValue(propKey, out JsonParameterInfoValues? matchingParameterInfoValues))
-            {
-                propertyInfo.AddJsonParameterInfo(matchingParameterInfoValues);
-            }
-        }
-        internal void ConfigureConstructorParameters()
-        {
-            Debug.Assert(Kind == JsonTypeInfoKind.Object);
-            Debug.Assert(DetermineUsesParameterizedConstructor());
-            Debug.Assert(_propertyCache is not null);
-            Debug.Assert(_parameterCache is null);
-            List<JsonParameterInfo> parameterCache = new(ParameterCount);
-            Dictionary<ParameterLookupKey, JsonParameterInfo> parameterIndex = new(ParameterCount);
-            foreach (JsonPropertyInfo propertyInfo in _propertyCache)
-            {
-                JsonParameterInfo? parameterInfo = propertyInfo.AssociatedParameter;
-                if (parameterInfo is null)
-                {
-                    continue;
-                }
-                string propertyName = propertyInfo.MemberName ?? propertyInfo.Name;
-                ParameterLookupKey paramKey = new(propertyInfo.PropertyType, propertyName);
-                if (!parameterIndex.TryAdd(paramKey, parameterInfo))
-                {
-                    ThrowHelper.ThrowInvalidOperationException_MultiplePropertiesBindToConstructorParameters(
-                        Type,
-                        parameterInfo.Name,
-                        propertyInfo.Name,
-                        parameterIndex[paramKey].MatchingProperty.Name);
-                }
-                parameterCache.Add(parameterInfo);
-            }
-            if (ExtensionDataProperty is { AssociatedParameter: not null })
-            {
-                Debug.Assert(ExtensionDataProperty.MemberName != null, "Custom property info cannot be data extension property");
-                ThrowHelper.ThrowInvalidOperationException_ExtensionDataCannotBindToCtorParam(ExtensionDataProperty.MemberName, ExtensionDataProperty);
-            }
-            _parameterCache = parameterCache.ToArray();
-            _parameterInfoValuesIndex = null;
-        }
-        internal static void ValidateType(Type type)
-        {
-            if (IsInvalidForSerialization(type))
-            {
-                ThrowHelper.ThrowInvalidOperationException_CannotSerializeInvalidType(type, declaringType: null, memberInfo: null);
-            }
-        }
-        internal static bool IsInvalidForSerialization(Type type)
-        {
-            return type == typeof(void) || type.IsPointer || type.IsByRef || IsByRefLike(type) || type.ContainsGenericParameters;
-        }
-        internal void PopulatePolymorphismMetadata()
-        {
-            Debug.Assert(!IsReadOnly);
-            JsonPolymorphismOptions? options = JsonPolymorphismOptions.CreateFromAttributeDeclarations(Type);
-            if (options != null)
-            {
-                options.DeclaringTypeInfo = this;
-                _polymorphismOptions = options;
-            }
-        }
-        internal void MapInterfaceTypesToCallbacks()
-        {
-            Debug.Assert(!IsReadOnly);
-            if (Kind is JsonTypeInfoKind.Object or JsonTypeInfoKind.Enumerable or JsonTypeInfoKind.Dictionary)
-            {
-                if (typeof(IJsonOnSerializing).IsAssignableFrom(Type))
-                {
-                    OnSerializing = static obj => ((IJsonOnSerializing)obj).OnSerializing();
-                }
-                if (typeof(IJsonOnSerialized).IsAssignableFrom(Type))
-                {
-                    OnSerialized = static obj => ((IJsonOnSerialized)obj).OnSerialized();
-                }
-                if (typeof(IJsonOnDeserializing).IsAssignableFrom(Type))
-                {
-                    OnDeserializing = static obj => ((IJsonOnDeserializing)obj).OnDeserializing();
-                }
-                if (typeof(IJsonOnDeserialized).IsAssignableFrom(Type))
-                {
-                    OnDeserialized = static obj => ((IJsonOnDeserialized)obj).OnDeserialized();
-                }
-            }
-        }
-        internal void SetCreateObjectIfCompatible(Delegate? createObject)
-        {
-            Debug.Assert(!IsReadOnly);
-            if (Converter.SupportsCreateObjectDelegate && !Converter.ConstructorIsParameterized)
-            {
-                SetCreateObject(createObject);
-            }
-        }
-        private static bool IsByRefLike(Type type)
-        {
-#if NET
-            return type.IsByRefLike;
-#else
-            if (!type.IsValueType)
-            {
-                return false;
-            }
-            object[] attributes = type.GetCustomAttributes(inherit: false);
-            for (int i = 0; i < attributes.Length; i++)
-            {
-                if (attributes[i].GetType().FullName == "System.Runtime.CompilerServices.IsByRefLikeAttribute")
-                {
-                    return true;
-                }
-            }
-            return false;
-#endif
-        }
-        [DebuggerBrowsable(DebuggerBrowsableState.Never)]
-        internal bool SupportsPolymorphicDeserialization
-        {
-            get
-            {
-                Debug.Assert(IsConfigurationStarted);
-                return PolymorphicTypeResolver?.UsesTypeDiscriminators == true;
-            }
-        }
-        internal static bool IsValidExtensionDataProperty(Type propertyType)
-        {
-            return typeof(IDictionary<string, object>).IsAssignableFrom(propertyType) ||
-                typeof(IDictionary<string, JsonElement>).IsAssignableFrom(propertyType) ||
-                (propertyType.FullName == JsonObjectTypeName && ReferenceEquals(propertyType.Assembly, typeof(JsonTypeInfo).Assembly));
-        }
-        private static JsonTypeInfoKind GetTypeInfoKind(Type type, JsonConverter converter)
-        {
-            if (type == typeof(object) && converter.CanBePolymorphic)
-            {
-                Debug.Assert(converter is ObjectConverter);
-                return JsonTypeInfoKind.None;
-            }
-            switch (converter.ConverterStrategy)
-            {
-                case ConverterStrategy.Value: return JsonTypeInfoKind.None;
-                case ConverterStrategy.Object: return JsonTypeInfoKind.Object;
-                case ConverterStrategy.Enumerable: return JsonTypeInfoKind.Enumerable;
-                case ConverterStrategy.Dictionary: return JsonTypeInfoKind.Dictionary;
-                case ConverterStrategy.None:
-                    Debug.Assert(converter is JsonConverterFactory);
-                    ThrowHelper.ThrowNotSupportedException_SerializationNotSupported(type);
-                    return default;
-                default:
-                    Debug.Fail($"Unexpected class type: {converter.ConverterStrategy}");
-                    throw new InvalidOperationException();
-            }
-        }
-        internal sealed class JsonPropertyInfoList : ConfigurationList<JsonPropertyInfo>
-        {
-            private readonly JsonTypeInfo _jsonTypeInfo;
-            public JsonPropertyInfoList(JsonTypeInfo jsonTypeInfo)
-            {
-                _jsonTypeInfo = jsonTypeInfo;
-            }
-            public override bool IsReadOnly => _jsonTypeInfo._properties == this && _jsonTypeInfo.IsReadOnly || _jsonTypeInfo.Kind != JsonTypeInfoKind.Object;
-            protected override void OnCollectionModifying()
-            {
-                if (_jsonTypeInfo._properties == this)
-                {
-                    _jsonTypeInfo.VerifyMutable();
-                }
-                if (_jsonTypeInfo.Kind != JsonTypeInfoKind.Object)
-                {
-                    ThrowHelper.ThrowInvalidOperationException_JsonTypeInfoOperationNotPossibleForKind(_jsonTypeInfo.Kind);
-                }
-            }
-            protected override void ValidateAddedValue(JsonPropertyInfo item)
-            {
-                item.EnsureChildOf(_jsonTypeInfo);
-            }
-            public void SortProperties()
-            {
-                _list.StableSortByKey(static propInfo => propInfo.Order);
-            }
-            public void AddPropertyWithConflictResolution(JsonPropertyInfo jsonPropertyInfo, ref PropertyHierarchyResolutionState state)
-            {
-                Debug.Assert(!_jsonTypeInfo.IsConfigured);
-                Debug.Assert(jsonPropertyInfo.MemberName != null, "MemberName can be null in custom JsonPropertyInfo instances and should never be passed in this method");
-                string memberName = jsonPropertyInfo.MemberName;
-                if (state.AddedProperties.TryAdd(jsonPropertyInfo.Name, (jsonPropertyInfo, Count)))
-                {
-                    Add(jsonPropertyInfo);
-                    state.IsPropertyOrderSpecified |= jsonPropertyInfo.Order != 0;
-                }
-                else
-                {
-                    (JsonPropertyInfo other, int index) = state.AddedProperties[jsonPropertyInfo.Name];
-                    if (other.IsIgnored)
-                    {
-                        state.AddedProperties[jsonPropertyInfo.Name] = (jsonPropertyInfo, index);
-                        this[index] = jsonPropertyInfo;
-                        state.IsPropertyOrderSpecified |= jsonPropertyInfo.Order != 0;
-                    }
-                    else
-                    {
-                        bool ignoreCurrentProperty =
-                            jsonPropertyInfo.IsIgnored ||
-                            jsonPropertyInfo.IsOverriddenOrShadowedBy(other) ||
-                            (state.IgnoredProperties?.TryGetValue(memberName, out JsonPropertyInfo? ignored) == true && jsonPropertyInfo.IsOverriddenOrShadowedBy(ignored));
-                        if (!ignoreCurrentProperty)
-                        {
-                            ThrowHelper.ThrowInvalidOperationException_SerializerPropertyNameConflict(_jsonTypeInfo.Type, jsonPropertyInfo.Name);
-                        }
-                    }
-                }
-                if (jsonPropertyInfo.IsIgnored)
-                {
-                    (state.IgnoredProperties ??= new())[memberName] = jsonPropertyInfo;
-                }
-            }
-        }
-        [DebuggerBrowsable(DebuggerBrowsableState.Never)]
-        private string DebuggerDisplay => $"Type = {Type.Name}, Kind = {Kind}";
-    }
-}

--- a/src/mono/mono/metadata/class.c
+++ b//dev/null
@@ -1,6264 +0,0 @@
-/**
- * \file
- * Class management for the Mono runtime
- *
- * Author:
- *   Miguel de Icaza (miguel@ximian.com)
- *
- * Copyright 2001-2003 Ximian, Inc (http://www.ximian.com)
- * Copyright 2004-2009 Novell, Inc (http://www.novell.com)
- * Copyright 2012 Xamarin Inc (http://www.xamarin.com)
- * Licensed under the MIT license. See LICENSE file in the project root for full license information.
- */
-#include <config.h>
-#ifdef HAVE_ALLOCA_H
-#include <alloca.h>
-#endif
-#include <glib.h>
-#include <stdio.h>
-#include <string.h>
-#include <stdlib.h>
-#include <mono/metadata/image.h>
-#include <mono/metadata/image-internals.h>
-#include <mono/metadata/assembly.h>
-#include <mono/metadata/assembly-internals.h>
-#include <mono/metadata/exception-internals.h>
-#include <mono/metadata/metadata.h>
-#include <mono/metadata/metadata-internals.h>
-#include <mono/metadata/profiler-private.h>
-#include <mono/metadata/tabledefs.h>
-#include <mono/metadata/tokentype.h>
-#include <mono/metadata/class-init.h>
-#include <mono/metadata/class-init-internals.h>
-#include <mono/metadata/class-internals.h>
-#include <mono/metadata/object.h>
-#include <mono/metadata/appdomain.h>
-#include <mono/metadata/mono-endian.h>
-#include <mono/metadata/debug-helpers.h>
-#include <mono/metadata/reflection.h>
-#include <mono/metadata/exception.h>
-#include <mono/metadata/attrdefs.h>
-#include <mono/metadata/gc-internals.h>
-#include <mono/metadata/mono-debug.h>
-#include <mono/metadata/metadata-update.h>
-#include <mono/metadata/method-builder-ilgen.h>
-#include <mono/utils/mono-string.h>
-#include <mono/utils/mono-error-internals.h>
-#include <mono/utils/mono-logger-internals.h>
-#include <mono/utils/mono-memory-model.h>
-#include <mono/utils/atomic.h>
-#include <mono/utils/unlocked.h>
-#include <mono/utils/bsearch.h>
-#include <mono/utils/checked-build.h>
-#include "../native/containers/dn-simdhash-specializations.h"
-MonoStats mono_stats;
-/* Statistics */
-extern gint32 mono_inflated_methods_size;
-static gboolean can_access_type (MonoClass *access_klass, MonoClass *member_klass);
-static char* mono_assembly_name_from_token (MonoImage *image, guint32 type_token);
-static guint32 mono_field_resolve_flags (MonoClassField *field);
-static MonoClass *
-mono_class_from_name_checked_aux (MonoImage *image, const char* name_space, const char *name, GHashTable* visited_images, gboolean case_sensitive, MonoError *error);
-GENERATE_GET_CLASS_WITH_CACHE (valuetype, "System", "ValueType")
-GENERATE_TRY_GET_CLASS_WITH_CACHE (handleref, "System.Runtime.InteropServices", "HandleRef")
-#define CTOR_REQUIRED_FLAGS (METHOD_ATTRIBUTE_SPECIAL_NAME | METHOD_ATTRIBUTE_RT_SPECIAL_NAME)
-#define CTOR_INVALID_FLAGS (METHOD_ATTRIBUTE_STATIC)
-#undef DEBUG_INFLATE_CMODS
-static
-MonoImage *
-mono_method_get_image (MonoMethod *method)
-{
-	return m_class_get_image (method->klass);
-}
-/**
- * mono_class_from_typeref:
- * \param image a MonoImage
- * \param type_token a TypeRef token
- *
- * Creates the \c MonoClass* structure representing the type defined by
- * the typeref token valid inside \p image.
- * \returns The \c MonoClass* representing the typeref token, or NULL if it could
- * not be loaded.
- */
-MonoClass *
-mono_class_from_typeref (MonoImage *image, guint32 type_token)
-{
-	ERROR_DECL (error);
-	MonoClass *klass = mono_class_from_typeref_checked (image, type_token, error);
-	g_assert (is_ok (error)); /*FIXME proper error handling*/
-	return klass;
-}
-/**
- * mono_class_from_typeref_checked:
- * \param image a MonoImage
- * \param type_token a TypeRef token
- * \param error error return code, if any.
- *
- * Creates the \c MonoClass* structure representing the type defined by
- * the typeref token valid inside \p image.
- *
- * \returns The \c MonoClass* representing the typeref token, NULL if it could
- * not be loaded with the \p error value filled with the information about the
- * error.
- */
-MonoClass *
-mono_class_from_typeref_checked (MonoImage *image, guint32 type_token, MonoError *error)
-{
-	guint32 cols [MONO_TYPEREF_SIZE];
-	MonoTableInfo  *t = &image->tables [MONO_TABLE_TYPEREF];
-	guint32 idx;
-	const char *name, *nspace;
-	MonoClass *res = NULL;
-	MonoImage *module;
-	error_init (error);
-	mono_metadata_decode_row (t, (type_token&0xffffff)-1, cols, MONO_TYPEREF_SIZE);
-	name = mono_metadata_string_heap (image, cols [MONO_TYPEREF_NAME]);
-	nspace = mono_metadata_string_heap (image, cols [MONO_TYPEREF_NAMESPACE]);
-	idx = cols [MONO_TYPEREF_SCOPE] >> MONO_RESOLUTION_SCOPE_BITS;
-	switch (cols [MONO_TYPEREF_SCOPE] & MONO_RESOLUTION_SCOPE_MASK) {
-	case MONO_RESOLUTION_SCOPE_MODULE:
-		/*
-		LAMESPEC The spec says that a null module resolution scope should go through the exported type table.
-		This is not the observed behavior of existing implementations.
-		The defacto behavior is that it's just a typedef in disguise.
-		*/
-		/* a typedef in disguise */
-		res = mono_class_from_name_checked (image, nspace, name, error);
-		goto done;
-	case MONO_RESOLUTION_SCOPE_MODULEREF:
-		module = mono_image_load_module_checked (image, idx, error);
-		if (module)
-			res = mono_class_from_name_checked (module, nspace, name, error);
-		goto done;
-	case MONO_RESOLUTION_SCOPE_TYPEREF: {
-		MonoClass *enclosing;
-		GList *tmp;
-		if (idx == mono_metadata_token_index (type_token)) {
-			mono_error_set_bad_image (error, image, "Image with self-referencing typeref token %08x.", type_token);
-			return NULL;
-		}
-		enclosing = mono_class_from_typeref_checked (image, MONO_TOKEN_TYPE_REF | idx, error);
-		return_val_if_nok (error, NULL);
-		GList *nested_classes = mono_class_get_nested_classes_property (enclosing);
-		if (m_class_is_nested_classes_inited (enclosing) && nested_classes) {
-			/* Micro-optimization: don't scan the metadata tables if enclosing is already inited */
-			for (tmp = nested_classes; tmp; tmp = tmp->next) {
-				res = (MonoClass *)tmp->data;
-				if (strcmp (m_class_get_name (res), name) == 0)
-					return res;
-			}
-		} else {
-			MonoImage *enclosing_image = m_class_get_image (enclosing);
-			guint32 enclosing_type_token = m_class_get_type_token (enclosing);
-			/* Don't call mono_class_init_internal as we might've been called by it recursively */
-			int i = mono_metadata_nesting_typedef (enclosing_image, enclosing_type_token, 1);
-			while (i) {
-				guint32 class_nested = mono_metadata_decode_row_col (&enclosing_image->tables [MONO_TABLE_NESTEDCLASS], i - 1, MONO_NESTED_CLASS_NESTED);
-				guint32 string_offset = mono_metadata_decode_row_col (&enclosing_image->tables [MONO_TABLE_TYPEDEF], class_nested - 1, MONO_TYPEDEF_NAME);
-				const char *nname = mono_metadata_string_heap (enclosing_image, string_offset);
-				if (strcmp (nname, name) == 0)
-					return mono_class_create_from_typedef (enclosing_image, MONO_TOKEN_TYPE_DEF | class_nested, error);
-				i = mono_metadata_nesting_typedef (enclosing_image, enclosing_type_token, i + 1);
-			}
-		}
-		g_warning ("TypeRef ResolutionScope not yet handled (%d) for %s.%s in image %s", idx, nspace, name, image->name);
-		goto done;
-	}
-	case MONO_RESOLUTION_SCOPE_ASSEMBLYREF:
-		break;
-	}
-	if (mono_metadata_table_bounds_check (image, MONO_TABLE_ASSEMBLYREF, idx)) {
-		mono_error_set_bad_image (error, image, "Image with invalid assemblyref token %08x.", idx);
-		return NULL;
-	}
-	if (!image->references || !image->references [idx - 1])
-		mono_assembly_load_reference (image, idx - 1);
-	g_assert (image->references [idx - 1]);
-	/* If the assembly did not load, register this as a type load exception */
-	if (image->references [idx - 1] == REFERENCE_MISSING){
-		MonoAssemblyName aname;
-		memset (&aname, 0, sizeof (MonoAssemblyName));
-		char *human_name;
-		mono_assembly_get_assemblyref (image, idx - 1, &aname);
-		human_name = mono_stringify_assembly_name (&aname);
-		mono_error_set_simple_file_not_found (error, human_name);
-		g_free (human_name);
-		return NULL;
-	}
-	res = mono_class_from_name_checked (image->references [idx - 1]->image, nspace, name, error);
-done:
-	/* Generic case, should be avoided for when a better error is possible. */
-	if (!res && is_ok (error)) {
-		char *class_name = mono_class_name_from_token (image, type_token);
-		char *assembly_name = mono_assembly_name_from_token (image, type_token);
-		mono_error_set_type_load_name (error, class_name, assembly_name, "Could not resolve type with token %08x from typeref (expected class '%s' in assembly '%s')", type_token, class_name, assembly_name);
-	}
-	return res;
-}
-static void *
-mono_image_memdup (MonoImage *image, void *data, guint size)
-{
-	void *res = mono_image_alloc (image, size);
-	memcpy (res, data, size);
-	return res;
-}
-/* Copy everything mono_metadata_free_array free. */
-MonoArrayType *
-mono_dup_array_type (MonoImage *image, MonoArrayType *a)
-{
-	if (image) {
-		a = (MonoArrayType *)mono_image_memdup (image, a, sizeof (MonoArrayType));
-		if (a->sizes)
-			a->sizes = (int *)mono_image_memdup (image, a->sizes, a->numsizes * sizeof (int));
-		if (a->lobounds)
-			a->lobounds = (int *)mono_image_memdup (image, a->lobounds, a->numlobounds * sizeof (int));
-	} else {
-		a = (MonoArrayType *)g_memdup (a, sizeof (MonoArrayType));
-		if (a->sizes)
-			a->sizes = (int *)g_memdup (a->sizes, a->numsizes * sizeof (int));
-		if (a->lobounds)
-			a->lobounds = (int *)g_memdup (a->lobounds, a->numlobounds * sizeof (int));
-	}
-	return a;
-}
-/* Copy everything mono_metadata_free_method_signature free. */
-MonoMethodSignature*
-mono_metadata_signature_deep_dup (MonoImage *image, MonoMethodSignature *sig)
-{
-	int i;
-	sig = mono_metadata_signature_dup_full (image, sig);
-	sig->ret = mono_metadata_type_dup (image, sig->ret);
-	for (i = 0; i < sig->param_count; ++i)
-		sig->params [i] = mono_metadata_type_dup (image, sig->params [i]);
-	return sig;
-}
-static void
-_mono_type_get_assembly_name (MonoClass *klass, GString *str)
-{
-	MonoAssembly *ta = m_class_get_image (klass)->assembly;
-	char *name;
-	name = mono_stringify_assembly_name (&ta->aname);
-	g_string_append_printf (str, ", %s", name);
-	g_free (name);
-}
-static void
-mono_type_name_check_byref (MonoType *type, GString *str)
-{
-	if (m_type_is_byref (type))
-		g_string_append_c (str, '&');
-}
-static char*
-escape_special_chars (const char* identifier)
-{
-	size_t id_len = strlen (identifier);
-	char *res = g_malloc (id_len * 2 + 1);
-	char *res_ptr = res;
-	for (const char *s = identifier; *s != 0; s++) {
-		switch (*s) {
-		case ',':
-		case '+':
-		case '&':
-		case '*':
-		case '[':
-		case ']':
-		case '\\':
-			*res_ptr++ = '\\';
-			break;
-		}
-		*res_ptr++ = *s;
-	}
-	*res_ptr = '\0';
-	return res;
-}
-/**
- * mono_identifier_escape_type_name_chars:
- * \param identifier the display name of a mono type
- *
- * \returns The name in external form, that is with escaping backslashes.
- *
- * The displayed form of an identifier has the characters ,+&*[]\
- * that have special meaning in type names escaped with a preceding
- * backslash (\) character.
- */
-char*
-mono_identifier_escape_type_name_chars (const char* identifier)
-{
-	if (!identifier)
-		return NULL;
-	for (const char *s = identifier; *s != 0; s++) {
-		switch (*s) {
-		case ',':
-		case '+':
-		case '&':
-		case '*':
-		case '[':
-		case ']':
-		case '\\':
-			return escape_special_chars (identifier);
-		}
-	}
-	return g_strdup (identifier);
-}
-static void
-mono_type_get_name_recurse (MonoType *type, GString *str, gboolean is_recursed,
-			    MonoTypeNameFormat format)
-{
-	MonoClass *klass;
-	switch (type->type) {
-	case MONO_TYPE_ARRAY: {
-		int i, rank = type->data.array->rank;
-		MonoTypeNameFormat nested_format;
-		nested_format = format == MONO_TYPE_NAME_FORMAT_ASSEMBLY_QUALIFIED ?
-			MONO_TYPE_NAME_FORMAT_FULL_NAME : format;
-		mono_type_get_name_recurse (
-			m_class_get_byval_arg (type->data.array->eklass), str, FALSE, nested_format);
-		g_string_append_c (str, '[');
-		if (rank == 1)
-			g_string_append_c (str, '*');
-		else if (rank > 64)
-			g_string_append_printf (str, "%d", rank);
-		else
-			for (i = 1; i < rank; i++)
-				g_string_append_c (str, ',');
-		g_string_append_c (str, ']');
-		mono_type_name_check_byref (type, str);
-		if (format == MONO_TYPE_NAME_FORMAT_ASSEMBLY_QUALIFIED)
-			_mono_type_get_assembly_name (type->data.array->eklass, str);
-		break;
-	}
-	case MONO_TYPE_SZARRAY: {
-		MonoTypeNameFormat nested_format;
-		nested_format = format == MONO_TYPE_NAME_FORMAT_ASSEMBLY_QUALIFIED ?
-			MONO_TYPE_NAME_FORMAT_FULL_NAME : format;
-		mono_type_get_name_recurse (
-			m_class_get_byval_arg (type->data.klass), str, FALSE, nested_format);
-		g_string_append (str, "[]");
-		mono_type_name_check_byref (type, str);
-		if (format == MONO_TYPE_NAME_FORMAT_ASSEMBLY_QUALIFIED)
-			_mono_type_get_assembly_name (type->data.klass, str);
-		break;
-	}
-	case MONO_TYPE_PTR: {
-		MonoTypeNameFormat nested_format;
-		nested_format = format == MONO_TYPE_NAME_FORMAT_ASSEMBLY_QUALIFIED ?
-			MONO_TYPE_NAME_FORMAT_FULL_NAME : format;
-		mono_type_get_name_recurse (
-			type->data.type, str, FALSE, nested_format);
-		g_string_append_c (str, '*');
-		mono_type_name_check_byref (type, str);
-		if (format == MONO_TYPE_NAME_FORMAT_ASSEMBLY_QUALIFIED)
-			_mono_type_get_assembly_name (mono_class_from_mono_type_internal (type->data.type), str);
-		break;
-	}
-	case MONO_TYPE_VAR:
-	case MONO_TYPE_MVAR:
-		if (!mono_generic_param_name (type->data.generic_param))
-			g_string_append_printf (str, "%s%d", type->type == MONO_TYPE_VAR ? "!" : "!!", type->data.generic_param->num);
-		else
-			g_string_append (str, mono_generic_param_name (type->data.generic_param));
-		mono_type_name_check_byref (type, str);
-		break;
-	case MONO_TYPE_FNPTR: {
-		MonoTypeNameFormat nested_format;
-		nested_format = format == MONO_TYPE_NAME_FORMAT_ASSEMBLY_QUALIFIED ?
-			MONO_TYPE_NAME_FORMAT_FULL_NAME : format;
-		mono_type_get_name_recurse (type->data.method->ret, str, FALSE, nested_format);
-		g_string_append_c (str, '(');
-		for (int i = 0; i < type->data.method->param_count; ++i) {
-			mono_type_get_name_recurse (type->data.method->params[i], str, FALSE, nested_format);
-			if (i != type->data.method->param_count - 1)
-				g_string_append (str, ", ");
-		}
-		g_string_append_c (str, ')');
-		break;
-	}
-	default:
-		klass = mono_class_from_mono_type_internal (type);
-		if (m_class_get_nested_in (klass)) {
-			mono_type_get_name_recurse (
-				m_class_get_byval_arg (m_class_get_nested_in (klass)), str, TRUE, format);
-			if (format == MONO_TYPE_NAME_FORMAT_IL)
-				g_string_append_c (str, '.');
-			else
-				g_string_append_c (str, '+');
-		} else if (*m_class_get_name_space (klass)) {
-			const char *klass_name_space = m_class_get_name_space (klass);
-			if (format == MONO_TYPE_NAME_FORMAT_IL)
-				g_string_append (str, klass_name_space);
-			else {
-				char *escaped = mono_identifier_escape_type_name_chars (klass_name_space);
-				g_string_append (str, escaped);
-				g_free (escaped);
-			}
-			g_string_append_c (str, '.');
-		}
-		const char *klass_name = m_class_get_name (klass);
-		if (format == MONO_TYPE_NAME_FORMAT_IL) {
-			const char *s = strchr (klass_name, '`');
-			gssize len = s ? (s - klass_name) : (gssize)strlen (klass_name);
-			g_string_append_len (str, klass_name, len);
-		} else {
-			char *escaped = mono_identifier_escape_type_name_chars (klass_name);
-			g_string_append (str, escaped);
-			g_free (escaped);
-		}
-		if (is_recursed)
-			break;
-		if (mono_class_is_ginst (klass)) {
-			MonoGenericClass *gclass = mono_class_get_generic_class (klass);
-			MonoGenericInst *inst = gclass->context.class_inst;
-			MonoTypeNameFormat nested_format;
-			nested_format = format == MONO_TYPE_NAME_FORMAT_FULL_NAME ?
-				MONO_TYPE_NAME_FORMAT_ASSEMBLY_QUALIFIED : format;
-			if (format == MONO_TYPE_NAME_FORMAT_IL)
-				g_string_append_c (str, '<');
-			else
-				g_string_append_c (str, '[');
-			for (guint i = 0; i < inst->type_argc; i++) {
-				MonoType *t = inst->type_argv [i];
-				if (i)
-					g_string_append_c (str, ',');
-				if ((nested_format == MONO_TYPE_NAME_FORMAT_ASSEMBLY_QUALIFIED) &&
-				    (t->type != MONO_TYPE_VAR) && (type->type != MONO_TYPE_MVAR))
-					g_string_append_c (str, '[');
-				mono_type_get_name_recurse (inst->type_argv [i], str, FALSE, nested_format);
-				if ((nested_format == MONO_TYPE_NAME_FORMAT_ASSEMBLY_QUALIFIED) &&
-				    (t->type != MONO_TYPE_VAR) && (type->type != MONO_TYPE_MVAR))
-					g_string_append_c (str, ']');
-			}
-			if (format == MONO_TYPE_NAME_FORMAT_IL)
-				g_string_append_c (str, '>');
-			else
-				g_string_append_c (str, ']');
-		} else if (mono_class_is_gtd (klass) &&
-			   (format != MONO_TYPE_NAME_FORMAT_FULL_NAME) &&
-			   (format != MONO_TYPE_NAME_FORMAT_ASSEMBLY_QUALIFIED)) {
-			if (format == MONO_TYPE_NAME_FORMAT_IL)
-				g_string_append_c (str, '<');
-			else
-				g_string_append_c (str, '[');
-			for (int i = 0; i < mono_class_get_generic_container (klass)->type_argc; i++) {
-				if (i)
-					g_string_append_c (str, ',');
-				g_string_append (str, mono_generic_container_get_param_info (mono_class_get_generic_container (klass), i)->name);
-			}
-			if (format == MONO_TYPE_NAME_FORMAT_IL)
-				g_string_append_c (str, '>');
-			else
-				g_string_append_c (str, ']');
-		}
-		mono_type_name_check_byref (type, str);
-		if ((format == MONO_TYPE_NAME_FORMAT_ASSEMBLY_QUALIFIED) &&
-		    (type->type != MONO_TYPE_VAR) && (type->type != MONO_TYPE_MVAR))
-			_mono_type_get_assembly_name (klass, str);
-		break;
-	}
-}
-/**
- * mono_type_get_name_full:
- * \param type a type
- * \param format the format for the return string.
- *
- *
- * \returns The string representation in a number of formats:
- *
- * if \p format is \c MONO_TYPE_NAME_FORMAT_REFLECTION, the return string is
- * returned in the format required by \c System.Reflection, this is the
- * inverse of mono_reflection_parse_type().
- *
- * if \p format is \c MONO_TYPE_NAME_FORMAT_IL, it returns a syntax that can
- * be used by the IL assembler.
- *
- * if \p format is \c MONO_TYPE_NAME_FORMAT_FULL_NAME
- *
- * if \p format is \c MONO_TYPE_NAME_FORMAT_ASSEMBLY_QUALIFIED
- */
-char*
-mono_type_get_name_full (MonoType *type, MonoTypeNameFormat format)
-{
-	GString* result;
-	result = g_string_new ("");
-	mono_type_get_name_recurse (type, result, FALSE, format);
-	return g_string_free (result, FALSE);
-}
-/**
- * mono_type_get_full_name:
- * \param class a class
- *
- * \returns The string representation for type as required by System.Reflection.
- * The inverse of mono_reflection_parse_type().
- */
-char *
-mono_type_get_full_name (MonoClass *klass)
-{
-	return mono_type_get_name_full (m_class_get_byval_arg (klass), MONO_TYPE_NAME_FORMAT_REFLECTION);
-}
-/**
- * mono_type_get_name:
- * \param type a type
- * \returns The string representation for type as it would be represented in IL code.
- */
-char*
-mono_type_get_name (MonoType *type)
-{
-	return mono_type_get_name_full (type, MONO_TYPE_NAME_FORMAT_IL);
-}
-/**
- * mono_type_get_underlying_type:
- * \param type a type
- * \returns The \c MonoType for the underlying integer type if \p type
- * is an enum and byref is false, otherwise the type itself.
- */
-MonoType*
-mono_type_get_underlying_type (MonoType *type)
-{
-	if (type->type == MONO_TYPE_VALUETYPE && m_class_is_enumtype (type->data.klass) && !m_type_is_byref (type))
-		return mono_class_enum_basetype_internal (type->data.klass);
-	if (type->type == MONO_TYPE_GENERICINST && m_class_is_enumtype (type->data.generic_class->container_class) && !m_type_is_byref (type))
-		return mono_class_enum_basetype_internal (type->data.generic_class->container_class);
-	return type;
-}
-/**
- * mono_class_is_open_constructed_type:
- * \param type a type
- *
- * \returns TRUE if type represents a generics open constructed type.
- * IOW, not all type parameters required for the instantiation have
- * been provided or it's a generic type definition.
- *
- * An open constructed type means it's a non realizable type. Not to
- * be mixed up with an abstract type - we can't cast or dispatch to
- * an open type, for example.
- */
-gboolean
-mono_class_is_open_constructed_type (MonoType *t)
-{
-	switch (t->type) {
-	case MONO_TYPE_VAR:
-	case MONO_TYPE_MVAR:
-		return TRUE;
-	case MONO_TYPE_SZARRAY:
-		return mono_class_is_open_constructed_type (m_class_get_byval_arg (t->data.klass));
-	case MONO_TYPE_ARRAY:
-		return mono_class_is_open_constructed_type (m_class_get_byval_arg (t->data.array->eklass));
-	case MONO_TYPE_PTR:
-		return mono_class_is_open_constructed_type (t->data.type);
-	case MONO_TYPE_GENERICINST:
-		return t->data.generic_class->context.class_inst->is_open;
-	case MONO_TYPE_CLASS:
-	case MONO_TYPE_VALUETYPE:
-		return mono_class_is_gtd (t->data.klass);
-	default:
-		return FALSE;
-	}
-}
-/*
-This is a simple function to catch the most common bad instances of generic types.
-Specially those that might lead to further failures in the runtime.
-*/
-gboolean
-mono_type_is_valid_generic_argument (MonoType *type)
-{
-	switch (type->type) {
-	case MONO_TYPE_VOID:
-		return FALSE;
-	default:
-		return TRUE;
-	}
-}
-static gboolean
-can_inflate_gparam_with (MonoGenericParam *gparam, MonoType *type)
-{
-	if (!mono_type_is_valid_generic_argument (type))
-		return FALSE;
-#if 0
-	/* Avoid inflating gparams with valuetype constraints with ref types during gsharing */
-	MonoGenericParamInfo *info = mono_generic_param_info (gparam);
-	if (info && (info->flags & GENERIC_PARAMETER_ATTRIBUTE_VALUE_TYPE_CONSTRAINT)) {
-		if (type->type == MONO_TYPE_VAR || type->type == MONO_TYPE_MVAR) {
-			MonoGenericParam *inst_gparam = type->data.generic_param;
-			if (inst_gparam->gshared_constraint && inst_gparam->gshared_constraint->type == MONO_TYPE_OBJECT)
-				return FALSE;
-		}
-	}
-#endif
-	return TRUE;
-}
-static MonoType*
-inflate_generic_custom_modifiers (MonoImage *image, const MonoType *type, MonoGenericContext *context, MonoError *error);
-static MonoType*
-inflate_generic_type (MonoImage *image, MonoType *type, MonoGenericContext *context, MonoError *error)
-{
-	gboolean changed = FALSE;
-	error_init (error);
-	/* C++/CLI (and some Roslyn tests) constructs method signatures like:
-	 *     void .CL1`1.Test(!0 modopt(System.Nullable`1<!0>))
-	 * where !0 has a custom modifier which itself mentions the type variable.
-	 * So we need to potentially inflate the modifiers.
-	 */
-	if (type->has_cmods) {
-		MonoType *new_type = inflate_generic_custom_modifiers (image, type, context, error);
-		return_val_if_nok (error, NULL);
-		if (new_type != NULL) {
-			type = new_type;
-			changed = TRUE;
-		}
-	}
-	switch (type->type) {
-	case MONO_TYPE_MVAR: {
-		MonoType *nt;
-		guint16 num = mono_type_get_generic_param_num (type);
-		MonoGenericInst *inst = context->method_inst;
-		if (!inst) {
-			if (!changed)
-				return NULL;
-			else
-				return type;
-		}
-		MonoGenericParam *gparam = type->data.generic_param;
-		if (num >= inst->type_argc) {
-			const char *pname = mono_generic_param_name (gparam);
-			mono_error_set_bad_image (error, image, "MVAR %d (%s) cannot be expanded in this context with %d instantiations",
-				num, pname ? pname : "", inst->type_argc);
-			return NULL;
-		}
-		if (!can_inflate_gparam_with (gparam, inst->type_argv [num])) {
-			const char *pname = mono_generic_param_name (gparam);
-			mono_error_set_bad_image (error, image, "MVAR %d (%s) cannot be expanded with type 0x%x",
-				num, pname ? pname : "", inst->type_argv [num]->type);
-			return NULL;
-		}
-		/*
-		 * Note that the VAR/MVAR cases are different from the rest.  The other cases duplicate @type,
-		 * while the VAR/MVAR duplicates a type from the context.  So, we need to ensure that the
-		 * ->byref__ and ->attrs from @type are propagated to the returned type.
-		 */
-		nt = mono_metadata_type_dup_with_cmods (image, inst->type_argv [num], type);
-		nt->byref__ = type->byref__;
-		nt->attrs = type->attrs;
-		return nt;
-	}
-	case MONO_TYPE_VAR: {
-		MonoType *nt;
-		guint16 num = mono_type_get_generic_param_num (type);
-		MonoGenericInst *inst = context->class_inst;
-		if (!inst) {
-			if (!changed)
-				return NULL;
-			else
-				return type;
-		}
-		MonoGenericParam *gparam = type->data.generic_param;
-		if (num >= inst->type_argc) {
-			const char *pname = mono_generic_param_name (gparam);
-			mono_error_set_bad_image (error, image, "VAR %hu (%s) cannot be expanded in this context with %d instantiations",
-				num, pname ? pname : "", inst->type_argc);
-			return NULL;
-		}
-		if (!can_inflate_gparam_with (gparam, inst->type_argv [num])) {
-			const char *pname = mono_generic_param_name (gparam);
-			mono_error_set_bad_image (error, image, "VAR %d (%s) cannot be expanded with type 0x%x",
-				num, pname ? pname : "", inst->type_argv [num]->type);
-			return NULL;
-		}
-#ifdef DEBUG_INFLATE_CMODS
-		gboolean append_cmods;
-		append_cmods = FALSE;
-		if (type->has_cmods && inst->type_argv[num]->has_cmods) {
-			char *tname = mono_type_full_name (type);
-			char *vname = mono_type_full_name (inst->type_argv[num]);
-			printf ("\n\n\tsubstitution for '%s' with '%s' yields...\n", tname, vname);
-			g_free (tname);
-			g_free (vname);
-			append_cmods = TRUE;
-		}
-#endif
-		nt = mono_metadata_type_dup_with_cmods (image, inst->type_argv [num], type);
-		nt->byref__ = type->byref__ || inst->type_argv[num]->byref__;
-		nt->attrs = type->attrs;
-#ifdef DEBUG_INFLATE_CMODS
-		if (append_cmods) {
-			char *ntname = mono_type_full_name (nt);
-			printf ("\tyields '%s'\n\n\n", ntname);
-			g_free (ntname);
-		}
-#endif
-		return nt;
-	}
-	case MONO_TYPE_SZARRAY: {
-		MonoClass *eclass = type->data.klass;
-		MonoType *nt, *inflated = inflate_generic_type (NULL, m_class_get_byval_arg (eclass), context, error);
-		if ((!inflated && !changed) || !is_ok (error))
-			return NULL;
-		if (!inflated)
-			return type;
-		nt = mono_metadata_type_dup (image, type);
-		nt->data.klass = mono_class_from_mono_type_internal (inflated);
-		mono_metadata_free_type (inflated);
-		return nt;
-	}
-	case MONO_TYPE_ARRAY: {
-		MonoClass *eclass = type->data.array->eklass;
-		MonoType *nt, *inflated = inflate_generic_type (NULL, m_class_get_byval_arg (eclass), context, error);
-		if ((!inflated && !changed) || !is_ok (error))
-			return NULL;
-		if (!inflated)
-			return type;
-		nt = mono_metadata_type_dup (image, type);
-		nt->data.array->eklass = mono_class_from_mono_type_internal (inflated);
-		mono_metadata_free_type (inflated);
-		return nt;
-	}
-	case MONO_TYPE_GENERICINST: {
-		MonoGenericClass *gclass = type->data.generic_class;
-		MonoGenericInst *inst;
-		MonoType *nt;
-		if (!gclass->context.class_inst->is_open) {
-			if (!changed)
-				return NULL;
-			else
-				return type;
-		}
-		inst = mono_metadata_inflate_generic_inst (gclass->context.class_inst, context, error);
-		return_val_if_nok (error, NULL);
-		if (inst != gclass->context.class_inst)
-			gclass = mono_metadata_lookup_generic_class (gclass->container_class, inst, gclass->is_dynamic);
-		if (gclass == type->data.generic_class) {
-			if (!changed)
-				return NULL;
-			else
-				return type;
-		}
-		nt = mono_metadata_type_dup (image, type);
-		nt->data.generic_class = gclass;
-		return nt;
-	}
-	case MONO_TYPE_CLASS:
-	case MONO_TYPE_VALUETYPE: {
-		MonoClass *klass = type->data.klass;
-		MonoGenericContainer *container = mono_class_try_get_generic_container (klass);
-		MonoGenericInst *inst;
-		MonoGenericClass *gclass = NULL;
-		MonoType *nt;
-		if (!container) {
-			if (!changed)
-				return NULL;
-			else
-				return type;
-		}
-		/* We can't use context->class_inst directly, since it can have more elements */
-		inst = mono_metadata_inflate_generic_inst (container->context.class_inst, context, error);
-		return_val_if_nok (error, NULL);
-		if (inst == container->context.class_inst) {
-			if (!changed)
-				return NULL;
-			else
-				return type;
-		}
-		gclass = mono_metadata_lookup_generic_class (klass, inst, image_is_dynamic (m_class_get_image (klass)));
-		nt = mono_metadata_type_dup (image, type);
-		nt->type = MONO_TYPE_GENERICINST;
-		nt->data.generic_class = gclass;
-		return nt;
-	}
-	case MONO_TYPE_PTR: {
-		MonoType *nt, *inflated = inflate_generic_type (image, type->data.type, context, error);
-		if ((!inflated && !changed) || !is_ok (error))
-			return NULL;
-		if (!inflated && changed)
-			return type;
-		nt = mono_metadata_type_dup (image, type);
-		nt->data.type = inflated;
-		return nt;
-	}
-	case MONO_TYPE_FNPTR: {
-		MonoMethodSignature *in_sig = type->data.method;
-		if (!in_sig->has_type_parameters) {
-			if (!changed)
-				return NULL;
-			else
-				return type;
-		}
-		MonoMethodSignature *new_sig = mono_inflate_generic_signature (in_sig, context, error);
-		if ((!new_sig && !changed) || !is_ok (error)) {
-			return NULL;
-		} else if (!new_sig && changed)
-			return type;
-		if (new_sig == in_sig) {
-			if (!changed)
-				return NULL;
-			else
-				return type;
-		}
-		MonoType *nt = mono_metadata_type_dup (image, type);
-		nt->data.method = new_sig;
-		return nt;
-	}
-	default:
-		if (!changed)
-			return NULL;
-		else
-			return type;
-	}
-	return NULL;
-}
-static MonoType*
-inflate_generic_custom_modifiers (MonoImage *image, const MonoType *type, MonoGenericContext *context, MonoError *error)
-{
-	MonoType *result = NULL;
-	g_assert (type->has_cmods);
-	guint8 count = mono_type_custom_modifier_count (type);
-	gboolean changed = FALSE;
-	/* Try not to blow up the stack. See comment on MONO_MAX_EXPECTED_CMODS. */
-	g_assert (count < MONO_MAX_EXPECTED_CMODS);
-	size_t aggregate_size = mono_sizeof_aggregate_modifiers (count);
-	MonoAggregateModContainer *candidate_mods = g_alloca (aggregate_size);
-	memset (candidate_mods, 0, aggregate_size);
-	candidate_mods->count = count;
-	for (guint8 i = 0; i < count; ++i) {
-		gboolean required;
-		MonoType *cmod_old = mono_type_get_custom_modifier (type, i, &required, error);
-		goto_if_nok (error, leave);
-		MonoType *cmod_new = inflate_generic_type (NULL, cmod_old, context, error);
-		goto_if_nok (error, leave);
-		if (cmod_new)
-			changed = TRUE;
-		candidate_mods->modifiers [i].required = required;
-		candidate_mods->modifiers [i].type = cmod_new;
-	}
-	if (changed) {
-		/* if we're going to make a new type, fill in any modifiers that weren't affected by inflation with copies of the original values. */
-		for (guint8 i = 0; i < count; ++i) {
-			if (candidate_mods->modifiers [i].type == NULL) {
-				candidate_mods->modifiers [i].type = mono_metadata_type_dup (NULL, mono_type_get_custom_modifier (type, i, NULL, error));
-				/* it didn't error in the first loop, so should be ok now, too */
-				mono_error_assert_ok (error);
-			}
-		}
-	}
-#ifdef DEBUG_INFLATE_CMODS
-	if (changed) {
-		char *full_name = mono_type_full_name ((MonoType*)type);
-		printf ("\n\n\tcustom modifier on '%s' affected by subsititution\n\n\n", full_name);
-		g_free (full_name);
-	}
-#endif
-	if (changed) {
-		MonoType *new_type = g_alloca (mono_sizeof_type_with_mods (count, TRUE));
-		/* first init just the non-modifier portion of new_type before populating the
-		 * new modifiers */
-		memcpy (new_type, type, MONO_SIZEOF_TYPE);
-		mono_type_with_mods_init (new_type, count, TRUE);
-		mono_type_set_amods (new_type, mono_metadata_get_canonical_aggregate_modifiers (candidate_mods));
-		result =  mono_metadata_type_dup (image, new_type);
-	}
-leave:
-	for (guint8 i = 0; i < count; ++i) {
-		if (candidate_mods->modifiers [i].type)
-			mono_metadata_free_type (candidate_mods->modifiers [i].type);
-	}
-	return result;
-}
-MonoGenericContext *
-mono_generic_class_get_context (MonoGenericClass *gclass)
-{
-	return &gclass->context;
-}
-MonoGenericContext *
-mono_class_get_context (MonoClass *klass)
-{
-	MonoGenericClass *gklass = mono_class_try_get_generic_class (klass);
-	return gklass ? mono_generic_class_get_context (gklass) : NULL;
-}
-/*
- * mono_class_inflate_generic_type_with_mempool:
- * @mempool: a mempool
- * @type: a type
- * @context: a generics context
- * @error: error context
- *
- * The same as mono_class_inflate_generic_type, but allocates the MonoType
- * from mempool if it is non-NULL.  If it is NULL, the MonoType is
- * allocated on the heap and is owned by the caller.
- * The returned type can potentially be the same as TYPE, so it should not be
- * modified by the caller, and it should be freed using mono_metadata_free_type ().
- */
-MonoType*
-mono_class_inflate_generic_type_with_mempool (MonoImage *image, MonoType *type, MonoGenericContext *context, MonoError *error)
-{
-	MonoType *inflated = NULL;
-	error_init (error);
-	if (context)
-		inflated = inflate_generic_type (image, type, context, error);
-	return_val_if_nok (error, NULL);
-	if (!inflated) {
-		MonoType *shared = mono_metadata_get_shared_type (type);
-		if (shared && !type->has_cmods) {
-			return shared;
-		} else {
-			return mono_metadata_type_dup (image, type);
-		}
-	}
-	UnlockedIncrement (&mono_stats.inflated_type_count);
-	return inflated;
-}
-/**
- * mono_class_inflate_generic_type:
- * \param type a type
- * \param context a generics context
- * \deprecated Please use \c mono_class_inflate_generic_type_checked instead
- *
- * If \p type is a generic type and \p context is not NULL, instantiate it using the
- * generics context \p context.
- *
- * \returns The instantiated type or a copy of \p type. The returned \c MonoType is allocated
- * on the heap and is owned by the caller. Returns NULL on error.
- */
-MonoType*
-mono_class_inflate_generic_type (MonoType *type, MonoGenericContext *context)
-{
-	ERROR_DECL (error);
-	MonoType *result;
-	result = mono_class_inflate_generic_type_checked (type, context, error);
-	mono_error_cleanup (error);
-	return result;
-}
-/*
- * mono_class_inflate_generic_type:
- * @type: a type
- * @context: a generics context
- * @error: error context to use
- *
- * If @type is a generic type and @context is not NULL, instantiate it using the
- * generics context @context.
- *
- * Returns: The instantiated type or a copy of @type. The returned MonoType is allocated
- * on the heap and is owned by the caller.
- */
-MonoType*
-mono_class_inflate_generic_type_checked (MonoType *type, MonoGenericContext *context, MonoError *error)
-{
-	return mono_class_inflate_generic_type_with_mempool (NULL, type, context, error);
-}
-/*
- * mono_class_inflate_generic_type_no_copy:
- *
- *   Same as inflate_generic_type_with_mempool, but return TYPE if no inflation
- * was done.
- */
-static MonoType*
-mono_class_inflate_generic_type_no_copy (MonoImage *image, MonoType *type, MonoGenericContext *context, MonoError *error)
-{
-	MonoType *inflated = NULL;
-	error_init (error);
-	if (context) {
-		inflated = inflate_generic_type (image, type, context, error);
-		return_val_if_nok (error, NULL);
-	}
-	if (!inflated)
-		return type;
-	UnlockedIncrement (&mono_stats.inflated_type_count);
-	return inflated;
-}
-/*
- * mono_class_inflate_generic_class:
- *
- *   Inflate the class @gklass with @context. Set @error on failure.
- */
-MonoClass*
-mono_class_inflate_generic_class_checked (MonoClass *gklass, MonoGenericContext *context, MonoError *error)
-{
-	MonoClass *res;
-	MonoType *inflated;
-	inflated = mono_class_inflate_generic_type_checked (m_class_get_byval_arg (gklass), context, error);
-	return_val_if_nok (error, NULL);
-	res = mono_class_from_mono_type_internal (inflated);
-	mono_metadata_free_type (inflated);
-	return res;
-}
-static MonoGenericContext
-inflate_generic_context (MonoGenericContext *context, MonoGenericContext *inflate_with, MonoError *error)
-{
-	MonoGenericInst *class_inst = NULL;
-	MonoGenericInst *method_inst = NULL;
-	MonoGenericContext res = { NULL, NULL };
-	error_init (error);
-	if (context->class_inst) {
-		class_inst = mono_metadata_inflate_generic_inst (context->class_inst, inflate_with, error);
-		if (!is_ok (error))
-			goto fail;
-	}
-	if (context->method_inst) {
-		method_inst = mono_metadata_inflate_generic_inst (context->method_inst, inflate_with, error);
-		if (!is_ok (error))
-			goto fail;
-	}
-	res.class_inst = class_inst;
-	res.method_inst = method_inst;
-fail:
-	return res;
-}
-/**
- * mono_class_inflate_generic_method:
- * \param method a generic method
- * \param context a generics context
- *
- * Instantiate the generic method \p method using the generics context \p context.
- *
- * \returns The new instantiated method
- */
-MonoMethod *
-mono_class_inflate_generic_method (MonoMethod *method, MonoGenericContext *context)
-{
-	ERROR_DECL (error);
-	MonoMethod *res = mono_class_inflate_generic_method_full_checked (method, NULL, context, error);
-	mono_error_assert_msg_ok (error, "Could not inflate generic method");
-	return res;
-}
-MonoMethod *
-mono_class_inflate_generic_method_checked (MonoMethod *method, MonoGenericContext *context, MonoError *error)
-{
-	return mono_class_inflate_generic_method_full_checked (method, NULL, context, error);
-}
-static gboolean
-inflated_method_equal (gconstpointer a, gconstpointer b)
-{
-	const MonoMethodInflated *ma = (const MonoMethodInflated *)a;
-	const MonoMethodInflated *mb = (const MonoMethodInflated *)b;
-	if (ma->declaring != mb->declaring)
-		return FALSE;
-	return mono_metadata_generic_context_equal (&ma->context, &mb->context);
-}
-static guint
-inflated_method_hash (gconstpointer a)
-{
-	const MonoMethodInflated *ma = (const MonoMethodInflated *)a;
-	return (mono_metadata_generic_context_hash (&ma->context) ^ mono_aligned_addr_hash (ma->declaring));
-}
-static void
-free_inflated_method (MonoMethodInflated *imethod)
-{
-	MonoMethod *method = (MonoMethod*)imethod;
-	if (method->signature)
-		mono_metadata_free_inflated_signature (method->signature);
-	if (method->wrapper_type)
-		g_free (((MonoMethodWrapper*)method)->method_data);
-	g_free (method);
-}
-/**
- * mono_class_inflate_generic_method_full_checked:
- * Instantiate method \p method with the generic context \p context.
- * On failure returns NULL and sets \p error.
- *
- * BEWARE: All non-trivial fields are invalid, including klass, signature, and header.
- *         Use mono_method_signature_internal () and mono_method_get_header () to get the correct values.
- */
-MonoMethod*
-mono_class_inflate_generic_method_full_checked (MonoMethod *method, MonoClass *klass_hint, MonoGenericContext *context, MonoError *error)
-{
-	MonoMethod *result;
-	MonoMethodInflated *iresult, *cached = NULL;
-	MonoMethodSignature *sig;
-	MonoGenericContext tmp_context;
-	error_init (error);
-	/* The `method' has already been instantiated before => we need to peel out the instantiation and create a new context */
-	while (method->is_inflated) {
-		MonoGenericContext *method_context = mono_method_get_context (method);
-		MonoMethodInflated *imethod = (MonoMethodInflated *) method;
-		tmp_context = inflate_generic_context (method_context, context, error);
-		return_val_if_nok (error, NULL);
-		context = &tmp_context;
-		if (mono_metadata_generic_context_equal (method_context, context))
-			return method;
-		method = imethod->declaring;
-	}
-	/*
-	 * A method only needs to be inflated if the context has argument for which it is
-	 * parameteric. Eg:
-	 *
-	 * class Foo<T> { void Bar(); } - doesn't need to be inflated if only mvars' are supplied
-	 * class Foo { void Bar<T> (); } - doesn't need to be if only vars' are supplied
-	 *
-	 */
-	if (!((method->is_generic && context->method_inst) ||
-		(mono_class_is_gtd (method->klass) && context->class_inst)))
-		return method;
-	iresult = g_new0 (MonoMethodInflated, 1);
-	iresult->context = *context;
-	iresult->declaring = method;
-	if (!context->method_inst && method->is_generic)
-		iresult->context.method_inst = mono_method_get_generic_container (method)->context.method_inst;
-	if (!context->class_inst) {
-		g_assert (!mono_class_is_ginst (iresult->declaring->klass));
-		if (mono_class_is_gtd (iresult->declaring->klass))
-			iresult->context.class_inst = mono_class_get_generic_container (iresult->declaring->klass)->context.class_inst;
-	}
-	/* This can happen with some callers like mono_object_get_virtual_method_internal () */
-	if (!mono_class_is_gtd (iresult->declaring->klass) && !mono_class_is_ginst (iresult->declaring->klass))
-		iresult->context.class_inst = NULL;
-	MonoMemoryManager *mm = mono_metadata_get_mem_manager_for_method (iresult);
-	mono_mem_manager_lock (mm);
-	if (!mm->gmethod_cache)
-		mm->gmethod_cache = dn_simdhash_ght_new_full (inflated_method_hash, inflated_method_equal, NULL, (GDestroyNotify)free_inflated_method, 0, NULL);
-	dn_simdhash_ght_try_get_value (mm->gmethod_cache, iresult, (void **)&cached);
-	mono_mem_manager_unlock (mm);
-	if (cached) {
-		g_free (iresult);
-		return (MonoMethod*)cached;
-	}
-	UnlockedIncrement (&mono_stats.inflated_method_count);
-	UnlockedAdd (&mono_inflated_methods_size,  sizeof (MonoMethodInflated));
-	sig = mono_method_signature_internal (method);
-	if (!sig) {
-		char *name = mono_type_get_full_name (method->klass);
-		mono_error_set_bad_image (error, mono_method_get_image (method), "Could not resolve signature of method %s:%s", name, method->name);
-		g_free (name);
-		goto fail;
-	}
-	if (sig->pinvoke) {
-		memcpy (&iresult->method.pinvoke, method, sizeof (MonoMethodPInvoke));
-	} else {
-		memcpy (&iresult->method.method, method, sizeof (MonoMethod));
-	}
-	result = (MonoMethod *) iresult;
-	result->is_inflated = TRUE;
-	result->is_generic = FALSE;
-	result->sre_method = FALSE;
-	result->signature = NULL;
-	if (method->wrapper_type) {
-		MonoMethodWrapper *mw = (MonoMethodWrapper*)method;
-		MonoMethodWrapper *resw = (MonoMethodWrapper*)result;
-		int len = GPOINTER_TO_INT (((void**)mw->method_data) [0]);
-		resw->method_data = (void **)g_malloc (sizeof (gpointer) * (len + 1));
-		memcpy (resw->method_data, mw->method_data, sizeof (gpointer) * (len + 1));
-		if (mw->inflate_wrapper_data) {
-			mono_mb_inflate_generic_wrapper_data (context, (gpointer*)resw->method_data, error);
-			if (!is_ok (error)) {
-				g_free (resw->method_data);
-				goto fail;
-			}
-			resw->inflate_wrapper_data = 1;
-		}
-	}
-	if (iresult->context.method_inst) {
-		MonoGenericInst *method_inst = iresult->context.method_inst;
-		/* Set the generic_container of the result to the generic_container of method */
-		MonoGenericContainer *generic_container = mono_method_get_generic_container (method);
-		if (generic_container && method_inst == generic_container->context.method_inst) {
-			result->is_generic = 1;
-			mono_method_set_generic_container (result, generic_container);
-		}
-		/* Check that the method is not instantiated with any invalid types */
-		for (guint i = 0; i < method_inst->type_argc; i++) {
-			if (!mono_type_is_valid_generic_argument (method_inst->type_argv [i])) {
-				mono_error_set_bad_image (error, mono_method_get_image (method), "MVAR %u cannot be expanded with type 0x%x",
-							  i, method_inst->type_argv [i]->type);
-				goto fail;
-			}
-		}
-	}
-	if (klass_hint) {
-		MonoGenericClass *gklass_hint = mono_class_try_get_generic_class (klass_hint);
-		if (gklass_hint && (gklass_hint->container_class != method->klass || gklass_hint->context.class_inst != context->class_inst))
-			klass_hint = NULL;
-	}
-	if (mono_class_is_gtd (method->klass))
-		result->klass = klass_hint;
-	if (!result->klass) {
-		MonoType *inflated = inflate_generic_type (NULL, m_class_get_byval_arg (method->klass), context, error);
-		if (!is_ok (error))
-			goto fail;
-		result->klass = inflated ? mono_class_from_mono_type_internal (inflated) : method->klass;
-		if (inflated)
-			mono_metadata_free_type (inflated);
-	}
-	/*
-	 * FIXME: This should hold, but it doesn't:
-	 *
-	 * if (result->is_inflated && mono_method_get_context (result)->method_inst &&
-	 *		mono_method_get_context (result)->method_inst == mono_method_get_generic_container (((MonoMethodInflated*)result)->declaring)->context.method_inst) {
-	 * 	g_assert (result->is_generic);
-	 * }
-	 *
-	 * Fixing this here causes other things to break, hence a very
-	 * ugly hack in mini-trampolines.c - see
-	 * is_generic_method_definition().
-	 */
-	mono_mem_manager_lock (mm);
-	cached = NULL;
-	dn_simdhash_ght_try_get_value (mm->gmethod_cache, iresult, (void **)&cached);
-	if (!cached) {
-		dn_simdhash_ght_insert (mm->gmethod_cache, iresult, iresult);
-		iresult->owner = mm;
-		cached = iresult;
-	}
-	mono_mem_manager_unlock (mm);
-	return (MonoMethod*)cached;
-fail:
-	g_free (iresult);
-	return NULL;
-}
-/**
- * mono_get_inflated_method:
- *
- * Obsolete.  We keep it around since it's mentioned in the public API.
- */
-MonoMethod*
-mono_get_inflated_method (MonoMethod *method)
-{
-	return method;
-}
-/*
- * mono_method_get_context_general:
- * @method: a method
- * @uninflated: handle uninflated methods?
- *
- * Returns the generic context of a method or NULL if it doesn't have
- * one.  For an inflated method that's the context stored in the
- * method.  Otherwise it's in the method's generic container or in the
- * generic container of the method's class.
- */
-MonoGenericContext*
-mono_method_get_context_general (MonoMethod *method, gboolean uninflated)
-{
-	if (method->is_inflated) {
-		MonoMethodInflated *imethod = (MonoMethodInflated *) method;
-		return &imethod->context;
-	}
-	if (!uninflated)
-		return NULL;
-	if (method->is_generic)
-		return &(mono_method_get_generic_container (method)->context);
-	if (mono_class_is_gtd (method->klass))
-		return &mono_class_get_generic_container (method->klass)->context;
-	return NULL;
-}
-/*
- * mono_method_get_context:
- * @method: a method
- *
- * Returns the generic context for method if it's inflated, otherwise
- * NULL.
- */
-MonoGenericContext*
-mono_method_get_context (MonoMethod *method)
-{
-	return mono_method_get_context_general (method, FALSE);
-}
-/*
- * mono_method_get_generic_container:
- *
- *   Returns the generic container of METHOD, which should be a generic method definition.
- * Returns NULL if METHOD is not a generic method definition.
- * LOCKING: Acquires the loader lock.
- */
-MonoGenericContainer*
-mono_method_get_generic_container (MonoMethod *method)
-{
-	MonoGenericContainer *container;
-	if (!method->is_generic)
-		return NULL;
-	container = (MonoGenericContainer *)mono_image_property_lookup (mono_method_get_image (method), method, MONO_METHOD_PROP_GENERIC_CONTAINER);
-	g_assert (container);
-	return container;
-}
-/*
- * mono_method_set_generic_container:
- *
- *   Sets the generic container of METHOD to CONTAINER.
- * LOCKING: Acquires the image lock.
- */
-void
-mono_method_set_generic_container (MonoMethod *method, MonoGenericContainer* container)
-{
-	g_assert (method->is_generic);
-	mono_image_property_insert (mono_method_get_image (method), method, MONO_METHOD_PROP_GENERIC_CONTAINER, container);
-}
-/**
- * mono_method_set_verification_success:
- *
- * Sets a bit indicating that the method has been verified.
- *
- * LOCKING: acquires the image lock.
- */
-void
-mono_method_set_verification_success (MonoMethod *method)
-{
-	g_assert (!method->is_inflated);
-	mono_image_property_insert (mono_method_get_image (method), method, MONO_METHOD_PROP_VERIFICATION_SUCCESS, GUINT_TO_POINTER(1));
-}
-/**
- * mono_method_get_verification_success:
- *
- * Returns \c TRUE if the method has been verified successfully.
- *
- * LOCKING: acquires the image lock.
- */
-gboolean
-mono_method_get_verification_success (MonoMethod *method)
-{
-	if (method->is_inflated)
-		method = ((MonoMethodInflated *)method)->declaring;
-	gpointer value = mono_image_property_lookup (mono_method_get_image (method), method, MONO_METHOD_PROP_VERIFICATION_SUCCESS);
-	return value != NULL;
-}
-/**
- * mono_method_lookup_infrequent_bits:
- *
- * Looks for existing \c MonoMethodDefInfrequentBits struct associated with
- * this method definition.  Unlike \c mono_method_get_infrequent bits, this
- * does not allocate a new struct if one doesn't exist.
- *
- * LOCKING: Acquires the image lock
- */
-const MonoMethodDefInfrequentBits*
-mono_method_lookup_infrequent_bits (MonoMethod *method)
-{
-	g_assert (!method->is_inflated);
-	return (const MonoMethodDefInfrequentBits*)mono_image_property_lookup (mono_method_get_image (method), method, MONO_METHOD_PROP_INFREQUENT_BITS);
-}
-/**
- * mono_method_get_infrequent_bits:
- *
- * Looks for an existing, or allocates a new \c MonoMethodDefInfrequentBits struct for this method definition.
- * Method must not be inflated.
- *
- * Unlike \c mono_method_lookup_infrequent_bits, this will allocate a new
- * struct if the method didn't have one.
- *
- * LOCKING: Acquires the image lock
- */
-MonoMethodDefInfrequentBits *
-mono_method_get_infrequent_bits (MonoMethod *method)
-{
-	g_assert (!method->is_inflated);
-	MonoImage *image = mono_method_get_image (method);
-	MonoMethodDefInfrequentBits *infrequent_bits = NULL;
-	mono_image_lock (image);
-	infrequent_bits = (MonoMethodDefInfrequentBits *)mono_image_property_lookup (image, method, MONO_METHOD_PROP_INFREQUENT_BITS);
-	if (!infrequent_bits) {
-		infrequent_bits = (MonoMethodDefInfrequentBits *)mono_image_alloc0 (image, sizeof (MonoMethodDefInfrequentBits));
-		mono_image_property_insert (image, method, MONO_METHOD_PROP_INFREQUENT_BITS, infrequent_bits);
-	}
-	mono_image_unlock (image);
-	return infrequent_bits;
-}
-gboolean
-mono_method_get_is_reabstracted (MonoMethod *method)
-{
-	if (method->is_inflated)
-		method = ((MonoMethodInflated*)method)->declaring;
-	const MonoMethodDefInfrequentBits *infrequent_bits = mono_method_lookup_infrequent_bits (method);
-	return infrequent_bits != NULL && infrequent_bits->is_reabstracted;
-}
-gboolean
-mono_method_get_is_covariant_override_impl (MonoMethod *method)
-{
-	if (method->is_inflated)
-		method = ((MonoMethodInflated*)method)->declaring;
-	const MonoMethodDefInfrequentBits *infrequent_bits = mono_method_lookup_infrequent_bits (method);
-	return infrequent_bits != NULL && infrequent_bits->is_covariant_override_impl;
-}
-/**
- * mono_method_set_is_reabstracted:
- *
- * Sets the \c MonoMethodDefInfrequentBits:is_reabstracted bit for this method
- * definition.  The bit means that the method is a default interface method
- * that used to have a default implementation in an ancestor interface, but is
- * now abstract once again.
- *
- * LOCKING: Assumes the loader lock is held
- */
-void
-mono_method_set_is_reabstracted (MonoMethod *method)
-{
-	mono_method_get_infrequent_bits (method)->is_reabstracted = 1;
-}
-/**
- * mono_method_set_is_covariant_override_impl:
- *
- * Sets the \c MonoMethodDefInfrequentBits:is_covariant_override_impl bit for
- * this method definition.  The bit means that the method is an override with a
- * signature that is not equal to the signature of the method that it is
- * overriding.
- *
- * LOCKING: Assumes the loader lock is held
- */
-void
-mono_method_set_is_covariant_override_impl (MonoMethod *method)
-{
-	mono_method_get_infrequent_bits (method)->is_covariant_override_impl = 1;
-}
-/**
- * mono_class_find_enum_basetype:
- * \param class The enum class
- *
- *   Determine the basetype of an enum by iterating through its fields. We do this
- * in a separate function since it is cheaper than calling mono_class_setup_fields.
- */
-MonoType*
-mono_class_find_enum_basetype (MonoClass *klass, MonoError *error)
-{
-	MonoGenericContainer *container = NULL;
-	MonoImage *image = m_class_get_image (klass);
-	const int top = mono_class_get_field_count (klass);
-	int i, first_field_idx;
-	g_assert (m_class_is_enumtype (klass));
-	error_init (error);
-	container = mono_class_try_get_generic_container (klass);
-	if (mono_class_is_ginst (klass)) {
-		MonoClass *gklass = mono_class_get_generic_class (klass)->container_class;
-		container = mono_class_get_generic_container (gklass);
-		g_assert (container);
-	}
-	/*
-	 * Fetch all the field information.
-	 */
-	first_field_idx = mono_class_get_first_field_idx (klass);
-	/*
-	 * metadata-update: adding new enum fields isn't supported, so when this code runs, all the
-	 * fields are contiguous in metadata.
-	 */
-	for (i = 0; i < top; i++){
-		const char *sig;
-		guint32 cols [MONO_FIELD_SIZE];
-		int idx = first_field_idx + i;
-		MonoType *ftype;
-		/* first_field_idx and idx points into the fieldptr table */
-		mono_metadata_decode_table_row (image, MONO_TABLE_FIELD, idx, cols, MONO_FIELD_SIZE);
-		if (cols [MONO_FIELD_FLAGS] & FIELD_ATTRIBUTE_STATIC) //no need to decode static fields
-			continue;
-		sig = mono_metadata_blob_heap (image, cols [MONO_FIELD_SIGNATURE]);
-		mono_metadata_decode_value (sig, &sig);
-		/* FIELD signature == 0x06 */
-		if (*sig != 0x06) {
-			mono_error_set_bad_image (error, image, "Invalid field signature %x, expected 0x6 but got %x", cols [MONO_FIELD_SIGNATURE], *sig);
-			goto fail;
-		}
-		ftype = mono_metadata_parse_type_checked (image, container, cols [MONO_FIELD_FLAGS], FALSE, sig + 1, &sig, error);
-		if (!ftype)
-			goto fail;
-		if (mono_class_is_ginst (klass)) {
-			ftype = mono_class_inflate_generic_type_checked (ftype, mono_class_get_context (klass), error);
-			if (!is_ok (error))
-				goto fail;
-			ftype->attrs = cols [MONO_FIELD_FLAGS];
-		}
-		return ftype;
-	}
-	mono_error_set_type_load_class (error, klass, "Could not find base type");
-fail:
-	return NULL;
-}
-/*
- * Checks for MonoClass::has_failure without resolving all MonoType's into MonoClass'es
- */
-gboolean
-mono_type_has_exceptions (MonoType *type)
-{
-	switch (type->type) {
-	case MONO_TYPE_CLASS:
-	case MONO_TYPE_VALUETYPE:
-	case MONO_TYPE_SZARRAY:
-		return mono_class_has_failure (type->data.klass);
-	case MONO_TYPE_ARRAY:
-		return mono_class_has_failure (type->data.array->eklass);
-	case MONO_TYPE_GENERICINST:
-		return mono_class_has_failure (mono_class_create_generic_inst (type->data.generic_class));
-	default:
-		return FALSE;
-	}
-}
-void
-mono_error_set_for_class_failure (MonoError *oerror, const MonoClass *klass)
-{
-	g_assert (mono_class_has_failure (klass));
-	MonoErrorBoxed *box = mono_class_get_exception_data ((MonoClass*)klass);
-	mono_error_set_from_boxed (oerror, box);
-}
-/*
- * mono_class_alloc:
- *
- *   Allocate memory for data belonging to CLASS.
- */
-gpointer
-mono_class_alloc (MonoClass *klass, int size)
-{
-	return m_class_alloc (klass, size);
-}
-gpointer
-(mono_class_alloc0) (MonoClass *klass, int size)
-{
-	return m_class_alloc0 (klass, size);
-}
-#define mono_class_new0(klass,struct_type, n_structs)		\
-    ((struct_type *) mono_class_alloc0 ((klass), ((gsize) sizeof (struct_type)) * ((gsize) (n_structs))))
-/**
- * mono_class_set_failure_causedby_class:
- * \param klass the class that is failing
- * \param caused_by the class that caused the failure
- * \param msg Why \p klass is failing.
- *
- * If \p caused_by has a failure, sets a TypeLoadException failure on
- * \p klass with message "\p msg, due to: {\p caused_by message}".
- *
- * \returns TRUE if a failiure was set, or FALSE if \p caused_by doesn't have a failure.
- */
-gboolean
-mono_class_set_type_load_failure_causedby_class (MonoClass *klass, const MonoClass *caused_by, const gchar* msg)
-{
-	if (mono_class_has_failure (caused_by)) {
-		ERROR_DECL (cause_error);
-		mono_error_set_for_class_failure (cause_error, caused_by);
-		mono_class_set_type_load_failure (klass, "%s, due to: %s", msg, mono_error_get_message (cause_error));
-		mono_error_cleanup (cause_error);
-		return TRUE;
-	} else {
-		return FALSE;
-	}
-}
-/*
- * mono_type_get_basic_type_from_generic:
- * @type: a type
- *
- * Returns a closed type corresponding to the possibly open type
- * passed to it.
- */
-MonoType*
-mono_type_get_basic_type_from_generic (MonoType *type)
-{
-	/* When we do generic sharing we let type variables stand for reference/primitive types. */
-	if (!m_type_is_byref (type) && (type->type == MONO_TYPE_VAR || type->type == MONO_TYPE_MVAR) &&
-		(!type->data.generic_param->gshared_constraint || type->data.generic_param->gshared_constraint->type == MONO_TYPE_OBJECT))
-		return mono_get_object_type ();
-	return type;
-}
-/*
- * mono_class_get_method_by_index:
- *
- *   Returns klass->methods [index], initializing klass->methods if necessary.
- *
- * LOCKING: Acquires the loader lock.
- */
-MonoMethod*
-mono_class_get_method_by_index (MonoClass *klass, int index)
-{
-	ERROR_DECL (error);
-	MonoGenericClass *gklass = mono_class_try_get_generic_class (klass);
-	/* Avoid calling setup_methods () if possible */
-	if (gklass && !m_class_get_methods (klass)) {
-		MonoMethod *m;
-		m = mono_class_inflate_generic_method_full_checked (
-			m_class_get_methods (gklass->container_class) [index], klass, mono_class_get_context (klass), error);
-		g_assert (is_ok (error)); /* FIXME don't swallow the error */
-		/*
-		 * If setup_methods () is called later for this class, no duplicates are created,
-		 * since inflate_generic_method guarantees that only one instance of a method
-		 * is created for each context.
-		 */
-		/*
-		mono_class_setup_methods (klass);
-		g_assert (m == klass->methods [index]);
-		*/
-		return m;
-	} else {
-		mono_class_setup_methods (klass);
-		if (mono_class_has_failure (klass)) /*FIXME do proper error handling*/
-			return NULL;
-		g_assert (index >= 0 && GINT_TO_UINT32(index) < mono_class_get_method_count (klass));
-		return m_class_get_methods (klass) [index];
-	}
-}
-/**
- * mono_class_get_inflated_method:
- * \param klass an inflated class
- * \param method a method of \p klass's generic definition
- * \param error set on error
- *
- * Given an inflated class \p klass and a method \p method which should be a
- * method of \p klass's generic definition, return the inflated method
- * corresponding to \p method.
- *
- * On failure sets \p error and returns NULL.
- */
-MonoMethod*
-mono_class_get_inflated_method (MonoClass *klass, MonoMethod *method, MonoError *error)
-{
-	MonoClass *gklass = mono_class_get_generic_class (klass)->container_class;
-	int i, mcount;
-	g_assert (method->klass == gklass);
-	mono_class_setup_methods (gklass);
-	if (mono_class_has_failure (gklass)) {
-		mono_error_set_for_class_failure (error, gklass);
-		return NULL;
-	}
-	MonoMethod **gklass_methods = m_class_get_methods (gklass);
-	mcount = mono_class_get_method_count (gklass);
-	for (i = 0; i < mcount; ++i) {
-		if (gklass_methods [i] == method) {
-			MonoMethod *inflated_method = NULL;
-			MonoMethod **klass_methods = m_class_get_methods (klass);
-			if (klass_methods) {
-				inflated_method = klass_methods [i];
-			} else {
-				inflated_method = mono_class_inflate_generic_method_full_checked (gklass_methods [i], klass, mono_class_get_context (klass), error);
-				return_val_if_nok (error, NULL);
-			}
-			g_assert (inflated_method);
-			return inflated_method;
-		}
-	}
-	g_assert_not_reached ();
-}
-/*
- * mono_class_get_vtable_entry:
- *
- *   Returns klass->vtable [offset], computing it if necessary. Returns NULL on failure.
- * LOCKING: Acquires the loader lock.
- */
-MonoMethod*
-mono_class_get_vtable_entry (MonoClass *klass, int offset)
-{
-	MonoMethod *m;
-	if (m_class_get_rank (klass) == 1) {
-		MonoClass *klass_parent = m_class_get_parent (klass);
-		/*
-		 * szarrays do not overwrite any methods of Array, so we can avoid
-		 * initializing their vtables in some cases.
-		 */
-		mono_class_setup_vtable (klass_parent);
-		if (offset < m_class_get_vtable_size (klass_parent))
-			return m_class_get_vtable (klass_parent) [offset];
-	}
-	if (mono_class_is_ginst (klass)) {
-		ERROR_DECL (error);
-		MonoClass *gklass = mono_class_get_generic_class (klass)->container_class;
-		mono_class_setup_vtable (gklass);
-		m = m_class_get_vtable (gklass) [offset];
-		m = mono_class_inflate_generic_method_full_checked (m, klass, mono_class_get_context (klass), error);
-		g_assert (is_ok (error)); /* FIXME don't swallow this error */
-	} else {
-		mono_class_setup_vtable (klass);
-		if (mono_class_has_failure (klass))
-			return NULL;
-		m = m_class_get_vtable (klass) [offset];
-	}
-	return m;
-}
-/*
- * mono_class_get_vtable_size:
- *
- *   Return the vtable size for KLASS.
- */
-int
-mono_class_get_vtable_size (MonoClass *klass)
-{
-	mono_class_setup_vtable (klass);
-	return m_class_get_vtable_size (klass);
-}
-static void
-collect_implemented_interfaces_aux (MonoClass *klass, GPtrArray **res, GHashTable **ifaces, MonoError *error)
-{
-	int i;
-	MonoClass *ic;
-	mono_class_setup_interfaces (klass, error);
-	return_if_nok (error);
-	MonoClass **klass_interfaces = m_class_get_interfaces (klass);
-	for (i = 0; i < m_class_get_interface_count (klass); i++) {
-		ic = klass_interfaces [i];
-		if (*res == NULL)
-			*res = g_ptr_array_new ();
-		if (*ifaces == NULL)
-			*ifaces = g_hash_table_new (NULL, NULL);
-		if (g_hash_table_lookup (*ifaces, ic))
-			continue;
-		/* A gparam is not an implemented interface for the purposes of
-		 * mono_class_get_implemented_interfaces */
-		if (mono_class_is_gparam (ic))
-			continue;
-		g_ptr_array_add (*res, ic);
-		g_hash_table_insert (*ifaces, ic, ic);
-		mono_class_init_internal (ic);
-		if (mono_class_has_failure (ic)) {
-			mono_error_set_type_load_class (error, ic, "Error Loading class");
-			return;
-		}
-		collect_implemented_interfaces_aux (ic, res, ifaces, error);
-		return_if_nok (error);
-	}
-}
-GPtrArray*
-mono_class_get_implemented_interfaces (MonoClass *klass, MonoError *error)
-{
-	GPtrArray *res = NULL;
-	GHashTable *ifaces = NULL;
-	collect_implemented_interfaces_aux (klass, &res, &ifaces, error);
-	if (ifaces)
-		g_hash_table_destroy (ifaces);
-	if (!is_ok (error)) {
-		if (res)
-			g_ptr_array_free (res, TRUE);
-		return NULL;
-	}
-	return res;
-}
-/*FIXME verify all callers if they should switch to mono_class_interface_offset_with_variance*/
-int
-mono_class_interface_offset (MonoClass *klass, MonoClass *itf)
-{
-	int i;
-	MonoClass **klass_interfaces_packed = m_class_get_interfaces_packed (klass);
-	for (i = m_class_get_interface_offsets_count (klass) -1 ; i >= 0 ; i-- ){
-		MonoClass *result = klass_interfaces_packed[i];
-		if (m_class_get_interface_id(result) == m_class_get_interface_id(itf)) {
-			return m_class_get_interface_offsets_packed (klass) [i];
-		}
-	}
-	return -1;
-}
-/**
- * mono_class_interface_offset_with_variance:
- *
- * Return the interface offset of \p itf in \p klass. Sets \p non_exact_match to TRUE if the match required variance check
- * If \p itf is an interface with generic variant arguments, try to find the compatible one.
- *
- * Note that this function is responsible for resolving ambiguities. Right now we use whatever ordering interfaces_packed gives us.
- *
- * FIXME figure out MS disambiguation rules and fix this function.
- */
-int
-mono_class_interface_offset_with_variance (MonoClass *klass, MonoClass *itf, gboolean *non_exact_match)
-{
-	gboolean has_variance = mono_class_has_variant_generic_params (itf);
-	int exact_match = mono_class_interface_offset (klass, itf), i = -1;
-	*non_exact_match = FALSE;
-	if (exact_match >= 0) {
-		if (!has_variance)
-			return exact_match;
-	}
-	int klass_interface_offsets_count = m_class_get_interface_offsets_count (klass);
-	if (m_class_is_array_special_interface (itf) && m_class_get_rank (klass) < 2) {
-		MonoClass *gtd = mono_class_get_generic_type_definition (itf);
-		int found = -1;
-		for (i = 0; i < klass_interface_offsets_count; i++) {
-			if (mono_class_is_variant_compatible (itf, m_class_get_interfaces_packed (klass) [i], FALSE)) {
-				found = i;
-				*non_exact_match = (i != exact_match);
-				break;
-			}
-		}
-		if (found != -1)
-			return m_class_get_interface_offsets_packed (klass) [found];
-		for (i = 0; i < klass_interface_offsets_count; i++) {
-			if (mono_class_get_generic_type_definition (m_class_get_interfaces_packed (klass) [i]) == gtd) {
-				found = i;
-				*non_exact_match = (i != exact_match);
-				break;
-			}
-		}
-		if (found == -1)
-			return -1;
-		return m_class_get_interface_offsets_packed (klass) [found];
-	} else if (has_variance) {
-		int vst_count, offset = 0;
-		MonoVarianceSearchTableEntry *vst = mono_class_get_variance_search_table (klass, &vst_count);
-		while (offset < vst_count) {
-			for (i = offset; i < vst_count; i++) {
-				if (vst [i].klass == NULL)
-					break;
-				if (itf != vst [i].klass)
-					continue;
-				*non_exact_match = FALSE;
-				g_assert (vst [i].offset == exact_match);
-				return exact_match;
-			}
-			for (i = offset; i < vst_count; i++) {
-				if (vst [i].klass == NULL) {
-					offset = i + 1;
-					break;
-				}
-				if (!mono_class_is_variant_compatible (itf, vst [i].klass, FALSE))
-					continue;
-				int inexact_match = vst [i].offset;
-				*non_exact_match = inexact_match != exact_match;
-				return inexact_match;
-			}
-		}
-		*non_exact_match = (exact_match < 0);
-		return exact_match;
-	}
-	return -1;
-}
-/*
- * mono_method_get_vtable_slot:
- *
- *   Returns method->slot, computing it if necessary. Return -1 on failure.
- * LOCKING: Acquires the loader lock.
- *
- * FIXME Use proper MonoError machinery here.
- */
-int
-mono_method_get_vtable_slot (MonoMethod *method)
-{
-	if (method->slot == -1) {
-		mono_class_setup_vtable (method->klass);
-		if (mono_class_has_failure (method->klass))
-			return -1;
-		if (method->slot == -1) {
-			MonoClass *gklass;
-			int i, mcount;
-			if (!mono_class_is_ginst (method->klass)) {
-				g_assert (method->is_inflated);
-				return mono_method_get_vtable_slot (((MonoMethodInflated*)method)->declaring);
-			}
-			/* This can happen for abstract methods of generic instances due to the shortcut code in mono_class_setup_vtable_general (). */
-			g_assert (mono_class_is_ginst (method->klass));
-			gklass = mono_class_get_generic_class (method->klass)->container_class;
-			mono_class_setup_methods (method->klass);
-			MonoMethod **klass_methods = m_class_get_methods (method->klass);
-			g_assert (klass_methods);
-			mcount = mono_class_get_method_count (method->klass);
-			for (i = 0; i < mcount; ++i) {
-				if (klass_methods [i] == method)
-					break;
-			}
-			g_assert (i < mcount);
-			g_assert (m_class_get_methods (gklass));
-			method->slot = m_class_get_methods (gklass) [i]->slot;
-		}
-		g_assert (method->slot != -1);
-	}
-	return method->slot;
-}
-/**
- * mono_method_get_vtable_index:
- * \param method a method
- *
- * Returns the index into the runtime vtable to access the method or,
- * in the case of a virtual generic method, the virtual generic method
- * thunk. Returns -1 on failure.
- *
- * FIXME Use proper MonoError machinery here.
- */
-int
-mono_method_get_vtable_index (MonoMethod *method)
-{
-	if (method->is_inflated && (method->flags & METHOD_ATTRIBUTE_VIRTUAL)) {
-		MonoMethodInflated *imethod = (MonoMethodInflated*)method;
-		if (imethod->declaring->is_generic)
-			return mono_method_get_vtable_slot (imethod->declaring);
-	}
-	return mono_method_get_vtable_slot (method);
-}
-/*
- * mono_class_has_finalizer:
- *
- *   Return whenever KLASS has a finalizer, initializing klass->has_finalizer in the
- * process.
- *
- * LOCKING: Acquires the loader lock;
- */
-gboolean
-mono_class_has_finalizer (MonoClass *klass)
-{
-	if (!m_class_is_has_finalize_inited (klass))
-		mono_class_setup_has_finalizer (klass);
-	return m_class_has_finalize (klass);
-}
-gboolean
-mono_is_corlib_image (MonoImage *image)
-{
-	return image == mono_defaults.corlib;
-}
-/** Is klass a Nullable<T> ginst? */
-gboolean
-mono_class_is_nullable (MonoClass *klass)
-{
-	MonoGenericClass *gklass = mono_class_try_get_generic_class (klass);
-	return gklass && gklass->container_class == mono_defaults.generic_nullable_class;
-}
-/** if klass is T? return T */
-MonoClass*
-mono_class_get_nullable_param_internal (MonoClass *klass)
-{
-	g_assert (mono_class_is_nullable (klass));
-	return mono_class_from_mono_type_internal (mono_class_get_generic_class (klass)->context.class_inst->type_argv [0]);
-}
-MonoClass*
-mono_class_get_nullable_param (MonoClass *klass)
-{
-	MonoClass *result = NULL;
-	MONO_ENTER_GC_UNSAFE;
-	result = mono_class_get_nullable_param_internal (klass);
-	MONO_EXIT_GC_UNSAFE;
-	return result;
-}
-gboolean
-mono_type_is_primitive (MonoType *type)
-{
-	return (type->type >= MONO_TYPE_BOOLEAN && type->type <= MONO_TYPE_R8) ||
-			type-> type == MONO_TYPE_I || type->type == MONO_TYPE_U;
-}
-static MonoImage *
-get_image_for_container (MonoGenericContainer *container)
-{
-	MonoImage *result;
-	if (container->is_anonymous) {
-		result = container->owner.image;
-	} else {
-		MonoClass *klass;
-		if (container->is_method) {
-			MonoMethod *method = container->owner.method;
-			g_assert_checked (method);
-			klass = method->klass;
-		} else {
-			klass = container->owner.klass;
-		}
-		g_assert_checked (klass);
-		result = m_class_get_image (klass);
-	}
-	g_assert (result);
-	return result;
-}
-MonoImage *
-mono_get_image_for_generic_param (MonoGenericParam *param)
-{
-	MonoGenericContainer *container = mono_generic_param_owner (param);
-	g_assert_checked (container);
-	return get_image_for_container (container);
-}
-#define INT_STRING_SIZE 16
-char *
-mono_make_generic_name_string (MonoImage *image, int num)
-{
-	char *name = (char *)mono_image_alloc0 (image, INT_STRING_SIZE);
-	g_snprintf (name, INT_STRING_SIZE, "%d", num);
-	return name;
-}
-/**
- * mono_class_from_generic_parameter:
- * \param param Parameter to find/construct a class for.
- * \param arg2 Is ignored.
- * \param arg3 Is ignored.
- */
-MonoClass *
-mono_class_from_generic_parameter (MonoGenericParam *param, MonoImage *arg2 G_GNUC_UNUSED, gboolean arg3 G_GNUC_UNUSED)
-{
-	return mono_class_create_generic_parameter (param);
-}
-/**
- * mono_ptr_class_get:
- */
-MonoClass *
-mono_ptr_class_get (MonoType *type)
-{
-	return mono_class_create_ptr (type);
-}
-/**
- * mono_class_from_mono_type:
- * \param type describes the type to return
- * \returns a \c MonoClass for the specified \c MonoType, the value is never NULL.
- */
-MonoClass *
-mono_class_from_mono_type (MonoType *type)
-{
-	MonoClass *result;
-	MONO_ENTER_GC_UNSAFE;
-	result = mono_class_from_mono_type_internal (type);
-	MONO_EXIT_GC_UNSAFE;
-	return result;
-}
-MonoClass *
-mono_class_from_mono_type_internal (MonoType *type)
-{
-	g_assert (type);
-	switch (type->type) {
-	case MONO_TYPE_OBJECT:
-		return type->data.klass? type->data.klass: mono_defaults.object_class;
-	case MONO_TYPE_VOID:
-		return type->data.klass? type->data.klass: mono_defaults.void_class;
-	case MONO_TYPE_BOOLEAN:
-		return type->data.klass? type->data.klass: mono_defaults.boolean_class;
-	case MONO_TYPE_CHAR:
-		return type->data.klass? type->data.klass: mono_defaults.char_class;
-	case MONO_TYPE_I1:
-		return type->data.klass? type->data.klass: mono_defaults.sbyte_class;
-	case MONO_TYPE_U1:
-		return type->data.klass? type->data.klass: mono_defaults.byte_class;
-	case MONO_TYPE_I2:
-		return type->data.klass? type->data.klass: mono_defaults.int16_class;
-	case MONO_TYPE_U2:
-		return type->data.klass? type->data.klass: mono_defaults.uint16_class;
-	case MONO_TYPE_I4:
-		return type->data.klass? type->data.klass: mono_defaults.int32_class;
-	case MONO_TYPE_U4:
-		return type->data.klass? type->data.klass: mono_defaults.uint32_class;
-	case MONO_TYPE_I:
-		return type->data.klass? type->data.klass: mono_defaults.int_class;
-	case MONO_TYPE_U:
-		return type->data.klass? type->data.klass: mono_defaults.uint_class;
-	case MONO_TYPE_I8:
-		return type->data.klass? type->data.klass: mono_defaults.int64_class;
-	case MONO_TYPE_U8:
-		return type->data.klass? type->data.klass: mono_defaults.uint64_class;
-	case MONO_TYPE_R4:
-		return type->data.klass? type->data.klass: mono_defaults.single_class;
-	case MONO_TYPE_R8:
-		return type->data.klass? type->data.klass: mono_defaults.double_class;
-	case MONO_TYPE_STRING:
-		return type->data.klass? type->data.klass: mono_defaults.string_class;
-	case MONO_TYPE_TYPEDBYREF:
-		return type->data.klass? type->data.klass: mono_defaults.typed_reference_class;
-	case MONO_TYPE_ARRAY:
-		return mono_class_create_bounded_array (type->data.array->eklass, type->data.array->rank, TRUE);
-	case MONO_TYPE_PTR:
-		return mono_class_create_ptr (type->data.type);
-	case MONO_TYPE_FNPTR:
-		return mono_class_create_fnptr (type->data.method);
-	case MONO_TYPE_SZARRAY:
-		return mono_class_create_array (type->data.klass, 1);
-	case MONO_TYPE_CLASS:
-	case MONO_TYPE_VALUETYPE:
-		return type->data.klass;
-	case MONO_TYPE_GENERICINST:
-		return mono_class_create_generic_inst (type->data.generic_class);
-	case MONO_TYPE_MVAR:
-	case MONO_TYPE_VAR:
-		return mono_class_create_generic_parameter (type->data.generic_param);
-	default:
-		g_warning ("mono_class_from_mono_type_internal: implement me 0x%02x\n", type->type);
-		g_assert_not_reached ();
-	}
-	return NULL;
-}
-/**
- * mono_type_retrieve_from_typespec
- * \param image context where the image is created
- * \param type_spec  typespec token
- * \param context the generic context used to evaluate generic instantiations in
- */
-static MonoType *
-mono_type_retrieve_from_typespec (MonoImage *image, guint32 type_spec, MonoGenericContext *context, gboolean *did_inflate, MonoError *error)
-{
-	MonoType *t = mono_type_create_from_typespec_checked (image, type_spec, error);
-	*did_inflate = FALSE;
-	if (!t)
-		return NULL;
-	if (context && (context->class_inst || context->method_inst)) {
-		MonoType *inflated = inflate_generic_type (NULL, t, context, error);
-		if (!is_ok (error)) {
-			return NULL;
-		}
-		if (inflated) {
-			t = inflated;
-			*did_inflate = TRUE;
-		}
-	}
-	return t;
-}
-/**
- * mono_class_create_from_typespec
- * \param image context where the image is created
- * \param type_spec typespec token
- * \param context the generic context used to evaluate generic instantiations in
- */
-static MonoClass *
-mono_class_create_from_typespec (MonoImage *image, guint32 type_spec, MonoGenericContext *context, MonoError *error)
-{
-	MonoClass *ret;
-	gboolean inflated = FALSE;
-	MonoType *t = mono_type_retrieve_from_typespec (image, type_spec, context, &inflated, error);
-	return_val_if_nok (error, NULL);
-	ret = mono_class_from_mono_type_internal (t);
-	if (inflated)
-		mono_metadata_free_type (t);
-	return ret;
-}
-/**
- * mono_bounded_array_class_get:
- * \param element_class element class
- * \param rank the dimension of the array class
- * \param bounded whenever the array has non-zero bounds
- * \returns A class object describing the array with element type \p element_type and
- * dimension \p rank.
- */
-MonoClass *
-mono_bounded_array_class_get (MonoClass *eclass, guint32 rank, gboolean bounded)
-{
-	return mono_class_create_bounded_array (eclass, rank, bounded);
-}
-/**
- * mono_array_class_get:
- * \param element_class element class
- * \param rank the dimension of the array class
- * \returns A class object describing the array with element type \p element_type and
- * dimension \p rank.
- */
-MonoClass *
-mono_array_class_get (MonoClass *eclass, guint32 rank)
-{
-	return mono_class_create_array (eclass, rank);
-}
-/**
- * mono_class_instance_size:
- * \param klass a class
- *
- * Use to get the size of a class in bytes.
- *
- * \returns The size of an object instance
- */
-gint32
-mono_class_instance_size (MonoClass *klass)
-{
-	if (!m_class_is_size_inited (klass))
-		mono_class_init_internal (klass);
-	return m_class_get_instance_size (klass);
-}
-/**
- * mono_class_min_align:
- * \param klass a class
- *
- * Use to get the computed minimum alignment requirements for the specified class.
- *
- * Returns: minimum alignment requirements
- */
-gint32
-mono_class_min_align (MonoClass *klass)
-{
-	if (!m_class_is_size_inited (klass))
-		mono_class_init_internal (klass);
-	return m_class_get_min_align (klass);
-}
-/**
- * mono_class_data_size:
- * \param klass a class
- *
- * \returns The size of the static class data
- */
-gint32
-mono_class_data_size (MonoClass *klass)
-{
-	if (!m_class_is_inited (klass))
-		mono_class_init_internal (klass);
-	/* This can happen with dynamically created types */
-	if (!m_class_is_fields_inited (klass))
-		mono_class_setup_fields (klass);
-	/* in arrays, sizes.class_size is unioned with element_size
-	 * and arrays have no static fields
-	 */
-	if (m_class_get_rank (klass))
-		return 0;
-	return m_class_get_sizes (klass).class_size;
-}
-/*
- * Auxiliary routine to mono_class_get_field
- *
- * Takes a field index instead of a field token.
- */
-static MonoClassField *
-mono_class_get_field_idx (MonoClass *klass, int idx)
-{
-	mono_class_setup_fields (klass);
-	if (mono_class_has_failure (klass))
-		return NULL;
-	while (klass) {
-		int first_field_idx = mono_class_get_first_field_idx (klass);
-		int fcount = mono_class_get_field_count (klass);
-		MonoImage *klass_image = m_class_get_image (klass);
-		MonoClassField *klass_fields = m_class_get_fields (klass);
-		if (klass_image->uncompressed_metadata) {
-			/*
-			 * first_field_idx points to the FieldPtr table, while idx points into the
-			 * Field table, so we have to do a search.
-			 */
-			/*FIXME this is broken for types with multiple fields with the same name.*/
-			const char *name = mono_metadata_string_heap (klass_image, mono_metadata_decode_row_col (&klass_image->tables [MONO_TABLE_FIELD], idx, MONO_FIELD_NAME));
-			int i;
-			for (i = 0; i < fcount; ++i)
-				if (mono_field_get_name (&klass_fields [i]) == name)
-					return &klass_fields [i];
-			g_assert_not_reached ();
-		} else {
-			if (fcount) {
-				if ((idx >= first_field_idx) && (idx < first_field_idx + fcount)){
-					return &klass_fields [idx - first_field_idx];
-				}
-			}
-			if (G_UNLIKELY (m_class_get_image (klass)->has_updates && mono_class_has_metadata_update_info (klass))) {
-				uint32_t token = mono_metadata_make_token (MONO_TABLE_FIELD, idx + 1);
-				return mono_metadata_update_get_field (klass, token);
-			}
-		}
-		klass = m_class_get_parent (klass);
-	}
-	return NULL;
-}
-/**
- * mono_class_get_field:
- * \param class the class to lookup the field.
- * \param field_token the field token
- *
- * \returns A \c MonoClassField representing the type and offset of
- * the field, or a NULL value if the field does not belong to this
- * class.
- */
-MonoClassField *
-mono_class_get_field (MonoClass *klass, guint32 field_token)
-{
-	int idx = mono_metadata_token_index (field_token);
-	g_assert (mono_metadata_token_code (field_token) == MONO_TOKEN_FIELD_DEF);
-	return mono_class_get_field_idx (klass, idx - 1);
-}
-/**
- * mono_class_get_field_from_name:
- * \param klass the class to lookup the field.
- * \param name the field name
- *
- * Search the class \p klass and its parents for a field with the name \p name.
- *
- * \returns The \c MonoClassField pointer of the named field or NULL
- */
-MonoClassField *
-mono_class_get_field_from_name (MonoClass *klass, const char *name)
-{
-	MonoClassField *result;
-	MONO_ENTER_GC_UNSAFE;
-	result = mono_class_get_field_from_name_full (klass, name, NULL);
-	MONO_EXIT_GC_UNSAFE;
-	return result;
-}
-/**
- * mono_class_get_field_from_name_full:
- * \param klass the class to lookup the field.
- * \param name the field name
- * \param type the type of the fields. This optional.
- *
- * Search the class \p klass and it's parents for a field with the name \p name and type \p type.
- *
- * If \p klass is an inflated generic type, the type comparison is done with the equivalent field
- * of its generic type definition.
- *
- * \returns The MonoClassField pointer of the named field or NULL
- */
-MonoClassField *
-mono_class_get_field_from_name_full (MonoClass *klass, const char *name, MonoType *type)
-{
-	MONO_REQ_GC_UNSAFE_MODE;
-	mono_class_setup_fields (klass);
-	if (mono_class_has_failure (klass))
-		return NULL;
-	while (klass) {
-		gpointer iter = NULL;
-		MonoClassField *field;
-		while ((field = mono_class_get_fields_internal (klass, &iter))) {
-			if (strcmp (name, mono_field_get_name (field)) != 0)
-				continue;
-			if (type) {
-				MonoClassField *gfield = mono_metadata_get_corresponding_field_from_generic_type_definition (field);
-				g_assert (gfield != NULL);
-				MonoType *field_type = gfield->type;
-				if (!mono_metadata_type_equal_full (type, field_type, MONO_TYPE_EQ_FLAGS_SIG_ONLY))
-					continue;
-			}
-			return field;
-		}
-		klass = m_class_get_parent (klass);
-	}
-	return NULL;
-}
-/**
- * mono_class_get_field_token:
- * \param field the field we need the token of
- *
- * Get the token of a field. Note that the tokesn is only valid for the image
- * the field was loaded from. Don't use this function for fields in dynamic types.
- *
- * \returns The token representing the field in the image it was loaded from.
- */
-guint32
-mono_class_get_field_token (MonoClassField *field)
-{
-	MonoClass *klass = m_field_get_parent (field);
-	int i;
-	mono_class_setup_fields (klass);
-	if (G_UNLIKELY (m_class_get_image (klass)->has_updates)) {
-		if (G_UNLIKELY (m_field_is_from_update (field))) {
-			uint32_t idx = mono_metadata_update_get_field_idx (field);
-			return mono_metadata_make_token (MONO_TABLE_FIELD, idx);
-		}
-	}
-	while (klass) {
-		MonoClassField *klass_fields = m_class_get_fields (klass);
-		if (!klass_fields)
-			return 0;
-		int first_field_idx = mono_class_get_first_field_idx (klass);
-		int fcount = mono_class_get_field_count (klass);
-		for (i = 0; i < fcount; ++i) {
-			if (&klass_fields [i] == field) {
-				int idx = first_field_idx + i + 1;
-				if (m_class_get_image (klass)->uncompressed_metadata)
-					idx = mono_metadata_translate_token_index (m_class_get_image (klass), MONO_TABLE_FIELD, idx);
-				return mono_metadata_make_token (MONO_TABLE_FIELD, idx);
-			}
-		}
-		klass = m_class_get_parent (klass);
-	}
-	g_assert_not_reached ();
-	return 0;
-}
-static int
-mono_field_get_index (MonoClassField *field)
-{
-	/* metadata-update: the callers of this method need changes to support updates */
-	g_assert (!m_field_is_from_update (field));
-	int index = GPTRDIFF_TO_INT (field - m_class_get_fields (m_field_get_parent (field)));
-	g_assert (index >= 0 && GINT_TO_UINT32(index) < mono_class_get_field_count (m_field_get_parent (field)));
-	return index;
-}
-/*
- * mono_class_get_field_default_value:
- *
- * Return the default value of the field as a pointer into the metadata blob.
- */
-const char*
-mono_class_get_field_default_value (MonoClassField *field, MonoTypeEnum *def_type)
-{
-	guint32 cindex;
-	guint32 constant_cols [MONO_CONSTANT_SIZE];
-	int field_index;
-	MonoClass *klass = m_field_get_parent (field);
-	MonoFieldDefaultValue *def_values;
-	g_assert (field->type->attrs & FIELD_ATTRIBUTE_HAS_DEFAULT);
-	def_values = mono_class_get_field_def_values (klass);
-	if (!def_values) {
-		def_values = (MonoFieldDefaultValue *)mono_class_alloc0 (klass, sizeof (MonoFieldDefaultValue) * mono_class_get_field_count (klass));
-		mono_class_set_field_def_values (klass, def_values);
-	}
-	/* TODO: metadata-update - added literal fields */
-	g_assert (!m_field_is_from_update (field));
-	field_index = mono_field_get_index (field);
-	if (!def_values [field_index].data) {
-		MonoImage *field_parent_image = m_class_get_image (m_field_get_parent (field));
-		cindex = mono_metadata_get_constant_index (field_parent_image, mono_class_get_field_token (field), 0);
-		if (!cindex)
-			return NULL;
-		g_assert (!(field->type->attrs & FIELD_ATTRIBUTE_HAS_FIELD_RVA));
-		mono_metadata_decode_row (&field_parent_image->tables [MONO_TABLE_CONSTANT], cindex - 1, constant_cols, MONO_CONSTANT_SIZE);
-		def_values [field_index].def_type = (MonoTypeEnum)constant_cols [MONO_CONSTANT_TYPE];
-		mono_memory_barrier ();
-		def_values [field_index].data = (const char *)mono_metadata_blob_heap (field_parent_image, constant_cols [MONO_CONSTANT_VALUE]);
-	}
-	*def_type = def_values [field_index].def_type;
-	return def_values [field_index].data;
-}
-static int
-mono_property_get_index (MonoProperty *prop)
-{
-	g_assert (!m_property_is_from_update (prop));
-	MonoClassPropertyInfo *info = mono_class_get_property_info (prop->parent);
-	int index = GPTRDIFF_TO_INT (prop - info->properties);
-	g_assert (index >= 0 && GINT_TO_UINT32(index) < info->count);
-	return index;
-}
-/*
- * mono_class_get_property_default_value:
- *
- * Return the default value of the field as a pointer into the metadata blob.
- */
-const char*
-mono_class_get_property_default_value (MonoProperty *property, MonoTypeEnum *def_type)
-{
-	guint32 cindex;
-	guint32 constant_cols [MONO_CONSTANT_SIZE];
-	MonoClass *klass = property->parent;
-	MonoImage *klass_image = m_class_get_image (klass);
-	g_assert (property->attrs & PROPERTY_ATTRIBUTE_HAS_DEFAULT);
-	/*
-	 * We don't cache here because it is not used by C# so it's quite rare, but
-	 * we still do the lookup in klass->ext because that is where the data
-	 * is stored for dynamic assemblies.
-	 */
-	if (image_is_dynamic (klass_image)) {
-		MonoClassPropertyInfo *info = mono_class_get_property_info (klass);
-		int prop_index = mono_property_get_index (property);
-		if (info->def_values && info->def_values [prop_index].data) {
-			*def_type = info->def_values [prop_index].def_type;
-			return info->def_values [prop_index].data;
-		}
-		return NULL;
-	}
-	/* metadata-update: Roslyn doesn't emit HasDefault on added properties. */
-	g_assert (!m_property_is_from_update (property));
-	cindex = mono_metadata_get_constant_index (klass_image, mono_class_get_property_token (property), 0);
-	if (!cindex)
-		return NULL;
-	mono_metadata_decode_row (&klass_image->tables [MONO_TABLE_CONSTANT], cindex - 1, constant_cols, MONO_CONSTANT_SIZE);
-	*def_type = (MonoTypeEnum)constant_cols [MONO_CONSTANT_TYPE];
-	return (const char *)mono_metadata_blob_heap (klass_image, constant_cols [MONO_CONSTANT_VALUE]);
-}
-/**
- * mono_class_get_event_token:
- */
-guint32
-mono_class_get_event_token (MonoEvent *event)
-{
-	MonoClass *klass = event->parent;
-	if (G_UNLIKELY (m_class_get_image (klass)->has_updates)) {
-		if (G_UNLIKELY (m_event_is_from_update (event))) {
-			uint32_t idx = mono_metadata_update_get_event_idx (event);
-			return mono_metadata_make_token (MONO_TABLE_EVENT, idx);
-		}
-	}
-	while (klass) {
-		MonoClassEventInfo *info = mono_class_get_event_info (klass);
-		if (info) {
-			for (guint32 i = 0; i < info->count; ++i) {
-				g_assert (!m_event_is_from_update (&info->events[i]));
-				if (&info->events [i] == event)
-					return mono_metadata_make_token (MONO_TABLE_EVENT, info->first + i + 1);
-			}
-		}
-		klass = m_class_get_parent (klass);
-	}
-	g_assert_not_reached ();
-	return 0;
-}
-MonoProperty*
-mono_class_get_property_from_name_internal (MonoClass *klass, const char *name)
-{
-	MONO_REQ_GC_UNSAFE_MODE;
-	while (klass) {
-		MonoProperty* p;
-		gpointer iter = NULL;
-		while ((p = mono_class_get_properties (klass, &iter))) {
-			if (! strcmp (name, p->name))
-				return p;
-		}
-		klass = m_class_get_parent (klass);
-	}
-	return NULL;
-}
-/**
- * mono_class_get_property_token:
- * \param prop MonoProperty to query
- *
- * \returns The ECMA token for the specified property.
- */
-guint32
-mono_class_get_property_token (MonoProperty *prop)
-{
-	MonoClass *klass = prop->parent;
-	if (G_UNLIKELY (m_class_get_image (klass)->has_updates)) {
-		if (G_UNLIKELY (m_property_is_from_update (prop))) {
-			uint32_t idx = mono_metadata_update_get_property_idx (prop);
-			return mono_metadata_make_token (MONO_TABLE_PROPERTY, idx);
-		}
-	}
-	while (klass) {
-		MonoProperty* p;
-		int i = 0;
-		gpointer iter = NULL;
-		MonoClassPropertyInfo *info = mono_class_get_property_info (klass);
-		while ((p = mono_class_get_properties (klass, &iter))) {
-			/* TODO: metadata-update: get tokens for added props, too */
-			g_assert (!m_property_is_from_update (p));
-			if (&info->properties [i] == prop)
-				return mono_metadata_make_token (MONO_TABLE_PROPERTY, info->first + i + 1);
-			i ++;
-		}
-		klass = m_class_get_parent (klass);
-	}
-	g_assert_not_reached ();
-	return 0;
-}
-/**
- * mono_class_name_from_token:
- */
-char *
-mono_class_name_from_token (MonoImage *image, guint32 type_token)
-{
-	const char *name, *nspace;
-	if (image_is_dynamic (image))
-		return g_strdup_printf ("DynamicType 0x%08x", type_token);
-	switch (type_token & 0xff000000){
-	case MONO_TOKEN_TYPE_DEF: {
-		guint tidx = mono_metadata_token_index (type_token);
-		if (mono_metadata_table_bounds_check (image, MONO_TABLE_TYPEDEF, tidx))
-			return g_strdup_printf ("Invalid type token 0x%08x", type_token);
-		guint32 cols [MONO_TYPEDEF_SIZE];
-		MonoTableInfo *tt = &image->tables [MONO_TABLE_TYPEDEF];
-		mono_metadata_decode_row (tt, tidx - 1, cols, MONO_TYPEDEF_SIZE);
-		name = mono_metadata_string_heap (image, cols [MONO_TYPEDEF_NAME]);
-		nspace = mono_metadata_string_heap (image, cols [MONO_TYPEDEF_NAMESPACE]);
-		if (strlen (nspace) == 0)
-			return g_strdup_printf ("%s", name);
-		else
-			return g_strdup_printf ("%s.%s", nspace, name);
-	}
-	case MONO_TOKEN_TYPE_REF: {
-		guint tidx = mono_metadata_token_index (type_token);
-		if (mono_metadata_table_bounds_check (image, MONO_TABLE_TYPEREF, tidx))
-			return g_strdup_printf ("Invalid type token 0x%08x", type_token);
-		guint32 cols [MONO_TYPEREF_SIZE];
-		MonoTableInfo  *t = &image->tables [MONO_TABLE_TYPEREF];
-		mono_metadata_decode_row (t, tidx-1, cols, MONO_TYPEREF_SIZE);
-		name = mono_metadata_string_heap (image, cols [MONO_TYPEREF_NAME]);
-		nspace = mono_metadata_string_heap (image, cols [MONO_TYPEREF_NAMESPACE]);
-		if (strlen (nspace) == 0)
-			return g_strdup_printf ("%s", name);
-		else
-			return g_strdup_printf ("%s.%s", nspace, name);
-	}
-	case MONO_TOKEN_TYPE_SPEC:
-		return g_strdup_printf ("Typespec 0x%08x", type_token);
-	default:
-		return g_strdup_printf ("Invalid type token 0x%08x", type_token);
-	}
-}
-static char *
-mono_assembly_name_from_token (MonoImage *image, guint32 type_token)
-{
-	if (image_is_dynamic (image))
-		return g_strdup_printf ("DynamicAssembly %s", image->name);
-	switch (type_token & 0xff000000){
-	case MONO_TOKEN_TYPE_DEF:
-		if (image->assembly)
-			return mono_stringify_assembly_name (&image->assembly->aname);
-		else if (image->assembly_name)
-			return g_strdup (image->assembly_name);
-		return g_strdup_printf ("%s", image->name ? image->name : "[Could not resolve assembly name");
-	case MONO_TOKEN_TYPE_REF: {
-		MonoAssemblyName aname;
-		memset (&aname, 0, sizeof (MonoAssemblyName));
-		guint32 cols [MONO_TYPEREF_SIZE];
-		MonoTableInfo  *t = &image->tables [MONO_TABLE_TYPEREF];
-		guint32 idx = mono_metadata_token_index (type_token);
-		if (mono_metadata_table_bounds_check (image, MONO_TABLE_TYPEREF, idx))
-			return g_strdup_printf ("Invalid type token 0x%08x", type_token);
-		mono_metadata_decode_row (t, idx-1, cols, MONO_TYPEREF_SIZE);
-		idx = cols [MONO_TYPEREF_SCOPE] >> MONO_RESOLUTION_SCOPE_BITS;
-		switch (cols [MONO_TYPEREF_SCOPE] & MONO_RESOLUTION_SCOPE_MASK) {
-		case MONO_RESOLUTION_SCOPE_MODULE:
-			/* FIXME: */
-			return g_strdup ("");
-		case MONO_RESOLUTION_SCOPE_MODULEREF:
-			/* FIXME: */
-			return g_strdup ("");
-		case MONO_RESOLUTION_SCOPE_TYPEREF:
-			/* FIXME: */
-			return g_strdup ("");
-		case MONO_RESOLUTION_SCOPE_ASSEMBLYREF:
-			mono_assembly_get_assemblyref (image, idx - 1, &aname);
-			return mono_stringify_assembly_name (&aname);
-		default:
-			g_assert_not_reached ();
-		}
-		break;
-	}
-	case MONO_TOKEN_TYPE_SPEC:
-		/* FIXME: */
-		return g_strdup ("");
-	default:
-		g_assert_not_reached ();
-	}
-	return NULL;
-}
-/**
- * mono_class_get_full:
- * \param image the image where the class resides
- * \param type_token the token for the class
- * \param context the generic context used to evaluate generic instantiations in
- * \deprecated Functions that expose \c MonoGenericContext are going away in mono 4.0
- * \returns The \c MonoClass that represents \p type_token in \p image
- */
-MonoClass *
-mono_class_get_full (MonoImage *image, guint32 type_token, MonoGenericContext *context)
-{
-	ERROR_DECL (error);
-	MonoClass *klass;
-	klass = mono_class_get_checked (image, type_token, error);
-	if (klass && context && mono_metadata_token_table (type_token) == MONO_TABLE_TYPESPEC)
-		klass = mono_class_inflate_generic_class_checked (klass, context, error);
-	mono_error_assert_ok (error);
-	return klass;
-}
-MonoClass *
-mono_class_get_and_inflate_typespec_checked (MonoImage *image, guint32 type_token, MonoGenericContext *context, MonoError *error)
-{
-	MonoClass *klass;
-	error_init (error);
-	klass = mono_class_get_checked (image, type_token, error);
-	if (klass && context && mono_metadata_token_table (type_token) == MONO_TABLE_TYPESPEC)
-		klass = mono_class_inflate_generic_class_checked (klass, context, error);
-	return klass;
-}
-/**
- * mono_class_get_checked:
- * \param image the image where the class resides
- * \param type_token the token for the class
- * \param error error object to return any error
- *
- * \returns The MonoClass that represents \p type_token in \p image, or NULL on error.
- */
-MonoClass *
-mono_class_get_checked (MonoImage *image, guint32 type_token, MonoError *error)
-{
-	MonoClass *klass = NULL;
-	error_init (error);
-	if (image_is_dynamic (image)) {
-		int table = mono_metadata_token_table (type_token);
-		if (table != MONO_TABLE_TYPEDEF && table != MONO_TABLE_TYPEREF && table != MONO_TABLE_TYPESPEC) {
-			mono_error_set_bad_image (error, image,"Bad token table for dynamic image: %x", table);
-			return NULL;
-		}
-		klass = (MonoClass *)mono_lookup_dynamic_token (image, type_token, NULL, error);
-		goto done;
-	}
-	switch (type_token & 0xff000000){
-	case MONO_TOKEN_TYPE_DEF:
-		klass = mono_class_create_from_typedef (image, type_token, error);
-		break;
-	case MONO_TOKEN_TYPE_REF:
-		klass = mono_class_from_typeref_checked (image, type_token, error);
-		break;
-	case MONO_TOKEN_TYPE_SPEC:
-		klass = mono_class_create_from_typespec (image, type_token, NULL, error);
-		break;
-	default:
-		mono_error_set_bad_image (error, image, "Unknown type token %x", type_token & 0xff000000);
-	}
-done:
-	/* Generic case, should be avoided for when a better error is possible. */
-	if (!klass && is_ok (error)) {
-		char *name = mono_class_name_from_token (image, type_token);
-		char *assembly = mono_assembly_name_from_token (image, type_token);
-		mono_error_set_type_load_name (error, name, assembly, "Could not resolve type with token %08x (expected class '%s' in assembly '%s')", type_token, name, assembly);
-	}
-	return klass;
-}
-/**
- * mono_type_get_checked:
- * \param image the image where the type resides
- * \param type_token the token for the type
- * \param context the generic context used to evaluate generic instantiations in
- * \param error Error handling context
- *
- * This functions exists to fulfill the fact that sometimes it's desirable to have access to the
- *
- * \returns The MonoType that represents \p type_token in \p image
- */
-MonoType *
-mono_type_get_checked (MonoImage *image, guint32 type_token, MonoGenericContext *context, MonoError *error)
-{
-	MonoType *type = NULL;
-	gboolean inflated = FALSE;
-	error_init (error);
-	if (image_is_dynamic (image)) {
-		MonoClass *klass = (MonoClass *)mono_lookup_dynamic_token (image, type_token, context, error);
-		return_val_if_nok (error, NULL);
-		return m_class_get_byval_arg (klass);
-	}
-	if ((type_token & 0xff000000) != MONO_TOKEN_TYPE_SPEC) {
-		MonoClass *klass = mono_class_get_checked (image, type_token, error);
-		if (!klass)
-			return NULL;
-		if (m_class_has_failure (klass)) {
-			mono_error_set_for_class_failure (error, klass);
-			return NULL;
-		}
-		return m_class_get_byval_arg (klass);
-	}
-	type = mono_type_retrieve_from_typespec (image, type_token, context, &inflated, error);
-	if (!type) {
-		return NULL;
-	}
-	if (inflated) {
-		MonoType *tmp = type;
-		type = m_class_get_byval_arg (mono_class_from_mono_type_internal (type));
-		/* FIXME: This is a workaround fo the fact that a typespec token sometimes reference to the generic type definition.
-		 * A MonoClass::_byval_arg of a generic type definion has type CLASS.
-		 * Some parts of mono create a GENERICINST to reference a generic type definition and this generates confict with _byval_arg.
-		 *
-		 * The long term solution is to chaise this places and make then set MonoType::type correctly.
-		 * */
-		if (type->type != tmp->type)
-			type = tmp;
-		else
-			mono_metadata_free_type (tmp);
-	}
-	return type;
-}
-/**
- * mono_class_get:
- * \param image image where the class token will be looked up.
- * \param type_token a type token from the image
- * \returns the \c MonoClass with the given \p type_token on the \p image
- */
-MonoClass *
-mono_class_get (MonoImage *image, guint32 type_token)
-{
-	MonoClass *result;
-	MONO_ENTER_GC_UNSAFE;
-	ERROR_DECL (error);
-	result = mono_class_get_checked (image, type_token, error);
-	mono_error_assert_ok (error);
-	MONO_EXIT_GC_UNSAFE;
-	return result;
-}
-/**
- * mono_image_init_name_cache:
- *
- *  Initializes the class name cache stored in image->name_cache.
- *
- * LOCKING: Acquires the corresponding image lock.
- */
-void
-mono_image_init_name_cache (MonoImage *image)
-{
-	MonoTableInfo  *t = &image->tables [MONO_TABLE_TYPEDEF];
-	guint32 cols [MONO_TYPEDEF_SIZE];
-	const char *name;
-	const char *nspace;
-	guint32 visib, nspace_index;
-	dn_simdhash_u32_ptr_t *name_cache2;
-	dn_simdhash_string_ptr_t *nspace_table, *the_name_cache;
-	if (image->name_cache)
-		return;
-	the_name_cache = dn_simdhash_string_ptr_new (0, NULL);
-	if (image_is_dynamic (image)) {
-		mono_image_lock (image);
-		if (image->name_cache) {
-			/* Somebody initialized it before us */
-			dn_simdhash_free (the_name_cache);
-		} else {
-			mono_atomic_store_release (&image->name_cache, the_name_cache);
-		}
-		mono_image_unlock (image);
-		return;
-	}
-	/* Temporary hash table to avoid lookups in the nspace_table */
-	name_cache2 = dn_simdhash_u32_ptr_new (0, NULL);
-	/* FIXME: metadata-update */
-	int rows = table_info_get_rows (t);
-	for (int i = 1; i <= rows; ++i) {
-		mono_metadata_decode_row (t, i - 1, cols, MONO_TYPEDEF_SIZE);
-		visib = cols [MONO_TYPEDEF_FLAGS] & TYPE_ATTRIBUTE_VISIBILITY_MASK;
-		/*
-		 * Nested types are accessed from the nesting name.  We use the fact that nested types use different visibility flags
-		 * than toplevel types, thus avoiding the need to grovel through the NESTED_TYPE table
-		 */
-		if (visib >= TYPE_ATTRIBUTE_NESTED_PUBLIC && visib <= TYPE_ATTRIBUTE_NESTED_FAM_OR_ASSEM)
-			continue;
-		name = mono_metadata_string_heap (image, cols [MONO_TYPEDEF_NAME]);
-		nspace = mono_metadata_string_heap (image, cols [MONO_TYPEDEF_NAMESPACE]);
-		nspace_index = cols [MONO_TYPEDEF_NAMESPACE];
-		if (!dn_simdhash_u32_ptr_try_get_value (name_cache2, nspace_index, (void **)&nspace_table)) {
-			nspace_table = dn_simdhash_string_ptr_new (0, NULL);
-			dn_simdhash_string_ptr_try_add (the_name_cache, nspace, nspace_table);
-			dn_simdhash_u32_ptr_try_add (name_cache2, nspace_index, nspace_table);
-		}
-		dn_simdhash_string_ptr_try_add (nspace_table, name, GUINT_TO_POINTER (i));
-	}
-	/* Load type names from EXPORTEDTYPES table */
-	{
-		MonoTableInfo *exptype_tbl = &image->tables [MONO_TABLE_EXPORTEDTYPE];
-		guint32 exptype_cols [MONO_EXP_TYPE_SIZE];
-		rows = table_info_get_rows (exptype_tbl);
-		for (int i = 0; i < rows; ++i) {
-			mono_metadata_decode_row (exptype_tbl, i, exptype_cols, MONO_EXP_TYPE_SIZE);
-			guint32 impl = exptype_cols [MONO_EXP_TYPE_IMPLEMENTATION];
-			if ((impl & MONO_IMPLEMENTATION_MASK) == MONO_IMPLEMENTATION_EXP_TYPE)
-				/* Nested type */
-				continue;
-			name = mono_metadata_string_heap (image, exptype_cols [MONO_EXP_TYPE_NAME]);
-			nspace = mono_metadata_string_heap (image, exptype_cols [MONO_EXP_TYPE_NAMESPACE]);
-			nspace_index = exptype_cols [MONO_EXP_TYPE_NAMESPACE];
-			if (!dn_simdhash_u32_ptr_try_get_value (name_cache2, nspace_index, (void **)&nspace_table)) {
-				nspace_table = dn_simdhash_string_ptr_new (0, NULL);
-				dn_simdhash_string_ptr_try_add (the_name_cache, nspace, nspace_table);
-				dn_simdhash_u32_ptr_try_add (name_cache2, nspace_index, nspace_table);
-			}
-			dn_simdhash_string_ptr_try_add (nspace_table, name, GUINT_TO_POINTER (mono_metadata_make_token (MONO_TABLE_EXPORTEDTYPE, i + 1)));
-		}
-	}
-	dn_simdhash_free (name_cache2);
-	mono_image_lock (image);
-	if (image->name_cache) {
-		/* Somebody initialized it before us */
-		dn_simdhash_free (the_name_cache);
-	} else {
-		mono_atomic_store_release (&image->name_cache, the_name_cache);
-	}
-	mono_image_unlock (image);
-}
-/*FIXME Only dynamic assemblies or metadata-update should allow this operation.*/
-/**
- * mono_image_add_to_name_cache:
- */
-void
-mono_image_add_to_name_cache (MonoImage *image, const char *nspace,
-							  const char *name, guint32 index)
-{
-	dn_simdhash_string_ptr_t *nspace_table, *name_cache;
-	mono_image_init_name_cache (image);
-	mono_image_lock (image);
-	name_cache = image->name_cache;
-	if (!dn_simdhash_string_ptr_try_get_value (name_cache, nspace, (void **)&nspace_table)) {
-		nspace_table = dn_simdhash_string_ptr_new (0, NULL);
-		dn_simdhash_string_ptr_try_add (name_cache, nspace, nspace_table);
-	}
-	if (!dn_simdhash_string_ptr_try_add (nspace_table, name, GUINT_TO_POINTER (index)))
-		g_error ("overrwritting old token ? on image %s for type %s::%s", image->name, nspace, name);
-	mono_image_unlock (image);
-}
-typedef struct {
-	gconstpointer key;
-	GSList *values;
-} FindAllUserData;
-static void
-find_all_nocase (const char *name, gpointer value, gpointer user_data)
-{
-	FindAllUserData *data = (FindAllUserData*)user_data;
-	if (mono_utf8_strcasecmp (name, (char*)data->key) == 0)
-		data->values = g_slist_prepend (data->values, value);
-}
-typedef struct {
-	gconstpointer key;
-	gpointer value;
-} FindUserData;
-static void
-find_nocase (const char *name, gpointer value, gpointer user_data)
-{
-	FindUserData *data = (FindUserData*)user_data;
-	if (!data->value && (mono_utf8_strcasecmp (name, (char*)data->key) == 0))
-		data->value = value;
-}
-/**
- * mono_class_from_name_case:
- * \param image The MonoImage where the type is looked up in
- * \param name_space the type namespace
- * \param name the type short name.
- * \deprecated use the mono_class_from_name_case_checked variant instead.
- *
- * Obtains a \c MonoClass with a given namespace and a given name which
- * is located in the given \c MonoImage.   The namespace and name
- * lookups are case insensitive.
- */
-MonoClass *
-mono_class_from_name_case (MonoImage *image, const char* name_space, const char *name)
-{
-	ERROR_DECL (error);
-	MonoClass *res = mono_class_from_name_case_checked (image, name_space, name, error);
-	mono_error_cleanup (error);
-	return res;
-}
-/**
- * mono_class_from_name_case_checked:
- * \param image The MonoImage where the type is looked up in
- * \param name_space the type namespace
- * \param name the type short name.
- * \param error if
- *
- * Obtains a MonoClass with a given namespace and a given name which
- * is located in the given MonoImage.   The namespace and name
- * lookups are case insensitive.
- *
- * \returns The MonoClass if the given namespace and name were found, or NULL if it
- * was not found.   The \p error object will contain information about the problem
- * in that case.
- */
-MonoClass *
-mono_class_from_name_case_checked (MonoImage *image, const char *name_space, const char *name, MonoError *error)
-{
-	MonoClass *klass;
-	GHashTable *visited_images;
-	visited_images = g_hash_table_new (g_direct_hash, g_direct_equal);
-	klass = mono_class_from_name_checked_aux (image, name_space, name, visited_images, FALSE, error);
-	g_hash_table_destroy (visited_images);
-	return klass;
-}
-static MonoClass*
-return_nested_in (MonoClass *klass, char *nested, gboolean case_sensitive)
-{
-	MonoClass *found;
-	char *s = strchr (nested, '/');
-	gpointer iter = NULL;
-	if (s) {
-		*s = 0;
-		s++;
-	}
-	while ((found = mono_class_get_nested_types (klass, &iter))) {
-		const char *name = m_class_get_name (found);
-		gint strcmp_result;
-		if (case_sensitive)
-			strcmp_result = strcmp (name, nested);
-		else
-			strcmp_result = mono_utf8_strcasecmp (name, nested);
-		if (strcmp_result == 0) {
-			if (s)
-				return return_nested_in (found, s, case_sensitive);
-			return found;
-		}
-	}
-	return NULL;
-}
-static MonoClass*
-search_modules (MonoImage *image, const char *name_space, const char *name, gboolean case_sensitive, MonoError *error)
-{
-	MonoTableInfo *file_table = &image->tables [MONO_TABLE_FILE];
-	MonoImage *file_image;
-	MonoClass *klass;
-	error_init (error);
-	/*
-	 * The EXPORTEDTYPES table only contains public types, so have to search the
-	 * modules as well.
-	 * Note: image->modules contains the contents of the MODULEREF table, while
-	 * the real module list is in the FILE table.
-	 */
-	guint32 rows = table_info_get_rows (file_table);
-	for (guint32 i = 0; i < rows; i++) {
-		guint32 cols [MONO_FILE_SIZE];
-		mono_metadata_decode_row (file_table, i, cols, MONO_FILE_SIZE);
-		if (cols [MONO_FILE_FLAGS] == FILE_CONTAINS_NO_METADATA)
-			continue;
-		file_image = mono_image_load_file_for_image_checked (image, i + 1, error);
-		if (file_image) {
-			if (case_sensitive)
-				klass = mono_class_from_name_checked (file_image, name_space, name, error);
-			else
-				klass = mono_class_from_name_case_checked (file_image, name_space, name, error);
-			if (klass || !is_ok (error))
-				return klass;
-		}
-	}
-	return NULL;
-}
-static MonoClass *
-mono_class_from_name_checked_aux (MonoImage *image, const char* name_space, const char *name, GHashTable* visited_images, gboolean case_sensitive, MonoError *error)
-{
-	dn_simdhash_string_ptr_t *nspace_table = NULL;
-	MonoImage *loaded_image = NULL;
-	guint32 token = 0;
-	MonoClass *klass;
-	char *nested;
-	char buf [1024];
-	error_init (error);
-	if (g_hash_table_lookup (visited_images, image))
-		return NULL;
-	g_hash_table_insert (visited_images, image, GUINT_TO_POINTER(1));
-	if ((nested = (char*)strchr (name, '/'))) {
-		int pos = GPTRDIFF_TO_INT (nested - name);
-		size_t len = strlen (name);
-		if (len > 1023)
-			return NULL;
-		memcpy (buf, name, len + 1);
-		buf [pos] = 0;
-		nested = buf + pos + 1;
-		name = buf;
-	}
-	/* FIXME: get_class_from_name () can't handle types in the EXPORTEDTYPE table */
-	if (table_info_get_rows (&image->tables [MONO_TABLE_EXPORTEDTYPE]) == 0 && case_sensitive) {
-		gboolean res = mono_get_runtime_callbacks ()->get_class_from_name (image, name_space, name, &klass);
-		if (res) {
-			if (!klass) {
-				klass = search_modules (image, name_space, name, case_sensitive, error);
-				if (!is_ok (error))
-					return NULL;
-			}
-			if (nested)
-				return klass ? return_nested_in (klass, nested, case_sensitive) : NULL;
-			else
-				return klass;
-		}
-	}
-	mono_image_init_name_cache (image);
-	mono_image_lock (image);
-	if (case_sensitive) {
-		if (dn_simdhash_string_ptr_try_get_value (image->name_cache, name_space, (void **)&nspace_table)) {
-			void * temp;
-			if (dn_simdhash_string_ptr_try_get_value (nspace_table, name, &temp))
-				token = GPOINTER_TO_UINT(temp);
-		}
-	} else {
-		FindAllUserData all_user_data = { name_space, NULL };
-		FindUserData user_data = { name, NULL };
-		GSList *values;
-		dn_simdhash_string_ptr_foreach (image->name_cache, find_all_nocase, &all_user_data);
-		values = all_user_data.values;
-		while (values && !user_data.value) {
-			nspace_table = (dn_simdhash_string_ptr_t *)values->data;
-			dn_simdhash_string_ptr_foreach (nspace_table, find_nocase, &user_data);
-			values = values->next;
-		}
-		g_slist_free (all_user_data.values);
-		if (user_data.value)
-			token = GPOINTER_TO_UINT (user_data.value);
-	}
-	mono_image_unlock (image);
-	if (!token && image_is_dynamic (image) && image->modules) {
-		/* Search modules as well */
-		for (guint32 i = 0; i < image->module_count; ++i) {
-			MonoImage *module = image->modules [i];
-			if (case_sensitive)
-				klass = mono_class_from_name_checked (module, name_space, name, error);
-			else
-				klass = mono_class_from_name_case_checked (module, name_space, name, error);
-			if (klass || !is_ok (error))
-				return klass;
-		}
-	}
-	if (!token) {
-		klass = search_modules (image, name_space, name, case_sensitive, error);
-		if (klass || !is_ok (error))
-			return klass;
-		return NULL;
-	}
-	if (mono_metadata_token_table (token) == MONO_TABLE_EXPORTEDTYPE) {
-		MonoTableInfo  *t = &image->tables [MONO_TABLE_EXPORTEDTYPE];
-		guint32 cols [MONO_EXP_TYPE_SIZE];
-		guint32 idx, impl;
-		idx = mono_metadata_token_index (token);
-		mono_metadata_decode_row (t, idx - 1, cols, MONO_EXP_TYPE_SIZE);
-		impl = cols [MONO_EXP_TYPE_IMPLEMENTATION];
-		if ((impl & MONO_IMPLEMENTATION_MASK) == MONO_IMPLEMENTATION_FILE) {
-			loaded_image = mono_assembly_load_module_checked (image->assembly, impl >> MONO_IMPLEMENTATION_BITS, error);
-			if (!loaded_image)
-				return NULL;
-			klass = mono_class_from_name_checked_aux (loaded_image, name_space, name, visited_images, case_sensitive, error);
-			if (nested)
-				return klass ? return_nested_in (klass, nested, case_sensitive) : NULL;
-			return klass;
-		} else if ((impl & MONO_IMPLEMENTATION_MASK) == MONO_IMPLEMENTATION_ASSEMBLYREF) {
-			guint32 assembly_idx;
-			assembly_idx = impl >> MONO_IMPLEMENTATION_BITS;
-			mono_assembly_load_reference (image, assembly_idx - 1);
-			g_assert (image->references [assembly_idx - 1]);
-			if (image->references [assembly_idx - 1] == (gpointer)-1)
-				return NULL;
-			klass = mono_class_from_name_checked_aux (image->references [assembly_idx - 1]->image, name_space, name, visited_images, case_sensitive, error);
-			if (nested)
-				return klass ? return_nested_in (klass, nested, case_sensitive) : NULL;
-			return klass;
-		} else {
-			g_assert_not_reached ();
-		}
-	}
-	token = MONO_TOKEN_TYPE_DEF | token;
-	klass = mono_class_get_checked (image, token, error);
-	if (nested)
-		return return_nested_in (klass, nested, case_sensitive);
-	return klass;
-}
-/**
- * mono_class_from_name_checked:
- * \param image The MonoImage where the type is looked up in
- * \param name_space the type namespace
- * \param name the type short name.
- *
- * Obtains a MonoClass with a given namespace and a given name which
- * is located in the given MonoImage.
- *
- * Works like mono_class_from_name, but error handling is tricky. It can return NULL and have no error
- * set if the class was not found or it will return NULL and set the error if there was a loading error.
- */
-MonoClass *
-mono_class_from_name_checked (MonoImage *image, const char* name_space, const char *name, MonoError *error)
-{
-	MonoClass *klass;
-	GHashTable *visited_images;
-	visited_images = g_hash_table_new (g_direct_hash, g_direct_equal);
-	klass = mono_class_from_name_checked_aux (image, name_space, name, visited_images, TRUE, error);
-	g_hash_table_destroy (visited_images);
-	return klass;
-}
-/**
- * mono_class_from_name:
- * \param image The \c MonoImage where the type is looked up in
- * \param name_space the type namespace
- * \param name the type short name.
- *
- * Obtains a \c MonoClass with a given namespace and a given name which
- * is located in the given \c MonoImage.
- *
- * To reference nested classes, use the "/" character as a separator.
- * For example use \c "Foo/Bar" to reference the class \c Bar that is nested
- * inside \c Foo, like this: "class Foo { class Bar {} }".
- */
-MonoClass *
-mono_class_from_name (MonoImage *image, const char* name_space, const char *name)
-{
-	MonoClass *klass;
-	MONO_ENTER_GC_UNSAFE;
-	ERROR_DECL (error);
-	klass = mono_class_from_name_checked (image, name_space, name, error);
-	mono_error_cleanup (error); /* FIXME Don't swallow the error */
-	MONO_EXIT_GC_UNSAFE;
-	return klass;
-}
-/**
- * mono_class_load_from_name:
- * \param image The MonoImage where the type is looked up in
- * \param name_space the type namespace
- * \param name the type short name.
- *
- * This function works exactly like mono_class_from_name but it will abort if the class is not found.
- * This function should be used by the runtime for critical types to which there's no way to recover but crash
- * if they are missing. For example, System.Object or System.String.
- */
-MonoClass *
-mono_class_load_from_name (MonoImage *image, const char* name_space, const char *name)
-{
-	ERROR_DECL (error);
-	MonoClass *klass;
-	klass = mono_class_from_name_checked (image, name_space, name, error);
-	if (!klass)
-		g_error ("Runtime critical type %s.%s not found", name_space, name);
-	mono_error_assertf_ok (error, "Could not load runtime critical type %s.%s", name_space, name);
-	return klass;
-}
-/**
- * mono_class_try_load_from_name:
- * \param image The MonoImage where the type is looked up in
- * \param name_space the type namespace
- * \param name the type short name.
- *
- * This function tries to load a type, returning the class was found or NULL otherwise.
- * This function should be used by the runtime when probing for optional types, those that could have being linked out.
- *
- * Big design consideration. This function aborts if there was an error loading the type. This prevents us from missing
- * a type that we would otherwise assume to be available but was not due some error.
- *
- */
-MonoClass*
-mono_class_try_load_from_name (MonoImage *image, const char* name_space, const char *name)
-{
-	ERROR_DECL (error);
-	MonoClass *klass;
-	klass = mono_class_from_name_checked (image, name_space, name, error);
-	mono_error_assertf_ok (error, "Could not load runtime critical type %s.%s", name_space, name);
-	return klass;
-}
-static gboolean
-mono_interface_implements_interface (MonoClass *interface_implementer, MonoClass *interface_implemented)
-{
-	int i;
-	ERROR_DECL (error);
-	mono_class_setup_interfaces (interface_implementer, error);
-	if (!is_ok (error)) {
-		mono_error_cleanup  (error);
-		return FALSE;
-	}
-	MonoClass **klass_interfaces = m_class_get_interfaces (interface_implementer);
-	for (i = 0; i < m_class_get_interface_count (interface_implementer); i++) {
-		MonoClass *ic = klass_interfaces [i];
-		if (mono_class_is_ginst (ic))
-			ic = mono_class_get_generic_type_definition (ic);
-		if (ic == interface_implemented)
-			return TRUE;
-	}
-	return FALSE;
-}
-gboolean
-mono_class_is_subclass_of_internal (MonoClass *klass, MonoClass *klassc,
-				    gboolean check_interfaces)
-{
-	MONO_REQ_GC_UNSAFE_MODE;
-	/* FIXME test for interfaces with variant generic arguments */
-	if (check_interfaces) {
-		mono_class_init_internal (klass);
-		mono_class_init_internal (klassc);
-	}
-	if (check_interfaces && MONO_CLASS_IS_INTERFACE_INTERNAL (klassc) && !MONO_CLASS_IS_INTERFACE_INTERNAL (klass)) {
-		if (MONO_CLASS_IMPLEMENTS_INTERFACE (klass, m_class_get_interface_id (klassc)))
-			return TRUE;
-	} else if (check_interfaces && MONO_CLASS_IS_INTERFACE_INTERNAL (klassc) && MONO_CLASS_IS_INTERFACE_INTERNAL (klass)) {
-		int i;
-		MonoClass **klass_interfaces = m_class_get_interfaces (klass);
-		for (i = 0; i < m_class_get_interface_count (klass); i ++) {
-			MonoClass *ic =  klass_interfaces [i];
-			if (ic == klassc)
-				return TRUE;
-		}
-	} else {
-		if (!MONO_CLASS_IS_INTERFACE_INTERNAL (klass) && mono_class_has_parent (klass, klassc))
-			return TRUE;
-	}
-	/*
-	 * MS.NET thinks interfaces are a subclass of Object, so we think it as
-	 * well.
-	 */
-	if (klassc == mono_defaults.object_class)
-		return TRUE;
-	return FALSE;
-}
-static gboolean
-mono_type_is_generic_argument (MonoType *type)
-{
-	return type->type == MONO_TYPE_VAR || type->type == MONO_TYPE_MVAR;
-}
-gboolean
-mono_class_has_variant_generic_params (MonoClass *klass)
-{
-	int i;
-	MonoGenericContainer *container;
-	if (!mono_class_is_ginst (klass))
-		return FALSE;
-	container = mono_class_get_generic_container (mono_class_get_generic_class (klass)->container_class);
-	for (i = 0; i < container->type_argc; ++i)
-		if (mono_generic_container_get_param_info (container, i)->flags & (MONO_GEN_PARAM_VARIANT|MONO_GEN_PARAM_COVARIANT))
-			return TRUE;
-	return FALSE;
-}
-static gboolean
-mono_gparam_is_reference_conversible (MonoClass *target, MonoClass *candidate, gboolean check_for_reference_conv)
-{
-	if (target == candidate)
-		return TRUE;
-	if (check_for_reference_conv &&
-		mono_type_is_generic_argument (m_class_get_byval_arg (target)) &&
-		mono_type_is_generic_argument (m_class_get_byval_arg (candidate))) {
-		MonoGenericParam *gparam = m_class_get_byval_arg (candidate)->data.generic_param;
-		MonoGenericParamInfo *pinfo = mono_generic_param_info (gparam);
-		if (!pinfo || (pinfo->flags & GENERIC_PARAMETER_ATTRIBUTE_REFERENCE_TYPE_CONSTRAINT) == 0)
-			return FALSE;
-	}
-	if (!mono_class_is_assignable_from_internal (target, candidate))
-		return FALSE;
-	return TRUE;
-}
-/**
- * @container the generic container from the GTD
- * @klass: the class to be assigned to
- * @oklass: the source class
- *
- * Both @klass and @oklass must be instances of the same generic interface.
- *
- * Returns: TRUE if @klass can be assigned to a @klass variable
- */
-gboolean
-mono_class_is_variant_compatible (MonoClass *klass, MonoClass *oklass, gboolean check_for_reference_conv)
-{
-	int j;
-	MonoType **klass_argv, **oklass_argv;
-	MonoClass *klass_gtd = mono_class_get_generic_type_definition (klass);
-	MonoGenericContainer *container = mono_class_get_generic_container (klass_gtd);
-	if (klass == oklass)
-		return TRUE;
-	/*Viable candidates are instances of the same generic interface*/
-	if (mono_class_get_generic_type_definition (oklass) != klass_gtd || oklass == klass_gtd)
-		return FALSE;
-	klass_argv = &mono_class_get_generic_class (klass)->context.class_inst->type_argv [0];
-	oklass_argv = &mono_class_get_generic_class (oklass)->context.class_inst->type_argv [0];
-	for (j = 0; j < container->type_argc; ++j) {
-		MonoClass *param1_class = mono_class_from_mono_type_internal (klass_argv [j]);
-		MonoClass *param2_class = mono_class_from_mono_type_internal (oklass_argv [j]);
-		if (m_class_is_valuetype (param1_class) != m_class_is_valuetype (param2_class) || (m_class_is_valuetype (param1_class) && param1_class != param2_class))
-			return FALSE;
-		/*
-		 * The _VARIANT and _COVARIANT constants should read _COVARIANT and
-		 * _CONTRAVARIANT, but they are in a public header so we can't fix it.
-		 */
-		if (param1_class != param2_class) {
-			if (mono_generic_container_get_param_info (container, j)->flags & MONO_GEN_PARAM_VARIANT) {
-				if (!mono_gparam_is_reference_conversible (param1_class, param2_class, check_for_reference_conv))
-					return FALSE;
-			} else if (mono_generic_container_get_param_info (container, j)->flags & MONO_GEN_PARAM_COVARIANT) {
-				if (!mono_gparam_is_reference_conversible (param2_class, param1_class, check_for_reference_conv))
-					return FALSE;
-			} else
-				return FALSE;
-		}
-	}
-	return TRUE;
-}
-static gboolean
-mono_gparam_is_assignable_from (MonoClass *target, MonoClass *candidate)
-{
-	MonoGenericParam *gparam, *ogparam;
-	MonoGenericParamInfo *tinfo, *cinfo;
-	MonoClass **candidate_class;
-	gboolean class_constraint_satisfied, valuetype_constraint_satisfied;
-	int tmask, cmask;
-	if (target == candidate)
-		return TRUE;
-	MonoType *target_byval_arg = m_class_get_byval_arg (target);
-	MonoType *candidate_byval_arg = m_class_get_byval_arg (candidate);
-	if (target_byval_arg->type != candidate_byval_arg->type)
-		return FALSE;
-	gparam = target_byval_arg->data.generic_param;
-	ogparam = candidate_byval_arg->data.generic_param;
-	tinfo = mono_generic_param_info (gparam);
-	cinfo = mono_generic_param_info (ogparam);
-	class_constraint_satisfied = FALSE;
-	valuetype_constraint_satisfied = FALSE;
-	/*candidate must have a super set of target's special constraints*/
-	tmask = tinfo->flags & GENERIC_PARAMETER_ATTRIBUTE_SPECIAL_CONSTRAINTS_MASK;
-	cmask = cinfo->flags & GENERIC_PARAMETER_ATTRIBUTE_SPECIAL_CONSTRAINTS_MASK;
-	if (cinfo->constraints) {
-		for (candidate_class = cinfo->constraints; *candidate_class; ++candidate_class) {
-			MonoClass *cc = *candidate_class;
-			MonoType *cc_byval_arg = m_class_get_byval_arg (cc);
-			if (mono_type_is_reference (cc_byval_arg) && !MONO_CLASS_IS_INTERFACE_INTERNAL (cc))
-				class_constraint_satisfied = TRUE;
-			else if (!mono_type_is_reference (cc_byval_arg) && !MONO_CLASS_IS_INTERFACE_INTERNAL (cc))
-				valuetype_constraint_satisfied = TRUE;
-		}
-	}
-	class_constraint_satisfied |= (cmask & GENERIC_PARAMETER_ATTRIBUTE_REFERENCE_TYPE_CONSTRAINT) != 0;
-	valuetype_constraint_satisfied |= (cmask & GENERIC_PARAMETER_ATTRIBUTE_VALUE_TYPE_CONSTRAINT) != 0;
-	if ((tmask & GENERIC_PARAMETER_ATTRIBUTE_REFERENCE_TYPE_CONSTRAINT) && !class_constraint_satisfied)
-		return FALSE;
-	if ((tmask & GENERIC_PARAMETER_ATTRIBUTE_VALUE_TYPE_CONSTRAINT) && !valuetype_constraint_satisfied)
-		return FALSE;
-	if ((tmask & GENERIC_PARAMETER_ATTRIBUTE_CONSTRUCTOR_CONSTRAINT) && !((cmask & GENERIC_PARAMETER_ATTRIBUTE_CONSTRUCTOR_CONSTRAINT) ||
-		valuetype_constraint_satisfied)) {
-		return FALSE;
-	}
-	/*candidate type constraints must be a superset of target's*/
-	if (tinfo->constraints) {
-		MonoClass **target_class;
-		for (target_class = tinfo->constraints; *target_class; ++target_class) {
-			MonoClass *tc = *target_class;
-			MonoType *tc_byval_arg = m_class_get_byval_arg (tc);
-			/*
-			 * A constraint from @target might inflate into @candidate itself and in that case we don't need
-			 * check it's constraints since it satisfy the constraint by itself.
-			 */
-			if (mono_metadata_type_equal (tc_byval_arg, candidate_byval_arg))
-				continue;
-			if (!cinfo->constraints)
-				return FALSE;
-			for (candidate_class = cinfo->constraints; *candidate_class; ++candidate_class) {
-				MonoClass *cc = *candidate_class;
-				if (mono_class_is_assignable_from_internal (tc, cc))
-					break;
-				/*
-				 * This happens when we have the following:
-				 *
-				 * Bar<K> where K : IFace
-				 * Foo<T, U> where T : U where U : IFace
-				 * 	...
-				 * 	Bar<T> <- T here satisfy K constraint transitively through to U's constraint
-				 *
-				 */
-				if (mono_type_is_generic_argument (m_class_get_byval_arg (cc))) {
-					if (mono_gparam_is_assignable_from (target, cc))
-						break;
-				}
-			}
-			if (!*candidate_class)
-				return FALSE;
-		}
-	}
-	/*candidate itself must have a constraint that satisfy target*/
-	if (cinfo->constraints) {
-		for (candidate_class = cinfo->constraints; *candidate_class; ++candidate_class) {
-			MonoClass *cc = *candidate_class;
-			if (mono_class_is_assignable_from_internal (target, cc))
-				return TRUE;
-		}
-	}
-	return FALSE;
-}
-static MonoType*
-mono_type_get_underlying_type_ignore_byref (MonoType *type)
-{
-	if (type->type == MONO_TYPE_VALUETYPE && m_class_is_enumtype (type->data.klass))
-		return mono_class_enum_basetype_internal (type->data.klass);
-	if (type->type == MONO_TYPE_GENERICINST && m_class_is_enumtype (type->data.generic_class->container_class))
-		return mono_class_enum_basetype_internal (type->data.generic_class->container_class);
-	return type;
-}
-/**
- * mono_byref_type_is_assignable_from:
- * \param type The type assignee
- * \param ctype The type being assigned
- * \param signature_assignment whether this is a signature assignment check according to ECMA rules, or reflection
- *
- * Given two byref types, returns \c TRUE if values of the second type are assignable to locations of the first type.
- *
- * The \p signature_assignment parameter affects comparing T& and U& where T and U are both reference types.  Reflection
- * does an IsAssignableFrom check for T and U here, but ECMA I.8.7.2 says that the verification types of T and U must be
- * identical. If \p signature_assignment is \c TRUE we do an ECMA check, otherwise, reflection.
- */
-gboolean
-mono_byref_type_is_assignable_from (MonoType *type, MonoType *ctype, gboolean signature_assignment)
-{
-	g_assert (m_type_is_byref (type));
-	g_assert (m_type_is_byref (ctype));
-	MonoType *t = mono_type_get_underlying_type_ignore_byref (type);
-	MonoType *ot = mono_type_get_underlying_type_ignore_byref (ctype);
-	MonoClass *klass = mono_class_from_mono_type_internal (t);
-	MonoClass *klassc = mono_class_from_mono_type_internal (ot);
-	if (mono_type_is_primitive (t)) {
-		return mono_type_is_primitive (ot) && m_class_get_instance_size (klass) == m_class_get_instance_size (klassc);
-	} else if (t->type == MONO_TYPE_VAR || t->type == MONO_TYPE_MVAR) {
-		return t->type == ot->type && t->data.generic_param->num == ot->data.generic_param->num;
-	} else if (t->type == MONO_TYPE_PTR || t->type == MONO_TYPE_FNPTR) {
-		return t->type == ot->type;
-	} else {
-		if (ot->type == MONO_TYPE_VAR || ot->type == MONO_TYPE_MVAR)
-			return FALSE;
-		if (m_class_is_valuetype (klass))
-			return klass == klassc;
-		if (m_class_is_valuetype (klassc))
-			return FALSE;
-		/*
-		 * assignment compatibility for location types, ECMA I.8.7.2 - two managed pointer types T& and U& are
-		 * assignment compatible if the verification types of T and U are identical.
-		 */
-		if (signature_assignment)
-			return klass == klassc;
-		/* the reflection IsAssignableFrom does a subtype comparison here for reference types only */
-		return mono_class_is_assignable_from_internal (klass, klassc);
-	}
-}
-/**
- * mono_class_is_assignable_from_internal:
- * \param klass the class to be assigned to
- * \param oklass the source class
- *
- * \returns TRUE if an instance of class \p oklass can be assigned to an
- * instance of class \p klass
- */
-gboolean
-mono_class_is_assignable_from_internal (MonoClass *klass, MonoClass *oklass)
-{
-	gboolean result = FALSE;
-	ERROR_DECL (error);
-	mono_class_is_assignable_from_checked (klass, oklass, &result, error);
-	mono_error_cleanup (error);
-	return result;
-}
-/**
- * mono_class_is_assignable_from:
- * \param klass the class to be assigned to
- * \param oklass the source class
- *
- * \returns TRUE if an instance of class \p oklass can be assigned to an
- * instance of class \p klass
- */
-mono_bool
-mono_class_is_assignable_from (MonoClass *klass, MonoClass *oklass)
-{
-	gboolean result;
-	MONO_ENTER_GC_UNSAFE;
-	result = mono_class_is_assignable_from_internal (klass, oklass);
-	MONO_EXIT_GC_UNSAFE;
-	return result;
-}
-/*
- * ECMA I.8.7.3 general assignment compatibility is defined in terms of an "intermediate type"
- * whereas ECMA I.8.7.1 assignment compatibility for signature types is defined in terms of a "reduced type".
- *
- * This matters when we're comparing arrays of IntPtr.  IntPtr[] is generally
- * assignable to int[] or long[], depending on architecture.  But for signature
- * compatibility, IntPtr[] is distinct from both of them.
- *
- * Similarly for ulong* and IntPtr*, etc.
- */
-static MonoClass*
-composite_type_to_reduced_element_type (MonoClass *array_klass)
-{
-	switch (m_class_get_byval_arg (m_class_get_element_class (array_klass))->type) {
-	case MONO_TYPE_I:
-	case MONO_TYPE_U:
-		return mono_defaults.int_class;
-	default:
-		return m_class_get_cast_class (array_klass);
-	}
-}
-static void
-mono_class_is_assignable_from_general (MonoClass *klass, MonoClass *oklass, gboolean signature_assignment, gboolean *result, MonoError *error);
-/**
- * mono_class_is_assignable_from_checked:
- * \param klass the class to be assigned to
- * \param oklass the source class
- * \param result set if there was no error
- * \param error set if there was an error
- *
- * Sets \p result to TRUE if an instance of class \p oklass can be assigned to
- * an instance of class \p klass or FALSE if it cannot.  On error, no \p error
- * is set and \p result is not valid.
- */
-void
-mono_class_is_assignable_from_checked (MonoClass *klass, MonoClass *oklass, gboolean *result, MonoError *error)
-{
-	const gboolean for_sig = FALSE;
-	mono_class_is_assignable_from_general (klass, oklass, for_sig, result, error);
-}
-void
-mono_class_signature_is_assignable_from (MonoClass *klass, MonoClass *oklass, gboolean *result, MonoError *error)
-{
-	const gboolean for_sig = TRUE;
-	mono_class_is_assignable_from_general (klass, oklass, for_sig, result, error);
-}
-static gboolean
-class_is_inited_for_assignable_check (MonoClass *klass)
-{
-	/* if it's inited, it's inited */
-	if (G_LIKELY (m_class_is_inited (klass)))
-		return TRUE;
-	/*
-	 * IMPORTANT: keep this in sync with ensure_inited_for_assignable_check and with
-	 * mono_class_is_assignable_from_general - if the is_assignable check needs more of the
-	 * MonoClass structure to be initialized, this method will need extra checks.
-	 */
-	/* otherwise we need the supertypes and the interface bitmap */
-	if (!m_class_get_supertypes (klass))
-		return FALSE;
-	if (!m_class_get_interface_bitmap (klass))
-		return FALSE;
-	return TRUE;
-}
-static void
-ensure_inited_for_assignable_check (MonoClass *klass)
-{
-	if (m_class_is_inited (klass))
-		return;
-	/*
-	 * IMPORTANT: keep this in sync with class_is_inited_for_assignable_check and with
-	 * mono_class_is_assignable_from_general - if the is_assignable check needs more of the
-	 * MonoClass structure to be initialized, this method will need to do additional work.
-	 */
-	if (mono_class_is_ginst (klass)) {
-		MonoClass *gklass = mono_class_get_generic_class (klass)->container_class;
-		ensure_inited_for_assignable_check (gklass);
-	}
-	mono_class_setup_supertypes (klass);
-	ERROR_DECL (local_error);
-	mono_class_setup_interfaces (klass, local_error);
-	if (!is_ok (local_error)) {
-		mono_class_set_type_load_failure (klass, "Could not set up interfaces for %s.%s due to: %s", m_class_get_name_space (klass), m_class_get_name (klass), mono_error_get_message (local_error));
-		mono_error_cleanup (local_error);
-	}
-	int result;
-	result = mono_class_setup_interface_offsets_internal (klass, 0, MONO_SETUP_ITF_OFFSETS_BITMAP_ONLY);
-	if (result == -1)
-		mono_class_set_type_load_failure (klass, "Setting up interface_bitmap for %s.%s failed", m_class_get_name_space (klass), m_class_get_name (klass));
-	if (MONO_CLASS_IS_INTERFACE_INTERNAL (klass))
-		mono_class_setup_interface_id (klass);
-}
-void
-mono_class_is_assignable_from_general (MonoClass *klass, MonoClass *oklass, gboolean signature_assignment, gboolean *result, MonoError *error)
-{
-	g_assert (result);
-	if (klass == oklass) {
-		*result = TRUE;
-		return;
-	}
-	MONO_REQ_GC_UNSAFE_MODE;
-	/*
-	 * IMPORTANT: keep this in sync with class_is_inited_for_assignable_check and with
-	 * ensure_inited_for_assignable_check - if the is_assignable check needs more of the
-	 * MonoClass structure to be initialized, those methods will need to do additional work.
-	 */
-	if (G_UNLIKELY (!class_is_inited_for_assignable_check (klass)))
-		ensure_inited_for_assignable_check (klass);
-	if (G_UNLIKELY (!class_is_inited_for_assignable_check (oklass)))
-		ensure_inited_for_assignable_check (oklass);
-	if (mono_class_has_failure (klass)) {
-		mono_error_set_for_class_failure (error, klass);
-		*result = FALSE;
-		return;
-	}
-	if (mono_class_has_failure (oklass)) {
-		mono_error_set_for_class_failure (error, oklass);
-		*result = FALSE;
-		return;
-	}
-	MonoType *klass_byval_arg = m_class_get_byval_arg (klass);
-	MonoType *oklass_byval_arg = m_class_get_byval_arg (oklass);
-	if (mono_type_is_generic_argument (klass_byval_arg)) {
-		if (!mono_type_is_generic_argument (oklass_byval_arg)) {
-			*result = FALSE;
-			return;
-		}
-		*result = mono_gparam_is_assignable_from (klass, oklass);
-		return;
-	}
-	/* This can happen if oklass is a tyvar that has a constraint which is another tyvar which in turn
-	 * has a constraint which is a class type:
-	 *
-	 *  class Foo { }
-	 *  class G<T1, T2> where T1 : T2 where T2 : Foo { }
-	 *
-	 * In this case, Foo is assignable from T1.
-	 */
-	if (mono_type_is_generic_argument (oklass_byval_arg)) {
-		MonoGenericParam *gparam = oklass_byval_arg->data.generic_param;
-		MonoClass **constraints = mono_generic_container_get_param_info (gparam->owner, gparam->num)->constraints;
-		int i;
-		if (constraints) {
-			for (i = 0; constraints [i]; ++i) {
-				if (mono_class_is_assignable_from_internal (klass, constraints [i])) {
-					*result = TRUE;
-					return;
-				}
-			}
-		}
-		*result = mono_class_has_parent (oklass, klass);
-		return;
-	}
-	if (MONO_CLASS_IS_INTERFACE_INTERNAL (klass)) {
-		/* interface_offsets might not be set for dynamic classes */
-		if (mono_class_get_ref_info_handle (oklass) && !m_class_get_interface_bitmap (oklass)) {
-			/*
-			 * oklass might be a generic type parameter but they have
-			 * interface_offsets set.
-			 */
-			gboolean assign_result = mono_reflection_call_is_assignable_to (oklass, klass, error);
-			return_if_nok (error);
-			*result = assign_result;
-			return;
-		}
-		if (!m_class_get_interface_bitmap (oklass)) {
-			/* Happens with generic instances of not-yet created dynamic types */
-			*result = FALSE;
-			return;
-		}
-		if (MONO_CLASS_IMPLEMENTS_INTERFACE (oklass, m_class_get_interface_id (klass))) {
-			*result = TRUE;
-			return;
-		}
-		if (m_class_is_array_special_interface (klass) && m_class_get_rank (oklass) == 1 && m_class_get_byval_arg (oklass)->type == MONO_TYPE_SZARRAY) {
-			if (mono_class_is_gtd (klass)) {
-				/* klass is an array special gtd like
-				 * IList`1<>, and oklass is X[] for some X.
-				 * Moreover we know that X isn't !0 (the gparam
-				 * of IList`1) because in that case we would
-				 * have returned TRUE for
-				 * MONO_CLASS_IMPLEMENTS_INTERFACE, above.
-				 */
-				*result = FALSE;
-				return;
-			}
-			if (mono_class_get_generic_type_definition (klass) == mono_defaults.generic_ienumerator_class) {
-				*result = FALSE;
-				return;
-			}
-			MonoClass *iface_klass = mono_class_from_mono_type_internal (mono_class_get_generic_class (klass)->context.class_inst->type_argv [0]);
-			MonoClass *obj_klass = m_class_get_cast_class (oklass); //This gets us the cast class of element type of the array
-			if (!mono_class_is_nullable (iface_klass)) {
-				if (m_class_is_valuetype (iface_klass))
-					iface_klass = m_class_get_cast_class (iface_klass);
-				if (!(m_class_is_valuetype (obj_klass) && !m_class_is_valuetype (iface_klass)) && mono_class_is_assignable_from_internal (iface_klass, obj_klass)) {
-					*result = TRUE;
-					return;
-				}
-			}
-		}
-		if (mono_class_has_variant_generic_params (klass)) {
-			int i;
-			mono_class_setup_interfaces (oklass, error);
-			return_if_nok (error);
-			/*klass is a generic variant interface, We need to extract from oklass a list of ifaces which are viable candidates.*/
-			for (i = 0; i < m_class_get_interface_offsets_count (oklass); ++i) {
-				MonoClass *iface = m_class_get_interfaces_packed (oklass) [i];
-				if (mono_class_is_variant_compatible (klass, iface, FALSE)) {
-					*result = TRUE;
-					return;
-				}
-			}
-		}
-		*result = FALSE;
-		return;
-	} else if (m_class_is_delegate (klass)) {
-		if (mono_class_has_variant_generic_params (klass) && mono_class_is_variant_compatible (klass, oklass, FALSE)) {
-			*result = TRUE;
-			return;
-		}
-	} else if (m_class_get_rank (klass)) {
-		MonoClass *eclass, *eoclass;
-		if (m_class_get_rank (oklass) != m_class_get_rank (klass)) {
-			*result = FALSE;
-			return;
-		}
-		/* vectors vs. one dimensional arrays */
-		if (oklass_byval_arg->type != klass_byval_arg->type) {
-			*result = FALSE;
-			return;
-		}
-		if (signature_assignment) {
-			eclass = composite_type_to_reduced_element_type (klass);
-			eoclass = composite_type_to_reduced_element_type (oklass);
-		} else {
-			eclass = m_class_get_cast_class (klass);
-			eoclass = m_class_get_cast_class (oklass);
-		}
-		/*
-		 * a is b does not imply a[] is b[] when a is a valuetype, and
-		 * b is a reference type.
-		 */
-		if (m_class_is_valuetype (eoclass)) {
-			if ((eclass == mono_defaults.enum_class) ||
-			    (eclass == m_class_get_parent (mono_defaults.enum_class)) ||
-			    (!m_class_is_valuetype (eclass))) {
-				*result = FALSE;
-				return;
-			}
-		}
-		/*
-		 * a is b does not imply a[] is b[] in the case where b is an interface and
-		 * a is a generic parameter, unless a has an additional class constraint.
-		 * For example (C#):
-		 * ```
-		 * interface I {}
-		 * class G<T> where T : I {}
-		 * class H<U> where U : class, I {}
-		 * public class P {
-		 *     public static void Main() {
-		 *         var t = typeof(G<>).GetTypeInfo().GenericTypeParameters[0].MakeArrayType();
-		 *         var i = typeof(I).MakeArrayType();
-		 *         var u = typeof(H<>).GetTypeInfo().GenericTypeParameters[0].MakeArrayType();
-		 *         Console.WriteLine("I[] assignable from T[] ? {0}", i.IsAssignableFrom(t));
-		 *         Console.WriteLine("I[] assignable from U[] ? {0}", i.IsAssignableFrom(u));
-		 *     }
-		 * }
-		 * ```
-		 * This should print:
-		 * I[] assignable from T[] ? False
-		 * I[] assignable from U[] ? True
-		 */
-		if (MONO_CLASS_IS_INTERFACE_INTERNAL (eclass)) {
-			MonoType *eoclass_byval_arg = m_class_get_byval_arg (eoclass);
-			if (mono_type_is_generic_argument (eoclass_byval_arg)) {
-				MonoGenericParam *eoparam = eoclass_byval_arg->data.generic_param;
-				MonoGenericParamInfo *eoinfo = mono_generic_param_info (eoparam);
-				int eomask = eoinfo->flags & GENERIC_PARAMETER_ATTRIBUTE_SPECIAL_CONSTRAINTS_MASK;
-				if ((eomask & GENERIC_PARAMETER_ATTRIBUTE_REFERENCE_TYPE_CONSTRAINT) == 0) {
-					*result = FALSE;
-					return;
-				}
-			}
-		}
-		if (mono_class_is_nullable (eclass) ^ mono_class_is_nullable (eoclass)) {
-			*result = FALSE;
-			return;
-		}
-		mono_class_is_assignable_from_checked (eclass, eoclass, result, error);
-		return;
-	} else if (mono_class_is_nullable (klass)) {
-		if (mono_class_is_nullable (oklass))
-			mono_class_is_assignable_from_checked (m_class_get_cast_class (klass), m_class_get_cast_class (oklass), result, error);
-		else
-			mono_class_is_assignable_from_checked (m_class_get_cast_class (klass), oklass, result, error);
-		return;
-	} else if (m_class_get_class_kind (klass) == MONO_CLASS_POINTER) {
-		if (m_class_get_class_kind (oklass) != MONO_CLASS_POINTER) {
-			*result = FALSE;
-			return;
-		}
-		if (m_class_get_byval_arg (klass)->type == MONO_TYPE_FNPTR) {
-			if (mono_metadata_signature_equal (klass_byval_arg->data.method, oklass_byval_arg->data.method)) {
-				*result = TRUE;
-				return;
-			}
-			*result = FALSE;
-			return;
-		}
-		if (m_class_get_byval_arg (oklass)->type != MONO_TYPE_PTR) {
-			*result = FALSE;
-		}
-		g_assert (m_class_get_byval_arg (klass)->type == MONO_TYPE_PTR);
-		MonoClass *eclass;
-		MonoClass *eoclass;
-		eclass = composite_type_to_reduced_element_type (klass);
-		eoclass = composite_type_to_reduced_element_type (oklass);
-		*result = (eclass == eoclass);
-		return;
-	} else if (klass == mono_defaults.object_class) {
-		if (m_class_get_class_kind (oklass) == MONO_CLASS_POINTER)
-			*result = FALSE;
-		else
-			*result = TRUE;
-		return;
-	}
-	*result = mono_class_has_parent (oklass, klass);
-}
-/*Check if @oklass is variant compatible with @klass.*/
-static gboolean
-mono_class_is_variant_compatible_slow (MonoClass *klass, MonoClass *oklass)
-{
-	int j;
-	MonoType **klass_argv, **oklass_argv;
-	MonoClass *klass_gtd = mono_class_get_generic_type_definition (klass);
-	MonoGenericContainer *container = mono_class_get_generic_container (klass_gtd);
-	/*Viable candidates are instances of the same generic interface*/
-	if (mono_class_get_generic_type_definition (oklass) != klass_gtd || oklass == klass_gtd)
-		return FALSE;
-	klass_argv = &mono_class_get_generic_class (klass)->context.class_inst->type_argv [0];
-	oklass_argv = &mono_class_get_generic_class (oklass)->context.class_inst->type_argv [0];
-	for (j = 0; j < container->type_argc; ++j) {
-		MonoClass *param1_class = mono_class_from_mono_type_internal (klass_argv [j]);
-		MonoClass *param2_class = mono_class_from_mono_type_internal (oklass_argv [j]);
-		if (m_class_is_valuetype (param1_class) != m_class_is_valuetype (param2_class))
-			return FALSE;
-		/*
-		 * The _VARIANT and _COVARIANT constants should read _COVARIANT and
-		 * _CONTRAVARIANT, but they are in a public header so we can't fix it.
-		 */
-		if (param1_class != param2_class) {
-			if (mono_generic_container_get_param_info (container, j)->flags & MONO_GEN_PARAM_VARIANT) {
-				if (!mono_class_is_assignable_from_slow (param1_class, param2_class))
-					return FALSE;
-			} else if (mono_generic_container_get_param_info (container, j)->flags & MONO_GEN_PARAM_COVARIANT) {
-				if (!mono_class_is_assignable_from_slow (param2_class, param1_class))
-					return FALSE;
-			} else
-				return FALSE;
-		}
-	}
-	return TRUE;
-}
-static gboolean
-mono_class_implement_interface_slow_cached (MonoClass *target, MonoClass *candidate, dn_simdhash_ptrpair_ptr_t *cache);
-static gboolean
-mono_class_implement_interface_slow_uncached (MonoClass *target, MonoClass *candidate, dn_simdhash_ptrpair_ptr_t *cache)
-{
-	ERROR_DECL (error);
-	int i;
-	gboolean is_variant = mono_class_has_variant_generic_params (target);
-	if (is_variant && MONO_CLASS_IS_INTERFACE_INTERNAL (candidate)) {
-		if (mono_class_is_variant_compatible_slow (target, candidate))
-			return TRUE;
-	}
-	do {
-		if (candidate == target)
-			return TRUE;
-		/*A TypeBuilder can have more interfaces on tb->interfaces than on candidate->interfaces*/
-		if (image_is_dynamic (m_class_get_image (candidate)) && !m_class_was_typebuilder (candidate)) {
-			MonoReflectionTypeBuilder *tb = mono_class_get_ref_info_raw (candidate); /* FIXME use handles */
-			int j;
-			if (tb && tb->interfaces) {
-				for (j = mono_array_length_internal (tb->interfaces) - 1; j >= 0; --j) {
-					MonoReflectionType *iface = mono_array_get_internal (tb->interfaces, MonoReflectionType*, j);
-					MonoClass *iface_class;
-					/* we can't realize the type here since it can do pretty much anything. */
-					if (!iface->type)
-						continue;
-					iface_class = mono_class_from_mono_type_internal (iface->type);
-					if (iface_class == target)
-						return TRUE;
-					if (is_variant && mono_class_is_variant_compatible_slow (target, iface_class))
-						return TRUE;
-					if (mono_class_implement_interface_slow_cached (target, iface_class, cache))
-						return TRUE;
-				}
-			}
-		} else {
-			/*setup_interfaces don't mono_class_init_internal anything*/
-			/*FIXME this doesn't handle primitive type arrays.
-			ICollection<sbyte> x byte [] won't work because candidate->interfaces, for byte[], won't have IList<sbyte>.
-			A possible way to fix this would be to move that to setup_interfaces from setup_interface_offsets.
-			*/
-			mono_class_setup_interfaces (candidate, error);
-			if (!is_ok (error)) {
-				mono_error_cleanup (error);
-				return FALSE;
-			}
-			int candidate_interface_count = m_class_get_interface_count (candidate);
-			MonoClass **candidate_interfaces = m_class_get_interfaces (candidate);
-			for (i = 0; i < candidate_interface_count; ++i) {
-				if (candidate_interfaces [i] == target)
-					return TRUE;
-				if (is_variant && mono_class_is_variant_compatible_slow (target, candidate_interfaces [i]))
-					return TRUE;
-				if (mono_class_implement_interface_slow_cached (target, candidate_interfaces [i], cache))
-					return TRUE;
-			}
-		}
-		candidate = m_class_get_parent (candidate);
-	} while (candidate);
-	return FALSE;
-}
-#if LOG_INTERFACE_CACHE_HITS
-static gint64 implement_interface_hits = 0, implement_interface_misses = 0;
-static void
-log_hit_rate (dn_simdhash_ptrpair_ptr_t *cache)
-{
-	gint64 total_calls = implement_interface_hits + implement_interface_misses;
-	if ((total_calls % 500) != 0)
-		return;
-	double hit_rate = implement_interface_hits * 100.0 / total_calls;
-	g_printf ("implement_interface cache hit rate: %f (%lld total calls). Overflow count: %u\n", hit_rate, total_calls, dn_simdhash_overflow_count (cache));
-}
-#endif
-static gboolean
-mono_class_implement_interface_slow_cached (MonoClass *target, MonoClass *candidate, dn_simdhash_ptrpair_ptr_t *cache)
-{
-	gpointer cached_result = NULL;
-	dn_ptrpair_t key = { target, candidate };
-	gboolean result = 0, cache_hit = 0;
-	if (candidate == target)
-		return TRUE;
-	cache_hit = dn_simdhash_ptrpair_ptr_try_get_value (cache, key, &cached_result);
-	if (cache_hit) {
-#if LOG_INTERFACE_CACHE_HITS
-		implement_interface_hits++;
-		log_hit_rate (cache);
-#endif
-		result = (cached_result != NULL);
-#ifndef ENABLE_CHECKED_BUILD
-		return result;
-#endif
-	}
-	gboolean uncached_result = mono_class_implement_interface_slow_uncached (target, candidate, cache);
-	if (!cache_hit) {
-#if LOG_INTERFACE_CACHE_HITS
-		implement_interface_misses++;
-		log_hit_rate (cache);
-#endif
-		dn_simdhash_ptrpair_ptr_try_add (cache, key, uncached_result ? GUINT_TO_POINTER(1) : NULL);
-	}
-#ifdef ENABLE_CHECKED_BUILD
-	if (cache_hit) {
-		if (result != uncached_result)
-			g_print (
-				"Cache mismatch for %s.%s and %s.%s: cached=%d, uncached=%d\n",
-				m_class_get_name_space (target), m_class_get_name (target),
-				m_class_get_name_space (candidate), m_class_get_name (candidate),
-				result, uncached_result
-			);
-		g_assert (result == uncached_result);
-	}
-#endif
-	return uncached_result;
-}
-static dn_simdhash_ptrpair_ptr_t *implement_interface_scratch_cache = NULL;
-/*Check if @candidate implements the interface @target*/
-static gboolean
-mono_class_implement_interface_slow (MonoClass *target, MonoClass *candidate)
-{
-	gpointer cas_result;
-	gboolean result;
-	dn_simdhash_ptrpair_ptr_t *cache = (dn_simdhash_ptrpair_ptr_t *)mono_atomic_xchg_ptr ((volatile gpointer *)&implement_interface_scratch_cache, NULL);
-	if (!cache)
-		cache = dn_simdhash_ptrpair_ptr_new (2048, NULL);
-	else if (dn_simdhash_count (cache) >= 2250) {
-		dn_simdhash_clear (cache);
-	}
-	result = mono_class_implement_interface_slow_cached (target, candidate, cache);
-	cas_result = mono_atomic_cas_ptr ((volatile gpointer *)&implement_interface_scratch_cache, cache, NULL);
-	if (cas_result != NULL)
-		dn_simdhash_free (cache);
-	return result;
-}
-/*
- * Check if @oklass can be assigned to @klass.
- * This function does the same as mono_class_is_assignable_from_internal but is safe to be used from mono_class_init_internal context.
- */
-gboolean
-mono_class_is_assignable_from_slow (MonoClass *target, MonoClass *candidate)
-{
-	if (candidate == target)
-		return TRUE;
-	if (target == mono_defaults.object_class)
-		return TRUE;
-	if (mono_class_has_parent (candidate, target))
-		return TRUE;
-	/*If target is not an interface there is no need to check them.*/
-	if (MONO_CLASS_IS_INTERFACE_INTERNAL (target)) {
-		return mono_class_implement_interface_slow (target, candidate);
-	}
-	if (m_class_is_delegate (target) && mono_class_has_variant_generic_params (target))
-		return mono_class_is_variant_compatible (target, candidate, FALSE);
-	if (m_class_get_rank (target)) {
-		MonoClass *eclass, *eoclass;
-		if (m_class_get_rank (target) != m_class_get_rank (candidate))
-			return FALSE;
-		/* vectors vs. one dimensional arrays */
-		if (m_class_get_byval_arg (target)->type != m_class_get_byval_arg (candidate)->type)
-			return FALSE;
-		eclass = m_class_get_cast_class (target);
-		eoclass = m_class_get_cast_class (candidate);
-		/*
-		 * a is b does not imply a[] is b[] when a is a valuetype, and
-		 * b is a reference type.
-		 */
-		if (m_class_is_valuetype (eoclass)) {
-			if ((eclass == mono_defaults.enum_class) ||
-			    (eclass == m_class_get_parent (mono_defaults.enum_class)) ||
-				(eclass == mono_defaults.object_class))
-				return FALSE;
-		}
-		return mono_class_is_assignable_from_slow (eclass, eoclass);
-	}
-	/*FIXME properly handle nullables */
-	/*FIXME properly handle (M)VAR */
-	return FALSE;
-}
-/**
- * mono_generic_param_get_base_type:
- *
- * Return the base type of the given generic parameter from its constraints.
- *
- * Could be another generic parameter, or it could be Object or ValueType.
- */
-MonoClass*
-mono_generic_param_get_base_type (MonoClass *klass)
-{
-	MonoType *type = m_class_get_byval_arg (klass);
-	g_assert (mono_type_is_generic_argument (type));
-	MonoGenericParam *gparam = type->data.generic_param;
-	g_assert (gparam->owner && !gparam->owner->is_anonymous);
-	MonoClass **constraints = mono_generic_container_get_param_info (gparam->owner, gparam->num)->constraints;
-	MonoClass *base_class = mono_defaults.object_class;
-	if (constraints) {
-		int i;
-		for (i = 0; constraints [i]; ++i) {
-			MonoClass *constraint = constraints[i];
-			if (MONO_CLASS_IS_INTERFACE_INTERNAL (constraint))
-				continue;
-			MonoType *constraint_type = m_class_get_byval_arg (constraint);
-			if (mono_type_is_generic_argument (constraint_type)) {
-				MonoGenericParam *constraint_param = constraint_type->data.generic_param;
-				MonoGenericParamInfo *constraint_info = mono_generic_param_info (constraint_param);
-				if ((constraint_info->flags & GENERIC_PARAMETER_ATTRIBUTE_REFERENCE_TYPE_CONSTRAINT) == 0 &&
-				    (constraint_info->flags & GENERIC_PARAMETER_ATTRIBUTE_VALUE_TYPE_CONSTRAINT) == 0)
-					continue;
-			}
-			base_class = constraint;
-		}
-	}
-	if (base_class == mono_defaults.object_class)
-	{
-		MonoGenericParamInfo *gparam_info = mono_generic_param_info (gparam);
-		if ((gparam_info->flags & GENERIC_PARAMETER_ATTRIBUTE_VALUE_TYPE_CONSTRAINT) != 0) {
-			base_class = mono_class_get_valuetype_class ();
-		}
-	}
-	return base_class;
-}
-/**
- * mono_class_get_cctor:
- * \param klass A MonoClass pointer
- *
- * \returns The static constructor of \p klass if it exists, NULL otherwise.
- */
-MonoMethod*
-mono_class_get_cctor (MonoClass *klass)
-{
-	MonoMethod *result = NULL;
-	ERROR_DECL (error);
-	MonoCachedClassInfo cached_info;
-	if (image_is_dynamic (m_class_get_image (klass))) {
-		/*
-		 * has_cctor is not set for these classes because mono_class_init_internal () is
-		 * not run for them.
-		 */
-		result = mono_class_get_method_from_name_checked (klass, ".cctor", -1, METHOD_ATTRIBUTE_SPECIAL_NAME, error);
-		mono_error_assert_msg_ok (error, "Could not lookup class cctor in dynamic image");
-		return result;
-	}
-	mono_class_init_internal (klass);
-	if (!m_class_has_cctor (klass))
-		return result;
-	if (mono_class_is_ginst (klass) && !m_class_get_methods (klass)) {
-		result = mono_class_get_inflated_method (klass, mono_class_get_cctor (mono_class_get_generic_class (klass)->container_class), error);
-		mono_error_assert_msg_ok (error, "Could not lookup inflated class cctor"); /* FIXME do proper error handling */
-		return result;
-	}
-	if (mono_class_get_cached_class_info (klass, &cached_info)) {
-		result = mono_get_method_checked (m_class_get_image (klass), cached_info.cctor_token, klass, NULL, error);
-		mono_error_assert_msg_ok (error, "Could not lookup class cctor from cached metadata");
-		return result;
-	}
-	result = mono_class_get_method_from_name_checked (klass, ".cctor", -1, METHOD_ATTRIBUTE_SPECIAL_NAME, error);
-	mono_error_assert_msg_ok (error, "Could not lookup class cctor");
-	return result;
-}
-/**
- * mono_class_get_finalizer:
- * \param klass: The MonoClass pointer
- *
- * \returns The finalizer method of \p klass if it exists, NULL otherwise.
- */
-MonoMethod*
-mono_class_get_finalizer (MonoClass *klass)
-{
-	MonoCachedClassInfo cached_info;
-	if (!m_class_is_inited (klass))
-		mono_class_init_internal (klass);
-	if (!mono_class_has_finalizer (klass))
-		return NULL;
-	if (mono_class_get_cached_class_info (klass, &cached_info)) {
-		ERROR_DECL (error);
-		MonoMethod *result = mono_get_method_checked (cached_info.finalize_image, cached_info.finalize_token, NULL, NULL, error);
-		mono_error_assert_msg_ok (error, "Could not lookup finalizer from cached metadata");
-		return result;
-	}else {
-		mono_class_setup_vtable (klass);
-		return m_class_get_vtable (klass) [mono_class_get_object_finalize_slot ()];
-	}
-}
-/**
- * mono_class_needs_cctor_run:
- * \param klass the MonoClass pointer
- * \param caller a MonoMethod describing the caller
- *
- * Determines whenever the class has a static constructor and whenever it
- * needs to be called when executing CALLER.
- */
-gboolean
-mono_class_needs_cctor_run (MonoClass *klass, MonoMethod *caller)
-{
-	MonoMethod *method;
-	method = mono_class_get_cctor (klass);
-	if (method)
-		return (method == caller) ? FALSE : TRUE;
-	else
-		return FALSE;
-}
-/**
- * mono_class_array_element_size:
- * \param klass
- *
- * \returns The number of bytes an element of type \p klass uses when stored into an array.
- */
-gint32
-mono_class_array_element_size (MonoClass *klass)
-{
-	MonoType *type = m_class_get_byval_arg (klass);
-handle_enum:
-	switch (type->type) {
-	case MONO_TYPE_I1:
-	case MONO_TYPE_U1:
-	case MONO_TYPE_BOOLEAN:
-		return 1;
-	case MONO_TYPE_I2:
-	case MONO_TYPE_U2:
-	case MONO_TYPE_CHAR:
-		return 2;
-	case MONO_TYPE_I4:
-	case MONO_TYPE_U4:
-	case MONO_TYPE_R4:
-		return 4;
-	case MONO_TYPE_I:
-	case MONO_TYPE_U:
-	case MONO_TYPE_PTR:
-	case MONO_TYPE_FNPTR:
-	case MONO_TYPE_CLASS:
-	case MONO_TYPE_STRING:
-	case MONO_TYPE_OBJECT:
-	case MONO_TYPE_SZARRAY:
-	case MONO_TYPE_ARRAY:
-		return TARGET_SIZEOF_VOID_P;
-	case MONO_TYPE_I8:
-	case MONO_TYPE_U8:
-	case MONO_TYPE_R8:
-		return 8;
-	case MONO_TYPE_VALUETYPE:
-		if (m_class_is_enumtype (type->data.klass)) {
-			type = mono_class_enum_basetype_internal (type->data.klass);
-			klass = m_class_get_element_class (klass);
-			goto handle_enum;
-		}
-		return mono_class_value_size (klass, NULL);
-	case MONO_TYPE_GENERICINST:
-		type = m_class_get_byval_arg (type->data.generic_class->container_class);
-		goto handle_enum;
-	case MONO_TYPE_VAR:
-	case MONO_TYPE_MVAR: {
-		int align;
-		return mono_type_size (type, &align);
-	}
-	case MONO_TYPE_VOID:
-		return 0;
-	default:
-		g_error ("unknown type 0x%02x in mono_class_array_element_size", type->type);
-	}
-	return -1;
-}
-/**
- * mono_array_element_size:
- * \param ac pointer to a \c MonoArrayClass
- *
- * \returns The size of single array element.
- *
- * LOCKING: Acquires the loader lock.
- */
-gint32
-mono_array_element_size (MonoClass *ac)
-{
-	g_assert (m_class_get_rank (ac));
-	if (G_UNLIKELY (!m_class_is_size_inited (ac))) {
-		mono_class_setup_fields (ac);
-	}
-	return m_class_get_sizes (ac).element_size;
-}
-/**
- * mono_ldtoken:
- */
-gpointer
-mono_ldtoken (MonoImage *image, guint32 token, MonoClass **handle_class,
-	      MonoGenericContext *context)
-{
-	gpointer res;
-	MONO_ENTER_GC_UNSAFE;
-	ERROR_DECL (error);
-	res = mono_ldtoken_checked (image, token, handle_class, context, error);
-	mono_error_assert_ok (error);
-	MONO_EXIT_GC_UNSAFE;
-	return res;
-}
-gpointer
-mono_ldtoken_checked (MonoImage *image, guint32 token, MonoClass **handle_class,
-	      MonoGenericContext *context, MonoError *error)
-{
-	error_init (error);
-	if (image_is_dynamic (image)) {
-		MonoClass *tmp_handle_class;
-		gpointer obj = mono_lookup_dynamic_token_class (image, token, TRUE, &tmp_handle_class, context, error);
-		mono_error_assert_ok (error);
-		g_assert (tmp_handle_class);
-		if (handle_class)
-			*handle_class = tmp_handle_class;
-		if (tmp_handle_class == mono_defaults.typehandle_class)
-			return m_class_get_byval_arg ((MonoClass*)obj);
-		else
-			return obj;
-	}
-	switch (token & 0xff000000) {
-	case MONO_TOKEN_TYPE_DEF:
-	case MONO_TOKEN_TYPE_REF:
-	case MONO_TOKEN_TYPE_SPEC: {
-		MonoType *type;
-		MonoClass *klass;
-		if (handle_class)
-			*handle_class = mono_defaults.typehandle_class;
-		type = mono_type_get_checked (image, token, context, error);
-		if (!type)
-			return NULL;
-		klass = mono_class_from_mono_type_internal (type);
-		mono_class_init_internal (klass);
-		if (mono_class_has_failure (klass)) {
-			mono_error_set_for_class_failure (error, klass);
-			return NULL;
-		}
-		/* We return a MonoType* as handle */
-		return type;
-	}
-	case MONO_TOKEN_FIELD_DEF: {
-		MonoClass *klass;
-		guint32 type = mono_metadata_typedef_from_field (image, mono_metadata_token_index (token));
-		if (!type) {
-			mono_error_set_bad_image (error, image, "Bad ldtoken %x", token);
-			return NULL;
-		}
-		if (handle_class)
-			*handle_class = mono_defaults.fieldhandle_class;
-		klass = mono_class_get_and_inflate_typespec_checked (image, MONO_TOKEN_TYPE_DEF | type, context, error);
-		if (!klass)
-			return NULL;
-		mono_class_init_internal (klass);
-		return mono_class_get_field (klass, token);
-	}
-	case MONO_TOKEN_METHOD_DEF:
-	case MONO_TOKEN_METHOD_SPEC: {
-		MonoMethod *meth;
-		meth = mono_get_method_checked (image, token, NULL, context, error);
-		if (handle_class)
-			*handle_class = mono_defaults.methodhandle_class;
-		if (!meth)
-			return NULL;
-		return meth;
-	}
-	case MONO_TOKEN_MEMBER_REF: {
-		guint32 cols [MONO_MEMBERREF_SIZE];
-		const char *sig;
-		mono_metadata_decode_row (&image->tables [MONO_TABLE_MEMBERREF], mono_metadata_token_index (token) - 1, cols, MONO_MEMBERREF_SIZE);
-		sig = mono_metadata_blob_heap (image, cols [MONO_MEMBERREF_SIGNATURE]);
-		mono_metadata_decode_blob_size (sig, &sig);
-		if (*sig == 0x6) { /* it's a field */
-			MonoClass *klass;
-			MonoClassField *field;
-			field = mono_field_from_token_checked (image, token, &klass, context, error);
-			if (handle_class)
-				*handle_class = mono_defaults.fieldhandle_class;
-			return field;
-		} else {
-			MonoMethod *meth;
-			meth = mono_get_method_checked (image, token, NULL, context, error);
-			if (handle_class)
-				*handle_class = mono_defaults.methodhandle_class;
-			return meth;
-		}
-	}
-	default:
-		mono_error_set_bad_image (error, image, "Bad ldtoken %x", token);
-	}
-	return NULL;
-}
-gpointer
-mono_lookup_dynamic_token (MonoImage *image, guint32 token, MonoGenericContext *context, MonoError *error)
-{
-	MonoClass *handle_class;
-	error_init (error);
-	return mono_reflection_lookup_dynamic_token (image, token, TRUE, &handle_class, context, error);
-}
-gpointer
-mono_lookup_dynamic_token_class (MonoImage *image, guint32 token, gboolean valid_token, MonoClass **handle_class, MonoGenericContext *context, MonoError *error)
-{
-	return mono_reflection_lookup_dynamic_token (image, token, valid_token, handle_class, context, error);
-}
-gboolean
-mono_class_get_cached_class_info (MonoClass *klass, MonoCachedClassInfo *res)
-{
-	return mono_get_runtime_callbacks ()->get_cached_class_info (klass, res);
-}
-/**
- * mono_class_get_image:
- *
- * Use this method to get the \c MonoImage* where this class came from.
- *
- * \returns The image where this class is defined.
- */
-MonoImage*
-mono_class_get_image (MonoClass *klass)
-{
-	return m_class_get_image (klass);
-}
-/**
- * mono_class_get_element_class:
- * \param klass the \c MonoClass to act on
- *
- * Use this function to get the element class of an array.
- *
- * \returns The element class of an array.
- */
-MonoClass*
-mono_class_get_element_class (MonoClass *klass)
-{
-	MonoClass *result;
-	MONO_ENTER_GC_UNSAFE;
-	result = m_class_get_element_class (klass);
-	MONO_EXIT_GC_UNSAFE;
-	return result;
-}
-/**
- * mono_class_is_valuetype:
- * \param klass the \c MonoClass to act on
- *
- * Use this method to determine if the provided \c MonoClass* represents a value type,
- * or a reference type.
- *
- * \returns TRUE if the \c MonoClass represents a \c ValueType, FALSE if it represents a reference type.
- */
-gboolean
-mono_class_is_valuetype (MonoClass *klass)
-{
-	gboolean result;
-	MONO_ENTER_GC_UNSAFE;
-	result = m_class_is_valuetype (klass);
-	MONO_EXIT_GC_UNSAFE;
-	return result;
-}
-/**
- * mono_class_is_enum:
- * \param klass the \c MonoClass to act on
- *
- * Use this function to determine if the provided \c MonoClass* represents an enumeration.
- *
- * \returns TRUE if the \c MonoClass represents an enumeration.
- */
-gboolean
-mono_class_is_enum (MonoClass *klass)
-{
-	gboolean result;
-	MONO_ENTER_GC_UNSAFE;
-	result = m_class_is_enumtype (klass);
-	MONO_EXIT_GC_UNSAFE;
-	return result;
-}
-/**
- * mono_class_enum_basetype_internal:
- * \param klass the \c MonoClass to act on
- *
- * Use this function to get the underlying type for an enumeration value.
- *
- * \returns The underlying type representation for an enumeration.
- */
-MonoType*
-mono_class_enum_basetype_internal (MonoClass *klass)
-{
-	if (m_class_get_element_class (klass) == klass)
-		/* SRE or broken types */
-		return NULL;
-	return m_class_get_byval_arg (m_class_get_element_class (klass));
-}
-/**
- * mono_class_enum_basetype:
- * \param klass the \c MonoClass to act on
- *
- * Use this function to get the underlying type for an enumeration value.
- *
- * \returns The underlying type representation for an enumeration.
- */
-MonoType*
-mono_class_enum_basetype (MonoClass *klass)
-{
-	MonoType *res;
-	MONO_ENTER_GC_UNSAFE;
-	res = mono_class_enum_basetype_internal (klass);
-	MONO_EXIT_GC_UNSAFE;
-	return res;
-}
-/**
- * mono_class_get_parent
- * \param klass the \c MonoClass to act on
- *
- * \returns The parent class for this class.
- */
-MonoClass*
-mono_class_get_parent (MonoClass *klass)
-{
-	MonoClass *result;
-	MONO_ENTER_GC_UNSAFE;
-	result = m_class_get_parent (klass);
-	MONO_EXIT_GC_UNSAFE;
-	return result;
-}
-/**
- * mono_class_get_nesting_type:
- * \param klass the \c MonoClass to act on
- *
- * Use this function to obtain the class that the provided \c MonoClass* is nested on.
- *
- * If the return is NULL, this indicates that this class is not nested.
- *
- * \returns The container type where this type is nested or NULL if this type is not a nested type.
- */
-MonoClass*
-mono_class_get_nesting_type (MonoClass *klass)
-{
-	return m_class_get_nested_in (klass);
-}
-/**
- * mono_class_get_rank:
- * \param klass the MonoClass to act on
- *
- * \returns The rank for the array (the number of dimensions).
- */
-int
-mono_class_get_rank (MonoClass *klass)
-{
-	return m_class_get_rank (klass);
-}
-/**
- * mono_class_get_name
- * \param klass the \c MonoClass to act on
- *
- * \returns The name of the class.
- */
-const char*
-mono_class_get_name (MonoClass *klass)
-{
-	const char *result;
-	MONO_ENTER_GC_UNSAFE;
-	result = m_class_get_name (klass);
-	MONO_EXIT_GC_UNSAFE;
-	return result;
-}
-/**
- * mono_class_get_namespace:
- * \param klass the \c MonoClass to act on
- *
- * \returns The namespace of the class.
- */
-const char*
-mono_class_get_namespace (MonoClass *klass)
-{
-	const char *result;
-	MONO_ENTER_GC_UNSAFE;
-	result = m_class_get_name_space (klass);
-	MONO_EXIT_GC_UNSAFE;
-	return result;
-}
-/**
- * mono_class_get_type:
- * \param klass the \c MonoClass to act on
- *
- * This method returns the internal \c MonoType representation for the class.
- *
- * \returns The \c MonoType from the class.
- */
-MonoType*
-mono_class_get_type (MonoClass *klass)
-{
-	return m_class_get_byval_arg (klass);
-}
-/**
- * mono_class_get_type_token:
- * \param klass the \c MonoClass to act on
- *
- * This method returns type token for the class.
- *
- * \returns The type token for the class.
- */
-guint32
-mono_class_get_type_token (MonoClass *klass)
-{
-	return m_class_get_type_token (klass);
-}
-/**
- * mono_class_get_byref_type:
- * \param klass the \c MonoClass to act on
- *
- *
- */
-MonoType*
-mono_class_get_byref_type (MonoClass *klass)
-{
-	return m_class_get_this_arg (klass);
-}
-/**
- * mono_class_num_fields:
- * \param klass the \c MonoClass to act on
- *
- * \returns The number of static and instance fields in the class.
- */
-int
-mono_class_num_fields (MonoClass *klass)
-{
-	MonoImage *image = m_class_get_image (klass);
-	if (G_UNLIKELY (image->has_updates)) {
-		return mono_class_get_field_count (klass) + mono_metadata_update_get_num_fields_added (klass);
-	}
-	return mono_class_get_field_count (klass);
-}
-/**
- * mono_class_num_methods:
- * \param klass the \c MonoClass to act on
- *
- * \returns The number of methods in the class.
- */
-int
-mono_class_num_methods (MonoClass *klass)
-{
-	MonoImage *image = m_class_get_image (klass);
-	if (G_UNLIKELY (image->has_updates)) {
-		return mono_class_get_method_count (klass) + mono_metadata_update_get_num_methods_added (klass);
-	}
-	return mono_class_get_method_count (klass);
-}
-/**
- * mono_class_num_properties
- * \param klass the \c MonoClass to act on
- *
- * \returns The number of properties in the class.
- */
-int
-mono_class_num_properties (MonoClass *klass)
-{
-	mono_class_setup_properties (klass);
-	return mono_class_get_property_info (klass)->count;
-}
-/**
- * mono_class_num_events:
- * \param klass the \c MonoClass to act on
- *
- * \returns The number of events in the class.
- */
-int
-mono_class_num_events (MonoClass *klass)
-{
-	mono_class_setup_events (klass);
-	return mono_class_get_event_info (klass)->count;
-}
-/**
- * mono_class_get_fields:
- * \param klass the \c MonoClass to act on
- *
- * This routine is an iterator routine for retrieving the fields in a class.
- *
- * You must pass a \c gpointer that points to zero and is treated as an opaque handle to
- * iterate over all of the elements.  When no more values are
- * available, the return value is NULL.
- *
- * \returns a \c MonoClassField* on each iteration, or NULL when no more fields are available.
- */
-MonoClassField*
-mono_class_get_fields (MonoClass* klass, gpointer *iter)
-{
-	MonoClassField *result;
-	MONO_ENTER_GC_UNSAFE;
-	result = mono_class_get_fields_internal (klass, iter);
-	MONO_EXIT_GC_UNSAFE;
-	return result;
-}
-MonoClassField*
-mono_class_get_fields_internal (MonoClass *klass, gpointer *iter)
-{
-	if (!iter)
-		return NULL;
-	MonoImage *image = m_class_get_image (klass);
-	if (!*iter) {
-		mono_class_setup_fields (klass);
-		if (mono_class_has_failure (klass))
-			return NULL;
-		/* start from the first */
-		if (mono_class_get_field_count (klass)) {
-			MonoClassField *klass_fields = m_class_get_fields (klass);
-			uint32_t idx = 0;
-			*iter = GUINT_TO_POINTER (idx + 1);
-			return &klass_fields [0];
-		} else {
-			/* no fields */
-			if (G_LIKELY (!image->has_updates))
-				return NULL;
-			else
-				*iter = 0;
-		}
-	}
-	uint32_t idx = GPOINTER_TO_UINT(*iter);
-	if (idx < mono_class_get_field_count (klass)) {
-		MonoClassField *field = &m_class_get_fields (klass) [idx];
-		++idx;
-		*iter = GUINT_TO_POINTER (idx);
-		return field;
-	}
-	if (G_UNLIKELY (image->has_updates)) {
-		return mono_metadata_update_added_fields_iter (klass, FALSE, iter);
-	}
-	return NULL;
-}
-/**
- * mono_class_get_methods:
- * \param klass the \c MonoClass to act on
- *
- * This routine is an iterator routine for retrieving the methods in a class.
- *
- * You must pass a \c gpointer that points to zero and is treated as an opaque handle to
- * iterate over all of the elements.  When no more values are
- * available, the return value is NULL.
- *
- * \returns a \c MonoMethod on each iteration or NULL when no more methods are available.
- */
-MonoMethod*
-mono_class_get_methods (MonoClass* klass, gpointer *iter)
-{
-	if (!iter)
-		return NULL;
-	MonoImage *image = m_class_get_image (klass);
-	if (!*iter) {
-		mono_class_setup_methods (klass);
-		MonoMethod **klass_methods = m_class_get_methods (klass);
-		/*
-		 * We can't fail lookup of methods otherwise the runtime will burst in flames on all sort of places.
-		 * FIXME we should better report this error to the caller
-		 */
-		if (!klass_methods && !image->has_updates)
-			return NULL;
-		uint32_t idx = 0;
-		/* start from the first */
-		if (mono_class_get_method_count (klass)) {
-			*iter = GUINT_TO_POINTER (idx + 1);
-			return klass_methods [0];
-		} else {
-			/* no method */
-			if (G_LIKELY (!image->has_updates))
-				return NULL;
-			else
-				*iter = 0;
-		}
-	}
-	uint32_t idx = GPOINTER_TO_UINT (*iter);
-	if (idx < mono_class_get_method_count (klass)) {
-		MonoMethod *method = m_class_get_methods (klass) [idx];
-		idx++;
-		*iter = GUINT_TO_POINTER (idx);
-		return method;
-	}
-	if (G_UNLIKELY (image->has_updates))
-		return mono_metadata_update_added_methods_iter (klass, iter);
-	return NULL;
-}
-/**
- * mono_class_get_properties:
- * \param klass the \c MonoClass to act on
- *
- * This routine is an iterator routine for retrieving the properties in a class.
- *
- * You must pass a gpointer that points to zero and is treated as an opaque handle to
- * iterate over all of the elements.  When no more values are
- * available, the return value is NULL.
- *
- * Returns: a \c MonoProperty* on each invocation, or NULL when no more are available.
- */
-MonoProperty*
-mono_class_get_properties (MonoClass* klass, gpointer *iter)
-{
-	if (!iter)
-		return NULL;
-	if (!*iter) {
-		mono_class_setup_properties (klass);
-		MonoClassPropertyInfo *info = mono_class_get_property_info (klass);
-		/* start from the first */
-		if (info->count) {
-			uint32_t idx = 0;
-			*iter = GUINT_TO_POINTER (idx + 1);
-			return (MonoProperty *)&info->properties [0];
-		} else {
-			/* no fields */
-			if (G_LIKELY (!m_class_get_image (klass)->has_updates))
-				return NULL;
-			else
-				*iter = 0;
-		}
-	}
-	uint32_t idx = GPOINTER_TO_UINT (*iter);
-	MonoClassPropertyInfo *info = mono_class_get_property_info (klass);
-	if (idx < info->count) {
-		MonoProperty *property = &info->properties [idx];
-		++idx;
-		*iter = GUINT_TO_POINTER (idx);
-		return property;
-	}
-	if (G_UNLIKELY (m_class_get_image (klass)->has_updates)) {
-		return mono_metadata_update_added_properties_iter (klass, iter);
-	}
-	return NULL;
-}
-/**
- * mono_class_get_events:
- * \param klass the \c MonoClass to act on
- *
- * This routine is an iterator routine for retrieving the properties in a class.
- *
- * You must pass a \c gpointer that points to zero and is treated as an opaque handle to
- * iterate over all of the elements.  When no more values are
- * available, the return value is NULL.
- *
- * \returns a \c MonoEvent* on each invocation, or NULL when no more are available.
- */
-MonoEvent*
-mono_class_get_events (MonoClass* klass, gpointer *iter)
-{
-	if (!iter)
-		return NULL;
-	if (!*iter) {
-		mono_class_setup_events (klass);
-		MonoClassEventInfo *info = mono_class_get_event_info (klass);
-		/* start from the first */
-		if (info->count) {
-			uint32_t idx = 0;
-			*iter = GUINT_TO_POINTER (idx + 1);
-			return (MonoEvent *)&info->events [0];
-		} else {
-			/* no fields */
-			if (G_LIKELY (!m_class_get_image (klass)->has_updates))
-				return NULL;
-			else
-				*iter = 0;
-		}
-	}
-	uint32_t idx = GPOINTER_TO_UINT (*iter);
-	MonoClassEventInfo *info = mono_class_get_event_info (klass);
-	if (idx < info->count) {
-		MonoEvent *event = &info->events[idx];
-		++idx;
-		*iter = GUINT_TO_POINTER (idx);
-		return event;
-	}
-	if (G_UNLIKELY (m_class_get_image (klass)->has_updates)) {
-		return mono_metadata_update_added_events_iter (klass, iter);
-	}
-	return NULL;
-}
-/**
- * mono_class_get_interfaces
- * \param klass the \c MonoClass to act on
- *
- * This routine is an iterator routine for retrieving the interfaces implemented by this class.
- *
- * You must pass a \c gpointer that points to zero and is treated as an opaque handle to
- * iterate over all of the elements.  When no more values are
- * available, the return value is NULL.
- *
- * \returns a \c MonoClass* on each invocation, or NULL when no more are available.
- */
-MonoClass*
-mono_class_get_interfaces (MonoClass* klass, gpointer *iter)
-{
-	ERROR_DECL (error);
-	MonoClass** iface;
-	if (!iter)
-		return NULL;
-	if (!*iter) {
-		if (!m_class_is_inited (klass))
-			mono_class_init_internal (klass);
-		if (!m_class_is_interfaces_inited (klass)) {
-			mono_class_setup_interfaces (klass, error);
-			if (!is_ok (error)) {
-				mono_error_cleanup (error);
-				return NULL;
-			}
-		}
-		/* start from the first */
-		if (m_class_get_interface_count (klass)) {
-			*iter = &m_class_get_interfaces (klass) [0];
-			return m_class_get_interfaces (klass) [0];
-		} else {
-			/* no interface */
-			return NULL;
-		}
-	}
-	iface = (MonoClass **)*iter;
-	iface++;
-	if (iface < &m_class_get_interfaces (klass) [m_class_get_interface_count (klass)]) {
-		*iter = iface;
-		return *iface;
-	}
-	return NULL;
-}
-/**
- * mono_class_get_nested_types
- * \param klass the \c MonoClass to act on
- *
- * This routine is an iterator routine for retrieving the nested types of a class.
- * This works only if \p klass is non-generic, or a generic type definition.
- *
- * You must pass a \c gpointer that points to zero and is treated as an opaque handle to
- * iterate over all of the elements.  When no more values are
- * available, the return value is NULL.
- *
- * \returns a \c Monoclass* on each invocation, or NULL when no more are available.
- */
-MonoClass*
-mono_class_get_nested_types (MonoClass* klass, gpointer *iter)
-{
-	GList *item;
-	if (!iter)
-		return NULL;
-	if (!m_class_is_nested_classes_inited (klass))
-		mono_class_setup_nested_types (klass);
-	if (!*iter) {
-		GList *nested_classes = mono_class_get_nested_classes_property (klass);
-		/* start from the first */
-		if (nested_classes) {
-			*iter = nested_classes;
-			return (MonoClass *)nested_classes->data;
-		} else {
-			/* no nested types */
-			return NULL;
-		}
-	}
-	item = (GList *)*iter;
-	item = item->next;
-	if (item) {
-		*iter = item;
-		return (MonoClass *)item->data;
-	}
-	return NULL;
-}
-/**
- * mono_class_is_delegate
- * \param klass the \c MonoClass to act on
- *
- * \returns TRUE if the \c MonoClass represents a \c System.Delegate.
- */
-mono_bool
-mono_class_is_delegate (MonoClass *klass)
-{
-	mono_bool result;
-	MONO_ENTER_GC_UNSAFE;
-	result = m_class_is_delegate (klass);
-	MONO_EXIT_GC_UNSAFE;
-	return result;
-}
-/**
- * mono_class_implements_interface
- * \param klass The MonoClass to act on
- * \param interface The interface to check if \p klass implements.
- *
- * \returns TRUE if \p klass implements \p interface.
- */
-mono_bool
-mono_class_implements_interface (MonoClass* klass, MonoClass* iface)
-{
-	mono_bool result;
-	MONO_ENTER_GC_UNSAFE;
-	result = mono_class_is_assignable_from_internal (iface, klass);
-	MONO_EXIT_GC_UNSAFE;
-	return result;
-}
-static mono_bool
-class_implements_interface_ignore_generics (MonoClass* klass, MonoClass* iface)
-{
-	int i;
-	ERROR_DECL (error);
-	if (mono_class_is_ginst (iface))
-		iface = mono_class_get_generic_type_definition (iface);
-	while (klass != NULL) {
-		if (mono_class_is_assignable_from_internal (iface, klass))
-			return TRUE;
-		mono_class_setup_interfaces (klass, error);
-		if (!is_ok (error)) {
-			mono_error_cleanup  (error);
-			return FALSE;
-		}
-		MonoClass **klass_interfaces = m_class_get_interfaces (klass);
-		for (i = 0; i < m_class_get_interface_count (klass); i++) {
-			MonoClass *ic = klass_interfaces [i];
-			if (mono_class_is_ginst (ic))
-				ic = mono_class_get_generic_type_definition (ic);
-			if (ic == iface) {
-				return TRUE;
-			}
-		}
-		klass = m_class_get_parent (klass);
-	}
-	return FALSE;
-}
-/**
- * mono_field_get_name:
- * \param field the \c MonoClassField to act on
- *
- * \returns The name of the field.
- */
-const char*
-mono_field_get_name (MonoClassField *field)
-{
-	return field->name;
-}
-/**
- * mono_field_get_type_internal:
- * \param field the \c MonoClassField to act on
- * \returns \c MonoType of the field.
- */
-MonoType*
-mono_field_get_type_internal (MonoClassField *field)
-{
-	MonoType *type = field->type;
-	if (type)
-		return type;
-	ERROR_DECL (error);
-	type = mono_field_get_type_checked (field, error);
-	if (!is_ok (error)) {
-		mono_trace_warning (MONO_TRACE_TYPE, "Could not load field's type due to %s", mono_error_get_message (error));
-		mono_error_cleanup (error);
-	}
-	return type;
-}
-/**
- * mono_field_get_type:
- * \param field the \c MonoClassField to act on
- * \returns \c MonoType of the field.
- */
-MonoType*
-mono_field_get_type (MonoClassField *field)
-{
-	MonoType *type = field->type;
-	if (type)
-		return type;
-	MONO_ENTER_GC_UNSAFE;
-	type = mono_field_get_type_internal (field);
-	MONO_EXIT_GC_UNSAFE;
-	return type;
-}
-/**
- * mono_field_get_type_checked:
- * \param field the \c MonoClassField to act on
- * \param error used to return any error found while retrieving \p field type
- *
- * \returns \c MonoType of the field.
- */
-MonoType*
-mono_field_get_type_checked (MonoClassField *field, MonoError *error)
-{
-	error_init (error);
-	MonoType *type = field->type;
-	if (type)
-		return type;
-	mono_field_resolve_type (field, error);
-	return field->type;
-}
-/**
- * mono_field_get_parent:
- * \param field the \c MonoClassField to act on
- *
- * \returns \c MonoClass where the field was defined.
- */
-MonoClass*
-mono_field_get_parent (MonoClassField *field)
-{
-	return m_field_get_parent (field);
-}
-/**
- * mono_field_get_flags;
- * \param field the \c MonoClassField to act on
- *
- * The metadata flags for a field are encoded using the
- * \c FIELD_ATTRIBUTE_* constants.  See the \c tabledefs.h file for details.
- *
- * \returns The flags for the field.
- */
-guint32
-mono_field_get_flags (MonoClassField *field)
-{
-	if (!field->type)
-		return mono_field_resolve_flags (field);
-	return field->type->attrs;
-}
-/**
- * mono_field_get_offset:
- * \param field the \c MonoClassField to act on
- *
- * \returns The field offset.
- */
-guint32
-mono_field_get_offset (MonoClassField *field)
-{
-	mono_class_setup_fields(m_field_get_parent (field));
-	return field->offset;
-}
-const char *
-mono_field_get_rva (MonoClassField *field, int swizzle)
-{
-	guint32 rva;
-	int field_index;
-	MonoClass *klass = m_field_get_parent (field);
-	MonoFieldDefaultValue *def_values;
-	g_assert (field->type->attrs & FIELD_ATTRIBUTE_HAS_FIELD_RVA);
-	/* metadata-update: added static fields with initializers don't seem to get here */
-	g_assert (!m_field_is_from_update (field));
-	def_values = mono_class_get_field_def_values_with_swizzle (klass, swizzle);
-	if (!def_values) {
-		def_values = (MonoFieldDefaultValue *)mono_class_alloc0 (klass, sizeof (MonoFieldDefaultValue) * mono_class_get_field_count (klass));
-		mono_class_set_field_def_values_with_swizzle (klass, def_values, swizzle);
-	}
-	field_index = mono_field_get_index (field);
-	if (!def_values [field_index].data) {
-		const char *rvaData;
-		if (!image_is_dynamic (m_class_get_image (klass))) {
-			int first_field_idx = mono_class_get_first_field_idx (klass);
-			mono_metadata_field_info (m_class_get_image (m_field_get_parent (field)), first_field_idx + field_index, NULL, &rva, NULL);
-			if (!rva)
-				g_warning ("field %s in %s should have RVA data, but hasn't", mono_field_get_name (field), m_class_get_name (m_field_get_parent (field)));
-			rvaData = mono_image_rva_map (m_class_get_image (m_field_get_parent (field)), rva);
-		} else {
-			rvaData = mono_field_get_data (field);
-		}
-		if (rvaData == NULL)
-			return NULL;
-		if (swizzle != 1) {
-			int dummy;
-			int dataSizeInBytes =  mono_type_size (field->type, &dummy);
-			char *swizzledRvaData = mono_class_alloc0 (klass, dataSizeInBytes);
-#define SWAP(n) {								\
-	guint ## n *data = (guint ## n *) swizzledRvaData; \
-	guint ## n *src = (guint ## n *) rvaData; 				\
-	int i,									\
-	    nEnt = (dataSizeInBytes / sizeof(guint ## n));					\
-										\
-	for (i = 0; i < nEnt; i++) {						\
-		data[i] = read ## n (&src[i]);					\
-	} 									\
-}
-			if (swizzle == 2) {
-				SWAP (16);
-			} else if (swizzle == 4) {
-				SWAP (32);
-			} else {
-				SWAP (64);
-			}
-#undef SWAP
-			def_values [field_index].data = swizzledRvaData;
-		} else {
-			def_values [field_index].data = rvaData;
-		}
-	}
-	return def_values [field_index].data;
-}
-/**
- * mono_field_get_data:
- * \param field the \c MonoClassField to act on
- *
- * \returns A pointer to the metadata constant value or to the field
- * data if it has an RVA flag.
- */
-const char *
-mono_field_get_data (MonoClassField *field)
-{
-	if (field->type->attrs & FIELD_ATTRIBUTE_HAS_DEFAULT) {
-		MonoTypeEnum def_type;
-		return mono_class_get_field_default_value (field, &def_type);
-	} else if (field->type->attrs & FIELD_ATTRIBUTE_HAS_FIELD_RVA) {
-		return mono_field_get_rva (field, 1);
-	} else {
-		return NULL;
-	}
-}
-/**
- * mono_property_get_name:
- * \param prop the \c MonoProperty to act on
- * \returns The name of the property
- */
-const char*
-mono_property_get_name (MonoProperty *prop)
-{
-	return prop->name;
-}
-/**
- * mono_property_get_set_method
- * \param prop the \c MonoProperty to act on.
- * \returns The setter method of the property, a \c MonoMethod.
- */
-MonoMethod*
-mono_property_get_set_method (MonoProperty *prop)
-{
-	return prop->set;
-}
-/**
- * mono_property_get_get_method
- * \param prop the MonoProperty to act on.
- * \returns The getter method of the property (A \c MonoMethod)
- */
-MonoMethod*
-mono_property_get_get_method (MonoProperty *prop)
-{
-	return prop->get;
-}
-/**
- * mono_property_get_parent:
- * \param prop the \c MonoProperty to act on.
- * \returns The \c MonoClass where the property was defined.
- */
-MonoClass*
-mono_property_get_parent (MonoProperty *prop)
-{
-	return prop->parent;
-}
-/**
- * mono_property_get_flags:
- * \param prop the \c MonoProperty to act on.
- *
- * The metadata flags for a property are encoded using the
- * \c PROPERTY_ATTRIBUTE_* constants.  See the \c tabledefs.h file for details.
- *
- * \returns The flags for the property.
- */
-guint32
-mono_property_get_flags (MonoProperty *prop)
-{
-	return prop->attrs & ~MONO_PROPERTY_META_FLAG_MASK;
-}
-/**
- * mono_event_get_name:
- * \param event the MonoEvent to act on
- * \returns The name of the event.
- */
-const char*
-mono_event_get_name (MonoEvent *event)
-{
-	return event->name;
-}
-/**
- * mono_event_get_add_method:
- * \param event The \c MonoEvent to act on.
- * \returns The \c add method for the event, a \c MonoMethod.
- */
-MonoMethod*
-mono_event_get_add_method (MonoEvent *event)
-{
-	return event->add;
-}
-/**
- * mono_event_get_remove_method:
- * \param event The \c MonoEvent to act on.
- * \returns The \c remove method for the event, a \c MonoMethod.
- */
-MonoMethod*
-mono_event_get_remove_method (MonoEvent *event)
-{
-	return event->remove;
-}
-/**
- * mono_event_get_raise_method:
- * \param event The \c MonoEvent to act on.
- * \returns The \c raise method for the event, a \c MonoMethod.
- */
-MonoMethod*
-mono_event_get_raise_method (MonoEvent *event)
-{
-	return event->raise;
-}
-/**
- * mono_event_get_parent:
- * \param event the MonoEvent to act on.
- * \returns The \c MonoClass where the event is defined.
- */
-MonoClass*
-mono_event_get_parent (MonoEvent *event)
-{
-	return event->parent;
-}
-/**
- * mono_event_get_flags
- * \param event the \c MonoEvent to act on.
- *
- * The metadata flags for an event are encoded using the
- * \c EVENT_* constants.  See the \c tabledefs.h file for details.
- *
- * \returns The flags for the event.
- */
-guint32
-mono_event_get_flags (MonoEvent *event)
-{
-	return event->attrs & ~MONO_EVENT_META_FLAG_MASK;
-}
-/**
- * mono_class_get_method_from_name:
- * \param klass where to look for the method
- * \param name name of the method
- * \param param_count number of parameters. -1 for any number.
- *
- * Obtains a \c MonoMethod with a given name and number of parameters.
- * It only works if there are no multiple signatures for any given method name.
- */
-MonoMethod *
-mono_class_get_method_from_name (MonoClass *klass, const char *name, int param_count)
-{
-	MonoMethod *result;
-	MONO_ENTER_GC_UNSAFE;
-	ERROR_DECL (error);
-	result = mono_class_get_method_from_name_checked (klass, name, param_count, 0, error);
-	mono_error_cleanup (error);
-	MONO_EXIT_GC_UNSAFE;
-	return result;
-}
-MonoMethod*
-mono_find_method_in_metadata (MonoClass *klass, const char *name, int param_count, int flags)
-{
-	MonoImage *klass_image = m_class_get_image (klass);
-	MonoMethod *res = NULL;
-	int i;
-	/* Search directly in the metadata to avoid calling setup_methods () */
-	int first_idx = mono_class_get_first_method_idx (klass);
-	int mcount = mono_class_get_method_count (klass);
-	for (i = 0; i < mcount; ++i) {
-		ERROR_DECL (error);
-		guint32 cols [MONO_METHOD_SIZE];
-		MonoMethod *method;
-		MonoMethodSignature *sig;
-		/* first_idx points into the methodptr table */
-		mono_metadata_decode_table_row (klass_image, MONO_TABLE_METHOD, first_idx + i, cols, MONO_METHOD_SIZE);
-		if (!strcmp (mono_metadata_string_heap (klass_image, cols [MONO_METHOD_NAME]), name)) {
-			method = mono_get_method_checked (klass_image, MONO_TOKEN_METHOD_DEF | (first_idx + i + 1), klass, NULL, error);
-			if (!method) {
-				mono_error_cleanup (error); /* FIXME don't swallow the error */
-				continue;
-			}
-			if (param_count == -1) {
-				res = method;
-				break;
-			}
-			sig = mono_method_signature_checked (method, error);
-			if (!sig) {
-				mono_error_cleanup (error); /* FIXME don't swallow the error */
-				continue;
-			}
-			if (sig->param_count == param_count) {
-				res = method;
-				break;
-			}
-		}
-	}
-	if (G_UNLIKELY (!res && klass_image->has_updates)) {
-		if (mono_class_has_metadata_update_info (klass)) {
-			ERROR_DECL (error);
-			res = mono_metadata_update_find_method_by_name (klass, name, param_count, flags, error);
-			mono_error_cleanup (error);
-		}
-	}
-	return res;
-}
-/**
- * mono_class_get_method_from_name_flags:
- * \param klass where to look for the method
- * \param name_space name of the method
- * \param param_count number of parameters. -1 for any number.
- * \param flags flags which must be set in the method
- *
- * Obtains a \c MonoMethod with a given name and number of parameters.
- * It only works if there are no multiple signatures for any given method name.
- */
-MonoMethod *
-mono_class_get_method_from_name_flags (MonoClass *klass, const char *name, int param_count, int flags)
-{
-	MonoMethod *method;
-	MONO_ENTER_GC_UNSAFE;
-	ERROR_DECL (error);
-	method = mono_class_get_method_from_name_checked (klass, name, param_count, flags, error);
-	mono_error_cleanup (error);
-	MONO_EXIT_GC_UNSAFE;
-	return method;
-}
-/**
- * mono_class_get_method_from_name_checked:
- * \param klass where to look for the method
- * \param name_space name of the method
- * \param param_count number of parameters. -1 for any number.
- * \param flags flags which must be set in the method
- * \param error
- *
- * Obtains a \c MonoMethod with a given name and number of parameters.
- * It only works if there are no multiple signatures for any given method name.
- */
-MonoMethod *
-mono_class_get_method_from_name_checked (MonoClass *klass, const char *name,
-	int param_count, int flags, MonoError *error)
-{
-	MonoMethod *res = NULL;
-	int i;
-	mono_class_init_internal (klass);
-	if (mono_class_is_ginst (klass) && (!m_class_get_methods (klass) || m_class_get_image (klass)->has_updates)) {
-		res = mono_class_get_method_from_name_checked (mono_class_get_generic_class (klass)->container_class, name, param_count, flags, error);
-		if (res)
-			res = mono_class_inflate_generic_method_full_checked (res, klass, mono_class_get_context (klass), error);
-		return res;
-	}
-	if (m_class_get_methods (klass) || !MONO_CLASS_HAS_STATIC_METADATA (klass)) {
-		mono_class_setup_methods (klass);
-		/*
-		We can't fail lookup of methods otherwise the runtime will burst in flames on all sort of places.
-		See mono/tests/array_load_exception.il
-		FIXME we should better report this error to the caller
-		 */
-		MonoMethod **klass_methods = m_class_get_methods (klass);
-		gboolean has_updates = m_class_get_image (klass)->has_updates;
-		if (!klass_methods && !has_updates)
-			return NULL;
-		int mcount = mono_class_get_method_count (klass);
-		for (i = 0; i < mcount; ++i) {
-			MonoMethod *method = klass_methods [i];
-			if (method->name[0] == name [0] &&
-				!strcmp (name, method->name) &&
-				(param_count == -1 || mono_method_signature_internal (method)->param_count == param_count) &&
-				((method->flags & flags) == flags)) {
-				res = method;
-				break;
-			}
-		}
-		if (G_UNLIKELY (!res && has_updates && mono_class_has_metadata_update_info (klass))) {
-			res = mono_metadata_update_find_method_by_name (klass, name, param_count, flags, error);
-		}
-	}
-	else {
-	    res = mono_find_method_in_metadata (klass, name, param_count, flags);
-	}
-	return res;
-}
-gboolean
-mono_class_has_failure (const MonoClass *klass)
-{
-	g_assert (klass != NULL);
-	return m_class_has_failure ((MonoClass*)klass) != 0;
-}
-gboolean
-mono_class_has_deferred_failure (const MonoClass *klass)
-{
-	g_assert (klass != NULL);
-	return m_class_has_deferred_failure ((MonoClass*)klass) != 0;
-}
-/**
- * mono_class_get_exception_for_failure:
- * \param klass class in which the failure was detected
- *
- * \returns a constructed MonoException than the caller can then throw
- * using mono_raise_exception - or NULL if no failure is present (or
- * doesn't result in an exception).
- */
-MonoException*
-mono_class_get_exception_for_failure (MonoClass *klass)
-{
-	if (!mono_class_has_failure (klass))
-		return NULL;
-	ERROR_DECL (unboxed_error);
-	mono_error_set_for_class_failure (unboxed_error, klass);
-	return mono_error_convert_to_exception (unboxed_error);
-}
-static gboolean
-is_nesting_type (MonoClass *outer_klass, MonoClass *inner_klass)
- {
-	outer_klass = mono_class_get_generic_type_definition (outer_klass);
-	inner_klass = mono_class_get_generic_type_definition (inner_klass);
-	do {
-		if (outer_klass == inner_klass)
-			return TRUE;
-		inner_klass = m_class_get_nested_in (inner_klass);
-	} while (inner_klass);
-	return FALSE;
-}
-MonoClass *
-mono_class_get_generic_type_definition (MonoClass *klass)
-{
-	MonoGenericClass *gklass =  mono_class_try_get_generic_class (klass);
-	return gklass ? gklass->container_class : klass;
-}
-/*
- * Check if @klass is a subtype of @parent ignoring generic instantiations.
- *
- * Generic instantiations are ignored for all super types of @klass.
- *
- * Visibility checks ignoring generic instantiations.
- *
- * Class implementing interface visibility checks ignore generic instantiations
- */
-gboolean
-mono_class_has_parent_and_ignore_generics (MonoClass *klass, MonoClass *parent)
-{
-	int i;
-	klass = mono_class_get_generic_type_definition (klass);
-	parent = mono_class_get_generic_type_definition (parent);
-	mono_class_setup_supertypes (klass);
-	for (i = 0; i < m_class_get_idepth (klass); ++i) {
-		if (parent == mono_class_get_generic_type_definition (m_class_get_supertypes (klass) [i]))
-			return TRUE;
-	}
-	if (MONO_CLASS_IS_INTERFACE_INTERNAL (parent) && class_implements_interface_ignore_generics (klass, parent))
-		return TRUE;
-	return FALSE;
-}
-/*
- * Subtype can only access parent members with family protection if the site object
- * is subclass of Subtype. For example:
- * class A { protected int x; }
- * class B : A {
- * 	void valid_access () {
- * 		B b;
- * 		b.x = 0;
- *  }
- *  void invalid_access () {
- *		A a;
- * 		a.x = 0;
- *  }
- * }
- * */
-static gboolean
-is_valid_family_access (MonoClass *access_klass, MonoClass *member_klass, MonoClass *context_klass)
-{
-	if (MONO_CLASS_IS_INTERFACE_INTERNAL (member_klass) && !MONO_CLASS_IS_INTERFACE_INTERNAL (access_klass)) {
-		/* Can happen with default interface methods */
-		if (!class_implements_interface_ignore_generics (access_klass, member_klass))
-			return FALSE;
-	} else if (member_klass != access_klass && MONO_CLASS_IS_INTERFACE_INTERNAL (member_klass) && MONO_CLASS_IS_INTERFACE_INTERNAL (access_klass)) {
-		/* Can happen with default interface methods */
-		if (!mono_interface_implements_interface (access_klass, member_klass))
-			return FALSE;
-	} else {
-		if (!mono_class_has_parent_and_ignore_generics (access_klass, member_klass))
-			return FALSE;
-	}
-	if (context_klass == NULL)
-		return TRUE;
-	/*if access_klass is not member_klass context_klass must be type compat*/
-	if (access_klass != member_klass && !mono_class_has_parent_and_ignore_generics (context_klass, access_klass))
-		return FALSE;
-	return TRUE;
-}
-static gboolean
-ignores_access_checks_to (MonoAssembly *accessing, MonoAssembly *accessed)
-{
-	if (!accessing || !accessed)
-		return FALSE;
-	mono_assembly_load_friends (accessing);
-	for (GSList *tmp = accessing->ignores_checks_assembly_names; tmp; tmp = tmp->next) {
-		MonoAssemblyName *victim = (MonoAssemblyName *)tmp->data;
-		if (!victim->name)
-			continue;
-		if (!g_ascii_strcasecmp (accessed->aname.name, victim->name))
-			return TRUE;
-	}
-	return FALSE;
-}
-static gboolean
-can_access_internals (MonoAssembly *accessing, MonoAssembly* accessed)
-{
-	GSList *tmp;
-	if (accessing == accessed)
-		return TRUE;
-	if (!accessed || !accessing)
-		return FALSE;
-	mono_assembly_load_friends (accessed);
-	for (tmp = accessed->friend_assembly_names; tmp; tmp = tmp->next) {
-		MonoAssemblyName *friend_ = (MonoAssemblyName *)tmp->data;
-		/* Be conservative with checks */
-		if (!friend_->name)
-			continue;
-		if (g_ascii_strcasecmp (accessing->aname.name, friend_->name))
-			continue;
-		if (friend_->public_key_token [0]) {
-			if (!accessing->aname.public_key_token [0])
-				continue;
-			if (!mono_public_tokens_are_equal (friend_->public_key_token, accessing->aname.public_key_token))
-				continue;
-		}
-		return TRUE;
-	}
-	return ignores_access_checks_to (accessing, accessed);
-}
-/*
- * If klass is a generic type or if it is derived from a generic type, return the
- * MonoClass of the generic definition
- * Returns NULL if not found
- */
-static MonoClass*
-get_generic_definition_class (MonoClass *klass)
-{
-	while (klass) {
-		MonoGenericClass *gklass = mono_class_try_get_generic_class (klass);
-		if (gklass && gklass->container_class)
-			return gklass->container_class;
-		klass = m_class_get_parent (klass);
-	}
-	return NULL;
-}
-static gboolean
-can_access_instantiation (MonoClass *access_klass, MonoGenericInst *ginst)
-{
-	for (guint i = 0; i < ginst->type_argc; ++i) {
-		MonoType *type = ginst->type_argv[i];
-		switch (type->type) {
-		case MONO_TYPE_SZARRAY:
-			if (!can_access_type (access_klass, type->data.klass))
-				return FALSE;
-			break;
-		case MONO_TYPE_ARRAY:
-			if (!can_access_type (access_klass, type->data.array->eklass))
-				return FALSE;
-			break;
-		case MONO_TYPE_PTR:
-			if (!can_access_type (access_klass, mono_class_from_mono_type_internal (type->data.type)))
-				return FALSE;
-			break;
-		case MONO_TYPE_CLASS:
-		case MONO_TYPE_VALUETYPE:
-		case MONO_TYPE_GENERICINST:
-			if (!can_access_type (access_klass, mono_class_from_mono_type_internal (type)))
-				return FALSE;
-		default:
-			break;
-		}
-	}
-	return TRUE;
-}
-static gboolean
-can_access_type (MonoClass *access_klass, MonoClass *member_klass)
-{
-	int access_level;
-	if (access_klass == member_klass)
-		return TRUE;
-	MonoAssembly *access_klass_assembly = m_class_get_image (access_klass)->assembly;
-	MonoAssembly *member_klass_assembly = m_class_get_image (member_klass)->assembly;
-	if (m_class_get_element_class (access_klass) && !m_class_is_enumtype (access_klass)) {
-		access_klass = m_class_get_element_class (access_klass);
-		access_klass_assembly = m_class_get_image (access_klass)->assembly;
-	}
-	if (m_class_get_element_class (member_klass) && !m_class_is_enumtype (member_klass)) {
-		member_klass = m_class_get_element_class (member_klass);
-		member_klass_assembly = m_class_get_image (member_klass)->assembly;
-	}
-	access_level = mono_class_get_flags (member_klass) & TYPE_ATTRIBUTE_VISIBILITY_MASK;
-	if (mono_type_is_generic_argument (m_class_get_byval_arg (member_klass)))
-		return TRUE;
-	if (mono_class_is_ginst (member_klass) && !can_access_instantiation (access_klass, mono_class_get_generic_class (member_klass)->context.class_inst))
-		return FALSE;
-	if (is_nesting_type (access_klass, member_klass) || (m_class_get_nested_in (access_klass) && is_nesting_type (m_class_get_nested_in (access_klass), member_klass)))
-		return TRUE;
-	/*Non nested type with nested visibility. We just fail it.*/
-	if (access_level >= TYPE_ATTRIBUTE_NESTED_PRIVATE && access_level <= TYPE_ATTRIBUTE_NESTED_FAM_OR_ASSEM && m_class_get_nested_in (member_klass) == NULL)
-		return FALSE;
-	MonoClass *member_klass_nested_in = m_class_get_nested_in (member_klass);
-	switch (access_level) {
-	case TYPE_ATTRIBUTE_NOT_PUBLIC:
-		return can_access_internals (access_klass_assembly, member_klass_assembly);
-	case TYPE_ATTRIBUTE_PUBLIC:
-		return TRUE;
-	case TYPE_ATTRIBUTE_NESTED_PUBLIC:
-		return member_klass_nested_in && can_access_type (access_klass, member_klass_nested_in);
-	case TYPE_ATTRIBUTE_NESTED_PRIVATE:
-		if (is_nesting_type (member_klass, access_klass) && member_klass_nested_in && can_access_type (access_klass, member_klass_nested_in))
-			return TRUE;
-		return ignores_access_checks_to (access_klass_assembly, member_klass_assembly);
-	case TYPE_ATTRIBUTE_NESTED_FAMILY:
-		return mono_class_has_parent_and_ignore_generics (access_klass, m_class_get_nested_in (member_klass));
-	case TYPE_ATTRIBUTE_NESTED_ASSEMBLY:
-		return can_access_internals (access_klass_assembly, member_klass_assembly) && member_klass_nested_in && can_access_type (access_klass, member_klass_nested_in);
-	case TYPE_ATTRIBUTE_NESTED_FAM_AND_ASSEM:
-		return can_access_internals (access_klass_assembly, m_class_get_image (member_klass_nested_in)->assembly) &&
-			mono_class_has_parent_and_ignore_generics (access_klass, member_klass_nested_in);
-	case TYPE_ATTRIBUTE_NESTED_FAM_OR_ASSEM:
-		return can_access_internals (access_klass_assembly, m_class_get_image (member_klass_nested_in)->assembly) ||
-			mono_class_has_parent_and_ignore_generics (access_klass, member_klass_nested_in);
-	}
-	return FALSE;
-}
-/* FIXME: check visibility of type, too */
-static gboolean
-can_access_member (MonoClass *access_klass, MonoClass *member_klass, MonoClass* context_klass, int access_level)
-{
-	MonoClass *member_generic_def;
-	MonoAssembly *access_klass_assembly = m_class_get_image (access_klass)->assembly;
-	MonoGenericClass *access_gklass = mono_class_try_get_generic_class (access_klass);
-	if (((access_gklass && access_gklass->container_class) ||
-					mono_class_is_gtd (access_klass)) &&
-			(member_generic_def = get_generic_definition_class (member_klass))) {
-		MonoClass *access_container;
-		if (mono_class_is_gtd (access_klass))
-			access_container = access_klass;
-		else
-			access_container = access_gklass->container_class;
-		if (can_access_member (access_container, member_generic_def, context_klass, access_level))
-			return TRUE;
-	}
-	MonoImage *member_klass_image = m_class_get_image (member_klass);
-	/* Partition I 8.5.3.2 */
-	/* the access level values are the same for fields and methods */
-	switch (access_level) {
-	case FIELD_ATTRIBUTE_COMPILER_CONTROLLED:
-		/* same compilation unit */
-		return m_class_get_image (access_klass) == member_klass_image;
-	case FIELD_ATTRIBUTE_PRIVATE:
-		return (access_klass == member_klass) || ignores_access_checks_to (access_klass_assembly, member_klass_image->assembly);
-	case FIELD_ATTRIBUTE_FAM_AND_ASSEM:
-		if (is_valid_family_access (access_klass, member_klass, context_klass) &&
-		    can_access_internals (access_klass_assembly, member_klass_image->assembly))
-			return TRUE;
-		return FALSE;
-	case FIELD_ATTRIBUTE_ASSEMBLY:
-		return can_access_internals (access_klass_assembly, member_klass_image->assembly);
-	case FIELD_ATTRIBUTE_FAMILY:
-		if (is_valid_family_access (access_klass, member_klass, context_klass))
-			return TRUE;
-		return FALSE;
-	case FIELD_ATTRIBUTE_FAM_OR_ASSEM:
-		if (is_valid_family_access (access_klass, member_klass, context_klass))
-			return TRUE;
-		return can_access_internals (access_klass_assembly, member_klass_image->assembly);
-	case FIELD_ATTRIBUTE_PUBLIC:
-		return TRUE;
-	}
-	return FALSE;
-}
-/**
- * mono_method_can_access_field:
- * \param method Method that will attempt to access the field
- * \param field the field to access
- *
- * Used to determine if a method is allowed to access the specified field.
- *
- * \returns TRUE if the given \p method is allowed to access the \p field while following
- * the accessibility rules of the CLI.
- */
-gboolean
-mono_method_can_access_field (MonoMethod *method, MonoClassField *field)
-{
-	/* FIXME: check all overlapping fields */
-	int can = can_access_member (method->klass, m_field_get_parent (field), NULL, mono_field_get_type_internal (field)->attrs & FIELD_ATTRIBUTE_FIELD_ACCESS_MASK);
-	if (!can) {
-		MonoClass *nested = m_class_get_nested_in (method->klass);
-		while (nested) {
-			can = can_access_member (nested, m_field_get_parent (field), NULL, mono_field_get_type_internal (field)->attrs & FIELD_ATTRIBUTE_FIELD_ACCESS_MASK);
-			if (can)
-				return TRUE;
-			nested = m_class_get_nested_in (nested);
-		}
-	}
-	return can;
-}
-static MonoMethod*
-mono_method_get_method_definition (MonoMethod *method)
-{
-	while (method->is_inflated)
-		method = ((MonoMethodInflated*)method)->declaring;
-	return method;
-}
-/**
- * mono_method_can_access_method:
- * \param method Method that will attempt to access the other method
- * \param called the method that we want to probe for accessibility.
- *
- * Used to determine if the \p method is allowed to access the specified \p called method.
- *
- * \returns TRUE if the given \p method is allowed to invoke the \p called while following
- * the accessibility rules of the CLI.
- */
-gboolean
-mono_method_can_access_method (MonoMethod *method, MonoMethod *called)
-{
-	method = mono_method_get_method_definition (method);
-	called = mono_method_get_method_definition (called);
-	return mono_method_can_access_method_full (method, called, NULL);
-}
-/*
- * mono_method_can_access_method_full:
- * @method: The caller method
- * @called: The called method
- * @context_klass: The static type on stack of the owner @called object used
- *
- * This function must be used with instance calls, as they have more strict family accessibility.
- * It can be used with static methods, but context_klass should be NULL.
- *
- * Returns: TRUE if caller have proper visibility and acessibility to @called
- */
-gboolean
-mono_method_can_access_method_full (MonoMethod *method, MonoMethod *called, MonoClass *context_klass)
-{
-	/* Wrappers are except from access checks */
-	if (method->wrapper_type != MONO_WRAPPER_NONE || called->wrapper_type != MONO_WRAPPER_NONE)
-		return TRUE;
-	MonoClass *access_class = method->klass;
-	MonoClass *member_class = called->klass;
-	int can = can_access_member (access_class, member_class, context_klass, called->flags & METHOD_ATTRIBUTE_MEMBER_ACCESS_MASK);
-	if (!can) {
-		MonoClass *nested = m_class_get_nested_in (access_class);
-		while (nested) {
-			can = can_access_member (nested, member_class, context_klass, called->flags & METHOD_ATTRIBUTE_MEMBER_ACCESS_MASK);
-			if (can)
-				break;
-			nested = m_class_get_nested_in (nested);
-		}
-	}
-	if (!can)
-		return FALSE;
-	can = can_access_type (access_class, member_class);
-	if (!can) {
-		MonoClass *nested = m_class_get_nested_in (access_class);
-		while (nested) {
-			can = can_access_type (nested, member_class);
-			if (can)
-				break;
-			nested = m_class_get_nested_in (nested);
-		}
-	}
-	if (!can)
-		return FALSE;
-	if (called->is_inflated) {
-		MonoMethodInflated * infl = (MonoMethodInflated*)called;
-		if (infl->context.method_inst && !can_access_instantiation (access_class, infl->context.method_inst))
-			return FALSE;
-	}
-	return TRUE;
-}
-/*
- * mono_method_can_access_field_full:
- * @method: The caller method
- * @field: The accessed field
- * @context_klass: The static type on stack of the owner @field object used
- *
- * This function must be used with instance fields, as they have more strict family accessibility.
- * It can be used with static fields, but context_klass should be NULL.
- *
- * Returns: TRUE if caller have proper visibility and acessibility to @field
- */
-gboolean
-mono_method_can_access_field_full (MonoMethod *method, MonoClassField *field, MonoClass *context_klass)
-{
-	MonoClass *access_class = method->klass;
-	MonoClass *member_class = m_field_get_parent (field);
-	/* FIXME: check all overlapping fields */
-	int can = can_access_member (access_class, member_class, context_klass, field->type->attrs & FIELD_ATTRIBUTE_FIELD_ACCESS_MASK);
-	if (!can) {
-		MonoClass *nested = m_class_get_nested_in (access_class);
-		while (nested) {
-			can = can_access_member (nested, member_class, context_klass, field->type->attrs & FIELD_ATTRIBUTE_FIELD_ACCESS_MASK);
-			if (can)
-				break;
-			nested = m_class_get_nested_in (nested);
-		}
-	}
-	if (!can)
-		return FALSE;
-	can = can_access_type (access_class, member_class);
-	if (!can) {
-		MonoClass *nested = m_class_get_nested_in (access_class);
-		while (nested) {
-			can = can_access_type (nested, member_class);
-			if (can)
-				break;
-			nested = m_class_get_nested_in (nested);
-		}
-	}
-	if (!can)
-		return FALSE;
-	return TRUE;
-}
-/*
- * mono_class_can_access_class:
- * @source_class: The source class
- * @target_class: The accessed class
- *
- * This function returns is @target_class is visible to @source_class
- *
- * Returns: TRUE if source have proper visibility and acessibility to target
- */
-gboolean
-mono_class_can_access_class (MonoClass *source_class, MonoClass *target_class)
-{
-	return can_access_type (source_class, target_class);
-}
-/**
- * mono_type_is_valid_enum_basetype:
- * \param type The MonoType to check
- * \returns TRUE if the type can be used as the basetype of an enum
- */
-gboolean mono_type_is_valid_enum_basetype (MonoType * type) {
-	switch (type->type) {
-	case MONO_TYPE_I1:
-	case MONO_TYPE_U1:
-	case MONO_TYPE_BOOLEAN:
-	case MONO_TYPE_I2:
-	case MONO_TYPE_U2:
-	case MONO_TYPE_CHAR:
-	case MONO_TYPE_I4:
-	case MONO_TYPE_U4:
-	case MONO_TYPE_I8:
-	case MONO_TYPE_U8:
-	case MONO_TYPE_I:
-	case MONO_TYPE_U:
-	case MONO_TYPE_R8:
-	case MONO_TYPE_R4:
-		return TRUE;
-	default:
-		return FALSE;
-	}
-}
-/**
- * mono_class_is_valid_enum:
- * \param klass An enum class to be validated
- *
- * This method verify the required properties an enum should have.
- *
- * FIXME: TypeBuilder enums are allowed to implement interfaces, but since they cannot have methods, only empty interfaces are possible
- * FIXME: enum types are not allowed to have a cctor, but mono_reflection_create_runtime_class sets has_cctor to 1 for all types
- * FIXME: TypeBuilder enums can have any kind of static fields, but the spec is very explicit about that (P II 14.3)
- *
- * \returns TRUE if the informed enum class is valid
- */
-gboolean
-mono_class_is_valid_enum (MonoClass *klass)
-{
-	MonoClassField * field;
-	gpointer iter = NULL;
-	gboolean found_base_field = FALSE;
-	g_assert (m_class_is_enumtype (klass));
-	MonoClass *klass_parent = m_class_get_parent (klass);
-	/* we cannot test against mono_defaults.enum_class, or mcs won't be able to compile the System namespace*/
-	if (!klass_parent || strcmp (m_class_get_name (klass_parent), "Enum") || strcmp (m_class_get_name_space (klass_parent), "System") ) {
-		return FALSE;
-	}
-	if (!mono_class_is_auto_layout (klass))
-		return FALSE;
-	while ((field = mono_class_get_fields_internal (klass, &iter))) {
-		if (!(field->type->attrs & FIELD_ATTRIBUTE_STATIC)) {
-			if (found_base_field)
-				return FALSE;
-			found_base_field = TRUE;
-			if (!mono_type_is_valid_enum_basetype (field->type))
-				return FALSE;
-		}
-	}
-	if (!found_base_field)
-		return FALSE;
-	if (mono_class_get_method_count (klass) > 0)
-		return FALSE;
-	return TRUE;
-}
-gboolean
-mono_generic_class_is_generic_type_definition (MonoGenericClass *gklass)
-{
-	return gklass->context.class_inst == mono_class_get_generic_container (gklass->container_class)->context.class_inst;
-}
-void
-mono_field_resolve_type (MonoClassField *field, MonoError *error)
-{
-	MonoClass *klass = m_field_get_parent (field);
-	MonoImage *image = m_class_get_image (klass);
-	MonoClass *gtd = mono_class_is_ginst (klass) ? mono_class_get_generic_type_definition (klass) : NULL;
-	MonoType *ftype;
-	int field_idx;
-	if (G_UNLIKELY (m_field_is_from_update (field))) {
-		field_idx = -1;
-	} else {
-		field_idx = GPTRDIFF_TO_INT (field - m_class_get_fields (klass));
-	}
-	error_init (error);
-	if (gtd) {
-		g_assert (field_idx != -1);
-		MonoClassField *gfield = &m_class_get_fields (gtd) [field_idx];
-		MonoType *gtype = mono_field_get_type_checked (gfield, error);
-		if (!is_ok (error)) {
-			char *full_name = mono_type_get_full_name (gtd);
-			mono_class_set_type_load_failure (klass, "Could not load generic type of field '%s:%s' (%d) due to: %s", full_name, gfield->name, field_idx, mono_error_get_message (error));
-			g_free (full_name);
-		}
-		ftype = mono_class_inflate_generic_type_no_copy (image, gtype, mono_class_get_context (klass), error);
-		if (!is_ok (error)) {
-			char *full_name = mono_type_get_full_name (klass);
-			mono_class_set_type_load_failure (klass, "Could not load instantiated type of field '%s:%s' (%d) due to: %s", full_name, field->name, field_idx, mono_error_get_message (error));
-			g_free (full_name);
-		}
-	} else {
-		const char *sig;
-		guint32 cols [MONO_FIELD_SIZE];
-		MonoGenericContainer *container = NULL;
-		int idx;
-		if (G_UNLIKELY (m_field_is_from_update (field))) {
-			idx = mono_metadata_update_get_field_idx (field) - 1;
-		} else {
-			idx = mono_class_get_first_field_idx (klass) + field_idx;
-		}
-		/*FIXME, in theory we do not lazy load SRE fields*/
-		g_assert (!image_is_dynamic (image));
-		if (mono_class_is_gtd (klass)) {
-			container = mono_class_get_generic_container (klass);
-		} else if (gtd) {
-			container = mono_class_get_generic_container (gtd);
-			g_assert (container);
-		}
-		/* first_field_idx and idx points into the fieldptr table */
-		mono_metadata_decode_table_row (image, MONO_TABLE_FIELD, idx, cols, MONO_FIELD_SIZE);
-		sig = mono_metadata_blob_heap (image, cols [MONO_FIELD_SIGNATURE]);
-		mono_metadata_decode_value (sig, &sig);
-		/* FIELD signature == 0x06 */
-		g_assert (*sig == 0x06);
-		ftype = mono_metadata_parse_type_checked (image, container, cols [MONO_FIELD_FLAGS], FALSE, sig + 1, &sig, error);
-		if (!ftype) {
-			char *full_name = mono_type_get_full_name (klass);
-			mono_class_set_type_load_failure (klass, "Could not load type of field '%s:%s' (%d) due to: %s", full_name, field->name, field_idx, mono_error_get_message (error));
-			g_free (full_name);
-		}
-	}
-	mono_memory_barrier ();
-	field->type = ftype;
-}
-static guint32
-mono_field_resolve_flags (MonoClassField *field)
-{
-	if (G_UNLIKELY (m_field_is_from_update (field))) {
-		/* metadata-update: Just resolve the whole field, for simplicity. */
-		ERROR_DECL (error);
-		mono_field_resolve_type (field, error);
-		mono_error_assert_ok (error);
-		g_assert (field->type);
-		return field->type->attrs;
-	}
-	MonoClass *klass = m_field_get_parent (field);
-	MonoImage *image = m_class_get_image (klass);
-	MonoClass *gtd = mono_class_is_ginst (klass) ? mono_class_get_generic_type_definition (klass) : NULL;
-	int field_idx = GPTRDIFF_TO_INT (field - m_class_get_fields (klass));
-	if (gtd) {
-		MonoClassField *gfield = &m_class_get_fields (gtd) [field_idx];
-		return mono_field_get_flags (gfield);
-	} else {
-		int idx = mono_class_get_first_field_idx (klass) + field_idx;
-		/*FIXME, in theory we do not lazy load SRE fields*/
-		g_assert (!image_is_dynamic (image));
-		return mono_metadata_decode_table_row_col (image, MONO_TABLE_FIELD, idx, MONO_FIELD_FLAGS);
-	}
-}
-/**
- * mono_class_get_fields_lazy:
- * \param klass the MonoClass to act on
- *
- * This routine is an iterator routine for retrieving the fields in a class.
- * Only minimal information about fields are loaded. Accessors must be used
- * for all MonoClassField returned.
- *
- * You must pass a gpointer that points to zero and is treated as an opaque handle to
- * iterate over all of the elements.  When no more values are
- * available, the return value is NULL.
- *
- * \returns a \c MonoClassField* on each iteration, or NULL when no more fields are available.
- */
-MonoClassField*
-mono_class_get_fields_lazy (MonoClass* klass, gpointer *iter)
-{
-	if (!iter)
-		return NULL;
-	MonoImage *image = m_class_get_image (klass);
-	if (!*iter) {
-		mono_class_setup_basic_field_info (klass);
-		MonoClassField *klass_fields = m_class_get_fields (klass);
-		if (!klass_fields)
-			return NULL;
-		/* start from the first */
-		if (mono_class_get_field_count (klass)) {
-			uint32_t idx = 0;
-			*iter = GUINT_TO_POINTER (idx+1);
-			return &klass_fields [0];
-		} else {
-			/* no fields */
-			if (G_LIKELY(!image->has_updates))
-				return NULL;
-			else
-				*iter = 0;
-		}
-	}
-	uint32_t idx = GPOINTER_TO_UINT(*iter);
-	if (idx < mono_class_get_field_count (klass)) {
-		MonoClassField *field = &m_class_get_fields (klass) [idx];
-		++idx;
-		*iter = GUINT_TO_POINTER (idx);
-		return field;
-	}
-	if (G_UNLIKELY (image->has_updates)) {
-		mono_trace (G_LOG_LEVEL_DEBUG, MONO_TRACE_METADATA_UPDATE, "Lazy iterating added fields %s", m_class_get_name(klass));
-		return mono_metadata_update_added_fields_iter (klass, TRUE, iter);
-	}
-	return NULL;
-}
-char*
-mono_class_full_name (MonoClass *klass)
-{
-	return mono_type_full_name (m_class_get_byval_arg (klass));
-}
-/* Declare all shared lazy type lookup functions */
-GENERATE_TRY_GET_CLASS_WITH_CACHE (safehandle, "System.Runtime.InteropServices", "SafeHandle")
-/**
- * mono_method_get_base_method:
- * \param method a method
- * \param definition if true, get the definition
- * \param error set on failure
- *
- * Given a virtual method associated with a subclass, return the corresponding
- * method from an ancestor.  If \p definition is FALSE, returns the method in the
- * superclass of the given method.  If \p definition is TRUE, return the method
- * in the ancestor class where it was first declared.  The type arguments will
- * be inflated in the ancestor classes.  If the method is not associated with a
- * class, or isn't virtual, returns the method itself.  On failure returns NULL
- * and sets \p error.
- */
-MonoMethod*
-mono_method_get_base_method (MonoMethod *method, gboolean definition, MonoError *error)
-{
-	MonoClass *klass, *parent;
-	MonoGenericContext *generic_inst = NULL;
-	MonoMethod *result = NULL;
-	int slot;
-	if (method->klass == NULL)
-		return method;
-	if (!(method->flags & METHOD_ATTRIBUTE_VIRTUAL) ||
-	    MONO_CLASS_IS_INTERFACE_INTERNAL (method->klass) ||
-	    method->flags & METHOD_ATTRIBUTE_NEW_SLOT)
-		return method;
-	slot = mono_method_get_vtable_slot (method);
-	if (slot == -1)
-		return method;
-	klass = method->klass;
-	if (mono_class_is_gtd (klass)) {
-		/* If we get a GTD like Foo`2 replace look instead at its instantiation with its own generic params: Foo`2<!0, !1>. */
-		/* In particular we want generic_inst to be initialized to <!0,
-		 * !1> so that we can inflate parent classes correctly as we go
-		 * up the class hierarchy. */
-		MonoType *ty = mono_class_gtd_get_canonical_inst (klass);
-		g_assert (ty->type == MONO_TYPE_GENERICINST);
-		MonoGenericClass *gklass = ty->data.generic_class;
-		generic_inst = mono_generic_class_get_context (gklass);
-		klass = gklass->container_class;
-	} else if (mono_class_is_ginst (klass)) {
-		generic_inst = mono_class_get_context (klass);
-		klass = mono_class_get_generic_class (klass)->container_class;
-	}
-retry:
-	if (definition) {
-		/* At the end of the loop, klass points to the eldest class that has this virtual function slot. */
-		for (parent = m_class_get_parent (klass); parent != NULL; parent = m_class_get_parent (parent)) {
-			/* on entry, klass is either a plain old non-generic class and generic_inst == NULL
-			   or klass is the generic container class and generic_inst is the instantiation.
-			   when we go to the parent, if the parent is an open constructed type, we need to
-			   replace the type parameters by the definitions from the generic_inst, and then take it
-			   apart again into the klass and the generic_inst.
-			   For cases like this:
-			   class C<T> : B<T, int> {
-			       public override void Foo () { ... }
-			   }
-			   class B<U,V> : A<HashMap<U,V>> {
-			       public override void Foo () { ... }
-			   }
-			   class A<X> {
-			       public virtual void Foo () { ... }
-			   }
-			   if at each iteration the parent isn't open, we can skip inflating it.  if at some
-			   iteration the parent isn't generic (after possible inflation), we set generic_inst to
-			   NULL;
-			*/
-			MonoGenericContext *parent_inst = NULL;
-			if (mono_class_is_open_constructed_type (m_class_get_byval_arg (parent))) {
-				parent = mono_class_inflate_generic_class_checked (parent, generic_inst, error);
-				return_val_if_nok  (error, NULL);
-				g_assert (parent);
-			}
-			if (mono_class_is_ginst (parent)) {
-				parent_inst = mono_class_get_context (parent);
-				parent = mono_class_get_generic_class (parent)->container_class;
-				g_assert (parent);
-			}
-			mono_class_setup_vtable (parent);
-			if (m_class_get_vtable_size (parent) <= slot)
-				break;
-			klass = parent;
-			generic_inst = parent_inst;
-		}
-	} else {
-		/* When we get here, possibly after a retry, if generic_inst is
-		 * set, then the class is must be a gtd */
-		g_assert (generic_inst == NULL || mono_class_is_gtd (klass));
-		klass = m_class_get_parent (klass);
-		if (!klass)
-			return method;
-		if (mono_class_is_open_constructed_type (m_class_get_byval_arg (klass))) {
-			klass = mono_class_inflate_generic_class_checked (klass, generic_inst, error);
-			return_val_if_nok (error, NULL);
-			g_assert (klass);
-			generic_inst = NULL;
-		}
-		if (mono_class_is_ginst (klass)) {
-			generic_inst = mono_class_get_context (klass);
-			klass = mono_class_get_generic_class (klass)->container_class;
-		}
-	}
-	if (generic_inst) {
-		klass = mono_class_inflate_generic_class_checked (klass, generic_inst, error);
-		return_val_if_nok (error, NULL);
-		g_assert (klass);
-		generic_inst = NULL;
-	}
-	if (klass == method->klass)
-		return method;
-	/*This is possible if definition == FALSE.
-	 * Do it here to be really sure we don't read invalid memory.
-	 */
-	if (slot >= m_class_get_vtable_size (klass))
-		return method;
-	mono_class_setup_vtable (klass);
-	result = m_class_get_vtable (klass) [slot];
-	if (result == NULL) {
-		/* It is an abstract method */
-		gboolean found = FALSE;
-		gpointer iter = NULL;
-		while ((result = mono_class_get_methods (klass, &iter))) {
-			if (result->slot == slot) {
-				found = TRUE;
-				break;
-			}
-		}
-		/* found might be FALSE if we looked in an abstract class
-		 * that doesn't override an abstract method of its
-		 * parent:
-		 *   abstract class Base {
-		 *     public abstract void Foo ();
-		 *   }
-		 *   abstract class Derived : Base { }
-		 *   class Child : Derived {
-		 *     public override void Foo () { }
-		 *  }
-		 *
-		 *  if m was Child.Foo and we ask for the base method,
-		 *  then we get here with klass == Derived and found == FALSE
-		 */
-		/* but it shouldn't be the case that if we're looking
-		 * for the definition and didn't find a result; the
-		 * loop above should've taken us as far as we could
-		 * go! */
-		g_assert (!(definition && !found));
-		if (!found)
-			goto retry;
-	}
-	g_assert (result != NULL);
-	return result;
-}
-gboolean
-mono_method_is_constructor (MonoMethod *method)
-{
-	return ((method->flags & CTOR_REQUIRED_FLAGS) == CTOR_REQUIRED_FLAGS &&
-			!(method->flags & CTOR_INVALID_FLAGS) &&
-			!strcmp (".ctor", method->name));
-}
-gboolean
-mono_class_has_default_constructor (MonoClass *klass, gboolean public_only)
-{
-	MonoMethod *method;
-	int i;
-	mono_class_setup_methods (klass);
-	if (mono_class_has_failure (klass))
-		return FALSE;
-	int mcount = mono_class_get_method_count (klass);
-	MonoMethod **klass_methods = m_class_get_methods (klass);
-	for (i = 0; i < mcount; ++i) {
-		method = klass_methods [i];
-		if (mono_method_is_constructor (method) &&
-			mono_method_signature_internal (method) &&
-			mono_method_signature_internal (method)->param_count == 0 &&
-			(!public_only || (method->flags & METHOD_ATTRIBUTE_MEMBER_ACCESS_MASK) == METHOD_ATTRIBUTE_PUBLIC))
-			return TRUE;
-	}
-	return FALSE;
-}
-/**
- * mono_class_set_deferred_type_load_failure:
- * \param klass class in which the failure was detected
- * \param fmt \c printf -style error message string.
- *
- * Sets a deferred failure in the class and prints a warning message.
- * The deferred failure allows the runtime to attempt setting up the class layout at runtime.
- *
- * LOCKING: Acquires the loader lock.
- *
- * \returns FALSE
- */
-gboolean
-mono_class_set_deferred_type_load_failure (MonoClass *klass, const char * fmt, ...)
-{
-	if (!mono_class_has_deferred_failure (klass)) {
-		va_list args;
-		va_start (args, fmt);
-		g_warning ("Warning: %s", fmt, args);
-		va_end (args);
-		mono_class_set_deferred_failure (klass);
-	}
-	return FALSE;
-}
-/**
- * mono_class_set_type_load_failure:
- * \param klass class in which the failure was detected
- * \param fmt \c printf -style error message string.
- *
- * Collect detected failure informaion in the class for later processing.
- * The error is stored as a MonoErrorBoxed as with mono_error_set_type_load_class()
- * Note that only the first failure is kept.
- *
- * LOCKING: Acquires the loader lock.
- *
- * \returns TRUE
- */
-gboolean
-mono_class_set_type_load_failure (MonoClass *klass, const char * fmt, ...)
-{
-	if (!mono_class_has_failure (klass)) {
-		ERROR_DECL (prepare_error);
-		va_list args;
-		va_start (args, fmt);
-		mono_error_vset_type_load_class (prepare_error, klass, fmt, args);
-		va_end (args);
-		MonoErrorBoxed *box = mono_error_box (prepare_error, m_class_get_image (klass));
-		mono_error_cleanup (prepare_error);
-		mono_class_set_failure (klass, box);
-	}
-	return TRUE;
-}
-void mono_set_failure_type (MonoFailureType failure_type) {
-	switch (failure_type) {
-		case MONO_CLASS_LOADER_IMMEDIATE_FAILURE:
-			mono_get_runtime_callbacks ()->mono_class_set_deferred_type_load_failure_callback = mono_class_set_type_load_failure;
-			break;
-		case MONO_CLASS_LOADER_DEFERRED_FAILURE:
-			mono_get_runtime_callbacks ()->mono_class_set_deferred_type_load_failure_callback = mono_class_set_deferred_type_load_failure;
-			break;
-		default:
-			g_assert_not_reached();
-			break;
-	}
-}

--- a/src/mono/mono/metadata/marshal-lightweight.c
+++ b//dev/null
@@ -1,2906 +0,0 @@
-/**
- * \file
- * Copyright 2018 Microsoft
- * Licensed under the MIT license. See LICENSE file in the project root for full license information.
- */
-#include "config.h"
-#ifdef HAVE_ALLOCA_H
-#include <alloca.h>
-#endif
-#include "mono/metadata/method-builder-ilgen.h"
-#include "mono/metadata/method-builder-ilgen-internals.h"
-#include <mono/metadata/object.h>
-#include <mono/metadata/loader.h>
-#include "cil-coff.h"
-#include "metadata/marshal.h"
-#include "metadata/marshal-internals.h"
-#include "metadata/marshal-lightweight.h"
-#include "metadata/marshal-shared.h"
-#include "metadata/tabledefs.h"
-#include <mono/metadata/exception.h>
-#include <mono/metadata/appdomain.h>
-#include "mono/metadata/abi-details.h"
-#include "mono/metadata/class-abi-details.h"
-#include "mono/metadata/class-init.h"
-#include "mono/metadata/components.h"
-#include "mono/metadata/debug-helpers.h"
-#include "mono/metadata/threads.h"
-#include "mono/metadata/monitor.h"
-#include "mono/metadata/class-internals.h"
-#include "mono/metadata/metadata-internals.h"
-#include "mono/metadata/domain-internals.h"
-#include "mono/metadata/gc-internals.h"
-#include "mono/metadata/threads-types.h"
-#include "mono/metadata/string-icalls.h"
-#include "mono/metadata/attrdefs.h"
-#include "mono/metadata/reflection-internals.h"
-#include "mono/metadata/handle.h"
-#include "mono/metadata/custom-attrs-internals.h"
-#include "mono/metadata/icall-internals.h"
-#include "mono/metadata/unsafe-accessor.h"
-#include "mono/utils/mono-tls.h"
-#include "mono/utils/mono-memory-model.h"
-#include "mono/utils/atomic.h"
-#include <mono/utils/mono-threads.h>
-#include <mono/utils/mono-threads-coop.h>
-#include <mono/utils/mono-error-internals.h>
-#include <mono/utils/options.h>
-#include <string.h>
-#include <errno.h>
-#include "icall-decl.h"
-#define OPDEF(a,b,c,d,e,f,g,h,i,j) \
-	a = i,
-enum {
-#include "mono/cil/opcode.def"
-	LAST = 0xff
-};
-#undef OPDEF
-static GENERATE_GET_CLASS_WITH_CACHE (date_time, "System", "DateTime");
-static GENERATE_TRY_GET_CLASS_WITH_CACHE (icustom_marshaler, "System.Runtime.InteropServices", "ICustomMarshaler");
-static MonoImage*
-get_method_image (MonoMethod *method)
-{
-	return m_class_get_image (method->klass);
-}
-/**
- * mono_mb_strdup:
- * \param mb the MethodBuilder
- * \param s a string
- *
- * Creates a copy of the string \p s that can be referenced from the IL of \c mb.
- *
- * \returns a pointer to the new string which is owned by the method builder
- */
-char*
-mono_mb_strdup (MonoMethodBuilder *mb, const char *s)
-{
-	char *res;
-	if (!mb->dynamic)
-		res = mono_image_strdup (get_method_image (mb->method), s);
-	else
-		res = g_strdup (s);
-	return res;
-}
-G_GNUC_UNUSED
-static MonoMethod*
-mono_get_Marshal_GetObjectForNativeVariant (void)
-{
-	MONO_STATIC_POINTER_INIT (MonoMethod, get_object_for_native_variant)
-		get_object_for_native_variant = mono_marshal_shared_get_method_nofail (mono_defaults.marshal_class, "GetObjectForNativeVariant", 1, 0);
-	MONO_STATIC_POINTER_INIT_END (MonoMethod, get_object_for_native_variant)
-	g_assert (get_object_for_native_variant);
-	return get_object_for_native_variant;
-}
-G_GNUC_UNUSED
-static MonoMethod*
-mono_get_Marshal_GetNativeVariantForObject (void)
-{
-	MONO_STATIC_POINTER_INIT (MonoMethod, get_native_variant_for_object)
-		get_native_variant_for_object = mono_marshal_shared_get_method_nofail (mono_defaults.marshal_class, "GetNativeVariantForObject", 2, 0);
-	MONO_STATIC_POINTER_INIT_END (MonoMethod, get_native_variant_for_object)
-	g_assert (get_native_variant_for_object);
-	return get_native_variant_for_object;
-}
-static void
-emit_struct_free (MonoMethodBuilder *mb, MonoClass *klass, int struct_var)
-{
-	/* Call DestroyStructure */
-	/* FIXME: Only do this if needed */
-	mono_mb_emit_byte (mb, MONO_CUSTOM_PREFIX);
-	mono_mb_emit_op (mb, CEE_MONO_CLASSCONST, klass);
-	mono_mb_emit_ldloc (mb, struct_var);
-	mono_mb_emit_icall (mb, mono_struct_delete_old);
-}
-static void
-emit_thread_interrupt_checkpoint (MonoMethodBuilder *mb)
-{
-	if (strstr (mb->name, "mono_thread_interruption_checkpoint"))
-		return;
-	mono_marshal_shared_emit_thread_interrupt_checkpoint_call (mb, MONO_JIT_ICALL_mono_thread_interruption_checkpoint);
-}
-static void
-emit_thread_force_interrupt_checkpoint (MonoMethodBuilder *mb)
-{
-	mono_marshal_shared_emit_thread_interrupt_checkpoint_call (mb, MONO_JIT_ICALL_mono_thread_force_interruption_checkpoint_noraise);
-}
-void
-mono_marshal_emit_thread_interrupt_checkpoint (MonoMethodBuilder *mb)
-{
-	emit_thread_interrupt_checkpoint (mb);
-}
-void
-mono_marshal_emit_thread_force_interrupt_checkpoint (MonoMethodBuilder *mb)
-{
-	emit_thread_force_interrupt_checkpoint (mb);
-}
-int
-mono_mb_emit_save_args (MonoMethodBuilder *mb, MonoMethodSignature *sig, gboolean save_this)
-{
-	int i, params_var, tmp_var;
-	MonoType *int_type = mono_get_int_type ();
-	/* allocate local (pointer) *params[] */
-	params_var = mono_mb_add_local (mb, int_type);
-	/* allocate local (pointer) tmp */
-	tmp_var = mono_mb_add_local (mb, int_type);
-	/* alloate space on stack to store an array of pointers to the arguments */
-	mono_mb_emit_icon (mb, TARGET_SIZEOF_VOID_P * (sig->param_count + 1));
-	mono_mb_emit_byte (mb, CEE_PREFIX1);
-	mono_mb_emit_byte (mb, CEE_LOCALLOC);
-	mono_mb_emit_stloc (mb, params_var);
-	/* tmp = params */
-	mono_mb_emit_ldloc (mb, params_var);
-	mono_mb_emit_stloc (mb, tmp_var);
-	if (save_this && sig->hasthis) {
-		mono_mb_emit_ldloc (mb, tmp_var);
-		mono_mb_emit_ldarg_addr (mb, 0);
-		mono_mb_emit_byte (mb, CEE_STIND_I);
-		/* tmp = tmp + sizeof (gpointer) */
-		if (sig->param_count)
-			mono_mb_emit_add_to_local (mb, GINT_TO_UINT16 (tmp_var), TARGET_SIZEOF_VOID_P);
-	}
-	for (i = 0; i < sig->param_count; i++) {
-		mono_mb_emit_ldloc (mb, tmp_var);
-		mono_mb_emit_ldarg_addr (mb, i + sig->hasthis);
-		mono_mb_emit_byte (mb, CEE_STIND_I);
-		/* tmp = tmp + sizeof (gpointer) */
-		if (i < (sig->param_count - 1))
-			mono_mb_emit_add_to_local (mb, GINT_TO_UINT16 (tmp_var), TARGET_SIZEOF_VOID_P);
-	}
-	return params_var;
-}
-void
-mono_mb_emit_restore_result (MonoMethodBuilder *mb, MonoType *return_type)
-{
-	MonoType *t = mono_type_get_underlying_type (return_type);
-	MonoType *int_type = mono_get_int_type ();
-	if (m_type_is_byref (return_type))
-		return_type = int_type;
-	switch (t->type) {
-	case MONO_TYPE_VOID:
-		g_assert_not_reached ();
-		break;
-	case MONO_TYPE_PTR:
-	case MONO_TYPE_FNPTR:
-	case MONO_TYPE_STRING:
-	case MONO_TYPE_CLASS:
-	case MONO_TYPE_OBJECT:
-	case MONO_TYPE_ARRAY:
-	case MONO_TYPE_SZARRAY:
-		/* nothing to do */
-		break;
-	case MONO_TYPE_U1:
-	case MONO_TYPE_BOOLEAN:
-	case MONO_TYPE_I1:
-	case MONO_TYPE_U2:
-	case MONO_TYPE_CHAR:
-	case MONO_TYPE_I2:
-	case MONO_TYPE_I:
-	case MONO_TYPE_U:
-	case MONO_TYPE_I4:
-	case MONO_TYPE_U4:
-	case MONO_TYPE_U8:
-	case MONO_TYPE_I8:
-	case MONO_TYPE_R4:
-	case MONO_TYPE_R8:
-		mono_mb_emit_op (mb, CEE_UNBOX, mono_class_from_mono_type_internal (return_type));
-		mono_mb_emit_byte (mb, mono_type_to_ldind (return_type));
-		break;
-	case MONO_TYPE_GENERICINST:
-		if (!mono_type_generic_inst_is_valuetype (t))
-			break;
-		/* fall through */
-	case MONO_TYPE_VALUETYPE: {
-		MonoClass *klass = mono_class_from_mono_type_internal (return_type);
-		mono_mb_emit_op (mb, CEE_UNBOX, klass);
-		mono_mb_emit_op (mb, CEE_LDOBJ, klass);
-		break;
-	}
-	case MONO_TYPE_VAR:
-	case MONO_TYPE_MVAR: {
-		MonoClass *klass = mono_class_from_mono_type_internal (return_type);
-		mono_mb_emit_op (mb, CEE_UNBOX_ANY, klass);
-		break;
-	}
-	default:
-		g_warning ("type 0x%x not handled", return_type->type);
-		g_assert_not_reached ();
-	}
-	mono_mb_emit_byte (mb, CEE_RET);
-}
-/*
- * emit_invoke_call:
- *
- *   Emit the call to the wrapper method from a runtime invoke wrapper.
- */
-static void
-emit_invoke_call (MonoMethodBuilder *mb, MonoMethod *method,
-				  MonoMethodSignature *sig, MonoMethodSignature *callsig,
-				  int loc_res,
-				  gboolean virtual_, gboolean need_direct_wrapper)
-{
-	int i;
-	gboolean void_ret = FALSE;
-	gboolean string_ctor = method && method->string_ctor;
-	if (virtual_) {
-		g_assert (sig->hasthis);
-		g_assert (method->flags & METHOD_ATTRIBUTE_VIRTUAL);
-	}
-	if (sig->hasthis) {
-		if (string_ctor) {
-			/* This will call the code emitted by mono_marshal_get_native_wrapper () which ignores it */
-			mono_mb_emit_icon (mb, 0);
-			mono_mb_emit_byte (mb, CEE_CONV_I);
-		} else {
-			mono_mb_emit_ldarg (mb, 0);
-		}
-	}
-	for (i = 0; i < sig->param_count; i++) {
-		MonoType *t = sig->params [i];
-		int type;
-		mono_mb_emit_ldarg (mb, 1);
-		if (i) {
-			mono_mb_emit_icon (mb, TARGET_SIZEOF_VOID_P * i);
-			mono_mb_emit_byte (mb, CEE_ADD);
-		}
-		if (m_type_is_byref (t)) {
-			mono_mb_emit_byte (mb, CEE_LDIND_I);
-			continue;
-		}
-		type = sig->params [i]->type;
-handle_enum:
-		switch (type) {
-		case MONO_TYPE_I1:
-		case MONO_TYPE_BOOLEAN:
-		case MONO_TYPE_U1:
-		case MONO_TYPE_I2:
-		case MONO_TYPE_U2:
-		case MONO_TYPE_CHAR:
-		case MONO_TYPE_I:
-		case MONO_TYPE_U:
-		case MONO_TYPE_I4:
-		case MONO_TYPE_U4:
-		case MONO_TYPE_R4:
-		case MONO_TYPE_R8:
-		case MONO_TYPE_I8:
-		case MONO_TYPE_U8:
-			mono_mb_emit_no_nullcheck (mb);
-			mono_mb_emit_byte (mb, CEE_LDIND_I);
-			mono_mb_emit_no_nullcheck (mb);
-			mono_mb_emit_byte (mb, mono_type_to_ldind (sig->params [i]));
-			break;
-		case MONO_TYPE_STRING:
-		case MONO_TYPE_CLASS:
-		case MONO_TYPE_ARRAY:
-		case MONO_TYPE_PTR:
-		case MONO_TYPE_FNPTR:
-		case MONO_TYPE_SZARRAY:
-		case MONO_TYPE_OBJECT:
-			mono_mb_emit_no_nullcheck (mb);
-			mono_mb_emit_byte (mb, mono_type_to_ldind (sig->params [i]));
-			break;
-		case MONO_TYPE_GENERICINST:
-			if (!mono_type_generic_inst_is_valuetype (sig->params [i])) {
-				mono_mb_emit_no_nullcheck (mb);
-				mono_mb_emit_byte (mb, mono_type_to_ldind (sig->params [i]));
-				break;
-			}
-			t = m_class_get_byval_arg (t->data.generic_class->container_class);
-			type = t->type;
-			goto handle_enum;
-		case MONO_TYPE_VALUETYPE:
-			if (type == MONO_TYPE_VALUETYPE && m_class_is_enumtype (t->data.klass)) {
-				type = mono_class_enum_basetype_internal (t->data.klass)->type;
-				goto handle_enum;
-			}
-			mono_mb_emit_no_nullcheck (mb);
-			mono_mb_emit_byte (mb, CEE_LDIND_I);
-			mono_mb_emit_op (mb, CEE_LDOBJ, mono_class_from_mono_type_internal (sig->params [i]));
-			break;
-		default:
-			g_assert_not_reached ();
-		}
-	}
-	if (virtual_) {
-		mono_mb_emit_op (mb, CEE_CALLVIRT, method);
-	} else if (need_direct_wrapper) {
-		mono_mb_emit_op (mb, CEE_CALL, method);
-	} else {
-		mono_mb_emit_ldarg (mb, 3);
-		mono_mb_emit_calli (mb, callsig);
-	}
-	if (m_type_is_byref (sig->ret)) {
-		/* perform indirect load and return by value */
-		guint8 ldind_op;
-		MonoType* ret_byval = m_class_get_byval_arg (mono_class_from_mono_type_internal (sig->ret));
-		g_assert (!m_type_is_byref (ret_byval));
-		ldind_op = mono_type_to_ldind (ret_byval);
-		/* taken from similar code in mini-generic-sharing.c
-		 * we need to use mono_mb_emit_op to add method data when loading
-		 * a structure since method-to-ir needs this data for wrapper methods */
-		if (ldind_op == CEE_LDOBJ)
-			mono_mb_emit_op (mb, CEE_LDOBJ, mono_class_from_mono_type_internal (ret_byval));
-		else
-			mono_mb_emit_byte (mb, ldind_op);
-	}
-	switch (sig->ret->type) {
-	case MONO_TYPE_VOID:
-		if (!string_ctor)
-			void_ret = TRUE;
-		break;
-	case MONO_TYPE_BOOLEAN:
-	case MONO_TYPE_CHAR:
-	case MONO_TYPE_I1:
-	case MONO_TYPE_U1:
-	case MONO_TYPE_I2:
-	case MONO_TYPE_U2:
-	case MONO_TYPE_I4:
-	case MONO_TYPE_U4:
-	case MONO_TYPE_I:
-	case MONO_TYPE_U:
-	case MONO_TYPE_R4:
-	case MONO_TYPE_R8:
-	case MONO_TYPE_I8:
-	case MONO_TYPE_U8:
-	case MONO_TYPE_VALUETYPE:
-	case MONO_TYPE_TYPEDBYREF:
-	case MONO_TYPE_GENERICINST:
-		/* box value types */
-		mono_mb_emit_op (mb, CEE_BOX, mono_class_from_mono_type_internal (sig->ret));
-		break;
-	case MONO_TYPE_STRING:
-	case MONO_TYPE_CLASS:
-	case MONO_TYPE_ARRAY:
-	case MONO_TYPE_SZARRAY:
-	case MONO_TYPE_OBJECT:
-		/* nothing to do */
-		break;
-	case MONO_TYPE_PTR:
-	case MONO_TYPE_FNPTR:
-		/* The result is an IntPtr */
-		mono_mb_emit_op (mb, CEE_BOX, mono_defaults.int_class);
-		break;
-	default:
-		g_assert_not_reached ();
-	}
-	if (!void_ret)
-		mono_mb_emit_stloc (mb, loc_res);
-}
-static void
-emit_runtime_invoke_body_ilgen (MonoMethodBuilder *mb, const char **param_names, MonoImage *image, MonoMethod *method,
-						  MonoMethodSignature *sig, MonoMethodSignature *callsig,
-						  gboolean virtual_, gboolean need_direct_wrapper)
-{
-	gint32 labels [16];
-	MonoExceptionClause *clause;
-	int loc_res, loc_exc;
-	mono_mb_set_param_names (mb, param_names);
-	/* The wrapper looks like this:
-	 *
-	 * <interrupt check>
-	 * if (exc) {
-	 *	 try {
-	 *	   return <call>
-	 *	 } catch (Exception e) {
-	 *     *exc = e;
-	 *   }
-	 * } else {
-	 *     return <call>
-	 * }
-	 */
-	MonoType *object_type = mono_get_object_type ();
-	/* allocate local 0 (object) tmp */
-	loc_res = mono_mb_add_local (mb, object_type);
-	/* allocate local 1 (object) exc */
-	loc_exc = mono_mb_add_local (mb, object_type);
-	/* *exc is assumed to be initialized to NULL by the caller */
-	mono_mb_emit_byte (mb, CEE_LDARG_2);
-	labels [0] = mono_mb_emit_branch (mb, CEE_BRFALSE);
-	/*
-	 * if (exc) case
-	 */
-	labels [1] = mono_mb_get_label (mb);
-	emit_thread_force_interrupt_checkpoint (mb);
-	emit_invoke_call (mb, method, sig, callsig, loc_res, virtual_, need_direct_wrapper);
-	labels [2] = mono_mb_emit_branch (mb, CEE_LEAVE);
-	/* Add a try clause around the call */
-	clause = (MonoExceptionClause *)mono_image_alloc0 (image, sizeof (MonoExceptionClause));
-	clause->flags = MONO_EXCEPTION_CLAUSE_NONE;
-	clause->data.catch_class = mono_defaults.exception_class;
-	clause->try_offset = labels [1];
-	clause->try_len = mono_mb_get_label (mb) - labels [1];
-	clause->handler_offset = mono_mb_get_label (mb);
-	/* handler code */
-	mono_mb_emit_stloc (mb, loc_exc);
-	mono_mb_emit_byte (mb, CEE_LDARG_2);
-	mono_mb_emit_ldloc (mb, loc_exc);
-	mono_mb_emit_byte (mb, CEE_STIND_REF);
-	mono_mb_emit_branch (mb, CEE_LEAVE);
-	clause->handler_len = mono_mb_get_pos (mb) - clause->handler_offset;
-	mono_mb_set_clauses (mb, 1, clause);
-	mono_mb_patch_branch (mb, labels [2]);
-	mono_mb_emit_ldloc (mb, loc_res);
-	mono_mb_emit_byte (mb, CEE_RET);
-	/*
-	 * if (!exc) case
-	 */
-	mono_mb_patch_branch (mb, labels [0]);
-	emit_thread_force_interrupt_checkpoint (mb);
-	emit_invoke_call (mb, method, sig, callsig, loc_res, virtual_, need_direct_wrapper);
-	mono_mb_emit_ldloc (mb, loc_res);
-	mono_mb_emit_byte (mb, CEE_RET);
-}
-static void
-emit_runtime_invoke_dynamic_ilgen (MonoMethodBuilder *mb)
-{
-	int pos;
-	MonoExceptionClause *clause;
-	MonoType *object_type = mono_get_object_type ();
-	/* allocate local 0 (object) tmp */
-	mono_mb_add_local (mb, object_type);
-	/* allocate local 1 (object) exc */
-	mono_mb_add_local (mb, object_type);
-	/* cond set *exc to null */
-	mono_mb_emit_byte (mb, CEE_LDARG_1);
-	mono_mb_emit_byte (mb, CEE_BRFALSE_S);
-	mono_mb_emit_byte (mb, 3);
-	mono_mb_emit_byte (mb, CEE_LDARG_1);
-	mono_mb_emit_byte (mb, CEE_LDNULL);
-	mono_mb_emit_byte (mb, CEE_STIND_REF);
-	emit_thread_force_interrupt_checkpoint (mb);
-	mono_mb_emit_byte (mb, CEE_LDARG_0);
-	mono_mb_emit_byte (mb, CEE_LDARG_2);
-	mono_mb_emit_byte (mb, MONO_CUSTOM_PREFIX);
-	mono_mb_emit_byte (mb, CEE_MONO_DYN_CALL);
-	pos = mono_mb_emit_branch (mb, CEE_LEAVE);
-	clause = (MonoExceptionClause *)mono_image_alloc0 (mono_defaults.corlib, sizeof (MonoExceptionClause));
-	clause->flags = MONO_EXCEPTION_CLAUSE_FILTER;
-	clause->try_len = mono_mb_get_label (mb);
-	/* filter code */
-	clause->data.filter_offset = mono_mb_get_label (mb);
-	mono_mb_emit_byte (mb, CEE_POP);
-	mono_mb_emit_byte (mb, CEE_LDARG_1);
-	mono_mb_emit_byte (mb, CEE_LDC_I4_0);
-	mono_mb_emit_byte (mb, CEE_PREFIX1);
-	mono_mb_emit_byte (mb, CEE_CGT_UN);
-	mono_mb_emit_byte (mb, CEE_PREFIX1);
-	mono_mb_emit_byte (mb, CEE_ENDFILTER);
-	clause->handler_offset = mono_mb_get_label (mb);
-	/* handler code */
-	/* store exception */
-	mono_mb_emit_stloc (mb, 1);
-	mono_mb_emit_byte (mb, CEE_LDARG_1);
-	mono_mb_emit_ldloc (mb, 1);
-	mono_mb_emit_byte (mb, CEE_STIND_REF);
-	mono_mb_emit_byte (mb, CEE_LDNULL);
-	mono_mb_emit_stloc (mb, 0);
-	mono_mb_emit_branch (mb, CEE_LEAVE);
-	clause->handler_len = mono_mb_get_pos (mb) - clause->handler_offset;
-	mono_mb_set_clauses (mb, 1, clause);
-	/* return result */
-	mono_mb_patch_branch (mb, pos);
-	mono_mb_emit_byte (mb, CEE_RET);
-}
-typedef struct EmitGCSafeTransitionBuilder {
-	MonoMethodBuilder *mb;
-	gboolean func_param;
-	int coop_gc_var;
-} GCSafeTransitionBuilder;
-static gboolean
-gc_safe_transition_builder_init (GCSafeTransitionBuilder *builder, MonoMethodBuilder *mb, gboolean func_param)
-{
-	builder->mb = mb;
-	builder->func_param = func_param;
-	builder->coop_gc_var = -1;
-#if defined (TARGET_WASM)
-	#ifndef DISABLE_THREADS
-		return TRUE;
-	#else
-		/* if we're in the AOT compiler, obey the --wasm-gc-safepoints option even if the AOT compiler doesn't have threads enabled */
-		return mono_opt_wasm_gc_safepoints;
-	#endif
-#else
-	return TRUE;
-#endif
-}
-/**
- * adds locals for the gc safe transition to the method builder.
- */
-static void
-gc_safe_transition_builder_add_locals (GCSafeTransitionBuilder *builder)
-{
-	MonoType *int_type = mono_get_int_type();
-	/* local 4, the local to be used when calling the suspend funcs */
-	builder->coop_gc_var = mono_mb_add_local (builder->mb, int_type);
-}
-/**
- * emits
- *     cookie = mono_threads_enter_gc_safe_region_unbalanced (ref dummy);
- *
- */
-static void
-gc_safe_transition_builder_emit_enter (GCSafeTransitionBuilder *builder, MonoMethod *method, gboolean aot)
-{
-	if (!builder->func_param && aot) {
-		mono_mb_emit_byte (builder->mb, MONO_CUSTOM_PREFIX);
-		mono_mb_emit_op (builder->mb, CEE_MONO_ICALL_ADDR, method);
-		mono_mb_emit_byte (builder->mb, CEE_POP); // Result not needed yet
-	}
-	mono_mb_emit_byte (builder->mb, MONO_CUSTOM_PREFIX);
-	mono_mb_emit_byte (builder->mb, CEE_MONO_GET_SP);
-	mono_mb_emit_icall (builder->mb, mono_threads_enter_gc_safe_region_unbalanced);
-	mono_mb_emit_stloc (builder->mb, builder->coop_gc_var);
-}
-/**
- * emits
- *     mono_threads_exit_gc_safe_region_unbalanced (cookie, ref dummy);
- *
- */
-static void
-gc_safe_transition_builder_emit_exit (GCSafeTransitionBuilder *builder)
-{
-	mono_mb_emit_ldloc (builder->mb, builder->coop_gc_var);
-	mono_mb_emit_byte (builder->mb, MONO_CUSTOM_PREFIX);
-	mono_mb_emit_byte (builder->mb, CEE_MONO_GET_SP);
-	mono_mb_emit_icall (builder->mb, mono_threads_exit_gc_safe_region_unbalanced);
-}
-static void
-gc_safe_transition_builder_cleanup (GCSafeTransitionBuilder *builder)
-{
-	builder->mb = NULL;
-	builder->coop_gc_var = -1;
-}
-typedef struct EmitGCUnsafeTransitionBuilder {
-	MonoMethodBuilder *mb;
-	int orig_domain_var;
-	int attach_cookie_var;
-} GCUnsafeTransitionBuilder;
-static void
-gc_unsafe_transition_builder_init (GCUnsafeTransitionBuilder *builder, MonoMethodBuilder *mb, gboolean use_attach)
-{
-	g_assert_checked (use_attach);
-	builder->mb = mb;
-	builder->orig_domain_var = -1;
-	builder->attach_cookie_var = -1;
-}
-static void
-gc_unsafe_transition_builder_add_vars (GCUnsafeTransitionBuilder *builder)
-{
-	MonoType *int_type = mono_get_int_type ();
-	builder->orig_domain_var = mono_mb_add_local (builder->mb, int_type);
-	builder->attach_cookie_var = mono_mb_add_local (builder->mb, int_type);
-}
-static void
-gc_unsafe_transition_builder_emit_enter (GCUnsafeTransitionBuilder *builder)
-{
-	MonoMethodBuilder *mb = builder->mb;
-	int attach_cookie = builder->attach_cookie_var;
-	int orig_domain = builder->orig_domain_var;
-	/*
-	 * // does (STARTING|RUNNING|BLOCKING) -> RUNNING + set/switch domain
-	 * intptr_t attach_cookie;
-	 * intptr_t orig_domain = mono_threads_attach_coop (domain, &attach_cookie);
-	 * <interrupt check>
-	 */
-	/* orig_domain = mono_threads_attach_coop (domain, &attach_cookie); */
-	mono_mb_emit_byte (mb, MONO_CUSTOM_PREFIX);
-	mono_mb_emit_byte (mb, CEE_MONO_LDDOMAIN);
-	mono_mb_emit_ldloc_addr (mb, attach_cookie);
-	/*
-	 * This icall is special cased in the JIT so it works in native-to-managed wrappers in unattached threads.
-	 * Keep this in sync with the CEE_JIT_ICALL code in the JIT.
-	 *
-	 * Special cased in interpreter, keep in sync.
-	 */
-	mono_mb_emit_icall (mb, mono_threads_attach_coop);
-	mono_mb_emit_stloc (mb, orig_domain);
-	/* <interrupt check> */
-	emit_thread_interrupt_checkpoint (mb);
-}
-static void
-gc_unsafe_transition_builder_emit_exit (GCUnsafeTransitionBuilder *builder)
-{
-	MonoMethodBuilder *mb = builder->mb;
-	int orig_domain = builder->orig_domain_var;
-	int attach_cookie = builder->attach_cookie_var;
-	/*
-	 * // does RUNNING -> (RUNNING|BLOCKING) + unset/switch domain
-	 * mono_threads_detach_coop (orig_domain, &attach_cookie);
-	 */
-	/* mono_threads_detach_coop (orig_domain, &attach_cookie); */
-	mono_mb_emit_ldloc (mb, orig_domain);
-	mono_mb_emit_ldloc_addr (mb, attach_cookie);
-	/* Special cased in interpreter, keep in sync */
-	mono_mb_emit_icall (mb, mono_threads_detach_coop);
-}
-static void
-gc_unsafe_transition_builder_cleanup (GCUnsafeTransitionBuilder *builder)
-{
-	builder->mb = NULL;
-	builder->orig_domain_var = -1;
-	builder->attach_cookie_var = -1;
-}
-static gboolean
-emit_native_wrapper_validate_signature (MonoMethodBuilder *mb, MonoMethodSignature* sig, MonoMarshalSpec** mspecs)
-{
-	if (mspecs) {
-		for (int i = 0; i < sig->param_count; i ++) {
-			if (mspecs [i + 1] && mspecs [i + 1]->native == MONO_NATIVE_CUSTOM) {
-				if (!mspecs [i + 1]->data.custom_data.custom_name || strlen (mspecs [i + 1]->data.custom_data.custom_name) == 0) {
-					mono_mb_emit_exception_full (mb, "System", "TypeLoadException", g_strdup ("Missing ICustomMarshaler type"));
-					return FALSE;
-				}
-				switch (sig->params[i]->type) {
-				case MONO_TYPE_CLASS:
-				case MONO_TYPE_OBJECT:
-				case MONO_TYPE_STRING:
-				case MONO_TYPE_ARRAY:
-				case MONO_TYPE_SZARRAY:
-				case MONO_TYPE_VALUETYPE:
-					break;
-				default:
-					mono_mb_emit_exception_full (mb, "System.Runtime.InteropServices", "MarshalDirectiveException", g_strdup_printf ("custom marshalling of type %x is currently not supported", sig->params[i]->type));
-					return FALSE;
-				}
-			}
-			else if (sig->params[i]->type == MONO_TYPE_VALUETYPE) {
-				MonoMarshalType *marshal_type = mono_marshal_load_type_info (mono_class_from_mono_type_internal (sig->params [i]));
-				for (guint32 field_idx = 0; field_idx < marshal_type->num_fields; ++field_idx) {
-					if (marshal_type->fields [field_idx].mspec && marshal_type->fields [field_idx].mspec->native == MONO_NATIVE_CUSTOM) {
-						mono_mb_emit_exception_full (mb, "System", "TypeLoadException", g_strdup ("Value type includes custom marshaled fields"));
-						return FALSE;
-					}
-				}
-			}
-		}
-	}
-	return TRUE;
-}
-/**
- * emit_native_wrapper_ilgen:
- * \param image the image to use for looking up custom marshallers
- * \param sig The signature of the native function
- * \param piinfo Marshalling information
- * \param mspecs Marshalling information
- * \param aot whenever the created method will be compiled by the AOT compiler
- * \param method if non-NULL, the pinvoke method to call
- * \param check_exceptions Whenever to check for pending exceptions after the native call
- * \param func_param the function to call is passed as a boxed IntPtr as the first parameter
- * \param func_param_unboxed combined with \p func_param, expect the function to call as an unboxed IntPtr as the first parameter
- * \param skip_gc_trans Whenever to skip GC transitions
- *
- * generates IL code for the pinvoke wrapper, the generated code calls \p func .
- */
-static void
-emit_native_wrapper_ilgen (MonoImage *image, MonoMethodBuilder *mb, MonoMethodSignature *sig, MonoMethodPInvoke *piinfo, MonoMarshalSpec **mspecs, gpointer func, MonoNativeWrapperFlags flags)
-{
-	g_assert (!MONO_CLASS_IS_IMPORT (mb->method->klass));
-	gboolean aot = (flags & EMIT_NATIVE_WRAPPER_AOT) != 0;
-	gboolean check_exceptions = (flags & EMIT_NATIVE_WRAPPER_CHECK_EXCEPTIONS) != 0;
-	gboolean func_param = (flags & EMIT_NATIVE_WRAPPER_FUNC_PARAM) != 0;
-	gboolean func_param_unboxed = (flags & EMIT_NATIVE_WRAPPER_FUNC_PARAM_UNBOXED) != 0;
-	gboolean skip_gc_trans = (flags & EMIT_NATIVE_WRAPPER_SKIP_GC_TRANS) != 0;
-	gboolean runtime_marshalling_enabled = (flags & EMIT_NATIVE_WRAPPER_RUNTIME_MARSHALLING_ENABLED) != 0;
-	EmitMarshalContext m;
-	MonoMethodSignature *csig;
-	MonoClass *klass;
-	int i, argnum, *tmp_locals;
-	int type, param_shift = 0;
-	int func_addr_local = -1;
-	gboolean need_gc_safe = FALSE;
-	GCSafeTransitionBuilder gc_safe_transition_builder;
-	memset (&m, 0, sizeof (m));
-	m.runtime_marshalling_enabled = runtime_marshalling_enabled;
-	m.mb = mb;
-	m.sig = sig;
-	m.piinfo = piinfo;
-	if (!emit_native_wrapper_validate_signature (mb, sig, mspecs))
-		return;
-	if (!skip_gc_trans)
-		need_gc_safe = gc_safe_transition_builder_init (&gc_safe_transition_builder, mb, func_param);
-	/* we copy the signature, so that we can set pinvoke to 0 */
-	if (func_param) {
-		/* The function address is passed as the first argument */
-		g_assert (!sig->hasthis);
-		param_shift += 1;
-	}
-	csig = mono_metadata_signature_dup_full (get_method_image (mb->method), sig);
-	csig->pinvoke = 1;
-	if (!runtime_marshalling_enabled)
-		csig->marshalling_disabled = 1;
-	m.csig = csig;
-	m.image = image;
-	if (sig->hasthis)
-		param_shift += 1;
-	MonoType *int_type = mono_get_int_type ();
-	MonoType *boolean_type = m_class_get_byval_arg (mono_defaults.boolean_class);
-	/* we allocate local for use with mono_marshal_shared_emit_struct_conv() */
-	/* allocate local 0 (pointer) src_ptr */
-	mono_mb_add_local (mb, int_type);
-	/* allocate local 1 (pointer) dst_ptr */
-	mono_mb_add_local (mb, int_type);
-	/* allocate local 2 (boolean) delete_old */
-	mono_mb_add_local (mb, boolean_type);
-	/* delete_old = FALSE */
-	mono_mb_emit_icon (mb, 0);
-	mono_mb_emit_stloc (mb, 2);
-	if (!MONO_TYPE_IS_VOID (sig->ret)) {
-		/* allocate local 3 to store the return value */
-		mono_mb_add_local (mb, sig->ret);
-	}
-	if (need_gc_safe)
-		gc_safe_transition_builder_add_locals (&gc_safe_transition_builder);
-	if (!func && !aot && !func_param) {
-		/*
-		 * On netcore, its possible to register pinvoke resolvers at runtime, so
-		 * a pinvoke lookup can fail, and then succeed later. So if the
-		 * original lookup failed, do a lookup every time until it
-		 * succeeds.
-		 * This adds some overhead, but only when the pinvoke lookup
-		 * was not initially successful.
-		 * FIXME: AOT case
-		 */
-		func_addr_local = mono_mb_add_local (mb, int_type);
-		int cache_local = mono_mb_add_local (mb, int_type);
-		mono_mb_emit_byte (mb, MONO_CUSTOM_PREFIX);
-		mono_mb_emit_op (mb, CEE_MONO_PINVOKE_ADDR_CACHE, &piinfo->method);
-		mono_mb_emit_stloc (mb, cache_local);
-		mono_mb_emit_ldloc (mb, cache_local);
-		mono_mb_emit_byte (mb, CEE_LDIND_I);
-		int pos = mono_mb_emit_branch (mb, CEE_BRTRUE);
-		mono_mb_emit_ldloc (mb, cache_local);
-		mono_mb_emit_byte (mb, MONO_CUSTOM_PREFIX);
-		mono_mb_emit_op (mb, CEE_MONO_METHODCONST, &piinfo->method);
-		mono_mb_emit_icall (mb, mono_marshal_lookup_pinvoke);
-		mono_mb_emit_byte (mb, CEE_STIND_I);
-		mono_mb_patch_branch (mb, pos);
-		mono_mb_emit_ldloc (mb, cache_local);
-		mono_mb_emit_byte (mb, CEE_LDIND_I);
-		mono_mb_emit_stloc (mb, func_addr_local);
-	}
-	/*
-	 * cookie = mono_threads_enter_gc_safe_region_unbalanced (ref dummy);
-	 *
-	 * ret = method (...);
-	 *
-	 * mono_threads_exit_gc_safe_region_unbalanced (cookie, ref dummy);
-	 *
-	 * <interrupt check>
-	 *
-	 * return ret;
-	 */
-	if (MONO_TYPE_ISSTRUCT (sig->ret))
-		m.vtaddr_var = mono_mb_add_local (mb, int_type);
-	if (mspecs [0] && mspecs [0]->native == MONO_NATIVE_CUSTOM) {
-		/* Return type custom marshaling */
-		/*
-		 * Since we can't determine the return type of the unmanaged function,
-		 * we assume it returns a pointer, and pass that pointer to
-		 * MarshalNativeToManaged.
-		 */
-		csig->ret = int_type;
-	}
-	if (piinfo && (piinfo->piflags & PINVOKE_ATTRIBUTE_SUPPORTS_LAST_ERROR) && !m.runtime_marshalling_enabled)
-		mono_marshal_shared_mb_emit_exception_marshal_directive(mb, g_strdup("Setting SetLastError=true is not supported when runtime marshalling is disabled."));
-	/* we first do all conversions */
-	tmp_locals = g_newa (int, sig->param_count);
-	m.orig_conv_args = g_newa (int, sig->param_count + 1);
-	for (i = 0; i < sig->param_count; i ++) {
-		tmp_locals [i] = mono_emit_marshal (&m, i + param_shift, sig->params [i], mspecs [i + 1], 0, &csig->params [i], MARSHAL_ACTION_CONV_IN);
-	}
-	if (need_gc_safe)
-		gc_safe_transition_builder_emit_enter (&gc_safe_transition_builder, &piinfo->method, aot);
-	/* push all arguments */
-	if (sig->hasthis)
-		mono_mb_emit_byte (mb, CEE_LDARG_0);
-	for (i = 0; i < sig->param_count; i++) {
-		mono_emit_marshal (&m, i + param_shift, sig->params [i], mspecs [i + 1], tmp_locals [i], NULL, MARSHAL_ACTION_PUSH);
-	}
-	/* call the native method */
-	if (func_param) {
-		mono_mb_emit_byte (mb, CEE_LDARG_0);
-		if (!func_param_unboxed) {
-			mono_mb_emit_op (mb, CEE_UNBOX, mono_defaults.int_class);
-			mono_mb_emit_byte (mb, CEE_LDIND_I);
-		}
-		if (piinfo && (piinfo->piflags & PINVOKE_ATTRIBUTE_SUPPORTS_LAST_ERROR) != 0) {
-			mono_mb_emit_byte (mb, MONO_CUSTOM_PREFIX);
-			mono_mb_emit_byte (mb, CEE_MONO_SAVE_LAST_ERROR);
-		}
-		mono_mb_emit_calli (mb, csig);
-	} else {
-		if (func_addr_local != -1) {
-			mono_mb_emit_ldloc (mb, func_addr_local);
-		} else {
-			if (aot) {
-				/* Reuse the ICALL_ADDR opcode for pinvokes too */
-				mono_mb_emit_byte (mb, MONO_CUSTOM_PREFIX);
-				mono_mb_emit_op (mb, CEE_MONO_ICALL_ADDR, &piinfo->method);
-			}
-		}
-		if (piinfo->piflags & PINVOKE_ATTRIBUTE_SUPPORTS_LAST_ERROR) {
-			mono_mb_emit_byte (mb, MONO_CUSTOM_PREFIX);
-			mono_mb_emit_byte (mb, CEE_MONO_SAVE_LAST_ERROR);
-		}
-		if (func_addr_local != -1 || aot)
-			mono_mb_emit_calli (mb, csig);
-		else
-			mono_mb_emit_native_call (mb, csig, func);
-	}
-	if (MONO_TYPE_ISSTRUCT (sig->ret)) {
-		klass = mono_class_from_mono_type_internal (sig->ret);
-		mono_class_init_internal (klass);
-		if (!(mono_class_is_explicit_layout (klass) || m_class_is_blittable (klass))) {
-			/* TODO: marshal-lightweight: can this move to marshal-ilgen? */
-			/* This is used by emit_marshal_vtype (), but it needs to go right before the call */
-			mono_mb_emit_byte (mb, MONO_CUSTOM_PREFIX);
-			mono_mb_emit_byte (mb, CEE_MONO_VTADDR);
-			mono_mb_emit_stloc (mb, m.vtaddr_var);
-		}
-	}
-	/* Unblock before converting the result, since that can involve calls into the runtime */
-	if (need_gc_safe)
-		gc_safe_transition_builder_emit_exit (&gc_safe_transition_builder);
-	gc_safe_transition_builder_cleanup (&gc_safe_transition_builder);
-	/* convert the result */
-	if (!m_type_is_byref (sig->ret)) {
-		MonoMarshalSpec *spec = mspecs [0];
-		type = sig->ret->type;
-		if (spec && spec->native == MONO_NATIVE_CUSTOM) {
-			mono_emit_marshal (&m, 0, sig->ret, spec, 0, NULL, MARSHAL_ACTION_CONV_RESULT);
-		} else {
-		handle_enum:
-			switch (type) {
-			case MONO_TYPE_VOID:
-				break;
-			case MONO_TYPE_VALUETYPE:
-				klass = sig->ret->data.klass;
-				if (m_class_is_enumtype (klass)) {
-					type = mono_class_enum_basetype_internal (sig->ret->data.klass)->type;
-					goto handle_enum;
-				}
-				mono_emit_marshal (&m, 0, sig->ret, spec, 0, NULL, MARSHAL_ACTION_CONV_RESULT);
-				break;
-			case MONO_TYPE_I1:
-			case MONO_TYPE_U1:
-			case MONO_TYPE_I2:
-			case MONO_TYPE_U2:
-			case MONO_TYPE_I4:
-			case MONO_TYPE_U4:
-			case MONO_TYPE_I:
-			case MONO_TYPE_U:
-			case MONO_TYPE_R4:
-			case MONO_TYPE_R8:
-			case MONO_TYPE_I8:
-			case MONO_TYPE_U8:
-			case MONO_TYPE_FNPTR:
-			case MONO_TYPE_STRING:
-			case MONO_TYPE_CLASS:
-			case MONO_TYPE_OBJECT:
-			case MONO_TYPE_BOOLEAN:
-			case MONO_TYPE_ARRAY:
-			case MONO_TYPE_SZARRAY:
-			case MONO_TYPE_CHAR:
-			case MONO_TYPE_PTR:
-			case MONO_TYPE_GENERICINST:
-				mono_emit_marshal (&m, 0, sig->ret, spec, 0, NULL, MARSHAL_ACTION_CONV_RESULT);
-				break;
-			case MONO_TYPE_TYPEDBYREF:
-			default:
-				g_warning ("return type 0x%02x unknown", sig->ret->type);
-				g_assert_not_reached ();
-			}
-		}
-	} else {
-		mono_mb_emit_stloc (mb, 3);
-	}
-	/*
-	 * Need to call this after converting the result since MONO_VTADDR needs
-	 * to be adjacent to the call instruction.
-	 */
-	if (check_exceptions)
-		emit_thread_interrupt_checkpoint (mb);
-	/* we need to convert byref arguments back and free string arrays */
-	for (i = 0; i < sig->param_count; i++) {
-		MonoType *t = sig->params [i];
-		MonoMarshalSpec *spec = mspecs [i + 1];
-		argnum = i + param_shift;
-		if (spec && ((spec->native == MONO_NATIVE_CUSTOM) || (spec->native == MONO_NATIVE_ASANY))) {
-			mono_emit_marshal (&m, argnum, t, spec, tmp_locals [i], NULL, MARSHAL_ACTION_CONV_OUT);
-			continue;
-		}
-		switch (t->type) {
-		case MONO_TYPE_STRING:
-		case MONO_TYPE_VALUETYPE:
-		case MONO_TYPE_CLASS:
-		case MONO_TYPE_OBJECT:
-		case MONO_TYPE_SZARRAY:
-		case MONO_TYPE_BOOLEAN:
-			mono_emit_marshal (&m, argnum, t, spec, tmp_locals [i], NULL, MARSHAL_ACTION_CONV_OUT);
-			break;
-		default:
-			break;
-		}
-	}
-	if (!MONO_TYPE_IS_VOID(sig->ret))
-		mono_mb_emit_ldloc (mb, 3);
-	mono_mb_emit_byte (mb, CEE_RET);
-}
-/*
- * The code directly following this is the cache hit, value positive branch
- *
- * This function takes a new method builder with 0 locals and adds two locals
- * to create multiple out-branches and the fall through state of having the object
- * on the stack after a cache miss
- */
-static void
-generate_check_cache (int obj_arg_position, int class_arg_position, int cache_arg_position, // In-parameters
-											int *null_obj, int *cache_hit_neg, int *cache_hit_pos, // Out-parameters
-											MonoMethodBuilder *mb)
-{
-	int cache_miss_pos;
-	MonoType *int_type = mono_get_int_type ();
-	/* allocate local 0 (pointer) obj_vtable */
-	mono_mb_add_local (mb, int_type);
-	/* allocate local 1 (pointer) cached_vtable */
-	mono_mb_add_local (mb, int_type);
-	/*if (!obj)*/
-	mono_mb_emit_ldarg (mb, obj_arg_position);
-	*null_obj = mono_mb_emit_branch (mb, CEE_BRFALSE);
-	/*obj_vtable = obj->vtable;*/
-	mono_mb_emit_ldarg (mb, obj_arg_position);
-	mono_mb_emit_ldflda (mb, MONO_STRUCT_OFFSET (MonoObject, vtable));
-	mono_mb_emit_byte (mb, CEE_LDIND_I);
-	mono_mb_emit_stloc (mb, 0);
-	/* cached_vtable = *cache*/
-	mono_mb_emit_ldarg (mb, cache_arg_position);
-	mono_mb_emit_byte (mb, CEE_LDIND_I);
-	mono_mb_emit_stloc (mb, 1);
-	mono_mb_emit_ldloc (mb, 1);
-	mono_mb_emit_byte (mb, CEE_LDC_I4);
-	mono_mb_emit_i4 (mb, ~0x1);
-	mono_mb_emit_byte (mb, CEE_CONV_I);
-	mono_mb_emit_byte (mb, CEE_AND);
-	mono_mb_emit_ldloc (mb, 0);
-	/*if ((cached_vtable & ~0x1)== obj_vtable)*/
-	cache_miss_pos = mono_mb_emit_branch (mb, CEE_BNE_UN);
-	/*return (cached_vtable & 0x1) ? NULL : obj;*/
-	mono_mb_emit_ldloc (mb, 1);
-	mono_mb_emit_byte(mb, CEE_LDC_I4_1);
-	mono_mb_emit_byte (mb, CEE_CONV_U);
-	mono_mb_emit_byte (mb, CEE_AND);
-	*cache_hit_neg = mono_mb_emit_branch (mb, CEE_BRTRUE);
-	*cache_hit_pos = mono_mb_emit_branch (mb, CEE_BR);
-	mono_mb_patch_branch (mb, cache_miss_pos);
-	mono_mb_emit_ldarg (mb, obj_arg_position);
-	mono_mb_emit_ldarg (mb, class_arg_position);
-	mono_mb_emit_ldarg (mb, cache_arg_position);
-	mono_mb_emit_icall (mb, mono_marshal_isinst_with_cache);
-}
-static void
-emit_castclass_ilgen (MonoMethodBuilder *mb)
-{
-	int return_null_pos, positive_cache_hit_pos, negative_cache_hit_pos, invalid_cast_pos;
-	const int obj_arg_position = TYPECHECK_OBJECT_ARG_POS;
-	const int class_arg_position = TYPECHECK_CLASS_ARG_POS;
-	const int cache_arg_position = TYPECHECK_CACHE_ARG_POS;
-	generate_check_cache (obj_arg_position, class_arg_position, cache_arg_position,
-												&return_null_pos, &negative_cache_hit_pos, &positive_cache_hit_pos, mb);
-	invalid_cast_pos = mono_mb_emit_branch (mb, CEE_BRFALSE);
-	/*return obj;*/
-	mono_mb_patch_branch (mb, positive_cache_hit_pos);
-	mono_mb_emit_ldarg (mb, obj_arg_position);
-	mono_mb_emit_byte (mb, CEE_RET);
-	/*fails*/
-	mono_mb_patch_branch (mb, negative_cache_hit_pos);
-	mono_mb_patch_branch (mb, invalid_cast_pos);
-	mono_mb_emit_exception (mb, "InvalidCastException", NULL);
-	/*return null*/
-	mono_mb_patch_branch (mb, return_null_pos);
-	mono_mb_emit_byte (mb, CEE_LDNULL);
-	mono_mb_emit_byte (mb, CEE_RET);
-}
-static void
-emit_isinst_ilgen (MonoMethodBuilder *mb)
-{
-	int return_null_pos, positive_cache_hit_pos, negative_cache_hit_pos;
-	const int obj_arg_position = TYPECHECK_OBJECT_ARG_POS;
-	const int class_arg_position = TYPECHECK_CLASS_ARG_POS;
-	const int cache_arg_position = TYPECHECK_CACHE_ARG_POS;
-	generate_check_cache (obj_arg_position, class_arg_position, cache_arg_position,
-		&return_null_pos, &negative_cache_hit_pos, &positive_cache_hit_pos, mb);
-	mono_mb_emit_byte (mb, CEE_RET);
-	mono_mb_patch_branch (mb, negative_cache_hit_pos);
-	mono_mb_patch_branch (mb, return_null_pos);
-	mono_mb_emit_byte (mb, CEE_LDNULL);
-	mono_mb_emit_byte (mb, CEE_RET);
-	mono_mb_patch_branch (mb, positive_cache_hit_pos);
-	mono_mb_emit_ldarg (mb, obj_arg_position);
-	mono_mb_emit_byte (mb, CEE_RET);
-}
-static void
-load_array_element_address (MonoMethodBuilder *mb)
-{
-	mono_mb_emit_ldarg (mb, 0);
-	mono_mb_emit_ldarg (mb, 1);
-	mono_mb_emit_op (mb, CEE_LDELEMA, mono_defaults.object_class);
-}
-static void
-load_array_class (MonoMethodBuilder *mb, int aklass)
-{
-	mono_mb_emit_ldarg (mb, 0);
-	mono_mb_emit_ldflda (mb, MONO_STRUCT_OFFSET (MonoObject, vtable));
-	mono_mb_emit_byte (mb, CEE_LDIND_I);
-	mono_mb_emit_ldflda (mb, MONO_STRUCT_OFFSET (MonoVTable, klass));
-	mono_mb_emit_byte (mb, CEE_LDIND_I);
-	mono_mb_emit_ldflda (mb, GINTPTR_TO_INT32 (m_class_offsetof_element_class ()));
-	mono_mb_emit_byte (mb, CEE_LDIND_I);
-	mono_mb_emit_stloc (mb, aklass);
-}
-static void
-load_value_class (MonoMethodBuilder *mb, int vklass)
-{
-	mono_mb_emit_ldarg (mb, 2);
-	mono_mb_emit_ldflda (mb, MONO_STRUCT_OFFSET (MonoObject, vtable));
-	mono_mb_emit_byte (mb, CEE_LDIND_I);
-	mono_mb_emit_ldflda (mb, MONO_STRUCT_OFFSET (MonoVTable, klass));
-	mono_mb_emit_byte (mb, CEE_LDIND_I);
-	mono_mb_emit_stloc (mb, vklass);
-}
-static int
-emit_marshal_scalar_ilgen (EmitMarshalContext *m, int argnum, MonoType *t,
-		     MonoMarshalSpec *spec, int conv_arg,
-		     MonoType **conv_arg_type, MarshalAction action)
-{
-	MonoMethodBuilder *mb = m->mb;
-	switch (action) {
-	case MARSHAL_ACTION_PUSH:
-		mono_mb_emit_ldarg (mb, argnum);
-		break;
-	case MARSHAL_ACTION_CONV_RESULT:
-		/* no conversions necessary */
-		mono_mb_emit_stloc (mb, 3);
-		break;
-	case MARSHAL_ACTION_MANAGED_CONV_RESULT:
-		mono_mb_emit_stloc (mb, 3);
-		break;
-	default:
-		break;
-	}
-	return conv_arg;
-}
-static void
-emit_virtual_stelemref_ilgen (MonoMethodBuilder *mb, const char **param_names, MonoStelemrefKind kind)
-{
-	guint32 b1, b2, b3, b4;
-	int aklass, vklass, vtable, uiid;
-	int array_slot_addr;
-	mono_mb_set_param_names (mb, param_names);
-	MonoType *int_type = mono_get_int_type ();
-	MonoType *int32_type = m_class_get_byval_arg (mono_defaults.int32_class);
-	MonoType *object_type_byref = mono_class_get_byref_type (mono_defaults.object_class);
-	/*For now simply call plain old stelemref*/
-	switch (kind) {
-	case STELEMREF_OBJECT:
-		/* ldelema (implicit bound check) */
-		load_array_element_address (mb);
-		/* do_store */
-		mono_mb_emit_ldarg (mb, 2);
-		mono_mb_emit_byte (mb, CEE_STIND_REF);
-		mono_mb_emit_byte (mb, CEE_RET);
-		break;
-	case STELEMREF_COMPLEX: {
-		int b_fast;
-		/*
-		<ldelema (bound check)>
-		if (!value)
-			goto store;
-		if (!mono_object_isinst (value, aklass))
-			goto do_exception;
-		 do_store:
-			 *array_slot_addr = value;
-		do_exception:
-			throw new ArrayTypeMismatchException ();
-		*/
-		aklass = mono_mb_add_local (mb, int_type);
-		vklass = mono_mb_add_local (mb, int_type);
-		array_slot_addr = mono_mb_add_local (mb, object_type_byref);
-#if 0
-		{
-			/*Use this to debug/record stores that are going thru the slow path*/
-			MonoMethodSignature *csig;
-			csig = mono_metadata_signature_alloc (mono_defaults.corlib, 3);
-			csig->ret = mono_get_void_type ();
-			csig->params [0] = object_type;
-			csig->params [1] = int_type; /* this is a natural sized int */
-			csig->params [2] = object_type;
-			mono_mb_emit_ldarg (mb, 0);
-			mono_mb_emit_ldarg (mb, 1);
-			mono_mb_emit_ldarg (mb, 2);
-			mono_mb_emit_native_call (mb, csig, record_slot_vstore);
-		}
-#endif
-		/* ldelema (implicit bound check) */
-		load_array_element_address (mb);
-		mono_mb_emit_stloc (mb, array_slot_addr);
-		/* if (!value) goto do_store */
-		mono_mb_emit_ldarg (mb, 2);
-		b1 = mono_mb_emit_branch (mb, CEE_BRFALSE);
-		/* aklass = array->vtable->klass->element_class */
-		load_array_class (mb, aklass);
-		/* vklass = value->vtable->klass */
-		load_value_class (mb, vklass);
-		/* fastpath */
-		mono_mb_emit_ldloc (mb, vklass);
-		mono_mb_emit_ldloc (mb, aklass);
-		b_fast = mono_mb_emit_branch (mb, CEE_BEQ);
-		/*if (mono_object_isinst (value, aklass)) */
-		mono_mb_emit_ldarg (mb, 2);
-		mono_mb_emit_ldloc (mb, aklass);
-		mono_mb_emit_icall (mb, mono_object_isinst_icall);
-		b2 = mono_mb_emit_branch (mb, CEE_BRFALSE);
-		/* do_store: */
-		mono_mb_patch_branch (mb, b1);
-		mono_mb_patch_branch (mb, b_fast);
-		mono_mb_emit_ldloc (mb, array_slot_addr);
-		mono_mb_emit_ldarg (mb, 2);
-		mono_mb_emit_byte (mb, CEE_STIND_REF);
-		mono_mb_emit_byte (mb, CEE_RET);
-		/* do_exception: */
-		mono_mb_patch_branch (mb, b2);
-		mono_mb_emit_exception (mb, "ArrayTypeMismatchException", NULL);
-		break;
-	}
-	case STELEMREF_SEALED_CLASS:
-		/*
-		<ldelema (bound check)>
-		if (!value)
-			goto store;
-		aklass = array->vtable->m_class_get_element_class (klass);
-		vklass = value->vtable->klass;
-		if (vklass != aklass)
-			goto do_exception;
-		do_store:
-			 *array_slot_addr = value;
-		do_exception:
-			throw new ArrayTypeMismatchException ();
-		*/
-		aklass = mono_mb_add_local (mb, int_type);
-		vklass = mono_mb_add_local (mb, int_type);
-		array_slot_addr = mono_mb_add_local (mb, object_type_byref);
-		/* ldelema (implicit bound check) */
-		load_array_element_address (mb);
-		mono_mb_emit_stloc (mb, array_slot_addr);
-		/* if (!value) goto do_store */
-		mono_mb_emit_ldarg (mb, 2);
-		b1 = mono_mb_emit_branch (mb, CEE_BRFALSE);
-		/* aklass = array->vtable->klass->element_class */
-		load_array_class (mb, aklass);
-		/* vklass = value->vtable->klass */
-		load_value_class (mb, vklass);
-		/*if (vklass != aklass) goto do_exception; */
-		mono_mb_emit_ldloc (mb, aklass);
-		mono_mb_emit_ldloc (mb, vklass);
-		b2 = mono_mb_emit_branch (mb, CEE_BNE_UN);
-		/* do_store: */
-		mono_mb_patch_branch (mb, b1);
-		mono_mb_emit_ldloc (mb, array_slot_addr);
-		mono_mb_emit_ldarg (mb, 2);
-		mono_mb_emit_byte (mb, CEE_STIND_REF);
-		mono_mb_emit_byte (mb, CEE_RET);
-		/* do_exception: */
-		mono_mb_patch_branch (mb, b2);
-		mono_mb_emit_exception (mb, "ArrayTypeMismatchException", NULL);
-		break;
-	case STELEMREF_CLASS: {
-		/*
-		the method:
-		<ldelema (bound check)>
-		if (!value)
-			goto do_store;
-		aklass = array->vtable->m_class_get_element_class (klass);
-		vklass = value->vtable->klass;
-		if (vklass->idepth < aklass->idepth)
-			goto do_exception;
-		if (vklass->supertypes [aklass->idepth - 1] != aklass)
-			goto do_exception;
-		do_store:
-			*array_slot_addr = value;
-			return;
-		long:
-			throw new ArrayTypeMismatchException ();
-		*/
-		aklass = mono_mb_add_local (mb, int_type);
-		vklass = mono_mb_add_local (mb, int_type);
-		array_slot_addr = mono_mb_add_local (mb, object_type_byref);
-		/* ldelema (implicit bound check) */
-		load_array_element_address (mb);
-		mono_mb_emit_stloc (mb, array_slot_addr);
-		/* if (!value) goto do_store */
-		mono_mb_emit_ldarg (mb, 2);
-		b1 = mono_mb_emit_branch (mb, CEE_BRFALSE);
-		/* aklass = array->vtable->klass->element_class */
-		load_array_class (mb, aklass);
-		/* vklass = value->vtable->klass */
-		load_value_class (mb, vklass);
-		/* if (vklass->idepth < aklass->idepth) goto failue */
-		mono_mb_emit_ldloc (mb, vklass);
-		mono_mb_emit_ldflda (mb, GINTPTR_TO_INT32 (m_class_offsetof_idepth ()));
-		mono_mb_emit_byte (mb, CEE_LDIND_U2);
-		mono_mb_emit_ldloc (mb, aklass);
-		mono_mb_emit_ldflda (mb, GINTPTR_TO_INT32 (m_class_offsetof_idepth ()));
-		mono_mb_emit_byte (mb, CEE_LDIND_U2);
-		b3 = mono_mb_emit_branch (mb, CEE_BLT_UN);
-		/* if (vklass->supertypes [aklass->idepth - 1] != aklass) goto failure */
-		mono_mb_emit_ldloc (mb, vklass);
-		mono_mb_emit_ldflda (mb, GINTPTR_TO_INT32 (m_class_offsetof_supertypes ()));
-		mono_mb_emit_byte (mb, CEE_LDIND_I);
-		mono_mb_emit_ldloc (mb, aklass);
-		mono_mb_emit_ldflda (mb, GINTPTR_TO_INT32 (m_class_offsetof_idepth ()));
-		mono_mb_emit_byte (mb, CEE_LDIND_U2);
-		mono_mb_emit_icon (mb, 1);
-		mono_mb_emit_byte (mb, CEE_SUB);
-		mono_mb_emit_icon (mb, TARGET_SIZEOF_VOID_P);
-		mono_mb_emit_byte (mb, CEE_MUL);
-		mono_mb_emit_byte (mb, CEE_ADD);
-		mono_mb_emit_byte (mb, CEE_LDIND_I);
-		mono_mb_emit_ldloc (mb, aklass);
-		b4 = mono_mb_emit_branch (mb, CEE_BNE_UN);
-		/* do_store: */
-		mono_mb_patch_branch (mb, b1);
-		mono_mb_emit_ldloc (mb, array_slot_addr);
-		mono_mb_emit_ldarg (mb, 2);
-		mono_mb_emit_byte (mb, CEE_STIND_REF);
-		mono_mb_emit_byte (mb, CEE_RET);
-		/* do_exception: */
-		mono_mb_patch_branch (mb, b3);
-		mono_mb_patch_branch (mb, b4);
-		mono_mb_emit_exception (mb, "ArrayTypeMismatchException", NULL);
-		break;
-	}
-	case STELEMREF_CLASS_SMALL_IDEPTH:
-		/*
-		the method:
-		<ldelema (bound check)>
-		if (!value)
-			goto do_store;
-		aklass = array->vtable->m_class_get_element_class (klass);
-		vklass = value->vtable->klass;
-		if (vklass->supertypes [aklass->idepth - 1] != aklass)
-			goto do_exception;
-		do_store:
-			*array_slot_addr = value;
-			return;
-		long:
-			throw new ArrayTypeMismatchException ();
-		*/
-		aklass = mono_mb_add_local (mb, int_type);
-		vklass = mono_mb_add_local (mb, int_type);
-		array_slot_addr = mono_mb_add_local (mb, object_type_byref);
-		/* ldelema (implicit bound check) */
-		load_array_element_address (mb);
-		mono_mb_emit_stloc (mb, array_slot_addr);
-		/* if (!value) goto do_store */
-		mono_mb_emit_ldarg (mb, 2);
-		b1 = mono_mb_emit_branch (mb, CEE_BRFALSE);
-		/* aklass = array->vtable->klass->element_class */
-		load_array_class (mb, aklass);
-		/* vklass = value->vtable->klass */
-		load_value_class (mb, vklass);
-		/* if (vklass->supertypes [aklass->idepth - 1] != aklass) goto failure */
-		mono_mb_emit_ldloc (mb, vklass);
-		mono_mb_emit_ldflda (mb, GINTPTR_TO_INT32 (m_class_offsetof_supertypes ()));
-		mono_mb_emit_byte (mb, CEE_LDIND_I);
-		mono_mb_emit_ldloc (mb, aklass);
-		mono_mb_emit_ldflda (mb, GINTPTR_TO_INT32 (m_class_offsetof_idepth ()));
-		mono_mb_emit_byte (mb, CEE_LDIND_U2);
-		mono_mb_emit_icon (mb, 1);
-		mono_mb_emit_byte (mb, CEE_SUB);
-		mono_mb_emit_icon (mb, TARGET_SIZEOF_VOID_P);
-		mono_mb_emit_byte (mb, CEE_MUL);
-		mono_mb_emit_byte (mb, CEE_ADD);
-		mono_mb_emit_byte (mb, CEE_LDIND_I);
-		mono_mb_emit_ldloc (mb, aklass);
-		b4 = mono_mb_emit_branch (mb, CEE_BNE_UN);
-		/* do_store: */
-		mono_mb_patch_branch (mb, b1);
-		mono_mb_emit_ldloc (mb, array_slot_addr);
-		mono_mb_emit_ldarg (mb, 2);
-		mono_mb_emit_byte (mb, CEE_STIND_REF);
-		mono_mb_emit_byte (mb, CEE_RET);
-		/* do_exception: */
-		mono_mb_patch_branch (mb, b4);
-		mono_mb_emit_exception (mb, "ArrayTypeMismatchException", NULL);
-		break;
-	case STELEMREF_INTERFACE:
-		/*Mono *klass;
-		MonoVTable *vt;
-		unsigned uiid;
-		if (value == NULL)
-			goto store;
-		klass = array->obj.vtable->klass->element_class;
-		vt = value->vtable;
-		uiid = klass->interface_id;
-		if (uiid > vt->max_interface_id)
-			goto exception;
-		if (!(vt->interface_bitmap [(uiid) >> 3] & (1 << ((uiid)&7))))
-			goto exception;
-		store:
-			mono_array_setref_internal (array, index, value);
-			return;
-		exception:
-			mono_raise_exception (mono_get_exception_array_type_mismatch ());*/
-		array_slot_addr = mono_mb_add_local (mb, object_type_byref);
-		aklass = mono_mb_add_local (mb, int_type);
-		vtable = mono_mb_add_local (mb, int_type);
-		uiid = mono_mb_add_local (mb, int32_type);
-		/* ldelema (implicit bound check) */
-		load_array_element_address (mb);
-		mono_mb_emit_stloc (mb, array_slot_addr);
-		/* if (!value) goto do_store */
-		mono_mb_emit_ldarg (mb, 2);
-		b1 = mono_mb_emit_branch (mb, CEE_BRFALSE);
-		/* klass = array->vtable->m_class_get_element_class (klass) */
-		load_array_class (mb, aklass);
-		/* vt = value->vtable */
-		mono_mb_emit_ldarg (mb, 2);
-		mono_mb_emit_ldflda (mb, MONO_STRUCT_OFFSET (MonoObject, vtable));
-		mono_mb_emit_byte (mb, CEE_LDIND_I);
-		mono_mb_emit_stloc (mb, vtable);
-		/* uiid = klass->interface_id; */
-		mono_mb_emit_ldloc (mb, aklass);
-		mono_mb_emit_ldflda (mb, GINTPTR_TO_INT32 (m_class_offsetof_interface_id ()));
-		mono_mb_emit_byte (mb, CEE_LDIND_U4);
-		mono_mb_emit_stloc (mb, uiid);
-		/*if (uiid > vt->max_interface_id)*/
-		mono_mb_emit_ldloc (mb, uiid);
-		mono_mb_emit_ldloc (mb, vtable);
-		mono_mb_emit_ldflda (mb, MONO_STRUCT_OFFSET (MonoVTable, max_interface_id));
-		mono_mb_emit_byte (mb, CEE_LDIND_U4);
-		b2 = mono_mb_emit_branch (mb, CEE_BGT_UN);
-		/* if (!(vt->interface_bitmap [(uiid) >> 3] & (1 << ((uiid)&7)))) */
-		/*vt->interface_bitmap*/
-		mono_mb_emit_ldloc (mb, vtable);
-		mono_mb_emit_ldflda (mb, MONO_STRUCT_OFFSET (MonoVTable, interface_bitmap));
-		mono_mb_emit_byte (mb, CEE_LDIND_I);
-		/*uiid >> 3*/
-		mono_mb_emit_ldloc (mb, uiid);
-		mono_mb_emit_icon (mb, 3);
-		mono_mb_emit_byte (mb, CEE_SHR_UN);
-		/*vt->interface_bitmap [(uiid) >> 3]*/
-		mono_mb_emit_byte (mb, CEE_ADD); /*interface_bitmap is a guint8 array*/
-		mono_mb_emit_byte (mb, CEE_LDIND_U1);
-		/*(1 << ((uiid)&7)))*/
-		mono_mb_emit_icon (mb, 1);
-		mono_mb_emit_ldloc (mb, uiid);
-		mono_mb_emit_icon (mb, 7);
-		mono_mb_emit_byte (mb, CEE_AND);
-		mono_mb_emit_byte (mb, CEE_SHL);
-		/*bitwise and the whole thing*/
-		mono_mb_emit_byte (mb, CEE_AND);
-		b3 = mono_mb_emit_branch (mb, CEE_BRFALSE);
-		/* do_store: */
-		mono_mb_patch_branch (mb, b1);
-		mono_mb_emit_ldloc (mb, array_slot_addr);
-		mono_mb_emit_ldarg (mb, 2);
-		mono_mb_emit_byte (mb, CEE_STIND_REF);
-		mono_mb_emit_byte (mb, CEE_RET);
-		/* do_exception: */
-		mono_mb_patch_branch (mb, b2);
-		mono_mb_patch_branch (mb, b3);
-		mono_mb_emit_exception (mb, "ArrayTypeMismatchException", NULL);
-		break;
-	default:
-		mono_mb_emit_ldarg (mb, 0);
-		mono_mb_emit_ldarg (mb, 1);
-		mono_mb_emit_ldarg (mb, 2);
-		mono_mb_emit_managed_call (mb, mono_marshal_get_stelemref (), NULL);
-		mono_mb_emit_byte (mb, CEE_RET);
-		g_assert (0);
-	}
-}
-static void
-emit_stelemref_ilgen (MonoMethodBuilder *mb)
-{
-	guint32 b1, b2, b3, b4;
-	guint32 copy_pos;
-	int aklass, vklass;
-	int array_slot_addr;
-	MonoType *int_type = mono_get_int_type ();
-	MonoType *object_type_byref = mono_class_get_byref_type (mono_defaults.object_class);
-	aklass = mono_mb_add_local (mb, int_type);
-	vklass = mono_mb_add_local (mb, int_type);
-	array_slot_addr = mono_mb_add_local (mb, object_type_byref);
-	/*
-	the method:
-	<ldelema (bound check)>
-	if (!value)
-		goto store;
-	aklass = array->vtable->m_class_get_element_class (klass);
-	vklass = value->vtable->klass;
-	if (vklass->idepth < aklass->idepth)
-		goto long;
-	if (vklass->supertypes [aklass->idepth - 1] != aklass)
-		goto long;
-	store:
-		*array_slot_addr = value;
-		return;
-	long:
-		if (mono_object_isinst (value, aklass))
-			goto store;
-		throw new ArrayTypeMismatchException ();
-	*/
-	/* ldelema (implicit bound check) */
-	mono_mb_emit_ldarg (mb, 0);
-	mono_mb_emit_ldarg (mb, 1);
-	mono_mb_emit_op (mb, CEE_LDELEMA, mono_defaults.object_class);
-	mono_mb_emit_stloc (mb, array_slot_addr);
-	/* if (!value) goto do_store */
-	mono_mb_emit_ldarg (mb, 2);
-	b1 = mono_mb_emit_branch (mb, CEE_BRFALSE);
-	/* aklass = array->vtable->klass->element_class */
-	mono_mb_emit_ldarg (mb, 0);
-	mono_mb_emit_ldflda (mb, MONO_STRUCT_OFFSET (MonoObject, vtable));
-	mono_mb_emit_byte (mb, CEE_LDIND_I);
-	mono_mb_emit_ldflda (mb, MONO_STRUCT_OFFSET (MonoVTable, klass));
-	mono_mb_emit_byte (mb, CEE_LDIND_I);
-	mono_mb_emit_ldflda (mb, GINTPTR_TO_INT32 (m_class_offsetof_element_class ()));
-	mono_mb_emit_byte (mb, CEE_LDIND_I);
-	mono_mb_emit_stloc (mb, aklass);
-	/* vklass = value->vtable->klass */
-	mono_mb_emit_ldarg (mb, 2);
-	mono_mb_emit_ldflda (mb, MONO_STRUCT_OFFSET (MonoObject, vtable));
-	mono_mb_emit_byte (mb, CEE_LDIND_I);
-	mono_mb_emit_ldflda (mb, MONO_STRUCT_OFFSET (MonoVTable, klass));
-	mono_mb_emit_byte (mb, CEE_LDIND_I);
-	mono_mb_emit_stloc (mb, vklass);
-	/* if (vklass->idepth < aklass->idepth) goto failue */
-	mono_mb_emit_ldloc (mb, vklass);
-	mono_mb_emit_ldflda (mb, GINTPTR_TO_INT32 (m_class_offsetof_idepth ()));
-	mono_mb_emit_byte (mb, CEE_LDIND_U2);
-	mono_mb_emit_ldloc (mb, aklass);
-	mono_mb_emit_ldflda (mb, GINTPTR_TO_INT32 (m_class_offsetof_idepth ()));
-	mono_mb_emit_byte (mb, CEE_LDIND_U2);
-	b2 = mono_mb_emit_branch (mb, CEE_BLT_UN);
-	/* if (vklass->supertypes [aklass->idepth - 1] != aklass) goto failure */
-	mono_mb_emit_ldloc (mb, vklass);
-	mono_mb_emit_ldflda (mb, GINTPTR_TO_INT32 (m_class_offsetof_supertypes ()));
-	mono_mb_emit_byte (mb, CEE_LDIND_I);
-	mono_mb_emit_ldloc (mb, aklass);
-	mono_mb_emit_ldflda (mb, GINTPTR_TO_INT32 (m_class_offsetof_idepth ()));
-	mono_mb_emit_byte (mb, CEE_LDIND_U2);
-	mono_mb_emit_icon (mb, 1);
-	mono_mb_emit_byte (mb, CEE_SUB);
-	mono_mb_emit_icon (mb, TARGET_SIZEOF_VOID_P);
-	mono_mb_emit_byte (mb, CEE_MUL);
-	mono_mb_emit_byte (mb, CEE_ADD);
-	mono_mb_emit_byte (mb, CEE_LDIND_I);
-	mono_mb_emit_ldloc (mb, aklass);
-	b3 = mono_mb_emit_branch (mb, CEE_BNE_UN);
-	copy_pos = mono_mb_get_label (mb);
-	/* do_store */
-	mono_mb_patch_branch (mb, b1);
-	mono_mb_emit_ldloc (mb, array_slot_addr);
-	mono_mb_emit_ldarg (mb, 2);
-	mono_mb_emit_byte (mb, CEE_STIND_REF);
-	mono_mb_emit_byte (mb, CEE_RET);
-	/* the hard way */
-	mono_mb_patch_branch (mb, b2);
-	mono_mb_patch_branch (mb, b3);
-	mono_mb_emit_ldarg (mb, 2);
-	mono_mb_emit_ldloc (mb, aklass);
-	mono_mb_emit_icall (mb, mono_object_isinst_icall);
-	b4 = mono_mb_emit_branch (mb, CEE_BRTRUE);
-	mono_mb_patch_addr (mb, b4, copy_pos - (b4 + 4));
-	mono_mb_emit_exception (mb, "ArrayTypeMismatchException", NULL);
-	mono_mb_emit_byte (mb, CEE_RET);
-}
-static void
-mb_emit_byte_ilgen (MonoMethodBuilder *mb, guint8 op)
-{
-	mono_mb_emit_byte (mb, op);
-}
-static void
-emit_array_address_ilgen (MonoMethodBuilder *mb, int rank, int elem_size)
-{
-	int i, bounds, ind, realidx;
-	int branch_pos, *branch_positions;
-	MonoType *int_type = mono_get_int_type ();
-	MonoType *int32_type = mono_get_int32_type ();
-	branch_positions = g_new0 (int, rank);
-	bounds = mono_mb_add_local (mb, int_type);
-	ind = mono_mb_add_local (mb, int32_type);
-	realidx = mono_mb_add_local (mb, int32_type);
-	/* bounds = array->bounds; */
-	mono_mb_emit_ldarg (mb, 0);
-	mono_mb_emit_ldflda (mb, MONO_STRUCT_OFFSET (MonoArray, bounds));
-	mono_mb_emit_byte (mb, CEE_LDIND_I);
-	mono_mb_emit_stloc (mb, bounds);
-	/* ind is the overall element index, realidx is the partial index in a single dimension */
-	/* ind = idx0 - bounds [0].lower_bound */
-	mono_mb_emit_ldarg (mb, 1);
-	mono_mb_emit_ldloc (mb, bounds);
-	mono_mb_emit_icon (mb, MONO_STRUCT_OFFSET (MonoArrayBounds, lower_bound));
-	mono_mb_emit_byte (mb, CEE_ADD);
-	mono_mb_emit_byte (mb, CEE_LDIND_I4);
-	mono_mb_emit_byte (mb, CEE_SUB);
-	mono_mb_emit_stloc (mb, ind);
-	/* if (ind >= bounds [0].length) goto exception; */
-	mono_mb_emit_ldloc (mb, ind);
-	mono_mb_emit_ldloc (mb, bounds);
-	mono_mb_emit_icon (mb, MONO_STRUCT_OFFSET (MonoArrayBounds, length));
-	mono_mb_emit_byte (mb, CEE_ADD);
-	mono_mb_emit_byte (mb, CEE_LDIND_I4);
-	/* note that we use unsigned comparison */
-	branch_pos = mono_mb_emit_branch (mb, CEE_BGE_UN);
- 	/* For large ranks (> 4?) use a loop n IL later to reduce code size.
-	 * We could also decide to ignore the passed elem_size and get it
-	 * from the array object, to reduce the number of methods we generate:
-	 * the additional cost is 3 memory loads and a non-immediate mul.
-	 */
-	for (i = 1; i < rank; ++i) {
-		/* realidx = idxi - bounds [i].lower_bound */
-		mono_mb_emit_ldarg (mb, 1 + i);
-		mono_mb_emit_ldloc (mb, bounds);
-		mono_mb_emit_icon (mb, (i * sizeof (MonoArrayBounds)) + MONO_STRUCT_OFFSET (MonoArrayBounds, lower_bound));
-		mono_mb_emit_byte (mb, CEE_ADD);
-		mono_mb_emit_byte (mb, CEE_LDIND_I4);
-		mono_mb_emit_byte (mb, CEE_SUB);
-		mono_mb_emit_stloc (mb, realidx);
-		/* if (realidx >= bounds [i].length) goto exception; */
-		mono_mb_emit_ldloc (mb, realidx);
-		mono_mb_emit_ldloc (mb, bounds);
-		mono_mb_emit_icon (mb, (i * sizeof (MonoArrayBounds)) + MONO_STRUCT_OFFSET (MonoArrayBounds, length));
-		mono_mb_emit_byte (mb, CEE_ADD);
-		mono_mb_emit_byte (mb, CEE_LDIND_I4);
-		branch_positions [i] = mono_mb_emit_branch (mb, CEE_BGE_UN);
-		/* ind = ind * bounds [i].length + realidx */
-		mono_mb_emit_ldloc (mb, ind);
-		mono_mb_emit_ldloc (mb, bounds);
-		mono_mb_emit_icon (mb, (i * sizeof (MonoArrayBounds)) + MONO_STRUCT_OFFSET (MonoArrayBounds, length));
-		mono_mb_emit_byte (mb, CEE_ADD);
-		mono_mb_emit_byte (mb, CEE_LDIND_I4);
-		mono_mb_emit_byte (mb, CEE_MUL);
-		mono_mb_emit_ldloc (mb, realidx);
-		mono_mb_emit_byte (mb, CEE_ADD);
-		mono_mb_emit_stloc (mb, ind);
-	}
-	/* return array->vector + ind * element_size */
-	mono_mb_emit_ldarg (mb, 0);
-	mono_mb_emit_ldflda (mb, MONO_STRUCT_OFFSET (MonoArray, vector));
-	mono_mb_emit_ldloc (mb, ind);
-	if (elem_size) {
-		mono_mb_emit_icon (mb, elem_size);
-	} else {
-		/* Load arr->vtable->klass->sizes.element_class */
-		mono_mb_emit_ldarg (mb, 0);
-		mono_mb_emit_byte (mb, CEE_CONV_I);
-		mono_mb_emit_icon (mb, MONO_STRUCT_OFFSET (MonoObject, vtable));
-		mono_mb_emit_byte (mb, CEE_ADD);
-		mono_mb_emit_byte (mb, CEE_LDIND_I);
-		mono_mb_emit_icon (mb, MONO_STRUCT_OFFSET (MonoVTable, klass));
-		mono_mb_emit_byte (mb, CEE_ADD);
-		mono_mb_emit_byte (mb, CEE_LDIND_I);
-		/* sizes is an union, so this reads sizes.element_size */
-		mono_mb_emit_icon (mb, GINTPTR_TO_INT32 (m_class_offsetof_sizes ()));
-		mono_mb_emit_byte (mb, CEE_ADD);
-		mono_mb_emit_byte (mb, CEE_LDIND_I4);
-	}
-		mono_mb_emit_byte (mb, CEE_MUL);
-	mono_mb_emit_byte (mb, CEE_ADD);
-	mono_mb_emit_byte (mb, CEE_RET);
-	/* patch the branches to get here and throw */
-	for (i = 1; i < rank; ++i) {
-		mono_mb_patch_branch (mb, branch_positions [i]);
-	}
-	mono_mb_patch_branch (mb, branch_pos);
-	/* throw exception */
-	mono_mb_emit_exception (mb, "IndexOutOfRangeException", NULL);
-	g_free (branch_positions);
-}
-static void
-emit_delegate_begin_invoke_ilgen (MonoMethodBuilder *mb, MonoMethodSignature *sig)
-{
-	int params_var;
-	params_var = mono_mb_emit_save_args (mb, sig, FALSE);
-	mono_mb_emit_ldarg (mb, 0);
-	mono_mb_emit_ldloc (mb, params_var);
-	mono_mb_emit_icall (mb, mono_delegate_begin_invoke);
-	mono_mb_emit_byte (mb, CEE_RET);
-}
-static void
-emit_delegate_end_invoke_ilgen (MonoMethodBuilder *mb, MonoMethodSignature *sig)
-{
-	int params_var;
-	params_var = mono_mb_emit_save_args (mb, sig, FALSE);
-	mono_mb_emit_ldarg (mb, 0);
-	mono_mb_emit_ldloc (mb, params_var);
-	mono_mb_emit_icall (mb, mono_delegate_end_invoke);
-	if (sig->ret->type == MONO_TYPE_VOID) {
-		mono_mb_emit_byte (mb, CEE_POP);
-		mono_mb_emit_byte (mb, CEE_RET);
-	} else
-		mono_mb_emit_restore_result (mb, sig->ret);
-}
-#define MONO_TYPE_IS_PRIMITIVE(t) ((!m_type_is_byref ((t)) && ((((t)->type >= MONO_TYPE_BOOLEAN && (t)->type <= MONO_TYPE_R8) || ((t)->type >= MONO_TYPE_I && (t)->type <= MONO_TYPE_U)))))
-static void
-emit_delegate_invoke_internal_ilgen (MonoMethodBuilder *mb, MonoMethodSignature *sig, MonoMethodSignature *invoke_sig, MonoMethodSignature *target_method_sig, gboolean static_method_with_first_arg_bound, gboolean callvirt, gboolean closed_over_null, MonoMethod *method, MonoMethod *target_method, MonoGenericContext *ctx, MonoGenericContainer *container)
-{
-	int local_i, local_len, local_delegates, local_d, local_target, local_res = 0;
-	int pos0, pos1, pos2;
-	int i;
-	gboolean void_ret;
-	MonoType *int32_type = mono_get_int32_type ();
-	MonoType *object_type = mono_get_object_type ();
-	void_ret = sig->ret->type == MONO_TYPE_VOID && !method->string_ctor;
-	/* allocate local 0 (object) */
-	local_i = mono_mb_add_local (mb, int32_type);
-	local_len = mono_mb_add_local (mb, int32_type);
-	local_delegates = mono_mb_add_local (mb, m_class_get_byval_arg (mono_defaults.array_class));
-	local_d = mono_mb_add_local (mb, m_class_get_byval_arg (mono_defaults.multicastdelegate_class));
-	local_target = mono_mb_add_local (mb, object_type);
-	if (!void_ret)
-		local_res = mono_mb_add_local (mb, sig->ret);
-	g_assert (sig->hasthis);
-	/*
-	 * {type: sig->ret} res;
-	 * if (delegates == null) {
-	 *     return this.<target> ( args .. );
-	 * } else {
-	 *     int i = 0, len = this.delegates.Length;
-	 *     do {
-	 *         res = this.delegates [i].Invoke ( args .. );
-	 *     } while (++i < len);
-	 *     return res;
-	 * }
-	 */
-	/* this wrapper can be used in unmanaged-managed transitions */
-	emit_thread_interrupt_checkpoint (mb);
-	/* delegates = this.delegates */
-	mono_mb_emit_ldarg (mb, 0);
-	mono_mb_emit_ldflda (mb, MONO_STRUCT_OFFSET (MonoMulticastDelegate, delegates));
-	mono_mb_emit_byte (mb, CEE_LDIND_REF);
-	mono_mb_emit_stloc (mb, local_delegates);
-	/* if (delegates == null) */
-	mono_mb_emit_ldloc (mb, local_delegates);
-	pos2 = mono_mb_emit_branch (mb, CEE_BRTRUE);
-	/* return target.<target_method|method_ptr> ( args .. ); */
-	/* target = d.target; */
-	mono_mb_emit_ldarg (mb, 0);
-	mono_mb_emit_ldflda (mb, MONO_STRUCT_OFFSET (MonoDelegate, target));
-	mono_mb_emit_byte (mb, CEE_LDIND_REF);
-	mono_mb_emit_stloc (mb, local_target);
-	/*static methods with bound first arg can have null target and still be bound*/
-	if (!static_method_with_first_arg_bound) {
-		/* if bound */
-		mono_mb_emit_ldarg (mb, 0);
-		mono_mb_emit_ldflda (mb, MONO_STRUCT_OFFSET (MonoDelegate, bound));
-		/* bound: MonoBoolean */
-		mono_mb_emit_byte (mb, CEE_LDIND_I1);
-		int pos_bound = mono_mb_emit_branch (mb, CEE_BRTRUE);
-		/* if target != null */
-		mono_mb_emit_ldloc (mb, local_target);
-		pos0 = mono_mb_emit_branch (mb, CEE_BRFALSE);
-		mono_mb_patch_branch (mb, pos_bound);
-		/* then call this->method_ptr nonstatic */
-		if (callvirt) {
-			mono_mb_emit_exception_full (mb, "System", "NotImplementedException", "");
-		} else {
-			mono_mb_emit_ldloc (mb, local_target);
-			for (i = 0; i < sig->param_count; ++i)
-				mono_mb_emit_ldarg (mb, i + 1);
-			mono_mb_emit_ldarg (mb, 0);
-			mono_mb_emit_ldflda (mb, MONO_STRUCT_OFFSET (MonoDelegate, extra_arg));
-			mono_mb_emit_byte (mb, CEE_LDIND_I);
-			mono_mb_emit_ldarg (mb, 0);
-			mono_mb_emit_byte (mb, MONO_CUSTOM_PREFIX);
-			mono_mb_emit_byte (mb, CEE_MONO_LD_DELEGATE_METHOD_PTR);
-			mono_mb_emit_byte (mb, MONO_CUSTOM_PREFIX);
-			mono_mb_emit_op (mb, CEE_MONO_CALLI_EXTRA_ARG, sig);
-			mono_mb_emit_byte (mb, CEE_RET);
-		}
-		/* else [target == null] call this->method_ptr static */
-		mono_mb_patch_branch (mb, pos0);
-	}
-	if (callvirt) {
-		if (!closed_over_null) {
-			for (i = 1; i <= sig->param_count; ++i) {
-				mono_mb_emit_ldarg (mb, i);
-				if (i == 1) {
-					MonoType *t = sig->params [0];
-					if (!m_type_is_byref (t))
-						mono_mb_emit_op (mb, CEE_BOX, mono_class_from_mono_type_internal (t));
-				}
-			}
-			mono_mb_emit_ldarg_addr (mb, 1);
-			mono_mb_emit_ldarg (mb, 0);
-			mono_mb_emit_icall (mb, mono_get_addr_compiled_method);
-			mono_mb_emit_op (mb, CEE_CALLI, target_method_sig);
-		} else {
-			mono_mb_emit_byte (mb, CEE_LDNULL);
-			for (i = 0; i < sig->param_count; ++i)
-				mono_mb_emit_ldarg (mb, i + 1);
-			mono_mb_emit_op (mb, CEE_CALL, target_method);
-		}
-	} else {
-		if (static_method_with_first_arg_bound) {
-			mono_mb_emit_ldloc (mb, local_target);
-			if (!MONO_TYPE_IS_REFERENCE (invoke_sig->params[0]))
-				mono_mb_emit_op (mb, CEE_UNBOX_ANY, mono_class_from_mono_type_internal (invoke_sig->params[0]));
-		}
-		for (i = 0; i < sig->param_count; ++i)
-			mono_mb_emit_ldarg (mb, i + 1);
-		mono_mb_emit_ldarg (mb, 0);
-		mono_mb_emit_ldflda (mb, MONO_STRUCT_OFFSET (MonoDelegate, extra_arg));
-		mono_mb_emit_byte (mb, CEE_LDIND_I);
-		mono_mb_emit_ldarg (mb, 0);
-		mono_mb_emit_byte (mb, MONO_CUSTOM_PREFIX);
-		mono_mb_emit_byte (mb, CEE_MONO_LD_DELEGATE_METHOD_PTR);
-		mono_mb_emit_byte (mb, MONO_CUSTOM_PREFIX);
-		mono_mb_emit_op (mb, CEE_MONO_CALLI_EXTRA_ARG, invoke_sig);
-	}
-	mono_mb_emit_byte (mb, CEE_RET);
-	/* else [delegates != null] */
-	mono_mb_patch_branch (mb, pos2);
-	/* len = delegates.Length; */
-	mono_mb_emit_ldloc (mb, local_delegates);
-	mono_mb_emit_byte (mb, CEE_LDLEN);
-	mono_mb_emit_byte (mb, CEE_CONV_I4);
-	mono_mb_emit_stloc (mb, local_len);
-	/* i = 0; */
-	mono_mb_emit_icon (mb, 0);
-	mono_mb_emit_stloc (mb, local_i);
-	pos1 = mono_mb_get_label (mb);
-	/* d = delegates [i]; */
-	mono_mb_emit_ldloc (mb, local_delegates);
-	mono_mb_emit_ldloc (mb, local_i);
-	mono_mb_emit_byte (mb, CEE_LDELEM_REF);
-	mono_mb_emit_stloc (mb, local_d);
-	/* res = d.Invoke ( args .. ); */
-	mono_mb_emit_ldloc (mb, local_d);
-	for (i = 0; i < sig->param_count; i++)
-		mono_mb_emit_ldarg (mb, i + 1);
-	if (!ctx) {
-		mono_mb_emit_op (mb, CEE_CALLVIRT, method);
-	} else {
-		ERROR_DECL (error);
-		mono_mb_emit_op (mb, CEE_CALLVIRT, mono_class_inflate_generic_method_checked (method, &container->context, error));
-		g_assert (is_ok (error)); /* FIXME don't swallow the error */
-	}
-	if (!void_ret)
-		mono_mb_emit_stloc (mb, local_res);
-	/* i += 1 */
-	mono_mb_emit_add_to_local (mb, GINT_TO_UINT16 (local_i), 1);
-	/* i < l */
-	mono_mb_emit_ldloc (mb, local_i);
-	mono_mb_emit_ldloc (mb, local_len);
-	mono_mb_emit_branch_label (mb, CEE_BLT, pos1);
-	/* return res */
-	if (!void_ret)
-		mono_mb_emit_ldloc (mb, local_res);
-	mono_mb_emit_byte (mb, CEE_RET);
-}
-static void
-mb_skip_visibility_ilgen (MonoMethodBuilder *mb)
-{
-	mb->skip_visibility = 1;
-}
-static void
-mb_inflate_wrapper_data_ilgen (MonoMethodBuilder *mb)
-{
-	g_assert (!mb->dynamic); // dynamic methods with inflated data not implemented yet - needs at least mono_free_method changes, probably more
-	mb->inflate_wrapper_data = TRUE;
-	int idx = mono_mb_add_data (mb, NULL);
-	g_assertf (idx == MONO_MB_ILGEN_INFLATE_WRAPPER_INFO_IDX, "mb_inflate_wrapper_data called after data already added");
-}
-static void
-emit_synchronized_wrapper_ilgen (MonoMethodBuilder *mb, MonoMethod *method, MonoGenericContext *ctx, MonoGenericContainer *container, MonoMethod *enter_method, MonoMethod *exit_method, MonoMethod *gettypefromhandle_method)
-{
-	int i, pos, pos2, this_local, taken_local, ret_local = 0;
-	MonoMethodSignature *sig = mono_method_signature_internal (method);
-	MonoExceptionClause *clause;
-	/* result */
-	if (!MONO_TYPE_IS_VOID (sig->ret))
-		ret_local = mono_mb_add_local (mb, sig->ret);
-	if (m_class_is_valuetype (method->klass) && !(method->flags & MONO_METHOD_ATTR_STATIC)) {
-		/* FIXME Is this really the best way to signal an error here?  Isn't this called much later after class setup? -AK */
-		mono_class_set_type_load_failure (method->klass, "");
-		/* This will throw the type load exception when the wrapper is compiled */
-		mono_mb_emit_byte (mb, CEE_LDNULL);
-		mono_mb_emit_op (mb, CEE_ISINST, method->klass);
-		mono_mb_emit_byte (mb, CEE_POP);
-		if (!MONO_TYPE_IS_VOID (sig->ret))
-			mono_mb_emit_ldloc (mb, ret_local);
-		mono_mb_emit_byte (mb, CEE_RET);
-		return;
-	}
-	MonoType *object_type = mono_get_object_type ();
-	MonoType *boolean_type = m_class_get_byval_arg (mono_defaults.boolean_class);
-	/* this */
-	this_local = mono_mb_add_local (mb, object_type);
-	taken_local = mono_mb_add_local (mb, boolean_type);
-	clause = (MonoExceptionClause *)mono_image_alloc0 (get_method_image (method), sizeof (MonoExceptionClause));
-	clause->flags = MONO_EXCEPTION_CLAUSE_FINALLY;
-	/* Push this or the type object */
-	if (method->flags & METHOD_ATTRIBUTE_STATIC) {
-		/* We have special handling for this in the JIT */
-		int index = mono_mb_add_data (mb, method->klass);
-		mono_mb_add_data (mb, mono_defaults.typehandle_class);
-		mono_mb_emit_byte (mb, CEE_LDTOKEN);
-		mono_mb_emit_i4 (mb, index);
-		mono_mb_emit_managed_call (mb, gettypefromhandle_method, NULL);
-	}
-	else
-		mono_mb_emit_ldarg (mb, 0);
-	mono_mb_emit_stloc (mb, this_local);
-	clause->try_offset = mono_mb_get_label (mb);
-	/* Call Monitor::Enter() */
-	mono_mb_emit_ldloc (mb, this_local);
-	mono_mb_emit_ldloc_addr (mb, taken_local);
-	mono_mb_emit_managed_call (mb, enter_method, NULL);
-	/* Call the method */
-	if (sig->hasthis)
-		mono_mb_emit_ldarg (mb, 0);
-	for (i = 0; i < sig->param_count; i++)
-		mono_mb_emit_ldarg (mb, i + (sig->hasthis == TRUE));
-	if (ctx) {
-		ERROR_DECL (error);
-		mono_mb_emit_managed_call (mb, mono_class_inflate_generic_method_checked (method, &container->context, error), NULL);
-		g_assert (is_ok (error)); /* FIXME don't swallow the error */
-	} else {
-		mono_mb_emit_managed_call (mb, method, NULL);
-	}
-	if (!MONO_TYPE_IS_VOID (sig->ret))
-		mono_mb_emit_stloc (mb, ret_local);
-	pos = mono_mb_emit_branch (mb, CEE_LEAVE);
-	clause->try_len = mono_mb_get_pos (mb) - clause->try_offset;
-	clause->handler_offset = mono_mb_get_label (mb);
-	/* Call Monitor::Exit() if needed */
-	mono_mb_emit_ldloc (mb, taken_local);
-	pos2 = mono_mb_emit_branch (mb, CEE_BRFALSE);
-	mono_mb_emit_ldloc (mb, this_local);
-	mono_mb_emit_managed_call (mb, exit_method, NULL);
-	mono_mb_patch_branch (mb, pos2);
-	mono_mb_emit_byte (mb, CEE_ENDFINALLY);
-	clause->handler_len = mono_mb_get_pos (mb) - clause->handler_offset;
-	mono_mb_patch_branch (mb, pos);
-	if (!MONO_TYPE_IS_VOID (sig->ret))
-		mono_mb_emit_ldloc (mb, ret_local);
-	mono_mb_emit_byte (mb, CEE_RET);
-	mono_mb_set_clauses (mb, 1, clause);
-}
-static void
-emit_unbox_wrapper_ilgen (MonoMethodBuilder *mb, MonoMethod *method)
-{
-	MonoMethodSignature *sig = mono_method_signature_internal (method);
-	mono_mb_emit_ldarg (mb, 0);
-	mono_mb_emit_icon (mb, MONO_ABI_SIZEOF (MonoObject));
-	mono_mb_emit_byte (mb, CEE_ADD);
-	for (int i = 0; i < sig->param_count; ++i)
-		mono_mb_emit_ldarg (mb, i + 1);
-	mono_mb_emit_managed_call (mb, method, NULL);
-	mono_mb_emit_byte (mb, CEE_RET);
-}
-static void
-emit_array_accessor_wrapper_ilgen (MonoMethodBuilder *mb, MonoMethod *method, MonoMethodSignature *sig, MonoGenericContext *ctx)
-{
-	MonoGenericContainer *container = NULL;
-	/* Call the method */
-	if (sig->hasthis)
-		mono_mb_emit_ldarg (mb, 0);
-	for (int i = 0; i < sig->param_count; i++)
-		mono_mb_emit_ldarg (mb, i + (sig->hasthis == TRUE));
-	if (ctx) {
-		ERROR_DECL (error);
-		mono_mb_emit_managed_call (mb, mono_class_inflate_generic_method_checked (method, &container->context, error), NULL);
-		g_assert (is_ok (error)); /* FIXME don't swallow the error */
-	} else {
-		mono_mb_emit_managed_call (mb, method, NULL);
-	}
-	mono_mb_emit_byte (mb, CEE_RET);
-}
-static gboolean
-unsafe_accessor_target_type_forbidden (MonoType *target_type);
-static void
-emit_unsafe_accessor_field_wrapper (MonoMethodBuilder *mb, gboolean inflate_generic_data, MonoMethod *accessor_method, MonoMethodSignature *sig, MonoUnsafeAccessorKind kind, const char *member_name)
-{
-	g_assert (kind == MONO_UNSAFE_ACCESSOR_FIELD || kind == MONO_UNSAFE_ACCESSOR_STATIC_FIELD);
-	g_assert (member_name != NULL);
-	MonoType *target_type = sig->param_count == 1 ? sig->params[0] : NULL; // params[0] is the field's parent
-	if (sig->param_count != 1 || target_type == NULL || sig->ret->type == MONO_TYPE_VOID || unsafe_accessor_target_type_forbidden (target_type)) {
-		mono_mb_emit_exception_full (mb, "System", "BadImageFormatException", "Invalid usage of UnsafeAccessorAttribute.");
-		return;
-	}
-	MonoType *ret_type = sig->ret;
-	MonoClass *target_class = mono_class_from_mono_type_internal (target_type);
-	gboolean target_byref = m_type_is_byref (target_type);
-	gboolean target_valuetype = m_class_is_valuetype (target_class);
-	gboolean ret_byref = m_type_is_byref (ret_type);
-	if (!ret_byref || (kind == MONO_UNSAFE_ACCESSOR_FIELD && target_valuetype && !target_byref)) {
-		mono_mb_emit_exception_full (mb, "System", "BadImageFormatException", "Invalid usage of UnsafeAccessorAttribute.");
-		return;
-	}
-	MonoClassField *target_field = mono_class_get_field_from_name_full (target_class, member_name, NULL);
-	if (target_field == NULL || !mono_metadata_type_equal_full (target_field->type, m_class_get_byval_arg (mono_class_from_mono_type_internal (ret_type)), MONO_TYPE_EQ_FLAGS_SIG_ONLY | MONO_TYPE_EQ_FLAG_IGNORE_CMODS)) {
-		mono_mb_emit_exception_full (mb, "System", "MissingFieldException",
-			g_strdup_printf("No '%s' in '%s'. Or the type of '%s' doesn't match", member_name, m_class_get_name (target_class), member_name));
-		return;
-	}
-	gboolean is_field_static = !!(target_field->type->attrs & FIELD_ATTRIBUTE_STATIC);
-	if ((kind == MONO_UNSAFE_ACCESSOR_FIELD && is_field_static) || (kind == MONO_UNSAFE_ACCESSOR_STATIC_FIELD && !is_field_static)) {
-		mono_mb_emit_exception_full (mb, "System", "MissingFieldException", g_strdup_printf("UnsafeAccessorKind does not match expected static modifier on field '%s' in '%s'", member_name, m_class_get_name (target_class)));
-		return;
-	}
-	if (is_field_static && m_field_get_parent (target_field) != target_class) {
-		mono_mb_emit_exception_full (mb, "System", "MissingFieldException", g_strdup_printf("Field '%s' not found in '%s'", member_name, m_class_get_name (target_class)));
-	}
-	if (kind == MONO_UNSAFE_ACCESSOR_FIELD)
-		mono_mb_emit_ldarg (mb, 0);
-	mono_mb_emit_op (mb, kind == MONO_UNSAFE_ACCESSOR_FIELD ? CEE_LDFLDA : CEE_LDSFLDA, target_field);
-	if (inflate_generic_data)
-		mono_mb_set_wrapper_data_kind (mb, MONO_MB_ILGEN_WRAPPER_DATA_FIELD);
-	mono_mb_emit_byte (mb, CEE_RET);
-}
-/*
- * Given an accessor method signature (where the first arg is a target class) creates the signature
- * of the expected member method (ie, with the first arg removed)
- */
-static MonoMethodSignature *
-method_sig_from_accessor_sig (MonoMethodBuilder *mb, gboolean hasthis, MonoMethodSignature *accessor_sig)
-{
-	MonoMethodSignature *ret = mono_metadata_signature_dup_full (get_method_image (mb->method), accessor_sig);
-	g_assert (ret->param_count > 0);
-	ret->hasthis = hasthis;
-	for (int i = 1; i < ret->param_count; i++)
-		ret->params [i - 1] = ret->params [i];
-	memset (&ret->params[ret->param_count - 1], 0, sizeof (MonoType*)); // just in case
-	ret->param_count--;
-	return ret;
-}
-/*
- * Given an accessor method signature (where the return type is a target class) creates the signature
- * of the expected constructor method (same args, but return type is void).
- */
-static MonoMethodSignature *
-ctor_sig_from_accessor_sig (MonoMethodBuilder *mb, MonoMethodSignature *accessor_sig)
-{
-	MonoMethodSignature *ret = mono_metadata_signature_dup_full (get_method_image (mb->method), accessor_sig);
-	ret->hasthis = TRUE; /* ctors are considered instance methods */
-	ret->ret = mono_get_void_type ();
-	return ret;
-}
-static void
-emit_unsafe_accessor_ldargs (MonoMethodBuilder *mb, MonoMethodSignature *accessor_sig, int skip_count)
-{
-	for (int i = skip_count; i < accessor_sig->param_count; i++)
-		mono_mb_emit_ldarg (mb, i);
-}
-static gboolean
-unsafe_accessor_target_type_forbidden (MonoType *target_type)
-{
-	switch (target_type->type)
-	{
-	case MONO_TYPE_VOID:
-	case MONO_TYPE_PTR:
-	case MONO_TYPE_FNPTR:
-	case MONO_TYPE_VAR:
-	case MONO_TYPE_MVAR:
-		return TRUE;
-	default:
-		return FALSE;
-	}
-}
-static void
-emit_missing_method_error (MonoMethodBuilder *mb, MonoError *failure, const char *display_member_name)
-{
-	if (!is_ok (failure)) {
-		mono_mb_emit_exception_full (mb, "System", "MissingMethodException", g_strdup_printf ("Could not find %s due to: %s", display_member_name, mono_error_get_message (failure)));
-	} else {
-		mono_mb_emit_exception_full (mb, "System", "MissingMethodException", g_strdup_printf ("Could not find %s", display_member_name));
-	}
-}
-static MonoMethod *
-inflate_method (MonoClass *klass, MonoMethod *method, MonoMethod *accessor_method, MonoError *error)
-{
-	MonoMethod *result = method;
-	MonoGenericContext context = { NULL, NULL };
-	if (mono_class_is_ginst (klass))
-		context.class_inst = mono_class_get_generic_class (klass)->context.class_inst;
-	if (accessor_method->is_inflated)
-		context.method_inst = mono_method_get_context (accessor_method)->method_inst;
-	if ((context.class_inst != NULL) || (context.method_inst != NULL))
-		result = mono_class_inflate_generic_method_checked (method, &context, error);
-	mono_error_assert_ok (error);
-	return result;
-}
-static void
-emit_unsafe_accessor_ctor_wrapper (MonoMethodBuilder *mb, gboolean inflate_generic_data, MonoMethod *accessor_method, MonoMethodSignature *sig, MonoUnsafeAccessorKind kind, const char *member_name)
-{
-	g_assert (kind == MONO_UNSAFE_ACCESSOR_CTOR);
-	if (!member_name || member_name[0] == '\0')
-		member_name = ".ctor";
-	if (strcmp (member_name, ".ctor") != 0) {
-		mono_mb_emit_exception_full (mb, "System", "BadImageFormatException", "Invalid UnsafeAccessorAttribute for constructor.");
-		return;
-	}
-	MonoType *target_type = sig->ret; // for constructors the return type is the target type
-	if (target_type == NULL || m_type_is_byref (target_type) || unsafe_accessor_target_type_forbidden (target_type)) {
-		mono_mb_emit_exception_full (mb, "System", "BadImageFormatException", "Invalid usage of UnsafeAccessorAttribute.");
-		return;
-	}
-	MonoClass *target_class = mono_class_from_mono_type_internal (target_type);
-	ERROR_DECL(find_method_error);
-	MonoMethodSignature *member_sig = ctor_sig_from_accessor_sig (mb, sig);
-	MonoClass *in_class = target_class;
-	MonoMethod *target_method = mono_unsafe_accessor_find_ctor (in_class, member_sig, target_class, find_method_error);
-	if (!is_ok (find_method_error) || target_method == NULL) {
-		if (mono_error_get_error_code (find_method_error) == MONO_ERROR_GENERIC)
-			mono_mb_emit_exception_for_error (mb, find_method_error);
-		else
-			emit_missing_method_error (mb, find_method_error, "constructor");
-		mono_error_cleanup (find_method_error);
-		return;
-	}
-	target_method = inflate_method (target_class, target_method, accessor_method, find_method_error);
-	g_assert (target_method->klass == target_class);
-	emit_unsafe_accessor_ldargs (mb, sig, 0);
-	mono_mb_emit_op (mb, CEE_NEWOBJ, target_method);
-	if (inflate_generic_data)
-		mono_mb_set_wrapper_data_kind (mb, MONO_MB_ILGEN_WRAPPER_DATA_METHOD);
-	mono_mb_emit_byte (mb, CEE_RET);
-}
-static void
-emit_unsafe_accessor_method_wrapper (MonoMethodBuilder *mb, gboolean inflate_generic_data, MonoMethod *accessor_method, MonoMethodSignature *sig, MonoUnsafeAccessorKind kind, const char *member_name)
-{
-	g_assert (kind == MONO_UNSAFE_ACCESSOR_METHOD || kind == MONO_UNSAFE_ACCESSOR_STATIC_METHOD);
-	g_assert (member_name != NULL);
-	gboolean ctor_as_method = !strcmp (member_name, ".ctor");
-	MonoType *target_type = sig->param_count >= 1 ? sig->params[0] : NULL;
-	if (sig->param_count < 1 || target_type == NULL || unsafe_accessor_target_type_forbidden (target_type)) {
-		mono_mb_emit_exception_full (mb, "System", "BadImageFormatException", "Invalid usage of UnsafeAccessorAttribute.");
-		return;
-	}
-	gboolean hasthis = kind == MONO_UNSAFE_ACCESSOR_METHOD;
-	MonoClass *target_class = mono_class_from_mono_type_internal (target_type);
-	if (hasthis && m_class_is_valuetype (target_class) && !m_type_is_byref (target_type)) {
-		mono_mb_emit_exception_full (mb, "System", "BadImageFormatException", "Invalid usage of UnsafeAccessorAttribute.");
-	}
-	ERROR_DECL(find_method_error);
-	MonoMethodSignature *member_sig = method_sig_from_accessor_sig (mb, hasthis, sig);
-	MonoClass *in_class = target_class;
-	MonoMethod *target_method = NULL;
-	if (!ctor_as_method)
-		target_method = mono_unsafe_accessor_find_method (in_class, member_name, member_sig, target_class, find_method_error);
-	else
-		target_method = mono_unsafe_accessor_find_ctor (in_class, member_sig, target_class, find_method_error);
-	if (!is_ok (find_method_error) || target_method == NULL) {
-		if (mono_error_get_error_code (find_method_error) == MONO_ERROR_GENERIC)
-			mono_mb_emit_exception_for_error (mb, find_method_error);
-		else
-			emit_missing_method_error (mb, find_method_error, member_name);
-		mono_error_cleanup (find_method_error);
-		return;
-	}
-	target_method = inflate_method (target_class, target_method, accessor_method, find_method_error);
-	if (!hasthis && target_method->klass != target_class) {
-		emit_missing_method_error (mb, find_method_error, member_name);
-		return;
-	}
-	g_assert (target_method->klass == target_class);
-	emit_unsafe_accessor_ldargs (mb, sig, !hasthis ? 1 : 0);
-	mono_mb_emit_op (mb, hasthis ? CEE_CALLVIRT : CEE_CALL, target_method);
-	if (inflate_generic_data)
-		mono_mb_set_wrapper_data_kind (mb, MONO_MB_ILGEN_WRAPPER_DATA_METHOD);
-	mono_mb_emit_byte (mb, CEE_RET);
-}
-static void
-emit_unsafe_accessor_wrapper_ilgen (MonoMethodBuilder *mb, gboolean inflate_generic_data, MonoMethod *accessor_method, MonoMethodSignature *sig, MonoUnsafeAccessorKind kind, const char *member_name)
-{
-	if (!m_method_is_static (accessor_method)) {
-		mono_mb_emit_exception_full (mb, "System", "BadImageFormatException", "UnsafeAccessor_NonStatic");
-		return;
-	}
-	switch (kind) {
-	case MONO_UNSAFE_ACCESSOR_FIELD:
-	case MONO_UNSAFE_ACCESSOR_STATIC_FIELD:
-		emit_unsafe_accessor_field_wrapper (mb, inflate_generic_data, accessor_method, sig, kind, member_name);
-		return;
-	case MONO_UNSAFE_ACCESSOR_CTOR:
-		emit_unsafe_accessor_ctor_wrapper (mb, inflate_generic_data, accessor_method, sig, kind, member_name);
-		return;
-	case MONO_UNSAFE_ACCESSOR_METHOD:
-	case MONO_UNSAFE_ACCESSOR_STATIC_METHOD:
-		emit_unsafe_accessor_method_wrapper (mb, inflate_generic_data, accessor_method, sig, kind, member_name);
-		return;
-	default:
-		mono_mb_emit_exception_full (mb, "System", "BadImageFormatException", "UnsafeAccessor_InvalidKindValue");
-		return;
-	}
-}
-static void
-emit_generic_array_helper_ilgen (MonoMethodBuilder *mb, MonoMethod *method, MonoMethodSignature *csig)
-{
-	mono_mb_emit_ldarg (mb, 0);
-	for (int i = 0; i < csig->param_count; i++)
-		mono_mb_emit_ldarg (mb, i + 1);
-	mono_mb_emit_managed_call (mb, method, NULL);
-	mono_mb_emit_byte (mb, CEE_RET);
-}
-static void
-emit_thunk_invoke_wrapper_ilgen (MonoMethodBuilder *mb, MonoMethod *method, MonoMethodSignature *csig)
-{
-	MonoImage *image = get_method_image (method);
-	MonoMethodSignature *sig = mono_method_signature_internal (method);
-	int param_count = sig->param_count + sig->hasthis + 1;
-	int pos_leave;
-	MonoExceptionClause *clause;
-	MonoType *object_type = mono_get_object_type ();
-#if defined (TARGET_WASM)
-	/* in the AOT compiler emit blocking transitions if --wasm-gc-safepoints was used */
-	#ifndef DISABLE_THREADS
-		const gboolean do_blocking_transition = TRUE;
-	#else
-		const gboolean do_blocking_transition = mono_opt_wasm_gc_safepoints;
-	#endif
-#else
-	const gboolean do_blocking_transition = TRUE;
-#endif
-	GCUnsafeTransitionBuilder gc_unsafe_builder = {0,};
-	if (do_blocking_transition)
-		gc_unsafe_transition_builder_init (&gc_unsafe_builder, mb, TRUE);
-	/* local 0 (temp for exception object) */
-	mono_mb_add_local (mb, object_type);
-	/* local 1 (temp for result) */
-	if (!MONO_TYPE_IS_VOID (sig->ret))
-		mono_mb_add_local (mb, sig->ret);
-	if (do_blocking_transition) {
-		gc_unsafe_transition_builder_add_vars (&gc_unsafe_builder);
-	}
-	/* clear exception arg */
-	mono_mb_emit_ldarg (mb, param_count - 1);
-	mono_mb_emit_byte (mb, CEE_LDNULL);
-	mono_mb_emit_byte (mb, CEE_STIND_REF);
-	if (do_blocking_transition) {
-		gc_unsafe_transition_builder_emit_enter (&gc_unsafe_builder);
-	}
-	/* try */
-	clause = (MonoExceptionClause *)mono_image_alloc0 (image, sizeof (MonoExceptionClause));
-	clause->try_offset = mono_mb_get_label (mb);
-	/* push method's args */
-	for (int i = 0; i < param_count - 1; i++) {
-		MonoType *type;
-		MonoClass *klass;
-		mono_mb_emit_ldarg (mb, i);
-		/* get the byval type of the param */
-		klass = mono_class_from_mono_type_internal (csig->params [i]);
-		type = m_class_get_byval_arg (klass);
-		/* unbox struct args */
-		if (MONO_TYPE_ISSTRUCT (type)) {
-			mono_mb_emit_op (mb, CEE_UNBOX, klass);
-			/* byref args & and the "this" arg must remain a ptr.
-			   Otherwise make a copy of the value type */
-			if (!(m_type_is_byref (csig->params [i]) || (i == 0 && sig->hasthis)))
-				mono_mb_emit_op (mb, CEE_LDOBJ, klass);
-			csig->params [i] = object_type;
-		}
-	}
-	/* call */
-	if (method->flags & METHOD_ATTRIBUTE_VIRTUAL)
-		mono_mb_emit_op (mb, CEE_CALLVIRT, method);
-	else
-		mono_mb_emit_op (mb, CEE_CALL, method);
-	/* save result at local 1 */
-	if (!MONO_TYPE_IS_VOID (sig->ret))
-		mono_mb_emit_stloc (mb, 1);
-	pos_leave = mono_mb_emit_branch (mb, CEE_LEAVE);
-	/* catch */
-	clause->flags = MONO_EXCEPTION_CLAUSE_NONE;
-	clause->try_len = mono_mb_get_pos (mb) - clause->try_offset;
-	clause->data.catch_class = mono_defaults.object_class;
-	clause->handler_offset = mono_mb_get_label (mb);
-	/* store exception at local 0 */
-	mono_mb_emit_stloc (mb, 0);
-	mono_mb_emit_ldarg (mb, param_count - 1);
-	mono_mb_emit_ldloc (mb, 0);
-	mono_mb_emit_byte (mb, CEE_STIND_REF);
-	mono_mb_emit_branch (mb, CEE_LEAVE);
-	clause->handler_len = mono_mb_get_pos (mb) - clause->handler_offset;
-	mono_mb_set_clauses (mb, 1, clause);
-	mono_mb_patch_branch (mb, pos_leave);
-	/* end-try */
-	if (!MONO_TYPE_IS_VOID (sig->ret)) {
-		mono_mb_emit_ldloc (mb, 1);
-		/* box the return value */
-		if (MONO_TYPE_ISSTRUCT (sig->ret))
-			mono_mb_emit_op (mb, CEE_BOX, mono_class_from_mono_type_internal (sig->ret));
-	}
-	if (do_blocking_transition) {
-		gc_unsafe_transition_builder_emit_exit (&gc_unsafe_builder);
-		gc_unsafe_transition_builder_cleanup (&gc_unsafe_builder);
-	}
-	mono_mb_emit_byte (mb, CEE_RET);
-}
-static gboolean
-emit_managed_wrapper_validate_signature (MonoMethodSignature* sig, MonoMarshalSpec** mspecs, MonoError* error)
-{
-	if (mspecs) {
-		for (int i = 0; i < sig->param_count; i ++) {
-			if (mspecs [i + 1] && mspecs [i + 1]->native == MONO_NATIVE_CUSTOM) {
-				if (!mspecs [i + 1]->data.custom_data.custom_name || *mspecs [i + 1]->data.custom_data.custom_name == '\0') {
-					mono_error_set_generic_error (error, "System", "TypeLoadException", "Missing ICustomMarshaler type");
-					return FALSE;
-				}
-				switch (sig->params[i]->type) {
-				case MONO_TYPE_OBJECT:
-				case MONO_TYPE_CLASS:
-				case MONO_TYPE_VALUETYPE:
-				case MONO_TYPE_ARRAY:
-				case MONO_TYPE_SZARRAY:
-				case MONO_TYPE_STRING:
-				case MONO_TYPE_BOOLEAN:
-					break;
-				default:
-					mono_error_set_generic_error (error, "System.Runtime.InteropServices", "MarshalDirectiveException", "custom marshalling of type %x is currently not supported", sig->params[i]->type);
-					return FALSE;
-				}
-			} else if (sig->params[i]->type == MONO_TYPE_VALUETYPE) {
-				MonoClass *klass = mono_class_from_mono_type_internal (sig->params [i]);
-				MonoMarshalType *marshal_type = mono_marshal_load_type_info (klass);
-				for (guint32 field_idx = 0; field_idx < marshal_type->num_fields; ++field_idx) {
-					if (marshal_type->fields [field_idx].mspec && marshal_type->fields [field_idx].mspec->native == MONO_NATIVE_CUSTOM) {
-						mono_error_set_type_load_class (error, klass, "Value type includes custom marshaled fields");
-						return FALSE;
-					}
-				}
-			}
-		}
-	}
-	return TRUE;
-}
-static void
-emit_swift_lowered_struct_load (MonoMethodBuilder *mb, MonoMethodSignature *csig, SwiftPhysicalLowering swift_lowering, int tmp_local, uint32_t csig_argnum)
-{
-	guint8 stind_op;
-	uint32_t offset = 0;
-	for (uint32_t idx_lowered = 0; idx_lowered < swift_lowering.num_lowered_elements; idx_lowered++) {
-		offset = swift_lowering.offsets [idx_lowered];
-		mono_mb_emit_ldloc_addr (mb, tmp_local);
-		mono_mb_emit_icon (mb, offset);
-		mono_mb_emit_byte (mb, CEE_ADD);
-		mono_mb_emit_ldarg (mb, csig_argnum + idx_lowered);
-		stind_op = mono_type_to_stind (csig->params [csig_argnum + idx_lowered]);
-		mono_mb_emit_byte (mb, stind_op);
-    }
-}
-/* Swift struct lowering handling causes csig to have additional arguments.
- * This function returns the index of the argument in the csig that corresponds to the argument in the original signature.
- */
-static int
-get_csig_argnum (int i, EmitMarshalContext* m)
-{
-	if (m->swift_sig_to_csig_mp) {
-		g_assert (i < m->sig->param_count);
-		int csig_argnum = m->swift_sig_to_csig_mp [i];
-		g_assert (csig_argnum >= 0 && csig_argnum < m->csig->param_count);
-		return csig_argnum;
-	}
-	return i;
-}
-static void
-emit_managed_wrapper_ilgen (MonoMethodBuilder *mb, MonoMethodSignature *invoke_sig, MonoMarshalSpec **mspecs, EmitMarshalContext* m, MonoMethod *method, MonoGCHandle target_handle, gboolean runtime_init_callback, MonoError *error)
-{
-	MonoMethodSignature *sig, *csig;
-	int i, *tmp_locals;
-	gboolean closed = FALSE;
-	GCUnsafeTransitionBuilder gc_unsafe_builder = {0,};
-	SwiftPhysicalLowering *swift_lowering = m->swift_lowering;
-	sig = m->sig;
-	csig = m->csig;
-	if (!sig->hasthis && sig->param_count != invoke_sig->param_count) {
-		/* Closed delegate */
-		if (sig->param_count != invoke_sig->param_count + 1) {
-			g_warning ("Closed delegate has incorrect number of arguments: %s.", mono_method_full_name (method, TRUE));
-			g_assert_not_reached ();
-		}
-		closed = TRUE;
-		/* Use a new signature without the first argument */
-		sig = mono_metadata_signature_dup (sig);
-		memmove (&sig->params [0], &sig->params [1], (sig->param_count - 1) * sizeof (MonoType*));
-		sig->param_count --;
-	}
-	if (!emit_managed_wrapper_validate_signature (sig, mspecs, error)) {
-		if (closed)
-			g_free (sig);
-		return;
-	}
-	MonoType *int_type = mono_get_int_type ();
-	MonoType *boolean_type = m_class_get_byval_arg (mono_defaults.boolean_class);
-	/* allocate local 0 (pointer) src_ptr */
-	mono_mb_add_local (mb, int_type);
-	/* allocate local 1 (pointer) dst_ptr */
-	mono_mb_add_local (mb, int_type);
-	/* allocate local 2 (boolean) delete_old */
-	mono_mb_add_local (mb, boolean_type);
-	if (!MONO_TYPE_IS_VOID(sig->ret)) {
-		/* allocate local 3 to store the return value */
-		mono_mb_add_local (mb, sig->ret);
-	}
-	if (MONO_TYPE_ISSTRUCT (sig->ret))
-		m->vtaddr_var = mono_mb_add_local (mb, int_type);
-	gc_unsafe_transition_builder_init (&gc_unsafe_builder, mb, TRUE);
-	gc_unsafe_transition_builder_add_vars (&gc_unsafe_builder);
-	/*
-	 * // does (STARTING|RUNNING|BLOCKING) -> RUNNING + set/switch domain
-	 * intptr_t attach_cookie;
-	 * intptr_t orig_domain = mono_threads_attach_coop (domain, &attach_cookie);
-	 * <interrupt check>
-	 *
-	 * ret = method (...);
-	 * // does RUNNING -> (RUNNING|BLOCKING) + unset/switch domain
-	 * mono_threads_detach_coop (orig_domain, &attach_cookie);
-	 *
-	 * return ret;
-	 */
-	/* delete_old = FALSE */
-	mono_mb_emit_icon (mb, 0);
-	mono_mb_emit_stloc (mb, 2);
-	/*
-	* Transformed into a direct icall when runtime init callback is enabled for a native-to-managed wrapper.
-	* This icall is special cased in the JIT so it can be called in native-to-managed wrapper before
-	* runtime has been initialized. On return, runtime must be fully initialized.
-	*/
-	if (runtime_init_callback)
-		mono_mb_emit_icall (mb, mono_dummy_runtime_init_callback);
-	gc_unsafe_transition_builder_emit_enter(&gc_unsafe_builder);
-	/* we first do all conversions */
-	tmp_locals = g_newa (int, sig->param_count);
-	for (i = 0; i < sig->param_count; i ++) {
-		MonoType *t = sig->params [i];
-		MonoMarshalSpec *spec = mspecs [i + 1];
-		int csig_argnum = get_csig_argnum (i, m);
-		if (spec && spec->native == MONO_NATIVE_CUSTOM) {
-			tmp_locals [i] = mono_emit_marshal (m, csig_argnum, t, mspecs [i + 1], 0,  &csig->params [csig_argnum], MARSHAL_ACTION_MANAGED_CONV_IN);
-		} else {
-			switch (t->type) {
-			case MONO_TYPE_VALUETYPE:
-				if (mono_method_signature_has_ext_callconv (csig, MONO_EXT_CALLCONV_SWIFTCALL)) {
-					if (swift_lowering [i].num_lowered_elements > 0) {
-						tmp_locals [i] = mono_mb_add_local (mb, sig->params [i]);
-						emit_swift_lowered_struct_load (mb, csig, swift_lowering [i], tmp_locals [i], csig_argnum);
-						break;
-					} else if (swift_lowering [i].by_reference) {
-						/* Structs passed by reference are handled during arg loading emission */
-						tmp_locals [i] = 0;
-						break;
-					}
-				} /* else fallthru */
-			case MONO_TYPE_OBJECT:
-			case MONO_TYPE_CLASS:
-			case MONO_TYPE_ARRAY:
-			case MONO_TYPE_SZARRAY:
-			case MONO_TYPE_STRING:
-			case MONO_TYPE_BOOLEAN:
-				tmp_locals [i] = mono_emit_marshal (m, csig_argnum, t, mspecs [i + 1], 0, &csig->params [csig_argnum], MARSHAL_ACTION_MANAGED_CONV_IN);
-				break;
-			default:
-				tmp_locals [i] = 0;
-				break;
-			}
-		}
-	}
-	if (sig->hasthis) {
-		if (target_handle) {
-			mono_mb_emit_icon8 (mb, (gint64)target_handle);
-			mono_mb_emit_byte (mb, CEE_CONV_I);
-			mono_mb_emit_icall (mb, mono_gchandle_get_target_internal);
-		} else {
-			/* fixme: */
-			g_assert_not_reached ();
-		}
-	} else if (closed) {
-		mono_mb_emit_icon8 (mb, (gint64)target_handle);
-		mono_mb_emit_byte (mb, CEE_CONV_I);
-		mono_mb_emit_icall (mb, mono_gchandle_get_target_internal);
-	}
-	for (i = 0; i < sig->param_count; i++) {
-		MonoType *t = sig->params [i];
-		int csig_argnum = get_csig_argnum (i, m);
-		if (mono_method_signature_has_ext_callconv (csig, MONO_EXT_CALLCONV_SWIFTCALL) && swift_lowering [i].by_reference) {
-			mono_mb_emit_ldarg (mb, csig_argnum);
-			MonoClass* klass = mono_class_from_mono_type_internal (sig->params [i]);
-			mono_mb_emit_op (mb, CEE_LDOBJ, klass);
-		} else if (tmp_locals [i]) {
-			if (m_type_is_byref (t))
-				mono_mb_emit_ldloc_addr (mb, tmp_locals [i]);
-			else
-				mono_mb_emit_ldloc (mb, tmp_locals [i]);
-		} else
-			mono_mb_emit_ldarg (mb, csig_argnum);
-	}
-	/* ret = method (...) */
-	mono_mb_emit_managed_call (mb, method, NULL);
-	if (MONO_TYPE_ISSTRUCT (sig->ret) && sig->ret->type != MONO_TYPE_GENERICINST) {
-		MonoClass *klass = mono_class_from_mono_type_internal (sig->ret);
-		mono_class_init_internal (klass);
-		if (!(mono_class_is_explicit_layout (klass) || m_class_is_blittable (klass))) {
-			/* TODO: marshal-lightweight: can this move to marshal-ilgen? */
-			/* This is used by get_marshal_cb ()->emit_marshal_vtype (), but it needs to go right before the call */
-			mono_mb_emit_byte (mb, MONO_CUSTOM_PREFIX);
-			mono_mb_emit_byte (mb, CEE_MONO_VTADDR);
-			mono_mb_emit_stloc (mb, m->vtaddr_var);
-		}
-	}
-	if (mspecs [0] && mspecs [0]->native == MONO_NATIVE_CUSTOM) {
-		mono_emit_marshal (m, 0, sig->ret, mspecs [0], 0, NULL, MARSHAL_ACTION_MANAGED_CONV_RESULT);
-	} else if (!m_type_is_byref (sig->ret)) {
-		switch (sig->ret->type) {
-		case MONO_TYPE_VOID:
-			break;
-		case MONO_TYPE_BOOLEAN:
-		case MONO_TYPE_I1:
-		case MONO_TYPE_U1:
-		case MONO_TYPE_CHAR:
-		case MONO_TYPE_I2:
-		case MONO_TYPE_U2:
-		case MONO_TYPE_I4:
-		case MONO_TYPE_U4:
-		case MONO_TYPE_I:
-		case MONO_TYPE_U:
-		case MONO_TYPE_PTR:
-		case MONO_TYPE_R4:
-		case MONO_TYPE_R8:
-		case MONO_TYPE_I8:
-		case MONO_TYPE_U8:
-		case MONO_TYPE_OBJECT:
-			mono_mb_emit_stloc (mb, 3);
-			break;
-		case MONO_TYPE_STRING:
-			csig->ret = int_type;
-			mono_emit_marshal (m, 0, sig->ret, mspecs [0], 0, NULL, MARSHAL_ACTION_MANAGED_CONV_RESULT);
-			break;
-		case MONO_TYPE_VALUETYPE:
-		case MONO_TYPE_CLASS:
-		case MONO_TYPE_SZARRAY:
-			mono_emit_marshal (m, 0, sig->ret, mspecs [0], 0, NULL, MARSHAL_ACTION_MANAGED_CONV_RESULT);
-			break;
-		case MONO_TYPE_GENERICINST: {
-			mono_mb_emit_byte (mb, CEE_POP);
-			break;
-		}
-		default:
-			g_warning ("return type 0x%02x unknown", sig->ret->type);
-			g_assert_not_reached ();
-		}
-	} else {
-		mono_mb_emit_stloc (mb, 3);
-	}
-	/* Convert byref arguments back */
-	for (i = 0; i < sig->param_count; i ++) {
-		MonoType *t = sig->params [i];
-		MonoMarshalSpec *spec = mspecs [i + 1];
-		if (spec && spec->native == MONO_NATIVE_CUSTOM) {
-			mono_emit_marshal (m, i, t, mspecs [i + 1], tmp_locals [i], NULL, MARSHAL_ACTION_MANAGED_CONV_OUT);
-		}
-		else if (m_type_is_byref (t)) {
-			switch (t->type) {
-			case MONO_TYPE_CLASS:
-			case MONO_TYPE_VALUETYPE:
-			case MONO_TYPE_OBJECT:
-			case MONO_TYPE_STRING:
-			case MONO_TYPE_BOOLEAN:
-				mono_emit_marshal (m, i, t, mspecs [i + 1], tmp_locals [i], NULL, MARSHAL_ACTION_MANAGED_CONV_OUT);
-				break;
-			default:
-				break;
-			}
-		}
-		else if (invoke_sig->params [i]->attrs & PARAM_ATTRIBUTE_OUT) {
-			/* The [Out] information is encoded in the delegate signature */
-			switch (t->type) {
-			case MONO_TYPE_SZARRAY:
-			case MONO_TYPE_CLASS:
-			case MONO_TYPE_VALUETYPE:
-			case MONO_TYPE_PTR:
-			case MONO_TYPE_I:
-				mono_emit_marshal (m, i, invoke_sig->params [i], mspecs [i + 1], tmp_locals [i], NULL, MARSHAL_ACTION_MANAGED_CONV_OUT);
-				break;
-			default:
-				g_assert_not_reached ();
-			}
-		}
-	}
-	gc_unsafe_transition_builder_emit_exit (&gc_unsafe_builder);
-	gc_unsafe_transition_builder_cleanup (&gc_unsafe_builder);
-	/* return ret; */
-	if (m->retobj_var) {
-		mono_mb_emit_ldloc (mb, m->retobj_var);
-		mono_mb_emit_byte (mb, MONO_CUSTOM_PREFIX);
-		mono_mb_emit_op (mb, CEE_MONO_RETOBJ, m->retobj_class);
-	}
-	else {
-		if (!MONO_TYPE_IS_VOID (sig->ret))
-			mono_mb_emit_ldloc (mb, 3);
-		mono_mb_emit_byte (mb, CEE_RET);
-	}
-	if (closed)
-		g_free (sig);
-}
-static void
-emit_struct_to_ptr_ilgen (MonoMethodBuilder *mb, MonoClass *klass)
-{
-	MonoType *int_type = mono_get_int_type ();
-	MonoType *boolean_type = m_class_get_byval_arg (mono_defaults.boolean_class);
-	if (m_class_is_blittable (klass)) {
-		mono_mb_emit_byte (mb, CEE_LDARG_1);
-		mono_mb_emit_byte (mb, CEE_LDARG_0);
-		mono_mb_emit_ldflda (mb, MONO_ABI_SIZEOF (MonoObject));
-		mono_mb_emit_icon (mb, mono_class_value_size (klass, NULL));
-		mono_mb_emit_byte (mb, CEE_PREFIX1);
-		mono_mb_emit_byte (mb, CEE_CPBLK);
-	} else {
-		/* allocate local 0 (pointer) src_ptr */
-		mono_mb_add_local (mb, int_type);
-		/* allocate local 1 (pointer) dst_ptr */
-		mono_mb_add_local (mb, int_type);
-		/* allocate local 2 (boolean) delete_old */
-		mono_mb_add_local (mb, boolean_type);
-		mono_mb_emit_byte (mb, CEE_LDARG_2);
-		mono_mb_emit_stloc (mb, 2);
-		/* initialize src_ptr to point to the start of object data */
-		mono_mb_emit_byte (mb, CEE_LDARG_0);
-		mono_mb_emit_ldflda (mb, MONO_ABI_SIZEOF (MonoObject));
-		mono_mb_emit_stloc (mb, 0);
-		/* initialize dst_ptr */
-		mono_mb_emit_byte (mb, CEE_LDARG_1);
-		mono_mb_emit_stloc (mb, 1);
-		mono_marshal_shared_emit_struct_conv (mb, klass, FALSE);
-	}
-	mono_mb_emit_byte (mb, CEE_RET);
-}
-static void
-emit_ptr_to_struct_ilgen (MonoMethodBuilder *mb, MonoClass *klass)
-{
-	MonoType *int_type = mono_get_int_type ();
-	if (m_class_is_blittable (klass)) {
-		mono_mb_emit_byte (mb, CEE_LDARG_1);
-		mono_mb_emit_ldflda (mb, MONO_ABI_SIZEOF (MonoObject));
-		mono_mb_emit_byte (mb, CEE_LDARG_0);
-		mono_mb_emit_icon (mb, mono_class_value_size (klass, NULL));
-		mono_mb_emit_byte (mb, CEE_PREFIX1);
-		mono_mb_emit_byte (mb, CEE_CPBLK);
-	} else {
-		/* allocate local 0 (pointer) src_ptr */
-		mono_mb_add_local (mb, int_type);
-		/* allocate local 1 (pointer) dst_ptr */
-		mono_mb_add_local (mb, m_class_get_this_arg (klass));
-		/* initialize src_ptr to point to the start of object data */
-		mono_mb_emit_byte (mb, CEE_LDARG_0);
-		mono_mb_emit_stloc (mb, 0);
-		/* initialize dst_ptr */
-		mono_mb_emit_byte (mb, CEE_LDARG_1);
-		mono_mb_emit_ldflda (mb, MONO_ABI_SIZEOF (MonoObject));
-		mono_mb_emit_stloc (mb, 1);
-		mono_marshal_shared_emit_struct_conv (mb, klass, TRUE);
-	}
-	mono_mb_emit_byte (mb, CEE_RET);
-}
-static void
-emit_create_string_hack_ilgen (MonoMethodBuilder *mb, MonoMethodSignature *csig, MonoMethod *res)
-{
-	int i;
-	g_assert (!mono_method_signature_internal (res)->hasthis);
-	for (i = 1; i <= csig->param_count; i++)
-		mono_mb_emit_ldarg (mb, i);
-	mono_mb_emit_managed_call (mb, res, NULL);
-	mono_mb_emit_byte (mb, CEE_RET);
-}
-/* How the arguments of an icall should be wrapped */
-typedef enum {
-	/* Don't wrap at all, pass the argument as is */
-	ICALL_HANDLES_WRAP_NONE,
-	/* Wrap the argument in an object handle, pass the handle to the icall */
-	ICALL_HANDLES_WRAP_OBJ,
-	/* Wrap the argument in an object handle, pass the handle to the icall,
-	   write the value out from the handle when the icall returns */
-	ICALL_HANDLES_WRAP_OBJ_INOUT,
-	/* Initialized an object handle to null, pass to the icalls,
-	   write the value out from the handle when the icall returns */
-	ICALL_HANDLES_WRAP_OBJ_OUT,
-	/* Wrap the argument (a valuetype reference) in a handle to pin its
-	   enclosing object, but pass the raw reference to the icall.  This is
-	   also how we pass byref generic parameter arguments to generic method
-	   icalls (e.g. System.Array:GetGenericValue_icall<T>(int idx, T out value)) */
-	ICALL_HANDLES_WRAP_VALUETYPE_REF,
-} IcallHandlesWrap;
-typedef struct {
-	IcallHandlesWrap wrap;
-	int handle;
-}  IcallHandlesLocal;
-/*
- * Describes how to wrap the given parameter.
- *
- */
-static IcallHandlesWrap
-signature_param_uses_handles (MonoMethodSignature *sig, MonoMethodSignature *generic_sig, int param)
-{
-	/* If there is a generic parameter that isn't passed byref, we don't
-	 * know how to pass it to an icall that expects some arguments to be
-	 * wrapped in handles: if the actual argument type is a reference type
-	 * we'd need to wrap it in a handle, otherwise we'd want to pass it as is.
-	 */
-	/* FIXME: We should eventually relax the assertion, below, to
-	 * allow generic parameters that are constrained to be reference types.
-	 */
-	g_assert (!generic_sig || !mono_type_is_generic_parameter (generic_sig->params [param]));
-	/* If the parameter in the generic version of the method signature is a
-	 * byref type variable T&, pass the corresponding argument by pinning
-	 * the memory and passing the raw pointer to the icall.  Note that we
-	 * do this even if the actual instantiation is a byref reference type
-	 * like string& since the C code for the icall has to work uniformly
-	 * for both valuetypes and reference types.
-	 */
-	if (generic_sig && m_type_is_byref (generic_sig->params [param]) &&
-	    (generic_sig->params [param]->type == MONO_TYPE_VAR || generic_sig->params [param]->type == MONO_TYPE_MVAR))
-		return ICALL_HANDLES_WRAP_VALUETYPE_REF;
-	if (MONO_TYPE_IS_REFERENCE (sig->params [param])) {
-		if (mono_signature_param_is_out (sig, param))
-			return ICALL_HANDLES_WRAP_OBJ_OUT;
-		else if (m_type_is_byref (sig->params [param]))
-			return ICALL_HANDLES_WRAP_OBJ_INOUT;
-		else
-			return ICALL_HANDLES_WRAP_OBJ;
-	} else if (m_type_is_byref (sig->params [param]))
-		return ICALL_HANDLES_WRAP_VALUETYPE_REF;
-	else
-		return ICALL_HANDLES_WRAP_NONE;
-}
-static void
-emit_native_icall_wrapper_ilgen (MonoMethodBuilder *mb, MonoMethod *method, MonoMethodSignature *csig, gboolean check_exceptions, gboolean aot, MonoMethodPInvoke *piinfo)
-{
-	MonoMethodSignature *call_sig = csig;
-	gboolean uses_handles = FALSE;
-	gboolean foreign_icall = FALSE;
-	IcallHandlesLocal *handles_locals = NULL;
-	MonoMethodSignature *sig = mono_method_signature_internal (method);
-	gboolean need_gc_safe = FALSE;
-	GCSafeTransitionBuilder gc_safe_transition_builder;
-	(void) mono_lookup_internal_call_full (method, FALSE, &uses_handles, &foreign_icall);
-	if (G_UNLIKELY (foreign_icall)) {
-		/* FIXME: we only want the transitions for hybrid suspend.  Q: What to do about AOT? */
-		need_gc_safe = gc_safe_transition_builder_init (&gc_safe_transition_builder, mb, FALSE);
-		if (need_gc_safe)
-			gc_safe_transition_builder_add_locals (&gc_safe_transition_builder);
-	}
-	if (sig->hasthis) {
-		/*
-		 * Add a null check since public icalls can be called with 'call' which
-		 * does no such check.
-		 */
-		mono_mb_emit_byte (mb, CEE_LDARG_0);
-		const int pos = mono_mb_emit_branch (mb, CEE_BRTRUE);
-		mono_mb_emit_exception (mb, "NullReferenceException", NULL);
-		mono_mb_patch_branch (mb, pos);
-	}
-	if (uses_handles) {
-		MonoMethodSignature *generic_sig = NULL;
-		if (method->is_inflated) {
-			ERROR_DECL (error);
-			MonoMethod *generic_method = ((MonoMethodInflated*)method)->declaring;
-			generic_sig = mono_method_signature_checked (generic_method, error);
-			mono_error_assert_ok (error);
-		}
-		call_sig = mono_metadata_signature_alloc (get_method_image (method), csig->param_count);
-		call_sig->param_count = csig->param_count;
-		call_sig->ret = csig->ret;
-		call_sig->pinvoke = csig->pinvoke;
-		/* TODO support adding wrappers to non-static struct methods */
-		g_assert (!sig->hasthis || !m_class_is_valuetype (mono_method_get_class (method)));
-		handles_locals = g_new0 (IcallHandlesLocal, csig->param_count);
-		for (int i = 0; i < csig->param_count; ++i) {
-			const IcallHandlesWrap w = signature_param_uses_handles (csig, generic_sig, i);
-			handles_locals [i].wrap = w;
-			int local = -1;
-			switch (w) {
-				case ICALL_HANDLES_WRAP_OBJ:
-				case ICALL_HANDLES_WRAP_OBJ_INOUT:
-				case ICALL_HANDLES_WRAP_OBJ_OUT:
-					call_sig->params [i] = mono_class_get_byref_type (mono_class_from_mono_type_internal (csig->params[i]));
-					break;
-				case ICALL_HANDLES_WRAP_NONE:
-				case ICALL_HANDLES_WRAP_VALUETYPE_REF:
-					call_sig->params [i] = csig->params [i];
-					break;
-				default:
-					g_assert_not_reached ();
-			}
-			switch (w) {
-				case ICALL_HANDLES_WRAP_OBJ_INOUT:
-				case ICALL_HANDLES_WRAP_OBJ_OUT:
-					local = mono_mb_add_local (mb, mono_get_object_type ());
-					if (!mb->volatile_locals) {
-						gpointer mem = mono_image_alloc0 (get_method_image (method), mono_bitset_alloc_size (csig->param_count + 1, 0));
-						mb->volatile_locals = mono_bitset_mem_new (mem, csig->param_count + 1, 0);
-					}
-					mono_bitset_set (mb->volatile_locals, local);
-					break;
-				case ICALL_HANDLES_WRAP_VALUETYPE_REF:
-				case ICALL_HANDLES_WRAP_OBJ:
-					if (!mb->volatile_args) {
-						gpointer mem = mono_image_alloc0 (get_method_image (method), mono_bitset_alloc_size (csig->param_count + 1, 0));
-						mb->volatile_args = mono_bitset_mem_new (mem, csig->param_count + 1, 0);
-					}
-					mono_bitset_set (mb->volatile_args, i);
-					break;
-				case ICALL_HANDLES_WRAP_NONE:
-					break;
-				default:
-					g_assert_not_reached ();
-			}
-			handles_locals [i].handle = local;
-			switch (w) {
-				case ICALL_HANDLES_WRAP_NONE:
-				case ICALL_HANDLES_WRAP_VALUETYPE_REF:
-					mono_mb_emit_ldarg (mb, i);
-					break;
-				case ICALL_HANDLES_WRAP_OBJ:
-					mono_mb_emit_ldarg_addr (mb, i);
-					break;
-				case ICALL_HANDLES_WRAP_OBJ_INOUT:
-				case ICALL_HANDLES_WRAP_OBJ_OUT:
-					if (w == ICALL_HANDLES_WRAP_OBJ_OUT) {
-						mono_mb_emit_byte (mb, CEE_LDNULL);
-					} else {
-						mono_mb_emit_ldarg (mb, i);
-						mono_mb_emit_byte (mb, CEE_LDIND_REF);
-					}
-					mono_mb_emit_stloc (mb, local);
-					mono_mb_emit_ldloc_addr (mb, local);
-					break;
-				default:
-					g_assert_not_reached ();
-			}
-		}
-	} else {
-		for (int i = 0; i < csig->param_count; i++)
-			mono_mb_emit_ldarg (mb, i);
-	}
-	if (need_gc_safe)
-		gc_safe_transition_builder_emit_enter (&gc_safe_transition_builder, &piinfo->method, aot);
-	if (aot) {
-		mono_mb_emit_byte (mb, MONO_CUSTOM_PREFIX);
-		mono_mb_emit_op (mb, CEE_MONO_ICALL_ADDR, &piinfo->method);
-		mono_mb_emit_calli (mb, call_sig);
-	} else {
-		g_assert (piinfo->addr);
-		mono_mb_emit_native_call (mb, call_sig, piinfo->addr);
-	}
-	if (need_gc_safe)
-		gc_safe_transition_builder_emit_exit (&gc_safe_transition_builder);
-	if (mb->volatile_locals) {
-		g_assert (handles_locals);
-		for (int i = 0; i < csig->param_count; i++) {
-			const int local = handles_locals [i].handle;
-			if (local >= 0) {
-				mono_mb_emit_ldarg (mb, i);
-				mono_mb_emit_ldloc (mb, local);
-				mono_mb_emit_byte (mb, CEE_STIND_REF);
-			}
-		}
-	}
-	g_free (handles_locals);
-	if (need_gc_safe)
-		gc_safe_transition_builder_cleanup (&gc_safe_transition_builder);
-	if (check_exceptions)
-		emit_thread_interrupt_checkpoint (mb);
-	mono_mb_emit_byte (mb, CEE_RET);
-}
-static void
-mb_emit_exception_ilgen (MonoMethodBuilder *mb, const char *exc_nspace, const char *exc_name, const char *msg)
-{
-	mono_mb_emit_exception_full (mb, exc_nspace, exc_name, msg);
-}
-static void
-mb_emit_exception_for_error_ilgen (MonoMethodBuilder *mb, const MonoError *error)
-{
-	mono_mb_emit_exception_for_error (mb, (MonoError*)error);
-}
-static void
-emit_marshal_directive_exception_ilgen (EmitMarshalContext *m, int argnum, const char* msg)
-{
-	char* fullmsg = NULL;
-	if (argnum == 0)
-		fullmsg = g_strdup_printf("Error marshalling return value: %s", msg);
-	else
-		fullmsg = g_strdup_printf("Error marshalling parameter #%d: %s", argnum, msg);
-	mono_marshal_shared_mb_emit_exception_marshal_directive (m->mb, fullmsg);
-}
-static void
-emit_vtfixup_ftnptr_ilgen (MonoMethodBuilder *mb, MonoMethod *method, int param_count, guint16 type)
-{
-	for (int i = 0; i < param_count; i++)
-		mono_mb_emit_ldarg (mb, i);
-	if (type & VTFIXUP_TYPE_CALL_MOST_DERIVED)
-		mono_mb_emit_op (mb, CEE_CALLVIRT, method);
-	else
-		mono_mb_emit_op (mb, CEE_CALL, method);
-	mono_mb_emit_byte (mb, CEE_RET);
-}
-static void
-emit_icall_wrapper_ilgen (MonoMethodBuilder *mb, MonoJitICallInfo *callinfo, MonoMethodSignature *csig2, gboolean check_exceptions)
-{
-	MonoMethodSignature *const sig = callinfo->sig;
-	if (sig->hasthis)
-		mono_mb_emit_byte (mb, CEE_LDARG_0);
-	for (int i = 0; i < sig->param_count; i++)
-		mono_mb_emit_ldarg (mb, i + sig->hasthis);
-	mono_mb_emit_byte (mb, MONO_CUSTOM_PREFIX);
-	mono_mb_emit_byte (mb, CEE_MONO_JIT_ICALL_ADDR);
-	mono_mb_emit_i4 (mb, GPTRDIFF_TO_INT32 (mono_jit_icall_info_index (callinfo)));
-	mono_mb_emit_calli (mb, csig2);
-	if (check_exceptions)
-		emit_thread_interrupt_checkpoint (mb);
-	mono_mb_emit_byte (mb, CEE_RET);
-}
-static void
-emit_return_ilgen (MonoMethodBuilder *mb)
-{
-	mono_mb_emit_byte (mb, CEE_RET);
-}
-void
-mono_marshal_lightweight_init (void)
-{
-	MonoMarshalLightweightCallbacks cb;
-	cb.version = MONO_MARSHAL_CALLBACKS_VERSION;
-	cb.emit_marshal_scalar = emit_marshal_scalar_ilgen;
-	cb.emit_castclass = emit_castclass_ilgen;
-	cb.emit_struct_to_ptr = emit_struct_to_ptr_ilgen;
-	cb.emit_ptr_to_struct = emit_ptr_to_struct_ilgen;
-	cb.emit_isinst = emit_isinst_ilgen;
-	cb.emit_virtual_stelemref = emit_virtual_stelemref_ilgen;
-	cb.emit_stelemref = emit_stelemref_ilgen;
-	cb.emit_array_address = emit_array_address_ilgen;
-	cb.emit_native_wrapper = emit_native_wrapper_ilgen;
-	cb.emit_managed_wrapper = emit_managed_wrapper_ilgen;
-	cb.emit_runtime_invoke_body = emit_runtime_invoke_body_ilgen;
-	cb.emit_runtime_invoke_dynamic = emit_runtime_invoke_dynamic_ilgen;
-	cb.emit_delegate_begin_invoke = emit_delegate_begin_invoke_ilgen;
-	cb.emit_delegate_end_invoke = emit_delegate_end_invoke_ilgen;
-	cb.emit_delegate_invoke_internal = emit_delegate_invoke_internal_ilgen;
-	cb.emit_synchronized_wrapper = emit_synchronized_wrapper_ilgen;
-	cb.emit_unbox_wrapper = emit_unbox_wrapper_ilgen;
-	cb.emit_array_accessor_wrapper = emit_array_accessor_wrapper_ilgen;
-	cb.emit_unsafe_accessor_wrapper = emit_unsafe_accessor_wrapper_ilgen;
-	cb.emit_generic_array_helper = emit_generic_array_helper_ilgen;
-	cb.emit_thunk_invoke_wrapper = emit_thunk_invoke_wrapper_ilgen;
-	cb.emit_create_string_hack = emit_create_string_hack_ilgen;
-	cb.emit_native_icall_wrapper = emit_native_icall_wrapper_ilgen;
-	cb.emit_icall_wrapper = emit_icall_wrapper_ilgen;
-	cb.emit_return = emit_return_ilgen;
-	cb.emit_vtfixup_ftnptr = emit_vtfixup_ftnptr_ilgen;
-	cb.mb_skip_visibility = mb_skip_visibility_ilgen;
-	cb.mb_inflate_wrapper_data = mb_inflate_wrapper_data_ilgen;
-	cb.mb_emit_exception = mb_emit_exception_ilgen;
-	cb.mb_emit_exception_for_error = mb_emit_exception_for_error_ilgen;
-	cb.mb_emit_byte = mb_emit_byte_ilgen;
-	cb.emit_marshal_directive_exception = emit_marshal_directive_exception_ilgen;
-	mono_install_marshal_callbacks (&cb);
-}

--- a/src/mono/mono/metadata/metadata-internals.h
+++ b//dev/null
@@ -1,1081 +0,0 @@
-/**
- * \file
- */
-#ifndef __MONO_METADATA_INTERNALS_H__
-#define __MONO_METADATA_INTERNALS_H__
-#include "mono/utils/mono-forward-internal.h"
-#include "mono/metadata/image.h"
-#include "mono/metadata/blob.h"
-#include "mono/metadata/cil-coff.h"
-#include "mono/metadata/mempool.h"
-#include "mono/metadata/domain-internals.h"
-#include "mono/metadata/mono-hash.h"
-#include "mono/utils/mono-compiler.h"
-#include "mono/utils/mono-dl.h"
-#include "mono/utils/monobitset.h"
-#include "mono/utils/mono-property-hash.h"
-#include <mono/utils/mono-error.h>
-#include "mono/utils/mono-conc-hashtable.h"
-#include "mono/utils/refcount.h"
-#include "../native/containers/dn-simdhash-specializations.h"
-struct _MonoType {
-	union {
-		MonoClass *klass; /* for VALUETYPE and CLASS */
-		MonoType *type;   /* for PTR */
-		MonoArrayType *array; /* for ARRAY */
-		MonoMethodSignature *method;
-		MonoGenericParam *generic_param; /* for VAR and MVAR */
-		MonoGenericClass *generic_class; /* for GENERICINST */
-	} data;
-	unsigned int attrs    : 16; /* param attributes or field flags */
-	MonoTypeEnum type     : 8;
-	unsigned int has_cmods : 1;
-	unsigned int byref__    : 1; /* don't access directly, use m_type_is_byref */
-	unsigned int pinned   : 1;  /* valid when included in a local var signature */
-};
-typedef struct {
-	unsigned int required : 1;
-	MonoType *type;
-} MonoSingleCustomMod;
-/* Aggregate custom modifiers can happen if a generic VAR or MVAR is inflated,
- * and both the VAR and the type that will be used to inflated it have custom
- * modifiers, but they come from different images.  (e.g. inflating 'class G<T>
- * {void Test (T modopt(IsConst) t);}' with 'int32 modopt(IsLong)' where G is
- * in image1 and the int32 is in image2.)
- *
- * Moreover, we can't just store an image and a type token per modifier, because
- * Roslyn and C++/CLI sometimes create modifiers that mention generic parameters that must be inflated, like:
- *     void .CL1`1.Test(!0 modopt(System.Nullable`1<!0>))
- * So we have to store a resolved MonoType*.
- *
- * Because the types come from different images, we allocate the aggregate
- * custom modifiers container object in the mempool of a MonoImageSet to ensure
- * that it doesn't have dangling image pointers.
- */
-typedef struct {
-	uint8_t count;
-	MonoSingleCustomMod modifiers[1]; /* Actual length is count */
-} MonoAggregateModContainer;
-/* ECMA says upto 64 custom modifiers.  It's possible we could see more at
- * runtime due to modifiers being appended together when we inflate type.  In
- * that case we should revisit the places where this define is used to make
- * sure that we don't blow up the stack (or switch to heap allocation for
- * temporaries).
- */
-#define MONO_MAX_EXPECTED_CMODS 64
-typedef struct {
-	MonoType unmodified;
-	gboolean is_aggregate;
-	union {
-		MonoCustomModContainer cmods;
-		/* the actual aggregate modifiers are in a MonoImageSet mempool
-		 * that includes all the images of all the modifier types and
-		 * also the type that this aggregate container is a part of.*/
-		MonoAggregateModContainer *amods;
-	} mods;
-} MonoTypeWithModifiers;
-gboolean
-mono_type_is_aggregate_mods (const MonoType *t);
-static inline void
-mono_type_with_mods_init (MonoType *dest, uint8_t num_mods, gboolean is_aggregate)
-{
-	if (num_mods == 0) {
-		dest->has_cmods = 0;
-		return;
-	}
-	dest->has_cmods = 1;
-	MonoTypeWithModifiers *dest_full = (MonoTypeWithModifiers *)dest;
-	dest_full->is_aggregate = !!is_aggregate;
-	if (is_aggregate)
-		dest_full->mods.amods = NULL;
-	else
-		dest_full->mods.cmods.count = num_mods;
-}
-MonoCustomModContainer *
-mono_type_get_cmods (const MonoType *t);
-MonoAggregateModContainer *
-mono_type_get_amods (const MonoType *t);
-void
-mono_type_set_amods (MonoType *t, MonoAggregateModContainer *amods);
-static inline uint8_t
-mono_type_custom_modifier_count (const MonoType *t)
-{
-	if (!t->has_cmods)
-		return 0;
-	MonoTypeWithModifiers *full = (MonoTypeWithModifiers *)t;
-	if (full->is_aggregate)
-		return full->mods.amods->count;
-	else
-		return full->mods.cmods.count;
-}
-MonoType *
-mono_type_get_custom_modifier (const MonoType *ty, uint8_t idx, gboolean *required, MonoError *error);
-#define MONO_SIZEOF_TYPE sizeof (MonoType)
-size_t
-mono_sizeof_type_with_mods (uint8_t num_mods, gboolean aggregate);
-size_t
-mono_sizeof_type (const MonoType *ty);
-size_t
-mono_sizeof_aggregate_modifiers (uint8_t num_mods);
-MonoAggregateModContainer *
-mono_metadata_get_canonical_aggregate_modifiers (MonoAggregateModContainer *candidate);
-#define MONO_PUBLIC_KEY_TOKEN_LENGTH	17
-#define MONO_PROCESSOR_ARCHITECTURE_NONE 0
-#define MONO_PROCESSOR_ARCHITECTURE_MSIL 1
-#define MONO_PROCESSOR_ARCHITECTURE_X86 2
-#define MONO_PROCESSOR_ARCHITECTURE_IA64 3
-#define MONO_PROCESSOR_ARCHITECTURE_AMD64 4
-#define MONO_PROCESSOR_ARCHITECTURE_ARM 5
-struct _MonoAssemblyName {
-	const char *name;
-	const char *culture;
-	const char *hash_value;
-	const mono_byte* public_key;
-	mono_byte public_key_token [MONO_PUBLIC_KEY_TOKEN_LENGTH];
-	uint32_t hash_alg;
-	uint32_t hash_len;
-	uint32_t flags;
-	int32_t major, minor, build, revision, arch;
-	MonoBoolean without_version;
-	MonoBoolean without_culture;
-	MonoBoolean without_public_key_token;
-};
-struct MonoTypeNameParse {
-	char *name_space;
-	char *name;
-	MonoAssemblyName assembly;
-	GList *modifiers; /* 0 -> byref, -1 -> pointer, > 0 -> array rank */
-	GPtrArray *type_arguments;
-	GList *nested;
-};
-typedef struct _MonoAssemblyContext {
-	/* Don't fire managed load event for this assembly */
-	guint8 no_managed_load_event : 1;
-} MonoAssemblyContext;
-struct _MonoAssembly {
-	/*
-	 * The number of appdomains which have this assembly loaded plus the number of
-	 * assemblies referencing this assembly through an entry in their image->references
-	 * arrays. The latter is needed because entries in the image->references array
-	 * might point to assemblies which are only loaded in some appdomains, and without
-	 * the additional reference, they can be freed at any time.
-	 * The ref_count is initially 0.
-	 */
-	gint32 ref_count; /* use atomic operations only */
-	char *basedir;
-	MonoAssemblyName aname;
-	MonoImage *image;
-	GSList *friend_assembly_names; /* Computed by mono_assembly_load_friends () */
-	GSList *ignores_checks_assembly_names; /* Computed by mono_assembly_load_friends () */
-	guint8 friend_assembly_names_inited;
-	guint8 dynamic;
-	MonoAssemblyContext context;
-	guint8 wrap_non_exception_throws;
-	guint8 wrap_non_exception_throws_inited;
-	guint8 jit_optimizer_disabled;
-	guint8 jit_optimizer_disabled_inited;
-	guint8 runtime_marshalling_enabled;
-	guint8 runtime_marshalling_enabled_inited;
-};
-typedef struct {
-	const char* data;
-	guint32  size;
-} MonoStreamHeader;
-#define MONO_TABLE_INFO_MAX_COLUMNS 9
-struct _MonoTableInfo {
-	const char *base;
-	guint       rows_     : 24;	/* don't access directly, use table_info_get_rows */
-	guint       row_size : 8;
-	/*
-	 * Tables contain up to 9 columns and the possible sizes of the
-	 * fields in the documentation are 1, 2 and 4 bytes.  So we
-	 * can encode in 2 bits the size.
-	 *
-	 * A 32 bit value can encode the resulting size
-	 *
-	 * The top eight bits encode the number of columns in the table.
-	 * we only need 4, but 8 is aligned no shift required.
-	 */
-	guint32   size_bitfield;
-	/*
-	 * optimize out the loop in mono_metadata_decode_row_col_raw.
-	 * 4 * 9 easily fits in a uint8
-	 */
-	guint8    column_offsets[MONO_TABLE_INFO_MAX_COLUMNS];
-};
-#define REFERENCE_MISSING ((gpointer) -1)
-typedef struct {
-	gboolean (*match) (MonoImage*);
-	gboolean (*load_pe_data) (MonoImage*);
-	gboolean (*load_cli_data) (MonoImage*);
-	gboolean (*load_tables) (MonoImage*);
-} MonoImageLoader;
-/* Represents the physical bytes for an image (usually in the file system, but
- * could be in memory).
- *
- * The MonoImageStorage owns the raw data for an image and is responsible for
- * cleanup.
- *
- * May be shared by multiple MonoImage objects if they opened the same
- * underlying file or byte blob in memory.
- *
- * There is an abstract string key (usually a file path, but could be formed in
- * other ways) that is used to share MonoImageStorage objects among images.
- *
- */
-typedef struct {
-	MonoRefCount ref;
-	/* key used for lookups.  owned by this image storage. */
-	char *key;
-	/* If the raw data was allocated from a source such as mmap, the allocator may store resource tracking information here. */
-	void *raw_data_handle;
-	char *raw_data;
-	guint32 raw_data_len;
-	/* data was allocated with mono_file_map and must be unmapped */
-	guint8 raw_buffer_used    : 1;
-	/* data was allocated with malloc and must be freed */
-	guint8 raw_data_allocated : 1;
-	/* data was allocated with mono_file_map_fileio */
-	guint8 fileio_used : 1;
-#ifdef HOST_WIN32
-	/* Module was loaded using LoadLibrary. */
-	guint8 is_module_handle : 1;
-	/* Module entry point is _CorDllMain. */
-	guint8 has_entry_point : 1;
-#endif
-#ifdef ENABLE_WEBCIL
-	/* set to a non-zero value when we load a webcil-in-wasm image.
-	 * Note that in that case MonoImage:raw_data is not equal to MonoImageStorage:raw_data
-	 */
-	int32_t webcil_section_adjustment;
-#endif
-} MonoImageStorage;
-struct _MonoImage {
-	/*
-	 * This count is incremented during these situations:
-	 *   - An assembly references this MonoImage through its 'image' field
-	 *   - This MonoImage is present in the 'files' field of an image
-	 *   - This MonoImage is present in the 'modules' field of an image
-	 *   - A thread is holding a temporary reference to this MonoImage between
-	 *     calls to mono_image_open and mono_image_close ()
-	 */
-	int   ref_count;
-	MonoImageStorage *storage;
-	/* Points into storage->raw_data when storage is non-NULL. Otherwise NULL. */
-	char *raw_data;
-	guint32 raw_data_len;
-	/* Whenever this is a dynamically emitted module */
-	guint8 dynamic : 1;
-	/* Whenever this image is not an executable, such as .mibc */
-	guint8 not_executable : 1;
-	/* Whenever this image contains uncompressed metadata */
-	guint8 uncompressed_metadata : 1;
-	/* Whenever this image contains metadata only without PE data */
-	guint8 metadata_only : 1;
-	guint8 checked_module_cctor : 1;
-	guint8 has_module_cctor : 1;
-	guint8 idx_string_wide : 1;
-	guint8 idx_guid_wide : 1;
-	guint8 idx_blob_wide : 1;
-	/* NOT SUPPORTED: Whenever this image is considered as platform code for the CoreCLR security model */
-	guint8 core_clr_platform_code : 1;
-	/* Whether a #JTD stream was present. Indicates that this image was a minimal delta and its heaps only include the new heap entries */
-	guint8 minimal_delta : 1;
-	/* The path to the file for this image or an arbitrary name for images loaded from data. */
-	char *name;
-	/* The path to the file for this image or NULL */
-	char *filename;
-	/* The assembly name reported in the file for this image (expected to be NULL for a netmodule) */
-	const char *assembly_name;
-	/* The module name reported in the file for this image (could be NULL for a malformed file) */
-	const char *module_name;
-	char *version;
-	gint16 md_version_major, md_version_minor;
-	char *guid;
-	MonoCLIImageInfo    *image_info;
-	MonoMemPool         *mempool; /*protected by the image lock*/
-	char                *raw_metadata;
-	MonoStreamHeader     heap_strings;
-	MonoStreamHeader     heap_us;
-	MonoStreamHeader     heap_blob;
-	MonoStreamHeader     heap_guid;
-	MonoStreamHeader     heap_tables;
-	MonoStreamHeader     heap_pdb;
-	const char          *tables_base;
-	/* For PPDB files */
-	guint64 referenced_tables;
-	int *referenced_table_rows;
-	/**/
-	MonoTableInfo        tables [MONO_TABLE_NUM];
-	/*
-	 * references is initialized only by using the mono_assembly_open
-	 * function, and not by using the lowlevel mono_image_open.
-	 *
-	 * Protected by the image lock.
-	 *
-	 * It is NULL terminated.
-	 */
-	MonoAssembly **references;
-	int nreferences;
-	/* Code files in the assembly. The main assembly has a "file" table and also a "module"
-	 * table, where the module table is a subset of the file table. We track both lists,
-	 * and because we can lazy-load them at different times we reference-increment both.
-	 */
-	/* No netmodules in netcore, but for System.Reflection.Emit support we still use modules */
-	MonoImage **modules;
-	guint32 module_count;
-	gboolean *modules_loaded;
-	MonoImage **files;
-	guint32 file_count;
-	MonoAotModule *aot_module;
-	guint8 aotid[16];
-	/*
-	 * The Assembly this image was loaded from.
-	 */
-	MonoAssembly *assembly;
-	/*
-	 * The AssemblyLoadContext that this image was loaded into.
-	 */
-	MonoAssemblyLoadContext *alc;
-	/*
-	 * Indexed by method tokens and typedef tokens.
-	 */
-	dn_simdhash_u32_ptr_t *method_cache; /*protected by the image lock*/
-	MonoInternalHashTable class_cache;
-	/* Indexed by memberref + methodspec tokens */
-	dn_simdhash_u32_ptr_t *methodref_cache; /*protected by the image lock*/
-	/*
-	 * Indexed by fielddef and memberref tokens
-	 */
-	MonoConcurrentHashTable *field_cache; /*protected by the image lock*/
-	/* indexed by typespec tokens. */
-	MonoConcurrentHashTable *typespec_cache; /* protected by the image lock */
-	/* indexed by token */
-	GHashTable *memberref_signatures;
-	/* Indexed by blob heap indexes */
-	GHashTable *method_signatures;
-	/*
-	 * Indexes namespaces to hash tables that map class name to typedef token.
-	 */
-	dn_simdhash_string_ptr_t *name_cache;  /*protected by the image lock*/
-	/*
-	 * Indexed by MonoClass
-	 */
-	GHashTable *array_cache;
-	GHashTable *ptr_cache;
-	GHashTable *szarray_cache;
-	/* This has a separate lock to improve scalability */
-	mono_mutex_t szarray_cache_lock;
-	/*
-	 * indexed by SignaturePointerPair
-	 */
-	GHashTable *native_func_wrapper_cache;
-	/*
-	 * indexed by MonoMethod pointers
-	 */
-	GHashTable *wrapper_param_names;
-	GHashTable *array_accessor_cache;
-	GHashTable *icall_wrapper_cache;
-	GHashTable *rgctx_template_hash; /* LOCKING: templates lock */
-	/* Contains rarely used fields of runtime structures belonging to this image */
-	MonoPropertyHash *property_hash;
-	void *reflection_info;
-	/*
-	 * user_info is a public field and is not touched by the
-	 * metadata engine
-	 */
-	void *user_info;
-	/* interfaces IDs from this image */
-	/* protected by the classes lock */
-	MonoBitSet *interface_bitset;
-	/* when the image is being closed, this is abused as a list of
-	   malloc'ed regions to be freed. */
-	GSList *reflection_info_unregister_classes;
-	/* List of dependent image sets containing this image */
-	/* Protected by image_sets_lock */
-	GSList *image_sets;
-	/* Caches for wrappers that DO NOT reference generic */
-	/* arguments */
-	MonoWrapperCaches wrapper_caches;
-	/* Pre-allocated anon generic params for the first N generic
-	 * parameters, for a small N */
-	MonoGenericParam *var_gparam_cache_fast;
-	MonoGenericParam *mvar_gparam_cache_fast;
-	/* Anon generic parameters past N, if needed */
-	MonoConcurrentHashTable *var_gparam_cache;
-	MonoConcurrentHashTable *mvar_gparam_cache;
-	/* The loader used to load this image */
-	MonoImageLoader *loader;
-	MonoGenericContainer *anonymous_generic_class_container;
-	MonoGenericContainer *anonymous_generic_method_container;
-#ifdef ENABLE_WEAK_ATTR
-	gboolean weak_fields_inited;
-	/* Contains 1 based indexes */
-	GHashTable *weak_field_indexes;
-#endif
-        /* baseline images only: whether any metadata updates have been applied to this image */
-        gboolean has_updates;
-	/*
-	 * No other runtime locks must be taken while holding this lock.
-	 * It's meant to be used only to mutate and query structures part of this image.
-	 */
-	mono_mutex_t    lock;
-};
-enum {
-	MONO_SECTION_TEXT,
-	MONO_SECTION_RSRC,
-	MONO_SECTION_RELOC,
-	MONO_SECTION_MAX
-};
-typedef struct {
-	GHashTable *hash;
-	char *data;
-	guint32 alloc_size; /* malloced bytes */
-	guint32 index;
-	guint32 offset; /* from start of metadata */
-} MonoDynamicStream;
-typedef struct {
-	guint32 alloc_rows;
-	guint32 rows;
-	guint8  row_size; /*  calculated later with column_sizes */
-	guint8  columns;
-	guint32 next_idx;
-	guint32 *values; /* rows * columns */
-} MonoDynamicTable;
-/* "Dynamic" assemblies and images arise from System.Reflection.Emit */
-struct _MonoDynamicAssembly {
-	MonoAssembly assembly;
-	char *strong_name;
-	guint32 strong_name_size;
-};
-struct _MonoDynamicImage {
-	MonoImage image;
-	guint32 meta_size;
-	guint32 text_rva;
-	guint32 metadata_rva;
-	guint32 image_base;
-	guint32 cli_header_offset;
-	guint32 iat_offset;
-	guint32 idt_offset;
-	guint32 ilt_offset;
-	guint32 imp_names_offset;
-	struct {
-		guint32 rva;
-		guint32 size;
-		guint32 offset;
-		guint32 attrs;
-	} sections [MONO_SECTION_MAX];
-	GHashTable *typespec;
-	GHashTable *typeref;
-	GHashTable *handleref;
-	MonoGHashTable *tokens;
-	GHashTable *blob_cache;
-	GHashTable *standalonesig_cache;
-	GList *array_methods;
-	GHashTable *method_aux_hash;
-	GHashTable *vararg_aux_hash;
-	MonoGHashTable *generic_def_objects;
-	gboolean initial_image;
-	guint32 pe_kind, machine;
-	char *strong_name;
-	guint32 strong_name_size;
-	char *win32_res;
-	guint32 win32_res_size;
-	guint8 *public_key;
-	int public_key_len;
-	MonoDynamicStream sheap;
-	MonoDynamicStream code; /* used to store method headers and bytecode */
-	MonoDynamicStream resources; /* managed embedded resources */
-	MonoDynamicStream us;
-	MonoDynamicStream blob;
-	MonoDynamicStream tstream;
-	MonoDynamicStream guid;
-	MonoDynamicTable tables [MONO_TABLE_NUM];
-	MonoClass *wrappers_type; /*wrappers are bound to this type instead of <Module>*/
-};
-/* Contains information about assembly binding */
-typedef struct _MonoAssemblyBindingInfo {
-	char *name;
-	char *culture;
-	guchar public_key_token [MONO_PUBLIC_KEY_TOKEN_LENGTH];
-	int major;
-	int minor;
-	AssemblyVersionSet old_version_bottom;
-	AssemblyVersionSet old_version_top;
-	AssemblyVersionSet new_version;
-	guint has_old_version_bottom : 1;
-	guint has_old_version_top : 1;
-	guint has_new_version : 1;
-	guint is_valid : 1;
-	gint32 domain_id; /*Needed to unload per-domain binding*/
-} MonoAssemblyBindingInfo;
-struct _MonoMethodHeader {
-	const unsigned char  *code;
-#ifdef MONO_SMALL_CONFIG
-	guint16      code_size;
-#else
-	guint32      code_size;
-#endif
-	guint16      max_stack   : 15;
-	unsigned int is_transient: 1; /* mono_metadata_free_mh () will actually free this header */
-	unsigned int num_clauses : 15;
-	/* if num_locals != 0, then the following apply: */
-	unsigned int init_locals : 1;
-	guint16      num_locals;
-	MonoExceptionClause *clauses;
-	MonoBitSet  *volatile_args;
-	MonoBitSet  *volatile_locals;
-	MonoType    *locals [MONO_ZERO_LEN_ARRAY];
-};
-typedef struct {
-	const unsigned char *code;
-	guint32      code_size;
-	guint16      max_stack;
-	gboolean     has_clauses;
-	gboolean     has_locals;
-} MonoMethodHeaderSummary;
-#define MONO_SIZEOF_METHOD_HEADER (sizeof (struct _MonoMethodHeader) - MONO_ZERO_LEN_ARRAY * SIZEOF_VOID_P)
-struct _MonoMethodSignature {
-	MonoType     *ret;
-#ifdef MONO_SMALL_CONFIG
-	guint8        param_count;
-	gint8         sentinelpos;
-	unsigned int  generic_param_count : 5;
-#else
-	guint16       param_count;
-	gint16        sentinelpos;
-	unsigned int  generic_param_count : 16;
-#endif
-	unsigned int  call_convention     : 6;
-	unsigned int  hasthis             : 1;
-	unsigned int  explicit_this       : 1;
-	unsigned int  pinvoke             : 1;
-	unsigned int  is_inflated         : 1;
-	unsigned int  has_type_parameters : 1;
-	unsigned int  marshalling_disabled : 1;
-	uint8_t       ext_callconv; // see MonoExtCallConv
-	MonoType     *params [MONO_ZERO_LEN_ARRAY];
-};
-typedef enum {
-  MONO_EXT_CALLCONV_SUPPRESS_GC_TRANSITION = 0x01,
-  MONO_EXT_CALLCONV_SWIFTCALL = 0x02,
-} MonoExtCallConv;
-/*
- * AOT cache configuration loaded from config files.
- * Doesn't really belong here.
- */
-typedef struct {
-	/*
-	 * Enable aot caching for applications whose main assemblies are in
-	 * this list.
-	 */
-	GSList *apps;
-	GSList *assemblies;
-	char *aot_options;
-} MonoAotCacheConfig;
-#define MONO_SIZEOF_METHOD_SIGNATURE (sizeof (struct _MonoMethodSignature) - MONO_ZERO_LEN_ARRAY * SIZEOF_VOID_P)
-typedef enum {
-    MONO_CLASS_LOADER_IMMEDIATE_FAILURE, // Used during runtime to indicate that the failure should be reported
-    MONO_CLASS_LOADER_DEFERRED_FAILURE // Used during AOT compilation to defer failure for execution
-} MonoFailureType;
-static inline gboolean
-image_is_dynamic (MonoImage *image)
-{
-#ifdef DISABLE_REFLECTION_EMIT
-	return FALSE;
-#else
-	return image->dynamic;
-#endif
-}
-static inline gboolean
-assembly_is_dynamic (MonoAssembly *assembly)
-{
-#ifdef DISABLE_REFLECTION_EMIT
-	return FALSE;
-#else
-	return assembly->dynamic;
-#endif
-}
-static inline uint32_t
-table_info_get_rows (const MonoTableInfo *table)
-{
-	return table->rows_;
-}
-/* for use with allocated memory blocks (assumes alignment is to 8 bytes) */
-MONO_COMPONENT_API guint mono_aligned_addr_hash (gconstpointer ptr);
-void
-mono_image_check_for_module_cctor (MonoImage *image);
-gpointer
-mono_image_alloc  (MonoImage *image, guint size);
-gpointer
-mono_image_alloc0 (MonoImage *image, guint size);
-#define mono_image_new0(image,type,size) ((type *) mono_image_alloc0 (image, sizeof (type)* (size)))
-char*
-mono_image_strdup (MonoImage *image, const char *s);
-char*
-mono_image_strdup_vprintf (MonoImage *image, const char *format, va_list args);
-char*
-mono_image_strdup_printf (MonoImage *image, const char *format, ...) MONO_ATTR_FORMAT_PRINTF(2,3);
-MONO_COMPONENT_API
-GList*
-mono_g_list_prepend_image (MonoImage *image, GList *list, gpointer data);
-GSList*
-mono_g_slist_append_image (MonoImage *image, GSList *list, gpointer data);
-MONO_COMPONENT_API
-void
-mono_image_lock (MonoImage *image);
-MONO_COMPONENT_API
-void
-mono_image_unlock (MonoImage *image);
-gpointer
-mono_image_property_lookup (MonoImage *image, gpointer subject, guint32 property);
-void
-mono_image_property_insert (MonoImage *image, gpointer subject, guint32 property, gpointer value);
-void
-mono_image_property_remove (MonoImage *image, gpointer subject);
-MONO_COMPONENT_API
-gboolean
-mono_image_close_except_pools (MonoImage *image);
-MONO_COMPONENT_API
-void
-mono_image_close_finish (MonoImage *image);
-typedef void  (*MonoImageUnloadFunc) (MonoImage *image, gpointer user_data);
-void
-mono_install_image_unload_hook (MonoImageUnloadFunc func, gpointer user_data);
-void
-mono_remove_image_unload_hook (MonoImageUnloadFunc func, gpointer user_data);
-void
-mono_install_image_loader (const MonoImageLoader *loader);
-void
-mono_image_append_class_to_reflection_info_set (MonoClass *klass);
-typedef struct _MonoMetadataUpdateData MonoMetadataUpdateData;
-struct _MonoMetadataUpdateData {
-	int has_updates;
-};
-extern MonoMetadataUpdateData mono_metadata_update_data_private;
-/* returns TRUE if there's at least one update */
-static inline gboolean
-mono_metadata_has_updates (void)
-{
-	return mono_metadata_update_data_private.has_updates != 0;
-}
-/* components can't call the inline function directly since the private data isn't exported */
-MONO_COMPONENT_API
-gboolean
-mono_metadata_has_updates_api (void);
-void
-mono_image_effective_table_slow (const MonoTableInfo **t, uint32_t idx);
-gboolean
-mono_metadata_update_has_modified_rows (const MonoTableInfo *t);
-static inline void
-mono_image_effective_table (const MonoTableInfo **t, uint32_t idx)
-{
-	if (G_UNLIKELY (mono_metadata_has_updates ())) {
-		if (G_UNLIKELY (idx >= table_info_get_rows (*t) || mono_metadata_update_has_modified_rows (*t))) {
-			mono_image_effective_table_slow (t, idx);
-		}
-	}
-}
-enum MonoEnCDeltaOrigin {
-        MONO_ENC_DELTA_API = 0,
-        MONO_ENC_DELTA_DBG = 1,
-};
-MONO_COMPONENT_API void
-mono_image_load_enc_delta (int delta_origin, MonoImage *base_image, gconstpointer dmeta, uint32_t dmeta_len, gconstpointer dil, uint32_t dil_len, gconstpointer dpdb, uint32_t dpdb_len, MonoError *error);
-MONO_COMPONENT_API const char*
-mono_enc_capabilities (void);
-gboolean
-mono_image_load_cli_header (MonoImage *image, MonoCLIImageInfo *iinfo);
-gboolean
-mono_image_load_metadata (MonoImage *image, MonoCLIImageInfo *iinfo);
-const char*
-mono_metadata_string_heap_checked (MonoImage *meta, uint32_t table_index, MonoError *error);
-const char *
-mono_metadata_blob_heap_null_ok (MonoImage *meta, guint32 index);
-const char*
-mono_metadata_blob_heap_checked (MonoImage *meta, uint32_t table_index, MonoError *error);
-gboolean
-mono_metadata_decode_row_checked (const MonoImage *image, const MonoTableInfo *t, int idx, uint32_t *res, int res_size, MonoError *error);
-MONO_COMPONENT_API
-void
-mono_metadata_decode_row_raw (const MonoTableInfo *t, int idx, uint32_t *res, int res_size);
-gboolean
-mono_metadata_decode_row_dynamic_checked (const MonoDynamicImage *image, const MonoDynamicTable *t, guint idx, guint32 *res, int res_size, MonoError *error);
-MonoType*
-mono_metadata_get_shared_type (MonoType *type);
-void
-mono_metadata_clean_generic_classes_for_image (MonoImage *image);
-gboolean
-mono_metadata_table_bounds_check_slow (MonoImage *image, int table_index, int token_index);
-guint32
-mono_metadata_table_num_rows_slow (MonoImage *image, int table_index);
-static inline guint32
-mono_metadata_table_num_rows (MonoImage *image, int table_index)
-{
-	if (G_LIKELY (!image->has_updates))
-		return table_info_get_rows (&image->tables [table_index]);
-	else
-		return mono_metadata_table_num_rows_slow (image, table_index);
-}
-/* token_index is 1-based */
-static inline gboolean
-mono_metadata_table_bounds_check (MonoImage *image, int table_index, int token_index)
-{
-	/* returns true if given index is not in bounds with provided table/index pair */
-	if (G_LIKELY (GINT_TO_UINT32(token_index) <= table_info_get_rows (&image->tables [table_index])))
-		return FALSE;
-        if (G_LIKELY (!image->has_updates))
-                return TRUE;
-	return mono_metadata_table_bounds_check_slow (image, table_index, token_index);
-}
-MONO_COMPONENT_API
-const char *   mono_meta_table_name              (int table);
-void           mono_metadata_compute_table_bases (MonoImage *meta);
-MONO_COMPONENT_API
-void           mono_metadata_compute_column_offsets (MonoTableInfo *table);
-gboolean
-mono_metadata_interfaces_from_typedef_full  (MonoImage             *image,
-											 guint32                table_index,
-											 MonoClass           ***interfaces,
-											 guint                 *count,
-											 gboolean               heap_alloc_result,
-											 MonoGenericContext    *context,
-											 MonoError *error);
-MONO_API MonoMethodSignature *
-mono_metadata_parse_method_signature_full   (MonoImage             *image,
-					     MonoGenericContainer  *generic_container,
-					     int                     def,
-					     const char             *ptr,
-					     const char            **rptr,
-					     MonoError *error);
-MONO_API MonoMethodHeader *
-mono_metadata_parse_mh_full                 (MonoImage             *image,
-					     MonoGenericContainer  *container,
-					     const char            *ptr,
-						 MonoError *error);
-MonoMethodSignature  *mono_metadata_parse_signature_checked (MonoImage *image,
-							     uint32_t    token,
-							     MonoError *error);
-gboolean
-mono_method_get_header_summary (MonoMethod *method, MonoMethodHeaderSummary *summary);
-int* mono_metadata_get_param_attrs          (MonoImage *m, int def, guint32 param_count);
-gboolean mono_metadata_method_has_param_attrs (MonoImage *m, int def);
-guint
-mono_metadata_generic_context_hash          (const MonoGenericContext *context);
-gboolean
-mono_metadata_generic_context_equal         (const MonoGenericContext *g1,
-					     const MonoGenericContext *g2);
-MonoGenericInst *
-mono_metadata_parse_generic_inst            (MonoImage             *image,
-					     MonoGenericContainer  *container,
-					     int                    count,
-					     const char            *ptr,
-					     const char           **rptr,
-						 MonoError *error);
-MONO_COMPONENT_API MonoGenericInst *
-mono_metadata_get_generic_inst              (int 		    type_argc,
-					     MonoType 		  **type_argv);
-MonoGenericInst *
-mono_metadata_get_canonical_generic_inst    (MonoGenericInst *candidate);
-MonoGenericClass *
-mono_metadata_lookup_generic_class          (MonoClass		   *gclass,
-					     MonoGenericInst	   *inst,
-					     gboolean		    is_dynamic);
-MonoGenericInst * mono_metadata_inflate_generic_inst  (MonoGenericInst *ginst, MonoGenericContext *context, MonoError *error);
-guint
-mono_metadata_generic_param_hash (MonoGenericParam *p);
-gboolean
-mono_metadata_generic_param_equal (MonoGenericParam *p1, MonoGenericParam *p2);
-void mono_dynamic_stream_reset  (MonoDynamicStream* stream);
-void mono_assembly_load_friends (MonoAssembly* ass);
-MONO_API gint32
-mono_assembly_addref (MonoAssembly *assembly);
-gint32
-mono_assembly_decref (MonoAssembly *assembly);
-void mono_assembly_release_gc_roots (MonoAssembly *assembly);
-gboolean mono_assembly_close_except_image_pools (MonoAssembly *assembly);
-void mono_assembly_close_finish (MonoAssembly *assembly);
-gboolean mono_public_tokens_are_equal (const unsigned char *pubt1, const unsigned char *pubt2);
-gboolean
-mono_assembly_name_parse_full 		     (const char	   *name,
-					      MonoAssemblyName	   *aname,
-					      gboolean save_public_key,
-					      gboolean *is_version_defined,
-						  gboolean *is_token_defined);
-gboolean
-mono_assembly_fill_assembly_name_full (MonoImage *image, MonoAssemblyName *aname, gboolean copyBlobs);
-MONO_API guint32 mono_metadata_get_generic_param_row (MonoImage *image, guint32 token, guint32 *owner);
-MonoGenericParam*
-mono_metadata_create_anon_gparam (MonoImage *image, gint32 param_num, gboolean is_mvar);
-void mono_unload_interface_ids (MonoBitSet *bitset);
-MonoType *mono_metadata_type_dup (MonoImage *image, const MonoType *original);
-MonoType *mono_metadata_type_dup_with_cmods (MonoImage *image, const MonoType *original, const MonoType *cmods_source);
-MonoMethodSignature  *mono_metadata_signature_dup_full (MonoImage *image,MonoMethodSignature *sig);
-MonoMethodSignature  *mono_metadata_signature_dup_mempool (MonoMemPool *mp, MonoMethodSignature *sig);
-MonoMethodSignature  *mono_metadata_signature_dup_mem_manager (MonoMemoryManager *mem_manager, MonoMethodSignature *sig);
-MonoMethodSignature  *mono_metadata_signature_dup_add_this (MonoImage *image, MonoMethodSignature *sig, MonoClass *klass);
-MonoMethodSignature  *mono_metadata_signature_dup_delegate_invoke_to_target (MonoMethodSignature *sig);
-MonoMethodSignature  *mono_metadata_signature_allocate_internal (MonoImage *image, MonoMemPool *mp, MonoMemoryManager *mem_manager, size_t sig_size);
-MonoMethodSignature  *mono_metadata_signature_dup_new_params (MonoMemPool *mp, MonoMemoryManager *mem_manager, MonoMethodSignature *sig, uint32_t num_params, MonoType **new_params);
-MonoGenericInst *
-mono_get_shared_generic_inst (MonoGenericContainer *container);
-int
-mono_type_stack_size_internal (MonoType *t, int *align, gboolean allow_open);
-MONO_API void            mono_type_get_desc (GString *res, MonoType *type, mono_bool include_namespace);
-enum {
-	MONO_TYPE_EQ_FLAGS_NONE = 0,
-	MONO_TYPE_EQ_FLAGS_SIG_ONLY = 1,
-	MONO_TYPE_EQ_FLAG_IGNORE_CMODS = 2,
-};
-gboolean
-mono_metadata_type_equal_full (MonoType *t1, MonoType *t2, int flags);
-MonoMarshalSpec *
-mono_metadata_parse_marshal_spec_full (MonoImage *image, MonoImage *parent_image, const char *ptr);
-guint	       mono_metadata_generic_inst_hash (gconstpointer data);
-gboolean       mono_metadata_generic_inst_equal (gconstpointer ka, gconstpointer kb);
-gboolean
-mono_metadata_signature_equal_no_ret (MonoMethodSignature *sig1, MonoMethodSignature *sig2);
-gboolean
-mono_metadata_signature_equal_ignore_custom_modifier (MonoMethodSignature *sig1, MonoMethodSignature *sig2);
-gboolean
-mono_metadata_signature_equal_vararg (MonoMethodSignature *sig1, MonoMethodSignature *sig2);
-gboolean
-mono_metadata_signature_equal_vararg_ignore_custom_modifier (MonoMethodSignature *sig1, MonoMethodSignature *sig2);
-MONO_API void
-mono_metadata_field_info_with_mempool (
-					  MonoImage *meta,
-				      guint32       table_index,
-				      guint32      *offset,
-				      guint32      *rva,
-				      MonoMarshalSpec **marshal_spec);
-MonoClassField*
-mono_metadata_get_corresponding_field_from_generic_type_definition (MonoClassField *field);
-MonoEvent*
-mono_metadata_get_corresponding_event_from_generic_type_definition (MonoEvent *event);
-MonoProperty*
-mono_metadata_get_corresponding_property_from_generic_type_definition (MonoProperty *property);
-guint32
-mono_metadata_signature_size (MonoMethodSignature *sig);
-guint mono_metadata_str_hash (gconstpointer v1);
-gboolean mono_image_load_pe_data (MonoImage *image);
-gboolean mono_image_load_cli_data (MonoImage *image);
-void mono_image_load_names (MonoImage *image);
-MonoImage *mono_image_open_raw (MonoAssemblyLoadContext *alc, const char *fname, MonoImageOpenStatus *status);
-MonoImage *mono_image_open_metadata_only (MonoAssemblyLoadContext *alc, const char *fname, MonoImageOpenStatus *status);
-MONO_COMPONENT_API
-MonoImage *mono_image_open_from_data_internal (MonoAssemblyLoadContext *alc, char *data, guint32 data_len, gboolean need_copy, MonoImageOpenStatus *status, gboolean metadata_only, const char *name, const char *filename);
-MonoException *mono_get_exception_field_access_msg (const char *msg);
-MonoException *mono_get_exception_method_access_msg (const char *msg);
-MonoMethod* mono_method_from_method_def_or_ref (MonoImage *m, guint32 tok, MonoGenericContext *context, MonoError *error);
-MonoMethod *mono_get_method_constrained_with_method (MonoImage *image, MonoMethod *method, MonoClass *constrained_class, MonoGenericContext *context, MonoError *error);
-MonoMethod *mono_get_method_constrained_checked (MonoImage *image, guint32 token, MonoClass *constrained_class, MonoGenericContext *context, MonoMethod **cil_method, MonoError *error);
-void mono_type_set_alignment (MonoTypeEnum type, int align);
-MonoType *
-mono_type_create_from_typespec_checked (MonoImage *image, guint32 type_spec, MonoError *error);
-MonoMethodSignature*
-mono_method_get_signature_checked (MonoMethod *method, MonoImage *image, guint32 token, MonoGenericContext *context, MonoError *error);
-MONO_COMPONENT_API MonoMethod *
-mono_get_method_checked (MonoImage *image, guint32 token, MonoClass *klass, MonoGenericContext *context, MonoError *error);
-guint32
-mono_metadata_localscope_from_methoddef (MonoImage *meta, guint32 index);
-void
-mono_wrapper_caches_free (MonoWrapperCaches *cache);
-MonoWrapperCaches*
-mono_method_get_wrapper_cache (MonoMethod *method);
-MonoWrapperCaches*
-mono_method_get_wrapper_cache (MonoMethod *method);
-MonoType*
-mono_metadata_parse_type_checked (MonoImage *m, MonoGenericContainer *container, guint32 opt_attrs, gboolean transient, const char *ptr, const char **rptr, MonoError *error);
-MonoGenericContainer *
-mono_get_anonymous_container_for_image (MonoImage *image, gboolean is_mvar);
-void
-mono_loader_register_module (const char *name, MonoDl *module);
-void
-mono_ginst_get_desc (GString *str, MonoGenericInst *ginst);
-void
-mono_loader_set_strict_assembly_name_check (gboolean enabled);
-gboolean
-mono_loader_get_strict_assembly_name_check (void);
-MONO_COMPONENT_API gboolean
-mono_type_in_image (MonoType *type, MonoImage *image);
-gboolean
-mono_type_is_valid_generic_argument (MonoType *type);
-void
-mono_metadata_get_class_guid (MonoClass* klass, uint8_t* guid, MonoError *error);
-#define MONO_CLASS_IS_INTERFACE_INTERNAL(c) ((mono_class_get_flags (c) & TYPE_ATTRIBUTE_INTERFACE) || mono_type_is_generic_parameter (m_class_get_byval_arg (c)))
-/*
- * We use this to pass context information to the row locator
- */
-typedef struct {
-	guint32 idx;			/* The index that we are trying to locate */
-	guint32 col_idx;		/* The index in the row where idx may be stored */
-	MonoTableInfo *t;		/* pointer to the table */
-	gint32 metadata_has_updates; // -1: uninitialized. 0/1: value
-	const char * t_base;
-	guint t_row_size;
-	guint32 t_rows;
-	guint32 column_size;
-	const char * first_column_data;
-	guint32 result;
-} mono_locator_t;
-MONO_ALWAYS_INLINE static mono_locator_t
-mono_locator_init (MonoTableInfo *t, guint32 idx, guint32 col_idx)
-{
-	mono_locator_t result = { 0, };
-	result.idx = idx;
-	result.col_idx = col_idx;
-	result.t = t;
-	g_assert (t);
-	if (!t->base)
-		return result;
-	result.metadata_has_updates = -1;
-	result.t_base = t->base;
-	result.t_row_size = t->row_size;
-	result.t_rows = table_info_get_rows (t);
-	g_assert (col_idx < mono_metadata_table_count (t->size_bitfield));
-	result.column_size = mono_metadata_table_size (t->size_bitfield, col_idx);
-	result.first_column_data = result.t_base + t->column_offsets [col_idx];
-	return result;
-}
-static inline gboolean
-m_image_is_raw_data_allocated (MonoImage *image)
-{
-	return image->storage ? image->storage->raw_data_allocated : FALSE;
-}
-static inline gboolean
-m_image_is_fileio_used (MonoImage *image)
-{
-	return image->storage ? image->storage->fileio_used : FALSE;
-}
-#ifdef HOST_WIN32
-static inline gboolean
-m_image_is_module_handle (MonoImage *image)
-{
-	return image->storage ? image->storage->is_module_handle : FALSE;
-}
-static inline gboolean
-m_image_has_entry_point (MonoImage *image)
-{
-	return image->storage ? image->storage->has_entry_point : FALSE;
-}
-#endif
-static inline const char *
-m_image_get_name (MonoImage *image)
-{
-	return image->name;
-}
-static inline const char *
-m_image_get_filename (MonoImage *image)
-{
-	return image->filename;
-}
-static inline const char *
-m_image_get_assembly_name (MonoImage *image)
-{
-	return image->assembly_name;
-}
-static inline
-MonoAssemblyLoadContext *
-mono_image_get_alc (MonoImage *image)
-{
-	return image->alc;
-}
-static inline
-MonoAssemblyLoadContext *
-mono_assembly_get_alc (MonoAssembly *assm)
-{
-	return mono_image_get_alc (assm->image);
-}
-static inline MonoType*
-mono_signature_get_return_type_internal (MonoMethodSignature *sig)
-{
-	return sig->ret;
-}
-/**
- * mono_type_get_type_internal:
- * \param type the \c MonoType operated on
- * \returns the IL type value for \p type. This is one of the \c MonoTypeEnum
- * enum members like \c MONO_TYPE_I4 or \c MONO_TYPE_STRING.
- */
-static inline int
-mono_type_get_type_internal (MonoType *type)
-{
-	return type->type;
-}
-/**
- * mono_type_get_signature:
- * \param type the \c MonoType operated on
- * It is only valid to call this function if \p type is a \c MONO_TYPE_FNPTR .
- * \returns the \c MonoMethodSignature pointer that describes the signature
- * of the function pointer \p type represents.
- */
-static inline MonoMethodSignature*
-mono_type_get_signature_internal (MonoType *type)
-{
-	g_assert (type->type == MONO_TYPE_FNPTR);
-	return type->data.method;
-}
-/**
- * m_type_is_byref:
- * \param type the \c MonoType operated on
- * \returns TRUE if \p type represents a type passed by reference,
- * FALSE otherwise.
- */
-static inline gboolean
-m_type_is_byref (const MonoType *type)
-{
-	return type->byref__;
-}
-/**
- * mono_type_get_class_internal:
- * \param type the \c MonoType operated on
- * It is only valid to call this function if \p type is a \c MONO_TYPE_CLASS or a
- * \c MONO_TYPE_VALUETYPE . For more general functionality, use \c mono_class_from_mono_type_internal,
- * instead.
- * \returns the \c MonoClass pointer that describes the class that \p type represents.
- */
-static inline MonoClass*
-mono_type_get_class_internal (MonoType *type)
-{
-	/* FIXME: review the runtime users before adding the assert here */
-	return type->data.klass;
-}
-/**
- * mono_type_get_array_type_internal:
- * \param type the \c MonoType operated on
- * It is only valid to call this function if \p type is a \c MONO_TYPE_ARRAY .
- * \returns a \c MonoArrayType struct describing the array type that \p type
- * represents. The info includes details such as rank, array element type
- * and the sizes and bounds of multidimensional arrays.
- */
-static inline MonoArrayType*
-mono_type_get_array_type_internal (MonoType *type)
-{
-	return type->data.array;
-}
-static inline int
-mono_metadata_table_to_ptr_table (int table_num)
-{
-	switch (table_num) {
-	case MONO_TABLE_FIELD: return MONO_TABLE_FIELD_POINTER;
-	case MONO_TABLE_METHOD: return MONO_TABLE_METHOD_POINTER;
-	case MONO_TABLE_PARAM: return MONO_TABLE_PARAM_POINTER;
-	case MONO_TABLE_PROPERTY: return MONO_TABLE_PROPERTY_POINTER;
-	case MONO_TABLE_EVENT: return MONO_TABLE_EVENT_POINTER;
-	default:
-		g_assert_not_reached ();
-	}
-}
-uint32_t
-mono_metadata_get_method_params (MonoImage *image, uint32_t method_idx, uint32_t *last_param_out);
-void
-mono_set_failure_type (MonoFailureType failure_type);
-gboolean
-mono_class_set_deferred_type_load_failure (MonoClass *klass, const char * fmt, ...);
-gboolean
-mono_class_set_type_load_failure (MonoClass *klass, const char * fmt, ...);
-static inline gboolean
-mono_method_signature_has_ext_callconv (MonoMethodSignature *sig, MonoExtCallConv flags) {
-	return (sig->ext_callconv & flags) != 0;
-}
-#endif /* __MONO_METADATA_INTERNALS_H__ */

--- a/src/mono/mono/metadata/metadata.c
+++ b//dev/null
@@ -1,7058 +0,0 @@
-/**
- * \file
- * Routines for accessing the metadata
- *
- * Authors:
- *   Miguel de Icaza (miguel@ximian.com)
- *   Paolo Molaro (lupus@ximian.com)
- *
- * Copyright 2001-2003 Ximian, Inc (http://www.ximian.com)
- * Copyright 2004-2009 Novell, Inc (http://www.novell.com)
- * Licensed under the MIT license. See LICENSE file in the project root for full license information.
- */
-#include <config.h>
-#include <stdio.h>
-#include <stdlib.h>
-#include <string.h>
-#include <glib.h>
-#include <mono/metadata/metadata.h>
-#include "tabledefs.h"
-#include "mono-endian.h"
-#include "cil-coff.h"
-#include <mono/metadata/tokentype.h>
-#include "class-internals.h"
-#include "metadata-internals.h"
-#include "reflection-internals.h"
-#include "metadata-update.h"
-#include <mono/metadata/class.h>
-#include "marshal.h"
-#include <mono/metadata/debug-helpers.h>
-#include "abi-details.h"
-#include "components.h"
-#include <mono/metadata/exception-internals.h>
-#include <mono/utils/mono-error-internals.h>
-#include <mono/utils/mono-memory-model.h>
-#include <mono/utils/mono-digest.h>
-#include <mono/utils/bsearch.h>
-#include <mono/utils/atomic.h>
-#include <mono/utils/unlocked.h>
-#include <mono/utils/mono-logger-internals.h>
-/* Auxiliary structure used for caching inflated signatures */
-typedef struct {
-	MonoMethodSignature *sig;
-	MonoGenericContext context;
-} MonoInflatedMethodSignature;
-static gboolean do_mono_metadata_parse_type (MonoType *type, MonoImage *m, MonoGenericContainer *container, gboolean transient,
-					 const char *ptr, const char **rptr, MonoError *error);
-static gboolean do_mono_metadata_type_equal (MonoType *t1, MonoType *t2, int equiv_flags);
-static gboolean mono_metadata_class_equal (MonoClass *c1, MonoClass *c2, gboolean signature_only);
-static gboolean mono_metadata_fnptr_equal (MonoMethodSignature *s1, MonoMethodSignature *s2, int equiv_flags);
-static gboolean _mono_metadata_generic_class_equal (const MonoGenericClass *g1, const MonoGenericClass *g2,
-						    gboolean signature_only);
-static void free_generic_inst (MonoGenericInst *ginst);
-static void free_generic_class (MonoGenericClass *ginst);
-static void free_inflated_signature (MonoInflatedMethodSignature *sig);
-static void free_aggregate_modifiers (MonoAggregateModContainer *amods);
-static void mono_metadata_field_info_full (MonoImage *meta, guint32 index, guint32 *offset, guint32 *rva, MonoMarshalSpec **marshal_spec, gboolean alloc_from_image);
-static MonoType* mono_signature_get_params_internal (MonoMethodSignature *sig, gpointer *iter);
-/*
- * This enumeration is used to describe the data types in the metadata
- * tables
- */
-enum {
-	MONO_MT_END,
-	/* Sized elements */
-	MONO_MT_UINT32,
-	MONO_MT_UINT16,
-	MONO_MT_UINT8,
-	/* Index into Blob heap */
-	MONO_MT_BLOB_IDX,
-	/* Index into String heap */
-	MONO_MT_STRING_IDX,
-	/* GUID index */
-	MONO_MT_GUID_IDX,
-	/* Pointer into a table */
-	MONO_MT_TABLE_IDX,
-	/* HasConstant:Parent pointer (Param, Field or Property) */
-	MONO_MT_CONST_IDX,
-	/* HasCustomAttribute index.  Indexes any table except CustomAttribute */
-	MONO_MT_HASCAT_IDX,
-	/* CustomAttributeType encoded index */
-	MONO_MT_CAT_IDX,
-	/* HasDeclSecurity index: TypeDef Method or Assembly */
-	MONO_MT_HASDEC_IDX,
-	/* Implementation coded index: File, Export AssemblyRef */
-	MONO_MT_IMPL_IDX,
-	/* HasFieldMarshal coded index: Field or Param table */
-	MONO_MT_HFM_IDX,
-	/* MemberForwardedIndex: Field or Method */
-	MONO_MT_MF_IDX,
-	/* TypeDefOrRef coded index: typedef, typeref, typespec */
-	MONO_MT_TDOR_IDX,
-	/* MemberRefParent coded index: typeref, moduleref, method, memberref, typesepc, typedef */
-	MONO_MT_MRP_IDX,
-	/* MethodDefOrRef coded index: Method or Member Ref table */
-	MONO_MT_MDOR_IDX,
-	/* HasSemantic coded index: Event or Property */
-	MONO_MT_HS_IDX,
-	/* ResolutionScope coded index: Module, ModuleRef, AssemblytRef, TypeRef */
-	MONO_MT_RS_IDX,
-	/* CustomDebugInformation parent encoded index */
-	MONO_MT_HASCUSTDEBUG_IDX
-};
-const static unsigned char TableSchemas [] = {
-#define ASSEMBLY_SCHEMA_OFFSET 0
-	MONO_MT_UINT32,     /* "HashId" }, */
-	MONO_MT_UINT16,     /* "Major" },  */
-	MONO_MT_UINT16,     /* "Minor" }, */
-	MONO_MT_UINT16,     /* "BuildNumber" }, */
-	MONO_MT_UINT16,     /* "RevisionNumber" }, */
-	MONO_MT_UINT32,     /* "Flags" }, */
-	MONO_MT_BLOB_IDX,   /* "PublicKey" }, */
-	MONO_MT_STRING_IDX, /* "Name" }, */
-	MONO_MT_STRING_IDX, /* "Culture" }, */
-	MONO_MT_END,
-#define ASSEMBLYOS_SCHEMA_OFFSET ASSEMBLY_SCHEMA_OFFSET + 10
-	MONO_MT_UINT32,     /* "OSPlatformID" }, */
-	MONO_MT_UINT32,     /* "OSMajor" }, */
-	MONO_MT_UINT32,     /* "OSMinor" }, */
-	MONO_MT_END,
-#define ASSEMBLYPROC_SCHEMA_OFFSET ASSEMBLYOS_SCHEMA_OFFSET + 4
-	MONO_MT_UINT32,     /* "Processor" }, */
-	MONO_MT_END,
-#define ASSEMBLYREF_SCHEMA_OFFSET ASSEMBLYPROC_SCHEMA_OFFSET + 2
-	MONO_MT_UINT16,     /* "Major" }, */
-	MONO_MT_UINT16,     /* "Minor" }, */
-	MONO_MT_UINT16,     /* "Build" }, */
-	MONO_MT_UINT16,     /* "Revision" }, */
-	MONO_MT_UINT32,     /* "Flags" }, */
-	MONO_MT_BLOB_IDX,   /* "PublicKeyOrToken" }, */
-	MONO_MT_STRING_IDX, /* "Name" }, */
-	MONO_MT_STRING_IDX, /* "Culture" }, */
-	MONO_MT_BLOB_IDX,   /* "HashValue" }, */
-	MONO_MT_END,
-#define ASSEMBLYREFOS_SCHEMA_OFFSET ASSEMBLYREF_SCHEMA_OFFSET + 10
-	MONO_MT_UINT32,     /* "OSPlatformID" }, */
-	MONO_MT_UINT32,     /* "OSMajorVersion" }, */
-	MONO_MT_UINT32,     /* "OSMinorVersion" }, */
-	MONO_MT_TABLE_IDX,  /* "AssemblyRef:AssemblyRef" }, */
-	MONO_MT_END,
-#define ASSEMBLYREFPROC_SCHEMA_OFFSET ASSEMBLYREFOS_SCHEMA_OFFSET + 5
-	MONO_MT_UINT32,     /* "Processor" }, */
-	MONO_MT_TABLE_IDX,  /* "AssemblyRef:AssemblyRef" }, */
-	MONO_MT_END,
-#define CLASS_LAYOUT_SCHEMA_OFFSET ASSEMBLYREFPROC_SCHEMA_OFFSET + 3
-	MONO_MT_UINT16,     /* "PackingSize" }, */
-	MONO_MT_UINT32,     /* "ClassSize" }, */
-	MONO_MT_TABLE_IDX,  /* "Parent:TypeDef" }, */
-	MONO_MT_END,
-#define CONSTANT_SCHEMA_OFFSET CLASS_LAYOUT_SCHEMA_OFFSET + 4
-	MONO_MT_UINT8,      /* "Type" }, */
-	MONO_MT_UINT8,      /* "PaddingZero" }, */
-	MONO_MT_CONST_IDX,  /* "Parent" }, */
-	MONO_MT_BLOB_IDX,   /* "Value" }, */
-	MONO_MT_END,
-#define CUSTOM_ATTR_SCHEMA_OFFSET CONSTANT_SCHEMA_OFFSET + 5
-	MONO_MT_HASCAT_IDX, /* "Parent" }, */
-	MONO_MT_CAT_IDX,    /* "Type" }, */
-	MONO_MT_BLOB_IDX,   /* "Value" }, */
-	MONO_MT_END,
-#define DECL_SEC_SCHEMA_OFFSET CUSTOM_ATTR_SCHEMA_OFFSET + 4
-	MONO_MT_UINT16,     /* "Action" }, */
-	MONO_MT_HASDEC_IDX, /* "Parent" }, */
-	MONO_MT_BLOB_IDX,   /* "PermissionSet" }, */
-	MONO_MT_END,
-#define EVENTMAP_SCHEMA_OFFSET DECL_SEC_SCHEMA_OFFSET + 4
-	MONO_MT_TABLE_IDX,  /* "Parent:TypeDef" }, */
-	MONO_MT_TABLE_IDX,  /* "EventList:Event" }, */
-	MONO_MT_END,
-#define EVENT_SCHEMA_OFFSET EVENTMAP_SCHEMA_OFFSET + 3
-	MONO_MT_UINT16,     /* "EventFlags#EventAttribute" }, */
-	MONO_MT_STRING_IDX, /* "Name" }, */
-	MONO_MT_TDOR_IDX,  /* "EventType" }, TypeDef or TypeRef or TypeSpec  */
-	MONO_MT_END,
-#define EVENT_POINTER_SCHEMA_OFFSET EVENT_SCHEMA_OFFSET + 4
-	MONO_MT_TABLE_IDX,  /* "Event" }, */
-	MONO_MT_END,
-#define EXPORTED_TYPE_SCHEMA_OFFSET EVENT_POINTER_SCHEMA_OFFSET + 2
-	MONO_MT_UINT32,     /* "Flags" }, */
-	MONO_MT_TABLE_IDX,  /* "TypeDefId" }, */
-	MONO_MT_STRING_IDX, /* "TypeName" }, */
-	MONO_MT_STRING_IDX, /* "TypeNameSpace" }, */
-	MONO_MT_IMPL_IDX,   /* "Implementation" }, */
-	MONO_MT_END,
-#define FIELD_SCHEMA_OFFSET EXPORTED_TYPE_SCHEMA_OFFSET + 6
-	MONO_MT_UINT16,     /* "Flags" }, */
-	MONO_MT_STRING_IDX, /* "Name" }, */
-	MONO_MT_BLOB_IDX,   /* "Signature" }, */
-	MONO_MT_END,
-#define FIELD_LAYOUT_SCHEMA_OFFSET FIELD_SCHEMA_OFFSET + 4
-	MONO_MT_UINT32,     /* "Offset" }, */
-	MONO_MT_TABLE_IDX,  /* "Field:Field" }, */
-	MONO_MT_END,
-#define FIELD_MARSHAL_SCHEMA_OFFSET FIELD_LAYOUT_SCHEMA_OFFSET + 3
-	MONO_MT_HFM_IDX,    /* "Parent" }, */
-	MONO_MT_BLOB_IDX,   /* "NativeType" }, */
-	MONO_MT_END,
-#define FIELD_RVA_SCHEMA_OFFSET FIELD_MARSHAL_SCHEMA_OFFSET + 3
-	MONO_MT_UINT32,     /* "RVA" }, */
-	MONO_MT_TABLE_IDX,  /* "Field:Field" }, */
-	MONO_MT_END,
-#define ENCLOG_SCHEMA_OFFSET FIELD_RVA_SCHEMA_OFFSET + 3
-	MONO_MT_UINT32,    /* "Token" }, */
-	MONO_MT_UINT32,    /* "FuncCode" }, */
-	MONO_MT_END,
-#define ENCMAP_SCHEMA_OFFSET ENCLOG_SCHEMA_OFFSET + 3
-	MONO_MT_UINT32,    /* "Token" }, */
-	MONO_MT_END,
-#define FIELD_POINTER_SCHEMA_OFFSET ENCMAP_SCHEMA_OFFSET + 2
-	MONO_MT_TABLE_IDX,  /* "Field" }, */
-	MONO_MT_END,
-#define FILE_SCHEMA_OFFSET FIELD_POINTER_SCHEMA_OFFSET + 2
-	MONO_MT_UINT32,     /* "Flags" }, */
-	MONO_MT_STRING_IDX, /* "Name" }, */
-	MONO_MT_BLOB_IDX,   /* "Value" },  */
-	MONO_MT_END,
-#define IMPLMAP_SCHEMA_OFFSET FILE_SCHEMA_OFFSET + 4
-	MONO_MT_UINT16,     /* "MappingFlag" }, */
-	MONO_MT_MF_IDX,     /* "MemberForwarded" }, */
-	MONO_MT_STRING_IDX, /* "ImportName" }, */
-	MONO_MT_TABLE_IDX,  /* "ImportScope:ModuleRef" }, */
-	MONO_MT_END,
-#define IFACEMAP_SCHEMA_OFFSET IMPLMAP_SCHEMA_OFFSET + 5
-	MONO_MT_TABLE_IDX,  /* "Class:TypeDef" },  */
-	MONO_MT_TDOR_IDX,  /* "Interface=TypeDefOrRef" }, */
-	MONO_MT_END,
-#define MANIFEST_SCHEMA_OFFSET IFACEMAP_SCHEMA_OFFSET + 3
-	MONO_MT_UINT32,     /* "Offset" }, */
-	MONO_MT_UINT32,     /* "Flags" }, */
-	MONO_MT_STRING_IDX, /* "Name" }, */
-	MONO_MT_IMPL_IDX,   /* "Implementation" }, */
-	MONO_MT_END,
-#define MEMBERREF_SCHEMA_OFFSET MANIFEST_SCHEMA_OFFSET + 5
-	MONO_MT_MRP_IDX,    /* "Class" }, */
-	MONO_MT_STRING_IDX, /* "Name" }, */
-	MONO_MT_BLOB_IDX,   /* "Signature" }, */
-	MONO_MT_END,
-#define METHOD_SCHEMA_OFFSET MEMBERREF_SCHEMA_OFFSET + 4
-	MONO_MT_UINT32,     /* "RVA" }, */
-	MONO_MT_UINT16,     /* "ImplFlags#MethodImplAttributes" }, */
-	MONO_MT_UINT16,     /* "Flags#MethodAttribute" }, */
-	MONO_MT_STRING_IDX, /* "Name" }, */
-	MONO_MT_BLOB_IDX,   /* "Signature" }, */
-	MONO_MT_TABLE_IDX,  /* "ParamList:Param" }, */
-	MONO_MT_END,
-#define METHOD_IMPL_SCHEMA_OFFSET METHOD_SCHEMA_OFFSET + 7
-	MONO_MT_TABLE_IDX,  /* "Class:TypeDef" }, */
-	MONO_MT_MDOR_IDX,   /* "MethodBody" }, */
-	MONO_MT_MDOR_IDX,   /* "MethodDeclaration" }, */
-	MONO_MT_END,
-#define METHOD_SEMA_SCHEMA_OFFSET METHOD_IMPL_SCHEMA_OFFSET + 4
-	MONO_MT_UINT16,     /* "MethodSemantic" }, */
-	MONO_MT_TABLE_IDX,  /* "Method:Method" }, */
-	MONO_MT_HS_IDX,     /* "Association" }, */
-	MONO_MT_END,
-#define METHOD_POINTER_SCHEMA_OFFSET METHOD_SEMA_SCHEMA_OFFSET + 4
-	MONO_MT_TABLE_IDX,  /* "Method" }, */
-	MONO_MT_END,
-#define MODULE_SCHEMA_OFFSET METHOD_POINTER_SCHEMA_OFFSET + 2
-	MONO_MT_UINT16,     /* "Generation" }, */
-	MONO_MT_STRING_IDX, /* "Name" }, */
-	MONO_MT_GUID_IDX,   /* "MVID" }, */
-	MONO_MT_GUID_IDX,   /* "EncID" }, */
-	MONO_MT_GUID_IDX,   /* "EncBaseID" }, */
-	MONO_MT_END,
-#define MODULEREF_SCHEMA_OFFSET MODULE_SCHEMA_OFFSET + 6
-	MONO_MT_STRING_IDX, /* "Name" }, */
-	MONO_MT_END,
-#define NESTED_CLASS_SCHEMA_OFFSET MODULEREF_SCHEMA_OFFSET + 2
-	MONO_MT_TABLE_IDX,  /* "NestedClass:TypeDef" }, */
-	MONO_MT_TABLE_IDX,  /* "EnclosingClass:TypeDef" }, */
-	MONO_MT_END,
-#define PARAM_SCHEMA_OFFSET NESTED_CLASS_SCHEMA_OFFSET + 3
-	MONO_MT_UINT16,     /* "Flags" }, */
-	MONO_MT_UINT16,     /* "Sequence" }, */
-	MONO_MT_STRING_IDX, /* "Name" }, */
-	MONO_MT_END,
-#define PARAM_POINTER_SCHEMA_OFFSET PARAM_SCHEMA_OFFSET + 4
-	MONO_MT_TABLE_IDX,  /* "Param" }, */
-	MONO_MT_END,
-#define PROPERTY_SCHEMA_OFFSET PARAM_POINTER_SCHEMA_OFFSET + 2
-	MONO_MT_UINT16,     /* "Flags" }, */
-	MONO_MT_STRING_IDX, /* "Name" }, */
-	MONO_MT_BLOB_IDX,   /* "Type" }, */
-	MONO_MT_END,
-#define PROPERTY_POINTER_SCHEMA_OFFSET PROPERTY_SCHEMA_OFFSET + 4
-	MONO_MT_TABLE_IDX, /* "Property" }, */
-	MONO_MT_END,
-#define PROPERTY_MAP_SCHEMA_OFFSET PROPERTY_POINTER_SCHEMA_OFFSET + 2
-	MONO_MT_TABLE_IDX,  /* "Parent:TypeDef" }, */
-	MONO_MT_TABLE_IDX,  /* "PropertyList:Property" }, */
-	MONO_MT_END,
-#define STDALON_SIG_SCHEMA_OFFSET PROPERTY_MAP_SCHEMA_OFFSET + 3
-	MONO_MT_BLOB_IDX,   /* "Signature" }, */
-	MONO_MT_END,
-#define TYPEDEF_SCHEMA_OFFSET STDALON_SIG_SCHEMA_OFFSET + 2
-	MONO_MT_UINT32,     /* "Flags" }, */
-	MONO_MT_STRING_IDX, /* "Name" }, */
-	MONO_MT_STRING_IDX, /* "Namespace" }, */
-	MONO_MT_TDOR_IDX,   /* "Extends" }, */
-	MONO_MT_TABLE_IDX,  /* "FieldList:Field" }, */
-	MONO_MT_TABLE_IDX,  /* "MethodList:Method" }, */
-	MONO_MT_END,
-#define TYPEREF_SCHEMA_OFFSET TYPEDEF_SCHEMA_OFFSET + 7
-	MONO_MT_RS_IDX,     /* "ResolutionScope=ResolutionScope" }, */
-	MONO_MT_STRING_IDX, /* "Name" }, */
-	MONO_MT_STRING_IDX, /* "Namespace" }, */
-	MONO_MT_END,
-#define TYPESPEC_SCHEMA_OFFSET TYPEREF_SCHEMA_OFFSET + 4
-	MONO_MT_BLOB_IDX,   /* "Signature" }, */
-	MONO_MT_END,
-#define GENPARAM_SCHEMA_OFFSET TYPESPEC_SCHEMA_OFFSET + 2
-	MONO_MT_UINT16,     /* "Number" }, */
-	MONO_MT_UINT16,     /* "Flags" }, */
-	MONO_MT_TABLE_IDX,  /* "Owner" },  TypeDef or MethodDef */
-	MONO_MT_STRING_IDX, /* "Name" }, */
-	MONO_MT_END,
-#define METHOD_SPEC_SCHEMA_OFFSET GENPARAM_SCHEMA_OFFSET + 5
-	MONO_MT_MDOR_IDX,   /* "Method" }, */
-	MONO_MT_BLOB_IDX,   /* "Signature" }, */
-	MONO_MT_END,
-#define GEN_CONSTRAINT_SCHEMA_OFFSET METHOD_SPEC_SCHEMA_OFFSET + 3
-	MONO_MT_TABLE_IDX,  /* "GenericParam" }, */
-	MONO_MT_TDOR_IDX,   /* "Constraint" }, */
-	MONO_MT_END,
-#define DOCUMENT_SCHEMA_OFFSET GEN_CONSTRAINT_SCHEMA_OFFSET + 3
-	MONO_MT_BLOB_IDX,   /* Name */
-	MONO_MT_GUID_IDX,   /* HashAlgorithm */
-	MONO_MT_BLOB_IDX,   /* Hash */
-	MONO_MT_GUID_IDX,   /* Language */
-	MONO_MT_END,
-#define METHODBODY_SCHEMA_OFFSET DOCUMENT_SCHEMA_OFFSET + 5
-	MONO_MT_TABLE_IDX,   /* Document */
-	MONO_MT_BLOB_IDX,   /* SequencePoints */
-	MONO_MT_END,
-#define LOCALSCOPE_SCHEMA_OFFSET METHODBODY_SCHEMA_OFFSET + 3
-	MONO_MT_TABLE_IDX,   /* Method */
-	MONO_MT_TABLE_IDX,   /* ImportScope */
-	MONO_MT_TABLE_IDX,   /* VariableList */
-	MONO_MT_TABLE_IDX,   /* ConstantList */
-	MONO_MT_UINT32,      /* StartOffset */
-	MONO_MT_UINT32,      /* Length */
-	MONO_MT_END,
-#define LOCALVARIABLE_SCHEMA_OFFSET LOCALSCOPE_SCHEMA_OFFSET + 7
-	MONO_MT_UINT16,      /* Attributes */
-	MONO_MT_UINT16,      /* Index */
-	MONO_MT_STRING_IDX,  /* Name */
-	MONO_MT_END,
-#define LOCALCONSTANT_SCHEMA_OFFSET LOCALVARIABLE_SCHEMA_OFFSET + 4
-	MONO_MT_STRING_IDX,  /* Name (String heap index) */
-	MONO_MT_BLOB_IDX,    /* Signature (Blob heap index, LocalConstantSig blob) */
-	MONO_MT_END,
-#define IMPORTSCOPE_SCHEMA_OFFSET LOCALCONSTANT_SCHEMA_OFFSET + 3
-	MONO_MT_TABLE_IDX, /* Parent (ImportScope row id or nil) */
-	MONO_MT_BLOB_IDX,  /* Imports (Blob index, encoding: Imports blob) */
-	MONO_MT_END,
-#define ASYNCMETHOD_SCHEMA_OFFSET IMPORTSCOPE_SCHEMA_OFFSET + 3
-	MONO_MT_TABLE_IDX, /* MoveNextMethod (MethodDef row id) */
-	MONO_MT_TABLE_IDX, /* KickoffMethod (MethodDef row id) */
-	MONO_MT_END,
-#define CUSTOMDEBUGINFORMATION_SCHEMA_OFFSET ASYNCMETHOD_SCHEMA_OFFSET + 3
-	MONO_MT_HASCUSTDEBUG_IDX, /* Parent (HasCustomDebugInformation coded index) */
-	MONO_MT_GUID_IDX,  /* Kind (Guid heap index) */
-	MONO_MT_BLOB_IDX,  /* Value (Blob heap index) */
-	MONO_MT_END,
-#define NULL_SCHEMA_OFFSET CUSTOMDEBUGINFORMATION_SCHEMA_OFFSET + 4
-	MONO_MT_END
-};
-/* Must be the same order as MONO_TABLE_* */
-const static unsigned char
-table_description [] = {
-	MODULE_SCHEMA_OFFSET,
-	TYPEREF_SCHEMA_OFFSET,
-	TYPEDEF_SCHEMA_OFFSET,
-	FIELD_POINTER_SCHEMA_OFFSET,
-	FIELD_SCHEMA_OFFSET,
-	METHOD_POINTER_SCHEMA_OFFSET,
-	METHOD_SCHEMA_OFFSET,
-	PARAM_POINTER_SCHEMA_OFFSET,
-	PARAM_SCHEMA_OFFSET,
-	IFACEMAP_SCHEMA_OFFSET,
-	MEMBERREF_SCHEMA_OFFSET, /* 0xa */
-	CONSTANT_SCHEMA_OFFSET,
-	CUSTOM_ATTR_SCHEMA_OFFSET,
-	FIELD_MARSHAL_SCHEMA_OFFSET,
-	DECL_SEC_SCHEMA_OFFSET,
-	CLASS_LAYOUT_SCHEMA_OFFSET,
-	FIELD_LAYOUT_SCHEMA_OFFSET, /* 0x10 */
-	STDALON_SIG_SCHEMA_OFFSET,
-	EVENTMAP_SCHEMA_OFFSET,
-	EVENT_POINTER_SCHEMA_OFFSET,
-	EVENT_SCHEMA_OFFSET,
-	PROPERTY_MAP_SCHEMA_OFFSET,
-	PROPERTY_POINTER_SCHEMA_OFFSET,
-	PROPERTY_SCHEMA_OFFSET,
-	METHOD_SEMA_SCHEMA_OFFSET,
-	METHOD_IMPL_SCHEMA_OFFSET,
-	MODULEREF_SCHEMA_OFFSET, /* 0x1a */
-	TYPESPEC_SCHEMA_OFFSET,
-	IMPLMAP_SCHEMA_OFFSET,
-	FIELD_RVA_SCHEMA_OFFSET,
-	ENCLOG_SCHEMA_OFFSET,
-	ENCMAP_SCHEMA_OFFSET,
-	ASSEMBLY_SCHEMA_OFFSET, /* 0x20 */
-	ASSEMBLYPROC_SCHEMA_OFFSET,
-	ASSEMBLYOS_SCHEMA_OFFSET,
-	ASSEMBLYREF_SCHEMA_OFFSET,
-	ASSEMBLYREFPROC_SCHEMA_OFFSET,
-	ASSEMBLYREFOS_SCHEMA_OFFSET,
-	FILE_SCHEMA_OFFSET,
-	EXPORTED_TYPE_SCHEMA_OFFSET,
-	MANIFEST_SCHEMA_OFFSET,
-	NESTED_CLASS_SCHEMA_OFFSET,
-	GENPARAM_SCHEMA_OFFSET, /* 0x2a */
-	METHOD_SPEC_SCHEMA_OFFSET,
-	GEN_CONSTRAINT_SCHEMA_OFFSET,
-	NULL_SCHEMA_OFFSET,
-	NULL_SCHEMA_OFFSET,
-	NULL_SCHEMA_OFFSET,
-	DOCUMENT_SCHEMA_OFFSET, /* 0x30 */
-	METHODBODY_SCHEMA_OFFSET,
-	LOCALSCOPE_SCHEMA_OFFSET,
-	LOCALVARIABLE_SCHEMA_OFFSET,
-	LOCALCONSTANT_SCHEMA_OFFSET,
-	IMPORTSCOPE_SCHEMA_OFFSET,
-	ASYNCMETHOD_SCHEMA_OFFSET,
-	CUSTOMDEBUGINFORMATION_SCHEMA_OFFSET
-};
-#define MSGSTRFIELD(line) MSGSTRFIELD1(line)
-#define MSGSTRFIELD1(line) str##line
-static const struct msgstr_t {
-#define TABLEDEF(a,b) char MSGSTRFIELD(__LINE__) [sizeof (b)];
-#include "mono/cil/tables.def"
-#undef TABLEDEF
-} tablestr = {
-#define TABLEDEF(a,b) b,
-#include "mono/cil/tables.def"
-#undef TABLEDEF
-};
-static const gint16 tableidx [] = {
-#define TABLEDEF(a,b) offsetof (struct msgstr_t, MSGSTRFIELD(__LINE__)),
-#include "mono/cil/tables.def"
-#undef TABLEDEF
-};
-/* On legacy, if TRUE (but also see DISABLE_DESKTOP_LOADER #define), Mono will check
- * that the public key token, culture and version of a candidate assembly matches
- * the requested strong name. On netcore, it will check the culture and version.
- * If FALSE, as long as the name matches, the candidate will be allowed.
- */
-static gboolean check_assembly_names_strictly = FALSE;
-#define INITIAL_IMAGE_SET_SIZE    1024
-/**
- * mono_meta_table_name:
- * \param table table index
- *
- * Returns the name of the given ECMA metadata logical format table
- * as described in ECMA 335, Partition II, Section 22.
- *
- * \returns the name for the \p table index
- */
-const char *
-mono_meta_table_name (int table)
-{
-	if ((table < 0) || (table > MONO_TABLE_LAST))
-		return "";
-	return (const char*)&tablestr + tableidx [table];
-}
-/* The guy who wrote the spec for this should not be allowed near a
- * computer again.
-If  e is a coded token(see clause 23.1.7) that points into table ti out of n possible tables t0, .. tn-1,
-then it is stored as e << (log n) & tag{ t0, .. tn-1}[ ti] using 2 bytes if the maximum number of
-rows of tables t0, ..tn-1, is less than 2^16 - (log n), and using 4 bytes otherwise. The family of
-finite maps tag{ t0, ..tn-1} is defined below. Note that to decode a physical row, you need the
-inverse of this mapping.
- */
-static int
-rtsize (MonoImage *meta, int sz, int bits)
-{
-	if (G_UNLIKELY (meta->minimal_delta))
-		return 4;
-	if (sz < (1 << bits))
-		return 2;
-	else
-		return 4;
-}
-static int
-idx_size (MonoImage *meta, int idx)
-{
-	if (G_UNLIKELY (meta->minimal_delta))
-		return 4;
-	if (meta->referenced_tables && (meta->referenced_tables & ((guint64)1 << idx)))
-		return meta->referenced_table_rows [idx] < 65536 ? 2 : 4;
-	else
-		return table_info_get_rows (&meta->tables [idx]) < 65536 ? 2 : 4;
-}
-static int
-get_nrows (MonoImage *meta, int idx)
-{
-	if (meta->referenced_tables && (meta->referenced_tables & ((guint64)1 << idx)))
-		return meta->referenced_table_rows [idx];
-	else
-		return table_info_get_rows (&meta->tables [idx]);
-}
-/* Reference: Partition II - 23.2.6 */
-/**
- * mono_metadata_compute_size:
- * \param meta metadata context
- * \param tableindex metadata table number
- * \param result_bitfield pointer to \c guint32 where to store additional info
- *
- * \c mono_metadata_compute_size computes the length in bytes of a single
- * row in a metadata table. The size of each column is encoded in the
- * \p result_bitfield return value along with the number of columns in the table.
- * the resulting bitfield should be handed to the \c mono_metadata_table_size
- * and \c mono_metadata_table_count macros.
- * This is a Mono runtime internal only function.
- */
-int
-mono_metadata_compute_size (MonoImage *meta, int tableindex, guint32 *result_bitfield)
-{
-	guint32 bitfield = 0;
-	int size = 0, field_size = 0;
-	int i, n, code;
-	int shift = 0;
-	const unsigned char *description = TableSchemas + table_description [tableindex];
-	for (i = 0; (code = description [i]) != MONO_MT_END; i++){
-		switch (code){
-		case MONO_MT_UINT32:
-			field_size = 4; break;
-		case MONO_MT_UINT16:
-			field_size = 2; break;
-		case MONO_MT_UINT8:
-			field_size = 1; break;
-		case MONO_MT_BLOB_IDX:
-			field_size = meta->idx_blob_wide ? 4 : 2; break;
-		case MONO_MT_STRING_IDX:
-			field_size = meta->idx_string_wide ? 4 : 2; break;
-		case MONO_MT_GUID_IDX:
-			field_size = meta->idx_guid_wide ? 4 : 2; break;
-		case MONO_MT_TABLE_IDX:
-			/* Uhm, a table index can point to other tables besides the current one
-			 * so, it's not correct to use the rowcount of the current table to
-			 * get the size for this column - lupus
-			 */
-			switch (tableindex) {
-			case MONO_TABLE_ASSEMBLYREFOS:
-				g_assert (i == 3);
-				field_size = idx_size (meta, MONO_TABLE_ASSEMBLYREF); break;
-			case MONO_TABLE_ASSEMBLYREFPROCESSOR:
-				g_assert (i == 1);
-				field_size = idx_size (meta, MONO_TABLE_ASSEMBLYREF); break;
-			case MONO_TABLE_CLASSLAYOUT:
-				g_assert (i == 2);
-				field_size = idx_size (meta, MONO_TABLE_TYPEDEF); break;
-			case MONO_TABLE_EVENTMAP:
-				g_assert (i == 0 || i == 1);
-				field_size = i ? idx_size (meta, MONO_TABLE_EVENT):
-					idx_size (meta, MONO_TABLE_TYPEDEF);
-				break;
-			case MONO_TABLE_EVENT_POINTER:
-				g_assert (i == 0);
-				field_size = idx_size (meta, MONO_TABLE_EVENT); break;
-			case MONO_TABLE_EXPORTEDTYPE:
-				g_assert (i == 1);
-				/* the index is in another metadata file, so it must be 4 */
-				field_size = 4; break;
-			case MONO_TABLE_FIELDLAYOUT:
-				g_assert (i == 1);
-				field_size = idx_size (meta, MONO_TABLE_FIELD); break;
-			case MONO_TABLE_FIELDRVA:
-				g_assert (i == 1);
-				field_size = idx_size (meta, MONO_TABLE_FIELD); break;
-			case MONO_TABLE_FIELD_POINTER:
-				g_assert (i == 0);
-				field_size = idx_size (meta, MONO_TABLE_FIELD); break;
-			case MONO_TABLE_IMPLMAP:
-				g_assert (i == 3);
-				field_size = idx_size (meta, MONO_TABLE_MODULEREF); break;
-			case MONO_TABLE_INTERFACEIMPL:
-				g_assert (i == 0);
-				field_size = idx_size (meta, MONO_TABLE_TYPEDEF); break;
-			case MONO_TABLE_METHOD:
-				g_assert (i == 5);
-				field_size = idx_size (meta, MONO_TABLE_PARAM); break;
-			case MONO_TABLE_METHODIMPL:
-				g_assert (i == 0);
-				field_size = idx_size (meta, MONO_TABLE_TYPEDEF); break;
-			case MONO_TABLE_METHODSEMANTICS:
-				g_assert (i == 1);
-				field_size = idx_size (meta, MONO_TABLE_METHOD); break;
-			case MONO_TABLE_METHOD_POINTER:
-				g_assert (i == 0);
-				field_size = idx_size (meta, MONO_TABLE_METHOD); break;
-			case MONO_TABLE_NESTEDCLASS:
-				g_assert (i == 0 || i == 1);
-				field_size = idx_size (meta, MONO_TABLE_TYPEDEF); break;
-			case MONO_TABLE_PARAM_POINTER:
-				g_assert (i == 0);
-				field_size = idx_size (meta, MONO_TABLE_PARAM); break;
-			case MONO_TABLE_PROPERTYMAP:
-				g_assert (i == 0 || i == 1);
-				field_size = i ? idx_size (meta, MONO_TABLE_PROPERTY):
-					idx_size (meta, MONO_TABLE_TYPEDEF);
-				break;
-			case MONO_TABLE_PROPERTY_POINTER:
-				g_assert (i == 0);
-				field_size = idx_size (meta, MONO_TABLE_PROPERTY); break;
-			case MONO_TABLE_TYPEDEF:
-				g_assert (i == 4 || i == 5);
-				field_size = i == 4 ? idx_size (meta, MONO_TABLE_FIELD):
-					idx_size (meta, MONO_TABLE_METHOD);
-				break;
-			case MONO_TABLE_GENERICPARAM:
-				g_assert (i == 2);
-				n = MAX (get_nrows (meta, MONO_TABLE_METHOD), get_nrows (meta, MONO_TABLE_TYPEDEF));
-				/*This is a coded token for 2 tables, so takes 1 bit */
-				field_size = rtsize (meta, n, 16 - MONO_TYPEORMETHOD_BITS);
-				break;
-			case MONO_TABLE_GENERICPARAMCONSTRAINT:
-				g_assert (i == 0);
-				field_size = idx_size (meta, MONO_TABLE_GENERICPARAM);
-				break;
-			case MONO_TABLE_LOCALSCOPE:
-				switch (i) {
-				case 0:
-					field_size = idx_size (meta, MONO_TABLE_METHOD);
-					break;
-				case 1:
-					field_size = idx_size (meta, MONO_TABLE_IMPORTSCOPE);
-					break;
-				case 2:
-					field_size = idx_size (meta, MONO_TABLE_LOCALVARIABLE);
-					break;
-				case 3:
-					field_size = idx_size (meta, MONO_TABLE_LOCALCONSTANT);
-					break;
-				default:
-					g_assert_not_reached ();
-					break;
-				}
-				break;
-			case MONO_TABLE_METHODBODY:
-				g_assert (i == 0);
-				field_size = idx_size (meta, MONO_TABLE_DOCUMENT); break;
-			case MONO_TABLE_IMPORTSCOPE:
-				g_assert(i == 0);
-				field_size = idx_size (meta, MONO_TABLE_IMPORTSCOPE); break;
-			case MONO_TABLE_STATEMACHINEMETHOD:
-				g_assert(i == 0 || i == 1);
-				field_size = idx_size(meta, MONO_TABLE_METHOD); break;
-			default:
-				g_error ("Can't handle MONO_MT_TABLE_IDX for table %d element %d", tableindex, i);
-			}
-			break;
-			/*
-			 * HasConstant: ParamDef, FieldDef, Property
-			 */
-		case MONO_MT_CONST_IDX:
-			n = MAX (get_nrows (meta, MONO_TABLE_PARAM),
-				 get_nrows (meta, MONO_TABLE_FIELD));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_PROPERTY));
-			/* 2 bits to encode tag */
-			field_size = rtsize (meta, n, 16-2);
-			break;
-			/*
-			 * HasCustomAttribute: points to any table but
-			 * itself.
-			 */
-		case MONO_MT_HASCAT_IDX:
-			/*
-			 * We believe that since the signature and
-			 * permission are indexing the Blob heap,
-			 * we should consider the blob size first
-			 */
-			/* I'm not a believer - lupus
-			if (meta->idx_blob_wide){
-				field_size = 4;
-				break;
-			}*/
-			n = MAX (get_nrows (meta, MONO_TABLE_METHOD),
-				 get_nrows (meta, MONO_TABLE_FIELD));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_TYPEREF));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_TYPEDEF));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_PARAM));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_INTERFACEIMPL));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_MEMBERREF));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_MODULE));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_DECLSECURITY));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_PROPERTY));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_EVENT));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_STANDALONESIG));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_MODULEREF));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_TYPESPEC));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_ASSEMBLY));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_ASSEMBLYREF));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_FILE));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_EXPORTEDTYPE));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_MANIFESTRESOURCE));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_GENERICPARAM));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_GENERICPARAMCONSTRAINT));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_METHODSPEC));
-			/* 5 bits to encode */
-			field_size = rtsize (meta, n, 16-5);
-			break;
-			/*
-			* HasCustomAttribute: points to any table but
-			* itself.
-			*/
-		case MONO_MT_HASCUSTDEBUG_IDX:
-			n = MAX(get_nrows (meta, MONO_TABLE_METHOD),
-					get_nrows (meta, MONO_TABLE_FIELD));
-			n = MAX(n, get_nrows (meta, MONO_TABLE_TYPEREF));
-			n = MAX(n, get_nrows (meta, MONO_TABLE_TYPEDEF));
-			n = MAX(n, get_nrows (meta, MONO_TABLE_PARAM));
-			n = MAX(n, get_nrows (meta, MONO_TABLE_INTERFACEIMPL));
-			n = MAX(n, get_nrows (meta, MONO_TABLE_MEMBERREF));
-			n = MAX(n, get_nrows (meta, MONO_TABLE_MODULE));
-			n = MAX(n, get_nrows (meta, MONO_TABLE_DECLSECURITY));
-			n = MAX(n, get_nrows (meta, MONO_TABLE_PROPERTY));
-			n = MAX(n, get_nrows (meta, MONO_TABLE_EVENT));
-			n = MAX(n, get_nrows (meta, MONO_TABLE_STANDALONESIG));
-			n = MAX(n, get_nrows (meta, MONO_TABLE_MODULEREF));
-			n = MAX(n, get_nrows (meta, MONO_TABLE_TYPESPEC));
-			n = MAX(n, get_nrows (meta, MONO_TABLE_ASSEMBLY));
-			n = MAX(n, get_nrows (meta, MONO_TABLE_ASSEMBLYREF));
-			n = MAX(n, get_nrows (meta, MONO_TABLE_FILE));
-			n = MAX(n, get_nrows (meta, MONO_TABLE_EXPORTEDTYPE));
-			n = MAX(n, get_nrows (meta, MONO_TABLE_MANIFESTRESOURCE));
-			n = MAX(n, get_nrows (meta, MONO_TABLE_GENERICPARAM));
-			n = MAX(n, get_nrows (meta, MONO_TABLE_GENERICPARAMCONSTRAINT));
-			n = MAX(n, get_nrows (meta, MONO_TABLE_METHODSPEC));
-			n = MAX(n, get_nrows (meta, MONO_TABLE_DOCUMENT));
-			n = MAX(n, get_nrows (meta, MONO_TABLE_LOCALSCOPE));
-			n = MAX(n, get_nrows (meta, MONO_TABLE_LOCALVARIABLE));
-			n = MAX(n, get_nrows (meta, MONO_TABLE_LOCALCONSTANT));
-			n = MAX(n, get_nrows (meta, MONO_TABLE_IMPORTSCOPE));
-			/* 5 bits to encode */
-			field_size = rtsize(meta, n, 16 - 5);
-			break;
-			/*
-			 * CustomAttributeType: MethodDef, MemberRef.
-			 */
-		case MONO_MT_CAT_IDX:
-			n = MAX (get_nrows (meta, MONO_TABLE_METHOD),
-					 get_nrows (meta, MONO_TABLE_MEMBERREF));
-			/* 3 bits to encode */
-			field_size = rtsize (meta, n, 16-3);
-			break;
-			/*
-			 * HasDeclSecurity: Typedef, MethodDef, Assembly
-			 */
-		case MONO_MT_HASDEC_IDX:
-			n = MAX (get_nrows (meta, MONO_TABLE_TYPEDEF),
-				 get_nrows (meta, MONO_TABLE_METHOD));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_ASSEMBLY));
-			/* 2 bits to encode */
-			field_size = rtsize (meta, n, 16-2);
-			break;
-			/*
-			 * Implementation: File, AssemblyRef, ExportedType
-			 */
-		case MONO_MT_IMPL_IDX:
-			n = MAX (get_nrows (meta, MONO_TABLE_FILE),
-				 get_nrows (meta, MONO_TABLE_ASSEMBLYREF));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_EXPORTEDTYPE));
-			/* 2 bits to encode tag */
-			field_size = rtsize (meta, n, 16-2);
-			break;
-			/*
-			 * HasFieldMarshall: FieldDef, ParamDef
-			 */
-		case MONO_MT_HFM_IDX:
-			n = MAX (get_nrows (meta, MONO_TABLE_FIELD),
-				 get_nrows (meta, MONO_TABLE_PARAM));
-			/* 1 bit used to encode tag */
-			field_size = rtsize (meta, n, 16-1);
-			break;
-			/*
-			 * MemberForwarded: FieldDef, MethodDef
-			 */
-		case MONO_MT_MF_IDX:
-			n = MAX (get_nrows (meta, MONO_TABLE_FIELD),
-				 get_nrows (meta, MONO_TABLE_METHOD));
-			/* 1 bit used to encode tag */
-			field_size = rtsize (meta, n, 16-1);
-			break;
-			/*
-			 * TypeDefOrRef: TypeDef, ParamDef, TypeSpec
-			 * LAMESPEC
-			 * It is TypeDef, _TypeRef_, TypeSpec, instead.
-			 */
-		case MONO_MT_TDOR_IDX:
-			n = MAX (get_nrows (meta, MONO_TABLE_TYPEDEF),
-				 get_nrows (meta, MONO_TABLE_TYPEREF));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_TYPESPEC));
-			/* 2 bits to encode */
-			field_size = rtsize (meta, n, 16-2);
-			break;
-			/*
-			 * MemberRefParent: TypeDef, TypeRef, MethodDef, ModuleRef, TypeSpec, MemberRef
-			 */
-		case MONO_MT_MRP_IDX:
-			n = MAX (get_nrows (meta, MONO_TABLE_TYPEDEF),
-				 get_nrows (meta, MONO_TABLE_TYPEREF));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_METHOD));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_MODULEREF));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_TYPESPEC));
-			/* 3 bits to encode */
-			field_size = rtsize (meta, n, 16 - 3);
-			break;
-			/*
-			 * MethodDefOrRef: MethodDef, MemberRef
-			 */
-		case MONO_MT_MDOR_IDX:
-			n = MAX (get_nrows (meta, MONO_TABLE_METHOD),
-				 get_nrows (meta, MONO_TABLE_MEMBERREF));
-			/* 1 bit used to encode tag */
-			field_size = rtsize (meta, n, 16-1);
-			break;
-			/*
-			 * HasSemantics: Property, Event
-			 */
-		case MONO_MT_HS_IDX:
-			n = MAX (get_nrows (meta, MONO_TABLE_PROPERTY),
-				 get_nrows (meta, MONO_TABLE_EVENT));
-			/* 1 bit used to encode tag */
-			field_size = rtsize (meta, n, 16-1);
-			break;
-			/*
-			 * ResolutionScope: Module, ModuleRef, AssemblyRef, TypeRef
-			 */
-		case MONO_MT_RS_IDX:
-			n = MAX (get_nrows (meta, MONO_TABLE_MODULE),
-				 get_nrows (meta, MONO_TABLE_MODULEREF));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_ASSEMBLYREF));
-			n = MAX (n, get_nrows (meta, MONO_TABLE_TYPEREF));
-			/* 2 bits used to encode tag (ECMA spec claims 3) */
-			field_size = rtsize (meta, n, 16 - 2);
-			break;
-		}
-		/*
-		 * encode field size as follows (we just need to
-		 * distinguish them).
-		 *
-		 * 4 -> 3
-		 * 2 -> 1
-		 * 1 -> 0
-		 */
-		bitfield |= (field_size-1) << shift;
-		shift += 2;
-		size += field_size;
-		/*g_print ("table %02x field %d size %d\n", tableindex, i, field_size);*/
-	}
-	*result_bitfield = (i << 24) | bitfield;
-	return size;
-}
-/* returns true if given index is not in bounds with provided table/index pair */
-gboolean
-mono_metadata_table_bounds_check_slow (MonoImage *image, int table_index, int token_index)
-{
-	if (G_LIKELY (GINT_TO_UINT32(token_index) <= table_info_get_rows (&image->tables [table_index])))
-		return FALSE;
-	if (G_LIKELY (!image->has_updates))
-		return TRUE;
-	return mono_metadata_update_table_bounds_check (image, table_index, token_index);
-}
-void
-mono_metadata_compute_column_offsets (MonoTableInfo *table)
-{
-	int offset = 0, c = mono_metadata_table_count (table->size_bitfield);
-	memset(table->column_offsets, 0, MONO_TABLE_INFO_MAX_COLUMNS);
-	for (int i = 0; i < c; i++) {
-		int size = mono_metadata_table_size (table->size_bitfield, i);
-		table->column_offsets[i] = (guint8)offset;
-		offset += size;
-	}
-}
-/**
- * mono_metadata_compute_table_bases:
- * \param meta metadata context to compute table values
- *
- * Computes the table bases for the metadata structure.
- * This is an internal function used by the image loader code.
- */
-void
-mono_metadata_compute_table_bases (MonoImage *meta)
-{
-	int i;
-	const char *base = meta->tables_base;
-	for (i = 0; i < MONO_TABLE_NUM; i++) {
-		MonoTableInfo *table = &meta->tables [i];
-		if (table_info_get_rows (table) == 0)
-			continue;
-		table->row_size = mono_metadata_compute_size (meta, i, &table->size_bitfield);
-		mono_metadata_compute_column_offsets (table);
-		table->base = base;
-		base += table_info_get_rows (table) * table->row_size;
-	}
-}
-/**
- * mono_metadata_locate:
- * \param meta metadata context
- * \param table table code.
- * \param idx index of element to retrieve from \p table.
- *
- * \returns a pointer to the \p idx element in the metadata table
- * whose code is \p table.
- */
-const char *
-mono_metadata_locate (MonoImage *meta, int table, int idx)
-{
-	/* FIXME: metadata-update */
-	/* idx == 0 refers always to NULL */
-	g_return_val_if_fail (idx > 0 && GINT_TO_UINT32(idx) <= table_info_get_rows (&meta->tables [table]), ""); /*FIXME shouldn't we return NULL here?*/
-	return meta->tables [table].base + (meta->tables [table].row_size * (idx - 1));
-}
-/**
- * mono_metadata_locate_token:
- * \param meta metadata context
- * \param token metadata token
- *
- * \returns a pointer to the data in the metadata represented by the
- * token \p token .
- */
-const char *
-mono_metadata_locate_token (MonoImage *meta, guint32 token)
-{
-	return mono_metadata_locate (meta, token >> 24, token & 0xffffff);
-}
-static MonoStreamHeader *
-get_string_heap (MonoImage *image)
-{
-	return &image->heap_strings;
-}
-static MonoStreamHeader *
-get_user_string_heap (MonoImage *image)
-{
-	return &image->heap_us;
-}
-static MonoStreamHeader *
-get_blob_heap (MonoImage *image)
-{
-	return &image->heap_blob;
-}
-static gboolean
-mono_delta_heap_lookup (MonoImage *base_image, MetadataHeapGetterFunc get_heap, guint32 orig_index, MonoImage **image_out, guint32 *index_out)
-{
-	return mono_metadata_update_delta_heap_lookup (base_image, get_heap, orig_index, image_out, index_out);
-}
-/**
- * mono_metadata_string_heap:
- * \param meta metadata context
- * \param index index into the string heap.
- * \returns an in-memory pointer to the \p index in the string heap.
- */
-const char *
-mono_metadata_string_heap (MonoImage *meta, guint32 index)
-{
-	if (G_UNLIKELY (index >= meta->heap_strings.size && meta->has_updates)) {
-		MonoImage *dmeta;
-		guint32 dindex;
-		gboolean ok = mono_delta_heap_lookup (meta, &get_string_heap, index, &dmeta, &dindex);
-		g_assertf (ok, "Could not find token=0x%08x in string heap of assembly=%s and its delta images", index, meta && meta->name ? meta->name : "unknown image");
-		meta = dmeta;
-		index = dindex;
-	}
-	g_assertf (index < meta->heap_strings.size, " index = 0x%08x size = 0x%08x meta=%s ", index, meta->heap_strings.size, meta && meta->name ? meta->name : "unknown image" );
-	g_return_val_if_fail (index < meta->heap_strings.size, "");
-	return meta->heap_strings.data + index;
-}
-/**
- * mono_metadata_string_heap_checked:
- * \param meta metadata context
- * \param index index into the string heap.
- * \param error set on error
- * \returns an in-memory pointer to the \p index in the string heap.
- * On failure returns NULL and sets \p error.
- */
-const char *
-mono_metadata_string_heap_checked (MonoImage *meta, guint32 index, MonoError *error)
-{
-	if (mono_image_is_dynamic (meta))
-	{
-		MonoDynamicImage* img = (MonoDynamicImage*) meta;
-		const char *image_name = meta && meta->name ? meta->name : "unknown image";
-		if (G_UNLIKELY (!(index < img->sheap.index))) {
-			mono_error_set_bad_image_by_name (error, image_name, "string heap index %ud out bounds %u: %s", index, img->sheap.index, image_name);
-			return NULL;
-		}
-		return img->sheap.data + index;
-	}
-	if (G_UNLIKELY (index >= meta->heap_strings.size && meta->has_updates)) {
-		MonoImage *dmeta;
-		guint32 dindex;
-		gboolean ok = mono_delta_heap_lookup (meta, &get_string_heap, index, &dmeta, &dindex);
-		if (G_UNLIKELY (!ok)) {
-			const char *image_name = meta && meta->name ? meta->name : "unknown image";
-			mono_error_set_bad_image_by_name (error, image_name, "string heap index %ud out bounds %u: %s, also checked delta images", index, meta->heap_strings.size, image_name);
-			return NULL;
-		}
-		meta = dmeta;
-		index = dindex;
-	}
-	if (G_UNLIKELY (!(index < meta->heap_strings.size))) {
-		const char *image_name = meta && meta->name ? meta->name : "unknown image";
-		mono_error_set_bad_image_by_name (error, image_name, "string heap index %ud out bounds %u: %s", index, meta->heap_strings.size, image_name);
-		return NULL;
-	}
-	return meta->heap_strings.data + index;
-}
-/**
- * mono_metadata_user_string:
- * \param meta metadata context
- * \param index index into the user string heap.
- * \returns an in-memory pointer to the \p index in the user string heap (<code>#US</code>).
- */
-const char *
-mono_metadata_user_string (MonoImage *meta, guint32 index)
-{
-	if (G_UNLIKELY (index >= meta->heap_us.size && meta->has_updates)) {
-		MonoImage *dmeta;
-		guint32 dindex;
-		gboolean ok = mono_delta_heap_lookup (meta, &get_user_string_heap, index, &dmeta, &dindex);
-		g_assertf (ok, "Could not find token=0x%08x in user string heap of assembly=%s and its delta images", index, meta && meta->name ? meta->name : "unknown image");
-		meta = dmeta;
-		index = dindex;
-	}
-	g_assert (index < meta->heap_us.size);
-	g_return_val_if_fail (index < meta->heap_us.size, "");
-	return meta->heap_us.data + index;
-}
-/**
- * mono_metadata_blob_heap:
- * \param meta metadata context
- * \param index index into the blob.
- * \returns an in-memory pointer to the \p index in the Blob heap.
- */
-const char *
-mono_metadata_blob_heap (MonoImage *meta, guint32 index)
-{
-	/* Some tools can produce assemblies with a size 0 Blob stream. If a
-	 * blob value is optional, if the index == 0 and heap_blob.size == 0
-	 * assertion is hit, consider updating caller to use
-	 * mono_metadata_blob_heap_null_ok and handling a null return value. */
-	g_assert (!(index == 0 && meta->heap_blob.size == 0));
-	if (G_UNLIKELY (index >= meta->heap_blob.size && meta->has_updates)) {
-		MonoImage *dmeta;
-		guint32 dindex;
-		gboolean ok = mono_delta_heap_lookup (meta, &get_blob_heap, index, &dmeta, &dindex);
-		g_assertf (ok, "Could not find token=0x%08x in blob heap of assembly=%s and its delta images", index, meta && meta->name ? meta->name : "unknown image");
-		meta = dmeta;
-		index = dindex;
-	}
-	g_assert (index < meta->heap_blob.size);
-	return meta->heap_blob.data + index;
-}
-/**
- * mono_metadata_blob_heap_null_ok:
- * \param meta metadata context
- * \param index index into the blob.
- * \return an in-memory pointer to the \p index in the Blob heap.
- * If the Blob heap is empty or missing and index is 0 returns NULL, instead of asserting.
- */
-const char *
-mono_metadata_blob_heap_null_ok (MonoImage *meta, guint32 index)
-{
-	if (G_UNLIKELY (index == 0 && meta->heap_blob.size == 0))
-		return NULL;
-	else
-		return mono_metadata_blob_heap (meta, index);
-}
-/**
- * mono_metadata_blob_heap_checked:
- * \param meta metadata context
- * \param index index into the blob.
- * \param error set on error
- * \returns an in-memory pointer to the \p index in the Blob heap.  On failure sets \p error and returns NULL;
- * If the Blob heap is empty or missing and \p index is 0 returns NULL, without setting error.
- *
- */
-const char *
-mono_metadata_blob_heap_checked (MonoImage *meta, guint32 index, MonoError *error)
-{
-	if (mono_image_is_dynamic (meta)) {
-		MonoDynamicImage* img = (MonoDynamicImage*) meta;
-		const char *image_name = meta && meta->name ? meta->name : "unknown image";
-		if (G_UNLIKELY (!(index < img->blob.index))) {
-			mono_error_set_bad_image_by_name (error, image_name, "blob heap index %u out of bounds %u: %s", index, img->blob.index, image_name);
-			return NULL;
-		}
-		if (G_UNLIKELY (index == 0 && img->blob.alloc_size == 0))
-			return NULL;
-		return img->blob.data + index;
-	}
-	if (G_UNLIKELY (index == 0 && meta->heap_blob.size == 0))
-		return NULL;
-	if (G_UNLIKELY (index >= meta->heap_blob.size && meta->has_updates)) {
-		MonoImage *dmeta;
-		guint32 dindex;
-		gboolean ok = mono_delta_heap_lookup (meta, &get_blob_heap, index, &dmeta, &dindex);
-		if (G_UNLIKELY(!ok)) {
-			const char *image_name = meta && meta->name ? meta->name : "unknown image";
-			mono_error_set_bad_image_by_name (error, image_name, "Could not find token=0x%08x in blob heap of assembly=%s and its delta images", index, image_name);
-			return NULL;
-		}
-		meta = dmeta;
-		index = dindex;
-	}
-	if (G_UNLIKELY (!(index < meta->heap_blob.size))) {
-		const char *image_name = meta && meta->name ? meta->name : "unknown image";
-		mono_error_set_bad_image_by_name (error, image_name, "blob heap index %u out of bounds %u: %s", index, meta->heap_blob.size, image_name);
-		return NULL;
-	}
-	return meta->heap_blob.data + index;
-}
-/**
- * mono_metadata_guid_heap:
- * \param meta metadata context
- * \param index index into the guid heap.
- * \returns an in-memory pointer to the \p index in the guid heap.
- */
-const char *
-mono_metadata_guid_heap (MonoImage *meta, guint32 index)
-{
-	/* EnC TODO: lookup in DeltaInfo:delta_image_last.  Unlike the other heaps, the GUID heaps are always full in every delta, even in minimal delta images. */
-	--index;
-	index *= 16; /* adjust for guid size and 1-based index */
-	g_return_val_if_fail (index < meta->heap_guid.size, "");
-	return meta->heap_guid.data + index;
-}
-static const unsigned char *
-dword_align (const unsigned char *ptr)
-{
-	return (const unsigned char *) (((gsize) (ptr + 3)) & ~3);
-}
-static void
-mono_metadata_decode_row_slow (const MonoTableInfo *t, int idx, guint32 *res, int res_size);
-/**
- * mono_metadata_decode_row:
- * \param t table to extract information from.
- * \param idx index in table.
- * \param res array of \p res_size cols to store the results in
- *
- * This decompresses the metadata element \p idx in table \p t
- * into the \c guint32 \p res array that has \p res_size elements
- */
-void
-mono_metadata_decode_row (const MonoTableInfo *t, int idx, guint32 *res, int res_size)
-{
-	if (G_UNLIKELY (mono_metadata_has_updates ())) {
-		mono_metadata_decode_row_slow (t, idx, res, res_size);
-	} else {
-		mono_metadata_decode_row_raw (t, idx, res, res_size);
-	}
-}
-void
-mono_metadata_decode_row_slow (const MonoTableInfo *t, int idx, guint32 *res, int res_size)
-{
-	g_assert (idx >= 0);
-	mono_image_effective_table (&t, idx);
-	mono_metadata_decode_row_raw (t, idx, res, res_size);
-}
-/**
- * same as mono_metadata_decode_row, but ignores potential delta images
- */
-void
-mono_metadata_decode_row_raw (const MonoTableInfo *t, int idx, guint32 *res, int res_size)
-{
-	guint32 bitfield = t->size_bitfield;
-	int i, count = mono_metadata_table_count (bitfield);
-	const char *data;
-	g_assert (GINT_TO_UINT32(idx) < table_info_get_rows (t));
-	g_assert (idx >= 0);
-	data = t->base + idx * t->row_size;
-	g_assert (res_size == count);
-	for (i = 0; i < count; i++) {
-		int n = mono_metadata_table_size (bitfield, i);
-		switch (n){
-		case 1:
-			res [i] = *data; break;
-		case 2:
-			res [i] = read16 (data); break;
-		case 4:
-			res [i] = read32 (data); break;
-		default:
-			g_assert_not_reached ();
-		}
-		data += n;
-	}
-}
-/**
- * mono_metadata_decode_row_checked:
- * \param image the \c MonoImage the table belongs to
- * \param t table to extract information from.
- * \param idx index in the table.
- * \param res array of \p res_size cols to store the results in
- * \param error set on bounds error
- *
- *
- * This decompresses the metadata element \p idx in the table \p t
- * into the \c guint32 \p res array that has \p res_size elements.
- *
- * \returns TRUE if the read succeeded. Otherwise sets \p error and returns FALSE.
- */
-gboolean
-mono_metadata_decode_row_checked (const MonoImage *image, const MonoTableInfo *t, int idx, guint32 *res, int res_size, MonoError *error)
-{
-	const char *image_name = image && image->name ? image->name : "unknown image";
-	g_assert (idx >= 0);
-	mono_image_effective_table (&t, idx);
-	guint32 bitfield = t->size_bitfield;
-	int i, count = mono_metadata_table_count (bitfield);
-	if (G_UNLIKELY (! (GINT_TO_UINT32(idx) < table_info_get_rows (t) && idx >= 0))) {
-		mono_error_set_bad_image_by_name (error, image_name, "row index %d out of bounds: %d rows: %s", idx, table_info_get_rows (t), image_name);
-		return FALSE;
-	}
-	const char *data = t->base + idx * t->row_size;
-	if (G_UNLIKELY (res_size != count)) {
-		mono_error_set_bad_image_by_name (error, image_name, "res_size %d != count %d: %s", res_size, count, image_name);
-		return FALSE;
-	}
-	for (i = 0; i < count; i++) {
-		int n = mono_metadata_table_size (bitfield, i);
-		switch (n) {
-		case 1:
-			res [i] = *data; break;
-		case 2:
-			res [i] = read16 (data); break;
-		case 4:
-			res [i] = read32 (data); break;
-		default:
-			mono_error_set_bad_image_by_name (error, image_name, "unexpected table [%d] size %d: %s", i, n, image_name);
-			return FALSE;
-		}
-		data += n;
-	}
-	return TRUE;
-}
-gboolean
-mono_metadata_decode_row_dynamic_checked (const MonoDynamicImage *image, const MonoDynamicTable *t, guint idx, guint32 *res, int res_size, MonoError *error)
-{
-	int i, count = t->columns;
-	const char *image_name = image && image->image.name ? image->image.name : "unknown image";
-	if (G_UNLIKELY (! (idx < t->rows && idx >= 0))) {
-		mono_error_set_bad_image_by_name (error, image_name, "row index %d out of bounds: %d rows: %s", idx, t->rows, image_name);
-		return FALSE;
-	}
-	guint32 *data = t->values + (idx + 1) * count;
-	if (G_UNLIKELY (res_size != count)) {
-		mono_error_set_bad_image_by_name (error, image_name, "res_size %d != count %d: %s", res_size, count, image_name);
-		return FALSE;
-	}
-	for (i = 0; i < count; i++) {
-		res [i] = *data;
-		data++;
-	}
-	return TRUE;
-}
-static guint32
-mono_metadata_decode_row_col_raw (const MonoTableInfo *t, int idx, guint col);
-static guint32
-mono_metadata_decode_row_col_slow (const MonoTableInfo *t, int idx, guint col);
-/**
- * mono_metadata_decode_row_col:
- * \param t table to extract information from.
- * \param idx index for row in table.
- * \param col column in the row.
- *
- * This function returns the value of column \p col from the \p idx
- * row in the table \p t .
- */
-guint32
-mono_metadata_decode_row_col (const MonoTableInfo *t, int idx, guint col)
-{
-	if (G_UNLIKELY (mono_metadata_has_updates ())) {
-		return mono_metadata_decode_row_col_slow (t, idx, col);
-	} else {
-		return mono_metadata_decode_row_col_raw (t, idx, col);
-	}
-}
-guint32
-mono_metadata_decode_row_col_slow (const MonoTableInfo *t, int idx, guint col)
-{
-	g_assert (idx >= 0);
-	mono_image_effective_table (&t, idx);
-	return mono_metadata_decode_row_col_raw (t, idx, col);
-}
-/**
- * mono_metadata_decode_row_col_raw:
- *
- * Same as \c mono_metadata_decode_row_col but doesn't look for the effective
- * table on metadata updates.
- */
-guint32
-mono_metadata_decode_row_col_raw (const MonoTableInfo *t, int idx, guint col)
-{
-	const char *data;
-	int n;
-	guint32 bitfield = t->size_bitfield;
-	g_assert (GINT_TO_UINT32(idx) < table_info_get_rows (t));
-	g_assert (col < mono_metadata_table_count (bitfield));
-	data = t->base + idx * t->row_size + t->column_offsets [col];
-	n = mono_metadata_table_size (bitfield, col);
-	switch (n) {
-	case 1:
-		return *data;
-	case 2:
-		return read16 (data);
-	case 4:
-		return read32 (data);
-	default:
-		g_assert_not_reached ();
-	}
-	return 0;
-}
-/**
- * mono_metadata_decode_blob_size:
- * \param ptr pointer to a blob object
- * \param rptr the new position of the pointer
- *
- * This decodes a compressed size as described by 24.2.4 (#US and #Blob a blob or user string object)
- *
- * \returns the size of the blob object
- */
-guint32
-mono_metadata_decode_blob_size (const char *xptr, const char **rptr)
-{
-	const unsigned char *ptr = (const unsigned char *)xptr;
-	guint32 size;
-	if ((*ptr & 0x80) == 0){
-		size = ptr [0] & 0x7f;
-		ptr++;
-	} else if ((*ptr & 0x40) == 0){
-		size = ((ptr [0] & 0x3f) << 8) + ptr [1];
-		ptr += 2;
-	} else {
-		size = ((ptr [0] & 0x1f) << 24) +
-			(ptr [1] << 16) +
-			(ptr [2] << 8) +
-			ptr [3];
-		ptr += 4;
-	}
-	if (rptr)
-		*rptr = (char*)ptr;
-	return size;
-}
-/**
- * mono_metadata_decode_value:
- * \param ptr pointer to decode from
- * \param rptr the new position of the pointer
- *
- * This routine decompresses 32-bit values as specified in the "Blob and
- * Signature" section (23.2)
- *
- * \returns the decoded value
- */
-guint32
-mono_metadata_decode_value (const char *_ptr, const char **rptr)
-{
-	const unsigned char *ptr = (const unsigned char *) _ptr;
-	unsigned char b = *ptr;
-	guint32 len;
-	if ((b & 0x80) == 0){
-		len = b;
-		++ptr;
-	} else if ((b & 0x40) == 0){
-		len = ((b & 0x3f) << 8 | ptr [1]);
-		ptr += 2;
-	} else {
-		len = ((b & 0x1f) << 24) |
-			(ptr [1] << 16) |
-			(ptr [2] << 8) |
-			ptr [3];
-		ptr += 4;
-	}
-	if (rptr)
-		*rptr = (char*)ptr;
-	return len;
-}
-/**
- * mono_metadata_decode_signed_value:
- * \param ptr pointer to decode from
- * \param rptr the new position of the pointer
- *
- * This routine decompresses 32-bit signed values
- * (not specified in the spec)
- *
- * \returns the decoded value
- */
-gint32
-mono_metadata_decode_signed_value (const char *ptr, const char **rptr)
-{
-	guint32 uval = mono_metadata_decode_value (ptr, rptr);
-	gint32 ival = uval >> 1;
-	if (!(uval & 1))
-		return ival;
-	/* ival is a truncated 2's complement negative number.  */
-	if (ival < 0x40)
-		/* 6 bits = 7 bits for compressed representation (top bit is '0') - 1 sign bit */
-		return ival - 0x40;
-	if (ival < 0x2000)
-		/* 13 bits = 14 bits for compressed representation (top bits are '10') - 1 sign bit */
-		return ival - 0x2000;
-	if (ival < 0x10000000)
-		/* 28 bits = 29 bits for compressed representation (top bits are '110') - 1 sign bit */
-		return ival - 0x10000000;
-	g_assert (ival < 0x20000000);
-	g_warning ("compressed signed value appears to use 29 bits for compressed representation: %x (raw: %8x)", ival, uval);
-	return ival - 0x20000000;
-}
-/**
- * mono_metadata_translate_token_index:
- * Translates the given 1-based index into the \c Method, \c Field, \c Event, or \c Param tables
- * using the \c *Ptr tables in uncompressed metadata, if they are available.
- *
- * FIXME: The caller is not forced to call this function, which is error-prone, since
- * forgetting to call it would only show up as a bug on uncompressed metadata.
- */
-guint32
-mono_metadata_translate_token_index (MonoImage *image, int table, guint32 idx)
-{
-	if (!image->uncompressed_metadata)
-		return idx;
-	switch (table) {
-	case MONO_TABLE_METHOD:
-		if (table_info_get_rows (&image->tables [MONO_TABLE_METHOD_POINTER]))
-			return mono_metadata_decode_row_col (&image->tables [MONO_TABLE_METHOD_POINTER], idx - 1, MONO_METHOD_POINTER_METHOD);
-		else
-			return idx;
-	case MONO_TABLE_FIELD:
-		if (table_info_get_rows (&image->tables [MONO_TABLE_FIELD_POINTER]))
-			return mono_metadata_decode_row_col (&image->tables [MONO_TABLE_FIELD_POINTER], idx - 1, MONO_FIELD_POINTER_FIELD);
-		else
-			return idx;
-	case MONO_TABLE_EVENT:
-		if (table_info_get_rows (&image->tables [MONO_TABLE_EVENT_POINTER]))
-			return mono_metadata_decode_row_col (&image->tables [MONO_TABLE_EVENT_POINTER], idx - 1, MONO_EVENT_POINTER_EVENT);
-		else
-			return idx;
-	case MONO_TABLE_PROPERTY:
-		if (table_info_get_rows (&image->tables [MONO_TABLE_PROPERTY_POINTER]))
-			return mono_metadata_decode_row_col (&image->tables [MONO_TABLE_PROPERTY_POINTER], idx - 1, MONO_PROPERTY_POINTER_PROPERTY);
-		else
-			return idx;
-	case MONO_TABLE_PARAM:
-		if (table_info_get_rows (&image->tables [MONO_TABLE_PARAM_POINTER]))
-			return mono_metadata_decode_row_col (&image->tables [MONO_TABLE_PARAM_POINTER], idx - 1, MONO_PARAM_POINTER_PARAM);
-		else
-			return idx;
-	default:
-		return idx;
-	}
-}
-/**
- * mono_metadata_decode_table_row:
- *
- * Same as \c mono_metadata_decode_row, but takes an \p image + \p table ID pair, and takes
- * uncompressed metadata into account, so it should be used to access the
- * \c Method, \c Field, \c Param and \c Event tables when the access is made from metadata, i.e.
- * \p idx is retrieved from a metadata table, like \c MONO_TYPEDEF_FIELD_LIST.
- */
-void
-mono_metadata_decode_table_row (MonoImage *image, int table, int idx, guint32 *res, int res_size)
-{
-	if (image->uncompressed_metadata)
-		idx = mono_metadata_translate_token_index (image, table, idx + 1) - 1;
-	mono_metadata_decode_row (&image->tables [table], idx, res, res_size);
-}
-/**
- * mono_metadata_decode_table_row_col:
- *
- * Same as \c mono_metadata_decode_row_col, but takes an \p image + \p table ID pair, and takes
- * uncompressed metadata into account, so it should be used to access the
- * \c Method, \c Field, \c Param and \c Event tables.
- */
-guint32 mono_metadata_decode_table_row_col (MonoImage *image, int table, int idx, guint col)
-{
-	if (image->uncompressed_metadata)
-		idx = mono_metadata_translate_token_index (image, table, idx + 1) - 1;
-	return mono_metadata_decode_row_col (&image->tables [table], idx, col);
-}
-/**
- * mono_metadata_parse_typedef_or_ref:
- * \param m a metadata context.
- * \param ptr a pointer to an encoded TypedefOrRef in \p m
- * \param rptr pointer updated to match the end of the decoded stream
- * \returns a token valid in the \p m metadata decoded from
- * the compressed representation.
- */
-guint32
-mono_metadata_parse_typedef_or_ref (MonoImage *m, const char *ptr, const char **rptr)
-{
-	guint32 token;
-	token = mono_metadata_decode_value (ptr, &ptr);
-	if (rptr)
-		*rptr = ptr;
-	return mono_metadata_token_from_dor (token);
-}
-/**
- * mono_metadata_parse_custom_mod:
- * \param m a metadata context.
- * \param dest storage where the info about the custom modifier is stored (may be NULL)
- * \param ptr a pointer to (possibly) the start of a custom modifier list
- * \param rptr pointer updated to match the end of the decoded stream
- *
- * Checks if \p ptr points to a type custom modifier compressed representation.
- *
- * \returns TRUE if a custom modifier was found, FALSE if not.
- */
-int
-mono_metadata_parse_custom_mod (MonoImage *m, MonoCustomMod *dest, const char *ptr, const char **rptr)
-{
-	MonoCustomMod local;
-	if ((*ptr == MONO_TYPE_CMOD_OPT) || (*ptr == MONO_TYPE_CMOD_REQD)) {
-		if (!dest)
-			dest = &local;
-		dest->required = *ptr == MONO_TYPE_CMOD_REQD ? 1 : 0;
-		dest->token = mono_metadata_parse_typedef_or_ref (m, ptr + 1, rptr);
-		return TRUE;
-	}
-	return FALSE;
-}
-/*
- * mono_metadata_parse_array_internal:
- * @m: a metadata context.
- * @transient: whenever to allocate data from the heap
- * @ptr: a pointer to an encoded array description.
- * @rptr: pointer updated to match the end of the decoded stream
- *
- * Decodes the compressed array description found in the metadata @m at @ptr.
- *
- * Returns: a #MonoArrayType structure describing the array type
- * and dimensions. Memory is allocated from the heap or from the image mempool, depending
- * on the value of @transient.
- *
- * LOCKING: Acquires the loader lock
- */
-static MonoArrayType *
-mono_metadata_parse_array_internal (MonoImage *m, MonoGenericContainer *container,
-									gboolean transient, const char *ptr, const char **rptr, MonoError *error)
-{
-	int i;
-	MonoArrayType *array;
-	MonoType *etype;
-	etype = mono_metadata_parse_type_checked (m, container, 0, FALSE, ptr, &ptr, error); //FIXME this doesn't respect @transient
-	if (!etype)
-		return NULL;
-	array = transient ? (MonoArrayType *)g_malloc0 (sizeof (MonoArrayType)) : (MonoArrayType *)mono_image_alloc0 (m, sizeof (MonoArrayType));
-	array->eklass = mono_class_from_mono_type_internal (etype);
-	array->rank = GUINT32_TO_UINT8 (mono_metadata_decode_value (ptr, &ptr));
-	array->numsizes = GUINT32_TO_UINT8 (mono_metadata_decode_value (ptr, &ptr));
-	if (array->numsizes)
-		array->sizes = transient ? (int *)g_malloc0 (sizeof (int) * array->numsizes) : (int *)mono_image_alloc0 (m, sizeof (int) * array->numsizes);
-	for (i = 0; i < array->numsizes; ++i)
-		array->sizes [i] = mono_metadata_decode_value (ptr, &ptr);
-	array->numlobounds = GUINT32_TO_UINT8 (mono_metadata_decode_value (ptr, &ptr));
-	if (array->numlobounds)
-		array->lobounds = transient ? (int *)g_malloc0 (sizeof (int) * array->numlobounds) : (int *)mono_image_alloc0 (m, sizeof (int) * array->numlobounds);
-	for (i = 0; i < array->numlobounds; ++i)
-		array->lobounds [i] = mono_metadata_decode_signed_value (ptr, &ptr);
-	if (rptr)
-		*rptr = ptr;
-	return array;
-}
-/**
- * mono_metadata_parse_array:
- */
-MonoArrayType *
-mono_metadata_parse_array (MonoImage *m, const char *ptr, const char **rptr)
-{
-	ERROR_DECL (error);
-	MonoArrayType *ret = mono_metadata_parse_array_internal (m, NULL, FALSE, ptr, rptr, error);
-	mono_error_cleanup (error);
-	return ret;
-}
-/**
- * mono_metadata_free_array:
- * \param array array description
- *
- * Frees the array description returned from \c mono_metadata_parse_array.
- */
-void
-mono_metadata_free_array (MonoArrayType *array)
-{
-	g_free (array->sizes);
-	g_free (array->lobounds);
-	g_free (array);
-}
-/*
- * need to add common field and param attributes combinations:
- * [out] param
- * public static
- * public static literal
- * private
- * private static
- * private static literal
- */
-static const MonoType
-builtin_types[] = {
-	/* data, attrs, type,              nmods, byref, pinned */
-	{{NULL}, 0,     MONO_TYPE_VOID,    0,     0,     0},
-	{{NULL}, 0,     MONO_TYPE_BOOLEAN, 0,     0,     0},
-	{{NULL}, 0,     MONO_TYPE_BOOLEAN, 0,     1,     0},
-	{{NULL}, 0,     MONO_TYPE_CHAR,    0,     0,     0},
-	{{NULL}, 0,     MONO_TYPE_CHAR,    0,     1,     0},
-	{{NULL}, 0,     MONO_TYPE_I1,      0,     0,     0},
-	{{NULL}, 0,     MONO_TYPE_I1,      0,     1,     0},
-	{{NULL}, 0,     MONO_TYPE_U1,      0,     0,     0},
-	{{NULL}, 0,     MONO_TYPE_U1,      0,     1,     0},
-	{{NULL}, 0,     MONO_TYPE_I2,      0,     0,     0},
-	{{NULL}, 0,     MONO_TYPE_I2,      0,     1,     0},
-	{{NULL}, 0,     MONO_TYPE_U2,      0,     0,     0},
-	{{NULL}, 0,     MONO_TYPE_U2,      0,     1,     0},
-	{{NULL}, 0,     MONO_TYPE_I4,      0,     0,     0},
-	{{NULL}, 0,     MONO_TYPE_I4,      0,     1,     0},
-	{{NULL}, 0,     MONO_TYPE_U4,      0,     0,     0},
-	{{NULL}, 0,     MONO_TYPE_U4,      0,     1,     0},
-	{{NULL}, 0,     MONO_TYPE_I8,      0,     0,     0},
-	{{NULL}, 0,     MONO_TYPE_I8,      0,     1,     0},
-	{{NULL}, 0,     MONO_TYPE_U8,      0,     0,     0},
-	{{NULL}, 0,     MONO_TYPE_U8,      0,     1,     0},
-	{{NULL}, 0,     MONO_TYPE_R4,      0,     0,     0},
-	{{NULL}, 0,     MONO_TYPE_R4,      0,     1,     0},
-	{{NULL}, 0,     MONO_TYPE_R8,      0,     0,     0},
-	{{NULL}, 0,     MONO_TYPE_R8,      0,     1,     0},
-	{{NULL}, 0,     MONO_TYPE_STRING,  0,     0,     0},
-	{{NULL}, 0,     MONO_TYPE_STRING,  0,     1,     0},
-	{{NULL}, 0,     MONO_TYPE_OBJECT,  0,     0,     0},
-	{{NULL}, 0,     MONO_TYPE_OBJECT,  0,     1,     0},
-	{{NULL}, 0,     MONO_TYPE_TYPEDBYREF,  0,     0,     0},
-	{{NULL}, 0,     MONO_TYPE_I,       0,     0,     0},
-	{{NULL}, 0,     MONO_TYPE_I,       0,     1,     0},
-	{{NULL}, 0,     MONO_TYPE_U,       0,     0,     0},
-	{{NULL}, 0,     MONO_TYPE_U,       0,     1,     0},
-};
-static GHashTable *type_cache = NULL;
-static gint32 next_generic_inst_id = 0;
-static guint mono_generic_class_hash (gconstpointer data);
-/*
- * MonoTypes with modifies are never cached, so we never check or use that field.
- */
-static guint
-mono_type_hash (gconstpointer data)
-{
-	const MonoType *type = (const MonoType *) data;
-	if (type->type == MONO_TYPE_GENERICINST)
-		return mono_generic_class_hash (type->data.generic_class);
-	else
-		return type->type | ((m_type_is_byref (type) ? 1 : 0) << 8) | (type->attrs << 9);
-}
-static gint
-mono_type_equal (gconstpointer ka, gconstpointer kb)
-{
-	const MonoType *a = (const MonoType *) ka;
-	const MonoType *b = (const MonoType *) kb;
-	if (a->type != b->type || m_type_is_byref (a) != m_type_is_byref (b) || a->attrs != b->attrs || a->pinned != b->pinned)
-		return 0;
-	/* need other checks */
-	return 1;
-}
-guint
-mono_metadata_generic_inst_hash (gconstpointer data)
-{
-	const MonoGenericInst *ginst = (const MonoGenericInst *) data;
-	guint hash = 0;
-	g_assert (ginst);
-	g_assert (ginst->type_argv);
-	for (guint i = 0; i < ginst->type_argc; ++i) {
-		hash *= 13;
-		g_assert (ginst->type_argv [i]);
-		hash += mono_metadata_type_hash (ginst->type_argv [i]);
-	}
-	return hash ^ (ginst->is_open << 8);
-}
-static gboolean
-mono_generic_inst_equal_full (const MonoGenericInst *a, const MonoGenericInst *b, gboolean signature_only)
-{
-#ifndef MONO_SMALL_CONFIG // Optimization does not work in MONO_SMALL_CONFIG: There are no IDs
-	if (a->id && b->id) { // "id 0" means "object has no id"-- de-duping hasn't been performed yet, must check contents.
-		if (a->id == b->id)
-			return TRUE;
-		if (!signature_only)
-			return FALSE;
-	}
-#endif
-	if (a->is_open != b->is_open || a->type_argc != b->type_argc)
-		return FALSE;
-	for (guint i = 0; i < a->type_argc; ++i) {
-		if (!do_mono_metadata_type_equal (a->type_argv [i], b->type_argv [i], signature_only ? MONO_TYPE_EQ_FLAGS_SIG_ONLY : 0))
-			return FALSE;
-	}
-	return TRUE;
-}
-gboolean
-mono_metadata_generic_inst_equal (gconstpointer ka, gconstpointer kb)
-{
-	const MonoGenericInst *a = (const MonoGenericInst *) ka;
-	const MonoGenericInst *b = (const MonoGenericInst *) kb;
-	return mono_generic_inst_equal_full (a, b, FALSE);
-}
-static guint
-mono_generic_class_hash (gconstpointer data)
-{
-	const MonoGenericClass *gclass = (const MonoGenericClass *) data;
-	guint hash = m_class_get_name_hash (gclass->container_class);
-	hash *= 13;
-	hash += gclass->is_tb_open;
-	hash += mono_metadata_generic_context_hash (&gclass->context);
-	return hash;
-}
-static gboolean
-mono_generic_class_equal (gconstpointer ka, gconstpointer kb)
-{
-	const MonoGenericClass *a = (const MonoGenericClass *) ka;
-	const MonoGenericClass *b = (const MonoGenericClass *) kb;
-	return _mono_metadata_generic_class_equal (a, b, FALSE);
-}
-/**
- * mono_metadata_init:
- *
- * Initialize the global variables of this module.
- * This is a Mono runtime internal function.
- */
-void
-mono_metadata_init (void)
-{
-	int i;
-	/* We guard against double initialization due to how pedump in verification mode works.
-	Until runtime initialization is properly factored to work with what it needs we need workarounds like this.
-	FIXME: https://bugzilla.xamarin.com/show_bug.cgi?id=58793
-	*/
-	static gboolean inited;
-	if (inited)
-		return;
-	inited = TRUE;
-	type_cache = g_hash_table_new (mono_type_hash, mono_type_equal);
-	for (i = 0; i < G_N_ELEMENTS (builtin_types); ++i)
-		g_hash_table_insert (type_cache, (gpointer) &builtin_types [i], (gpointer) &builtin_types [i]);
-	mono_metadata_update_init ();
-}
-/*
- * Make a pass over the metadata signature blob starting at \p tmp_ptr and count the custom modifiers.
- */
-static int
-count_custom_modifiers (MonoImage *m, const char *tmp_ptr)
-{
-	int count = 0;
-	gboolean found = TRUE;
-	while (found) {
-		switch (*tmp_ptr) {
-		case MONO_TYPE_PINNED:
-		case MONO_TYPE_BYREF:
-			++tmp_ptr;
-			break;
-		case MONO_TYPE_CMOD_REQD:
-		case MONO_TYPE_CMOD_OPT:
-			count ++;
-			mono_metadata_parse_custom_mod (m, NULL, tmp_ptr, &tmp_ptr);
-			break;
-		default:
-			found = FALSE;
-		}
-	}
-	return count;
-}
-/*
- * Decode the (expected \p count, possibly 0) custom modifiers as well as the "byref" and "pinned"
- * markers from the metadata stream \p ptr and put them into \p cmods
- *
- * Sets \p rptr past the end of the parsed metadata.  Sets \p pinned and \p byref if those modifiers
- * were present.
- */
-static void
-decode_custom_modifiers (MonoImage *m, MonoCustomModContainer *cmods, int count, const char *ptr, const char **rptr, gboolean *pinned, gboolean *byref)
-{
-	gboolean found = TRUE;
-	/* cmods are encoded in reverse order from how we normally see them.
-	 * "int32 modopt (Foo) modopt (Bar)" is encoded as "cmod_opt [typedef_or_ref "Bar"] cmod_opt [typedef_or_ref "Foo"] I4"
-	 */
-	while (found) {
-		switch (*ptr) {
-		case MONO_TYPE_PINNED:
-			*pinned = TRUE;
-			++ptr;
-			break;
-		case MONO_TYPE_BYREF:
-			*byref = TRUE;
-			++ptr;
-			break;
-		case MONO_TYPE_CMOD_REQD:
-		case MONO_TYPE_CMOD_OPT:
-			g_assert (count > 0);
-			mono_metadata_parse_custom_mod (m, &(cmods->modifiers [--count]), ptr, &ptr);
-			break;
-		default:
-			found = FALSE;
-		}
-	}
-	g_assert (count == 0);
-	*rptr = ptr;
-}
-/*
- * Allocate the memory necessary to hold a \c MonoType with \p count custom modifiers.
- * If \p transient is true, allocate from the heap, otherwise allocate from the mempool of image \p m
- */
-static MonoType *
-alloc_type_with_cmods (MonoImage *m, gboolean transient, int count)
-{
-	g_assert (count > 0 && count <= G_MAXUINT8);
-	MonoType *type;
-	uint8_t count8 = GINT_TO_UINT8 (count);
-	size_t size = mono_sizeof_type_with_mods (count8, FALSE);
-	type = transient ? (MonoType *)g_malloc0 (size) : (MonoType *)mono_image_alloc0 (m, (guint)size);
-	type->has_cmods = TRUE;
-	MonoCustomModContainer *cmods = mono_type_get_cmods (type);
-	cmods->count = count8;
-	cmods->image = m;
-	return type;
-}
-/*
- * If \p transient is true, free \p type, otherwise no-op
- */
-static void
-free_parsed_type (MonoType *type, gboolean transient)
-{
-	if (transient)
-		mono_metadata_free_type (type);
-}
-/*
- * Try to find a pre-allocated version of the given \p type.
- * Returns true and sets \p canonical_type if found, otherwise return false.
- *
- * For classes and valuetypes, this returns their embedded byval_arg or
- * this_arg types.  For base types, it returns the global versions.
- */
-static gboolean
-try_get_canonical_type (MonoType *type, MonoType **canonical_type)
-{
-	/* Note: If the type has any attribtues or modifiers the function currently returns false,
-	 * although there's no fundamental reason we can't have cached copies in those instances (or
-	 * indeed cached arrays, pointers or some generic instances).  However in that case there's
-	 * limited utility in returning a cached copy because the parsing code in
-	 * do_mono_metadata_parse_type could have allocated some mempool or heap memory already.
-	 *
-	 * This function should be kept closely in sync with mono_metadata_free_type so that it
-	 * doesn't try to free canonical MonoTypes (which might not even be heap allocated).
-	 */
-	g_assert (!type->has_cmods);
-	if ((type->type == MONO_TYPE_CLASS || type->type == MONO_TYPE_VALUETYPE) && !type->pinned && !type->attrs) {
-		MonoType *ret = m_type_is_byref (type) ? m_class_get_this_arg (type->data.klass) : m_class_get_byval_arg (type->data.klass);
-		/* Consider the case:
-		   class Foo<T> { class Bar {} }
-		   class Test : Foo<Test>.Bar {}
-		   When Foo<Test> is being expanded, 'Test' isn't yet initialized.  It's actually in
-		   a really pristine state: it doesn't even know whether 'Test' is a reference or a value type.
-		   We ensure that the MonoClass is in a state that we can canonicalize to:
-		   klass->_byval_arg.data.klass == klass
-		   klass->this_arg.data.klass == klass
-		   If we can't canonicalize 'type', it doesn't matter, since later users of 'type' will do it.
-		   LOCKING: even though we don't explicitly hold a lock, in the problematic case 'ret' is a field
-		   of a MonoClass which currently holds the loader lock.  'type' is local.
-		*/
-		if (ret->data.klass == type->data.klass) {
-			*canonical_type = ret;
-			return TRUE;
-		}
-	}
-	/* Maybe it's one of the globally-known basic types */
-	MonoType *cached;
-	/* No need to use locking since nobody is modifying the hash table */
-	if ((cached = (MonoType *)g_hash_table_lookup (type_cache, type))) {
-		*canonical_type = cached;
-		return TRUE;
-	}
-	return FALSE;
-}
-/*
- * Fill in \p type (expecting \p cmod_count custom modifiers) by parsing it from the metadata stream pointed at by \p ptr.
- *
- * On success returns true and sets \p rptr past the parsed stream data.  On failure return false and sets \p error.
- */
-static gboolean
-do_mono_metadata_parse_type_with_cmods (MonoType *type, int cmod_count, MonoImage *m, MonoGenericContainer *container,
-					guint32 opt_attrs, gboolean transient, const char *ptr, const char **rptr, MonoError *error)
-{
-	gboolean byref= FALSE;
-	gboolean pinned = FALSE;
-	error_init (error);
-	/* Iterate again, but now parse pinned, byref and custom modifiers */
-	decode_custom_modifiers (m, mono_type_get_cmods (type), cmod_count, ptr, &ptr, &pinned, &byref);
-	type->attrs = opt_attrs;
-	type->byref__ = byref;
-	type->pinned = pinned ? 1 : 0;
-	if (!do_mono_metadata_parse_type (type, m, container, transient, ptr, &ptr, error))
-		return FALSE;
-	if (rptr)
-		*rptr = ptr;
-	return TRUE;
-}
-MONO_DISABLE_WARNING(4701) /* potentially uninitialized local variable 'stype' used */
-/**
- * mono_metadata_parse_type:
- * \param m metadata context
- * \param mode kind of type that may be found at \p ptr
- * \param opt_attrs optional attributes to store in the returned type
- * \param ptr pointer to the type representation
- * \param rptr pointer updated to match the end of the decoded stream
- * \param transient whenever to allocate the result from the heap or from a mempool
- *
- * Decode a compressed type description found at \p ptr in \p m .
- * \p mode can be one of \c MONO_PARSE_MOD_TYPE, \c MONO_PARSE_PARAM, \c MONO_PARSE_RET,
- * \c MONO_PARSE_FIELD, \c MONO_PARSE_LOCAL, \c MONO_PARSE_TYPE.
- * This function can be used to decode type descriptions in method signatures,
- * field signatures, locals signatures etc.
- *
- * To parse a generic type, \c generic_container points to the current class'es
- * (the \c generic_container field in the <code>MonoClass</code>) or the current generic method's
- * (stored in <code>image->property_hash</code>) generic container.
- * When we encounter a \c MONO_TYPE_VAR or \c MONO_TYPE_MVAR, it's looked up in
- * this \c MonoGenericContainer.
- *
- * LOCKING: Acquires the loader lock.
- *
- * \returns a \c MonoType structure representing the decoded type.
- */
-static MonoType*
-mono_metadata_parse_type_internal (MonoImage *m, MonoGenericContainer *container,
-								   guint32 opt_attrs, gboolean transient, const char *ptr, const char **rptr, MonoError *error)
-{
-	MonoType *type;
-	MonoType stype;
-	int count = 0; // Number of mod arguments
-	gboolean allocated = FALSE;
-	error_init (error);
-	/*
-	 * Q: What's going on with `stype` and `allocated`?  A: A very common case is that we're
-	 * parsing "int" or "string" or "Dictionary<K,V>" non-transiently.  In that case we don't
-	 * want to flood the mempool with millions of copies of MonoType 'int' (etc).  So we parse
-	 * it into a stack variable and try_get_canonical_type, below.  As long as the type is
-	 * normal, we will avoid having to make an extra copy in the mempool.
-	 */
-	/*
-	 * According to the spec, custom modifiers should come before the byref
-	 * flag, but the IL produced by ilasm from the following signature:
-	 *   object modopt(...) &
-	 * starts with a byref flag, followed by the modifiers. (bug #49802)
-	 * Also, this type seems to be different from 'object & modopt(...)'. Maybe
-	 * it would be better to treat byref as real type constructor instead of
-	 * a modifier...
-	 * Also, pinned should come before anything else, but some MSV++ produced
-	 * assemblies violate this (#bug 61990).
-	 */
-	/* Count the modifiers first */
-	count = count_custom_modifiers (m, ptr);
-	if (count) { // There are mods, so the MonoType will be of nonstandard size.
-		allocated = TRUE;
-		if (count > 64) {
-			mono_error_set_bad_image (error, m, "Invalid type with more than 64 modifiers");
-			return NULL;
-		}
-		type = alloc_type_with_cmods (m, transient, count);
-	} else {     // The type is of standard size, so we can allocate it on the stack.
-		type = &stype;
-		memset (type, 0, MONO_SIZEOF_TYPE);
-	}
-	if (!do_mono_metadata_parse_type_with_cmods (type, count, m, container, opt_attrs, transient, ptr, rptr, error)) {
-		if (allocated)
-			free_parsed_type (type, transient);
-		return NULL;
-	}
-	if (!allocated && !transient) {
-		/* no need to free type here, because it is on the stack */
-		MonoType *ret_type = NULL;
-		if (try_get_canonical_type (type, &ret_type))
-			return ret_type;
-	}
-	/* printf ("%x %x %c %s\n", type->attrs, type->num_mods, type->pinned ? 'p' : ' ', mono_type_full_name (type)); */
-	if (!allocated) { // Type was allocated on the stack, so we need to copy it to safety
-		type = transient ? (MonoType *)g_malloc (MONO_SIZEOF_TYPE) : (MonoType *)mono_image_alloc (m, MONO_SIZEOF_TYPE);
-		memcpy (type, &stype, MONO_SIZEOF_TYPE);
-	}
-	g_assert (type != &stype);
-	return type;
-}
-MONO_RESTORE_WARNING
-MonoType*
-mono_metadata_parse_type_checked (MonoImage *m, MonoGenericContainer *container,
-							   guint32 opt_attrs, gboolean transient, const char *ptr, const char **rptr, MonoError *error)
-{
-	return mono_metadata_parse_type_internal (m, container, opt_attrs, transient, ptr, rptr, error);
-}
-/*
- * LOCKING: Acquires the loader lock.
- */
-MonoType*
-mono_metadata_parse_type (MonoImage *m, MonoParseTypeMode mode, short opt_attrs,
-			  const char *ptr, const char **rptr)
-{
-	ERROR_DECL (error);
-	MonoType * type = mono_metadata_parse_type_internal (m, NULL, opt_attrs, FALSE, ptr, rptr, error);
-	mono_error_cleanup (error);
-	return type;
-}
-gboolean
-mono_metadata_method_has_param_attrs (MonoImage *m, int def)
-{
-	MonoTableInfo *paramt = &m->tables [MONO_TABLE_PARAM];
-	guint lastp, i, param_index;
-	param_index = mono_metadata_get_method_params (m, def, (uint32_t*)&lastp);
-	if (!param_index)
-		return FALSE;
-	for (i = param_index; i < lastp; ++i) {
-		guint32 flags = mono_metadata_decode_row_col (paramt, i - 1, MONO_PARAM_FLAGS);
-		if (flags)
-			return TRUE;
-	}
-	return FALSE;
-}
-/*
- * mono_metadata_get_param_attrs:
- *
- * @m The image to loader parameter attributes from
- * @def method def token (one based)
- * @param_count number of params to decode including the return value
- *
- *   Return the parameter attributes for the method whose MethodDef index is DEF. The
- * returned memory needs to be freed by the caller. If all the param attributes are
- * 0, then NULL is returned.
- */
-int*
-mono_metadata_get_param_attrs (MonoImage *m, int def, guint32 param_count)
-{
-	MonoTableInfo *paramt = &m->tables [MONO_TABLE_PARAM];
-	guint32 cols [MONO_PARAM_SIZE];
-	guint lastp, i, param_index;
-	int *pattrs = NULL;
-	param_index = mono_metadata_get_method_params (m, def, (uint32_t*)&lastp);
-	if (!param_index)
-		return NULL;
-	for (i = param_index; i < lastp; ++i) {
-		mono_metadata_decode_row (paramt, i - 1, cols, MONO_PARAM_SIZE);
-		if (cols [MONO_PARAM_FLAGS]) {
-			if (!pattrs)
-				pattrs = g_new0 (int, param_count);
-			/* at runtime we just ignore this kind of malformed file:
-			* the verifier can signal the error to the user
-			*/
-			if (cols [MONO_PARAM_SEQUENCE] >= param_count)
-				continue;
-			pattrs [cols [MONO_PARAM_SEQUENCE]] = cols [MONO_PARAM_FLAGS];
-		}
-	}
-	return pattrs;
-}
-/**
- * mono_metadata_parse_signature:
- * \param image metadata context
- * \param token metadata token
- *
- * Decode a method signature stored in the \c StandAloneSig table
- *
- * \returns a \c MonoMethodSignature describing the signature.
- */
-MonoMethodSignature*
-mono_metadata_parse_signature (MonoImage *image, guint32 token)
-{
-	ERROR_DECL (error);
-	MonoMethodSignature *ret;
-	ret = mono_metadata_parse_signature_checked (image, token, error);
-	mono_error_cleanup (error);
-	return ret;
-}
-/*
- * mono_metadata_parse_signature_checked:
- * @image: metadata context
- * @token: metadata token
- * @error: set on error
- *
- * Decode a method signature stored in the STANDALONESIG table
- *
- * Returns: a MonoMethodSignature describing the signature. On failure
- * returns NULL and sets @error.
- */
-MonoMethodSignature*
-mono_metadata_parse_signature_checked (MonoImage *image, guint32 token, MonoError *error)
-{
-	error_init (error);
-	MonoTableInfo *tables = image->tables;
-	guint32 idx = mono_metadata_token_index (token);
-	guint32 sig;
-	const char *ptr;
-	if (image_is_dynamic (image)) {
-		return (MonoMethodSignature *)mono_lookup_dynamic_token (image, token, NULL, error);
-	}
-	g_assert (mono_metadata_token_table(token) == MONO_TABLE_STANDALONESIG);
-	sig = mono_metadata_decode_row_col (&tables [MONO_TABLE_STANDALONESIG], idx - 1, 0);
-	ptr = mono_metadata_blob_heap (image, sig);
-	mono_metadata_decode_blob_size (ptr, &ptr);
-	return mono_metadata_parse_method_signature_full (image, NULL, 0, ptr, NULL, error);
-}
-/**
- * mono_metadata_signature_alloc:
- * \param image metadata context
- * \param nparams number of parameters in the signature
- *
- * Allocate a \c MonoMethodSignature structure with the specified number of params.
- * The return type and the params types need to be filled later.
- * This is a Mono runtime internal function.
- *
- * LOCKING: Assumes the loader lock is held.
- *
- * \returns the new \c MonoMethodSignature structure.
- */
-MonoMethodSignature*
-mono_metadata_signature_alloc (MonoImage *m, guint32 nparams)
-{
-	MonoMethodSignature *sig;
-	sig = (MonoMethodSignature *)mono_image_alloc0 (m, MONO_SIZEOF_METHOD_SIGNATURE + ((gint32)nparams) * sizeof (MonoType*));
-	sig->param_count = GUINT32_TO_UINT16 (nparams);
-	sig->sentinelpos = -1;
-	return sig;
-}
-static MonoMethodSignature*
-mono_metadata_signature_dup_internal (MonoImage *image, MonoMemPool *mp, MonoMemoryManager *mem_manager,
-									  MonoMethodSignature *sig, size_t padding)
-{
-	size_t sigsize, sig_header_size;
-	MonoMethodSignature *ret;
-	sigsize = sig_header_size = MONO_SIZEOF_METHOD_SIGNATURE + sig->param_count * sizeof (MonoType *) + padding;
-	if (sig->ret)
-		sigsize += mono_sizeof_type (sig->ret);
-	ret = mono_metadata_signature_allocate_internal (image, mp, mem_manager, sigsize);
-	memcpy (ret, sig, sig_header_size - padding);
-	if (sig->ret) {
-		intptr_t end_of_header = (intptr_t)( (char*)(ret) + sig_header_size);
-		ret->ret = (MonoType *)end_of_header;
-		memcpy (ret->ret, sig->ret, mono_sizeof_type (sig->ret));
-	}
-	return ret;
-}
-/**
- * Allocates memory for a MonoMethodSignature based on the provided parameters.
- *
- * @param image MonoImage for allocation.
- * @param mp MonoMemPool for allocation.
- * @param mem_manager MonoMemoryManager for allocation.
- * @param sig_size Size of the signature to allocate.
- * @return Pointer to the allocated MonoMethodSignature.
- */
-MonoMethodSignature*
-mono_metadata_signature_allocate_internal (MonoImage *image, MonoMemPool *mp, MonoMemoryManager *mem_manager, size_t sig_size)
-{
-    if (image) {
-        return (MonoMethodSignature *)mono_image_alloc (image, (guint)sig_size);
-    } else if (mp) {
-        return (MonoMethodSignature *)mono_mempool_alloc (mp, (unsigned int)sig_size);
-    } else if (mem_manager) {
-        return (MonoMethodSignature *)mono_mem_manager_alloc (mem_manager, (guint)sig_size);
-    } else {
-        return (MonoMethodSignature *)g_malloc (sig_size);
-    }
-}
-/*
- * signature_dup_add_this:
- *
- *  Make a copy of @sig, adding an explicit this argument.
- */
-MonoMethodSignature*
-mono_metadata_signature_dup_add_this (MonoImage *image, MonoMethodSignature *sig, MonoClass *klass)
-{
-	MonoMethodSignature *ret;
-	ret = mono_metadata_signature_dup_internal (image, NULL, NULL, sig, sizeof (MonoType *));
-	ret->param_count = sig->param_count + 1;
-	ret->hasthis = FALSE;
-	for (int i = sig->param_count - 1; i >= 0; i --)
-		ret->params [i + 1] = sig->params [i];
-	ret->params [0] = m_class_is_valuetype (klass) ? m_class_get_this_arg (klass) : m_class_get_byval_arg (klass);
-	for (int i = sig->param_count - 1; i >= 0; i --)
-		g_assert(ret->params [i + 1]->type == sig->params [i]->type && ret->params [i+1]->type != MONO_TYPE_END);
-	g_assert (ret->ret->type == sig->ret->type && ret->ret->type != MONO_TYPE_END);
-	return ret;
-}
-MonoMethodSignature*
-mono_metadata_signature_dup_full (MonoImage *image, MonoMethodSignature *sig)
-{
-	MonoMethodSignature *ret = mono_metadata_signature_dup_internal (image, NULL, NULL, sig, 0);
-	for (int i = 0 ; i < sig->param_count; i ++)
-		g_assert (ret->params [i]->type == sig->params [i]->type);
-	g_assert (ret->ret->type == sig->ret->type);
-	return ret;
-}
-/*The mempool is accessed without synchronization*/
-MonoMethodSignature*
-mono_metadata_signature_dup_mempool (MonoMemPool *mp, MonoMethodSignature *sig)
-{
-	return mono_metadata_signature_dup_internal (NULL, mp, NULL, sig, 0);
-}
-MonoMethodSignature*
-mono_metadata_signature_dup_mem_manager (MonoMemoryManager *mem_manager, MonoMethodSignature *sig)
-{
-	return mono_metadata_signature_dup_internal (NULL, NULL, mem_manager, sig, 0);
-}
-/**
- * mono_metadata_signature_dup:
- * \param sig method signature
- *
- * Duplicate an existing \c MonoMethodSignature so it can be modified.
- * This is a Mono runtime internal function.
- *
- * \returns the new \c MonoMethodSignature structure.
- */
-MonoMethodSignature*
-mono_metadata_signature_dup (MonoMethodSignature *sig)
-{
-	return mono_metadata_signature_dup_full (NULL, sig);
-}
-/**
- * mono_metadata_signature_dup_delegate_invoke_to_target:
- * \param sig method signature
- *
- * Duplicate an existing \c MonoMethodSignature but removes first param from it so it can
- * be used as signature for a delegate target method.
- * This is a Mono runtime internal function.
- *
- * \returns the new \c MonoMethodSignature structure.
- */
-MonoMethodSignature*
-mono_metadata_signature_dup_delegate_invoke_to_target (MonoMethodSignature *sig)
-{
-	MonoMethodSignature *res = mono_metadata_signature_dup_full (NULL, sig);
-	for (int i = 0 ; i < sig->param_count - 1; i ++) {
-		res->params [i] = sig->params [i + 1];
-	}
-	res->param_count --;
-	return res;
-}
-/**
- * mono_metadata_signature_dup_new_params:
- * @param mp The mempool to allocate the new signature from.
- * @param mem_manager The memory manager to allocate the new signature from.
- * @param sig The original method signature.
- * @param num_params The number parameters in the new signature.
- * @param new_params An array of MonoType pointers representing the new parameters.
- *
- * Duplicate an existing \c MonoMethodSignature but with a new set of parameters.
- * This is a Mono runtime internal function.
- *
- * @return the new \c MonoMethodSignature structure.
- */
-MonoMethodSignature*
-mono_metadata_signature_dup_new_params (MonoMemPool *mp, MonoMemoryManager *mem_manager, MonoMethodSignature *sig, uint32_t num_params, MonoType **new_params)
-{
-	size_t new_sig_size = MONO_SIZEOF_METHOD_SIGNATURE + num_params * sizeof (MonoType*);
-	if (sig->ret)
-		new_sig_size += mono_sizeof_type (sig->ret);
-	MonoMethodSignature *res = mono_metadata_signature_allocate_internal (NULL, mp, mem_manager, new_sig_size);
-	memcpy (res, sig, MONO_SIZEOF_METHOD_SIGNATURE);
-	res->param_count = GUINT32_TO_UINT16 (num_params);
-	for (uint16_t i = 0; i < res->param_count; i++) {
-		res->params [i] = new_params [i];
-	}
-	res->ret = sig->ret;
-	return res;
-}
-/*
- * mono_metadata_signature_size:
- *
- *   Return the amount of memory allocated to SIG.
- */
-guint32
-mono_metadata_signature_size (MonoMethodSignature *sig)
-{
-	return MONO_SIZEOF_METHOD_SIGNATURE + sig->param_count * sizeof (MonoType *);
-}
-/**
- * metadata_signature_set_modopt_call_conv:
- *
- * Reads the custom attributes from \p cmod_type and adds them to the signature \p sig.
- *
- * This follows the C# unmanaged function pointer encoding.
- * The modopts are from the System.Runtime.CompilerServices namespace and all have a name of the form CallConvXXX.
- *
- * The calling convention will be one of:
- * Cdecl, Thiscall, Stdcall, Fastcall
- * plus an optional SuppressGCTransition
- */
-static void
-metadata_signature_set_modopt_call_conv (MonoMethodSignature *sig, MonoType *cmod_type, MonoError *error)
-{
-	uint8_t count = mono_type_custom_modifier_count (cmod_type);
-	if (count == 0)
-		return;
-	int base_callconv = sig->call_convention;
-	gboolean suppress_gc_transition = mono_method_signature_has_ext_callconv (sig, MONO_EXT_CALLCONV_SUPPRESS_GC_TRANSITION);
-	for (uint8_t i = 0; i < count; ++i) {
-		gboolean req = FALSE;
-		MonoType *cmod = mono_type_get_custom_modifier (cmod_type, i, &req, error);
-		return_if_nok (error);
-		/* callconv is a modopt, not a modreq */
-		if (req)
-			continue;
-		/* shouldn't be a valuetype, array, gparam, gtd, ginst etc */
-		if (cmod->type != MONO_TYPE_CLASS)
-			continue;
-		MonoClass *cmod_klass = mono_class_from_mono_type_internal (cmod);
-		if (m_class_get_image (cmod_klass) != mono_defaults.corlib)
-			continue;
-		if (strcmp (m_class_get_name_space (cmod_klass), "System.Runtime.CompilerServices"))
-			continue;
-		const char *name = m_class_get_name (cmod_klass);
-		if (strstr (name, "CallConv") != name)
-			continue;
-		name += strlen ("CallConv"); /* skip the prefix */
-		/* Check for the known base unmanaged calling conventions */
-		if (!strcmp (name, "Cdecl")) {
-			base_callconv = MONO_CALL_C;
-			continue;
-		} else if (!strcmp (name, "Stdcall")) {
-			base_callconv = MONO_CALL_STDCALL;
-			continue;
-		} else if (!strcmp (name, "Thiscall")) {
-			base_callconv = MONO_CALL_THISCALL;
-			continue;
-		} else if (!strcmp (name, "Fastcall")) {
-			base_callconv = MONO_CALL_FASTCALL;
-			continue;
-		}
-		/* Check for known calling convention modifiers */
-		if (!strcmp (name, "SuppressGCTransition")) {
-			suppress_gc_transition = TRUE;
-			continue;
-		}
-	}
-	sig->call_convention = base_callconv;
-	if (suppress_gc_transition)
-		sig->ext_callconv |= MONO_EXT_CALLCONV_SUPPRESS_GC_TRANSITION;
-}
-/**
- * mono_metadata_parse_method_signature_full:
- * \param m metadata context
- * \param generic_container: generics container
- * \param def the \c MethodDef index or 0 for \c Ref signatures.
- * \param ptr pointer to the signature metadata representation
- * \param rptr pointer updated to match the end of the decoded stream
- * \param error set on error
- *
- *
- * Decode a method signature stored at \p ptr.
- * This is a Mono runtime internal function.
- *
- * LOCKING: Assumes the loader lock is held.
- *
- * \returns a \c MonoMethodSignature describing the signature.  On error sets
- * \p error and returns \c NULL.
- */
-MonoMethodSignature *
-mono_metadata_parse_method_signature_full (MonoImage *m, MonoGenericContainer *container,
-					   int def, const char *ptr, const char **rptr, MonoError *error)
-{
-	MonoMethodSignature *method;
-	int *pattrs = NULL;
-	guint32 hasthis = 0, explicit_this = 0, call_convention, param_count;
-	guint32 gen_param_count = 0;
-	gboolean is_open = FALSE;
-	error_init (error);
-	if (*ptr & 0x10)
-		gen_param_count = 1;
-	if (*ptr & 0x20)
-		hasthis = 1;
-	if (*ptr & 0x40)
-		explicit_this = 1;
-	call_convention = *ptr & 0x0F;
-	ptr++;
-	if (gen_param_count)
-		gen_param_count = mono_metadata_decode_value (ptr, &ptr);
-	param_count = mono_metadata_decode_value (ptr, &ptr);
-	if (def)
-		pattrs = mono_metadata_get_param_attrs (m, def, param_count + 1); /*Must be + 1 since signature's param count doesn't account for the return value */
-	method = mono_metadata_signature_alloc (m, param_count);
-	method->hasthis = hasthis;
-	method->explicit_this = explicit_this;
-	method->call_convention = call_convention;
-	method->generic_param_count = gen_param_count;
-	switch (method->call_convention) {
-	case MONO_CALL_DEFAULT:
-	case MONO_CALL_VARARG:
-		method->pinvoke = 0;
-		break;
-	case MONO_CALL_C:
-	case MONO_CALL_STDCALL:
-	case MONO_CALL_THISCALL:
-	case MONO_CALL_FASTCALL:
-	case MONO_CALL_UNMANAGED_MD:
-		method->pinvoke = 1;
-		break;
-	}
-	if (mono_method_signature_has_ext_callconv (method, MONO_EXT_CALLCONV_SWIFTCALL)) {
-		method->pinvoke = 1;
-	}
-	if (call_convention != 0xa) {
-		method->ret = mono_metadata_parse_type_checked (m, container, pattrs ? pattrs [0] : 0, FALSE, ptr, &ptr, error);
-		if (!method->ret) {
-			mono_metadata_free_method_signature (method);
-			g_free (pattrs);
-			return NULL;
-		}
-		is_open = mono_class_is_open_constructed_type (method->ret);
-		if (G_UNLIKELY (method->ret->has_cmods && method->call_convention == MONO_CALL_UNMANAGED_MD)) {
-			/* calling convention encoded in modopts */
-			metadata_signature_set_modopt_call_conv (method, method->ret, error);
-			if (!is_ok (error)) {
-				g_free (pattrs);
-				return NULL;
-			}
-		}
-	}
-	for (guint16 i = 0; i < method->param_count; ++i) {
-		if (*ptr == MONO_TYPE_SENTINEL) {
-			if (method->call_convention != MONO_CALL_VARARG || def) {
-				mono_error_set_bad_image (error, m, "Found sentinel for methoddef or no vararg");
-				g_free (pattrs);
-				return NULL;
-			}
-			if (method->sentinelpos >= 0) {
-				mono_error_set_bad_image (error, m, "Found sentinel twice in the same signature.");
-				g_free (pattrs);
-				return NULL;
-			}
-			method->sentinelpos = i;
-			ptr++;
-		}
-		method->params [i] = mono_metadata_parse_type_checked (m, container, pattrs ? pattrs [i+1] : 0, FALSE, ptr, &ptr, error);
-		if (!method->params [i]) {
-			mono_metadata_free_method_signature (method);
-			g_free (pattrs);
-			return NULL;
-		}
-		if (!is_open)
-			is_open = mono_class_is_open_constructed_type (method->params [i]);
-	}
-	/* The sentinel could be missing if the caller does not pass any additional arguments */
-	if (!def && method->call_convention == MONO_CALL_VARARG && method->sentinelpos < 0)
-		method->sentinelpos = method->param_count;
-	method->has_type_parameters = is_open;
-	if (def && (method->call_convention == MONO_CALL_VARARG))
-		method->sentinelpos = method->param_count;
-	g_free (pattrs);
-	if (rptr)
-		*rptr = ptr;
-	/*
-	 * Add signature to a cache and increase ref count...
-	 */
-	return method;
-}
-/**
- * mono_metadata_parse_method_signature:
- * \param m metadata context
- * \param def the \c MethodDef index or 0 for \c Ref signatures.
- * \param ptr pointer to the signature metadata representation
- * \param rptr pointer updated to match the end of the decoded stream
- *
- * Decode a method signature stored at \p ptr.
- * This is a Mono runtime internal function.
- *
- * LOCKING: Assumes the loader lock is held.
- *
- * \returns a \c MonoMethodSignature describing the signature.
- */
-MonoMethodSignature *
-mono_metadata_parse_method_signature (MonoImage *m, int def, const char *ptr, const char **rptr)
-{
-	/*
-	 * This function MUST NOT be called by runtime code as it does error handling incorrectly.
-	 * Use mono_metadata_parse_method_signature_full instead.
-	 * It's ok to assert on failure as we no longer use it.
-	 */
-	ERROR_DECL (error);
-	MonoMethodSignature *ret;
-	ret = mono_metadata_parse_method_signature_full (m, NULL, def, ptr, rptr, error);
-	mono_error_assert_ok (error);
-	return ret;
-}
-/**
- * mono_metadata_free_method_signature:
- * \param sig signature to destroy
- *
- * Free the memory allocated in the signature \p sig.
- * This method needs to be robust and work also on partially-built
- * signatures, so it does extra checks.
- */
-void
-mono_metadata_free_method_signature (MonoMethodSignature *sig)
-{
-	/* Everything is allocated from mempools */
-	/*
-	int i;
-	if (sig->ret)
-		mono_metadata_free_type (sig->ret);
-	for (i = 0; i < sig->param_count; ++i) {
-		if (sig->params [i])
-			mono_metadata_free_type (sig->params [i]);
-	}
-	*/
-}
-void
-mono_metadata_free_inflated_signature (MonoMethodSignature *sig)
-{
-	int i;
-	/* Allocated in inflate_generic_signature () */
-	if (sig->ret)
-		mono_metadata_free_type (sig->ret);
-	for (i = 0; i < sig->param_count; ++i) {
-		if (sig->params [i])
-			mono_metadata_free_type (sig->params [i]);
-	}
-	g_free (sig);
-}
-static gboolean
-inflated_method_equal (gconstpointer a, gconstpointer b)
-{
-	const MonoMethodInflated *ma = (const MonoMethodInflated *)a;
-	const MonoMethodInflated *mb = (const MonoMethodInflated *)b;
-	if (ma->declaring != mb->declaring)
-		return FALSE;
-	return mono_metadata_generic_context_equal (&ma->context, &mb->context);
-}
-static guint
-inflated_method_hash (gconstpointer a)
-{
-	const MonoMethodInflated *ma = (const MonoMethodInflated *)a;
-	return (mono_metadata_generic_context_hash (&ma->context) ^ mono_aligned_addr_hash (ma->declaring));
-}
-static gboolean
-inflated_signature_equal (gconstpointer a, gconstpointer b)
-{
-	const MonoInflatedMethodSignature *sig1 = (const MonoInflatedMethodSignature *)a;
-	const MonoInflatedMethodSignature *sig2 = (const MonoInflatedMethodSignature *)b;
-	/* sig->sig is assumed to be canonized */
-	if (sig1->sig != sig2->sig)
-		return FALSE;
-	/* The generic instances are canonized */
-	return mono_metadata_generic_context_equal (&sig1->context, &sig2->context);
-}
-static guint
-inflated_signature_hash (gconstpointer a)
-{
-	const MonoInflatedMethodSignature *sig = (const MonoInflatedMethodSignature *)a;
-	/* sig->sig is assumed to be canonized */
-	return mono_metadata_generic_context_hash (&sig->context) ^ mono_aligned_addr_hash (sig->sig);
-}
-/*static void
-dump_ginst (MonoGenericInst *ginst)
-{
-	int i;
-	char *name;
-	g_print ("Ginst: <");
-	for (i = 0; i < ginst->type_argc; ++i) {
-		if (i != 0)
-			g_print (", ");
-		name = mono_type_get_name (ginst->type_argv [i]);
-		g_print ("%s", name);
-		g_free (name);
-	}
-	g_print (">");
-}*/
-static gboolean
-aggregate_modifiers_equal (gconstpointer ka, gconstpointer kb)
-{
-	MonoAggregateModContainer *amods1 = (MonoAggregateModContainer *)ka;
-	MonoAggregateModContainer *amods2 = (MonoAggregateModContainer *)kb;
-	if (amods1->count != amods2->count)
-		return FALSE;
-	for (int i = 0; i < amods1->count; ++i) {
-		if (amods1->modifiers [i].required != amods2->modifiers [i].required)
-			return FALSE;
-		if (!mono_metadata_type_equal_full (amods1->modifiers [i].type, amods2->modifiers [i].type, MONO_TYPE_EQ_FLAGS_SIG_ONLY))
-			return FALSE;
-	}
-	return TRUE;
-}
-static guint
-aggregate_modifiers_hash (gconstpointer a)
-{
-	const MonoAggregateModContainer *amods = (const MonoAggregateModContainer *)a;
-	guint hash = 0;
-	for (int i = 0; i < amods->count; ++i)
-	{
-		hash *= 13;
-		hash ^= (amods->modifiers [i].required << 8);
-		hash += mono_metadata_type_hash (amods->modifiers [i].type);
-	}
-	return hash;
-}
-static gboolean type_in_image (MonoType *type, MonoImage *image);
-static gboolean aggregate_modifiers_in_image (MonoAggregateModContainer *amods, MonoImage *image);
-static gboolean
-signature_in_image (MonoMethodSignature *sig, MonoImage *image)
-{
-	gpointer iter = NULL;
-	MonoType *p;
-	while ((p = mono_signature_get_params_internal (sig, &iter)) != NULL)
-		if (type_in_image (p, image))
-			return TRUE;
-	return type_in_image (mono_signature_get_return_type_internal (sig), image);
-}
-static gboolean
-ginst_in_image (MonoGenericInst *ginst, MonoImage *image)
-{
-	for (guint i = 0; i < ginst->type_argc; ++i) {
-		if (type_in_image (ginst->type_argv [i], image))
-			return TRUE;
-	}
-	return FALSE;
-}
-static gboolean
-gclass_in_image (MonoGenericClass *gclass, MonoImage *image)
-{
-	return m_class_get_image (gclass->container_class) == image ||
-		ginst_in_image (gclass->context.class_inst, image);
-}
-static gboolean
-type_in_image (MonoType *type, MonoImage *image)
-{
-retry:
-	if (type->has_cmods && mono_type_is_aggregate_mods (type))
-		if (aggregate_modifiers_in_image (mono_type_get_amods (type), image))
-			return TRUE;
-	switch (type->type) {
-	case MONO_TYPE_GENERICINST:
-		return gclass_in_image (type->data.generic_class, image);
-	case MONO_TYPE_PTR:
-		type = type->data.type;
-		goto retry;
-	case MONO_TYPE_SZARRAY:
-		type = m_class_get_byval_arg (type->data.klass);
-		goto retry;
-	case MONO_TYPE_ARRAY:
-		type = m_class_get_byval_arg (type->data.array->eklass);
-		goto retry;
-	case MONO_TYPE_FNPTR:
-		return signature_in_image (type->data.method, image);
-	case MONO_TYPE_VAR:
-	case MONO_TYPE_MVAR:
-		if (image == mono_get_image_for_generic_param (type->data.generic_param))
-			return TRUE;
-		else if (type->data.generic_param->gshared_constraint) {
-			type = type->data.generic_param->gshared_constraint;
-			goto retry;
-		}
-		return FALSE;
-	default:
-		/* At this point, we should've avoided all potential allocations in mono_class_from_mono_type_internal () */
-		return image == m_class_get_image (mono_class_from_mono_type_internal (type));
-	}
-}
-gboolean
-mono_type_in_image (MonoType *type, MonoImage *image)
-{
-	return type_in_image (type, image);
-}
-gboolean
-aggregate_modifiers_in_image (MonoAggregateModContainer *amods, MonoImage *image)
-{
-	for (int i = 0; i < amods->count; i++)
-		if (type_in_image (amods->modifiers [i].type, image))
-			return TRUE;
-	return FALSE;
-}
-/*
- * Structure used by the collect_..._images functions to store the image list.
- */
-typedef struct {
-	MonoImage *image_buf [64];
-	MonoImage **images;
-	int nimages, images_len;
-} CollectData;
-static void
-collect_data_init (CollectData *data)
-{
-	data->images = data->image_buf;
-	data->images_len = 64;
-	data->nimages = 0;
-}
-static void
-collect_data_free (CollectData *data)
-{
-	if (data->images != data->image_buf)
-		g_free (data->images);
-}
-static void
-enlarge_data (CollectData *data)
-{
-	int new_len = data->images_len < 16 ? 16 : data->images_len * 2;
-	MonoImage **d = g_new (MonoImage *, new_len);
-	g_assert_not_reached ();
-	memcpy (d, data->images, data->images_len);
-	if (data->images != data->image_buf)
-		g_free (data->images);
-	data->images = d;
-	data->images_len = new_len;
-}
-static void
-add_image (MonoImage *image, CollectData *data)
-{
-	int i;
-	/* The arrays are small, so use a linear search instead of a hash table */
-	for (i = 0; i < data->nimages; ++i)
-		if (data->images [i] == image)
-			return;
-	if (data->nimages == data->images_len)
-		enlarge_data (data);
-	data->images [data->nimages ++] = image;
-}
-static void
-collect_type_images (MonoType *type, CollectData *data);
-static void
-collect_ginst_images (MonoGenericInst *ginst, CollectData *data)
-{
-	for (guint i = 0; i < ginst->type_argc; ++i) {
-		collect_type_images (ginst->type_argv [i], data);
-	}
-}
-static void
-collect_gclass_images (MonoGenericClass *gclass, CollectData *data)
-{
-	add_image (m_class_get_image (gclass->container_class), data);
-	if (gclass->context.class_inst)
-		collect_ginst_images (gclass->context.class_inst, data);
-}
-static void
-collect_signature_images (MonoMethodSignature *sig, CollectData *data)
-{
-	gpointer iter = NULL;
-	MonoType *p;
-	collect_type_images (mono_signature_get_return_type_internal (sig), data);
-	while ((p = mono_signature_get_params_internal (sig, &iter)) != NULL)
-		collect_type_images (p, data);
-}
-static void
-collect_inflated_signature_images (MonoInflatedMethodSignature *sig, CollectData *data)
-{
-	collect_signature_images (sig->sig, data);
-	if (sig->context.class_inst)
-		collect_ginst_images (sig->context.class_inst, data);
-	if (sig->context.method_inst)
-		collect_ginst_images (sig->context.method_inst, data);
-}
-static void
-collect_method_images (MonoMethodInflated *method, CollectData *data)
-{
-	MonoMethod *m = method->declaring;
-	add_image (m_class_get_image (method->declaring->klass), data);
-	if (method->context.class_inst)
-		collect_ginst_images (method->context.class_inst, data);
-	if (method->context.method_inst)
-		collect_ginst_images (method->context.method_inst, data);
-	/*
-	 * Dynamic assemblies have no references, so the images they depend on can be unloaded before them.
-	 */
-	if (image_is_dynamic (m_class_get_image (m->klass)))
-		collect_signature_images (mono_method_signature_internal (m), data);
-}
-static void
-collect_aggregate_modifiers_images (MonoAggregateModContainer *amods, CollectData *data)
-{
-	for (int i = 0; i < amods->count; ++i)
-		collect_type_images (amods->modifiers [i].type, data);
-}
-static void
-collect_type_images (MonoType *type, CollectData *data)
-{
-retry:
-	if (G_UNLIKELY (type->has_cmods && mono_type_is_aggregate_mods (type))) {
-		collect_aggregate_modifiers_images (mono_type_get_amods (type), data);
-	}
-	switch (type->type) {
-	case MONO_TYPE_GENERICINST:
-		collect_gclass_images (type->data.generic_class, data);
-		break;
-	case MONO_TYPE_PTR:
-		type = type->data.type;
-		goto retry;
-	case MONO_TYPE_SZARRAY:
-		type = m_class_get_byval_arg (type->data.klass);
-		goto retry;
-	case MONO_TYPE_ARRAY:
-		type = m_class_get_byval_arg (type->data.array->eklass);
-		goto retry;
-	case MONO_TYPE_FNPTR:
-		collect_signature_images (type->data.method, data);
-		break;
-	case MONO_TYPE_VAR:
-	case MONO_TYPE_MVAR:
-	{
-		MonoImage *image = mono_get_image_for_generic_param (type->data.generic_param);
-		add_image (image, data);
-		type = type->data.generic_param->gshared_constraint;
-		if (type)
-			goto retry;
-		break;
-	}
-	case MONO_TYPE_CLASS:
-	case MONO_TYPE_VALUETYPE:
-		add_image (m_class_get_image (mono_class_from_mono_type_internal (type)), data);
-		break;
-	default:
-		add_image (mono_defaults.corlib, data);
-	}
-}
-typedef struct {
-	MonoImage *image;
-	GSList *list;
-} CleanForImageUserData;
-static gboolean
-steal_gclass_in_image (gpointer key, gpointer value, gpointer data)
-{
-	MonoGenericClass *gclass = (MonoGenericClass *)key;
-	CleanForImageUserData *user_data = (CleanForImageUserData *)data;
-	g_assert (gclass_in_image (gclass, user_data->image));
-	user_data->list = g_slist_prepend (user_data->list, gclass);
-	return TRUE;
-}
-static gboolean
-steal_ginst_in_image (gpointer key, gpointer value, gpointer data)
-{
-	MonoGenericInst *ginst = (MonoGenericInst *)key;
-	CleanForImageUserData *user_data = (CleanForImageUserData *)data;
-	user_data->list = g_slist_prepend (user_data->list, ginst);
-	return TRUE;
-}
-static gboolean
-steal_aggregate_modifiers_in_image (gpointer key, gpointer value, gpointer data)
-{
-	MonoAggregateModContainer *amods = (MonoAggregateModContainer *)key;
-	CleanForImageUserData *user_data = (CleanForImageUserData *)data;
-	g_assert (aggregate_modifiers_in_image (amods, user_data->image));
-	user_data->list = g_slist_prepend (user_data->list, amods);
-	return TRUE;
-}
-static gboolean
-inflated_method_in_image (gpointer key, gpointer value, gpointer data)
-{
-	MonoImage *image = (MonoImage *)data;
-	MonoMethodInflated *method = (MonoMethodInflated *)key;
-	g_assert (m_class_get_image (method->declaring->klass) == image ||
-		(method->context.class_inst && ginst_in_image (method->context.class_inst, image)) ||
-			  (method->context.method_inst && ginst_in_image (method->context.method_inst, image)) || (((MonoMethod*)method)->signature && signature_in_image (mono_method_signature_internal ((MonoMethod*)method), image)));
-	return TRUE;
-}
-static gboolean
-inflated_signature_in_image (gpointer key, gpointer value, gpointer data)
-{
-	MonoImage *image = (MonoImage *)data;
-	MonoInflatedMethodSignature *sig = (MonoInflatedMethodSignature *)key;
-	return signature_in_image (sig->sig, image) ||
-		(sig->context.class_inst && ginst_in_image (sig->context.class_inst, image)) ||
-		(sig->context.method_inst && ginst_in_image (sig->context.method_inst, image));
-}
-static gboolean
-class_in_image (gpointer key, gpointer value, gpointer data)
-{
-	MonoImage *image = (MonoImage *)data;
-	MonoClass *klass = (MonoClass *)key;
-	g_assert (type_in_image (m_class_get_byval_arg (klass), image));
-	return TRUE;
-}
-static void
-check_gmethod (gpointer key, gpointer value, gpointer data)
-{
-	MonoMethodInflated *method = (MonoMethodInflated *)key;
-	MonoImage *image = (MonoImage *)data;
-	if (method->context.class_inst)
-		g_assert (!ginst_in_image (method->context.class_inst, image));
-	if (method->context.method_inst)
-		g_assert (!ginst_in_image (method->context.method_inst, image));
-	if (((MonoMethod*)method)->signature)
-		g_assert (!signature_in_image (mono_method_signature_internal ((MonoMethod*)method), image));
-}
-static void
-free_generic_inst (MonoGenericInst *ginst)
-{
-	/* The ginst itself is allocated from the mem manager */
-	for (guint i = 0; i < ginst->type_argc; ++i)
-		mono_metadata_free_type (ginst->type_argv [i]);
-}
-static void
-free_generic_class (MonoGenericClass *gclass)
-{
-	/* The gclass itself is allocated from the mem manager */
-	if (gclass->cached_class && m_class_get_interface_id (gclass->cached_class))
-		mono_unload_interface_id (gclass->cached_class);
-}
-static void
-free_inflated_signature (MonoInflatedMethodSignature *sig)
-{
-	mono_metadata_free_inflated_signature (sig->sig);
-}
-static void
-free_aggregate_modifiers (MonoAggregateModContainer *amods)
-{
-	for (int i = 0; i < amods->count; i++)
-		mono_metadata_free_type (amods->modifiers [i].type);
-	/* the container itself is allocated in the image set mempool */
-}
-/*
- * mono_metadata_get_inflated_signature:
- *
- *   Given an inflated signature and a generic context, return a canonical copy of the
- * signature. The returned signature might be equal to SIG or it might be a cached copy.
- */
-MonoMethodSignature *
-mono_metadata_get_inflated_signature (MonoMethodSignature *sig, MonoGenericContext *context)
-{
-	MonoInflatedMethodSignature helper;
-	MonoInflatedMethodSignature *res = NULL;
-	CollectData data;
-	helper.sig = sig;
-	helper.context.class_inst = context->class_inst;
-	helper.context.method_inst = context->method_inst;
-	collect_data_init (&data);
-	collect_inflated_signature_images (&helper, &data);
-	MonoMemoryManager *mm = mono_mem_manager_get_generic (data.images, data.nimages);
-	collect_data_free (&data);
-	mono_mem_manager_lock (mm);
-	if (!mm->gsignature_cache)
-		mm->gsignature_cache = dn_simdhash_ght_new_full (inflated_signature_hash, inflated_signature_equal, NULL, (GDestroyNotify)free_inflated_signature, 256, NULL);
-	dn_simdhash_ght_try_get_value (mm->gsignature_cache, &helper, (gpointer *)&res);
-	if (!res) {
-		res = mono_mem_manager_alloc0 (mm, sizeof (MonoInflatedMethodSignature));
-		res->sig = sig;
-		res->context.class_inst = context->class_inst;
-		res->context.method_inst = context->method_inst;
-		dn_simdhash_ght_insert (mm->gsignature_cache, res, res);
-	}
-	mono_mem_manager_unlock (mm);
-	return res->sig;
-}
-MonoMemoryManager *
-mono_metadata_get_mem_manager_for_type (MonoType *type)
-{
-	MonoMemoryManager *mm;
-	CollectData image_set_data;
-	collect_data_init (&image_set_data);
-	collect_type_images (type, &image_set_data);
-	mm = mono_mem_manager_get_generic (image_set_data.images, image_set_data.nimages);
-	collect_data_free (&image_set_data);
-	return mm;
-}
-MonoMemoryManager *
-mono_metadata_get_mem_manager_for_class (MonoClass *klass)
-{
-	return mono_metadata_get_mem_manager_for_type (m_class_get_byval_arg (klass));
-}
-MonoMemoryManager *
-mono_metadata_get_mem_manager_for_method (MonoMethodInflated *method)
-{
-	MonoMemoryManager *mm;
-	CollectData image_set_data;
-	collect_data_init (&image_set_data);
-	collect_method_images (method, &image_set_data);
-	mm = mono_mem_manager_get_generic (image_set_data.images, image_set_data.nimages);
-	collect_data_free (&image_set_data);
-	return mm;
-}
-static MonoMemoryManager *
-mono_metadata_get_mem_manager_for_aggregate_modifiers (MonoAggregateModContainer *amods)
-{
-	MonoMemoryManager *mm;
-	CollectData image_set_data;
-	collect_data_init (&image_set_data);
-	collect_aggregate_modifiers_images (amods, &image_set_data);
-	mm = mono_mem_manager_get_generic (image_set_data.images, image_set_data.nimages);
-	collect_data_free (&image_set_data);
-	return mm;
-}
-static gboolean
-type_is_gtd (MonoType *type)
-{
-	switch (type->type) {
-	case MONO_TYPE_CLASS:
-	case MONO_TYPE_VALUETYPE:
-		return mono_class_is_gtd (type->data.klass);
-	default:
-		return FALSE;
-	}
-}
-/*
- * mono_metadata_get_generic_inst:
- *
- * Given a list of types, return a MonoGenericInst that represents that list.
- * The returned MonoGenericInst has its own copy of the list of types.  The list
- * passed in the argument can be freed, modified or disposed of.
- *
- */
-MonoGenericInst *
-mono_metadata_get_generic_inst (int type_argc, MonoType **type_argv)
-{
-	MonoGenericInst *ginst;
-	gboolean is_open;
-	int i;
-	int size = MONO_SIZEOF_GENERIC_INST + type_argc * sizeof (MonoType *);
-	for (i = 0; i < type_argc; ++i)
-		if (mono_class_is_open_constructed_type (type_argv [i]))
-			break;
-	is_open = (i < type_argc);
-	ginst = (MonoGenericInst *)g_alloca (size);
-	memset (ginst, 0, MONO_SIZEOF_GENERIC_INST);
-	ginst->is_open = is_open;
-	ginst->type_argc = type_argc;
-	memcpy (ginst->type_argv, type_argv, type_argc * sizeof (MonoType *));
-	for (i = 0; i < type_argc; ++i) {
-		MonoType *t = ginst->type_argv [i];
-		if (type_is_gtd (t)) {
-			ginst->type_argv [i] = mono_class_gtd_get_canonical_inst (t->data.klass);
-		}
-	}
-	return mono_metadata_get_canonical_generic_inst (ginst);
-}
-/**
- * mono_metadata_get_canonical_generic_inst:
- * \param candidate an arbitrary generic instantiation
- *
- * \returns the canonical generic instantiation that represents the given
- * candidate by identifying the image set for the candidate instantiation and
- * finding the instance in the image set or adding a copy of the given instance
- * to the image set.
- *
- * The returned MonoGenericInst has its own copy of the list of types.  The list
- * passed in the argument can be freed, modified or disposed of.
- *
- */
-MonoGenericInst *
-mono_metadata_get_canonical_generic_inst (MonoGenericInst *candidate)
-{
-	CollectData data;
-	int type_argc = candidate->type_argc;
-	gboolean is_open = candidate->is_open;
-	collect_data_init (&data);
-	collect_ginst_images (candidate, &data);
-	MonoMemoryManager *mm = mono_mem_manager_get_generic (data.images, data.nimages);
-	collect_data_free (&data);
-	mono_loader_lock ();
-	if (!mm->ginst_cache)
-		mm->ginst_cache = dn_simdhash_ght_new_full (mono_metadata_generic_inst_hash, mono_metadata_generic_inst_equal, NULL, (GDestroyNotify)free_generic_inst, 0, NULL);
-	MonoGenericInst *ginst = NULL;
-	dn_simdhash_ght_try_get_value (mm->ginst_cache, candidate, (void **)&ginst);
-	if (!ginst) {
-		int size = MONO_SIZEOF_GENERIC_INST + type_argc * sizeof (MonoType *);
-		ginst = (MonoGenericInst *)mono_mem_manager_alloc0 (mm, size);
-#ifndef MONO_SMALL_CONFIG
-		ginst->id = mono_atomic_inc_i32 (&next_generic_inst_id);
-#endif
-		ginst->is_open = is_open;
-		ginst->type_argc = type_argc;
-		for (int i = 0; i < type_argc; ++i)
-			ginst->type_argv [i] = mono_metadata_type_dup (NULL, candidate->type_argv [i]);
-		dn_simdhash_ght_insert (mm->ginst_cache, ginst, ginst);
-	}
-	mono_loader_unlock ();
-	return ginst;
-}
-MonoAggregateModContainer *
-mono_metadata_get_canonical_aggregate_modifiers (MonoAggregateModContainer *candidate)
-{
-	g_assert (candidate->count > 0);
-	MonoMemoryManager *mm = mono_metadata_get_mem_manager_for_aggregate_modifiers (candidate);
-	mono_loader_lock ();
-	if (!mm->aggregate_modifiers_cache)
-		mm->aggregate_modifiers_cache = g_hash_table_new_full (aggregate_modifiers_hash, aggregate_modifiers_equal, NULL, (GDestroyNotify)free_aggregate_modifiers);
-	MonoAggregateModContainer *amods = (MonoAggregateModContainer *)g_hash_table_lookup (mm->aggregate_modifiers_cache, candidate);
-	if (!amods) {
-		size_t size = mono_sizeof_aggregate_modifiers (candidate->count);
-		amods = (MonoAggregateModContainer *)mono_mem_manager_alloc0 (mm, (guint)size);
-		amods->count = candidate->count;
-		for (int i = 0; i < candidate->count; ++i) {
-			amods->modifiers [i].required = candidate->modifiers [i].required;
-			amods->modifiers [i].type = mono_metadata_type_dup (NULL, candidate->modifiers [i].type);
-		}
-		g_hash_table_insert (mm->aggregate_modifiers_cache, amods, amods);
-	}
-	mono_loader_unlock ();
-	return amods;
-}
-static gboolean
-mono_metadata_is_type_builder_generic_type_definition (MonoClass *container_class, MonoGenericInst *inst, gboolean is_dynamic)
-{
-	MonoGenericContainer *container = mono_class_get_generic_container (container_class);
-	if (!is_dynamic || m_class_was_typebuilder (container_class) || container->type_argc != inst->type_argc)
-		return FALSE;
-	return inst == container->context.class_inst;
-}
-/*
- * mono_metadata_lookup_generic_class:
- *
- * Returns a MonoGenericClass with the given properties.
- *
- */
-MonoGenericClass *
-mono_metadata_lookup_generic_class (MonoClass *container_class, MonoGenericInst *inst, gboolean is_dynamic)
-{
-	MonoGenericClass *gclass;
-	MonoGenericClass helper;
-	gboolean is_tb_open = mono_metadata_is_type_builder_generic_type_definition (container_class, inst, is_dynamic);
-	CollectData data;
-	g_assert (mono_class_get_generic_container (container_class)->type_argc == inst->type_argc);
-	memset (&helper, 0, sizeof(helper)); // act like g_new0
-	helper.container_class = container_class;
-	helper.context.class_inst = inst;
-	helper.is_dynamic = is_dynamic; /* We use this in a hash lookup, which does not attempt to downcast the pointer */
-	helper.is_tb_open = is_tb_open;
-	collect_data_init (&data);
-	collect_gclass_images (&helper, &data);
-	MonoMemoryManager *mm = mono_mem_manager_get_generic (data.images, data.nimages);
-	collect_data_free (&data);
-	if (!mm->gclass_cache) {
-		mono_mem_manager_lock (mm);
-		if (!mm->gclass_cache) {
-			MonoConcurrentHashTable *cache = mono_conc_hashtable_new_full (mono_generic_class_hash, mono_generic_class_equal, NULL, (GDestroyNotify)free_generic_class);
-			mono_memory_barrier ();
-			mm->gclass_cache = cache;
-		}
-		mono_mem_manager_unlock (mm);
-	}
-	gclass = (MonoGenericClass *)mono_conc_hashtable_lookup (mm->gclass_cache, &helper);
-	/* A tripwire just to keep us honest */
-	g_assert (!helper.cached_class);
-	if (gclass)
-		return gclass;
-	mono_loader_lock ();
-	gclass = mono_mem_manager_alloc0 (mm, sizeof (MonoGenericClass));
-	if (is_dynamic)
-		gclass->is_dynamic = 1;
-	gclass->is_tb_open = is_tb_open;
-	gclass->container_class = container_class;
-	gclass->context.class_inst = inst;
-	gclass->context.method_inst = NULL;
-	gclass->owner = mm;
-	if (inst == mono_class_get_generic_container (container_class)->context.class_inst && !is_tb_open)
-		gclass->cached_class = container_class;
-	MonoGenericClass *gclass2 = (MonoGenericClass*)mono_conc_hashtable_insert (mm->gclass_cache, gclass, gclass);
-	if (!gclass2)
-		gclass2 = gclass;
-	mono_loader_unlock ();
-	return gclass2;
-}
-/*
- * mono_metadata_inflate_generic_inst:
- *
- * Instantiate the generic instance @ginst with the context @context.
- * Check @error for success.
- *
- */
-MonoGenericInst *
-mono_metadata_inflate_generic_inst (MonoGenericInst *ginst, MonoGenericContext *context, MonoError *error)
-{
-	MonoType **type_argv;
-	MonoGenericInst *nginst = NULL;
-	guint count = 0;
-	error_init (error);
-	if (!ginst->is_open)
-		return ginst;
-	type_argv = g_new0 (MonoType*, ginst->type_argc);
-	for (guint i = 0; i < ginst->type_argc; i++) {
-		type_argv [i] = mono_class_inflate_generic_type_checked (ginst->type_argv [i], context, error);
-		if (!is_ok (error))
-			goto cleanup;
-		++count;
-	}
-	nginst = mono_metadata_get_generic_inst (ginst->type_argc, type_argv);
-cleanup:
-	for (guint i = 0; i < count; i++)
-		mono_metadata_free_type (type_argv [i]);
-	g_free (type_argv);
-	return nginst;
-}
-MonoGenericInst *
-mono_metadata_parse_generic_inst (MonoImage *m, MonoGenericContainer *container,
-				  int count, const char *ptr, const char **rptr, MonoError *error)
-{
-	MonoType **type_argv;
-	MonoGenericInst *ginst = NULL;
-	int i, parse_count = 0;
-	error_init (error);
-	type_argv = g_new0 (MonoType*, count);
-	for (i = 0; i < count; i++) {
-		/* this can be a transient type, mono_metadata_get_generic_inst will allocate
-		 * a canonical one, if needed.
-		 */
-		MonoType *t = mono_metadata_parse_type_checked (m, container, 0, TRUE, ptr, &ptr, error);
-		if (!t)
-			goto cleanup;
-		type_argv [i] = t;
-		parse_count++;
-	}
-	if (rptr)
-		*rptr = ptr;
-	g_assert (parse_count == count);
-	ginst = mono_metadata_get_generic_inst (count, type_argv);
-cleanup:
-	for (i = 0; i < parse_count; i++)
-		mono_metadata_free_type (type_argv [i]);
-	g_free (type_argv);
-	return ginst;
-}
-static gboolean
-do_mono_metadata_parse_generic_class (MonoType *type, MonoImage *m, MonoGenericContainer *container,
-				      const char *ptr, const char **rptr, MonoError *error)
-{
-	MonoGenericInst *inst;
-	MonoClass *gklass;
-	MonoType *gtype;
-	int count;
-	error_init (error);
-	gtype = mono_metadata_parse_type_checked (m, NULL, 0, FALSE, ptr, &ptr, error);
-	if (gtype == NULL)
-		return FALSE;
-	gklass = mono_class_from_mono_type_internal (gtype);
-	if (!mono_class_is_gtd (gklass)) {
-		mono_error_set_bad_image (error, m, "Generic instance with non-generic definition");
-		return FALSE;
-	}
-	count = mono_metadata_decode_value (ptr, &ptr);
-	inst = mono_metadata_parse_generic_inst (m, container, count, ptr, &ptr, error);
-	if (inst == NULL)
-		return FALSE;
-	if (rptr)
-		*rptr = ptr;
-	type->data.generic_class = mono_metadata_lookup_generic_class (gklass, inst, FALSE);
-	return TRUE;
-}
-/*
- * select_container:
- * @gc: The generic container to normalize
- * @type: The kind of generic parameters the resulting generic-container should contain
- */
-static MonoGenericContainer *
-select_container (MonoGenericContainer *gc, MonoTypeEnum type)
-{
-	gboolean is_var = (type == MONO_TYPE_VAR);
-	if (!gc)
-		return NULL;
-	g_assert (is_var || type == MONO_TYPE_MVAR);
-	if (is_var) {
-		if (gc->is_method || gc->parent)
-			/*
-			 * The current MonoGenericContainer is a generic method -> its `parent'
-			 * points to the containing class'es container.
-			 */
-			return gc->parent;
-	}
-	return gc;
-}
-MonoGenericContainer *
-mono_get_anonymous_container_for_image (MonoImage *image, gboolean is_mvar)
-{
-	MonoGenericContainer **container_pointer;
-	if (is_mvar)
-		container_pointer = &image->anonymous_generic_method_container;
-	else
-		container_pointer = &image->anonymous_generic_class_container;
-	MonoGenericContainer *result = *container_pointer;
-	if (!result)
-	{
-		result = (MonoGenericContainer *)mono_image_alloc0 (image, sizeof (MonoGenericContainer));
-		result->owner.image = image;
-		result->is_anonymous = TRUE;
-		result->is_method = is_mvar;
-		MonoGenericContainer *exchange = (MonoGenericContainer *)mono_atomic_cas_ptr ((volatile gpointer *)container_pointer, result, NULL);
-		if (exchange)
-			result = exchange;
-	}
-	return result;
-}
-#define FAST_GPARAM_CACHE_SIZE 16
-static MonoGenericParam*
-lookup_anon_gparam (MonoImage *image, MonoGenericContainer *container, gint32 param_num, gboolean is_mvar)
-{
-	if (param_num >= 0 && param_num < FAST_GPARAM_CACHE_SIZE) {
-		MonoGenericParam *cache = is_mvar ? image->mvar_gparam_cache_fast : image->var_gparam_cache_fast;
-		if (!cache)
-			return NULL;
-		return &cache[param_num];
-	} else {
-		MonoGenericParam key;
-		memset (&key, 0, sizeof (key));
-		key.owner = container;
-		key.num = GINT32_TO_UINT16 (param_num);
-		key.gshared_constraint = NULL;
-		MonoConcurrentHashTable *cache = is_mvar ? image->mvar_gparam_cache : image->var_gparam_cache;
-		if (!cache)
-			return NULL;
-		return (MonoGenericParam*)mono_conc_hashtable_lookup (cache, &key);
-	}
-}
-static MonoGenericParam*
-publish_anon_gparam_fast (MonoImage *image, MonoGenericContainer *container, gint32 param_num)
-{
-	g_assert (param_num >= 0 && param_num < FAST_GPARAM_CACHE_SIZE);
-	MonoGenericParam **cache = container->is_method ? &image->mvar_gparam_cache_fast : &image->var_gparam_cache_fast;
-	if (!*cache) {
-		mono_image_lock (image);
-		if (!*cache) {
-			MonoGenericParam *new_cache = (MonoGenericParam*)mono_image_alloc0 (image, sizeof (MonoGenericParam) * FAST_GPARAM_CACHE_SIZE);
-			for (guint16 i = 0; i < FAST_GPARAM_CACHE_SIZE; ++i) {
-				MonoGenericParam *param = &new_cache[i];
-				param->owner = container;
-				param->num = i;
-			}
-			mono_memory_barrier ();
-			*cache = new_cache;
-		}
-		mono_image_unlock (image);
-	}
-	return &(*cache)[param_num];
-}
-/*
- * publish_anon_gparam_slow:
- *
- * Publish \p gparam anonymous generic parameter to the anon gparam cache for \p image.
- *
- * LOCKING: takes the image lock.
- */
-static MonoGenericParam*
-publish_anon_gparam_slow (MonoImage *image, MonoGenericParam *gparam)
-{
-	MonoConcurrentHashTable **cache = gparam->owner->is_method ? &image->mvar_gparam_cache : &image->var_gparam_cache;
-	if (!*cache) {
-		mono_image_lock (image);
-		if (!*cache) {
-			MonoConcurrentHashTable *ht = mono_conc_hashtable_new ((GHashFunc)mono_metadata_generic_param_hash,
-										(GEqualFunc) mono_metadata_generic_param_equal);
-			mono_atomic_store_release (cache, ht);
-		}
-		mono_image_unlock (image);
-	}
-	MonoGenericParam *other = (MonoGenericParam*)mono_conc_hashtable_insert (*cache, gparam, gparam);
-	return other ? other : gparam;
-}
-/**
- * mono_metadata_create_anon_gparam:
- * \param image the MonoImage that owns the anonymous generic parameter
- * \param param_num the parameter number
- * \param is_mvar TRUE if this is a method generic parameter, FALSE if it's a class generic parameter.
- *
- * Returns: a new, or exisisting \c MonoGenericParam for an anonymous generic parameter with the given properties.
- *
- * LOCKING: takes the image lock.
- */
-MonoGenericParam*
-mono_metadata_create_anon_gparam (MonoImage *image, gint32 param_num, gboolean is_mvar)
-{
-	MonoGenericContainer *container = mono_get_anonymous_container_for_image (image, is_mvar);
-	MonoGenericParam *gparam = lookup_anon_gparam (image, container, param_num, is_mvar);
-	if (gparam)
-		return gparam;
-	if (param_num >= 0 && param_num < FAST_GPARAM_CACHE_SIZE) {
-		return publish_anon_gparam_fast (image, container, param_num);
-	} else {
-		gparam = (MonoGenericParam*)mono_image_alloc0 (image, sizeof (MonoGenericParam));
-		gparam->owner = container;
-		gparam->num = GINT32_TO_UINT16 (param_num);
-		return publish_anon_gparam_slow (image, gparam);
-	}
-}
-/*
- * mono_metadata_parse_generic_param:
- * @generic_container: Our MonoClass's or MonoMethod's MonoGenericContainer;
- *                     see mono_metadata_parse_type_checked() for details.
- * Internal routine to parse a generic type parameter.
- * LOCKING: Acquires the loader lock
- */
-static MonoGenericParam *
-mono_metadata_parse_generic_param (MonoImage *m, MonoGenericContainer *generic_container,
-				   MonoTypeEnum type, const char *ptr, const char **rptr, MonoError *error)
-{
-	int index = mono_metadata_decode_value (ptr, &ptr);
-	if (rptr)
-		*rptr = ptr;
-	error_init (error);
-	generic_container = select_container (generic_container, type);
-	if (!generic_container) {
-		gboolean is_mvar = FALSE;
-		switch (type)
-		{
-			case MONO_TYPE_VAR:
-				break;
-			case MONO_TYPE_MVAR:
-				is_mvar = TRUE;
-				break;
-			default:
-				g_error ("Cerating generic param object with invalid MonoType"); // This is not a generic param
-		}
-		return mono_metadata_create_anon_gparam (m, index, is_mvar);
-	}
-	if (index >= generic_container->type_argc) {
-		mono_error_set_bad_image (error, m, "Invalid generic %s parameter index %d, max index is %d",
-			generic_container->is_method ? "method" : "type",
-			index, generic_container->type_argc);
-		return NULL;
-	}
-	return mono_generic_container_get_param (generic_container, index);
-}
-/*
- * mono_metadata_get_shared_type:
- *
- *   Return a shared instance of TYPE, if available, NULL otherwise.
- * Shared MonoType instances help save memory. Their contents should not be modified
- * by the caller. They do not need to be freed as their lifetime is bound by either
- * the lifetime of the runtime (builtin types), or the lifetime of the MonoClass
- * instance they are embedded in. If they are freed, they should be freed using
- * mono_metadata_free_type () instead of g_free ().
- */
-MonoType*
-mono_metadata_get_shared_type (MonoType *type)
-{
-	MonoType *cached;
-	/* No need to use locking since nobody is modifying the hash table */
-	if ((cached = (MonoType *)g_hash_table_lookup (type_cache, type)))
-		return cached;
-	switch (type->type){
-	case MONO_TYPE_CLASS:
-	case MONO_TYPE_VALUETYPE:
-		if (m_class_get_mem_manager (type->data.klass)->collectible)
-			/* These can be unloaded, so references to them shouldn't be shared */
-			return NULL;
-		if (type == m_class_get_byval_arg (type->data.klass))
-			return type;
-		if (type == m_class_get_this_arg (type->data.klass))
-			return type;
-		break;
-	default:
-		break;
-	}
-	return NULL;
-}
-static gboolean
-compare_type_literals (MonoImage *image, int class_type, int type_type, MonoError *error)
-{
-	error_init (error);
-	/* _byval_arg.type can be zero if we're decoding a type that references a class been loading.
-	 * See mcs/test/gtest-440. and #650936.
-	 * FIXME This better be moved to the metadata verifier as it can catch more cases.
-	 */
-	if (!class_type)
-		return TRUE;
-	/* NET 1.1 assemblies might encode string and object in a denormalized way.
-	 * See #675464.
-	 */
-	if (class_type == type_type)
-		return TRUE;
-	if (type_type == MONO_TYPE_CLASS) {
-		if (class_type == MONO_TYPE_STRING || class_type == MONO_TYPE_OBJECT)
-			return TRUE;
-		mono_error_set_type_load_name (error, NULL, NULL, "Expected reference type but got type kind %d", class_type);
-		return FALSE;
-	}
-	g_assert (type_type == MONO_TYPE_VALUETYPE);
-	switch (class_type) {
-	case MONO_TYPE_BOOLEAN:
-	case MONO_TYPE_CHAR:
-	case MONO_TYPE_I1:
-	case MONO_TYPE_U1:
-	case MONO_TYPE_I2:
-	case MONO_TYPE_U2:
-	case MONO_TYPE_I4:
-	case MONO_TYPE_U4:
-	case MONO_TYPE_I8:
-	case MONO_TYPE_U8:
-	case MONO_TYPE_R4:
-	case MONO_TYPE_R8:
-	case MONO_TYPE_I:
-	case MONO_TYPE_U:
-	case MONO_TYPE_CLASS:
-		return TRUE;
-	default:
-		mono_error_set_type_load_name (error, NULL, NULL, "Expected value type but got type kind %d", class_type);
-		return FALSE;
-	}
-}
-static gboolean
-verify_var_type_and_container (MonoImage *image, int var_type, MonoGenericContainer *container, MonoError *error)
-{
-	error_init (error);
-	if (var_type == MONO_TYPE_MVAR) {
-		if (!container->is_method) { //MVAR and a method container
-			mono_error_set_bad_image (error, image, "MVAR parsed in a context without a method container");
-			return FALSE;
-		}
-	} else {
-		if (!(!container->is_method || //VAR and class container
-			(container->is_method && container->parent))) { //VAR and method container with parent
-			mono_error_set_bad_image (error, image, "VAR parsed in a context without a class container");
-			return FALSE;
-		}
-	}
-	return TRUE;
-}
-/*
- * do_mono_metadata_parse_type:
- * @type: MonoType to be filled in with the return value
- * @m: image context
- * @generic_context: generics_context
- * @transient: whenever to allocate data from the heap
- * @ptr: pointer to the encoded type
- * @rptr: pointer where the end of the encoded type is saved
- *
- * Internal routine used to "fill" the contents of @type from an
- * allocated pointer.  This is done this way to avoid doing too
- * many mini-allocations (particularly for the MonoFieldType which
- * most of the time is just a MonoType, but sometimes might be augmented).
- *
- * This routine is used by mono_metadata_parse_type and
- * mono_metadata_parse_field_type
- *
- * This extracts a Type as specified in Partition II (22.2.12)
- *
- * Returns: FALSE if the type could not be loaded
- */
-static gboolean
-do_mono_metadata_parse_type (MonoType *type, MonoImage *m, MonoGenericContainer *container,
-							 gboolean transient, const char *ptr, const char **rptr, MonoError *error)
-{
-	error_init (error);
-	type->type = (MonoTypeEnum)mono_metadata_decode_value (ptr, &ptr);
-	switch (type->type){
-	case MONO_TYPE_VOID:
-	case MONO_TYPE_BOOLEAN:
-	case MONO_TYPE_CHAR:
-	case MONO_TYPE_I1:
-	case MONO_TYPE_U1:
-	case MONO_TYPE_I2:
-	case MONO_TYPE_U2:
-	case MONO_TYPE_I4:
-	case MONO_TYPE_U4:
-	case MONO_TYPE_I8:
-	case MONO_TYPE_U8:
-	case MONO_TYPE_R4:
-	case MONO_TYPE_R8:
-	case MONO_TYPE_I:
-	case MONO_TYPE_U:
-	case MONO_TYPE_STRING:
-	case MONO_TYPE_OBJECT:
-	case MONO_TYPE_TYPEDBYREF:
-		break;
-	case MONO_TYPE_VALUETYPE:
-	case MONO_TYPE_CLASS: {
-		guint32 token;
-		MonoClass *klass;
-		token = mono_metadata_parse_typedef_or_ref (m, ptr, &ptr);
-		klass = mono_class_get_checked (m, token, error);
-		type->data.klass = klass;
-		if (!klass)
-			return FALSE;
-		if (!compare_type_literals (m, m_class_get_byval_arg (klass)->type, type->type, error))
-			return FALSE;
-		break;
-	}
-	case MONO_TYPE_SZARRAY: {
-		MonoType *etype = mono_metadata_parse_type_checked (m, container, 0, transient, ptr, &ptr, error);
-		if (!etype)
-			return FALSE;
-		type->data.klass = mono_class_from_mono_type_internal (etype);
-		if (transient)
-			mono_metadata_free_type (etype);
-		g_assert (type->data.klass); //This was previously a check for NULL, but mcfmt should never fail. It can return a borken MonoClass, but should return at least something.
-		break;
-	}
-	case MONO_TYPE_PTR: {
-		type->data.type = mono_metadata_parse_type_checked (m, container, 0, transient, ptr, &ptr, error);
-		if (!type->data.type)
-			return FALSE;
-		break;
-	}
-	case MONO_TYPE_FNPTR: {
-		type->data.method = mono_metadata_parse_method_signature_full (m, container, 0, ptr, &ptr, error);
-		if (!type->data.method)
-			return FALSE;
-		break;
-	}
-	case MONO_TYPE_ARRAY: {
-		type->data.array = mono_metadata_parse_array_internal (m, container, transient, ptr, &ptr, error);
-		if (!type->data.array)
-			return FALSE;
-		break;
-	}
-	case MONO_TYPE_MVAR:
-	case MONO_TYPE_VAR: {
-		if (container && !verify_var_type_and_container (m, type->type, container, error))
-			return FALSE;
-		type->data.generic_param = mono_metadata_parse_generic_param (m, container, type->type, ptr, &ptr, error);
-		if (!type->data.generic_param)
-			return FALSE;
-		break;
-	}
-	case MONO_TYPE_GENERICINST: {
-		if (!do_mono_metadata_parse_generic_class (type, m, container, ptr, &ptr, error))
-			return FALSE;
-		break;
-	}
-	default:
-		mono_error_set_bad_image (error, m, "type 0x%02x not handled in do_mono_metadata_parse_type on image %s", type->type, m->name);
-		return FALSE;
-	}
-	if (rptr)
-		*rptr = ptr;
-	return TRUE;
-}
-/**
- * mono_metadata_free_type:
- * \param type type to free
- *
- * Free the memory allocated for type \p type which is allocated on the heap.
- */
-void
-mono_metadata_free_type (MonoType *type)
-{
-	/* Note: keep in sync with do_mono_metadata_parse_type and try_get_canonical_type which
-	 * allocate memory or try to avoid allocating memory. */
-	if (type >= builtin_types && type < builtin_types + G_N_ELEMENTS (builtin_types))
-		return;
-	switch (type->type){
-	case MONO_TYPE_OBJECT:
-	case MONO_TYPE_STRING:
-		if (!type->data.klass)
-			break;
-		/* fall through */
-	case MONO_TYPE_CLASS:
-	case MONO_TYPE_VALUETYPE:
-		if (type == m_class_get_byval_arg (type->data.klass) || type == m_class_get_this_arg (type->data.klass))
-			return;
-		break;
-	case MONO_TYPE_PTR:
-		mono_metadata_free_type (type->data.type);
-		break;
-	case MONO_TYPE_FNPTR:
-		mono_metadata_free_method_signature (type->data.method);
-		break;
-	case MONO_TYPE_ARRAY:
-		mono_metadata_free_array (type->data.array);
-		break;
-	default:
-		break;
-	}
-	g_free (type);
-}
-#if 0
-static void
-hex_dump (const char *buffer, int base, int count)
-{
-	int show_header = 1;
-	int i;
-	if (count < 0){
-		count = -count;
-		show_header = 0;
-	}
-	for (i = 0; i < count; i++){
-		if (show_header)
-			if ((i % 16) == 0)
-				printf ("\n0x%08x: ", (unsigned char) base + i);
-		printf ("%02x ", (unsigned char) (buffer [i]));
-	}
-	fflush (stdout);
-}
-#endif
-/**
- * @ptr: Points to the beginning of the Section Data (25.3)
- */
-static MonoExceptionClause*
-parse_section_data (MonoImage *m, int *num_clauses, const unsigned char *ptr, MonoError *error)
-{
-	unsigned char sect_data_flags;
-	int is_fat;
-	guint32 sect_data_len;
-	MonoExceptionClause* clauses = NULL;
-	error_init (error);
-	while (1) {
-		/* align on 32-bit boundary */
-		ptr = dword_align (ptr);
-		sect_data_flags = *ptr;
-		ptr++;
-		is_fat = sect_data_flags & METHOD_HEADER_SECTION_FAT_FORMAT;
-		if (is_fat) {
-			sect_data_len = (ptr [2] << 16) | (ptr [1] << 8) | ptr [0];
-			ptr += 3;
-		} else {
-			sect_data_len = ptr [0];
-			++ptr;
-		}
-		if (sect_data_flags & METHOD_HEADER_SECTION_EHTABLE) {
-			const unsigned char *p = dword_align (ptr);
-			int i;
-			*num_clauses = is_fat ? sect_data_len / 24: sect_data_len / 12;
-			/* we could just store a pointer if we don't need to byteswap */
-			clauses = (MonoExceptionClause *)g_malloc0 (sizeof (MonoExceptionClause) * (*num_clauses));
-			for (i = 0; i < *num_clauses; ++i) {
-				MonoExceptionClause *ec = &clauses [i];
-				guint32 tof_value;
-				if (is_fat) {
-					ec->flags = read32 (p);
-					ec->try_offset = read32 (p + 4);
-					ec->try_len = read32 (p + 8);
-					ec->handler_offset = read32 (p + 12);
-					ec->handler_len = read32 (p + 16);
-					tof_value = read32 (p + 20);
-					p += 24;
-				} else {
-					ec->flags = read16 (p);
-					ec->try_offset = read16 (p + 2);
-					ec->try_len = *(p + 4);
-					ec->handler_offset = read16 (p + 5);
-					ec->handler_len = *(p + 7);
-					tof_value = read32 (p + 8);
-					p += 12;
-				}
-				if (ec->flags == MONO_EXCEPTION_CLAUSE_FILTER) {
-					ec->data.filter_offset = tof_value;
-				} else if (ec->flags == MONO_EXCEPTION_CLAUSE_NONE) {
-					ec->data.catch_class = NULL;
-					if (tof_value) {
-						ec->data.catch_class = mono_class_get_checked (m, tof_value, error);
-						if (!is_ok (error)) {
-							g_free (clauses);
-							return NULL;
-						}
-					}
-				} else {
-					ec->data.catch_class = NULL;
-				}
-				/* g_print ("try %d: %x %04x-%04x %04x\n", i, ec->flags, ec->try_offset, ec->try_offset+ec->try_len, ec->try_len); */
-			}
-		}
-		if (sect_data_flags & METHOD_HEADER_SECTION_MORE_SECTS)
-			ptr += sect_data_len - 4; /* LAMESPEC: it seems the size includes the header */
-		else
-			return clauses;
-	}
-}
-/*
- * mono_method_get_header_summary:
- * @method: The method to get the header.
- * @summary: Where to store the header
- *
- *
- * Returns: TRUE if the header was properly decoded.
- */
-gboolean
-mono_method_get_header_summary (MonoMethod *method, MonoMethodHeaderSummary *summary)
-{
-	int idx;
-	guint32 rva;
-	MonoImage* img;
-	const char *ptr;
-	unsigned char flags, format;
-	guint16 fat_flags;
-	/*Only the GMD has a pointer to the metadata.*/
-	while (method->is_inflated)
-		method = ((MonoMethodInflated*)method)->declaring;
-	summary->code = NULL;
-	summary->code_size = 0;
-	summary->max_stack = 0;
-	summary->has_clauses = FALSE;
-	summary->has_locals = FALSE;
-	/*FIXME extract this into a MACRO and share it with mono_method_get_header*/
-	if ((method->flags & METHOD_ATTRIBUTE_ABSTRACT) || (method->iflags & METHOD_IMPL_ATTRIBUTE_RUNTIME) || (method->iflags & METHOD_IMPL_ATTRIBUTE_INTERNAL_CALL) || (method->flags & METHOD_ATTRIBUTE_PINVOKE_IMPL))
-		return FALSE;
-	if (method->wrapper_type != MONO_WRAPPER_NONE || method->sre_method) {
-		MonoMethodHeader *header =  ((MonoMethodWrapper *)method)->header;
-		if (!header)
-			return FALSE;
-		summary->code = header->code;
-		summary->code_size = header->code_size;
-		summary->max_stack = header->max_stack;
-		summary->has_clauses = header->num_clauses > 0;
-		summary->has_locals = header->num_locals > 0;
-		return TRUE;
-	}
-	idx = mono_metadata_token_index (method->token);
-	img = m_class_get_image (method->klass);
-	rva = mono_metadata_decode_row_col (&img->tables [MONO_TABLE_METHOD], idx - 1, MONO_METHOD_RVA);
-	ptr = mono_image_rva_map (img, rva);
-	if (!ptr)
-		return FALSE;
-	flags = *(const unsigned char *)ptr;
-	format = flags & METHOD_HEADER_FORMAT_MASK;
-	switch (format) {
-	case METHOD_HEADER_TINY_FORMAT:
-		ptr++;
-		summary->max_stack = 8;
-		summary->code = (unsigned char *) ptr;
-		summary->code_size = flags >> 2;
-		break;
-	case METHOD_HEADER_FAT_FORMAT:
-		fat_flags = read16 (ptr);
-		ptr += 2;
-		summary->max_stack = read16 (ptr);
-		ptr += 2;
-		summary->code_size = read32 (ptr);
-		ptr += 4;
-		summary->has_locals = !!read32 (ptr);
-		ptr += 4;
-		if (fat_flags & METHOD_HEADER_MORE_SECTS)
-			summary->has_clauses = TRUE;
-		summary->code = (unsigned char *) ptr;
-		break;
-	default:
-		return FALSE;
-	}
-	return TRUE;
-}
-/*
- * mono_metadata_parse_mh_full:
- * @m: metadata context
- * @generic_context: generics context
- * @ptr: pointer to the method header.
- *
- * Decode the method header at @ptr, including pointer to the IL code,
- * info about local variables and optional exception tables.
- * This is a Mono runtime internal function.
- *
- * LOCKING: Acquires the loader lock.
- *
- * Returns: a transient MonoMethodHeader allocated from the heap.
- */
-MonoMethodHeader *
-mono_metadata_parse_mh_full (MonoImage *m, MonoGenericContainer *container, const char *ptr, MonoError *error)
-{
-	MonoMethodHeader *mh = NULL;
-	unsigned char flags = *(const unsigned char *) ptr;
-	unsigned char format = flags & METHOD_HEADER_FORMAT_MASK;
-	guint16 fat_flags;
-	guint16 max_stack;
-	guint32 local_var_sig_tok, code_size, init_locals;
-	const unsigned char *code;
-	MonoExceptionClause* clauses = NULL;
-	int num_clauses = 0;
-	MonoTableInfo *t = &m->tables [MONO_TABLE_STANDALONESIG];
-	guint32 cols [MONO_STAND_ALONE_SIGNATURE_SIZE];
-	error_init (error);
-	if (!ptr) {
-		mono_error_set_bad_image (error, m, "Method header with null pointer");
-		return NULL;
-	}
-	switch (format) {
-	case METHOD_HEADER_TINY_FORMAT:
-		mh = (MonoMethodHeader *)g_malloc0 (MONO_SIZEOF_METHOD_HEADER);
-		ptr++;
-		mh->max_stack = 8;
-		mh->is_transient = TRUE;
-		local_var_sig_tok = 0;
-		mh->code_size = flags >> 2;
-		mh->code = (unsigned char*)ptr;
-		return mh;
-	case METHOD_HEADER_FAT_FORMAT:
-		fat_flags = read16 (ptr);
-		ptr += 2;
-		max_stack = read16 (ptr);
-		ptr += 2;
-		code_size = read32 (ptr);
-		ptr += 4;
-		local_var_sig_tok = read32 (ptr);
-		ptr += 4;
-		if (fat_flags & METHOD_HEADER_INIT_LOCALS)
-			init_locals = 1;
-		else
-			init_locals = 0;
-		code = (unsigned char*)ptr;
-		if (!(fat_flags & METHOD_HEADER_MORE_SECTS))
-			break;
-		/*
-		 * There are more sections
-		 */
-		ptr = (char*)code + code_size;
-		break;
-	default:
-		mono_error_set_bad_image (error, m, "Invalid method header format %d", format);
-		return NULL;
-	}
-	if (local_var_sig_tok) {
-		int idx = mono_metadata_token_index (local_var_sig_tok) - 1;
-		if (mono_metadata_table_bounds_check (m, MONO_TABLE_STANDALONESIG, idx + 1)) {
-			mono_error_set_bad_image (error, m, "Invalid method header local vars signature token 0x%08x", idx);
-			goto fail;
-		}
-		mono_metadata_decode_row (t, idx, cols, MONO_STAND_ALONE_SIGNATURE_SIZE);
-	}
-	if (fat_flags & METHOD_HEADER_MORE_SECTS) {
-		clauses = parse_section_data (m, &num_clauses, (const unsigned char*)ptr, error);
-		goto_if_nok (error, fail);
-	}
-	if (local_var_sig_tok) {
-		const char *locals_ptr;
-		guint16 len=0, i;
-		locals_ptr = mono_metadata_blob_heap (m, cols [MONO_STAND_ALONE_SIGNATURE]);
-		mono_metadata_decode_blob_size (locals_ptr, &locals_ptr);
-		if (*locals_ptr != 0x07)
-			g_warning ("wrong signature for locals blob");
-		locals_ptr++;
-		len = GUINT32_TO_UINT16 (mono_metadata_decode_value (locals_ptr, &locals_ptr));
-		mh = (MonoMethodHeader *)g_malloc0 (MONO_SIZEOF_METHOD_HEADER + len * sizeof (MonoType*) + num_clauses * sizeof (MonoExceptionClause));
-		mh->num_locals = len;
-		for (i = 0; i < len; ++i) {
-			mh->locals [i] = mono_metadata_parse_type_internal (m, container, 0, TRUE, locals_ptr, &locals_ptr, error);
-			goto_if_nok (error, fail);
-		}
-	} else {
-		mh = (MonoMethodHeader *)g_malloc0 (MONO_SIZEOF_METHOD_HEADER + num_clauses * sizeof (MonoExceptionClause));
-	}
-	mh->code = code;
-	mh->code_size = code_size;
-	mh->max_stack = max_stack;
-	mh->is_transient = TRUE;
-	mh->init_locals = init_locals;
-	if (clauses) {
-		MonoExceptionClause* clausesp = (MonoExceptionClause*)&mh->locals [mh->num_locals];
-		memcpy (clausesp, clauses, num_clauses * sizeof (MonoExceptionClause));
-		g_free (clauses);
-		mh->clauses = clausesp;
-		mh->num_clauses = num_clauses;
-	}
-	return mh;
-fail:
-	g_free (clauses);
-	g_free (mh);
-	return NULL;
-}
-/**
- * mono_metadata_parse_mh:
- * \param generic_context generics context
- * \param ptr pointer to the method header.
- *
- * Decode the method header at \p ptr, including pointer to the IL code,
- * info about local variables and optional exception tables.
- *
- * \returns a transient \c MonoMethodHeader allocated from the heap.
- */
-MonoMethodHeader *
-mono_metadata_parse_mh (MonoImage *m, const char *ptr)
-{
-	ERROR_DECL (error);
-	MonoMethodHeader *header = mono_metadata_parse_mh_full (m, NULL, ptr, error);
-	mono_error_cleanup (error);
-	return header;
-}
-/**
- * mono_metadata_free_mh:
- * \param mh a method header
- *
- * Free the memory allocated for the method header.
- */
-void
-mono_metadata_free_mh (MonoMethodHeader *mh)
-{
-	int i;
-	/* If it is not transient it means it's part of a wrapper method,
-	 * or a SRE-generated method, so the lifetime in that case is
-	 * dictated by the method's own lifetime
-	 */
-	if (mh && mh->is_transient) {
-		for (i = 0; i < mh->num_locals; ++i)
-			mono_metadata_free_type (mh->locals [i]);
-		g_free (mh);
-	}
-}
-/**
- * mono_method_header_get_code:
- * \param header a \c MonoMethodHeader pointer
- * \param code_size memory location for returning the code size
- * \param max_stack memory location for returning the max stack
- *
- * Method header accessor to retrieve info about the IL code properties:
- * a pointer to the IL code itself, the size of the code and the max number
- * of stack slots used by the code.
- *
- * \returns pointer to the IL code represented by the method header.
- */
-const unsigned char*
-mono_method_header_get_code (MonoMethodHeader *header, guint32* code_size, guint32* max_stack)
-{
-	if (code_size)
-		*code_size = header->code_size;
-	if (max_stack)
-		*max_stack = header->max_stack;
-	return header->code;
-}
-/**
- * mono_method_header_get_locals:
- * \param header a \c MonoMethodHeader pointer
- * \param num_locals memory location for returning the number of local variables
- * \param init_locals memory location for returning the init_locals flag
- *
- * Method header accessor to retrieve info about the local variables:
- * an array of local types, the number of locals and whether the locals
- * are supposed to be initialized to 0 on method entry
- *
- * \returns pointer to an array of types of the local variables
- */
-MonoType**
-mono_method_header_get_locals (MonoMethodHeader *header, guint32* num_locals, gboolean *init_locals)
-{
-	if (num_locals)
-		*num_locals = header->num_locals;
-	if (init_locals)
-		*init_locals = header->init_locals;
-	return header->locals;
-}
-/*
- * mono_method_header_get_num_clauses:
- * @header: a MonoMethodHeader pointer
- *
- * Method header accessor to retrieve the number of exception clauses.
- *
- * Returns: the number of exception clauses present
- */
-int
-mono_method_header_get_num_clauses (MonoMethodHeader *header)
-{
-	return header->num_clauses;
-}
-/**
- * mono_method_header_get_clauses:
- * \param header a \c MonoMethodHeader pointer
- * \param method \c MonoMethod the header belongs to
- * \param iter pointer to a iterator
- * \param clause pointer to a \c MonoExceptionClause structure which will be filled with the info
- *
- * Get the info about the exception clauses in the method. Set \c *iter to NULL to
- * initiate the iteration, then call the method repeatedly until it returns FALSE.
- * At each iteration, the structure pointed to by clause if filled with the
- * exception clause information.
- *
- * \returns TRUE if clause was filled with info, FALSE if there are no more exception
- * clauses.
- */
-int
-mono_method_header_get_clauses (MonoMethodHeader *header, MonoMethod *method, gpointer *iter, MonoExceptionClause *clause)
-{
-	MonoExceptionClause *sc;
-	/* later we'll be able to use this interface to parse the clause info on demand,
-	 * without allocating anything.
-	 */
-	if (!iter || !header->num_clauses)
-		return FALSE;
-	if (!*iter) {
-		*iter = sc = header->clauses;
-		*clause = *sc;
-		return TRUE;
-	}
-	sc = (MonoExceptionClause *)*iter;
-	sc++;
-	if (sc < header->clauses + header->num_clauses) {
-		*iter = sc;
-		*clause = *sc;
-		return TRUE;
-	}
-	return FALSE;
-}
-/**
- * mono_metadata_parse_field_type:
- * \param m metadata context to extract information from
- * \param ptr pointer to the field signature
- * \param rptr pointer updated to match the end of the decoded stream
- *
- * Parses the field signature, and returns the type information for it.
- *
- * \returns The \c MonoType that was extracted from \p ptr .
- */
-MonoType *
-mono_metadata_parse_field_type (MonoImage *m, short field_flags, const char *ptr, const char **rptr)
-{
-	ERROR_DECL (error);
-	MonoType * type = mono_metadata_parse_type_internal (m, NULL, field_flags, FALSE, ptr, rptr, error);
-	mono_error_cleanup (error);
-	return type;
-}
-/**
- * mono_metadata_parse_param:
- * \param m metadata context to extract information from
- * \param ptr pointer to the param signature
- * \param rptr pointer updated to match the end of the decoded stream
- *
- * Parses the param signature, and returns the type information for it.
- *
- * \returns The \c MonoType that was extracted from \p ptr .
- */
-MonoType *
-mono_metadata_parse_param (MonoImage *m, const char *ptr, const char **rptr)
-{
-	ERROR_DECL (error);
-	MonoType * type = mono_metadata_parse_type_internal (m, NULL, 0, FALSE, ptr, rptr, error);
-	mono_error_cleanup (error);
-	return type;
-}
-/**
- * mono_metadata_token_from_dor:
- * \param dor_token A \c TypeDefOrRef coded index
- *
- * \p dor_token is a \c TypeDefOrRef coded index: it contains either
- * a \c TypeDef, \c TypeRef or \c TypeSpec in the lower bits, and the upper
- * bits contain an index into the table.
- *
- * \returns an expanded token
- */
-guint32
-mono_metadata_token_from_dor (guint32 dor_index)
-{
-	guint32 table, idx;
-	table = dor_index & 0x03;
-	idx = dor_index >> 2;
-	switch (table){
-	case 0: /* TypeDef */
-		return MONO_TOKEN_TYPE_DEF | idx;
-	case 1: /* TypeRef */
-		return MONO_TOKEN_TYPE_REF | idx;
-	case 2: /* TypeSpec */
-		return MONO_TOKEN_TYPE_SPEC | idx;
-	default:
-		g_assert_not_reached ();
-	}
-	return 0;
-}
-static guint32
-decode_locator_row (mono_locator_t *loc, int row_index)
-{
-	const char *data;
-	if (G_UNLIKELY (loc->metadata_has_updates < 0))
-		loc->metadata_has_updates = mono_metadata_has_updates ();
-	if (G_UNLIKELY (loc->metadata_has_updates > 0))
-		return mono_metadata_decode_row_col_slow (loc->t, row_index, loc->col_idx);
-	g_assert (GINT_TO_UINT32(row_index) < loc->t_rows);
-	data = loc->first_column_data + (row_index * loc->t_row_size);
-	switch (loc->column_size) {
-	case 1:
-		return *data;
-	case 2:
-		return read16 (data);
-	case 4:
-		return read32 (data);
-	default:
-		g_assert_not_reached ();
-		return 0;
-	}
-}
-/*
- * How the row locator works.
- *
- *   Table A
- *   ___|___
- *   ___|___         Table B
- *   ___|___------>  _______
- *   ___|___         _______
- *
- * A column in the rows of table A references an index in table B.
- * For example A may be the TYPEDEF table and B the METHODDEF table.
- *
- * Given an index in table B we want to get the row in table A
- * where the column n references our index in B.
- *
- * In the locator_t structure:
- * 	t is table A
- * 	col_idx is the column number
- * 	index is the index in table B
- * 	result will be the index in table A
- *
- * Examples:
- * Table A		Table B		column (in table A)
- * TYPEDEF		METHODDEF   MONO_TYPEDEF_METHOD_LIST
- * TYPEDEF		FIELD		MONO_TYPEDEF_FIELD_LIST
- * PROPERTYMAP	PROPERTY	MONO_PROPERTY_MAP_PROPERTY_LIST
- * INTERFIMPL	TYPEDEF   	MONO_INTERFACEIMPL_CLASS
- * METHODSEM	PROPERTY	ASSOCIATION (encoded index)
- *
- * Note that we still don't support encoded indexes.
- *
- */
-static int
-typedef_locator (const void *a, const void *b)
-{
-	mono_locator_t *loc = (mono_locator_t *) a;
-	const char *bb = (const char *) b;
-	int typedef_index = GPTRDIFF_TO_INT ((bb - loc->t_base) / loc->t_row_size);
-	guint32 col, col_next, target_idx = loc->idx;
-	col = decode_locator_row (loc, typedef_index);
-	if (target_idx < col)
-		return -1;
-	/*
-	 * Need to check that the next row is valid.
-	 */
-	g_assert (typedef_index >= 0);
-	if (GINT_TO_UINT32(typedef_index) + 1 < loc->t_rows) {
-		col_next = decode_locator_row (loc, typedef_index + 1);
-		if (target_idx >= col_next)
-			return 1;
-		if (col == col_next)
-			return 1;
-	}
-	loc->result = typedef_index;
-	return 0;
-}
-static int
-table_locator (const void *a, const void *b)
-{
-	mono_locator_t *loc = (mono_locator_t *) a;
-	const char *bb = (const char *) b;
-	guint32 table_index = GPTRDIFF_TO_INT ((bb - loc->t_base) / loc->t_row_size);
-	guint32 col, target_idx = loc->idx;
-	col = decode_locator_row (loc, table_index);
-	if (target_idx == col) {
-		loc->result = table_index;
-		return 0;
-	}
-	if (target_idx < col)
-		return -1;
-	else
-		return 1;
-}
-static int
-declsec_locator (const void *a, const void *b)
-{
-	mono_locator_t *loc = (mono_locator_t *) a;
-	const char *bb = (const char *) b;
-	guint32 table_index = GPTRDIFF_TO_UINT32 ((bb - loc->t_base) / loc->t_row_size);
-	guint32 col, target_index = loc->idx;
-	col = decode_locator_row (loc, table_index);
-	if (target_index == col) {
-		loc->result = table_index;
-		return 0;
-	}
-	if (target_index < col)
-		return -1;
-	else
-		return 1;
-}
-/**
- * search_ptr_table:
- *
- *  Return the 1-based row index in TABLE, which must be one of the *Ptr tables,
- * which contains IDX.
- */
-static guint32
-search_ptr_table (MonoImage *image, int table, int idx)
-{
-	MonoTableInfo *ptrdef = &image->tables [table];
-	int rows = table_info_get_rows (ptrdef);
-	int i;
-	/* Use a linear search to find our index in the table */
-	for (i = 0; i < rows; i ++)
-		/* All the Ptr tables have the same structure */
-		if (mono_metadata_decode_row_col (ptrdef, i, 0) == idx)
-			break;
-	if (i < rows)
-		return i + 1;
-	else
-		return idx;
-}
-/**
- * mono_metadata_typedef_from_field:
- * \param meta metadata context
- * \param index FieldDef token
- *
- * \returns the 1-based index into the \c TypeDef table of the type that
- * declared the field described by \p index, or 0 if not found.
- */
-guint32
-mono_metadata_typedef_from_field (MonoImage *meta, guint32 index)
-{
-	MonoTableInfo *tdef = &meta->tables [MONO_TABLE_TYPEDEF];
-	mono_locator_t loc = mono_locator_init (tdef, mono_metadata_token_index (index), MONO_TYPEDEF_FIELD_LIST);
-	if (!tdef->base)
-		return 0;
-	if (meta->uncompressed_metadata)
-		loc.idx = search_ptr_table (meta, MONO_TABLE_FIELD_POINTER, loc.idx);
-	/* if it's not in the base image, look in the hot reload table */
-	gboolean added = (loc.idx > table_info_get_rows (&meta->tables [MONO_TABLE_FIELD]));
-	if (added) {
-		uint32_t res = mono_component_hot_reload()->field_parent (meta, loc.idx);
-		return res; /* 0 if not found, otherwise 1-based */
-	}
-	if (!mono_binary_search (&loc, tdef->base, table_info_get_rows (tdef), tdef->row_size, typedef_locator))
-		return 0;
-	/* loc_result is 0..1, needs to be mapped to table index (that is +1) */
-	return loc.result + 1;
-}
-/**
- * mono_metadata_typedef_from_method:
- * \param meta metadata context
- * \param index \c MethodDef token
- * \returns the 1-based index into the \c TypeDef table of the type that
- * declared the method described by \p index.  0 if not found.
- */
-guint32
-mono_metadata_typedef_from_method (MonoImage *meta, guint32 index)
-{
-	MonoTableInfo *tdef = &meta->tables [MONO_TABLE_TYPEDEF];
-	mono_locator_t loc = mono_locator_init (tdef, mono_metadata_token_index (index), MONO_TYPEDEF_METHOD_LIST);
-	if (!tdef->base)
-		return 0;
-	if (meta->uncompressed_metadata)
-		loc.idx = search_ptr_table (meta, MONO_TABLE_METHOD_POINTER, loc.idx);
-	/* if it's not in the base image, look in the hot reload table */
-	gboolean added = (loc.idx > table_info_get_rows (&meta->tables [MONO_TABLE_METHOD]));
-	if (added) {
-		uint32_t res = mono_component_hot_reload ()->method_parent (meta, loc.idx);
-		return res; /* 0 if not found, otherwise 1-based */
-	}
-	if (!mono_binary_search (&loc, tdef->base, table_info_get_rows (tdef), tdef->row_size, typedef_locator))
-		return 0;
-	/* loc_result is 0..1, needs to be mapped to table index (that is +1) */
-	return loc.result + 1;
-}
-/**
- * mono_metadata_interfaces_from_typedef_full:
- * \param meta metadata context
- * \param index typedef token
- * \param interfaces Out parameter used to store the interface array
- * \param count Out parameter used to store the number of interfaces
- * \param heap_alloc_result if TRUE the result array will be \c g_malloc'd
- * \param context The generic context
- * \param error set on error
- *
- * The array of interfaces that the \p index typedef token implements is returned in
- * \p interfaces. The number of elements in the array is returned in \p count.
- *
- * \returns \c TRUE on success, \c FALSE on failure and sets \p error.
- */
-gboolean
-mono_metadata_interfaces_from_typedef_full (MonoImage *meta, guint32 index, MonoClass ***interfaces, guint *count, gboolean heap_alloc_result, MonoGenericContext *context, MonoError *error)
-{
-	MonoTableInfo *tdef = &meta->tables [MONO_TABLE_INTERFACEIMPL];
-	mono_locator_t loc;
-	guint32 start, pos;
-	guint32 cols [MONO_INTERFACEIMPL_SIZE];
-	MonoClass **result;
-	*interfaces = NULL;
-	*count = 0;
-	error_init (error);
-	if (!tdef->base && !meta->has_updates)
-		return TRUE;
-	loc = mono_locator_init (tdef, mono_metadata_token_index (index), MONO_INTERFACEIMPL_CLASS);
-	gboolean found = tdef->base && mono_binary_search (&loc, tdef->base, table_info_get_rows (tdef), tdef->row_size, table_locator) != NULL;
-	if (!found && !meta->has_updates)
-		return TRUE;
-	if (G_UNLIKELY (meta->has_updates)) {
-		if (!found && !mono_metadata_update_metadata_linear_search (meta, tdef, &loc, table_locator)) {
-			mono_trace (G_LOG_LEVEL_INFO, MONO_TRACE_METADATA_UPDATE, "NO Found interfaces for class 0x%08x", index);
-			return TRUE;
-		}
-		mono_trace (G_LOG_LEVEL_INFO, MONO_TRACE_METADATA_UPDATE, "Found interfaces for class 0x%08x starting at 0x%08x", index, loc.result);
-	}
-	start = loc.result;
-	/*
-	 * We may end up in the middle of the rows...
-	 */
-	while (start > 0) {
-		if (loc.idx == mono_metadata_decode_row_col (tdef, start - 1, MONO_INTERFACEIMPL_CLASS))
-			start--;
-		else
-			break;
-	}
-	pos = start;
-	guint32 rows = mono_metadata_table_num_rows (meta, MONO_TABLE_INTERFACEIMPL);
-	while (pos < rows) {
-		mono_metadata_decode_row (tdef, pos, cols, MONO_INTERFACEIMPL_SIZE);
-		if (cols [MONO_INTERFACEIMPL_CLASS] != loc.idx)
-			break;
-		++pos;
-	}
-	if (heap_alloc_result)
-		result = g_new0 (MonoClass*, pos - start);
-	else
-		result = (MonoClass **)mono_image_alloc0 (meta, sizeof (MonoClass*) * (pos - start));
-	pos = start;
-	while (pos < rows) {
-		MonoClass *iface;
-		mono_metadata_decode_row (tdef, pos, cols, MONO_INTERFACEIMPL_SIZE);
-		if (cols [MONO_INTERFACEIMPL_CLASS] != loc.idx)
-			break;
-		iface = mono_class_get_and_inflate_typespec_checked (
-			meta, mono_metadata_token_from_dor (cols [MONO_INTERFACEIMPL_INTERFACE]), context, error);
-		if (iface == NULL)
-			return FALSE;
-		result [pos - start] = iface;
-		++pos;
-	}
-	*count = pos - start;
-	*interfaces = result;
-	return TRUE;
-}
-/**
- * mono_metadata_interfaces_from_typedef:
- * \param meta metadata context
- * \param index typedef token
- * \param count Out parameter used to store the number of interfaces
- *
- * The array of interfaces that the \p index typedef token implements is returned in
- * \p interfaces. The number of elements in the array is returned in \p count. The returned
- * array is allocated with \c g_malloc and the caller must free it.
- *
- * LOCKING: Acquires the loader lock .
- *
- * \returns the interface array on success, NULL on failure.
- */
-MonoClass**
-mono_metadata_interfaces_from_typedef (MonoImage *meta, guint32 index, guint *count)
-{
-	ERROR_DECL (error);
-	MonoClass **interfaces = NULL;
-	gboolean rv;
-	rv = mono_metadata_interfaces_from_typedef_full (meta, index, &interfaces, count, TRUE, NULL, error);
-	mono_error_assert_ok (error);
-	if (rv)
-		return interfaces;
-	else
-		return NULL;
-}
-/**
- * mono_metadata_nested_in_typedef:
- * \param meta metadata context
- * \param index typedef token
- * \returns the 1-based index into the TypeDef table of the type
- * where the type described by \p index is nested.
- * Returns 0 if \p index describes a non-nested type.
- */
-guint32
-mono_metadata_nested_in_typedef (MonoImage *meta, guint32 index)
-{
-	MonoTableInfo *tdef = &meta->tables [MONO_TABLE_NESTEDCLASS];
-	mono_locator_t loc = mono_locator_init (tdef, mono_metadata_token_index (index), MONO_NESTED_CLASS_NESTED);
-	if (!tdef->base && !meta->has_updates)
-		return 0;
-	gboolean found = tdef->base && mono_binary_search (&loc, tdef->base, table_info_get_rows (tdef), tdef->row_size, table_locator) != NULL;
-	if (!found && !meta->has_updates)
-		return 0;
-	if (G_UNLIKELY (meta->has_updates)) {
-		if (!found && !mono_metadata_update_metadata_linear_search (meta, tdef, &loc, table_locator))
-			return 0;
-	}
-	/* loc_result is 0..1, needs to be mapped to table index (that is +1) */
-	return mono_metadata_decode_row_col (tdef, loc.result, MONO_NESTED_CLASS_ENCLOSING) | MONO_TOKEN_TYPE_DEF;
-}
-/**
- * mono_metadata_nesting_typedef:
- * \param meta metadata context
- * \param index typedef token
- * \returns the 1-based index into the \c TypeDef table of the first type
- * that is nested inside the type described by \p index. The search starts at
- * \p start_index. Returns 0 if no such type is found.
- */
-guint32
-mono_metadata_nesting_typedef (MonoImage *meta, guint32 index, guint32 start_index)
-{
-	MonoTableInfo *tdef = &meta->tables [MONO_TABLE_NESTEDCLASS];
-	guint32 start;
-	guint32 class_index = mono_metadata_token_index (index);
-	if (!tdef->base)
-		return 0;
-	start = start_index;
-	guint32 rows = mono_metadata_table_num_rows (meta, MONO_TABLE_NESTEDCLASS);
-	while (start <= rows) {
-		if (class_index == mono_metadata_decode_row_col (tdef, start - 1, MONO_NESTED_CLASS_ENCLOSING))
-			break;
-		else
-			start++;
-	}
-	if (start > rows)
-		return 0;
-	else
-		return start;
-}
-/**
- * mono_metadata_packing_from_typedef:
- * \param meta metadata context
- * \param index token representing a type
- * \returns the info stored in the \c ClassLayout table for the given typedef token
- * into the \p packing and \p size pointers.
- * Returns 0 if the info is not found.
- */
-guint32
-mono_metadata_packing_from_typedef (MonoImage *meta, guint32 index, guint32 *packing, guint32 *size)
-{
-	MonoTableInfo *tdef = &meta->tables [MONO_TABLE_CLASSLAYOUT];
-	mono_locator_t loc = mono_locator_init (tdef, mono_metadata_token_index (index), MONO_CLASS_LAYOUT_PARENT);
-	guint32 cols [MONO_CLASS_LAYOUT_SIZE];
-	if (!tdef->base)
-		return 0;
-	/* FIXME: metadata-update */
-	if (!mono_binary_search (&loc, tdef->base, table_info_get_rows (tdef), tdef->row_size, table_locator))
-		return 0;
-	mono_metadata_decode_row (tdef, loc.result, cols, MONO_CLASS_LAYOUT_SIZE);
-	if (packing)
-		*packing = cols [MONO_CLASS_LAYOUT_PACKING_SIZE];
-	if (size)
-		*size = cols [MONO_CLASS_LAYOUT_CLASS_SIZE];
-	/* loc_result is 0..1, needs to be mapped to table index (that is +1) */
-	return loc.result + 1;
-}
-/**
- * mono_metadata_custom_attrs_from_index:
- * \param meta metadata context
- * \param index token representing the parent
- * \returns: the 1-based index into the \c CustomAttribute table of the first
- * attribute which belongs to the metadata object described by \p index.
- * Returns 0 if no such attribute is found.
- */
-guint32
-mono_metadata_custom_attrs_from_index (MonoImage *meta, guint32 index)
-{
-	MonoTableInfo *tdef = &meta->tables [MONO_TABLE_CUSTOMATTRIBUTE];
-	mono_locator_t loc = mono_locator_init (tdef, index, MONO_CUSTOM_ATTR_PARENT);
-	if (!tdef->base && !meta->has_updates)
-		return 0;
-	/* FIXME: Index translation */
-	gboolean found = tdef->base && mono_binary_search (&loc, tdef->base, table_info_get_rows (tdef), tdef->row_size, table_locator) != NULL;
-	if (!found) {
-		if (G_LIKELY (!meta->has_updates)) {
-			return 0;
-		} else {
-			if ((mono_metadata_table_num_rows (meta, MONO_TABLE_CUSTOMATTRIBUTE) > table_info_get_rows (tdef))) {
-				if (!mono_metadata_update_metadata_linear_search (meta, tdef, &loc, table_locator))
-					return 0;
-			} else {
-				return 0;
-			}
-		}
-	}
-	/* Find the first entry by searching backwards */
-	while ((loc.result > 0) && (mono_metadata_decode_row_col (tdef, loc.result - 1, MONO_CUSTOM_ATTR_PARENT) == index))
-		loc.result --;
-	/* loc_result is 0..1, needs to be mapped to table index (that is +1) */
-	return loc.result + 1;
-}
-/**
- * mono_metadata_declsec_from_index:
- * \param meta metadata context
- * \param index token representing the parent
- * \returns the 0-based index into the \c DeclarativeSecurity table of the first
- * attribute which belongs to the metadata object described by \p index.
- * Returns \c -1 if no such attribute is found.
- */
-guint32
-mono_metadata_declsec_from_index (MonoImage *meta, guint32 index)
-{
-	MonoTableInfo *tdef = &meta->tables [MONO_TABLE_DECLSECURITY];
-	mono_locator_t loc = mono_locator_init (tdef, index, MONO_DECL_SECURITY_PARENT);
-	if (!tdef->base)
-		return -1;
-	/* FIXME: metadata-update */
-	if (!mono_binary_search (&loc, tdef->base, table_info_get_rows (tdef), tdef->row_size, declsec_locator))
-		return -1;
-	/* Find the first entry by searching backwards */
-	while ((loc.result > 0) && (mono_metadata_decode_row_col (tdef, loc.result - 1, MONO_DECL_SECURITY_PARENT) == index))
-		loc.result --;
-	return loc.result;
-}
-/*
- * mono_metadata_localscope_from_methoddef:
- * @meta: metadata context
- * @index: methoddef index
- *
- * Returns: the 1-based index into the LocalScope table of the first
- * scope which belongs to the method described by @index.
- * Returns 0 if no such row is found.
- */
-guint32
-mono_metadata_localscope_from_methoddef (MonoImage *meta, guint32 index)
-{
-	MonoTableInfo *tdef = &meta->tables [MONO_TABLE_LOCALSCOPE];
-	mono_locator_t loc = mono_locator_init (tdef, index, MONO_LOCALSCOPE_METHOD);
-	if (!tdef->base)
-		return 0;
-	/* FIXME: metadata-update */
-	if (!mono_binary_search (&loc, tdef->base, table_info_get_rows (tdef), tdef->row_size, table_locator))
-		return 0;
-	/* Find the first entry by searching backwards */
-	while ((loc.result > 0) && (mono_metadata_decode_row_col (tdef, loc.result - 1, MONO_LOCALSCOPE_METHOD) == index))
-		loc.result --;
-	return loc.result + 1;
-}
-#ifdef DEBUG
-static void
-mono_backtrace (int limit)
-{
-	void *array[limit];
-	char **names;
-	int i;
-	backtrace (array, limit);
-	names = backtrace_symbols (array, limit);
-	for (i =0; i < limit; ++i) {
-		g_print ("\t%s\n", names [i]);
-	}
-	g_free (names);
-}
-#endif
-static int i8_align;
-/*
- * mono_type_set_alignment:
- *
- *   Set the alignment used by runtime to layout fields etc. of type TYPE to ALIGN.
- * This should only be used in AOT mode since the resulting layout will not match the
- * host abi layout.
- */
-void
-mono_type_set_alignment (MonoTypeEnum type, int align)
-{
-	/* Support only a few types whose alignment is abi dependent */
-	switch (type) {
-	case MONO_TYPE_I8:
-		i8_align = align;
-		break;
-	default:
-		g_assert_not_reached ();
-		break;
-	}
-}
-/**
- * mono_type_size:
- * \param t the type to return the size of
- * \returns The number of bytes required to hold an instance of this
- * type in memory
- */
-int
-mono_type_size (MonoType *t, int *align)
-{
-	MonoTypeEnum simple_type;
-	if (!t) {
-		*align = 1;
-		return 0;
-	}
-	if (m_type_is_byref (t)) {
-		*align = MONO_ABI_ALIGNOF (gpointer);
-		return MONO_ABI_SIZEOF (gpointer);
-	}
-	simple_type = t->type;
- again:
-	switch (simple_type) {
-	case MONO_TYPE_VOID:
-		*align = 1;
-		return 0;
-	case MONO_TYPE_BOOLEAN:
-		*align = MONO_ABI_ALIGNOF (gint8);
-		return 1;
-	case MONO_TYPE_I1:
-	case MONO_TYPE_U1:
-		*align = MONO_ABI_ALIGNOF (gint8);
-		return 1;
-	case MONO_TYPE_CHAR:
-	case MONO_TYPE_I2:
-	case MONO_TYPE_U2:
-		*align = MONO_ABI_ALIGNOF (gint16);
-		return 2;
-	case MONO_TYPE_I4:
-	case MONO_TYPE_U4:
-		*align = MONO_ABI_ALIGNOF (gint32);
-		return 4;
-	case MONO_TYPE_R4:
-		*align = MONO_ABI_ALIGNOF (float);
-		return 4;
-	case MONO_TYPE_I8:
-	case MONO_TYPE_U8:
-		*align = MONO_ABI_ALIGNOF (gint64);
-		return 8;
-	case MONO_TYPE_R8:
-		*align = MONO_ABI_ALIGNOF (double);
-		return 8;
-	case MONO_TYPE_I:
-	case MONO_TYPE_U:
-		*align = MONO_ABI_ALIGNOF (gpointer);
-		return MONO_ABI_SIZEOF (gpointer);
-	case MONO_TYPE_VALUETYPE: {
-		if (m_class_is_enumtype (t->data.klass))
-			return mono_type_size (mono_class_enum_basetype_internal (t->data.klass), align);
-		else
-			return mono_class_value_size (t->data.klass, (guint32*)align);
-	}
-	case MONO_TYPE_STRING:
-	case MONO_TYPE_OBJECT:
-	case MONO_TYPE_CLASS:
-	case MONO_TYPE_SZARRAY:
-	case MONO_TYPE_PTR:
-	case MONO_TYPE_FNPTR:
-	case MONO_TYPE_ARRAY:
-		*align = MONO_ABI_ALIGNOF (gpointer);
-		return MONO_ABI_SIZEOF (gpointer);
-	case MONO_TYPE_TYPEDBYREF:
-		return mono_class_value_size (mono_defaults.typed_reference_class, (guint32*)align);
-	case MONO_TYPE_GENERICINST: {
-		MonoGenericClass *gclass = t->data.generic_class;
-		MonoClass *container_class = gclass->container_class;
-		if (m_class_is_valuetype (container_class)) {
-			if (m_class_is_enumtype (container_class))
-				return mono_type_size (mono_class_enum_basetype_internal (container_class), align);
-			else
-				return mono_class_value_size (mono_class_from_mono_type_internal (t), (guint32*)align);
-		} else {
-			*align = MONO_ABI_ALIGNOF (gpointer);
-			return MONO_ABI_SIZEOF (gpointer);
-		}
-	}
-	case MONO_TYPE_VAR:
-	case MONO_TYPE_MVAR:
-		if (!t->data.generic_param->gshared_constraint || t->data.generic_param->gshared_constraint->type == MONO_TYPE_VALUETYPE) {
-			*align = MONO_ABI_ALIGNOF (gpointer);
-			return MONO_ABI_SIZEOF (gpointer);
-		} else {
-			/* The gparam can only match types given by gshared_constraint */
-			return mono_type_size (t->data.generic_param->gshared_constraint, align);
-			goto again;
-		}
-	default:
-		g_error ("mono_type_size: type 0x%02x unknown", t->type);
-	}
-	return 0;
-}
-/**
- * mono_type_stack_size:
- * \param t the type to return the size it uses on the stack
- * \returns The number of bytes required to hold an instance of this
- * type on the runtime stack
- */
-int
-mono_type_stack_size (MonoType *t, int *align)
-{
-	return mono_type_stack_size_internal (t, align, FALSE);
-}
-int
-mono_type_stack_size_internal (MonoType *t, int *align, gboolean allow_open)
-{
-	int tmp;
-	MonoTypeEnum simple_type;
-	int stack_slot_size = TARGET_SIZEOF_VOID_P;
-	int stack_slot_align = TARGET_SIZEOF_VOID_P;
-	g_assert (t != NULL);
-	if (!align)
-		align = &tmp;
-	if (m_type_is_byref (t)) {
-		*align = stack_slot_align;
-		return stack_slot_size;
-	}
-	simple_type = t->type;
-	switch (simple_type) {
-	case MONO_TYPE_BOOLEAN:
-	case MONO_TYPE_CHAR:
-	case MONO_TYPE_I1:
-	case MONO_TYPE_U1:
-	case MONO_TYPE_I2:
-	case MONO_TYPE_U2:
-	case MONO_TYPE_I4:
-	case MONO_TYPE_U4:
-	case MONO_TYPE_I:
-	case MONO_TYPE_U:
-	case MONO_TYPE_STRING:
-	case MONO_TYPE_OBJECT:
-	case MONO_TYPE_CLASS:
-	case MONO_TYPE_SZARRAY:
-	case MONO_TYPE_PTR:
-	case MONO_TYPE_FNPTR:
-	case MONO_TYPE_ARRAY:
-		*align = stack_slot_align;
-		return stack_slot_size;
-	case MONO_TYPE_VAR:
-	case MONO_TYPE_MVAR:
-		g_assert (allow_open);
-		if (!t->data.generic_param->gshared_constraint || t->data.generic_param->gshared_constraint->type == MONO_TYPE_VALUETYPE) {
-			*align = stack_slot_align;
-			return stack_slot_size;
-		} else {
-			/* The gparam can only match types given by gshared_constraint */
-			return mono_type_stack_size_internal (t->data.generic_param->gshared_constraint, align, allow_open);
-		}
-	case MONO_TYPE_TYPEDBYREF:
-		*align = stack_slot_align;
-		return stack_slot_size * 3;
-	case MONO_TYPE_R4:
-		*align = MONO_ABI_ALIGNOF (float);
-		return sizeof (float);
-	case MONO_TYPE_I8:
-	case MONO_TYPE_U8:
-		*align = MONO_ABI_ALIGNOF (gint64);
-		return sizeof (gint64);
-	case MONO_TYPE_R8:
-		*align = MONO_ABI_ALIGNOF (double);
-		return sizeof (double);
-	case MONO_TYPE_VALUETYPE: {
-		guint32 size;
-		if (m_class_is_enumtype (t->data.klass))
-			return mono_type_stack_size_internal (mono_class_enum_basetype_internal (t->data.klass), align, allow_open);
-		else {
-			size = mono_class_value_size (t->data.klass, (guint32*)align);
-			*align = *align + stack_slot_align - 1;
-			*align &= ~(stack_slot_align - 1);
-			size += stack_slot_size - 1;
-			size &= ~(stack_slot_size - 1);
-			return size;
-		}
-	}
-	case MONO_TYPE_GENERICINST: {
-		MonoGenericClass *gclass = t->data.generic_class;
-		MonoClass *container_class = gclass->container_class;
-		if (!allow_open)
-			g_assert (!gclass->context.class_inst->is_open);
-		if (m_class_is_valuetype (container_class)) {
-			if (m_class_is_enumtype (container_class))
-				return mono_type_stack_size_internal (mono_class_enum_basetype_internal (container_class), align, allow_open);
-			else {
-				guint32 size = mono_class_value_size (mono_class_from_mono_type_internal (t), (guint32*)align);
-				*align = *align + stack_slot_align - 1;
-				*align &= ~(stack_slot_align - 1);
-				size += stack_slot_size - 1;
-				size &= ~(stack_slot_size - 1);
-				return size;
-			}
-		} else {
-			*align = stack_slot_align;
-			return stack_slot_size;
-		}
-	}
-	default:
-		g_error ("type 0x%02x unknown", t->type);
-	}
-	return 0;
-}
-gboolean
-mono_type_generic_inst_is_valuetype (MonoType *type)
-{
-	g_assert (type->type == MONO_TYPE_GENERICINST);
-	return m_class_is_valuetype (type->data.generic_class->container_class);
-}
-/**
- * mono_metadata_generic_class_is_valuetype:
- */
-gboolean
-mono_metadata_generic_class_is_valuetype (MonoGenericClass *gclass)
-{
-	return m_class_is_valuetype (gclass->container_class);
-}
-static gboolean
-_mono_metadata_generic_class_equal (const MonoGenericClass *g1, const MonoGenericClass *g2, gboolean signature_only)
-{
-	MonoGenericInst *i1 = g1->context.class_inst;
-	MonoGenericInst *i2 = g2->context.class_inst;
-	if (g1->is_dynamic != g2->is_dynamic)
-		return FALSE;
-	if (!mono_metadata_class_equal (g1->container_class, g2->container_class, signature_only))
-		return FALSE;
-	if (!mono_generic_inst_equal_full (i1, i2, signature_only))
-		return FALSE;
-	return g1->is_tb_open == g2->is_tb_open;
-}
-static gboolean
-_mono_metadata_generic_class_container_equal (const MonoGenericClass *g1, MonoClass *c2, gboolean signature_only)
-{
-	MonoGenericInst *i1 = g1->context.class_inst;
-	MonoGenericInst *i2 = mono_class_get_generic_container (c2)->context.class_inst;
-	if (!mono_metadata_class_equal (g1->container_class, c2, signature_only))
-		return FALSE;
-	if (!mono_generic_inst_equal_full (i1, i2, signature_only))
-		return FALSE;
-	return !g1->is_tb_open;
-}
-guint
-mono_metadata_generic_context_hash (const MonoGenericContext *context)
-{
-	/* FIXME: check if this seed is good enough */
-	guint hash = 0xc01dfee7;
-	if (context->class_inst)
-		hash = ((hash << 5) - hash) ^ mono_metadata_generic_inst_hash (context->class_inst);
-	if (context->method_inst)
-		hash = ((hash << 5) - hash) ^ mono_metadata_generic_inst_hash (context->method_inst);
-	return hash;
-}
-gboolean
-mono_metadata_generic_context_equal (const MonoGenericContext *g1, const MonoGenericContext *g2)
-{
-	return g1->class_inst == g2->class_inst && g1->method_inst == g2->method_inst;
-}
-/*
- * mono_metadata_str_hash:
- *
- *   This should be used instead of g_str_hash for computing hash codes visible
- * outside this module, since g_str_hash () is not guaranteed to be stable
- * (its not the same in eglib for example).
- */
-guint
-mono_metadata_str_hash (gconstpointer v1)
-{
-	/* Same as g_str_hash () in glib */
-	/* note: signed/unsigned char matters - we feed UTF-8 to this function, so the high bit will give diferent results if we don't match. */
-	unsigned char *p = (unsigned char *) v1;
-	guint hash = *p;
-	while (*p++) {
-		if (*p)
-			hash = (hash << 5) - hash + *p;
-	}
-	return hash;
-}
-/**
- * mono_metadata_type_hash:
- * \param t1 a type
- * Computes a hash value for \p t1 to be used in \c GHashTable.
- * The returned hash is guaranteed to be the same across executions.
- */
-guint
-mono_metadata_type_hash (MonoType *t1)
-{
-	guint hash = t1->type;
-	hash |= (m_type_is_byref (t1) ? 1 : 0) << 6; /* do not collide with t1->type values */
-	switch (t1->type) {
-	case MONO_TYPE_VALUETYPE:
-	case MONO_TYPE_CLASS:
-	case MONO_TYPE_SZARRAY: {
-		MonoClass *klass = t1->data.klass;
-		/*
-		 * Dynamic classes must not be hashed on their type since it can change
-		 * during runtime. For example, if we hash a reference type that is
-		 * later made into a valuetype.
-		 *
-		 * This is specially problematic with generic instances since they are
-		 * inserted in a bunch of hash tables before been finished.
-		 */
-		if (image_is_dynamic (m_class_get_image (klass)))
-			return ((m_type_is_byref (t1) ? 1 : 0) << 6) | m_class_get_name_hash (klass);
-		return ((hash << 5) - hash) ^ m_class_get_name_hash (klass);
-	}
-	case MONO_TYPE_PTR:
-		return ((hash << 5) - hash) ^ mono_metadata_type_hash (t1->data.type);
-	case MONO_TYPE_ARRAY:
-		return ((hash << 5) - hash) ^ mono_metadata_type_hash (m_class_get_byval_arg (t1->data.array->eklass));
-	case MONO_TYPE_GENERICINST:
-		return ((hash << 5) - hash) ^ mono_generic_class_hash (t1->data.generic_class);
-	case MONO_TYPE_VAR:
-	case MONO_TYPE_MVAR:
-		return ((hash << 5) - hash) ^ mono_metadata_generic_param_hash (t1->data.generic_param);
-	default:
-		return hash;
-	}
-}
-guint
-mono_metadata_generic_param_hash (MonoGenericParam *p)
-{
-	guint hash;
-	MonoGenericParamInfo *info;
-	hash = (mono_generic_param_num (p) << 2);
-	if (p->gshared_constraint)
-		hash = ((hash << 5) - hash) ^ mono_metadata_type_hash (p->gshared_constraint);
-	info = mono_generic_param_info (p);
-	/* Can't hash on the owner klass/method, since those might not be set when this is called */
-	if (!p->owner->is_anonymous)
-		hash = ((hash << 5) - hash) ^ info->token;
-	return hash;
-}
-static gboolean
-mono_metadata_generic_param_equal_internal (MonoGenericParam *p1, MonoGenericParam *p2, gboolean signature_only)
-{
-	if (p1 == p2)
-		return TRUE;
-	if (mono_generic_param_num (p1) != mono_generic_param_num (p2))
-		return FALSE;
-	if (p1->gshared_constraint && p2->gshared_constraint) {
-		if (!mono_metadata_type_equal (p1->gshared_constraint, p2->gshared_constraint))
-			return FALSE;
-	} else {
-		if (p1->gshared_constraint != p2->gshared_constraint)
-			return FALSE;
-	}
-	/*
-	 * We have to compare the image as well because if we didn't,
-	 * the generic_inst_cache lookup wouldn't care about the image
-	 * of generic params, so what could happen is that a generic
-	 * inst with params from image A is put into the cache, then
-	 * image B gets that generic inst from the cache, image A is
-	 * unloaded, so the inst is deleted, but image B still retains
-	 * a pointer to it.
-	 */
-	if (mono_generic_param_owner (p1) == mono_generic_param_owner (p2))
-		return TRUE;
-	/*
-	 * If `signature_only' is true, we're comparing two (method) signatures.
-	 * In this case, the owner of two type parameters doesn't need to match.
-	 */
-	return signature_only;
-}
-gboolean
-mono_metadata_generic_param_equal (MonoGenericParam *p1, MonoGenericParam *p2)
-{
-	return mono_metadata_generic_param_equal_internal (p1, p2, TRUE);
-}
-static gboolean
-mono_metadata_class_equal (MonoClass *c1, MonoClass *c2, gboolean signature_only)
-{
-	if (c1 == c2)
-		return TRUE;
-	if (mono_class_is_ginst (c1) && mono_class_is_ginst (c2))
-		return _mono_metadata_generic_class_equal (mono_class_get_generic_class (c1), mono_class_get_generic_class (c2), signature_only);
-	if (mono_class_is_ginst (c1) && mono_class_is_gtd (c2))
-		return _mono_metadata_generic_class_container_equal (mono_class_get_generic_class (c1), c2, signature_only);
-	if (mono_class_is_gtd (c1) && mono_class_is_ginst (c2))
-		return _mono_metadata_generic_class_container_equal (mono_class_get_generic_class (c2), c1, signature_only);
-	MonoType *c1_type = m_class_get_byval_arg (c1);
-	MonoType *c2_type = m_class_get_byval_arg (c2);
-	if ((c1_type->type == MONO_TYPE_VAR) && (c2_type->type == MONO_TYPE_VAR))
-		return mono_metadata_generic_param_equal_internal (
-			c1_type->data.generic_param, c2_type->data.generic_param, signature_only);
-	if ((c1_type->type == MONO_TYPE_MVAR) && (c2_type->type == MONO_TYPE_MVAR))
-		return mono_metadata_generic_param_equal_internal (
-			c1_type->data.generic_param, c2_type->data.generic_param, signature_only);
-	if (signature_only &&
-	    (c1_type->type == MONO_TYPE_SZARRAY) && (c2_type->type == MONO_TYPE_SZARRAY))
-		return mono_metadata_class_equal (c1_type->data.klass, c2_type->data.klass, signature_only);
-	if (signature_only &&
-	    (c1_type->type == MONO_TYPE_ARRAY) && (c2_type->type == MONO_TYPE_ARRAY))
-		return do_mono_metadata_type_equal (c1_type, c2_type, signature_only ? MONO_TYPE_EQ_FLAGS_SIG_ONLY : 0);
-	if (signature_only &&
-		(c1_type->type == MONO_TYPE_PTR) && (c2_type->type == MONO_TYPE_PTR))
-		return do_mono_metadata_type_equal (c1_type->data.type, c2_type->data.type, signature_only ? MONO_TYPE_EQ_FLAGS_SIG_ONLY : 0);
-	if (signature_only &&
-		(c1_type->type == MONO_TYPE_FNPTR) && (c2_type->type == MONO_TYPE_FNPTR))
-		return mono_metadata_fnptr_equal (c1_type->data.method, c2_type->data.method, signature_only ? MONO_TYPE_EQ_FLAGS_SIG_ONLY : 0);
-	return FALSE;
-}
-static int
-mono_metadata_check_call_convention_category (unsigned int call_convention)
-{
-	switch (call_convention) {
-	case MONO_CALL_DEFAULT:
-		return 1;
-	case MONO_CALL_C:
-	case MONO_CALL_STDCALL:
-	case MONO_CALL_THISCALL:
-	case MONO_CALL_FASTCALL:
-	case MONO_CALL_UNMANAGED_MD:
-		return 2;
-	case MONO_CALL_VARARG:
-		return 3;
-	default:
-		g_assert_not_reached ();
-	}
-}
-static gboolean
-mono_metadata_fnptr_equal (MonoMethodSignature *s1, MonoMethodSignature *s2, int equiv_flags)
-{
-	gpointer iter1 = 0, iter2 = 0;
-	if (s1 == s2)
-		return TRUE;
-	if ((equiv_flags & MONO_TYPE_EQ_FLAG_IGNORE_CMODS) == 0) {
-		if (s1->call_convention != s2->call_convention)
-			return FALSE;
-	} else {
-		if (mono_metadata_check_call_convention_category (s1->call_convention) != mono_metadata_check_call_convention_category (s2->call_convention))
-			return FALSE;
-	}
-	if (s1->sentinelpos != s2->sentinelpos)
-		return FALSE;
-	if (s1->hasthis != s2->hasthis)
-		return FALSE;
-	if (s1->explicit_this != s2->explicit_this)
-		return FALSE;
-	if (! do_mono_metadata_type_equal (s1->ret, s2->ret, equiv_flags))
-		return FALSE;
-	if (s1->param_count != s2->param_count)
-		return FALSE;
-	while (TRUE) {
-		MonoType *t1 = mono_signature_get_params_internal (s1, &iter1);
-		MonoType *t2 = mono_signature_get_params_internal (s2, &iter2);
-		if (t1 == NULL || t2 == NULL)
-			return (t1 == t2);
-		if (! do_mono_metadata_type_equal (t1, t2, equiv_flags))
-			return FALSE;
-	}
-}
-static gboolean
-mono_metadata_custom_modifiers_equal (MonoType *t1, MonoType *t2, gboolean signature_only)
-{
-	uint8_t count = mono_type_custom_modifier_count (t1);
-	if (count != mono_type_custom_modifier_count (t2))
-		return FALSE;
-	for (uint8_t i=0; i < count; i++) {
-		ERROR_DECL (error);
-		gboolean cm1_required, cm2_required;
-		MonoType *cm1_type = mono_type_get_custom_modifier (t1, i, &cm1_required, error);
-		mono_error_assert_ok (error);
-		MonoType *cm2_type = mono_type_get_custom_modifier (t2, i, &cm2_required, error);
-		mono_error_assert_ok (error);
-		if (cm1_required != cm2_required)
-			return FALSE;
-		if (!do_mono_metadata_type_equal (cm1_type, cm2_type, signature_only ? MONO_TYPE_EQ_FLAGS_SIG_ONLY : 0))
-			return FALSE;
-	}
-	return TRUE;
-}
-/*
- * mono_metadata_type_equal:
- * @t1: a type
- * @t2: another type
- * @signature_only: If true, treat ginsts as equal which are instantiated separately but have equal positional value
- *
- * Determine if @t1 and @t2 represent the same type.
- * Returns: #TRUE if @t1 and @t2 are equal.
- */
-static gboolean
-do_mono_metadata_type_equal (MonoType *t1, MonoType *t2, int equiv_flags)
-{
-	if (t1->type != t2->type || m_type_is_byref (t1) != m_type_is_byref (t2))
-		return FALSE;
-	gboolean cmod_reject = FALSE;
-	if ((equiv_flags & MONO_TYPE_EQ_FLAG_IGNORE_CMODS) == 0) {
-		if (t1->has_cmods != t2->has_cmods)
-			cmod_reject = TRUE;
-		else if (t1->has_cmods && t2->has_cmods) {
-			cmod_reject = !mono_metadata_custom_modifiers_equal (t1, t2, (equiv_flags & MONO_TYPE_EQ_FLAGS_SIG_ONLY) != 0);
-		}
-	}
-	gboolean result = FALSE;
-	switch (t1->type) {
-	case MONO_TYPE_VOID:
-	case MONO_TYPE_BOOLEAN:
-	case MONO_TYPE_CHAR:
-	case MONO_TYPE_I1:
-	case MONO_TYPE_U1:
-	case MONO_TYPE_I2:
-	case MONO_TYPE_U2:
-	case MONO_TYPE_I4:
-	case MONO_TYPE_U4:
-	case MONO_TYPE_I8:
-	case MONO_TYPE_U8:
-	case MONO_TYPE_R4:
-	case MONO_TYPE_R8:
-	case MONO_TYPE_STRING:
-	case MONO_TYPE_I:
-	case MONO_TYPE_U:
-	case MONO_TYPE_OBJECT:
-	case MONO_TYPE_TYPEDBYREF:
-		result = TRUE;
-		break;
-	case MONO_TYPE_VALUETYPE:
-	case MONO_TYPE_CLASS:
-	case MONO_TYPE_SZARRAY:
-		result = mono_metadata_class_equal (t1->data.klass, t2->data.klass, (equiv_flags & MONO_TYPE_EQ_FLAGS_SIG_ONLY) != 0);
-		break;
-	case MONO_TYPE_PTR:
-		result = do_mono_metadata_type_equal (t1->data.type, t2->data.type, equiv_flags);
-		break;
-	case MONO_TYPE_ARRAY:
-		if (t1->data.array->rank != t2->data.array->rank)
-			result = FALSE;
-		else
-			result = mono_metadata_class_equal (t1->data.array->eklass, t2->data.array->eklass, (equiv_flags & MONO_TYPE_EQ_FLAGS_SIG_ONLY) != 0);
-		break;
-	case MONO_TYPE_GENERICINST:
-		result = _mono_metadata_generic_class_equal (
-			t1->data.generic_class, t2->data.generic_class, (equiv_flags & MONO_TYPE_EQ_FLAGS_SIG_ONLY) != 0);
-		break;
-	case MONO_TYPE_VAR:
-		result = mono_metadata_generic_param_equal_internal (
-			t1->data.generic_param, t2->data.generic_param, (equiv_flags & MONO_TYPE_EQ_FLAGS_SIG_ONLY) != 0);
-		break;
-	case MONO_TYPE_MVAR:
-		result = mono_metadata_generic_param_equal_internal (
-			t1->data.generic_param, t2->data.generic_param, (equiv_flags & MONO_TYPE_EQ_FLAGS_SIG_ONLY) != 0);
-		break;
-	case MONO_TYPE_FNPTR:
-		result = mono_metadata_fnptr_equal (t1->data.method, t2->data.method, equiv_flags);
-		break;
-	default:
-		g_error ("implement type compare for %0x!", t1->type);
-		return FALSE;
-	}
-	return result && !cmod_reject;
-}
-/**
- * mono_metadata_type_equal:
- */
-gboolean
-mono_metadata_type_equal (MonoType *t1, MonoType *t2)
-{
-	return do_mono_metadata_type_equal (t1, t2, MONO_TYPE_EQ_FLAGS_NONE);
-}
-/**
- * mono_metadata_type_equal_full:
- * \param t1 a type
- * \param t2 another type
- * \param flags flags used to modify comparison logic
- *
- * Determine if \p t1 and \p t2 are compatible based on the supplied flags.
- * The function mono_metadata_type_equal(a, b) is just a shortcut for mono_metadata_type_equal_full(a, b, MONO_TYPE_EQ_FLAGS_NONE).
- * \returns TRUE if \p t1 and \p t2 are equal.
- */
-gboolean
-mono_metadata_type_equal_full (MonoType *t1, MonoType *t2, int flags)
-{
-	return do_mono_metadata_type_equal (t1, t2, flags);
-}
-enum {
-	SIG_EQUIV_FLAG_NO_RET = 1,
-	SIG_EQUIV_FLAG_IGNORE_CMODS = 2,
-};
-gboolean
-signature_equiv (MonoMethodSignature *sig1, MonoMethodSignature *sig2, int flags);
-/**
- * mono_metadata_signature_equal:
- * \param sig1 a signature
- * \param sig2 another signature
- *
- * Determine if \p sig1 and \p sig2 represent the same signature, with the
- * same number of arguments and the same types.
- * \returns TRUE if \p sig1 and \p sig2 are equal.
- */
-gboolean
-mono_metadata_signature_equal (MonoMethodSignature *sig1, MonoMethodSignature *sig2)
-{
-	return signature_equiv (sig1, sig2, 0);
-}
-gboolean
-mono_metadata_signature_equal_no_ret (MonoMethodSignature *sig1, MonoMethodSignature *sig2)
-{
-	return signature_equiv (sig1, sig2, SIG_EQUIV_FLAG_NO_RET);
-}
-gboolean
-mono_metadata_signature_equal_ignore_custom_modifier (MonoMethodSignature *sig1, MonoMethodSignature *sig2)
-{
-	return signature_equiv (sig1, sig2, SIG_EQUIV_FLAG_IGNORE_CMODS);
-}
-gboolean
-signature_equiv (MonoMethodSignature *sig1, MonoMethodSignature *sig2, int equiv_flags)
-{
-	int i;
-	if (sig1->hasthis != sig2->hasthis || sig1->param_count != sig2->param_count)
-		return FALSE;
-	if (sig1->generic_param_count != sig2->generic_param_count)
-		return FALSE;
-	int flag = MONO_TYPE_EQ_FLAGS_SIG_ONLY | (((equiv_flags & SIG_EQUIV_FLAG_IGNORE_CMODS) != 0) ? MONO_TYPE_EQ_FLAG_IGNORE_CMODS : 0);
-	/*
-	 * We're just comparing the signatures of two methods here:
-	 *
-	 * If we have two generic methods `void Foo<U> (U u)' and `void Bar<V> (V v)',
-	 * U and V are equal here.
-	 *
-	 * That's what the `signature_only' argument of do_mono_metadata_type_equal() is for.
-	 */
-	for (i = 0; i < sig1->param_count; i++) {
-		MonoType *p1 = sig1->params[i];
-		MonoType *p2 = sig2->params[i];
-		/* if (p1->attrs != p2->attrs)
-			return FALSE;
-		*/
-		if (!do_mono_metadata_type_equal (p1, p2, flag))
-			return FALSE;
-	}
-	if ((equiv_flags & SIG_EQUIV_FLAG_NO_RET) != 0)
-		return TRUE;
-	if (!do_mono_metadata_type_equal (sig1->ret, sig2->ret, flag))
-		return FALSE;
-	return TRUE;
-}
-gboolean
-signature_equiv_vararg (MonoMethodSignature *sig1, MonoMethodSignature *sig2, int equiv_flags);
-gboolean
-mono_metadata_signature_equal_vararg (MonoMethodSignature *sig1, MonoMethodSignature *sig2)
-{
-	return signature_equiv_vararg (sig1, sig2, 0);
-}
-gboolean
-mono_metadata_signature_equal_vararg_ignore_custom_modifier (MonoMethodSignature *sig1, MonoMethodSignature *sig2)
-{
-	return signature_equiv_vararg (sig1, sig2, SIG_EQUIV_FLAG_IGNORE_CMODS);
-}
-gboolean
-signature_equiv_vararg (MonoMethodSignature *sig1, MonoMethodSignature *sig2, int equiv_flags)
-{
-	int i;
-	if (sig1->hasthis != sig2->hasthis ||
-	    sig1->sentinelpos != sig2->sentinelpos)
-		return FALSE;
-	int flag = MONO_TYPE_EQ_FLAGS_SIG_ONLY | (((equiv_flags & SIG_EQUIV_FLAG_IGNORE_CMODS) != 0) ? MONO_TYPE_EQ_FLAG_IGNORE_CMODS : 0);
-	for (i = 0; i < sig1->sentinelpos; i++) {
-		MonoType *p1 = sig1->params[i];
-		MonoType *p2 = sig2->params[i];
-		/*if (p1->attrs != p2->attrs)
-			return FALSE;
-		*/
-		if (!do_mono_metadata_type_equal (p1, p2, flag))
-			return FALSE;
-	}
-	if (!do_mono_metadata_type_equal (sig1->ret, sig2->ret, flag))
-		return FALSE;
-	return TRUE;
-}
-MonoType *
-mono_type_get_custom_modifier (const MonoType *ty, uint8_t idx, gboolean *required, MonoError *error)
-{
-	g_assert (ty->has_cmods);
-	if (mono_type_is_aggregate_mods (ty)) {
-		MonoAggregateModContainer *amods = mono_type_get_amods (ty);
-		g_assert (idx < amods->count);
-		MonoSingleCustomMod *cmod = &amods->modifiers [idx];
-		if (required)
-			*required = !!cmod->required;
-		return cmod->type;
-	} else {
-		MonoCustomModContainer *cmods = mono_type_get_cmods (ty);
-		g_assert (idx < cmods->count);
-		MonoCustomMod *cmod = &cmods->modifiers [idx];
-		if (required)
-			*required = !!cmod->required;
-		MonoImage *image = cmods->image;
-		uint32_t token = cmod->token;
-		return mono_type_get_checked (image, token, NULL, error);
-	}
-}
-/**
- * mono_metadata_type_dup:
- * \param image image to alloc memory from
- * \param original type to duplicate
- * \returns copy of type allocated from the image's mempool (or from the heap, if \p image is null).
- */
-MonoType *
-mono_metadata_type_dup (MonoImage *image, const MonoType *o)
-{
-	return mono_metadata_type_dup_with_cmods (image, o, o);
-}
-static void
-deep_type_dup_fixup (MonoImage *image, MonoType *r, const MonoType *o);
-static uint8_t
-custom_modifier_copy (MonoAggregateModContainer *dest, uint8_t dest_offset, const MonoType *source)
-{
-	if (mono_type_is_aggregate_mods (source)) {
-		MonoAggregateModContainer *src_cmods = mono_type_get_amods (source);
-		memcpy (&dest->modifiers [dest_offset], &src_cmods->modifiers[0], src_cmods->count * sizeof (MonoSingleCustomMod));
-		dest_offset += src_cmods->count;
-	} else {
-		MonoCustomModContainer *src_cmods = mono_type_get_cmods (source);
-		for (int i = 0; i < src_cmods->count; i++) {
-			ERROR_DECL (error); // XXX FIXME: AK - propagate the error to the caller.
-			MonoSingleCustomMod *cmod = &dest->modifiers [dest_offset++];
-			cmod->type = mono_type_get_checked (src_cmods->image, src_cmods->modifiers [i].token, NULL, error);
-			mono_error_assert_ok (error);
-			cmod->required = src_cmods->modifiers [i].required;
-		}
-	}
-	return dest_offset;
-}
-/* makes a dup of 'o' but also appends the custom modifiers from 'cmods_source' */
-static MonoType *
-do_metadata_type_dup_append_cmods (MonoImage *image, const MonoType *o, const MonoType *cmods_source)
-{
-	g_assert (o != cmods_source);
-	g_assert (o->has_cmods);
-	g_assert (cmods_source->has_cmods);
-	if (!mono_type_is_aggregate_mods (o) &&
-	    !mono_type_is_aggregate_mods (cmods_source) &&
-	    mono_type_get_cmods (o)->image == mono_type_get_cmods (cmods_source)->image) {
-		/* the uniform case: all the cmods are from the same image. */
-		MonoCustomModContainer *o_cmods = mono_type_get_cmods (o);
-		MonoCustomModContainer *extra_cmods = mono_type_get_cmods (cmods_source);
-		uint8_t total_cmods = o_cmods->count + extra_cmods->count;
-		gboolean aggregate = FALSE;
-		size_t sizeof_dup = mono_sizeof_type_with_mods (total_cmods, aggregate);
-		MonoType *r = image ? (MonoType *)mono_image_alloc0 (image, (guint)sizeof_dup) : (MonoType *)g_malloc0 (sizeof_dup);
-		mono_type_with_mods_init (r, total_cmods, aggregate);
-		/* copy the original type o, not including its modifiers */
-		memcpy (r, o, mono_sizeof_type_with_mods (0, FALSE));
-		deep_type_dup_fixup (image, r, o);
-		/* The modifier order matters to Roslyn, they expect the extra cmods to come first:
-		 *
-		 * Suppose we substitute 'int32 modopt(IsLong)' for 'T' in 'void Test
-		 * (T modopt(IsConst))'.  Roslyn expects the result to be 'void Test
-		 * (int32 modopt(IsLong) modopt(IsConst))'.
-		 *
-		 * but! cmods are encoded in IL in reverse order, so 'int32 modopt(IsConst) modopt(IsLong)' is
-		 * encoded as `cmod_opt [typeref IsLong] cmod_opt [typeref IsConst] I4`
-		 * so in our array, extra_cmods (IsLong) come first, followed by o_cmods (IsConst)
-		 *
-		 * (Here 'o' is 'int32 modopt(IsLong)' and cmods_source is 'T modopt(IsConst)')
-		 */
-		/* append the modifiers from cmods_source and o */
-		MonoCustomModContainer *r_container = mono_type_get_cmods (r);
-		uint8_t dest_offset = 0;
-		r_container->image = extra_cmods->image;
-		memcpy (&r_container->modifiers [dest_offset], &o_cmods->modifiers [0], o_cmods->count * sizeof (MonoCustomMod));
-		dest_offset += o_cmods->count;
-		memcpy (&r_container->modifiers [dest_offset], &extra_cmods->modifiers [0], extra_cmods->count * sizeof (MonoCustomMod));
-		dest_offset += extra_cmods->count;
-		g_assert (dest_offset == total_cmods);
-		return r;
-	} else {
-		/* The aggregate case: either o_cmods or extra_cmods has aggregate cmods, or they're both simple but from different images. */
-		uint8_t total_cmods = 0;
-		total_cmods += mono_type_custom_modifier_count (o);
-		total_cmods += mono_type_custom_modifier_count (cmods_source);
-		gboolean aggregate = TRUE;
-		size_t sizeof_dup = mono_sizeof_type_with_mods (total_cmods, aggregate);
-		/* FIXME: if image, and the images of the custom modifiers from
-		 * o and cmods_source are all different, we need an image
-		 * set... */
-		MonoType *r = image ? (MonoType *)mono_image_alloc0 (image, (guint)sizeof_dup) : (MonoType*)g_malloc0 (sizeof_dup);
-		mono_type_with_mods_init (r, total_cmods, aggregate);
-		memcpy (r, o, mono_sizeof_type_with_mods (0, FALSE));
-		deep_type_dup_fixup (image, r, o);
-		/* Try not to blow up the stack. See comment on
-		 * MONO_MAX_EXPECTED_CMODS.  Since here we're appending all the
-		 * mods together, it's possible we'll end up with more than the
-		 * maximum allowed.  If that ever happens in practice, we
-		 * should redefine the bound and possibly make this function
-		 * fail dynamically instead of asserting.
-		 */
-		g_assert (total_cmods < MONO_MAX_EXPECTED_CMODS);
-		size_t r_container_size = mono_sizeof_aggregate_modifiers (total_cmods);
-		MonoAggregateModContainer *r_container_candidate = g_alloca (r_container_size);
-		memset (r_container_candidate, 0, r_container_size);
-		uint8_t dest_offset = 0;
-		dest_offset = custom_modifier_copy (r_container_candidate, dest_offset, o);
-		dest_offset = custom_modifier_copy (r_container_candidate, dest_offset, cmods_source);
-		g_assert (dest_offset == total_cmods);
-		r_container_candidate->count = total_cmods;
-		mono_type_set_amods (r, mono_metadata_get_canonical_aggregate_modifiers (r_container_candidate));
-		return r;
-	}
-}
-/**
- * Works the same way as mono_metadata_type_dup but pick cmods from @cmods_source
- */
-MonoType *
-mono_metadata_type_dup_with_cmods (MonoImage *image, const MonoType *o, const MonoType *cmods_source)
-{
-	if (o->has_cmods && o != cmods_source && cmods_source->has_cmods) {
-		return do_metadata_type_dup_append_cmods (image, o, cmods_source);
-	}
-	MonoType *r = NULL;
-	/* if we get here, either o and cmods_source alias, or else exactly one of them has cmods. */
-	uint8_t num_mods = MAX (mono_type_custom_modifier_count (o), mono_type_custom_modifier_count (cmods_source));
-	gboolean aggregate = mono_type_is_aggregate_mods (o) || mono_type_is_aggregate_mods (cmods_source);
-	size_t sizeof_r = mono_sizeof_type_with_mods (num_mods, aggregate),
-		sizeof_o = mono_sizeof_type (o),
-		sizeof_cmods_source = cmods_source->has_cmods ? mono_sizeof_type (cmods_source) : 0,
-		sizeof_header = MAX(sizeof_o, sizeof_cmods_source);
-	uint8_t *r_bytes = NULL;
-	r = image ? (MonoType *)mono_image_alloc (image, (guint)sizeof_r) : (MonoType *)g_malloc (sizeof_r);
-	r_bytes = (uint8_t *)r;
-	if (cmods_source->has_cmods) {
-		/* FIXME: if it's aggregate what do we assert here? */
-		g_assert (!image || (!aggregate && image == mono_type_get_cmods (cmods_source)->image));
-		memcpy (r_bytes + sizeof_o, ((uint8_t *)cmods_source) + sizeof_o, sizeof_cmods_source - sizeof_o);
-	}
-	memcpy (r, o, sizeof_o);
-	if (sizeof_r > sizeof_header)
-		memset (r_bytes + sizeof_header, 0, sizeof_r - sizeof_header);
-	/* reset custom mod count and aggregateness to be correct. */
-	mono_type_with_mods_init (r, num_mods, aggregate);
-	if (aggregate)
-		mono_type_set_amods (r, mono_type_is_aggregate_mods (o) ? mono_type_get_amods (o) : mono_type_get_amods (cmods_source));
-	deep_type_dup_fixup (image, r, o);
-	return r;
-}
-static void
-deep_type_dup_fixup (MonoImage *image, MonoType *r, const MonoType *o)
-{
-	if (o->type == MONO_TYPE_PTR) {
-		r->data.type = mono_metadata_type_dup (image, o->data.type);
-	} else if (o->type == MONO_TYPE_ARRAY) {
-		r->data.array = mono_dup_array_type (image, o->data.array);
-	} else if (o->type == MONO_TYPE_FNPTR) {
-		/*FIXME the dup'ed signature is leaked mono_metadata_free_type*/
-		r->data.method = mono_metadata_signature_deep_dup (image, o->data.method);
-	}
-}
-/**
- * mono_signature_hash:
- */
-guint
-mono_signature_hash (MonoMethodSignature *sig)
-{
-	guint i, res = sig->ret->type;
-	for (i = 0; i < sig->param_count; i++)
-		res = (res << 5) - res + mono_type_hash (sig->params[i]);
-	return res;
-}
-/*
- * mono_metadata_encode_value:
- * @value: value to encode
- * @buf: buffer where to write the compressed representation
- * @endbuf: pointer updated to point at the end of the encoded output
- *
- * Encodes the value @value in the compressed representation used
- * in metadata and stores the result in @buf. @buf needs to be big
- * enough to hold the data (4 bytes).
- */
-void
-mono_metadata_encode_value (guint32 value, char *buf, char **endbuf)
-{
-	char *p = buf;
-	if (value < 0x80)
-		*p++ = GUINT32_TO_CHAR (value);
-	else if (value < 0x4000) {
-		p [0] = GUINT32_TO_CHAR (0x80 | (value >> 8));
-		p [1] = value & 0xff;
-		p += 2;
-	} else {
-		p [0] = (value >> 24) | 0xc0;
-		p [1] = (value >> 16) & 0xff;
-		p [2] = (value >> 8) & 0xff;
-		p [3] = value & 0xff;
-		p += 4;
-	}
-	if (endbuf)
-		*endbuf = p;
-}
-/**
- * mono_metadata_field_info:
- * \param meta the Image the field is defined in
- * \param index the index in the field table representing the field
- * \param offset a pointer to an integer where to store the offset that  may have been specified for the field in a FieldLayout table
- * \param rva a pointer to the RVA of the field data in the image that may have been defined in a \c FieldRVA table
- * \param marshal_spec a pointer to the marshal spec that may have been defined for the field in a \c FieldMarshal table.
- *
- * Gather info for field \p index that may have been defined in the \c FieldLayout,
- * \c FieldRVA and \c FieldMarshal tables.
- * Either of \p offset, \p rva and \p marshal_spec can be NULL if you're not interested
- * in the data.
- */
-void
-mono_metadata_field_info (MonoImage *meta, guint32 index, guint32 *offset, guint32 *rva,
-			  MonoMarshalSpec **marshal_spec)
-{
-	mono_metadata_field_info_full (meta, index, offset, rva, marshal_spec, FALSE);
-}
-void
-mono_metadata_field_info_with_mempool (MonoImage *meta, guint32 index, guint32 *offset, guint32 *rva,
-			  MonoMarshalSpec **marshal_spec)
-{
-	mono_metadata_field_info_full (meta, index, offset, rva, marshal_spec, TRUE);
-}
-static void
-mono_metadata_field_info_full (MonoImage *meta, guint32 index, guint32 *offset, guint32 *rva,
-				       MonoMarshalSpec **marshal_spec, gboolean alloc_from_image)
-{
-	MonoTableInfo *tdef;
-	mono_locator_t loc;
-	guint32 idx = index + 1;
-	if (meta->uncompressed_metadata)
-		idx = search_ptr_table (meta, MONO_TABLE_FIELD_POINTER, idx);
-	if (offset) {
-		tdef = &meta->tables [MONO_TABLE_FIELDLAYOUT];
-		loc = mono_locator_init (tdef, idx, MONO_FIELD_LAYOUT_FIELD);
-		/* metadata-update: explicit layout not supported, just return -1 */
-		if (tdef->base && mono_binary_search (&loc, tdef->base, table_info_get_rows (tdef), tdef->row_size, table_locator)) {
-			*offset = mono_metadata_decode_row_col (tdef, loc.result, MONO_FIELD_LAYOUT_OFFSET);
-		} else {
-			*offset = (guint32)-1;
-		}
-	}
-	if (rva) {
-		tdef = &meta->tables [MONO_TABLE_FIELDRVA];
-		loc = mono_locator_init (tdef, idx, MONO_FIELD_RVA_FIELD);
-		gboolean found = tdef->base && mono_binary_search (&loc, tdef->base, table_info_get_rows (tdef), tdef->row_size, table_locator);
-		if (G_UNLIKELY (meta->has_updates)) {
-			if (!found)
-				found = (mono_metadata_update_metadata_linear_search (meta, tdef, &loc, table_locator) != NULL);
-		}
-		if (found) {
-			/*
-			 * LAMESPEC: There is no signature, no nothing, just the raw data.
-			 */
-			*rva = mono_metadata_decode_row_col (tdef, loc.result, MONO_FIELD_RVA_RVA);
-		} else {
-			*rva = 0;
-		}
-	}
-	if (marshal_spec) {
-		const char *p;
-		if ((p = mono_metadata_get_marshal_info (meta, index, TRUE))) {
-			*marshal_spec = mono_metadata_parse_marshal_spec_full (alloc_from_image ? meta : NULL, meta, p);
-		}
-	}
-}
-/**
- * mono_metadata_get_constant_index:
- * \param meta the Image the field is defined in
- * \param index the token that may have a row defined in the constants table
- * \param hint possible position for the row
- *
- * \p token must be a \c FieldDef, \c ParamDef or \c PropertyDef token.
- *
- * \returns the index into the \c Constants table or 0 if not found.
- */
-guint32
-mono_metadata_get_constant_index (MonoImage *meta, guint32 token, guint32 hint)
-{
-	MonoTableInfo *tdef;
-	mono_locator_t loc;
-	guint32 index = mono_metadata_token_index (token);
-	tdef = &meta->tables [MONO_TABLE_CONSTANT];
-	index <<= MONO_HASCONSTANT_BITS;
-	switch (mono_metadata_token_table (token)) {
-	case MONO_TABLE_FIELD:
-		index |= MONO_HASCONSTANT_FIEDDEF;
-		break;
-	case MONO_TABLE_PARAM:
-		index |= MONO_HASCONSTANT_PARAM;
-		break;
-	case MONO_TABLE_PROPERTY:
-		index |= MONO_HASCONSTANT_PROPERTY;
-		break;
-	default:
-		g_warning ("Not a valid token for the constant table: 0x%08x", token);
-		return 0;
-	}
-	loc = mono_locator_init (tdef, index, MONO_CONSTANT_PARENT);
-	/* FIXME: Index translation */
-	if ((hint > 0) && (hint < table_info_get_rows (tdef)) && (mono_metadata_decode_row_col (tdef, hint - 1, MONO_CONSTANT_PARENT) == index))
-		return hint;
-	if (tdef->base && mono_binary_search (&loc, tdef->base, table_info_get_rows (tdef), tdef->row_size, table_locator)) {
-		return loc.result + 1;
-	}
-	if (G_UNLIKELY (meta->has_updates)) {
-		if (mono_metadata_update_metadata_linear_search (meta, tdef, &loc, table_locator))
-			return loc.result + 1;
-	}
-	return 0;
-}
-/**
- * mono_metadata_events_from_typedef:
- * \param meta metadata context
- * \param index 0-based index (in the \c TypeDef table) describing a type
- * \returns the 0-based index in the \c Event table for the events in the
- * type. The last event that belongs to the type (plus 1) is stored
- * in the \p end_idx pointer.
- */
-guint32
-mono_metadata_events_from_typedef (MonoImage *meta, guint32 index, guint *end_idx)
-{
-	mono_locator_t loc;
-	guint32 start, end;
-	MonoTableInfo *tdef  = &meta->tables [MONO_TABLE_EVENTMAP];
-	*end_idx = 0;
-	if (!tdef->base && !meta->has_updates)
-		return 0;
-	loc = mono_locator_init (tdef, index + 1, MONO_EVENT_MAP_PARENT);
-	gboolean found = tdef->base && mono_binary_search (&loc, tdef->base, table_info_get_rows (tdef), tdef->row_size, table_locator) != NULL;
-	if (!found && !meta->has_updates)
-		return 0;
-	if (G_UNLIKELY (meta->has_updates)) {
-		if (!found) {
-			uint32_t count;
-			if (metadata_update_get_typedef_skeleton_events (meta, mono_metadata_make_token (MONO_TABLE_TYPEDEF, index + 1), &start, &count)) {
-				*end_idx = start + count - 1;
-				return start - 1;
-			} else {
-				return 0;
-			}
-		}
-	}
-	start = mono_metadata_decode_row_col (tdef, loc.result, MONO_EVENT_MAP_EVENTLIST);
-	/*
-	 * metadata-update: note this next line needs block needs to look at the number of rows in
-	 * EventMap and Event of the base image.  Updates will add rows for new properties,
-	 * but they won't be contiguous.  if we set end to the number of rows in the updated
-	 * Property table, the range will include properties from some other class
-	 */
-	if (loc.result + 1 < table_info_get_rows (tdef)) {
-		end = mono_metadata_decode_row_col (tdef, loc.result + 1, MONO_EVENT_MAP_EVENTLIST) - 1;
-	} else {
-		end = table_info_get_rows (&meta->tables [MONO_TABLE_EVENT]);
-	}
-	*end_idx = end;
-	return start - 1;
-}
-/**
- * mono_metadata_methods_from_event:
- * \param meta metadata context
- * \param index 0-based index (in the \c Event table) describing a event
- * \returns the 0-based index in the \c MethodDef table for the methods in the
- * event. The last method that belongs to the event (plus 1) is stored
- * in the \p end_idx pointer.
- */
-guint32
-mono_metadata_methods_from_event   (MonoImage *meta, guint32 index, guint *end_idx)
-{
-	mono_locator_t loc;
-	guint32 start, end;
-	guint32 cols [MONO_METHOD_SEMA_SIZE];
-	MonoTableInfo *msemt = &meta->tables [MONO_TABLE_METHODSEMANTICS];
-	*end_idx = 0;
-	if (!msemt->base && !meta->has_updates)
-		return 0;
-	if (meta->uncompressed_metadata)
-	    index = search_ptr_table (meta, MONO_TABLE_EVENT_POINTER, index + 1) - 1;
-	loc = mono_locator_init (
-		msemt,
-		/* Method association coded index */
-		((index + 1) << MONO_HAS_SEMANTICS_BITS) | MONO_HAS_SEMANTICS_EVENT,
-		MONO_METHOD_SEMA_ASSOCIATION
-	);
-	gboolean found = msemt->base && mono_binary_search (&loc, msemt->base, table_info_get_rows (msemt), msemt->row_size, table_locator) != NULL;
-	if (!found && !meta->has_updates)
-		return 0;
-	if (G_UNLIKELY (meta->has_updates)) {
-		if (!found && !mono_metadata_update_metadata_linear_search (meta, msemt, &loc, table_locator))
-			return 0;
-	}
-	start = loc.result;
-	/*
-	 * We may end up in the middle of the rows...
-	 */
-	while (start > 0) {
-		if (loc.idx == mono_metadata_decode_row_col (msemt, start - 1, MONO_METHOD_SEMA_ASSOCIATION))
-			start--;
-		else
-			break;
-	}
-	end = start + 1;
-	guint32 rows = mono_metadata_table_num_rows (meta, MONO_TABLE_METHODSEMANTICS);
-	while (end < rows) {
-		mono_metadata_decode_row (msemt, end, cols, MONO_METHOD_SEMA_SIZE);
-		if (cols [MONO_METHOD_SEMA_ASSOCIATION] != loc.idx)
-			break;
-		++end;
-	}
-	*end_idx = GUINT32_TO_UINT(end);
-	return start;
-}
-/**
- * mono_metadata_properties_from_typedef:
- * \param meta metadata context
- * \param index 0-based index (in the \c TypeDef table) describing a type
- * \returns the 0-based index in the \c Property table for the properties in the
- * type. The last property that belongs to the type (plus 1) is stored
- * in the \p end_idx pointer.
- */
-guint32
-mono_metadata_properties_from_typedef (MonoImage *meta, guint32 index, guint *end_idx)
-{
-	mono_locator_t loc;
-	guint32 start, end;
-	MonoTableInfo *tdef  = &meta->tables [MONO_TABLE_PROPERTYMAP];
-	*end_idx = 0;
-	if (!tdef->base && !meta->has_updates)
-		return 0;
-	loc = mono_locator_init (tdef, index + 1, MONO_PROPERTY_MAP_PARENT);
-	gboolean found = tdef->base && mono_binary_search (&loc, tdef->base, table_info_get_rows (tdef), tdef->row_size, table_locator) != NULL;
-	if (!found && !meta->has_updates)
-		return 0;
-	if (G_UNLIKELY (meta->has_updates)) {
-		if (!found) {
-			uint32_t count;
-			if (metadata_update_get_typedef_skeleton_properties (meta, mono_metadata_make_token (MONO_TABLE_TYPEDEF, index + 1), &start, &count)) {
-				*end_idx = start + count - 1;
-				return start - 1;
-			} else {
-				return 0;
-			}
-		}
-	}
-	start = mono_metadata_decode_row_col (tdef, loc.result, MONO_PROPERTY_MAP_PROPERTY_LIST);
-	/*
-	 * metadata-update: note this next line needs block needs to look at the number of rows in
-	 * PropertyMap and Property of the base image.  Updates will add rows for new properties,
-	 * but they won't be contiguous.  if we set end to the number of rows in the updated
-	 * Property table, the range will include properties from some other class
-	 */
-	if (loc.result + 1 < table_info_get_rows (&meta->tables [MONO_TABLE_PROPERTYMAP])) {
-		end = mono_metadata_decode_row_col (tdef, loc.result + 1, MONO_PROPERTY_MAP_PROPERTY_LIST) - 1;
-	} else {
-		end = table_info_get_rows (&meta->tables [MONO_TABLE_PROPERTY]);
-	}
-	*end_idx = GUINT32_TO_UINT(end);
-	return start - 1;
-}
-/**
- * mono_metadata_methods_from_property:
- * \param meta metadata context
- * \param index 0-based index (in the \c PropertyDef table) describing a property
- * \returns the 0-based index in the \c MethodDef table for the methods in the
- * property. The last method that belongs to the property (plus 1) is stored
- * in the \p end_idx pointer.
- */
-guint32
-mono_metadata_methods_from_property   (MonoImage *meta, guint32 index, guint *end_idx)
-{
-	mono_locator_t loc;
-	guint32 start, end;
-	guint32 cols [MONO_METHOD_SEMA_SIZE];
-	MonoTableInfo *msemt = &meta->tables [MONO_TABLE_METHODSEMANTICS];
-	*end_idx = 0;
-	if (!msemt->base && !meta->has_updates)
-		return 0;
-	if (meta->uncompressed_metadata)
-	    index = search_ptr_table (meta, MONO_TABLE_PROPERTY_POINTER, index + 1) - 1;
-	loc = mono_locator_init (
-		msemt,
-		/* Method association coded index */
-		((index + 1) << MONO_HAS_SEMANTICS_BITS) | MONO_HAS_SEMANTICS_PROPERTY,
-		MONO_METHOD_SEMA_ASSOCIATION
-	);
-	gboolean found = msemt->base && mono_binary_search (&loc, msemt->base, table_info_get_rows (msemt), msemt->row_size, table_locator) != NULL;
-	if (!found && !meta->has_updates)
-		return 0;
-	if (G_UNLIKELY (meta->has_updates)) {
-		if (!found && !mono_metadata_update_metadata_linear_search (meta, msemt, &loc, table_locator))
-			return 0;
-	}
-	start = loc.result;
-	/*
-	 * We may end up in the middle of the rows...
-	 */
-	while (start > 0) {
-		if (loc.idx == mono_metadata_decode_row_col (msemt, start - 1, MONO_METHOD_SEMA_ASSOCIATION))
-			start--;
-		else
-			break;
-	}
-	end = start + 1;
-	guint32 rows = mono_metadata_table_num_rows (meta, MONO_TABLE_METHODSEMANTICS);
-	while (end < rows) {
-		mono_metadata_decode_row (msemt, end, cols, MONO_METHOD_SEMA_SIZE);
-		if (cols [MONO_METHOD_SEMA_ASSOCIATION] != loc.idx)
-			break;
-		++end;
-	}
-	*end_idx = GUINT32_TO_UINT(end);
-	return start;
-}
-/**
- * mono_metadata_implmap_from_method:
- */
-guint32
-mono_metadata_implmap_from_method (MonoImage *meta, guint32 method_idx)
-{
-	mono_locator_t loc;
-	MonoTableInfo *tdef  = &meta->tables [MONO_TABLE_IMPLMAP];
-	if (!tdef->base)
-		return 0;
-	/* No index translation seems to be needed */
-	loc = mono_locator_init (tdef, ((method_idx + 1) << MONO_MEMBERFORWD_BITS) | MONO_MEMBERFORWD_METHODDEF, MONO_IMPLMAP_MEMBER);
-	/* FIXME: metadata-update */
-	if (!mono_binary_search (&loc, tdef->base, table_info_get_rows (tdef), tdef->row_size, table_locator))
-		return 0;
-	return loc.result + 1;
-}
-/**
- * mono_type_create_from_typespec:
- * \param image context where the image is created
- * \param type_spec  typespec token
- * \deprecated use \c mono_type_create_from_typespec_checked that has proper error handling
- *
- * Creates a \c MonoType representing the \c TypeSpec indexed by the \p type_spec
- * token.
- */
-MonoType *
-mono_type_create_from_typespec (MonoImage *image, guint32 type_spec)
-{
-	ERROR_DECL (error);
-	MonoType *type = mono_type_create_from_typespec_checked (image, type_spec, error);
-	if (!type)
-		 g_error ("Could not create typespec %x due to %s", type_spec, mono_error_get_message (error));
-	return type;
-}
-MonoType *
-mono_type_create_from_typespec_checked (MonoImage *image, guint32 type_spec, MonoError *error)
-{
-	guint32 idx = mono_metadata_token_index (type_spec);
-	MonoTableInfo *t;
-	guint32 cols [MONO_TYPESPEC_SIZE];
-	const char *ptr;
-	MonoType *type, *type2;
-	error_init (error);
-	type = (MonoType *)mono_conc_hashtable_lookup (image->typespec_cache, GUINT_TO_POINTER (type_spec));
-	if (type)
-		return type;
-	t = &image->tables [MONO_TABLE_TYPESPEC];
-	mono_metadata_decode_row (t, idx-1, cols, MONO_TYPESPEC_SIZE);
-	ptr = mono_metadata_blob_heap (image, cols [MONO_TYPESPEC_SIGNATURE]);
-	mono_metadata_decode_value (ptr, &ptr);
-	type = mono_metadata_parse_type_checked (image, NULL, 0, TRUE, ptr, &ptr, error);
-	if (!type)
-		return NULL;
-	type2 = mono_metadata_type_dup (image, type);
-	mono_metadata_free_type (type);
-	mono_image_lock (image);
-	/* We might leak some data in the image mempool if found */
-	type = (MonoType*)mono_conc_hashtable_insert (image->typespec_cache, GUINT_TO_POINTER (type_spec), type2);
-	if (!type)
-		type = type2;
-	mono_image_unlock (image);
-	return type;
-}
-static char*
-mono_image_strndup (MonoImage *image, const char *data, guint len)
-{
-	char *res;
-	if (!image)
-		return g_strndup (data, len);
-	res = (char *)mono_image_alloc (image, len + 1);
-	memcpy (res, data, len);
-	res [len] = 0;
-	return res;
-}
-/**
- * mono_metadata_parse_marshal_spec:
- */
-MonoMarshalSpec *
-mono_metadata_parse_marshal_spec (MonoImage *image, const char *ptr)
-{
-	return mono_metadata_parse_marshal_spec_full (NULL, image, ptr);
-}
-/*
- * If IMAGE is non-null, memory will be allocated from its mempool, otherwise it will be allocated using malloc.
- * PARENT_IMAGE is the image containing the marshal spec.
- */
-MonoMarshalSpec *
-mono_metadata_parse_marshal_spec_full (MonoImage *image, MonoImage *parent_image, const char *ptr)
-{
-	MonoMarshalSpec *res;
-	int len;
-	const char *start = ptr;
-	/* fixme: this is incomplete, but I cant find more infos in the specs */
-	if (image)
-		res = (MonoMarshalSpec *)mono_image_alloc0 (image, sizeof (MonoMarshalSpec));
-	else
-		res = g_new0 (MonoMarshalSpec, 1);
-	len = mono_metadata_decode_value (ptr, &ptr);
-	res->native = (MonoMarshalNative)*ptr++;
-	if (res->native == MONO_NATIVE_LPARRAY) {
-		res->data.array_data.param_num = -1;
-		res->data.array_data.num_elem = -1;
-		res->data.array_data.elem_mult = -1;
-		if (ptr - start <= len)
-			res->data.array_data.elem_type = (MonoMarshalNative)*ptr++;
-		if (ptr - start <= len)
-			res->data.array_data.param_num = GUINT32_TO_INT16 (mono_metadata_decode_value (ptr, &ptr));
-		if (ptr - start <= len)
-			res->data.array_data.num_elem = mono_metadata_decode_value (ptr, &ptr);
-		if (ptr - start <= len) {
-			/*
-			 * LAMESPEC: Older spec versions say this parameter comes before
-			 * num_elem. Never spec versions don't talk about elem_mult at
-			 * all, but csc still emits it, and it is used to distinguish
-			 * between param_num being 0, and param_num being omitted.
-			 * So if (param_num == 0) && (num_elem > 0), then
-			 * elem_mult == 0 -> the array size is num_elem
-			 * elem_mult == 1 -> the array size is @param_num + num_elem
-			 */
-			res->data.array_data.elem_mult = GUINT32_TO_INT16 (mono_metadata_decode_value (ptr, &ptr));
-		}
-	}
-	if (res->native == MONO_NATIVE_BYVALTSTR) {
-		if (ptr - start <= len)
-			res->data.array_data.num_elem = mono_metadata_decode_value (ptr, &ptr);
-	}
-	if (res->native == MONO_NATIVE_BYVALARRAY) {
-		if (ptr - start <= len)
-			res->data.array_data.num_elem = mono_metadata_decode_value (ptr, &ptr);
-	}
-	if (res->native == MONO_NATIVE_CUSTOM) {
-		/* skip unused type guid */
-		len = mono_metadata_decode_value (ptr, &ptr);
-		ptr += len;
-		/* skip unused native type name */
-		len = mono_metadata_decode_value (ptr, &ptr);
-		ptr += len;
-		/* read custom marshaler type name */
-		len = mono_metadata_decode_value (ptr, &ptr);
-		res->data.custom_data.custom_name = mono_image_strndup (image, ptr, len);
-		ptr += len;
-		/* read cookie string */
-		len = mono_metadata_decode_value (ptr, &ptr);
-		res->data.custom_data.cookie = mono_image_strndup (image, ptr, len);
-		res->data.custom_data.image = parent_image;
-	}
-	if (res->native == MONO_NATIVE_SAFEARRAY) {
-		res->data.safearray_data.elem_type = (MonoMarshalVariant)0;
-		res->data.safearray_data.num_elem = 0;
-		if (ptr - start <= len)
-			res->data.safearray_data.elem_type = (MonoMarshalVariant)*ptr++;
-		if (ptr - start <= len)
-			res->data.safearray_data.num_elem = *ptr++;
-	}
-	return res;
-}
-/**
- * mono_metadata_free_marshal_spec:
- */
-void
-mono_metadata_free_marshal_spec (MonoMarshalSpec *spec)
-{
-	if (!spec)
-		return;
-	if (spec->native == MONO_NATIVE_CUSTOM) {
-		g_free (spec->data.custom_data.custom_name);
-		g_free (spec->data.custom_data.cookie);
-	}
-	g_free (spec);
-}
-/**
- * mono_type_to_unmanaged:
- * The value pointed to by \p conv will contain the kind of marshalling required for this
- * particular type one of the \c MONO_MARSHAL_CONV_ enumeration values.
- * \returns A \c MonoMarshalNative enumeration value (<code>MONO_NATIVE_</code>) value
- * describing the underlying native reprensetation of the type.
- */
-guint32 // FIXMEcxx MonoMarshalNative
-mono_type_to_unmanaged (MonoType *type, MonoMarshalSpec *mspec, gboolean as_field,
-			gboolean unicode, MonoMarshalConv *conv)
-{
-	MonoMarshalConv dummy_conv;
-	int t = type->type;
-	if (!conv)
-		conv = &dummy_conv;
-	*conv = MONO_MARSHAL_CONV_NONE;
-	if (m_type_is_byref (type))
-		return MONO_NATIVE_UINT;
-handle_enum:
-	switch (t) {
-	case MONO_TYPE_BOOLEAN:
-		if (mspec) {
-			switch (mspec->native) {
-			case MONO_NATIVE_VARIANTBOOL:
-				*conv = MONO_MARSHAL_CONV_BOOL_VARIANTBOOL;
-				return MONO_NATIVE_VARIANTBOOL;
-			case MONO_NATIVE_BOOLEAN:
-				*conv = MONO_MARSHAL_CONV_BOOL_I4;
-				return MONO_NATIVE_BOOLEAN;
-			case MONO_NATIVE_I1:
-			case MONO_NATIVE_U1:
-				return mspec->native;
-			default:
-				g_error ("cant marshal bool to native type %02x", mspec->native);
-			}
-		}
-		*conv = MONO_MARSHAL_CONV_BOOL_I4;
-		return MONO_NATIVE_BOOLEAN;
-	case MONO_TYPE_CHAR:
-		if (mspec) {
-			switch (mspec->native) {
-			case MONO_NATIVE_U2:
-			case MONO_NATIVE_U1:
-				return mspec->native;
-			default:
-				g_error ("cant marshal char to native type %02x", mspec->native);
-			}
-		}
-		return unicode ? MONO_NATIVE_U2 : MONO_NATIVE_U1;
-	case MONO_TYPE_I1: return MONO_NATIVE_I1;
-	case MONO_TYPE_U1: return MONO_NATIVE_U1;
-	case MONO_TYPE_I2: return MONO_NATIVE_I2;
-	case MONO_TYPE_U2: return MONO_NATIVE_U2;
-	case MONO_TYPE_I4: return MONO_NATIVE_I4;
-	case MONO_TYPE_U4: return MONO_NATIVE_U4;
-	case MONO_TYPE_I8: return MONO_NATIVE_I8;
-	case MONO_TYPE_U8: return MONO_NATIVE_U8;
-	case MONO_TYPE_R4: return MONO_NATIVE_R4;
-	case MONO_TYPE_R8: return MONO_NATIVE_R8;
-	case MONO_TYPE_STRING:
-		if (mspec) {
-			switch (mspec->native) {
-			case MONO_NATIVE_BSTR:
-				*conv = MONO_MARSHAL_CONV_STR_BSTR;
-				return MONO_NATIVE_BSTR;
-			case MONO_NATIVE_LPSTR:
-				*conv = MONO_MARSHAL_CONV_STR_LPSTR;
-				return MONO_NATIVE_LPSTR;
-			case MONO_NATIVE_LPWSTR:
-				*conv = MONO_MARSHAL_CONV_STR_LPWSTR;
-				return MONO_NATIVE_LPWSTR;
-			case MONO_NATIVE_LPTSTR:
-				*conv = MONO_MARSHAL_CONV_STR_LPTSTR;
-				return MONO_NATIVE_LPTSTR;
-			case MONO_NATIVE_ANSIBSTR:
-				*conv = MONO_MARSHAL_CONV_STR_ANSIBSTR;
-				return MONO_NATIVE_ANSIBSTR;
-			case MONO_NATIVE_TBSTR:
-				*conv = MONO_MARSHAL_CONV_STR_TBSTR;
-				return MONO_NATIVE_TBSTR;
-			case MONO_NATIVE_UTF8STR:
-				*conv = MONO_MARSHAL_CONV_STR_UTF8STR;
-				return MONO_NATIVE_UTF8STR;
-			case MONO_NATIVE_BYVALTSTR:
-				if (unicode)
-					*conv = MONO_MARSHAL_CONV_STR_BYVALWSTR;
-				else
-					*conv = MONO_MARSHAL_CONV_STR_BYVALSTR;
-				return MONO_NATIVE_BYVALTSTR;
-			case MONO_NATIVE_CUSTOM:
-				return MONO_NATIVE_CUSTOM;
-			default:
-				g_error ("Can not marshal string to native type '%02x': Invalid managed/unmanaged type combination (String fields must be paired with LPStr, LPWStr, BStr or ByValTStr).", mspec->native);
-			}
-		}
-		if (unicode) {
-			*conv = MONO_MARSHAL_CONV_STR_LPWSTR;
-			return MONO_NATIVE_LPWSTR;
-		}
-		else {
-			*conv = MONO_MARSHAL_CONV_STR_LPSTR;
-			return MONO_NATIVE_LPSTR;
-		}
-	case MONO_TYPE_PTR: return MONO_NATIVE_UINT;
-	case MONO_TYPE_VALUETYPE: /*FIXME*/
-		if (mspec && mspec->native == MONO_NATIVE_CUSTOM)
-			return MONO_NATIVE_CUSTOM;
-		if (m_class_is_enumtype (type->data.klass)) {
-			t = mono_class_enum_basetype_internal (type->data.klass)->type;
-			goto handle_enum;
-		}
-		if (type->data.klass == mono_class_try_get_handleref_class ()){
-			*conv = MONO_MARSHAL_CONV_HANDLEREF;
-			return MONO_NATIVE_INT;
-		}
-		return MONO_NATIVE_STRUCT;
-	case MONO_TYPE_SZARRAY:
-	case MONO_TYPE_ARRAY:
-		if (mspec) {
-			switch (mspec->native) {
-			case MONO_NATIVE_BYVALARRAY:
-				if ((m_class_get_element_class (type->data.klass) == mono_defaults.char_class) && !unicode)
-					*conv = MONO_MARSHAL_CONV_ARRAY_BYVALCHARARRAY;
-				else
-					*conv = MONO_MARSHAL_CONV_ARRAY_BYVALARRAY;
-				return MONO_NATIVE_BYVALARRAY;
-			case MONO_NATIVE_SAFEARRAY:
-				*conv = MONO_MARSHAL_CONV_ARRAY_SAVEARRAY;
-				return MONO_NATIVE_SAFEARRAY;
-			case MONO_NATIVE_LPARRAY:
-				*conv = MONO_MARSHAL_CONV_ARRAY_LPARRAY;
-				return MONO_NATIVE_LPARRAY;
-			case MONO_NATIVE_CUSTOM:
-				return MONO_NATIVE_CUSTOM;
-			default:
-				g_error ("cant marshal array as native type %02x", mspec->native);
-			}
-		}
-		*conv = MONO_MARSHAL_CONV_ARRAY_LPARRAY;
-		return MONO_NATIVE_LPARRAY;
-	case MONO_TYPE_I: return MONO_NATIVE_INT;
-	case MONO_TYPE_U: return MONO_NATIVE_UINT;
-	case MONO_TYPE_CLASS:
-	case MONO_TYPE_OBJECT: {
-		/* FIXME : we need to handle ArrayList and StringBuilder here, probably */
-		if (mspec) {
-			switch (mspec->native) {
-			case MONO_NATIVE_STRUCT:
-				if (t != MONO_TYPE_OBJECT)
-					*conv = MONO_MARSHAL_CONV_OBJECT_STRUCT;
-				return MONO_NATIVE_STRUCT;
-			case MONO_NATIVE_CUSTOM:
-				return MONO_NATIVE_CUSTOM;
-			case MONO_NATIVE_INTERFACE:
-				*conv = MONO_MARSHAL_CONV_OBJECT_INTERFACE;
-				return MONO_NATIVE_INTERFACE;
-			case MONO_NATIVE_IDISPATCH:
-				*conv = MONO_MARSHAL_CONV_OBJECT_IDISPATCH;
-				return MONO_NATIVE_IDISPATCH;
-			case MONO_NATIVE_IUNKNOWN:
-				*conv = MONO_MARSHAL_CONV_OBJECT_IUNKNOWN;
-				return MONO_NATIVE_IUNKNOWN;
-			case MONO_NATIVE_FUNC:
-				if (t == MONO_TYPE_CLASS && (type->data.klass == mono_defaults.multicastdelegate_class ||
-											 type->data.klass == mono_defaults.delegate_class ||
-							     				m_class_get_parent (type->data.klass) == mono_defaults.multicastdelegate_class)) {
-					*conv = MONO_MARSHAL_CONV_DEL_FTN;
-					return MONO_NATIVE_FUNC;
-				}
-				/* Fall through */
-			default:
-				g_error ("cant marshal object as native type %02x", mspec->native);
-			}
-		}
-		if (t == MONO_TYPE_CLASS && (type->data.klass == mono_defaults.multicastdelegate_class ||
-					     type->data.klass == mono_defaults.delegate_class ||
-					     m_class_get_parent (type->data.klass) == mono_defaults.multicastdelegate_class)) {
-			*conv = MONO_MARSHAL_CONV_DEL_FTN;
-			return MONO_NATIVE_FUNC;
-		}
-		if (mono_class_try_get_safehandle_class () && type->data.klass != NULL &&
-			mono_class_is_subclass_of_internal (type->data.klass,  mono_class_try_get_safehandle_class (), FALSE)){
-			*conv = MONO_MARSHAL_CONV_SAFEHANDLE;
-			return MONO_NATIVE_INT;
-		}
-		*conv = MONO_MARSHAL_CONV_OBJECT_STRUCT;
-		return MONO_NATIVE_STRUCT;
-	}
-	case MONO_TYPE_FNPTR: return MONO_NATIVE_FUNC;
-	case MONO_TYPE_GENERICINST:
-		type = m_class_get_byval_arg (type->data.generic_class->container_class);
-		t = type->type;
-		goto handle_enum;
-	case MONO_TYPE_TYPEDBYREF:
-	default:
-		g_error ("type 0x%02x not handled in marshal", t);
-	}
-	return MONO_NATIVE_MAX;
-}
-/**
- * mono_metadata_get_marshal_info:
- */
-const char*
-mono_metadata_get_marshal_info (MonoImage *meta, guint32 idx, gboolean is_field)
-{
-	mono_locator_t loc;
-	MonoTableInfo *tdef  = &meta->tables [MONO_TABLE_FIELDMARSHAL];
-	loc = mono_locator_init (
-		tdef,
-		((idx + 1) << MONO_HAS_FIELD_MARSHAL_BITS) | (is_field? MONO_HAS_FIELD_MARSHAL_FIELDSREF: MONO_HAS_FIELD_MARSHAL_PARAMDEF),
-		MONO_FIELD_MARSHAL_PARENT
-	);
-	/* FIXME: Index translation */
-	gboolean found = tdef->base && mono_binary_search (&loc, tdef->base, table_info_get_rows (tdef), tdef->row_size, table_locator);
-	if (G_UNLIKELY (meta->has_updates)) {
-		if (!found && !mono_metadata_update_metadata_linear_search (meta, tdef, &loc, table_locator))
-			return NULL;
-	}
-	return mono_metadata_blob_heap (meta, mono_metadata_decode_row_col (tdef, loc.result, MONO_FIELD_MARSHAL_NATIVE_TYPE));
-}
-MonoMethod*
-mono_method_from_method_def_or_ref (MonoImage *m, guint32 tok, MonoGenericContext *context, MonoError *error)
-{
-	MonoMethod *result = NULL;
-	guint32 idx = tok >> MONO_METHODDEFORREF_BITS;
-	error_init (error);
-	switch (tok & MONO_METHODDEFORREF_MASK) {
-	case MONO_METHODDEFORREF_METHODDEF:
-		result = mono_get_method_checked (m, MONO_TOKEN_METHOD_DEF | idx, NULL, context, error);
-		break;
-	case MONO_METHODDEFORREF_METHODREF:
-		result = mono_get_method_checked (m, MONO_TOKEN_MEMBER_REF | idx, NULL, context, error);
-		break;
-	default:
-		mono_error_set_bad_image (error, m, "Invalid MethodDefOfRef token %x", tok);
-	}
-	return result;
-}
-/*
- * mono_class_get_overrides_full:
- *
- *  Compute the method overrides belonging to class @type_token in @overrides, and the number of overrides in @num_overrides.
- *
- */
-void
-mono_class_get_overrides_full (MonoImage *image, guint32 type_token, MonoMethod ***overrides, gint32 *num_overrides, MonoGenericContext *generic_context, MonoError *error)
-{
-	mono_locator_t loc;
-	MonoTableInfo *tdef  = &image->tables [MONO_TABLE_METHODIMPL];
-	guint32 start, end;
-	gint32 i, num;
-	guint32 cols [MONO_METHODIMPL_SIZE];
-	MonoMethod **result;
-	error_init (error);
-	*overrides = NULL;
-	if (num_overrides)
-		*num_overrides = 0;
-	if (!tdef->base && !image->has_updates)
-		return;
-	loc = mono_locator_init (tdef, mono_metadata_token_index (type_token), MONO_METHODIMPL_CLASS);
-	gboolean found = tdef->base && mono_binary_search (&loc, tdef->base, table_info_get_rows (tdef), tdef->row_size, table_locator) != NULL;
-	if (!found && !image->has_updates)
-		return;
-	if (G_UNLIKELY (image->has_updates))  {
-		if (!found && !mono_metadata_update_metadata_linear_search (image, tdef, &loc, table_locator)) {
-			mono_trace (G_LOG_LEVEL_INFO, MONO_TRACE_METADATA_UPDATE, "NO Found interfaces for class 0x%08x", type_token);
-			return;
-		}
-		mono_trace (G_LOG_LEVEL_INFO, MONO_TRACE_METADATA_UPDATE, "Found interfaces for class 0x%08x starting at 0x%08x", type_token, loc.result);
-	}
-	start = loc.result;
-	end = start + 1;
-	/*
-	 * We may end up in the middle of the rows...
-	 */
-	while (start > 0) {
-		if (loc.idx == mono_metadata_decode_row_col (tdef, start - 1, MONO_METHODIMPL_CLASS))
-			start--;
-		else
-			break;
-	}
-	guint32 rows = mono_metadata_table_num_rows (image, MONO_TABLE_METHODIMPL);
-	while (end < rows) {
-		if (loc.idx == mono_metadata_decode_row_col (tdef, end, MONO_METHODIMPL_CLASS))
-			end++;
-		else
-			break;
-	}
-	num = end - start;
-	result = g_new (MonoMethod*, num * 2);
-	for (i = 0; i < num; ++i) {
-		MonoMethod *method;
-		mono_metadata_decode_row (tdef, start + i, cols, MONO_METHODIMPL_SIZE);
-		method = mono_method_from_method_def_or_ref (image, cols [MONO_METHODIMPL_DECLARATION], generic_context, error);
-		if (!method)
-			break;
-		result [i * 2] = method;
-		method = mono_method_from_method_def_or_ref (image, cols [MONO_METHODIMPL_BODY], generic_context, error);
-		if (!method)
-			break;
-		result [i * 2 + 1] = method;
-	}
-	if (!is_ok (error)) {
-		g_free (result);
-		*overrides = NULL;
-		if (num_overrides)
-			*num_overrides = 0;
-	} else {
-		*overrides = result;
-		if (num_overrides)
-			*num_overrides = num;
-	}
-}
-/**
- * mono_guid_to_string:
- *
- * Converts a 16 byte Microsoft GUID to the standard string representation.
- */
-char *
-mono_guid_to_string (const guint8 *guid)
-{
-	return g_strdup_printf ("%02X%02X%02X%02X-%02X%02X-%02X%02X-%02X%02X-%02X%02X%02X%02X%02X%02X",
-				guid[3], guid[2], guid[1], guid[0],
-				guid[5], guid[4],
-				guid[7], guid[6],
-				guid[8], guid[9],
-				guid[10], guid[11], guid[12], guid[13], guid[14], guid[15]);
-}
-/**
- * mono_guid_to_string_minimal:
- *
- * Converts a 16 byte Microsoft GUID to lower case no '-' representation..
- */
-char *
-mono_guid_to_string_minimal (const guint8 *guid)
-{
-	return g_strdup_printf ("%02x%02x%02x%02x%02x%02x%02x%02x%02x%02x%02x%02x%02x%02x%02x%02x",
-				guid[3], guid[2], guid[1], guid[0],
-				guid[5], guid[4],
-				guid[7], guid[6],
-				guid[8], guid[9],
-				guid[10], guid[11], guid[12], guid[13], guid[14], guid[15]);
-}
-static gboolean
-get_constraints (MonoImage *image, int owner, MonoClass ***constraints, MonoGenericContainer *container, MonoError *error)
-{
-	MonoTableInfo *tdef  = &image->tables [MONO_TABLE_GENERICPARAMCONSTRAINT];
-	guint32 cols [MONO_GENPARCONSTRAINT_SIZE];
-	mono_locator_t loc;
-	guint32 i, token, found, start;
-	MonoClass *klass, **res;
-	GSList *cons = NULL, *tmp;
-	MonoGenericContext *context = &container->context;
-	error_init (error);
-	*constraints = NULL;
-	found = 0;
-	/* FIXME: metadata-update */
-	guint32 rows = table_info_get_rows (tdef);
-	loc = mono_locator_init (tdef, owner, MONO_GENPARCONSTRAINT_GENERICPAR);
-	gboolean is_found = tdef->base && mono_binary_search (&loc, tdef->base, table_info_get_rows (tdef), tdef->row_size, table_locator) != NULL;
-	if (!is_found && !image->has_updates)
-		return TRUE;
-	if (is_found) {
-		/* Find the first entry by searching backwards */
-		while ((loc.result > 0) && (mono_metadata_decode_row_col (tdef, loc.result - 1, MONO_GENPARCONSTRAINT_GENERICPAR) == owner))
-			loc.result --;
-		start = loc.result;
-	} else {
-		start = 0;
-	}
-	for (i = start; i < rows; ++i) {
-		mono_metadata_decode_row (tdef, i, cols, MONO_GENPARCONSTRAINT_SIZE);
-		if (cols [MONO_GENPARCONSTRAINT_GENERICPAR] == owner) {
-			token = mono_metadata_token_from_dor (cols [MONO_GENPARCONSTRAINT_CONSTRAINT]);
-			klass = mono_class_get_and_inflate_typespec_checked (image, token, context, error);
-			if (!klass) {
-				g_slist_free (cons);
-				return FALSE;
-			}
-			cons = g_slist_append (cons, klass);
-			++found;
-		} else {
-			/* contiguous list finished */
-			if (found)
-				break;
-		}
-	}
-	if (!found)
-		return TRUE;
-	res = (MonoClass **)mono_image_alloc0 (image, sizeof (MonoClass*) * (found + 1));
-	for (i = 0, tmp = cons; i < found; ++i, tmp = tmp->next) {
-		res [i] = (MonoClass *)tmp->data;
-	}
-	g_slist_free (cons);
-	*constraints = res;
-	return TRUE;
-}
-/*
- * mono_metadata_get_generic_param_row:
- *
- * @image:
- * @token: TypeOrMethodDef token, owner for GenericParam
- * @owner: coded token, set on return
- *
- * Returns: 1-based row-id in the GenericParam table whose
- * owner is @token. 0 if not found.
- */
-guint32
-mono_metadata_get_generic_param_row (MonoImage *image, guint32 token, guint32 *owner)
-{
-	MonoTableInfo *tdef  = &image->tables [MONO_TABLE_GENERICPARAM];
-	mono_locator_t loc;
-	g_assert (owner);
-	if (!tdef->base && !image->has_updates)
-		return 0;
-	if (mono_metadata_token_table (token) == MONO_TABLE_TYPEDEF)
-		*owner = MONO_TYPEORMETHOD_TYPE;
-	else if (mono_metadata_token_table (token) == MONO_TABLE_METHOD)
-		*owner = MONO_TYPEORMETHOD_METHOD;
-	else {
-		g_error ("wrong token %x to get_generic_param_row", token);
-		return 0;
-	}
-	*owner |= mono_metadata_token_index (token) << MONO_TYPEORMETHOD_BITS;
-	loc = mono_locator_init (tdef, *owner, MONO_GENERICPARAM_OWNER);
-	gboolean found = tdef->base && mono_binary_search (&loc, tdef->base, table_info_get_rows (tdef), tdef->row_size, table_locator) != NULL;
-	if (!found && !image->has_updates)
-		return 0;
-	if (G_UNLIKELY (image->has_updates)) {
-		if (!found && !mono_metadata_update_metadata_linear_search (image, tdef, &loc, table_locator))
-			return 0;
-	}
-	/* Find the first entry by searching backwards */
-	while ((loc.result > 0) && (mono_metadata_decode_row_col (tdef, loc.result - 1, MONO_GENERICPARAM_OWNER) == loc.idx))
-		loc.result --;
-	return loc.result + 1;
-}
-gboolean
-mono_metadata_has_generic_params (MonoImage *image, guint32 token)
-{
-	guint32 owner;
-	return mono_metadata_get_generic_param_row (image, token, &owner);
-}
-/*
- * Memory is allocated from IMAGE's mempool.
- */
-gboolean
-mono_metadata_load_generic_param_constraints_checked (MonoImage *image, guint32 token,
-					      MonoGenericContainer *container, MonoError *error)
-{
-	guint32 start_row, owner;
-	error_init (error);
-	if (! (start_row = mono_metadata_get_generic_param_row (image, token, &owner)))
-		return TRUE;
-	for (int i = 0; i < container->type_argc; i++) {
-		if (!get_constraints (image, start_row + i, &mono_generic_container_get_param_info (container, i)->constraints, container, error)) {
-			return FALSE;
-		}
-	}
-	return TRUE;
-}
-/*
- * mono_metadata_load_generic_params:
- *
- * Load the type parameters from the type or method definition @token.
- *
- * Use this method after parsing a type or method definition to figure out whether it's a generic
- * type / method.  When parsing a method definition, @parent_container points to the generic container
- * of the current class, if any.
- *
- * Note: This method does not load the constraints: for typedefs, this has to be done after fully
- *       creating the type.
- *
- * Returns: NULL if @token is not a generic type or method definition or the new generic container.
- *
- * LOCKING: Acquires the loader lock
- *
- */
-MonoGenericContainer *
-mono_metadata_load_generic_params (MonoImage *image, guint32 token, MonoGenericContainer *parent_container, gpointer real_owner)
-{
-	MonoTableInfo *tdef  = &image->tables [MONO_TABLE_GENERICPARAM];
-	guint32 cols [MONO_GENERICPARAM_SIZE];
-	guint32 owner = 0, i;
-	MonoGenericContainer *container;
-	MonoGenericParamFull *params;
-	MonoGenericContext *context;
-	gboolean is_method = mono_metadata_token_table (token) == MONO_TABLE_METHOD;
-	gboolean is_anonymous = real_owner == NULL;
-	if (!(i = mono_metadata_get_generic_param_row (image, token, &owner)))
-		return NULL;
-	mono_metadata_decode_row (tdef, i - 1, cols, MONO_GENERICPARAM_SIZE);
-	params = NULL;
-	container = (MonoGenericContainer *)mono_image_alloc0 (image, sizeof (MonoGenericContainer));
-	container->is_anonymous = is_anonymous;
-	if (is_anonymous) {
-		container->owner.image = image;
-	} else {
-		if (is_method)
-			container->owner.method = (MonoMethod*)real_owner;
-		else
-			container->owner.klass = (MonoClass*)real_owner;
-	}
-	/* first pass over the gparam table - just count how many params we own */
-	guint32 type_argc = 0;
-	guint32 i2 = i;
-	do {
-		type_argc++;
-		if (++i2 > mono_metadata_table_num_rows (image, MONO_TABLE_GENERICPARAM))
-			break;
-		mono_metadata_decode_row (tdef, i2 - 1, cols, MONO_GENERICPARAM_SIZE);
-	} while (cols [MONO_GENERICPARAM_OWNER] == owner);
-	params = (MonoGenericParamFull *)mono_image_alloc0 (image, sizeof (MonoGenericParamFull) * type_argc);
-	/* second pass, fill in the gparam data */
-	guint32 n = 0;
-	mono_metadata_decode_row (tdef, i - 1, cols, MONO_GENERICPARAM_SIZE);
-	do {
-		n++;
-		params [n - 1].owner = container;
-		params [n - 1].num = GUINT32_TO_UINT16 (cols [MONO_GENERICPARAM_NUMBER]);
-		params [n - 1].info.token = i | MONO_TOKEN_GENERIC_PARAM;
-		params [n - 1].info.flags = GUINT32_TO_UINT16 (cols [MONO_GENERICPARAM_FLAGS]);
-		params [n - 1].info.name = mono_metadata_string_heap (image, cols [MONO_GENERICPARAM_NAME]);
-		if (params [n - 1].num != n - 1)
-			g_warning ("GenericParam table unsorted or hole in generic param sequence: token %d", i);
-		if (++i > mono_metadata_table_num_rows (image, MONO_TABLE_GENERICPARAM))
-			break;
-		mono_metadata_decode_row (tdef, i - 1, cols, MONO_GENERICPARAM_SIZE);
-	} while (cols [MONO_GENERICPARAM_OWNER] == owner);
-	container->type_argc = type_argc;
-	container->type_params = params;
-	container->parent = parent_container;
-	if (is_method)
-		container->is_method = 1;
-	g_assert (container->parent == NULL || container->is_method);
-	context = &container->context;
-	if (container->is_method) {
-		context->class_inst = container->parent ? container->parent->context.class_inst : NULL;
-		context->method_inst = mono_get_shared_generic_inst (container);
-	} else {
-		context->class_inst = mono_get_shared_generic_inst (container);
-	}
-	return container;
-}
-MonoGenericInst *
-mono_get_shared_generic_inst (MonoGenericContainer *container)
-{
-	MonoType **type_argv;
-	MonoType *helper;
-	MonoGenericInst *nginst;
-	int i;
-	type_argv = g_new0 (MonoType *, container->type_argc);
-	helper = g_new0 (MonoType, container->type_argc);
-	for (i = 0; i < container->type_argc; i++) {
-		MonoType *t = &helper [i];
-		t->type = container->is_method ? MONO_TYPE_MVAR : MONO_TYPE_VAR;
-		t->data.generic_param = mono_generic_container_get_param (container, i);
-		type_argv [i] = t;
-	}
-	nginst = mono_metadata_get_generic_inst (container->type_argc, type_argv);
-	g_free (type_argv);
-	g_free (helper);
-	return nginst;
-}
-/**
- * mono_type_is_byref:
- * \param type the \c MonoType operated on
- * \returns TRUE if \p type represents a type passed by reference,
- * FALSE otherwise.
- */
-mono_bool
-mono_type_is_byref (MonoType *type)
-{
-	mono_bool result;
-	MONO_ENTER_GC_UNSAFE; // FIXME slow
-	result = m_type_is_byref (type);
-	MONO_EXIT_GC_UNSAFE;
-	return result;
-}
-/**
- * mono_type_get_type:
- * \param type the \c MonoType operated on
- * \returns the IL type value for \p type. This is one of the \c MonoTypeEnum
- * enum members like \c MONO_TYPE_I4 or \c MONO_TYPE_STRING.
- */
-int
-mono_type_get_type (MonoType *type)
-{
-	return mono_type_get_type_internal (type);
-}
-/**
- * mono_type_get_signature:
- * \param type the \c MonoType operated on
- * It is only valid to call this function if \p type is a \c MONO_TYPE_FNPTR .
- * \returns the \c MonoMethodSignature pointer that describes the signature
- * of the function pointer \p type represents.
- */
-MonoMethodSignature*
-mono_type_get_signature (MonoType *type)
-{
-	return mono_type_get_signature_internal (type);
-}
-/**
- * mono_type_get_class:
- * \param type the \c MonoType operated on
- * It is only valid to call this function if \p type is a \c MONO_TYPE_CLASS or a
- * \c MONO_TYPE_VALUETYPE . For more general functionality, use \c mono_class_from_mono_type_internal,
- * instead.
- * \returns the \c MonoClass pointer that describes the class that \p type represents.
- */
-MonoClass*
-mono_type_get_class (MonoType *type)
-{
-	/* FIXME: review the runtime users before adding the assert here */
-	return mono_type_get_class_internal (type);
-}
-/**
- * mono_type_get_array_type:
- * \param type the \c MonoType operated on
- * It is only valid to call this function if \p type is a \c MONO_TYPE_ARRAY .
- * \returns a \c MonoArrayType struct describing the array type that \p type
- * represents. The info includes details such as rank, array element type
- * and the sizes and bounds of multidimensional arrays.
- */
-MonoArrayType*
-mono_type_get_array_type (MonoType *type)
-{
-	return mono_type_get_array_type_internal (type);
-}
-/**
- * mono_type_get_ptr_type:
- * \pararm type the \c MonoType operated on
- * It is only valid to call this function if \p type is a \c MONO_TYPE_PTR .
- * \returns the \c MonoType pointer that describes the type that \p type
- * represents a pointer to.
- */
-MonoType*
-mono_type_get_ptr_type (MonoType *type)
-{
-	g_assert (type->type == MONO_TYPE_PTR);
-	return type->data.type;
-}
-/**
- * mono_type_get_modifiers:
- */
-MonoClass*
-mono_type_get_modifiers (MonoType *type, gboolean *is_required, gpointer *iter)
-{
-	/* FIXME: implement */
-	return NULL;
-}
-/**
- * mono_type_is_struct:
- * \param type the \c MonoType operated on
- * \returns TRUE if \p type is a struct, that is a \c ValueType but not an enum
- * or a basic type like \c System.Int32 . FALSE otherwise.
- */
-mono_bool
-mono_type_is_struct (MonoType *type)
-{
-	return (!m_type_is_byref (type) && ((type->type == MONO_TYPE_VALUETYPE &&
-		!m_class_is_enumtype (type->data.klass)) || (type->type == MONO_TYPE_TYPEDBYREF) ||
-		((type->type == MONO_TYPE_GENERICINST) &&
-		mono_metadata_generic_class_is_valuetype (type->data.generic_class) &&
-		!m_class_is_enumtype (type->data.generic_class->container_class))));
-}
-/**
- * mono_type_is_void:
- * \param type the \c MonoType operated on
- * \returns TRUE if \p type is \c System.Void . FALSE otherwise.
- */
-mono_bool
-mono_type_is_void (MonoType *type)
-{
-	return (type && (type->type == MONO_TYPE_VOID) && !m_type_is_byref (type));
-}
-/**
- * mono_type_is_pointer:
- * \param type the \c MonoType operated on
- * \returns TRUE if \p type is a managed or unmanaged pointer type. FALSE otherwise.
- */
-mono_bool
-mono_type_is_pointer (MonoType *type)
-{
-	return (type && ((m_type_is_byref (type) || (type->type == MONO_TYPE_I) || type->type == MONO_TYPE_STRING)
-		|| (type->type == MONO_TYPE_SZARRAY) || (type->type == MONO_TYPE_CLASS) ||
-		(type->type == MONO_TYPE_U) || (type->type == MONO_TYPE_OBJECT) ||
-		(type->type == MONO_TYPE_ARRAY) || (type->type == MONO_TYPE_PTR) ||
-		(type->type == MONO_TYPE_FNPTR)));
-}
-/**
- * mono_type_is_reference:
- * \param type the \c MonoType operated on
- * \returns TRUE if \p type represents an object reference. FALSE otherwise.
- */
-mono_bool
-mono_type_is_reference (MonoType *type)
-{
-	/* NOTE: changing this function to return TRUE more often may have
-	 * consequences for generic sharing in the AOT compiler.  In
-	 * particular, returning TRUE for generic parameters with a 'class'
-	 * constraint may cause crashes.
-	 */
-	return (type && (((type->type == MONO_TYPE_STRING) ||
-		(type->type == MONO_TYPE_SZARRAY) || (type->type == MONO_TYPE_CLASS) ||
-		(type->type == MONO_TYPE_OBJECT) || (type->type == MONO_TYPE_ARRAY)) ||
-		((type->type == MONO_TYPE_GENERICINST) &&
-		!mono_metadata_generic_class_is_valuetype (type->data.generic_class))));
-}
-mono_bool
-mono_type_is_generic_parameter (MonoType *type)
-{
-	return !m_type_is_byref (type) && (type->type == MONO_TYPE_VAR || type->type == MONO_TYPE_MVAR);
-}
-/**
- * mono_signature_get_return_type:
- * \param sig the method signature inspected
- * \returns the return type of the method signature \p sig
- */
-MonoType*
-mono_signature_get_return_type (MonoMethodSignature *sig)
-{
-	MonoType *result;
-	MONO_ENTER_GC_UNSAFE;
-	result = sig->ret;
-	MONO_EXIT_GC_UNSAFE;
-	return result;
-}
-/**
- * mono_signature_get_params:
- * \param sig the method signature inspected
- * \param iter pointer to an iterator
- * Iterates over the parameters for the method signature \p sig.
- * A \c void* pointer must be initialized to NULL to start the iteration
- * and its address is passed to this function repeteadly until it returns
- * NULL.
- * \returns the next parameter type of the method signature \p sig,
- * NULL when finished.
- */
-MonoType*
-mono_signature_get_params (MonoMethodSignature *sig, gpointer *iter)
-{
-	MonoType *result;
-	MONO_ENTER_GC_UNSAFE;
-	result = mono_signature_get_params_internal (sig, iter);
-	MONO_EXIT_GC_UNSAFE;
-	return result;
-}
-MonoType*
-mono_signature_get_params_internal (MonoMethodSignature *sig, gpointer *iter)
-{
-	MonoType** type;
-	if (!iter)
-		return NULL;
-	if (!*iter) {
-		/* start from the first */
-		if (sig->param_count) {
-			*iter = &sig->params [0];
-			return sig->params [0];
-		} else {
-			/* no method */
-			return NULL;
-		}
-	}
-	type = (MonoType **)*iter;
-	type++;
-	if (type < &sig->params [sig->param_count]) {
-		*iter = type;
-		return *type;
-	}
-	return NULL;
-}
-/**
- * mono_signature_get_param_count:
- * \param sig the method signature inspected
- * \returns the number of parameters in the method signature \p sig.
- */
-guint32
-mono_signature_get_param_count (MonoMethodSignature *sig)
-{
-	return sig->param_count;
-}
-/**
- * mono_signature_get_call_conv:
- * \param sig the method signature inspected
- * \returns the call convention of the method signature \p sig.
- */
-guint32
-mono_signature_get_call_conv (MonoMethodSignature *sig)
-{
-	return sig->call_convention;
-}
-/**
- * mono_signature_vararg_start:
- * \param sig the method signature inspected
- * \returns the number of the first vararg parameter in the
- * method signature \param sig. \c -1 if this is not a vararg signature.
- */
-int
-mono_signature_vararg_start (MonoMethodSignature *sig)
-{
-	return sig->sentinelpos;
-}
-/**
- * mono_signature_is_instance:
- * \param sig the method signature inspected
- * \returns TRUE if this the method signature \p sig has an implicit
- * first instance argument. FALSE otherwise.
- */
-gboolean
-mono_signature_is_instance (MonoMethodSignature *sig)
-{
-	return sig->hasthis;
-}
-/**
- * mono_signature_param_is_out
- * \param sig the method signature inspected
- * \param param_num the 0-based index of the inspected parameter
- * \returns TRUE if the parameter is an out parameter, FALSE
- * otherwise.
- */
-mono_bool
-mono_signature_param_is_out (MonoMethodSignature *sig, int param_num)
-{
-	g_assert (param_num >= 0 && param_num < sig->param_count);
-	return (sig->params [param_num]->attrs & PARAM_ATTRIBUTE_OUT) != 0;
-}
-/**
- * mono_signature_explicit_this:
- * \param sig the method signature inspected
- * \returns TRUE if this the method signature \p sig has an explicit
- * instance argument. FALSE otherwise.
- */
-gboolean
-mono_signature_explicit_this (MonoMethodSignature *sig)
-{
-	return sig->explicit_this;
-}
-/* for use with allocated memory blocks (assumes alignment is to 8 bytes) */
-guint
-mono_aligned_addr_hash (gconstpointer ptr)
-{
-	/* Same hashing we use for objects */
-	return (GCONSTPOINTER_TO_UINT (ptr) >> 3) * 2654435761u;
-}
-/*
- * If @field belongs to an inflated generic class, return the corresponding field of the
- * generic type definition class.
- */
-MonoClassField*
-mono_metadata_get_corresponding_field_from_generic_type_definition (MonoClassField *field)
-{
-	MonoClass *gtd;
-	ptrdiff_t offset;
-	if (!mono_class_is_ginst (m_field_get_parent (field)))
-		return field;
-	gtd = mono_class_get_generic_class (m_field_get_parent (field))->container_class;
-	if (G_LIKELY (!m_field_is_from_update (field))) {
-		offset = field - m_class_get_fields (m_field_get_parent (field));
-		return m_class_get_fields (gtd) + offset;
-	} else {
-		uint32_t token = mono_class_get_field_token (field);
-		return mono_class_get_field (gtd, token);
-	}
-}
-/*
- * If @event belongs to an inflated generic class, return the corresponding event of the
- * generic type definition class.
- */
-MonoEvent*
-mono_metadata_get_corresponding_event_from_generic_type_definition (MonoEvent *event)
-{
-	MonoClass *gtd;
-	ptrdiff_t offset;
-	if (!mono_class_is_ginst (event->parent))
-		return event;
-	gtd = mono_class_get_generic_class (event->parent)->container_class;
-	offset = event - mono_class_get_event_info (event->parent)->events;
-	return mono_class_get_event_info (gtd)->events + offset;
-}
-/*
- * If @property belongs to an inflated generic class, return the corresponding property of the
- * generic type definition class.
- */
-MonoProperty*
-mono_metadata_get_corresponding_property_from_generic_type_definition (MonoProperty *property)
-{
-	MonoClassPropertyInfo *info;
-	MonoClass *gtd;
-	ptrdiff_t offset;
-	if (!mono_class_is_ginst (property->parent))
-		return property;
-	info = mono_class_get_property_info (property->parent);
-	gtd = mono_class_get_generic_class (property->parent)->container_class;
-	offset = property - info->properties;
-	return mono_class_get_property_info (gtd)->properties + offset;
-}
-MonoWrapperCaches*
-mono_method_get_wrapper_cache (MonoMethod *method)
-{
-	if (method->is_inflated) {
-		MonoMethodInflated *imethod = (MonoMethodInflated *)method;
-		return &imethod->owner->wrapper_caches;
-	} else {
-		return &m_class_get_image (method->klass)->wrapper_caches;
-	}
-}
-void
-mono_loader_set_strict_assembly_name_check (gboolean enabled)
-{
-	check_assembly_names_strictly = enabled;
-}
-gboolean
-mono_loader_get_strict_assembly_name_check (void)
-{
-	return check_assembly_names_strictly;
-}
-gboolean
-mono_type_is_aggregate_mods (const MonoType *t)
-{
-	if (!t->has_cmods)
-		return FALSE;
-	MonoTypeWithModifiers *full = (MonoTypeWithModifiers *)t;
-	return full->is_aggregate;
-}
-MonoCustomModContainer *
-mono_type_get_cmods (const MonoType *t)
-{
-	if (!t->has_cmods)
-		return NULL;
-	MonoTypeWithModifiers *full = (MonoTypeWithModifiers *)t;
-	g_assert (!full->is_aggregate);
-	return &full->mods.cmods;
-}
-MonoAggregateModContainer *
-mono_type_get_amods (const MonoType *t)
-{
-	if (!t->has_cmods)
-		return NULL;
-	MonoTypeWithModifiers *full = (MonoTypeWithModifiers *)t;
-	g_assert (full->is_aggregate);
-	return full->mods.amods;
-}
-size_t
-mono_sizeof_aggregate_modifiers (uint8_t num_mods)
-{
-	size_t accum = 0;
-	accum += offsetof (MonoAggregateModContainer, modifiers);
-	accum += sizeof (MonoSingleCustomMod) * num_mods;
-	return accum;
-}
-size_t
-mono_sizeof_type_with_mods (uint8_t num_mods, gboolean is_aggregate)
-{
-	if (num_mods == 0)
-		return sizeof (MonoType);
-	size_t accum = 0;
-	accum += offsetof (MonoTypeWithModifiers, mods);
-	if (!is_aggregate) {
-		accum += offsetof (struct _MonoCustomModContainer, modifiers);
-		accum += sizeof (MonoCustomMod) * num_mods;
-	} else {
-		accum += offsetof (MonoAggregateModContainer, modifiers);
-		accum += sizeof (MonoAggregateModContainer *);
-	}
-	return accum;
-}
-size_t
-mono_sizeof_type (const MonoType *ty)
-{
-	if (ty->has_cmods) {
-		if (!mono_type_is_aggregate_mods (ty)) {
-			MonoCustomModContainer *cmods = mono_type_get_cmods (ty);
-			return mono_sizeof_type_with_mods (cmods->count, FALSE);
-		} else {
-			MonoAggregateModContainer *amods = mono_type_get_amods (ty);
-			return mono_sizeof_type_with_mods (amods->count, TRUE);
-		}
-	} else
-		return sizeof (MonoType);
-}
-void
-mono_type_set_amods (MonoType *t, MonoAggregateModContainer *amods)
-{
-	g_assert (t->has_cmods);
-	MonoTypeWithModifiers *t_full = (MonoTypeWithModifiers*)t;
-	g_assert (t_full->is_aggregate);
-	g_assert (t_full->mods.amods == NULL);
-	t_full->mods.amods = amods;
-}
-static gint
-mono_unichar_xdigit_value (gunichar c)
-{
-	if (c >= 0x30 && c <= 0x39) /*0-9*/
-		return (c - 0x30);
-	if (c >= 0x41 && c <= 0x46) /*A-F*/
-		return (c - 0x37);
-	if (c >= 0x61 && c <= 0x66) /*a-f*/
-		return (c - 0x57);
-	return -1;
-}
-/**
- * mono_string_to_guid:
- *
- * Converts the standard string representation of a GUID
- * to a 16 byte Microsoft GUID.
- */
-static void
-mono_string_to_guid (MonoString* string, guint8 *guid) {
-	gunichar2 * chars = mono_string_chars_internal (string);
-	int i = 0;
-	static const guint8 indexes[16] = {7, 5, 3, 1, 12, 10, 17, 15, 20, 22, 25, 27, 29, 31, 33, 35};
-	for (i = 0; i < sizeof(indexes); i++)
-		guid [i] = GINT_TO_UINT8 (mono_unichar_xdigit_value (chars [indexes [i]]) + (mono_unichar_xdigit_value (chars [indexes [i] - 1]) << 4));
-}
-static GENERATE_GET_CLASS_WITH_CACHE (guid_attribute, "System.Runtime.InteropServices", "GuidAttribute")
-void
-mono_metadata_get_class_guid (MonoClass* klass, guint8* guid, MonoError *error)
-{
-	MonoReflectionGuidAttribute *attr = NULL;
-	MonoCustomAttrInfo *cinfo = mono_custom_attrs_from_class_checked (klass, error);
-	if (!is_ok (error))
-		return;
-	if (cinfo) {
-		attr = (MonoReflectionGuidAttribute*)mono_custom_attrs_get_attr_checked (cinfo, mono_class_get_guid_attribute_class (), error);
-		if (!is_ok (error))
-			return;
-		if (!cinfo->cached)
-			mono_custom_attrs_free (cinfo);
-	}
-	memset(guid, 0, 16);
-	if (attr)
-		mono_string_to_guid (attr->guid, guid);
-}
-uint32_t
-mono_metadata_get_method_params (MonoImage *image, uint32_t method_idx, uint32_t *last_param_out)
-{
-	if (last_param_out)
-		*last_param_out = 0;
-	if (!method_idx)
-		return 0;
-	MonoTableInfo *methodt = &image->tables [MONO_TABLE_METHOD];
-	uint32_t param_index, lastp;
-	param_index = mono_metadata_decode_row_col (methodt, method_idx - 1, MONO_METHOD_PARAMLIST);
-	if (G_UNLIKELY (param_index == 0 && image->has_updates)) {
-		uint32_t count;
-		param_index = mono_metadata_update_get_method_params (image, mono_metadata_make_token (MONO_TABLE_METHOD, method_idx), &count);
-		if (!param_index)
-			return 0;
-		lastp = param_index + count;
-	} else {
-		/* lastp is the starting param index for the next method in the table, or
-		 * one past the last row if this is the last method
-		 */
-		if (method_idx < table_info_get_rows (methodt))
-			lastp = mono_metadata_decode_row_col (methodt, method_idx, MONO_METHOD_PARAMLIST);
-		else
-			lastp = table_info_get_rows (&image->tables [MONO_TABLE_PARAM]) + 1;
-	}
-	if (last_param_out)
-		*last_param_out = lastp;
-	return param_index;
-}
-void
-dn_simdhash_assert_fail (const char *file, int line, const char *condition);
-void
-dn_simdhash_assert_fail (const char *file, int line, const char *condition) {
-	mono_assertion_message (file, line, condition);
-}

--- a/src/mono/mono/mini/method-to-ir.c
+++ b//dev/null
@@ -1,11913 +0,0 @@
-/**
- * \file
- * Convert CIL to the JIT internal representation
- *
- * Author:
- *   Paolo Molaro (lupus@ximian.com)
- *   Dietmar Maurer (dietmar@ximian.com)
- *
- * (C) 2002 Ximian, Inc.
- * Copyright 2003-2010 Novell, Inc (http://www.novell.com)
- * Copyright 2011 Xamarin, Inc (http://www.xamarin.com)
- * Licensed under the MIT license. See LICENSE file in the project root for full license information.
- */
-#include <config.h>
-#include <glib.h>
-#include <mono/utils/mono-compiler.h>
-#include "mini.h"
-#ifndef DISABLE_JIT
-#include <signal.h>
-#ifdef HAVE_UNISTD_H
-#include <unistd.h>
-#endif
-#include <math.h>
-#include <string.h>
-#include <ctype.h>
-#ifdef HAVE_SYS_TIME_H
-#include <sys/time.h>
-#endif
-#ifdef HAVE_ALLOCA_H
-#include <alloca.h>
-#endif
-#include <mono/utils/memcheck.h>
-#include <mono/metadata/abi-details.h>
-#include <mono/metadata/assembly.h>
-#include <mono/metadata/assembly-internals.h>
-#include <mono/metadata/attrdefs.h>
-#include <mono/metadata/loader.h>
-#include <mono/metadata/tabledefs.h>
-#include <mono/metadata/class.h>
-#include <mono/metadata/class-abi-details.h>
-#include <mono/metadata/object.h>
-#include <mono/metadata/exception.h>
-#include <mono/metadata/exception-internals.h>
-#include <mono/metadata/opcodes.h>
-#include <mono/metadata/mono-endian.h>
-#include <mono/metadata/tokentype.h>
-#include <mono/metadata/tabledefs.h>
-#include <mono/metadata/marshal.h>
-#include <mono/metadata/debug-helpers.h>
-#include <mono/metadata/debug-internals.h>
-#include <mono/metadata/gc-internals.h>
-#include <mono/metadata/threads-types.h>
-#include <mono/metadata/profiler-private.h>
-#include <mono/metadata/profiler.h>
-#include <mono/metadata/monitor.h>
-#include <mono/utils/mono-memory-model.h>
-#include <mono/utils/mono-error-internals.h>
-#include <mono/metadata/mono-basic-block.h>
-#include <mono/metadata/reflection-internals.h>
-#include <mono/utils/mono-threads-coop.h>
-#include <mono/utils/mono-utils-debug.h>
-#include <mono/utils/mono-logger-internals.h>
-#include <mono/metadata/verify-internals.h>
-#include <mono/metadata/icall-decl.h>
-#include "mono/metadata/icall-signatures.h"
-#include "trace.h"
-#include "ir-emit.h"
-#include "jit-icalls.h"
-#include <mono/jit/jit.h>
-#include "seq-points.h"
-#include "aot-compiler.h"
-#include "mini-llvm.h"
-#include "mini-runtime.h"
-#include "llvmonly-runtime.h"
-#include "mono/utils/mono-tls-inline.h"
-MONO_DISABLE_WARNING(4127) /* conditional expression is constant */
-#define BRANCH_COST 10
-#define CALL_COST 10
-/* Used for the JIT */
-#define INLINE_LENGTH_LIMIT 20
-/*
- * The aot and jit inline limits should be different,
- * since aot sees the whole program so we can let opt inline methods for us,
- * while the jit only sees one method, so we have to inline things ourselves.
- */
-/* Used by LLVM AOT */
-#define LLVM_AOT_INLINE_LENGTH_LIMIT 30
-/* Used to LLVM JIT */
-#define LLVM_JIT_INLINE_LENGTH_LIMIT 100
-static const gboolean debug_tailcall = FALSE;               // logging
-static const gboolean debug_tailcall_try_all = FALSE;       // consider any call followed by ret
-gboolean
-mono_tailcall_print_enabled (void)
-{
-	return debug_tailcall || MONO_TRACE_IS_TRACED (G_LOG_LEVEL_DEBUG, MONO_TRACE_TAILCALL);
-}
-void
-mono_tailcall_print (const char *format, ...)
-{
-	if (!mono_tailcall_print_enabled ())
-		return;
-	va_list args;
-	va_start (args, format);
-	g_printv (format, args);
-	va_end (args);
-}
-/* These have 'cfg' as an implicit argument */
-#define INLINE_FAILURE(msg) do {									\
-	if ((cfg->method != cfg->current_method) && (cfg->current_method->wrapper_type == MONO_WRAPPER_NONE)) { \
-		inline_failure (cfg, msg);										\
-		goto exception_exit;											\
-	} \
-	} while (0)
-#define CHECK_CFG_EXCEPTION do {\
-		if (cfg->exception_type != MONO_EXCEPTION_NONE)	\
-			goto exception_exit;						\
-	} while (0)
-#define FIELD_ACCESS_FAILURE(method, field) do {					\
-		field_access_failure ((cfg), (method), (field));			\
-		goto exception_exit;	\
-	} while (0)
-#define GENERIC_SHARING_FAILURE(opcode) do {		\
-		if (cfg->gshared) {									\
-			gshared_failure (cfg, opcode, __FILE__, __LINE__);	\
-			goto exception_exit;	\
-		}			\
-	} while (0)
-#define GSHAREDVT_FAILURE(opcode) do {		\
-	if (cfg->gsharedvt) {												\
-		gsharedvt_failure (cfg, opcode, __FILE__, __LINE__);			\
-		goto exception_exit;											\
-	}																	\
-	} while (0)
-#define OUT_OF_MEMORY_FAILURE do {	\
-		mono_cfg_set_exception (cfg, MONO_EXCEPTION_MONO_ERROR);		\
-		mono_error_set_out_of_memory (cfg->error, "");					\
-		goto exception_exit;	\
-	} while (0)
-#define DISABLE_AOT(cfg) do { \
-		if ((cfg)->verbose_level >= 2)						  \
-			printf ("AOT disabled: %s:%d\n", __FILE__, __LINE__);	\
-		(cfg)->disable_aot = TRUE;							  \
-	} while (0)
-#define LOAD_ERROR do { \
-		break_on_unverified ();								\
-		mono_cfg_set_exception (cfg, MONO_EXCEPTION_TYPE_LOAD); \
-		goto exception_exit;									\
-	} while (0)
-#define TYPE_LOAD_ERROR(klass) do { \
-		cfg->exception_ptr = klass; \
-		LOAD_ERROR; \
-	} while (0)
-#define CHECK_CFG_ERROR do {\
-		if (!is_ok (cfg->error)) { \
-			mono_cfg_set_exception (cfg, MONO_EXCEPTION_MONO_ERROR);	\
-			goto mono_error_exit; \
-		} \
-	} while (0)
-int mono_op_to_op_imm (int opcode);
-int mono_op_to_op_imm_noemul (int opcode);
-static int inline_method (MonoCompile *cfg, MonoMethod *cmethod, MonoMethodSignature *fsig, MonoInst **sp,
-						  guchar *ip, guint real_offset, gboolean inline_always, gboolean *is_empty);
-static MonoInst*
-convert_value (MonoCompile *cfg, MonoType *type, MonoInst *ins);
-/*
- * Instruction metadata
- */
-#ifdef MINI_OP
-#undef MINI_OP
-#endif
-#ifdef MINI_OP3
-#undef MINI_OP3
-#endif
-#define MINI_OP(a,b,dest,src1,src2) dest, src1, src2, ' ',
-#define MINI_OP3(a,b,dest,src1,src2,src3) dest, src1, src2, src3,
-#define NONE ' '
-#define IREG 'i'
-#define FREG 'f'
-#define VREG 'v'
-#define XREG 'x'
-#if SIZEOF_REGISTER == 8 && SIZEOF_REGISTER == TARGET_SIZEOF_VOID_P
-#define LREG IREG
-#else
-#define LREG 'l'
-#endif
-/* keep in sync with the enum in mini.h */
-const char
-mini_ins_info[] = {
-#include "mini-ops.h"
-};
-#undef MINI_OP
-#undef MINI_OP3
-#define MINI_OP(a,b,dest,src1,src2) ((src2) != NONE ? 2 : ((src1) != NONE ? 1 : 0)),
-#define MINI_OP3(a,b,dest,src1,src2,src3) ((src3) != NONE ? 3 : ((src2) != NONE ? 2 : ((src1) != NONE ? 1 : 0))),
-/*
- * This should contain the index of the last sreg + 1. This is not the same
- * as the number of sregs for opcodes like IA64_CMP_EQ_IMM.
- */
-const gint8 mini_ins_sreg_counts[] = {
-#include "mini-ops.h"
-};
-#undef MINI_OP
-#undef MINI_OP3
-guint32
-mono_alloc_ireg (MonoCompile *cfg)
-{
-	return alloc_ireg (cfg);
-}
-guint32
-mono_alloc_lreg (MonoCompile *cfg)
-{
-	return alloc_lreg (cfg);
-}
-guint32
-mono_alloc_freg (MonoCompile *cfg)
-{
-	return alloc_freg (cfg);
-}
-guint32
-mono_alloc_preg (MonoCompile *cfg)
-{
-	return alloc_preg (cfg);
-}
-guint32
-mono_alloc_dreg (MonoCompile *cfg, MonoStackType stack_type)
-{
-	return alloc_dreg (cfg, stack_type);
-}
-/*
- * mono_alloc_ireg_ref:
- *
- *   Allocate an IREG, and mark it as holding a GC ref.
- */
-guint32
-mono_alloc_ireg_ref (MonoCompile *cfg)
-{
-	return alloc_ireg_ref (cfg);
-}
-/*
- * mono_alloc_ireg_mp:
- *
- *   Allocate an IREG, and mark it as holding a managed pointer.
- */
-guint32
-mono_alloc_ireg_mp (MonoCompile *cfg)
-{
-	return alloc_ireg_mp (cfg);
-}
-/*
- * mono_alloc_ireg_copy:
- *
- *   Allocate an IREG with the same GC type as VREG.
- */
-guint32
-mono_alloc_ireg_copy (MonoCompile *cfg, guint32 vreg)
-{
-	if (vreg_is_ref (cfg, vreg))
-		return alloc_ireg_ref (cfg);
-	else if (vreg_is_mp (cfg, vreg))
-		return alloc_ireg_mp (cfg);
-	else
-		return alloc_ireg (cfg);
-}
-guint
-mono_type_to_regmove (MonoCompile *cfg, MonoType *type)
-{
-	if (m_type_is_byref (type))
-		return OP_MOVE;
-	type = mini_get_underlying_type (type);
-handle_enum:
-	switch (type->type) {
-	case MONO_TYPE_I1:
-	case MONO_TYPE_U1:
-		return OP_MOVE;
-	case MONO_TYPE_I2:
-	case MONO_TYPE_U2:
-		return OP_MOVE;
-	case MONO_TYPE_I4:
-	case MONO_TYPE_U4:
-		return OP_MOVE;
-	case MONO_TYPE_I:
-	case MONO_TYPE_U:
-	case MONO_TYPE_PTR:
-	case MONO_TYPE_FNPTR:
-		return OP_MOVE;
-	case MONO_TYPE_CLASS:
-	case MONO_TYPE_STRING:
-	case MONO_TYPE_OBJECT:
-	case MONO_TYPE_SZARRAY:
-	case MONO_TYPE_ARRAY:
-		return OP_MOVE;
-	case MONO_TYPE_I8:
-	case MONO_TYPE_U8:
-#if SIZEOF_REGISTER == 8
-		return OP_MOVE;
-#else
-		return OP_LMOVE;
-#endif
-	case MONO_TYPE_R4:
-		return cfg->r4fp ? OP_RMOVE : OP_FMOVE;
-	case MONO_TYPE_R8:
-		return OP_FMOVE;
-	case MONO_TYPE_VALUETYPE:
-		if (m_class_is_enumtype (type->data.klass)) {
-			type = mono_class_enum_basetype_internal (type->data.klass);
-			goto handle_enum;
-		}
-		if (mini_class_is_simd (cfg, mono_class_from_mono_type_internal (type)))
-			return OP_XMOVE;
-		return OP_VMOVE;
-	case MONO_TYPE_TYPEDBYREF:
-		return OP_VMOVE;
-	case MONO_TYPE_GENERICINST:
-		if (mini_class_is_simd (cfg, mono_class_from_mono_type_internal (type)))
-			return OP_XMOVE;
-		type = m_class_get_byval_arg (type->data.generic_class->container_class);
-		goto handle_enum;
-	case MONO_TYPE_VAR:
-	case MONO_TYPE_MVAR:
-		g_assert (cfg->gshared);
-		if (mini_type_var_is_vt (type))
-			return OP_VMOVE;
-		else
-			return mono_type_to_regmove (cfg, mini_get_underlying_type (type));
-	default:
-		g_error ("unknown type 0x%02x in type_to_regstore", type->type);
-	}
-	return -1;
-}
-void
-mono_print_bb (MonoBasicBlock *bb, const char *msg)
-{
-	int i;
-	MonoInst *tree;
-	GString *str = g_string_new ("");
-	g_string_append_printf (str, "%s %d: [IN: ", msg, bb->block_num);
-	for (i = 0; i < bb->in_count; ++i)
-		g_string_append_printf (str, " BB%d(%d)", bb->in_bb [i]->block_num, bb->in_bb [i]->dfn);
-	g_string_append_printf (str, ", OUT: ");
-	for (i = 0; i < bb->out_count; ++i)
-		g_string_append_printf (str, " BB%d(%d)", bb->out_bb [i]->block_num, bb->out_bb [i]->dfn);
-	g_string_append_printf (str, " ]\n");
-	g_print ("%s", str->str);
-	g_string_free (str, TRUE);
-	for (tree = bb->code; tree; tree = tree->next)
-		mono_print_ins_index (-1, tree);
-}
-static MONO_NEVER_INLINE gboolean
-break_on_unverified (void)
-{
-	if (mini_debug_options.break_on_unverified) {
-		G_BREAKPOINT ();
-		return TRUE;
-	}
-	return FALSE;
-}
-static void
-clear_cfg_error (MonoCompile *cfg)
-{
-	mono_error_cleanup (cfg->error);
-	error_init (cfg->error);
-}
-static MONO_NEVER_INLINE void
-field_access_failure (MonoCompile *cfg, MonoMethod *method, MonoClassField *field)
-{
-	char *method_fname = mono_method_full_name (method, TRUE);
-	char *field_fname = mono_field_full_name (field);
-	mono_cfg_set_exception (cfg, MONO_EXCEPTION_MONO_ERROR);
-	mono_error_set_generic_error (cfg->error, "System", "FieldAccessException", "Field `%s' is inaccessible from method `%s'\n", field_fname, method_fname);
-	g_free (method_fname);
-	g_free (field_fname);
-}
-static MONO_NEVER_INLINE void
-inline_failure (MonoCompile *cfg, const char *msg)
-{
-	if (cfg->verbose_level >= 2)
-		printf ("inline failed: %s\n", msg);
-	mono_cfg_set_exception (cfg, MONO_EXCEPTION_INLINE_FAILED);
-}
-static MONO_NEVER_INLINE void
-gshared_failure (MonoCompile *cfg, int opcode, const char *file, int line)
-{
-	if (cfg->verbose_level > 2)
-		printf ("sharing failed for method %s.%s.%s/%d opcode %s line %d\n", m_class_get_name_space (cfg->current_method->klass), m_class_get_name (cfg->current_method->klass), cfg->current_method->name, cfg->current_method->signature->param_count, mono_opcode_name (opcode), line);
-	mono_cfg_set_exception (cfg, MONO_EXCEPTION_GENERIC_SHARING_FAILED);
-}
-static MONO_NEVER_INLINE void
-gsharedvt_failure (MonoCompile *cfg, int opcode, const char *file, int line)
-{
-	cfg->exception_message = g_strdup_printf ("gsharedvt failed for method %s.%s.%s/%d opcode %s %s:%d", m_class_get_name_space (cfg->current_method->klass), m_class_get_name (cfg->current_method->klass), cfg->current_method->name, cfg->current_method->signature->param_count, mono_opcode_name ((opcode)), file, line);
-	if (cfg->verbose_level >= 2)
-		printf ("%s\n", cfg->exception_message);
-	mono_cfg_set_exception (cfg, MONO_EXCEPTION_GENERIC_SHARING_FAILED);
-}
-void
-mini_set_inline_failure (MonoCompile *cfg, const char *msg)
-{
-	if (cfg->verbose_level >= 2)
-		printf ("inline failed: %s\n", msg);
-	mono_cfg_set_exception (cfg, MONO_EXCEPTION_INLINE_FAILED);
-}
-/*
- * When using gsharedvt, some instatiations might be verifiable, and some might be not. i.e.
- * foo<T> (int i) { ldarg.0; box T; }
- */
-#define UNVERIFIED do { \
-	if (cfg->gsharedvt) { \
-		if (cfg->verbose_level > 2) \
-			printf ("gsharedvt method failed to verify, falling back to instantiation.\n"); \
-		mono_cfg_set_exception (cfg, MONO_EXCEPTION_GENERIC_SHARING_FAILED); \
-		goto exception_exit; \
-	} \
-	break_on_unverified (); \
-	goto unverified; \
-} while (0)
-#define GET_BBLOCK(cfg,tblock,ip) do { \
-		if ((ip) >= end || (ip) < header->code) { UNVERIFIED; }	\
-		(tblock) = cfg->cil_offset_to_bb [(ip) - cfg->cil_start]; \
-		if (!(tblock)) { \
-			NEW_BBLOCK (cfg, (tblock)); \
-			(tblock)->cil_code = (ip); \
-			ADD_BBLOCK (cfg, (tblock)); \
-		} \
-	} while (0)
-/* Emit conversions so both operands of a binary opcode are of the same type */
-static void
-add_widen_op (MonoCompile *cfg, MonoInst *ins, MonoInst **arg1_ref, MonoInst **arg2_ref)
-{
-	MonoInst *arg1 = *arg1_ref;
-	MonoInst *arg2 = *arg2_ref;
-	if (cfg->r4fp &&
-		((arg1->type == STACK_R4 && arg2->type == STACK_R8) ||
-		 (arg1->type == STACK_R8 && arg2->type == STACK_R4))) {
-		MonoInst *conv;
-		/* Mixing r4/r8 is allowed by the spec */
-		if (arg1->type == STACK_R4) {
-			int dreg = alloc_freg (cfg);
-			EMIT_NEW_UNALU (cfg, conv, OP_RCONV_TO_R8, dreg, arg1->dreg);
-			conv->type = STACK_R8;
-			ins->sreg1 = dreg;
-			*arg1_ref = conv;
-		}
-		if (arg2->type == STACK_R4) {
-			int dreg = alloc_freg (cfg);
-			EMIT_NEW_UNALU (cfg, conv, OP_RCONV_TO_R8, dreg, arg2->dreg);
-			conv->type = STACK_R8;
-			ins->sreg2 = dreg;
-			*arg2_ref = conv;
-		}
-	}
-#if SIZEOF_REGISTER == 8
-	/* FIXME: Need to add many more cases */
-	if ((arg1)->type == STACK_PTR && (arg2)->type == STACK_I4) {
-		MonoInst *widen;
-		int dr = alloc_preg (cfg);
-		EMIT_NEW_UNALU (cfg, widen, OP_SEXT_I4, dr, (arg2)->dreg);
-		(ins)->sreg2 = widen->dreg;
-	}
-#endif
-}
-#define ADD_UNOP(op) do { \
-		MONO_INST_NEW (cfg, ins, (op)); \
-		sp--; \
-		ins->sreg1 = sp [0]->dreg; \
-		type_from_op (cfg, ins, sp [0], NULL); \
-		CHECK_TYPE (ins); \
-		(ins)->dreg = alloc_dreg ((cfg), (MonoStackType)(ins)->type); \
-		MONO_ADD_INS ((cfg)->cbb, (ins)); \
-		*sp++ = mono_decompose_opcode (cfg, ins); \
-	} while (0)
-#define ADD_BINCOND(next_block) do { \
-		MonoInst *cmp; \
-		sp -= 2; \
-		MONO_INST_NEW(cfg, cmp, OP_COMPARE); \
-		cmp->sreg1 = sp [0]->dreg; \
-		cmp->sreg2 = sp [1]->dreg; \
-		add_widen_op (cfg, cmp, &sp [0], &sp [1]); \
-		type_from_op (cfg, cmp, sp [0], sp [1]); \
-		CHECK_TYPE (cmp); \
-		type_from_op (cfg, ins, sp [0], sp [1]); \
-		ins->inst_many_bb = (MonoBasicBlock **)mono_mempool_alloc (cfg->mempool, sizeof(gpointer)*2); \
-		GET_BBLOCK (cfg, tblock, target); \
-		link_bblock (cfg, cfg->cbb, tblock); \
-		ins->inst_true_bb = tblock; \
-		MONO_DISABLE_WARNING(4127) \
-		if ((next_block)) { \
-			link_bblock (cfg, cfg->cbb, (next_block)); \
-			ins->inst_false_bb = (next_block); \
-			start_new_bblock = 1; \
-		} else { \
-			GET_BBLOCK (cfg, tblock, next_ip); \
-			link_bblock (cfg, cfg->cbb, tblock); \
-			ins->inst_false_bb = tblock; \
-			start_new_bblock = 2; \
-		} \
-		MONO_RESTORE_WARNING \
-		if (sp != stack_start) { \
-			handle_stack_args (cfg, stack_start, GPTRDIFF_TO_INT (sp - stack_start)); \
-			CHECK_UNVERIFIABLE (cfg); \
-		} \
-		MONO_ADD_INS (cfg->cbb, cmp); \
-		MONO_ADD_INS (cfg->cbb, ins); \
-	} while (0)
-/* *
- * link_bblock: Links two basic blocks
- *
- * links two basic blocks in the control flow graph, the 'from'
- * argument is the starting block and the 'to' argument is the block
- * the control flow ends to after 'from'.
- */
-static void
-link_bblock (MonoCompile *cfg, MonoBasicBlock *from, MonoBasicBlock* to)
-{
-	MonoBasicBlock **newa;
-	int i, found;
-#if 0
-	if (from->cil_code) {
-		if (to->cil_code)
-			printf ("edge from IL%04x to IL_%04x\n", from->cil_code - cfg->cil_code, to->cil_code - cfg->cil_code);
-		else
-			printf ("edge from IL%04x to exit\n", from->cil_code - cfg->cil_code);
-	} else {
-		if (to->cil_code)
-			printf ("edge from entry to IL_%04x\n", to->cil_code - cfg->cil_code);
-		else
-			printf ("edge from entry to exit\n");
-	}
-#endif
-	found = FALSE;
-	for (i = 0; i < from->out_count; ++i) {
-		if (to == from->out_bb [i]) {
-			found = TRUE;
-			break;
-		}
-	}
-	if (!found) {
-		newa = (MonoBasicBlock **)mono_mempool_alloc (cfg->mempool, sizeof (gpointer) * (from->out_count + 1));
-		for (i = 0; i < from->out_count; ++i) {
-			newa [i] = from->out_bb [i];
-		}
-		newa [i] = to;
-		from->out_count++;
-		from->out_bb = newa;
-	}
-	found = FALSE;
-	for (i = 0; i < to->in_count; ++i) {
-		if (from == to->in_bb [i]) {
-			found = TRUE;
-			break;
-		}
-	}
-	if (!found) {
-		newa = (MonoBasicBlock **)mono_mempool_alloc (cfg->mempool, sizeof (gpointer) * (to->in_count + 1));
-		for (i = 0; i < to->in_count; ++i) {
-			newa [i] = to->in_bb [i];
-		}
-		newa [i] = from;
-		to->in_count++;
-		to->in_bb = newa;
-	}
-}
-void
-mono_link_bblock (MonoCompile *cfg, MonoBasicBlock *from, MonoBasicBlock* to)
-{
-	link_bblock (cfg, from, to);
-}
-static void
-mono_create_spvar_for_region (MonoCompile *cfg, int region);
-static void
-mark_bb_in_region (MonoCompile *cfg, guint region, uint32_t start, uint32_t end)
-{
-	MonoBasicBlock *bb = cfg->cil_offset_to_bb [start];
-	g_assert (bb);
-	if (cfg->verbose_level > 1)
-		g_print ("FIRST BB for %d is BB_%d\n", start, bb->block_num);
-	for (; bb && bb->real_offset < end; bb = bb->next_bb) {
-		if (bb->region == -1) {
-			bb->region = region;
-			continue;
-		}
-		if ((bb->region & (0xf << 4)) != MONO_REGION_TRY) {
-			continue;
-		}
-		if ((region & (0xf << 4)) != MONO_REGION_TRY) {
-			bb->region = region;
-		}
-	}
-	if (cfg->spvars)
-		mono_create_spvar_for_region (cfg, region);
-}
-static void
-compute_bb_regions (MonoCompile *cfg)
-{
-	MonoMethodHeader *header = cfg->header;
-	for (MonoBasicBlock *bb = cfg->bb_entry; bb; bb = bb->next_bb)
-		bb->region = -1;
-	for (guint i = 0; i < header->num_clauses; ++i) {
-		MonoExceptionClause *clause = &header->clauses [i];
-		if (clause->flags == MONO_EXCEPTION_CLAUSE_FILTER)
-			mark_bb_in_region (cfg, ((i + 1) << 8) | MONO_REGION_FILTER | clause->flags, clause->data.filter_offset, clause->handler_offset);
-		guint handler_region;
-		if (clause->flags == MONO_EXCEPTION_CLAUSE_FINALLY)
-			handler_region = ((i + 1) << 8) | MONO_REGION_FINALLY | clause->flags;
-		else if (clause->flags == MONO_EXCEPTION_CLAUSE_FAULT)
-			handler_region = ((i + 1) << 8) | MONO_REGION_FAULT | clause->flags;
-		else
-			handler_region = ((i + 1) << 8) | MONO_REGION_CATCH | clause->flags;
-		mark_bb_in_region (cfg, handler_region, clause->handler_offset, clause->handler_offset + clause->handler_len);
-		mark_bb_in_region (cfg, ((i + 1) << 8) | clause->flags, clause->try_offset, clause->try_offset + clause->try_len);
-	}
-	if (cfg->verbose_level > 2) {
-		for (MonoBasicBlock *bb = cfg->bb_entry; bb; bb = bb->next_bb)
-			g_print ("REGION BB%d IL_%04x ID_%08X\n", bb->block_num, bb->real_offset, bb->region);
-	}
-}
-static gboolean
-ip_in_finally_clause (MonoCompile *cfg, int offset)
-{
-	MonoMethodHeader *header = cfg->header;
-	MonoExceptionClause *clause;
-	for (guint i = 0; i < header->num_clauses; ++i) {
-		clause = &header->clauses [i];
-		if (clause->flags != MONO_EXCEPTION_CLAUSE_FINALLY && clause->flags != MONO_EXCEPTION_CLAUSE_FAULT)
-			continue;
-		if (MONO_OFFSET_IN_HANDLER (clause, GINT_TO_UINT32(offset)))
-			return TRUE;
-	}
-	return FALSE;
-}
-/* Find clauses between ip and target, from inner to outer */
-static GList*
-mono_find_leave_clauses (MonoCompile *cfg, guchar *ip, guchar *target)
-{
-	MonoMethodHeader *header = cfg->header;
-	MonoExceptionClause *clause;
-	GList *res = NULL;
-	for (guint i = 0; i < header->num_clauses; ++i) {
-		clause = &header->clauses [i];
-		if (MONO_OFFSET_IN_CLAUSE (clause, GPTRDIFF_TO_UINT32(ip - header->code)) &&
-		    (!MONO_OFFSET_IN_CLAUSE (clause, GPTRDIFF_TO_UINT32(target - header->code)))) {
-			MonoLeaveClause *leave = mono_mempool_alloc0 (cfg->mempool, sizeof (MonoLeaveClause));
-			leave->index = i;
-			leave->clause = clause;
-			res = g_list_append_mempool (cfg->mempool, res, leave);
-		}
-	}
-	return res;
-}
-static void
-mono_create_spvar_for_region (MonoCompile *cfg, int region)
-{
-	MonoInst *var;
-	var = (MonoInst *)g_hash_table_lookup (cfg->spvars, GINT_TO_POINTER (region));
-	if (var)
-		return;
-	var = mono_compile_create_var (cfg, mono_get_int_type (), OP_LOCAL);
-	/* prevent it from being register allocated */
-	var->flags |= MONO_INST_VOLATILE;
-	g_hash_table_insert (cfg->spvars, GINT_TO_POINTER (region), var);
-}
-MonoInst *
-mono_find_exvar_for_offset (MonoCompile *cfg, int offset)
-{
-	return (MonoInst *)g_hash_table_lookup (cfg->exvars, GINT_TO_POINTER (offset));
-}
-static MonoInst*
-mono_create_exvar_for_offset (MonoCompile *cfg, int offset)
-{
-	MonoInst *var;
-	var = (MonoInst *)g_hash_table_lookup (cfg->exvars, GINT_TO_POINTER (offset));
-	if (var)
-		return var;
-	var = mono_compile_create_var (cfg, mono_get_object_type (), OP_LOCAL);
-	/* prevent it from being register allocated */
-	var->flags |= MONO_INST_VOLATILE;
-	g_hash_table_insert (cfg->exvars, GINT_TO_POINTER (offset), var);
-	return var;
-}
-/*
- * Returns the type used in the eval stack when @type is loaded.
- * FIXME: return a MonoType/MonoClass for the byref and VALUETYPE cases.
- */
-void
-mini_type_to_eval_stack_type (MonoCompile *cfg, MonoType *type, MonoInst *inst)
-{
-	MonoClass *klass;
-	type = mini_get_underlying_type (type);
-	inst->klass = klass = mono_class_from_mono_type_internal (type);
-	if (m_type_is_byref (type)) {
-		inst->type = STACK_MP;
-		return;
-	}
-handle_enum:
-	switch (type->type) {
-	case MONO_TYPE_VOID:
-		inst->type = STACK_INV;
-		return;
-	case MONO_TYPE_I1:
-	case MONO_TYPE_U1:
-	case MONO_TYPE_I2:
-	case MONO_TYPE_U2:
-	case MONO_TYPE_I4:
-	case MONO_TYPE_U4:
-		inst->type = STACK_I4;
-		return;
-	case MONO_TYPE_I:
-	case MONO_TYPE_U:
-	case MONO_TYPE_PTR:
-	case MONO_TYPE_FNPTR:
-		inst->type = STACK_PTR;
-		return;
-	case MONO_TYPE_CLASS:
-	case MONO_TYPE_STRING:
-	case MONO_TYPE_OBJECT:
-	case MONO_TYPE_SZARRAY:
-	case MONO_TYPE_ARRAY:
-		inst->type = STACK_OBJ;
-		return;
-	case MONO_TYPE_I8:
-	case MONO_TYPE_U8:
-		inst->type = STACK_I8;
-		return;
-	case MONO_TYPE_R4:
-		inst->type = GINT_TO_UINT8 (cfg->r4_stack_type);
-		break;
-	case MONO_TYPE_R8:
-		inst->type = STACK_R8;
-		return;
-	case MONO_TYPE_VALUETYPE:
-		if (m_class_is_enumtype (type->data.klass)) {
-			type = mono_class_enum_basetype_internal (type->data.klass);
-			goto handle_enum;
-		} else {
-			inst->klass = klass;
-			inst->type = STACK_VTYPE;
-			return;
-		}
-	case MONO_TYPE_TYPEDBYREF:
-		inst->klass = mono_defaults.typed_reference_class;
-		inst->type = STACK_VTYPE;
-		return;
-	case MONO_TYPE_GENERICINST:
-		type = m_class_get_byval_arg (type->data.generic_class->container_class);
-		goto handle_enum;
-	case MONO_TYPE_VAR:
-	case MONO_TYPE_MVAR:
-		g_assert (cfg->gshared);
-		if (mini_is_gsharedvt_type (type)) {
-			g_assert (cfg->gsharedvt);
-			inst->type = STACK_VTYPE;
-		} else {
-			mini_type_to_eval_stack_type (cfg, mini_get_underlying_type (type), inst);
-		}
-		return;
-	default:
-		g_error ("unknown type 0x%02x in eval stack type", type->type);
-	}
-}
-/*
- * The following tables are used to quickly validate the IL code in type_from_op ().
- */
-#define IF_P8(v) (SIZEOF_VOID_P == 8 ? v : STACK_INV)
-#define IF_P8_I8 IF_P8(STACK_I8)
-#define IF_P8_PTR IF_P8(STACK_PTR)
-static const char
-bin_num_table [STACK_MAX] [STACK_MAX] = {
-	{STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV},
-	{STACK_INV, STACK_I4,  IF_P8_I8,  STACK_PTR, STACK_INV, STACK_MP,  STACK_INV, STACK_INV},
-	{STACK_INV, IF_P8_I8,  STACK_I8,  IF_P8_PTR, STACK_INV, STACK_INV, STACK_INV, STACK_INV},
-	{STACK_INV, STACK_PTR, IF_P8_PTR, STACK_PTR, STACK_INV, STACK_MP,  STACK_INV, STACK_INV},
-	{STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_R8,  STACK_INV, STACK_INV, STACK_INV, STACK_R8},
-	{STACK_INV, STACK_MP,  STACK_INV, STACK_MP,  STACK_INV, STACK_PTR, STACK_INV, STACK_INV},
-	{STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV},
-	{STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV},
-	{STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_R8, STACK_INV, STACK_INV, STACK_INV, STACK_R4}
-};
-static const char
-neg_table [] = {
-	STACK_INV, STACK_I4, STACK_I8, STACK_PTR, STACK_R8, STACK_INV, STACK_INV, STACK_INV, STACK_R4
-};
-/* reduce the size of this table */
-static const char
-bin_int_table [STACK_MAX] [STACK_MAX] = {
-	{STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV},
-	{STACK_INV, STACK_I4,  IF_P8_I8,  STACK_PTR, STACK_INV, STACK_INV, STACK_INV, STACK_INV},
-	{STACK_INV, IF_P8_I8,  STACK_I8,  IF_P8_PTR, STACK_INV, STACK_INV, STACK_INV, STACK_INV},
-	{STACK_INV, STACK_PTR, IF_P8_PTR, STACK_PTR, STACK_INV, STACK_INV, STACK_INV, STACK_INV},
-	{STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV},
-	{STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV},
-	{STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV},
-	{STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV}
-};
-#define P1 (SIZEOF_VOID_P == 8)
-static const char
-bin_comp_table [STACK_MAX] [STACK_MAX] = {
-/*	Inv i  L  p  F  &  O  vt r4 */
-	{0},
-	{0, 1, 0, 1, 0, 0, 0, 0}, /* i, int32 */
-	{0, 0, 1,P1, 0, 0, 0, 0}, /* L, int64 */
-	{0, 1,P1, 1, 0, 2, 4, 0}, /* p, ptr */
-	{0, 0, 0, 0, 1, 0, 0, 0, 1}, /* F, R8 */
-	{0, 0, 0, 2, 0, 1, 0, 0}, /* &, managed pointer */
-	{0, 0, 0, 4, 0, 0, 3, 0}, /* O, reference */
-	{0, 0, 0, 0, 0, 0, 0, 0}, /* vt value type */
-	{0, 0, 0, 0, 1, 0, 0, 0, 1}, /* r, r4 */
-};
-#undef P1
-/* reduce the size of this table */
-static const char
-shift_table [STACK_MAX] [STACK_MAX] = {
-	{STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV},
-	{STACK_INV, STACK_I4,  STACK_INV, STACK_I4,  STACK_INV, STACK_INV, STACK_INV, STACK_INV},
-	{STACK_INV, STACK_I8,  STACK_INV, STACK_I8,  STACK_INV, STACK_INV, STACK_INV, STACK_INV},
-	{STACK_INV, STACK_PTR, STACK_INV, STACK_PTR, STACK_INV, STACK_INV, STACK_INV, STACK_INV},
-	{STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV},
-	{STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV},
-	{STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV},
-	{STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV, STACK_INV}
-};
-/*
- * Tables to map from the non-specific opcode to the matching
- * type-specific opcode.
- */
-/* handles from CEE_ADD to CEE_SHR_UN (CEE_REM_UN for floats) */
-static const guint16
-binops_op_map [STACK_MAX] = {
-	0, OP_IADD-CEE_ADD, OP_LADD-CEE_ADD, OP_PADD-CEE_ADD, OP_FADD-CEE_ADD, OP_PADD-CEE_ADD, 0, 0, OP_RADD-CEE_ADD
-};
-/* handles from CEE_NEG to CEE_CONV_U8 */
-static const guint16
-unops_op_map [STACK_MAX] = {
-	0, OP_INEG-CEE_NEG, OP_LNEG-CEE_NEG, OP_PNEG-CEE_NEG, OP_FNEG-CEE_NEG, OP_PNEG-CEE_NEG, 0, 0, OP_RNEG-CEE_NEG
-};
-/* handles from CEE_CONV_U2 to CEE_SUB_OVF_UN */
-static const guint16
-ovfops_op_map [STACK_MAX] = {
-	0, OP_ICONV_TO_U2-CEE_CONV_U2, OP_LCONV_TO_U2-CEE_CONV_U2, OP_PCONV_TO_U2-CEE_CONV_U2, OP_FCONV_TO_U2-CEE_CONV_U2, OP_PCONV_TO_U2-CEE_CONV_U2, OP_PCONV_TO_U2-CEE_CONV_U2, 0, OP_RCONV_TO_U2-CEE_CONV_U2
-};
-/* handles from CEE_CONV_OVF_I1_UN to CEE_CONV_OVF_U_UN */
-static const guint16
-ovf2ops_op_map [STACK_MAX] = {
-	0, OP_ICONV_TO_OVF_I1_UN-CEE_CONV_OVF_I1_UN, OP_LCONV_TO_OVF_I1_UN-CEE_CONV_OVF_I1_UN, OP_PCONV_TO_OVF_I1_UN-CEE_CONV_OVF_I1_UN, OP_FCONV_TO_OVF_I1_UN-CEE_CONV_OVF_I1_UN, OP_PCONV_TO_OVF_I1_UN-CEE_CONV_OVF_I1_UN, 0, 0, OP_RCONV_TO_OVF_I1_UN-CEE_CONV_OVF_I1_UN
-};
-/* handles from CEE_CONV_OVF_I1 to CEE_CONV_OVF_U8 */
-static const guint16
-ovf3ops_op_map [STACK_MAX] = {
-	0, OP_ICONV_TO_OVF_I1-CEE_CONV_OVF_I1, OP_LCONV_TO_OVF_I1-CEE_CONV_OVF_I1, OP_PCONV_TO_OVF_I1-CEE_CONV_OVF_I1, OP_FCONV_TO_OVF_I1-CEE_CONV_OVF_I1, OP_PCONV_TO_OVF_I1-CEE_CONV_OVF_I1, 0, 0, OP_RCONV_TO_OVF_I1-CEE_CONV_OVF_I1
-};
-/* handles from CEE_BEQ to CEE_BLT_UN */
-static const guint16
-beqops_op_map [STACK_MAX] = {
-	0, OP_IBEQ-CEE_BEQ, OP_LBEQ-CEE_BEQ, OP_PBEQ-CEE_BEQ, OP_FBEQ-CEE_BEQ, OP_PBEQ-CEE_BEQ, OP_PBEQ-CEE_BEQ, 0, OP_FBEQ-CEE_BEQ
-};
-/* handles from CEE_CEQ to CEE_CLT_UN */
-static const guint16
-ceqops_op_map [STACK_MAX] = {
-	0, OP_ICEQ-OP_CEQ, OP_LCEQ-OP_CEQ, OP_PCEQ-OP_CEQ, OP_FCEQ-OP_CEQ, OP_PCEQ-OP_CEQ, OP_PCEQ-OP_CEQ, 0, OP_RCEQ-OP_CEQ
-};
-/*
- * Sets ins->type (the type on the eval stack) according to the
- * type of the opcode and the arguments to it.
- * Invalid IL code is marked by setting ins->type to the invalid value STACK_INV.
- *
- * FIXME: this function sets ins->type unconditionally in some cases, but
- * it should set it to invalid for some types (a conv.x on an object)
- */
-static void
-type_from_op (MonoCompile *cfg, MonoInst *ins, MonoInst *src1, MonoInst *src2)
-{
-	switch (ins->opcode) {
-	/* binops */
-	case MONO_CEE_ADD:
-	case MONO_CEE_SUB:
-	case MONO_CEE_MUL:
-	case MONO_CEE_DIV:
-	case MONO_CEE_REM:
-		/* FIXME: check unverifiable args for STACK_MP */
-		ins->type = bin_num_table [src1->type] [src2->type];
-		ins->opcode += binops_op_map [ins->type];
-		break;
-	case MONO_CEE_DIV_UN:
-	case MONO_CEE_REM_UN:
-	case MONO_CEE_AND:
-	case MONO_CEE_OR:
-	case MONO_CEE_XOR:
-		ins->type = bin_int_table [src1->type] [src2->type];
-		ins->opcode += binops_op_map [ins->type];
-		break;
-	case MONO_CEE_SHL:
-	case MONO_CEE_SHR:
-	case MONO_CEE_SHR_UN:
-		ins->type = shift_table [src1->type] [src2->type];
-		ins->opcode += binops_op_map [ins->type];
-		break;
-	case OP_COMPARE:
-	case OP_LCOMPARE:
-	case OP_ICOMPARE:
-		ins->type = bin_comp_table [src1->type] [src2->type] ? STACK_I4: STACK_INV;
-		if ((src1->type == STACK_I8) || ((TARGET_SIZEOF_VOID_P == 8) && ((src1->type == STACK_PTR) || (src1->type == STACK_OBJ) || (src1->type == STACK_MP))))
-			ins->opcode = OP_LCOMPARE;
-		else if (src1->type == STACK_R4)
-			ins->opcode = OP_RCOMPARE;
-		else if (src1->type == STACK_R8)
-			ins->opcode = OP_FCOMPARE;
-		else
-			ins->opcode = OP_ICOMPARE;
-		break;
-	case OP_ICOMPARE_IMM:
-		ins->type = bin_comp_table [src1->type] [src1->type] ? STACK_I4 : STACK_INV;
-		if ((src1->type == STACK_I8) || ((TARGET_SIZEOF_VOID_P == 8) && ((src1->type == STACK_PTR) || (src1->type == STACK_OBJ) || (src1->type == STACK_MP))))
-			ins->opcode = OP_LCOMPARE_IMM;
-		break;
-	case MONO_CEE_BEQ:
-	case MONO_CEE_BGE:
-	case MONO_CEE_BGT:
-	case MONO_CEE_BLE:
-	case MONO_CEE_BLT:
-	case MONO_CEE_BNE_UN:
-	case MONO_CEE_BGE_UN:
-	case MONO_CEE_BGT_UN:
-	case MONO_CEE_BLE_UN:
-	case MONO_CEE_BLT_UN:
-		ins->opcode += beqops_op_map [src1->type];
-		break;
-	case OP_CEQ:
-		ins->type = bin_comp_table [src1->type] [src2->type] ? STACK_I4: STACK_INV;
-		ins->opcode += ceqops_op_map [src1->type];
-		break;
-	case OP_CGT:
-	case OP_CGT_UN:
-	case OP_CLT:
-	case OP_CLT_UN:
-		ins->type = (bin_comp_table [src1->type] [src2->type] & 1) ? STACK_I4: STACK_INV;
-		ins->opcode += ceqops_op_map [src1->type];
-		break;
-	/* unops */
-	case MONO_CEE_NEG:
-		ins->type = neg_table [src1->type];
-		ins->opcode += unops_op_map [ins->type];
-		break;
-	case MONO_CEE_NOT:
-		if (src1->type >= STACK_I4 && src1->type <= STACK_PTR)
-			ins->type = src1->type;
-		else
-			ins->type = STACK_INV;
-		ins->opcode += unops_op_map [ins->type];
-		break;
-	case MONO_CEE_CONV_I1:
-	case MONO_CEE_CONV_I2:
-	case MONO_CEE_CONV_I4:
-	case MONO_CEE_CONV_U4:
-		ins->type = STACK_I4;
-		ins->opcode += unops_op_map [src1->type];
-		break;
-	case MONO_CEE_CONV_R_UN:
-		ins->type = STACK_R8;
-		switch (src1->type) {
-		case STACK_I4:
-#if TARGET_SIZEOF_VOID_P == 4
-		case STACK_PTR:
-#endif
-			ins->opcode = OP_ICONV_TO_R_UN;
-			break;
-		case STACK_I8:
-#if TARGET_SIZEOF_VOID_P == 8
-		case STACK_PTR:
-#endif
-			ins->opcode = OP_LCONV_TO_R_UN;
-			break;
-		case STACK_R4:
-			ins->opcode = OP_RCONV_TO_R8;
-			break;
-		case STACK_R8:
-			ins->opcode = OP_FMOVE;
-			break;
-		}
-		break;
-	case MONO_CEE_CONV_OVF_I1:
-	case MONO_CEE_CONV_OVF_U1:
-	case MONO_CEE_CONV_OVF_I2:
-	case MONO_CEE_CONV_OVF_U2:
-	case MONO_CEE_CONV_OVF_I4:
-	case MONO_CEE_CONV_OVF_U4:
-		ins->type = STACK_I4;
-		ins->opcode += ovf3ops_op_map [src1->type];
-		break;
-	case MONO_CEE_CONV_OVF_I_UN:
-	case MONO_CEE_CONV_OVF_U_UN:
-		ins->type = STACK_PTR;
-		ins->opcode += ovf2ops_op_map [src1->type];
-		break;
-	case MONO_CEE_CONV_OVF_I1_UN:
-	case MONO_CEE_CONV_OVF_I2_UN:
-	case MONO_CEE_CONV_OVF_I4_UN:
-	case MONO_CEE_CONV_OVF_U1_UN:
-	case MONO_CEE_CONV_OVF_U2_UN:
-	case MONO_CEE_CONV_OVF_U4_UN:
-		ins->type = STACK_I4;
-		ins->opcode += ovf2ops_op_map [src1->type];
-		break;
-	case MONO_CEE_CONV_U:
-		ins->type = STACK_PTR;
-		switch (src1->type) {
-		case STACK_I4:
-			ins->opcode = OP_ICONV_TO_U;
-			break;
-		case STACK_PTR:
-		case STACK_MP:
-		case STACK_OBJ:
-#if TARGET_SIZEOF_VOID_P == 8
-			ins->opcode = OP_LCONV_TO_U;
-#else
-			ins->opcode = OP_MOVE;
-#endif
-			break;
-		case STACK_I8:
-			ins->opcode = OP_LCONV_TO_U;
-			break;
-		case STACK_R8:
-			if (TARGET_SIZEOF_VOID_P == 8)
-				ins->opcode = OP_FCONV_TO_U8;
-			else
-				ins->opcode = OP_FCONV_TO_U4;
-			break;
-		case STACK_R4:
-			if (TARGET_SIZEOF_VOID_P == 8)
-				ins->opcode = OP_RCONV_TO_U8;
-			else
-				ins->opcode = OP_RCONV_TO_U4;
-			break;
-		}
-		break;
-	case MONO_CEE_CONV_I8:
-	case MONO_CEE_CONV_U8:
-		ins->type = STACK_I8;
-		ins->opcode += unops_op_map [src1->type];
-		break;
-	case MONO_CEE_CONV_OVF_I8:
-	case MONO_CEE_CONV_OVF_U8:
-		ins->type = STACK_I8;
-		ins->opcode += ovf3ops_op_map [src1->type];
-		break;
-	case MONO_CEE_CONV_OVF_U8_UN:
-	case MONO_CEE_CONV_OVF_I8_UN:
-		ins->type = STACK_I8;
-		ins->opcode += ovf2ops_op_map [src1->type];
-		break;
-	case MONO_CEE_CONV_R4:
-		ins->type = GINT_TO_UINT8 (cfg->r4_stack_type);
-		ins->opcode += unops_op_map [src1->type];
-		break;
-	case MONO_CEE_CONV_R8:
-		ins->type = STACK_R8;
-		ins->opcode += unops_op_map [src1->type];
-		break;
-	case OP_CKFINITE:
-		ins->type = STACK_R8;
-		break;
-	case MONO_CEE_CONV_U2:
-	case MONO_CEE_CONV_U1:
-		ins->type = STACK_I4;
-		ins->opcode += ovfops_op_map [src1->type];
-		break;
-	case MONO_CEE_CONV_I:
-	case MONO_CEE_CONV_OVF_I:
-	case MONO_CEE_CONV_OVF_U:
-		ins->type = STACK_PTR;
-		ins->opcode += ovfops_op_map [src1->type];
-		switch (ins->opcode) {
-		case OP_FCONV_TO_I:
-			ins->opcode = TARGET_SIZEOF_VOID_P == 4 ? OP_FCONV_TO_I4 : OP_FCONV_TO_I8;
-			break;
-		case OP_RCONV_TO_I:
-			ins->opcode = TARGET_SIZEOF_VOID_P == 4 ? OP_RCONV_TO_I4 : OP_RCONV_TO_I8;
-			break;
-		default:
-			break;
-		}
-		break;
-	case MONO_CEE_ADD_OVF:
-	case MONO_CEE_ADD_OVF_UN:
-	case MONO_CEE_MUL_OVF:
-	case MONO_CEE_MUL_OVF_UN:
-	case MONO_CEE_SUB_OVF:
-	case MONO_CEE_SUB_OVF_UN:
-		ins->type = bin_num_table [src1->type] [src2->type];
-		ins->opcode += ovfops_op_map [src1->type];
-		if (ins->type == STACK_R8)
-			ins->type = STACK_INV;
-		break;
-	case OP_LOAD_MEMBASE:
-		ins->type = STACK_PTR;
-		break;
-	case OP_LOADI1_MEMBASE:
-	case OP_LOADU1_MEMBASE:
-	case OP_LOADI2_MEMBASE:
-	case OP_LOADU2_MEMBASE:
-	case OP_LOADI4_MEMBASE:
-	case OP_LOADU4_MEMBASE:
-		ins->type = STACK_PTR;
-		break;
-	case OP_LOADI8_MEMBASE:
-		ins->type = STACK_I8;
-		break;
-	case OP_LOADR4_MEMBASE:
-		ins->type = GINT_TO_UINT8 (cfg->r4_stack_type);
-		break;
-	case OP_LOADR8_MEMBASE:
-		ins->type = STACK_R8;
-		break;
-	default:
-		g_error ("opcode 0x%04x not handled in type from op", ins->opcode);
-		break;
-	}
-	if (ins->type == STACK_MP) {
-		if (src1->type == STACK_MP)
-			ins->klass = src1->klass;
-		else
-			ins->klass = mono_defaults.object_class;
-	}
-}
-void
-mini_type_from_op (MonoCompile *cfg, MonoInst *ins, MonoInst *src1, MonoInst *src2)
-{
-	type_from_op (cfg, ins, src1, src2);
-}
-static MonoClass*
-ldind_to_type (int op)
-{
-	switch (op) {
-	case MONO_CEE_LDIND_I1: return mono_defaults.sbyte_class;
-	case MONO_CEE_LDIND_U1: return mono_defaults.byte_class;
-	case MONO_CEE_LDIND_I2: return mono_defaults.int16_class;
-	case MONO_CEE_LDIND_U2: return mono_defaults.uint16_class;
-	case MONO_CEE_LDIND_I4: return mono_defaults.int32_class;
-	case MONO_CEE_LDIND_U4: return mono_defaults.uint32_class;
-	case MONO_CEE_LDIND_I8: return mono_defaults.int64_class;
-	case MONO_CEE_LDIND_I: return mono_defaults.int_class;
-	case MONO_CEE_LDIND_R4: return mono_defaults.single_class;
-	case MONO_CEE_LDIND_R8: return mono_defaults.double_class;
-	case MONO_CEE_LDIND_REF:return mono_defaults.object_class; //FIXME we should try to return a more specific type
-	default: g_error ("Unknown ldind type %d", op);
-	}
-}
-static MonoClass*
-stind_to_type (int op)
-{
-	switch (op) {
-	case MONO_CEE_STIND_I1: return mono_defaults.sbyte_class;
-	case MONO_CEE_STIND_I2: return mono_defaults.int16_class;
-	case MONO_CEE_STIND_I4: return mono_defaults.int32_class;
-	case MONO_CEE_STIND_I8: return mono_defaults.int64_class;
-	case MONO_CEE_STIND_I: return mono_defaults.int_class;
-	case MONO_CEE_STIND_R4: return mono_defaults.single_class;
-	case MONO_CEE_STIND_R8: return mono_defaults.double_class;
-	case MONO_CEE_STIND_REF: return mono_defaults.object_class;
-	default: g_error ("Unknown stind type %d", op);
-	}
-}
-#if 0
-static const char
-param_table [STACK_MAX] [STACK_MAX] = {
-	{0},
-};
-static int
-check_values_to_signature (MonoInst *args, MonoType *this_ins, MonoMethodSignature *sig)
-{
-	int i;
-	if (sig->hasthis) {
-		switch (args->type) {
-		case STACK_I4:
-		case STACK_I8:
-		case STACK_R8:
-		case STACK_VTYPE:
-		case STACK_INV:
-			return 0;
-		}
-		args++;
-	}
-	for (i = 0; i < sig->param_count; ++i) {
-		switch (args [i].type) {
-		case STACK_INV:
-			return 0;
-		case STACK_MP:
-			if (m_type_is_byref (!sig->params [i]))
-				return 0;
-			continue;
-		case STACK_OBJ:
-			if (m_type_is_byref (sig->params [i]))
-				return 0;
-			switch (m_type_is_byref (sig->params [i])) {
-			case MONO_TYPE_CLASS:
-			case MONO_TYPE_STRING:
-			case MONO_TYPE_OBJECT:
-			case MONO_TYPE_SZARRAY:
-			case MONO_TYPE_ARRAY:
-				break;
-			default:
-				return 0;
-			}
-			continue;
-		case STACK_R8:
-			if (m_type_is_byref (sig->params [i]))
-				return 0;
-			if (sig->params [i]->type != MONO_TYPE_R4 && sig->params [i]->type != MONO_TYPE_R8)
-				return 0;
-			continue;
-		case STACK_PTR:
-		case STACK_I4:
-		case STACK_I8:
-		case STACK_VTYPE:
-			break;
-		}
-		/*if (!param_table [args [i].type] [sig->params [i]->type])
-			return 0;*/
-	}
-	return 1;
-}
-#endif
-/*
- * The got_var contains the address of the Global Offset Table when AOT
- * compiling.
- */
-MonoInst *
-mono_get_got_var (MonoCompile *cfg)
-{
-	if (!cfg->compile_aot || !cfg->backend->need_got_var || cfg->llvm_only)
-		return NULL;
-	if (!cfg->got_var) {
-		cfg->got_var = mono_compile_create_var (cfg, mono_get_int_type (), OP_LOCAL);
-	}
-	return cfg->got_var;
-}
-static void
-mono_create_rgctx_var (MonoCompile *cfg)
-{
-	if (!cfg->rgctx_var) {
-		cfg->rgctx_var = mono_compile_create_var (cfg, mono_get_int_type (), OP_LOCAL);
-		/* force the var to be stack allocated */
-		if (!COMPILE_LLVM (cfg))
-			cfg->rgctx_var->flags |= MONO_INST_VOLATILE;
-		if (cfg->verbose_level > 2) {
-			printf ("\trgctx : ");
-			mono_print_ins (cfg->rgctx_var);
-		}
-	}
-}
-static MonoInst *
-mono_get_mrgctx_var (MonoCompile *cfg)
-{
-	g_assert (cfg->gshared);
-	mono_create_rgctx_var (cfg);
-	return cfg->rgctx_var;
-}
-static MonoInst *
-mono_get_vtable_var (MonoCompile *cfg)
-{
-	g_assert (cfg->gshared);
-	/* The mrgctx and the vtable are stored in the same var */
-	mono_create_rgctx_var (cfg);
-	return cfg->rgctx_var;
-}
-static MonoType*
-type_from_stack_type (MonoInst *ins) {
-	switch (ins->type) {
-	case STACK_I4: return mono_get_int32_type ();
-	case STACK_I8: return m_class_get_byval_arg (mono_defaults.int64_class);
-	case STACK_PTR: return mono_get_int_type ();
-	case STACK_R4: return m_class_get_byval_arg (mono_defaults.single_class);
-	case STACK_R8: return m_class_get_byval_arg (mono_defaults.double_class);
-	case STACK_MP:
-		return m_class_get_this_arg (ins->klass);
-	case STACK_OBJ: return mono_get_object_type ();
-	case STACK_VTYPE: return m_class_get_byval_arg (ins->klass);
-	default:
-		g_error ("stack type %d to monotype not handled\n", ins->type);
-	}
-	return NULL;
-}
-MonoStackType
-mini_type_to_stack_type (MonoCompile *cfg, MonoType *t)
-{
-	t = mini_type_get_underlying_type (t);
-	switch (t->type) {
-	case MONO_TYPE_I1:
-	case MONO_TYPE_U1:
-	case MONO_TYPE_I2:
-	case MONO_TYPE_U2:
-	case MONO_TYPE_I4:
-	case MONO_TYPE_U4:
-		return STACK_I4;
-	case MONO_TYPE_I:
-	case MONO_TYPE_U:
-	case MONO_TYPE_PTR:
-	case MONO_TYPE_FNPTR:
-		return STACK_PTR;
-	case MONO_TYPE_CLASS:
-	case MONO_TYPE_STRING:
-	case MONO_TYPE_OBJECT:
-	case MONO_TYPE_SZARRAY:
-	case MONO_TYPE_ARRAY:
-		return STACK_OBJ;
-	case MONO_TYPE_I8:
-	case MONO_TYPE_U8:
-		return STACK_I8;
-	case MONO_TYPE_R4:
-		return (MonoStackType)cfg->r4_stack_type;
-	case MONO_TYPE_R8:
-		return STACK_R8;
-	case MONO_TYPE_VALUETYPE:
-	case MONO_TYPE_TYPEDBYREF:
-		return STACK_VTYPE;
-	case MONO_TYPE_GENERICINST:
-		if (mono_type_generic_inst_is_valuetype (t))
-			return STACK_VTYPE;
-		else
-			return STACK_OBJ;
-		break;
-	default:
-		g_assert_not_reached ();
-	}
-	return (MonoStackType)-1;
-}
-static MonoClass*
-array_access_to_klass (int opcode)
-{
-	switch (opcode) {
-	case MONO_CEE_LDELEM_U1:
-		return mono_defaults.byte_class;
-	case MONO_CEE_LDELEM_U2:
-		return mono_defaults.uint16_class;
-	case MONO_CEE_LDELEM_I:
-	case MONO_CEE_STELEM_I:
-		return mono_defaults.int_class;
-	case MONO_CEE_LDELEM_I1:
-	case MONO_CEE_STELEM_I1:
-		return mono_defaults.sbyte_class;
-	case MONO_CEE_LDELEM_I2:
-	case MONO_CEE_STELEM_I2:
-		return mono_defaults.int16_class;
-	case MONO_CEE_LDELEM_I4:
-	case MONO_CEE_STELEM_I4:
-		return mono_defaults.int32_class;
-	case MONO_CEE_LDELEM_U4:
-		return mono_defaults.uint32_class;
-	case MONO_CEE_LDELEM_I8:
-	case MONO_CEE_STELEM_I8:
-		return mono_defaults.int64_class;
-	case MONO_CEE_LDELEM_R4:
-	case MONO_CEE_STELEM_R4:
-		return mono_defaults.single_class;
-	case MONO_CEE_LDELEM_R8:
-	case MONO_CEE_STELEM_R8:
-		return mono_defaults.double_class;
-	case MONO_CEE_LDELEM_REF:
-	case MONO_CEE_STELEM_REF:
-		return mono_defaults.object_class;
-	default:
-		g_assert_not_reached ();
-	}
-	return NULL;
-}
-/*
- * We try to share variables when possible
- */
-static MonoInst *
-mono_compile_get_interface_var (MonoCompile *cfg, int slot, MonoInst *ins)
-{
-	MonoInst *res;
-	int pos, vnum;
-	MonoType *type;
-	type = type_from_stack_type (ins);
-	/* inlining can result in deeper stacks */
-	if (cfg->inline_depth || slot >= cfg->header->max_stack)
-		return mono_compile_create_var (cfg, type, OP_LOCAL);
-	pos = ins->type - 1 + slot * STACK_MAX;
-	switch (ins->type) {
-	case STACK_I4:
-	case STACK_I8:
-	case STACK_R8:
-	case STACK_PTR:
-	case STACK_MP:
-	case STACK_OBJ:
-		if ((vnum = cfg->intvars [pos]))
-			return cfg->varinfo [vnum];
-		res = mono_compile_create_var (cfg, type, OP_LOCAL);
-		cfg->intvars [pos] = GTMREG_TO_UINT16 (res->inst_c0);
-		break;
-	default:
-		res = mono_compile_create_var (cfg, type, OP_LOCAL);
-	}
-	return res;
-}
-static void
-mono_save_token_info (MonoCompile *cfg, MonoImage *image, guint32 token, gpointer key)
-{
-	/*
-	 * Don't use this if a generic_context is set, since that means AOT can't
-	 * look up the method using just the image+token.
-	 * table == 0 means this is a reference made from a wrapper.
-	 */
-	if (cfg->compile_aot && !cfg->generic_context && (mono_metadata_token_table (token) > 0)) {
-		MonoJumpInfoToken *jump_info_token = (MonoJumpInfoToken *)mono_mempool_alloc0 (cfg->mempool, sizeof (MonoJumpInfoToken));
-		jump_info_token->image = image;
-		jump_info_token->token = token;
-		g_hash_table_insert (cfg->token_info_hash, key, jump_info_token);
-	}
-}
-/*
- * This function is called to handle items that are left on the evaluation stack
- * at basic block boundaries. What happens is that we save the values to local variables
- * and we reload them later when first entering the target basic block (with the
- * handle_loaded_temps () function).
- * A single joint point will use the same variables (stored in the array bb->out_stack or
- * bb->in_stack, if the basic block is before or after the joint point).
- *
- * This function needs to be called _before_ emitting the last instruction of
- * the bb (i.e. before emitting a branch).
- * If the stack merge fails at a join point, cfg->unverifiable is set.
- */
-static void
-handle_stack_args (MonoCompile *cfg, MonoInst **sp, int count)
-{
-	MonoBasicBlock *bb = cfg->cbb;
-	MonoBasicBlock *outb;
-	MonoInst *inst, **locals;
-	gboolean found;
-	if (!count)
-		return;
-	if (cfg->verbose_level > 3)
-		printf ("%d item(s) on exit from B%d\n", count, bb->block_num);
-	if (!bb->out_scount) {
-		bb->out_scount = GINT_TO_UINT16 (count);
-		found = FALSE;
-		for (gint16 i = 0; i < bb->out_count; ++i) {
-			outb = bb->out_bb [i];
-			/* exception handlers are linked, but they should not be considered for stack args */
-			if (outb->flags & BB_EXCEPTION_HANDLER)
-				continue;
-			if (outb->in_stack) {
-				found = TRUE;
-				bb->out_stack = outb->in_stack;
-				break;
-			}
-		}
-		if (!found) {
-			bb->out_stack = (MonoInst **)mono_mempool_alloc (cfg->mempool, sizeof (MonoInst*) * count);
-			for (int i = 0; i < count; ++i) {
-				/*
-				 * try to reuse temps already allocated for this purpouse, if they occupy the same
-				 * stack slot and if they are of the same type.
-				 * This won't cause conflicts since if 'local' is used to
-				 * store one of the values in the in_stack of a bblock, then
-				 * the same variable will be used for the same outgoing stack
-				 * slot as well.
-				 * This doesn't work when inlining methods, since the bblocks
-				 * in the inlined methods do not inherit their in_stack from
-				 * the bblock they are inlined to. See bug #58863 for an
-				 * example.
-				 */
-				bb->out_stack [i] = mono_compile_get_interface_var (cfg, i, sp [i]);
-			}
-		}
-	}
-	for (gint16 i = 0; i < bb->out_count; ++i) {
-		outb = bb->out_bb [i];
-		/* exception handlers are linked, but they should not be considered for stack args */
-		if (outb->flags & BB_EXCEPTION_HANDLER)
-			continue;
-		if (outb->in_scount) {
-			if (outb->in_scount != bb->out_scount) {
-				cfg->unverifiable = TRUE;
-				return;
-			}
-			continue; /* check they are the same locals */
-		}
-		outb->in_scount = GINT_TO_UINT16 (count);
-		outb->in_stack = bb->out_stack;
-	}
-	locals = bb->out_stack;
-	cfg->cbb = bb;
-	for (int i = 0; i < count; ++i) {
-		sp [i] = convert_value (cfg, locals [i]->inst_vtype, sp [i]);
-		EMIT_NEW_TEMPSTORE (cfg, inst, locals [i]->inst_c0, sp [i]);
-		inst->cil_code = sp [i]->cil_code;
-		sp [i] = locals [i];
-		if (cfg->verbose_level > 3)
-			printf ("storing %d to temp %d\n", i, (int)locals [i]->inst_c0);
-	}
-	/*
-	 * It is possible that the out bblocks already have in_stack assigned, and
-	 * the in_stacks differ. In this case, we will store to all the different
-	 * in_stacks.
-	 */
-	found = TRUE;
-	gint16 bindex = 0;
-	while (found) {
-		/* Find a bblock which has a different in_stack */
-		found = FALSE;
-		while (bindex < bb->out_count) {
-			outb = bb->out_bb [bindex];
-			/* exception handlers are linked, but they should not be considered for stack args */
-			if (outb->flags & BB_EXCEPTION_HANDLER) {
-				bindex++;
-				continue;
-			}
-			if (outb->in_stack != locals) {
-				for (int i = 0; i < count; ++i) {
-					sp [i] = convert_value (cfg, outb->in_stack [i]->inst_vtype, sp [i]);
-					EMIT_NEW_TEMPSTORE (cfg, inst, outb->in_stack [i]->inst_c0, sp [i]);
-					inst->cil_code = sp [i]->cil_code;
-					sp [i] = locals [i];
-					if (cfg->verbose_level > 3)
-						printf ("storing %d to temp %d\n", i, (int)outb->in_stack [i]->inst_c0);
-				}
-				locals = outb->in_stack;
-				found = TRUE;
-				break;
-			}
-			bindex ++;
-		}
-	}
-}
-MonoInst*
-mini_emit_runtime_constant (MonoCompile *cfg, MonoJumpInfoType patch_type, gpointer data)
-{
-	MonoInst *ins;
-	if (cfg->compile_aot) {
-MONO_DISABLE_WARNING (4306) // 'type cast': conversion from 'MonoJumpInfoType' to 'MonoInst *' of greater size
-		EMIT_NEW_AOTCONST (cfg, ins, patch_type, data);
-MONO_RESTORE_WARNING
-	} else {
-		MonoJumpInfo ji;
-		gpointer target;
-		ERROR_DECL (error);
-		ji.type = patch_type;
-		ji.data.target = data;
-		target = mono_resolve_patch_target_ext (cfg->mem_manager, NULL, NULL, &ji, FALSE, error);
-		mono_error_assert_ok (error);
-		EMIT_NEW_PCONST (cfg, ins, target);
-	}
-	return ins;
-}
-static MonoInst*
-mono_create_fast_tls_getter (MonoCompile *cfg, MonoTlsKey key)
-{
-	if (cfg->compile_aot)
-		return NULL;
-	int tls_offset = mono_tls_get_tls_offset (key);
-	if (tls_offset != -1 && mono_arch_have_fast_tls ()) {
-		MonoInst *ins;
-		MONO_INST_NEW (cfg, ins, OP_TLS_GET);
-		ins->dreg = mono_alloc_preg (cfg);
-		ins->inst_offset = tls_offset;
-		return ins;
-	}
-	return NULL;
-}
-static MonoInst*
-mono_create_tls_get (MonoCompile *cfg, MonoTlsKey key)
-{
-	MonoInst *fast_tls = NULL;
-	if (!mini_debug_options.use_fallback_tls)
-		fast_tls = mono_create_fast_tls_getter (cfg, key);
-	if (fast_tls) {
-		MONO_ADD_INS (cfg->cbb, fast_tls);
-		return fast_tls;
-	}
-	const MonoJitICallId jit_icall_id = mono_get_tls_key_to_jit_icall_id (key);
-	if (cfg->compile_aot && !cfg->llvm_only) {
-		MonoInst *addr;
-		/*
-		 * tls getters are critical pieces of code and we don't want to resolve them
-		 * through the standard plt/tramp mechanism since we might expose ourselves
-		 * to crashes and infinite recursions.
-		 * Therefore the NOCALL part of MONO_PATCH_INFO_JIT_ICALL_ADDR_NOCALL, FALSE in is_plt_patch.
-		 */
-		EMIT_NEW_AOTCONST (cfg, addr, MONO_PATCH_INFO_JIT_ICALL_ADDR_NOCALL, GUINT_TO_POINTER (jit_icall_id));
-		return mini_emit_calli (cfg, mono_icall_sig_ptr, NULL, addr, NULL, NULL);
-	} else {
-		return mono_emit_jit_icall_id (cfg, jit_icall_id, NULL);
-	}
-}
-/*
- * emit_push_lmf:
- *
- *   Emit IR to push the current LMF onto the LMF stack.
- */
-static void
-emit_push_lmf (MonoCompile *cfg)
-{
-	/*
-	 * Emit IR to push the LMF:
-	 * lmf_addr = <lmf_addr from tls>
-	 * lmf->lmf_addr = lmf_addr
-	 * lmf->prev_lmf = *lmf_addr
-	 * *lmf_addr = lmf
-	 */
-	MonoInst *ins, *lmf_ins;
-	if (!cfg->lmf_ir)
-		return;
-	int lmf_reg, prev_lmf_reg;
-	/*
-	 * Store lmf_addr in a variable, so it can be allocated to a global register.
-	 */
-	if (!cfg->lmf_addr_var)
-		cfg->lmf_addr_var = mono_compile_create_var (cfg, mono_get_int_type (), OP_LOCAL);
-	if (!cfg->lmf_var) {
-		MonoInst *lmf_var = mono_compile_create_var (cfg, mono_get_int_type (), OP_LOCAL);
-		lmf_var->flags |= MONO_INST_VOLATILE;
-		lmf_var->flags |= MONO_INST_LMF;
-		cfg->lmf_var = lmf_var;
-	}
-	lmf_ins = mono_create_tls_get (cfg, TLS_KEY_LMF_ADDR);
-	g_assert (lmf_ins);
-	lmf_ins->dreg = cfg->lmf_addr_var->dreg;
-	EMIT_NEW_VARLOADA (cfg, ins, cfg->lmf_var, NULL);
-	lmf_reg = ins->dreg;
-	prev_lmf_reg = alloc_preg (cfg);
-	/* Save previous_lmf */
-	EMIT_NEW_LOAD_MEMBASE (cfg, ins, OP_LOAD_MEMBASE, prev_lmf_reg, cfg->lmf_addr_var->dreg, 0);
-	if (cfg->deopt)
-		/* Mark this as an LMFExt */
-		EMIT_NEW_BIALU_IMM (cfg, ins, OP_POR_IMM, prev_lmf_reg, prev_lmf_reg, 2);
-	EMIT_NEW_STORE_MEMBASE (cfg, ins, OP_STORE_MEMBASE_REG, lmf_reg, MONO_STRUCT_OFFSET (MonoLMF, previous_lmf), prev_lmf_reg);
-	/* Set new lmf */
-	EMIT_NEW_STORE_MEMBASE (cfg, ins, OP_STORE_MEMBASE_REG, cfg->lmf_addr_var->dreg, 0, lmf_reg);
-}
-/*
- * emit_pop_lmf:
- *
- *   Emit IR to pop the current LMF from the LMF stack.
- */
-static void
-emit_pop_lmf (MonoCompile *cfg)
-{
-	int lmf_reg, lmf_addr_reg;
-	MonoInst *ins;
-	if (!cfg->lmf_ir)
-		return;
- 	EMIT_NEW_VARLOADA (cfg, ins, cfg->lmf_var, NULL);
- 	lmf_reg = ins->dreg;
-	int prev_lmf_reg;
-	/*
-	 * Emit IR to pop the LMF:
-	 * *(lmf->lmf_addr) = lmf->prev_lmf
-	 */
-	/* This could be called before emit_push_lmf () */
-	if (!cfg->lmf_addr_var)
-		cfg->lmf_addr_var = mono_compile_create_var (cfg, mono_get_int_type (), OP_LOCAL);
-	lmf_addr_reg = cfg->lmf_addr_var->dreg;
-	prev_lmf_reg = alloc_preg (cfg);
-	EMIT_NEW_LOAD_MEMBASE (cfg, ins, OP_LOAD_MEMBASE, prev_lmf_reg, lmf_reg, MONO_STRUCT_OFFSET (MonoLMF, previous_lmf));
-	if (cfg->deopt)
-		/* Clear out the bit set by push_lmf () to mark this as LMFExt */
-		EMIT_NEW_BIALU_IMM (cfg, ins, OP_PXOR_IMM, prev_lmf_reg, prev_lmf_reg, 2);
-	EMIT_NEW_STORE_MEMBASE (cfg, ins, OP_STORE_MEMBASE_REG, lmf_addr_reg, 0, prev_lmf_reg);
-}
-/*
- * target_type_is_incompatible:
- * @cfg: MonoCompile context
- *
- * Check that the item @arg on the evaluation stack can be stored
- * in the target type (can be a local, or field, etc).
- * The cfg arg can be used to check if we need verification or just
- * validity checks.
- *
- * Returns: non-0 value if arg can't be stored on a target.
- */
-static int
-target_type_is_incompatible (MonoCompile *cfg, MonoType *target, MonoInst *arg)
-{
-	MonoType *simple_type;
-	MonoClass *klass;
-	if (m_type_is_byref (target)) {
-		/* FIXME: check that the pointed to types match */
-		if (arg->type == STACK_MP) {
-			/* This is needed to handle gshared types + ldaddr. We lower the types so we can handle enums and other typedef-like types. */
-			MonoClass *target_class_lowered = mono_class_from_mono_type_internal (mini_get_underlying_type (m_class_get_byval_arg (mono_class_from_mono_type_internal (target))));
-			MonoClass *source_class_lowered = mono_class_from_mono_type_internal (mini_get_underlying_type (m_class_get_byval_arg (arg->klass)));
-			/* if the target is native int& or X* or same type */
-			if (target->type == MONO_TYPE_I || target->type == MONO_TYPE_PTR || target_class_lowered == source_class_lowered)
-				return 0;
-			/* Both are primitive type byrefs and the source points to a larger type that the destination */
-			if (MONO_TYPE_IS_PRIMITIVE_SCALAR (m_class_get_byval_arg (target_class_lowered)) && MONO_TYPE_IS_PRIMITIVE_SCALAR (m_class_get_byval_arg (source_class_lowered)) &&
-				mono_class_instance_size (target_class_lowered) <= mono_class_instance_size (source_class_lowered))
-				return 0;
-			return 1;
-		}
-		if (arg->type == STACK_PTR)
-			return 0;
-		return 1;
-	}
-	simple_type = mini_get_underlying_type (target);
-	switch (simple_type->type) {
-	case MONO_TYPE_VOID:
-		return 1;
-	case MONO_TYPE_I1:
-	case MONO_TYPE_U1:
-	case MONO_TYPE_I2:
-	case MONO_TYPE_U2:
-	case MONO_TYPE_I4:
-	case MONO_TYPE_U4:
-		if (arg->type != STACK_I4 && arg->type != STACK_PTR)
-			return 1;
-		return 0;
-	case MONO_TYPE_PTR:
-		/* STACK_MP is needed when setting pinned locals */
-		if (arg->type != STACK_I4 && arg->type != STACK_PTR && arg->type != STACK_MP)
-#if SIZEOF_VOID_P == 8
-			if (arg->type != STACK_I8)
-#endif
-				return 1;
-		return 0;
-	case MONO_TYPE_I:
-	case MONO_TYPE_U:
-	case MONO_TYPE_FNPTR:
-		/*
-		 * Some opcodes like ldloca returns 'transient pointers' which can be stored in
-		 * in native int. (#688008).
-		 */
-		if (arg->type != STACK_I4 && arg->type != STACK_PTR && arg->type != STACK_MP)
-			return 1;
-		return 0;
-	case MONO_TYPE_CLASS:
-	case MONO_TYPE_STRING:
-	case MONO_TYPE_OBJECT:
-	case MONO_TYPE_SZARRAY:
-	case MONO_TYPE_ARRAY:
-		if (arg->type != STACK_OBJ)
-			return 1;
-		/* FIXME: check type compatibility */
-		return 0;
-	case MONO_TYPE_I8:
-	case MONO_TYPE_U8:
-		if (arg->type != STACK_I8)
-#if SIZEOF_VOID_P == 8
-			if (arg->type != STACK_PTR)
-#endif
-				return 1;
-		return 0;
-	case MONO_TYPE_R4:
-		if (arg->type != cfg->r4_stack_type)
-			return 1;
-		return 0;
-	case MONO_TYPE_R8:
-		if (arg->type != STACK_R8)
-			return 1;
-		return 0;
-	case MONO_TYPE_VALUETYPE:
-		if (arg->type != STACK_VTYPE)
-			return 1;
-		klass = mono_class_from_mono_type_internal (simple_type);
-		if (klass != arg->klass)
-			return 1;
-		return 0;
-	case MONO_TYPE_TYPEDBYREF:
-		if (arg->type != STACK_VTYPE)
-			return 1;
-		klass = mono_class_from_mono_type_internal (simple_type);
-		if (klass != arg->klass)
-			return 1;
-		return 0;
-	case MONO_TYPE_GENERICINST:
-		if (mono_type_generic_inst_is_valuetype (simple_type)) {
-			MonoClass *target_class;
-			if (arg->type != STACK_VTYPE)
-				return 1;
-			klass = mono_class_from_mono_type_internal (simple_type);
-			target_class = mono_class_from_mono_type_internal (target);
-			/* The second cases is needed when doing partial sharing */
-			if (klass != arg->klass && target_class != arg->klass && target_class != mono_class_from_mono_type_internal (mini_get_underlying_type (m_class_get_byval_arg (arg->klass))))
-				return 1;
-			return 0;
-		} else {
-			if (arg->type != STACK_OBJ)
-				return 1;
-			/* FIXME: check type compatibility */
-			return 0;
-		}
-	case MONO_TYPE_VAR:
-	case MONO_TYPE_MVAR:
-		g_assert (cfg->gshared);
-		if (mini_type_var_is_vt (simple_type)) {
-			if (arg->type != STACK_VTYPE)
-				return 1;
-		} else {
-			if (arg->type != STACK_OBJ)
-				return 1;
-		}
-		return 0;
-	default:
-		g_error ("unknown type 0x%02x in target_type_is_incompatible", simple_type->type);
-	}
-	return 1;
-}
-/*
- * convert_value:
- *
- *   Emit some implicit conversions which are not part of the .net spec, but are allowed by MS.NET.
- */
-static MonoInst*
-convert_value (MonoCompile *cfg, MonoType *type, MonoInst *ins)
-{
-	if (!cfg->r4fp)
-		return ins;
-	type = mini_get_underlying_type (type);
-	switch (type->type) {
-	case MONO_TYPE_R4:
-		if (ins->type == STACK_R8) {
-			int dreg = alloc_freg (cfg);
-			MonoInst *conv;
-			EMIT_NEW_UNALU (cfg, conv, OP_FCONV_TO_R4, dreg, ins->dreg);
-			conv->type = STACK_R4;
-			return conv;
-		}
-		break;
-	case MONO_TYPE_R8:
-		if (ins->type == STACK_R4) {
-			int dreg = alloc_freg (cfg);
-			MonoInst *conv;
-			EMIT_NEW_UNALU (cfg, conv, OP_RCONV_TO_R8, dreg, ins->dreg);
-			conv->type = STACK_R8;
-			return conv;
-		}
-		break;
-	default:
-		break;
-	}
-	return ins;
-}
-/*
- * Prepare arguments for passing to a function call.
- * Return a non-zero value if the arguments can't be passed to the given
- * signature.
- * The type checks are not yet complete and some conversions may need
- * casts on 32 or 64 bit architectures.
- *
- * FIXME: implement this using target_type_is_incompatible ()
- */
-static gboolean
-check_call_signature (MonoCompile *cfg, MonoMethodSignature *sig, MonoInst **args)
-{
-	MonoType *simple_type;
-	int i;
-	if (sig->hasthis) {
-		if (args [0]->type != STACK_OBJ && args [0]->type != STACK_MP && args [0]->type != STACK_PTR)
-			return TRUE;
-		args++;
-	}
-	for (i = 0; i < sig->param_count; ++i) {
-		if (m_type_is_byref (sig->params [i])) {
-			if (args [i]->type != STACK_MP && args [i]->type != STACK_PTR)
-				return TRUE;
-			continue;
-		}
-		simple_type = mini_get_underlying_type (sig->params [i]);
-handle_enum:
-		switch (simple_type->type) {
-		case MONO_TYPE_VOID:
-			return TRUE;
-		case MONO_TYPE_I1:
-		case MONO_TYPE_U1:
-		case MONO_TYPE_I2:
-		case MONO_TYPE_U2:
-		case MONO_TYPE_I4:
-		case MONO_TYPE_U4:
-			if (args [i]->type != STACK_I4 && args [i]->type != STACK_PTR)
-				return TRUE;
-			continue;
-		case MONO_TYPE_I:
-		case MONO_TYPE_U:
-			if (args [i]->type != STACK_I4 && args [i]->type != STACK_PTR && args [i]->type != STACK_MP && args [i]->type != STACK_OBJ)
-				return TRUE;
-			continue;
-		case MONO_TYPE_PTR:
-		case MONO_TYPE_FNPTR:
-			if (args [i]->type != STACK_I4 && !(SIZEOF_VOID_P == 8 && args [i]->type == STACK_I8) &&
-				args [i]->type != STACK_PTR && args [i]->type != STACK_MP && args [i]->type != STACK_OBJ)
-				return TRUE;
-			continue;
-		case MONO_TYPE_CLASS:
-		case MONO_TYPE_STRING:
-		case MONO_TYPE_OBJECT:
-		case MONO_TYPE_SZARRAY:
-		case MONO_TYPE_ARRAY:
-			if (args [i]->type != STACK_OBJ)
-				return TRUE;
-			continue;
-		case MONO_TYPE_I8:
-		case MONO_TYPE_U8:
-			if (args [i]->type != STACK_I8 &&
-				!(SIZEOF_VOID_P == 8 && (args [i]->type == STACK_I4 || args [i]->type == STACK_PTR)))
-				return TRUE;
-			continue;
-		case MONO_TYPE_R4:
-			if (args [i]->type != cfg->r4_stack_type)
-				return TRUE;
-			continue;
-		case MONO_TYPE_R8:
-			if (args [i]->type != STACK_R8)
-				return TRUE;
-			continue;
-		case MONO_TYPE_VALUETYPE:
-			if (m_class_is_enumtype (simple_type->data.klass)) {
-				simple_type = mono_class_enum_basetype_internal (simple_type->data.klass);
-				goto handle_enum;
-			}
-			if (args [i]->type != STACK_VTYPE)
-				return TRUE;
-			continue;
-		case MONO_TYPE_TYPEDBYREF:
-			if (args [i]->type != STACK_VTYPE)
-				return TRUE;
-			continue;
-		case MONO_TYPE_GENERICINST:
-			simple_type = m_class_get_byval_arg (simple_type->data.generic_class->container_class);
-			goto handle_enum;
-		case MONO_TYPE_VAR:
-		case MONO_TYPE_MVAR:
-			/* gsharedvt */
-			if (args [i]->type != STACK_VTYPE)
-				return TRUE;
-			continue;
-		default:
-			g_error ("unknown type 0x%02x in check_call_signature",
-				 simple_type->type);
-		}
-	}
-	return FALSE;
-}
-MonoJumpInfo *
-mono_patch_info_new (MonoMemPool *mp, int ip, MonoJumpInfoType type, gconstpointer target)
-{
-	MonoJumpInfo *ji = (MonoJumpInfo *)mono_mempool_alloc (mp, sizeof (MonoJumpInfo));
-	ji->ip.i = ip;
-	ji->type = type;
-	ji->data.target = target;
-	return ji;
-}
-int
-mini_class_check_context_used (MonoCompile *cfg, MonoClass *klass)
-{
-	if (cfg->gshared)
-		return mono_class_check_context_used (klass);
-	else
-		return 0;
-}
-int
-mini_method_check_context_used (MonoCompile *cfg, MonoMethod *method)
-{
-	if (cfg->gshared)
-		return mono_method_check_context_used (method);
-	else
-		return 0;
-}
-/*
- * need_mrgctx_arg:
- *
- *   Check whenever the mrgctx needs to be passed when calling CMETHOD.
- */
-static gboolean
-need_mrgctx_arg (MonoCompile *cfg, MonoMethod *cmethod)
-{
-	gboolean pass_mrgctx = FALSE;
-	if (((cmethod->flags & METHOD_ATTRIBUTE_STATIC) || m_class_is_valuetype (cmethod->klass)) &&
-		(mono_class_is_ginst (cmethod->klass) || mono_class_is_gtd (cmethod->klass))) {
-		gboolean sharable = FALSE;
-		if (mono_method_is_generic_sharable_full (cmethod, TRUE, TRUE, TRUE))
-			sharable = TRUE;
-		/*
-		 * Pass mrgctx iff target method might
-		 * be shared, which means that sharing
-		 * is enabled for its class and its
-		 * context is sharable (and it's not a
-		 * generic method).
-		 */
-		if (sharable && !(mini_method_get_context (cmethod) && mini_method_get_context (cmethod)->method_inst))
-			pass_mrgctx = TRUE;
-	}
-	if (mini_method_needs_mrgctx (cmethod)) {
-		if (mono_method_is_generic_sharable_full (cmethod, TRUE, TRUE, TRUE)) {
-			pass_mrgctx = TRUE;
-		} else {
-			if (cfg->gsharedvt && mini_is_gsharedvt_signature (mono_method_signature_internal (cmethod)))
-				pass_mrgctx = TRUE;
-		}
-	}
-	return pass_mrgctx;
-}
-static gboolean
-direct_icalls_enabled (MonoCompile *cfg, MonoMethod *method)
-{
-	if (cfg->gen_sdb_seq_points || cfg->disable_direct_icalls)
-		return FALSE;
-	if (method && cfg->compile_aot && mono_aot_direct_icalls_enabled_for_method (cfg, method))
-		return TRUE;
-	/* LLVM on amd64 can't handle calls to non-32 bit addresses */
-#ifdef TARGET_AMD64
-	if (cfg->compile_llvm && !cfg->llvm_only)
-		return FALSE;
-#endif
-	return FALSE;
-}
-MonoInst*
-mono_emit_jit_icall_by_info (MonoCompile *cfg, int il_offset, MonoJitICallInfo *info, MonoInst **args)
-{
-	/*
-	 * Call the jit icall without a wrapper if possible.
-	 * The wrapper is needed to be able to do stack walks for asynchronously suspended
-	 * threads when debugging.
-	 */
-	if (direct_icalls_enabled (cfg, NULL)) {
-		int costs;
-		if (!info->wrapper_method) {
-			info->wrapper_method = mono_marshal_get_icall_wrapper (info, TRUE);
-			mono_memory_barrier ();
-		}
-		/*
-		 * Inline the wrapper method, which is basically a call to the C icall, and
-		 * an exception check.
-		 */
-		costs = inline_method (cfg, info->wrapper_method, NULL,
-							   args, NULL, il_offset, TRUE, NULL);
-		g_assert (costs > 0);
-		g_assert (!MONO_TYPE_IS_VOID (info->sig->ret));
-		return args [0];
-	}
-	return mono_emit_jit_icall_id (cfg, mono_jit_icall_info_id (info), args);
-}
-static MonoInst*
-mono_emit_widen_call_res (MonoCompile *cfg, MonoInst *ins, MonoMethodSignature *fsig)
-{
-	if (!MONO_TYPE_IS_VOID (fsig->ret)) {
-#ifdef MONO_ARCH_LLVM_SUPPORTED
-		gboolean might_use_llvm = TRUE;
-#else
-		gboolean might_use_llvm = FALSE;
-#endif
-		if ((fsig->pinvoke || might_use_llvm) && !m_type_is_byref (fsig->ret)) {
-			int widen_op = -1;
-			/*
-			 * Native code might return non register sized integers
-			 * without initializing the upper bits.
-			 */
-			switch (mono_type_to_load_membase (cfg, fsig->ret)) {
-			case OP_LOADI1_MEMBASE:
-				widen_op = OP_ICONV_TO_I1;
-				break;
-			case OP_LOADU1_MEMBASE:
-				widen_op = OP_ICONV_TO_U1;
-				break;
-			case OP_LOADI2_MEMBASE:
-				widen_op = OP_ICONV_TO_I2;
-				break;
-			case OP_LOADU2_MEMBASE:
-				widen_op = OP_ICONV_TO_U2;
-				break;
-			default:
-				break;
-			}
-			if (widen_op != -1) {
-				int dreg = alloc_preg (cfg);
-				MonoInst *widen;
-				EMIT_NEW_UNALU (cfg, widen, widen_op, dreg, ins->dreg);
-				widen->type = ins->type;
-				ins = widen;
-			}
-		}
-	}
-	return ins;
-}
-static MonoInst*
-emit_get_rgctx_method (MonoCompile *cfg, int context_used,
-					   MonoMethod *cmethod, MonoRgctxInfoType rgctx_type);
-static void
-emit_method_access_failure (MonoCompile *cfg, MonoMethod *caller, MonoMethod *callee)
-{
-	MonoInst *args [2];
-	args [0] = emit_get_rgctx_method (cfg, mono_method_check_context_used (caller), caller, MONO_RGCTX_INFO_METHOD);
-	args [1] = emit_get_rgctx_method (cfg, mono_method_check_context_used (callee), callee, MONO_RGCTX_INFO_METHOD);
-	mono_emit_jit_icall (cfg, mono_throw_method_access, args);
-}
-static void
-emit_bad_image_failure (MonoCompile *cfg, MonoMethod *caller, MonoMethod *callee)
-{
-	mono_emit_jit_icall (cfg, mono_throw_bad_image, NULL);
-}
-static void
-emit_not_supported_failure (MonoCompile *cfg)
-{
-	mono_emit_jit_icall (cfg, mono_throw_not_supported, NULL);
-}
-static void
-emit_type_load_failure (MonoCompile* cfg, MonoClass* klass)
-{
-	MonoInst* iargs[1];
-	if (G_LIKELY (klass)) {
-		EMIT_NEW_CLASSCONST (cfg, iargs [0], klass);
-	} else {
-		EMIT_NEW_PCONST (cfg, iargs [0], NULL);
-	}
-	mono_emit_jit_icall (cfg, mono_throw_type_load, iargs);
-}
-static void
-emit_invalid_program_with_msg (MonoCompile *cfg, char *error_msg)
-{
-	MonoInst *iargs[1];
-	if (cfg->compile_aot)
-		EMIT_NEW_LDSTRLITCONST (cfg, iargs [0], error_msg);
-	else
-		EMIT_NEW_PCONST (cfg, iargs [0], error_msg);
-	mono_emit_jit_icall (cfg, mono_throw_invalid_program, iargs);
-}
-static MonoMethod*
-get_method_nofail (MonoClass *klass, const char *method_name, int num_params, int flags)
-{
-	MonoMethod *method;
-	ERROR_DECL (error);
-	method = mono_class_get_method_from_name_checked (klass, method_name, num_params, flags, error);
-	mono_error_assert_ok (error);
-	g_assertf (method, "Could not lookup method %s in %s", method_name, m_class_get_name (klass));
-	return method;
-}
-MonoMethod*
-mini_get_memcpy_method (void)
-{
-	static MonoMethod *memcpy_method = NULL;
-	if (!memcpy_method) {
-		memcpy_method = get_method_nofail (mono_defaults.string_class, "memcpy", 3, 0);
-		if (!memcpy_method)
-			g_error ("Old corlib found. Install a new one");
-	}
-	return memcpy_method;
-}
-MonoInst*
-mini_emit_storing_write_barrier (MonoCompile *cfg, MonoInst *ptr, MonoInst *value)
-{
-	MonoInst *store;
-	/*
-	 * Add a release memory barrier so the object contents are flushed
-	 * to memory before storing the reference into another object.
-	 */
-	if (!mini_debug_options.weak_memory_model)
-		mini_emit_memory_barrier (cfg, MONO_MEMORY_BARRIER_REL);
-	EMIT_NEW_STORE_MEMBASE (cfg, store, OP_STORE_MEMBASE_REG, ptr->dreg, 0, value->dreg);
-	mini_emit_write_barrier (cfg, ptr, value);
-	return store;
-}
-void
-mini_emit_write_barrier (MonoCompile *cfg, MonoInst *ptr, MonoInst *value)
-{
-	int card_table_shift_bits;
-	target_mgreg_t card_table_mask;
-	guint8 *card_table;
-	MonoInst *dummy_use;
-	int nursery_shift_bits;
-	size_t nursery_size;
-	if (!cfg->gen_write_barriers)
-		return;
-	card_table = mono_gc_get_target_card_table (&card_table_shift_bits, &card_table_mask);
-	mono_gc_get_nursery (&nursery_shift_bits, &nursery_size);
-	if (cfg->backend->have_card_table_wb && !cfg->compile_aot && card_table && nursery_shift_bits > 0 && !COMPILE_LLVM (cfg)) {
-		MonoInst *wbarrier;
-		MONO_INST_NEW (cfg, wbarrier, OP_CARD_TABLE_WBARRIER);
-		wbarrier->sreg1 = ptr->dreg;
-		wbarrier->sreg2 = value->dreg;
-		MONO_ADD_INS (cfg->cbb, wbarrier);
-	} else if (card_table) {
-		int offset_reg = alloc_preg (cfg);
-		int card_reg;
-		MonoInst *ins;
-		/*
-		 * We emit a fast light weight write barrier. This always marks cards as in the concurrent
-		 * collector case, so, for the serial collector, it might slightly slow down nursery
-		 * collections. We also expect that the host system and the target system have the same card
-		 * table configuration, which is the case if they have the same pointer size.
-		 */
-		MONO_EMIT_NEW_BIALU_IMM (cfg, OP_SHR_UN_IMM, offset_reg, ptr->dreg, card_table_shift_bits);
-		if (card_table_mask)
-			MONO_EMIT_NEW_BIALU_IMM (cfg, OP_PAND_IMM, offset_reg, offset_reg, card_table_mask);
-		/*We can't use PADD_IMM since the cardtable might end up in high addresses and amd64 doesn't support
-		 * IMM's larger than 32bits.
-		 */
-		ins = mini_emit_runtime_constant (cfg, MONO_PATCH_INFO_GC_CARD_TABLE_ADDR, NULL);
-		card_reg = ins->dreg;
-		MONO_EMIT_NEW_BIALU (cfg, OP_PADD, offset_reg, offset_reg, card_reg);
-		MONO_EMIT_NEW_STORE_MEMBASE_IMM (cfg, OP_STOREI1_MEMBASE_IMM, offset_reg, 0, 1);
-	} else {
-		MonoMethod *write_barrier = mono_gc_get_write_barrier ();
-		mono_emit_method_call (cfg, write_barrier, &ptr, NULL);
-	}
-	EMIT_NEW_DUMMY_USE (cfg, dummy_use, value);
-}
-MonoMethod*
-mini_get_memset_method (void)
-{
-	static MonoMethod *memset_method = NULL;
-	if (!memset_method) {
-		memset_method = get_method_nofail (mono_defaults.string_class, "memset", 3, 0);
-		if (!memset_method)
-			g_error ("Old corlib found. Install a new one");
-	}
-	return memset_method;
-}
-void
-mini_emit_initobj (MonoCompile *cfg, MonoInst *dest, const guchar *ip, MonoClass *klass)
-{
-	MonoInst *iargs [3];
-	int n;
-	guint32 align;
-	MonoMethod *memset_method;
-	MonoInst *size_ins = NULL;
-	MonoInst *bzero_ins = NULL;
-	static MonoMethod *bzero_method;
-	/* FIXME: Optimize this for the case when dest is an LDADDR */
-	mono_class_init_internal (klass);
-	if (mini_is_gsharedvt_klass (klass)) {
-		size_ins = mini_emit_get_gsharedvt_info_klass (cfg, klass, MONO_RGCTX_INFO_VALUE_SIZE);
-		bzero_ins = mini_emit_get_gsharedvt_info_klass (cfg, klass, MONO_RGCTX_INFO_BZERO);
-		if (!bzero_method)
-			bzero_method = get_method_nofail (mono_defaults.string_class, "bzero_aligned_1", 2, 0);
-		g_assert (bzero_method);
-		iargs [0] = dest;
-		iargs [1] = size_ins;
-		mini_emit_calli (cfg, mono_method_signature_internal (bzero_method), iargs, bzero_ins, NULL, NULL);
-		return;
-	}
-	klass = mono_class_from_mono_type_internal (mini_get_underlying_type (m_class_get_byval_arg (klass)));
-	n = mono_class_value_size (klass, &align);
-	if (n <= TARGET_SIZEOF_VOID_P * 8) {
-		mini_emit_memset (cfg, dest->dreg, 0, n, 0, align);
-	}
-	else {
-		memset_method = mini_get_memset_method ();
-		iargs [0] = dest;
-		EMIT_NEW_ICONST (cfg, iargs [1], 0);
-		EMIT_NEW_ICONST (cfg, iargs [2], n);
-		mono_emit_method_call (cfg, memset_method, iargs, NULL);
-	}
-}
-static gboolean
-context_used_is_mrgctx (MonoCompile *cfg, int context_used)
-{
-	if (mono_opt_experimental_gshared_mrgctx)
-		return context_used != 0;
-	/* gshared dim methods use an mrgctx */
-	if (mini_method_is_default_method (cfg->method))
-		return context_used != 0;
-	return context_used & MONO_GENERIC_CONTEXT_USED_METHOD;
-}
-/*
- * emit_get_rgctx:
- *
- *   Emit IR to return either the vtable or the mrgctx.
- */
-static MonoInst*
-emit_get_rgctx (MonoCompile *cfg, int context_used)
-{
-	g_assert (cfg->gshared);
-	/* Data whose context contains method type vars is stored in the mrgctx */
-	if (context_used_is_mrgctx (cfg, context_used) || cfg->gshared_info) {
-		MonoInst *mrgctx_loc, *mrgctx_var;
-		g_assert (cfg->rgctx_access == MONO_RGCTX_ACCESS_MRGCTX);
-		/*
-		if (!mini_method_is_default_method (method))
-			g_assert (method->is_inflated && mono_method_get_context (method)->method_inst);
-		*/
-		if (COMPILE_LLVM (cfg)) {
-			mrgctx_var = mono_get_mrgctx_var (cfg);
-		} else {
-			/* Volatile */
-			mrgctx_loc = mono_get_mrgctx_var (cfg);
-			g_assert (mrgctx_loc->flags & MONO_INST_VOLATILE);
-			EMIT_NEW_TEMPLOAD (cfg, mrgctx_var, mrgctx_loc->inst_c0);
-		}
-		return mrgctx_var;
-	}
-	/*
-	 * The rest of the entries are stored in vtable->runtime_generic_context so
-	 * have to return a vtable.
-	 */
-	if (cfg->rgctx_access == MONO_RGCTX_ACCESS_MRGCTX) {
-		MonoInst *mrgctx_loc, *mrgctx_var, *vtable_var;
-		int vtable_reg;
-		/* We are passed an mrgctx, return mrgctx->class_vtable */
-		if (cfg->llvm_only) {
-			mrgctx_var = mono_get_mrgctx_var (cfg);
-		} else {
-			mrgctx_loc = mono_get_mrgctx_var (cfg);
-			g_assert (mrgctx_loc->flags & MONO_INST_VOLATILE);
-			EMIT_NEW_TEMPLOAD (cfg, mrgctx_var, mrgctx_loc->inst_c0);
-		}
-		vtable_reg = alloc_preg (cfg);
-		EMIT_NEW_LOAD_MEMBASE (cfg, vtable_var, OP_LOAD_MEMBASE, vtable_reg, mrgctx_var->dreg, MONO_STRUCT_OFFSET (MonoMethodRuntimeGenericContext, class_vtable));
-		vtable_var->type = STACK_PTR;
-		return vtable_var;
-	} else {
-		MonoInst *ins, *this_ins;
-		int vtable_reg;
-		/* We are passed a this pointer, return this->vtable */
-		EMIT_NEW_VARLOAD (cfg, this_ins, cfg->this_arg, mono_get_object_type ());
-		vtable_reg = alloc_preg (cfg);
-		EMIT_NEW_LOAD_MEMBASE (cfg, ins, OP_LOAD_MEMBASE, vtable_reg, this_ins->dreg, MONO_STRUCT_OFFSET (MonoObject, vtable));
-		return ins;
-	}
-}
-static MonoJumpInfoRgctxEntry *
-mono_patch_info_rgctx_entry_new (MonoMemPool *mp, MonoMethod *method, gboolean in_mrgctx, MonoJumpInfoType patch_type, gconstpointer patch_data, MonoRgctxInfoType info_type)
-{
-	MonoJumpInfoRgctxEntry *res = (MonoJumpInfoRgctxEntry *)mono_mempool_alloc0 (mp, sizeof (MonoJumpInfoRgctxEntry));
-	if (in_mrgctx)
-		res->d.method = method;
-	else
-		res->d.klass = method->klass;
-	res->in_mrgctx = in_mrgctx;
-	res->data = (MonoJumpInfo *)mono_mempool_alloc0 (mp, sizeof (MonoJumpInfo));
-	res->data->type = patch_type;
-	res->data->data.target = patch_data;
-	res->info_type = info_type;
-	return res;
-}
-static MonoInst*
-emit_get_gsharedvt_info (MonoCompile *cfg, gpointer data, MonoRgctxInfoType rgctx_type);
-/*
- * get_gshared_info_slot:
- *
- *   Return a slot index in the mrgctx. PATCH_INFO describes a runtime structure, while
- * RGCTX_TYPE is a property of that structure.
- */
-static int
-get_gshared_info_slot (MonoCompile *cfg, MonoJumpInfo *patch_info, MonoRgctxInfoType rgctx_type)
-{
-	MonoGSharedMethodInfo *info = cfg->gshared_info;
-	int idx;
-	gpointer data;
-	g_assert (cfg->init_method_rgctx_ins);
-	g_assert (info);
-	/* The MonoRuntimeGenericContextInfoTemplate structure contains the 'resolved' patch_info, i.e. a MonoClass pointer etc. */
-	switch (patch_info->type) {
-	case MONO_PATCH_INFO_CLASS:
-		data = m_class_get_byval_arg (patch_info->data.klass);
-		break;
-	case MONO_PATCH_INFO_METHODCONST:
-	case MONO_PATCH_INFO_FIELD:
-	case MONO_PATCH_INFO_VIRT_METHOD:
-	case MONO_PATCH_INFO_DELEGATE_INFO:
-	case MONO_PATCH_INFO_GSHAREDVT_METHOD:
-	case MONO_PATCH_INFO_GSHAREDVT_CALL:
-	case MONO_PATCH_INFO_SIGNATURE:
-		data = (gpointer)patch_info->data.target;
-		break;
-	default:
-		g_assert_not_reached ();
-		break;
-	}
-	g_assert (data);
-	for (int i = 0; i < info->num_entries; ++i) {
-		if (info->entries [i].info_type == rgctx_type && info->entries [i].data == data && rgctx_type != MONO_RGCTX_INFO_LOCAL_OFFSET)
-			return i;
-	}
-	if (info->num_entries == info->count_entries) {
-		MonoRuntimeGenericContextInfoTemplate *new_entries;
-		int new_count_entries = info->count_entries ? info->count_entries * 2 : 16;
-		new_entries = (MonoRuntimeGenericContextInfoTemplate *)mono_mempool_alloc0 (cfg->mempool, sizeof (MonoRuntimeGenericContextInfoTemplate) * new_count_entries);
-		memcpy (new_entries, info->entries, sizeof (MonoRuntimeGenericContextInfoTemplate) * info->count_entries);
-		info->entries = new_entries;
-		info->count_entries = new_count_entries;
-	}
-	idx = info->num_entries;
-	info->entries [idx].info_type = rgctx_type;
-	info->entries [idx].data = data;
-	info->num_entries++;
-	return idx;
-}
-static MonoInst*
-emit_rgctx_fetch_inline (MonoCompile *cfg, MonoInst *rgctx, MonoJumpInfoRgctxEntry *entry)
-{
-	MonoInst *call;
-	MonoInst *slot_ins;
-	EMIT_NEW_AOTCONST (cfg, slot_ins, MONO_PATCH_INFO_RGCTX_SLOT_INDEX, entry);
-	if (cfg->disable_inline_rgctx_fetch || cfg->interp_entry_only) {
-		MonoInst *args [2] = { rgctx, slot_ins };
-		if (entry->in_mrgctx)
-			call = mono_emit_jit_icall (cfg, mono_fill_method_rgctx, args);
-		else
-			call = mono_emit_jit_icall (cfg, mono_fill_class_rgctx, args);
-		return call;
-	}
-	MonoBasicBlock *slowpath_bb, *end_bb;
-	MonoInst *ins, *res;
-	int rgctx_reg, res_reg;
-	/*
-	 * rgctx = vtable->runtime_generic_context;
-	 * if (rgctx) {
-	 *    val = rgctx [slot + 1];
-	 *    if (val)
-	 *       return val;
-	 * }
-	 * <slowpath>
-	 */
-	NEW_BBLOCK (cfg, end_bb);
-	NEW_BBLOCK (cfg, slowpath_bb);
-	if (entry->in_mrgctx) {
-		rgctx_reg = rgctx->dreg;
-	} else {
-		rgctx_reg = alloc_preg (cfg);
-		MONO_EMIT_NEW_LOAD_MEMBASE (cfg, rgctx_reg, rgctx->dreg, MONO_STRUCT_OFFSET (MonoVTable, runtime_generic_context));
-		MONO_EMIT_NEW_BIALU_IMM (cfg, OP_COMPARE_IMM, -1, rgctx_reg, 0);
-		MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_PBEQ, slowpath_bb);
-	}
-	int table_size = mono_class_rgctx_get_array_size (0, entry->in_mrgctx);
-	if (entry->in_mrgctx)
-		table_size -= MONO_SIZEOF_METHOD_RUNTIME_GENERIC_CONTEXT / TARGET_SIZEOF_VOID_P;
-	MONO_EMIT_NEW_BIALU_IMM (cfg, OP_COMPARE_IMM, -1, slot_ins->dreg, table_size - 1);
-	MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_PBGE, slowpath_bb);
-	int shifted_slot_reg = alloc_ireg (cfg);
-	EMIT_NEW_BIALU_IMM (cfg, ins, OP_ISHL_IMM, shifted_slot_reg, slot_ins->dreg, TARGET_SIZEOF_VOID_P == 8 ? 3 : 2);
-	int addr_reg = alloc_preg (cfg);
-	EMIT_NEW_UNALU (cfg, ins, OP_MOVE, addr_reg, rgctx_reg);
-	EMIT_NEW_BIALU (cfg, ins, OP_PADD, addr_reg, addr_reg, shifted_slot_reg);
-	int val_reg = alloc_preg (cfg);
-	MONO_EMIT_NEW_LOAD_MEMBASE (cfg, val_reg, addr_reg, TARGET_SIZEOF_VOID_P + (entry->in_mrgctx ? MONO_SIZEOF_METHOD_RUNTIME_GENERIC_CONTEXT : 0));
-	MONO_EMIT_NEW_BIALU_IMM (cfg, OP_COMPARE_IMM, -1, val_reg, 0);
-	MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_PBEQ, slowpath_bb);
-	res_reg = alloc_preg (cfg);
-	EMIT_NEW_UNALU (cfg, ins, OP_MOVE, res_reg, val_reg);
-	res = ins;
-	MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_BR, end_bb);
-	MONO_START_BB (cfg, slowpath_bb);
-	slowpath_bb->out_of_line = TRUE;
-	MonoInst *args[2] = { rgctx, slot_ins };
-	if (entry->in_mrgctx)
-		call = mono_emit_jit_icall (cfg, mono_fill_method_rgctx, args);
-	else
-		call = mono_emit_jit_icall (cfg, mono_fill_class_rgctx, args);
-	EMIT_NEW_UNALU (cfg, ins, OP_MOVE, res_reg, call->dreg);
-	MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_BR, end_bb);
-	MONO_START_BB (cfg, end_bb);
-	return res;
-}
-/*
- * emit_rgctx_fetch:
- *
- *   Emit IR to load the value of the rgctx entry ENTRY from the rgctx.
- */
-static MonoInst*
-emit_rgctx_fetch (MonoCompile *cfg, int context_used, MonoJumpInfoRgctxEntry *entry)
-{
-	MonoInst *rgctx = emit_get_rgctx (cfg, context_used);
-	if (cfg->gshared_info) {
-		MonoInst *ins;
-		int dreg, entries_reg, idx;
-		int ninlines = mono_class_rgctx_get_array_size (0, TRUE);
-		idx = get_gshared_info_slot (cfg, entry->data, entry->info_type);
-		/* The first few entries are stored inline, the rest are stored in mrgctx->entries */
-		if (idx < ninlines) {
-			/* Load mrgctx->infos [idx] */
-			dreg = alloc_preg (cfg);
-			EMIT_NEW_LOAD_MEMBASE (cfg, ins, OP_LOAD_MEMBASE, dreg, rgctx->dreg, MONO_STRUCT_OFFSET (MonoMethodRuntimeGenericContext, infos) + idx * TARGET_SIZEOF_VOID_P);
-		} else {
-			/* Load mrgctx->entries [idx - ninlines] */
-			entries_reg = alloc_preg (cfg);
-			EMIT_NEW_LOAD_MEMBASE (cfg, ins, OP_LOAD_MEMBASE, entries_reg, rgctx->dreg, MONO_STRUCT_OFFSET (MonoMethodRuntimeGenericContext, entries));
-			dreg = alloc_preg (cfg);
-			EMIT_NEW_LOAD_MEMBASE (cfg, ins, OP_LOAD_MEMBASE, dreg, entries_reg, (idx - ninlines) * TARGET_SIZEOF_VOID_P);
-		}
-		return ins;
-	}
-	if (cfg->llvm_only)
-		return emit_rgctx_fetch_inline (cfg, rgctx, entry);
-	else
-		return mini_emit_abs_call (cfg, MONO_PATCH_INFO_RGCTX_FETCH, entry, mono_icall_sig_ptr_ptr, &rgctx);
-}
-/*
- * mini_emit_get_rgctx_klass:
- *
- *   Emit IR to load the property RGCTX_TYPE of KLASS. If context_used is 0, emit
- * normal constants, else emit a load from the rgctx.
- */
-MonoInst*
-mini_emit_get_rgctx_klass (MonoCompile *cfg, int context_used,
-						   MonoClass *klass, MonoRgctxInfoType rgctx_type)
-{
-	if (!context_used) {
-		MonoInst *ins;
-		switch (rgctx_type) {
-		case MONO_RGCTX_INFO_KLASS:
-			EMIT_NEW_CLASSCONST (cfg, ins, klass);
-			return ins;
-		case MONO_RGCTX_INFO_VTABLE: {
-			MonoVTable *vtable = mono_class_vtable_checked (klass, cfg->error);
-			CHECK_CFG_ERROR;
-			EMIT_NEW_VTABLECONST (cfg, ins, vtable);
-			return ins;
-		}
-		default:
-			g_assert_not_reached ();
-		}
-	}
-	if (cfg->llvm_only && cfg->gsharedvt && !cfg->gshared_info)
-		return mini_emit_get_gsharedvt_info_klass (cfg, klass, rgctx_type);
-	MonoJumpInfoRgctxEntry *entry = mono_patch_info_rgctx_entry_new (cfg->mempool, cfg->method, context_used_is_mrgctx (cfg, context_used), MONO_PATCH_INFO_CLASS, klass, rgctx_type);
-	return emit_rgctx_fetch (cfg, context_used, entry);
-mono_error_exit:
-	return NULL;
-}
-static MonoInst*
-emit_get_rgctx_sig (MonoCompile *cfg, int context_used,
-					MonoMethodSignature *sig, MonoRgctxInfoType rgctx_type)
-{
-	MonoJumpInfoRgctxEntry *entry = mono_patch_info_rgctx_entry_new (cfg->mempool, cfg->method, context_used_is_mrgctx (cfg, context_used), MONO_PATCH_INFO_SIGNATURE, sig, rgctx_type);
-	return emit_rgctx_fetch (cfg, context_used, entry);
-}
-static MonoInst*
-emit_get_rgctx_gsharedvt_call (MonoCompile *cfg, int context_used,
-							   MonoMethodSignature *sig, MonoMethod *cmethod, MonoRgctxInfoType rgctx_type)
-{
-	MonoJumpInfoGSharedVtCall *call_info;
-	MonoJumpInfoRgctxEntry *entry;
-	call_info = (MonoJumpInfoGSharedVtCall *)mono_mempool_alloc0 (cfg->mempool, sizeof (MonoJumpInfoGSharedVtCall));
-	call_info->sig = sig;
-	call_info->method = cmethod;
-	entry = mono_patch_info_rgctx_entry_new (cfg->mempool, cfg->method, context_used_is_mrgctx (cfg, context_used), MONO_PATCH_INFO_GSHAREDVT_CALL, call_info, rgctx_type);
-	return emit_rgctx_fetch (cfg, context_used, entry);
-}
-/*
- * emit_get_rgctx_virt_method:
- *
- *   Return data for method VIRT_METHOD for a receiver of type KLASS.
- */
-static MonoInst*
-emit_get_rgctx_virt_method (MonoCompile *cfg, int context_used,
-							MonoClass *klass, MonoMethod *virt_method, MonoRgctxInfoType rgctx_type)
-{
-	MonoJumpInfoVirtMethod *info;
-	MonoJumpInfoRgctxEntry *entry;
-	if (context_used == -1)
-		context_used = mono_class_check_context_used (klass) | mono_method_check_context_used (virt_method);
-	info = (MonoJumpInfoVirtMethod *)mono_mempool_alloc0 (cfg->mempool, sizeof (MonoJumpInfoVirtMethod));
-	info->klass = klass;
-	info->method = virt_method;
-	entry = mono_patch_info_rgctx_entry_new (cfg->mempool, cfg->method, context_used_is_mrgctx (cfg, context_used), MONO_PATCH_INFO_VIRT_METHOD, info, rgctx_type);
-	return emit_rgctx_fetch (cfg, context_used, entry);
-}
-static MonoInst*
-emit_get_rgctx_gsharedvt_method (MonoCompile *cfg, int context_used,
-								 MonoMethod *cmethod, MonoGSharedVtMethodInfo *info)
-{
-	MonoJumpInfoRgctxEntry *entry;
-	entry = mono_patch_info_rgctx_entry_new (cfg->mempool, cfg->method, context_used_is_mrgctx (cfg, context_used), MONO_PATCH_INFO_GSHAREDVT_METHOD, info, MONO_RGCTX_INFO_METHOD_GSHAREDVT_INFO);
-	return emit_rgctx_fetch (cfg, context_used, entry);
-}
-/*
- * emit_get_rgctx_method:
- *
- *   Emit IR to load the property RGCTX_TYPE of CMETHOD. If context_used is 0, emit
- * normal constants, else emit a load from the rgctx.
- */
-static MonoInst*
-emit_get_rgctx_method (MonoCompile *cfg, int context_used,
-					   MonoMethod *cmethod, MonoRgctxInfoType rgctx_type)
-{
-	if (context_used == -1)
-		context_used = mono_method_check_context_used (cmethod);
-	if (!context_used) {
-		MonoInst *ins;
-		switch (rgctx_type) {
-		case MONO_RGCTX_INFO_METHOD:
-			EMIT_NEW_METHODCONST (cfg, ins, cmethod);
-			return ins;
-		case MONO_RGCTX_INFO_METHOD_RGCTX:
-			EMIT_NEW_METHOD_RGCTX_CONST (cfg, ins, cmethod);
-			return ins;
-		case MONO_RGCTX_INFO_METHOD_FTNDESC:
-			EMIT_NEW_AOTCONST (cfg, ins, MONO_PATCH_INFO_METHOD_FTNDESC, cmethod);
-			return ins;
-		case MONO_RGCTX_INFO_LLVMONLY_INTERP_ENTRY:
-			EMIT_NEW_AOTCONST (cfg, ins, MONO_PATCH_INFO_LLVMONLY_INTERP_ENTRY, cmethod);
-			return ins;
-		default:
-			g_assert_not_reached ();
-		}
-	} else {
-		if (cfg->llvm_only && cfg->gsharedvt && !cfg->gshared_info)
-			return emit_get_gsharedvt_info (cfg, cmethod, rgctx_type);
-		MonoJumpInfoRgctxEntry *entry = mono_patch_info_rgctx_entry_new (cfg->mempool, cfg->method, context_used_is_mrgctx (cfg, context_used), MONO_PATCH_INFO_METHODCONST, cmethod, rgctx_type);
-		return emit_rgctx_fetch (cfg, context_used, entry);
-	}
-}
-static MonoInst*
-emit_get_rgctx_field (MonoCompile *cfg, int context_used,
-					  MonoClassField *field, MonoRgctxInfoType rgctx_type)
-{
-	if (cfg->llvm_only && cfg->gsharedvt && !cfg->gshared_info)
-		return emit_get_gsharedvt_info (cfg, field, rgctx_type);
-	MonoJumpInfoRgctxEntry *entry = mono_patch_info_rgctx_entry_new (cfg->mempool, cfg->method, context_used_is_mrgctx (cfg, context_used), MONO_PATCH_INFO_FIELD, field, rgctx_type);
-	return emit_rgctx_fetch (cfg, context_used, entry);
-}
-MonoInst*
-mini_emit_get_rgctx_method (MonoCompile *cfg, int context_used,
-							MonoMethod *cmethod, MonoRgctxInfoType rgctx_type)
-{
-	return emit_get_rgctx_method (cfg, context_used, cmethod, rgctx_type);
-}
-static int
-get_gsharedvt_info_slot (MonoCompile *cfg, gpointer data, MonoRgctxInfoType rgctx_type)
-{
-	MonoGSharedVtMethodInfo *info = cfg->gsharedvt_info;
-	MonoRuntimeGenericContextInfoTemplate *template_;
-	int i, idx;
-	g_assert (info);
-	for (i = 0; i < info->num_entries; ++i) {
-		MonoRuntimeGenericContextInfoTemplate *otemplate = &info->entries [i];
-		if (otemplate->info_type == rgctx_type && otemplate->data == data && rgctx_type != MONO_RGCTX_INFO_LOCAL_OFFSET)
-			return i;
-	}
-	if (info->num_entries == info->count_entries) {
-		MonoRuntimeGenericContextInfoTemplate *new_entries;
-		int new_count_entries = info->count_entries ? info->count_entries * 2 : 16;
-		new_entries = (MonoRuntimeGenericContextInfoTemplate *)mono_mempool_alloc0 (cfg->mempool, sizeof (MonoRuntimeGenericContextInfoTemplate) * new_count_entries);
-		memcpy (new_entries, info->entries, sizeof (MonoRuntimeGenericContextInfoTemplate) * info->count_entries);
-		info->entries = new_entries;
-		info->count_entries = new_count_entries;
-	}
-	idx = info->num_entries;
-	template_ = &info->entries [idx];
-	template_->info_type = rgctx_type;
-	template_->data = data;
-	info->num_entries ++;
-	return idx;
-}
-/*
- * emit_get_gsharedvt_info:
- *
- *   This is similar to emit_get_rgctx_.., but loads the data from the gsharedvt info var instead of calling an rgctx fetch trampoline.
- */
-static MonoInst*
-emit_get_gsharedvt_info (MonoCompile *cfg, gpointer data, MonoRgctxInfoType rgctx_type)
-{
-	MonoInst *ins;
-	int idx, dreg;
-	idx = get_gsharedvt_info_slot (cfg, data, rgctx_type);
-	/* Load info->entries [idx] */
-	dreg = alloc_preg (cfg);
-	EMIT_NEW_LOAD_MEMBASE (cfg, ins, OP_LOAD_MEMBASE, dreg, cfg->gsharedvt_info_var->dreg, MONO_STRUCT_OFFSET (MonoGSharedVtMethodRuntimeInfo, entries) + (idx * TARGET_SIZEOF_VOID_P));
-	return ins;
-}
-MonoInst*
-mini_emit_get_gsharedvt_info_klass (MonoCompile *cfg, MonoClass *klass, MonoRgctxInfoType rgctx_type)
-{
-	return emit_get_gsharedvt_info (cfg, m_class_get_byval_arg (klass), rgctx_type);
-}
-/*
- * On return the caller must check @klass for load errors.
- */
-static void
-emit_class_init (MonoCompile *cfg, MonoClass *klass, gboolean for_field_access)
-{
-	MonoInst *vtable_arg;
-	int context_used;
-	context_used = mini_class_check_context_used (cfg, klass);
-	if (cfg->compile_aot && !for_field_access && mono_class_is_before_field_init (klass))
-		/* Only field accesses trigger initialization */
-		return;
-	if (context_used) {
-		vtable_arg = mini_emit_get_rgctx_klass (cfg, context_used,
-										   klass, MONO_RGCTX_INFO_VTABLE);
-	} else {
-		MonoVTable *vtable = mono_class_vtable_checked (klass, cfg->error);
-		if (!is_ok (cfg->error)) {
-			mono_cfg_set_exception (cfg, MONO_EXCEPTION_MONO_ERROR);
-			return;
-		}
-		EMIT_NEW_VTABLECONST (cfg, vtable_arg, vtable);
-	}
-	if (!COMPILE_LLVM (cfg) && cfg->backend->have_op_generic_class_init) {
-		MonoInst *ins;
-		/*
-		 * Using an opcode instead of emitting IR here allows the hiding of the call inside the opcode,
-		 * so this doesn't have to clobber any regs and it doesn't break basic blocks.
-		 */
-		MONO_INST_NEW (cfg, ins, OP_GENERIC_CLASS_INIT);
-		ins->sreg1 = vtable_arg->dreg;
-		MONO_ADD_INS (cfg->cbb, ins);
-	} else {
-		int inited_reg;
-		MonoBasicBlock *inited_bb;
-		inited_reg = alloc_ireg (cfg);
-		MONO_EMIT_NEW_LOAD_MEMBASE_OP (cfg, OP_LOADU1_MEMBASE, inited_reg, vtable_arg->dreg, MONO_STRUCT_OFFSET (MonoVTable, initialized));
-		NEW_BBLOCK (cfg, inited_bb);
-		MONO_EMIT_NEW_BIALU_IMM (cfg, OP_COMPARE_IMM, -1, inited_reg, 0);
-		MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_IBNE_UN, inited_bb);
-		cfg->cbb->out_of_line = TRUE;
-		mono_emit_jit_icall (cfg, mono_generic_class_init, &vtable_arg);
-		MONO_START_BB (cfg, inited_bb);
-	}
-}
-static void
-emit_seq_point (MonoCompile *cfg, MonoMethod *method, guint8* ip, gboolean intr_loc, gboolean nonempty_stack)
-{
-	MonoInst *ins;
-	if (cfg->gen_seq_points && cfg->method == method) {
-		NEW_SEQ_POINT (cfg, ins, GPTRDIFF_TO_TMREG (ip - cfg->header->code), intr_loc);
-		if (nonempty_stack)
-			ins->flags |= MONO_INST_NONEMPTY_STACK;
-		MONO_ADD_INS (cfg->cbb, ins);
-		cfg->last_seq_point = ins;
-	}
-}
-void
-mini_save_cast_details (MonoCompile *cfg, MonoClass *klass, int obj_reg, gboolean null_check)
-{
-	if (mini_debug_options.better_cast_details) {
-		int vtable_reg = alloc_preg (cfg);
-		int klass_reg = alloc_preg (cfg);
-		MonoBasicBlock *is_null_bb = NULL;
-		MonoInst *tls_get;
-		if (null_check) {
-			NEW_BBLOCK (cfg, is_null_bb);
-			MONO_EMIT_NEW_BIALU_IMM (cfg, OP_COMPARE_IMM, -1, obj_reg, 0);
-			MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_PBEQ, is_null_bb);
-		}
-		tls_get = mono_create_tls_get (cfg, TLS_KEY_JIT_TLS);
-		if (!tls_get) {
-			fprintf (stderr, "error: --debug=casts not supported on this platform.\n.");
-			exit (1);
-		}
-		MONO_EMIT_NEW_LOAD_MEMBASE (cfg, vtable_reg, obj_reg, MONO_STRUCT_OFFSET (MonoObject, vtable));
-		MONO_EMIT_NEW_LOAD_MEMBASE (cfg, klass_reg, vtable_reg, MONO_STRUCT_OFFSET (MonoVTable, klass));
-		MONO_EMIT_NEW_STORE_MEMBASE (cfg, OP_STORE_MEMBASE_REG, tls_get->dreg, MONO_STRUCT_OFFSET (MonoJitTlsData, class_cast_from), klass_reg);
-		MonoInst *class_ins = mini_emit_get_rgctx_klass (cfg, mini_class_check_context_used (cfg, klass), klass, MONO_RGCTX_INFO_KLASS);
-		MONO_EMIT_NEW_STORE_MEMBASE (cfg, OP_STORE_MEMBASE_REG, tls_get->dreg, MONO_STRUCT_OFFSET (MonoJitTlsData, class_cast_to), class_ins->dreg);
-		if (null_check)
-			MONO_START_BB (cfg, is_null_bb);
-	}
-}
-void
-mini_reset_cast_details (MonoCompile *cfg)
-{
-	/* Reset the variables holding the cast details */
-	if (mini_debug_options.better_cast_details) {
-		MonoInst *tls_get = mono_create_tls_get (cfg, TLS_KEY_JIT_TLS);
-		/* It is enough to reset the from field */
-		MONO_EMIT_NEW_STORE_MEMBASE_IMM (cfg, OP_STORE_MEMBASE_IMM, tls_get->dreg, MONO_STRUCT_OFFSET (MonoJitTlsData, class_cast_from), 0);
-	}
-}
-/*
- * On return the caller must check @array_class for load errors
- */
-static void
-mini_emit_check_array_type (MonoCompile *cfg, MonoInst *obj, MonoClass *array_class)
-{
-	int vtable_reg = alloc_preg (cfg);
-	int context_used;
-	context_used = mini_class_check_context_used (cfg, array_class);
-	mini_save_cast_details (cfg, array_class, obj->dreg, FALSE);
-	MONO_EMIT_NEW_LOAD_MEMBASE_FAULT (cfg, vtable_reg, obj->dreg, MONO_STRUCT_OFFSET (MonoObject, vtable));
-	if (context_used) {
-		MonoInst *vtable_ins;
-		vtable_ins = mini_emit_get_rgctx_klass (cfg, context_used, array_class, MONO_RGCTX_INFO_VTABLE);
-		MONO_EMIT_NEW_BIALU (cfg, OP_COMPARE, -1, vtable_reg, vtable_ins->dreg);
-	} else {
-		if (cfg->compile_aot) {
-			int vt_reg;
-			MonoVTable *vtable;
-			if (!(vtable = mono_class_vtable_checked (array_class, cfg->error))) {
-				mono_cfg_set_exception (cfg, MONO_EXCEPTION_MONO_ERROR);
-				return;
-			}
-			vt_reg = alloc_preg (cfg);
-			MONO_EMIT_NEW_VTABLECONST (cfg, vt_reg, vtable);
-			MONO_EMIT_NEW_BIALU (cfg, OP_COMPARE, -1, vtable_reg, vt_reg);
-		} else {
-			MonoVTable *vtable;
-			if (!(vtable = mono_class_vtable_checked (array_class, cfg->error))) {
-				mono_cfg_set_exception (cfg, MONO_EXCEPTION_MONO_ERROR);
-				return;
-			}
-			MONO_EMIT_NEW_BIALU_IMM (cfg, OP_COMPARE_IMM, -1, vtable_reg, (gssize)vtable);
-		}
-	}
-	MONO_EMIT_NEW_COND_EXC (cfg, NE_UN, "ArrayTypeMismatchException");
-	mini_reset_cast_details (cfg);
-}
-/**
- * Handles unbox of a Nullable<T>. If context_used is non zero, then shared
- * generic code is generated.
- */
-static MonoInst*
-handle_unbox_nullable (MonoCompile* cfg, MonoInst* val, MonoClass* klass, int context_used)
-{
-	MonoMethod* method;
-	if (m_class_is_enumtype (mono_class_get_nullable_param_internal (klass)))
-		method = get_method_nofail (klass, "UnboxExact", 1, 0);
-	else
-		method = get_method_nofail (klass, "Unbox", 1, 0);
-	g_assert (method);
-	if (context_used) {
-		MonoInst *rgctx, *addr;
-		/* FIXME: What if the class is shared?  We might not
-		   have to get the address of the method from the
-		   RGCTX. */
-		if (cfg->llvm_only) {
-			addr = emit_get_rgctx_method (cfg, context_used, method,
-										  MONO_RGCTX_INFO_METHOD_FTNDESC);
-			cfg->signatures = g_slist_prepend_mempool (cfg->mempool, cfg->signatures, mono_method_signature_internal (method));
-			return mini_emit_llvmonly_calli (cfg, mono_method_signature_internal (method), &val, addr);
-		} else {
-			addr = emit_get_rgctx_method (cfg, context_used, method,
-										  MONO_RGCTX_INFO_GENERIC_METHOD_CODE);
-			rgctx = emit_get_rgctx (cfg, context_used);
-			return mini_emit_calli (cfg, mono_method_signature_internal (method), &val, addr, NULL, rgctx);
-		}
-	} else {
-		MonoInst *rgctx_arg = NULL;
-		if (need_mrgctx_arg (cfg, method))
-			rgctx_arg = emit_get_rgctx_method (cfg, context_used, method,
-											   MONO_RGCTX_INFO_METHOD_RGCTX);
-		return mini_emit_method_call_full (cfg, method, NULL, FALSE, &val, NULL, NULL, rgctx_arg);
-	}
-}
-MonoInst*
-mini_handle_unbox (MonoCompile *cfg, MonoClass *klass, MonoInst *val, int context_used)
-{
-	MonoInst *add;
-	int obj_reg;
-	int vtable_reg = alloc_dreg (cfg ,STACK_PTR);
-	int klass_reg = alloc_dreg (cfg ,STACK_PTR);
-	int eclass_reg = alloc_dreg (cfg ,STACK_PTR);
-	int rank_reg = alloc_dreg (cfg ,STACK_I4);
-	obj_reg = val->dreg;
-	MONO_EMIT_NEW_LOAD_MEMBASE_FAULT (cfg, vtable_reg, obj_reg, MONO_STRUCT_OFFSET (MonoObject, vtable));
-	MONO_EMIT_NEW_LOAD_MEMBASE_OP (cfg, OP_LOADU1_MEMBASE, rank_reg, vtable_reg, MONO_STRUCT_OFFSET (MonoVTable, rank));
-	/* FIXME: generics */
-	g_assert (m_class_get_rank (klass) == 0);
-	MONO_EMIT_NEW_BIALU_IMM (cfg, OP_COMPARE_IMM, -1, rank_reg, 0);
-	MONO_EMIT_NEW_COND_EXC (cfg, NE_UN, "InvalidCastException");
-	MONO_EMIT_NEW_LOAD_MEMBASE (cfg, klass_reg, vtable_reg, MONO_STRUCT_OFFSET (MonoVTable, klass));
-	MONO_EMIT_NEW_LOAD_MEMBASE (cfg, eclass_reg, klass_reg, GINTPTR_TO_TMREG (m_class_offsetof_element_class ()));
-	if (context_used) {
-		MonoInst *element_class;
-		/* This assertion is from the unboxcast insn */
-		g_assert (m_class_get_rank (klass) == 0);
-		element_class = mini_emit_get_rgctx_klass (cfg, context_used,
-				klass, MONO_RGCTX_INFO_ELEMENT_KLASS);
-		MONO_EMIT_NEW_BIALU (cfg, OP_COMPARE, -1, eclass_reg, element_class->dreg);
-		MONO_EMIT_NEW_COND_EXC (cfg, NE_UN, "InvalidCastException");
-	} else {
-		mini_save_cast_details (cfg, m_class_get_element_class (klass), obj_reg, FALSE);
-		mini_emit_class_check (cfg, eclass_reg, m_class_get_element_class (klass));
-		mini_reset_cast_details (cfg);
-	}
-	NEW_BIALU_IMM (cfg, add, OP_ADD_IMM, alloc_dreg (cfg, STACK_MP), obj_reg, MONO_ABI_SIZEOF (MonoObject));
-	MONO_ADD_INS (cfg->cbb, add);
-	add->type = STACK_MP;
-	add->klass = klass;
-	return add;
-}
-static MonoInst*
-handle_unbox_gsharedvt (MonoCompile *cfg, MonoClass *klass, MonoInst *obj)
-{
-	MonoInst *addr, *klass_inst, *is_ref, *args[16];
-	MonoBasicBlock *is_ref_bb, *is_nullable_bb, *end_bb;
-	MonoInst *ins;
-	int dreg, addr_reg;
-	klass_inst = mini_emit_get_gsharedvt_info_klass (cfg, klass, MONO_RGCTX_INFO_KLASS);
-	/* obj */
-	args [0] = obj;
-	/* klass */
-	args [1] = klass_inst;
-	/* CASTCLASS */
-	obj = mono_emit_jit_icall (cfg, mono_object_castclass_unbox, args);
-	NEW_BBLOCK (cfg, is_ref_bb);
-	NEW_BBLOCK (cfg, is_nullable_bb);
-	NEW_BBLOCK (cfg, end_bb);
-	is_ref = mini_emit_get_gsharedvt_info_klass (cfg, klass, MONO_RGCTX_INFO_CLASS_BOX_TYPE);
-	MONO_EMIT_NEW_BIALU_IMM (cfg, OP_COMPARE_IMM, -1, is_ref->dreg, MONO_GSHAREDVT_BOX_TYPE_REF);
-	MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_IBEQ, is_ref_bb);
-	MONO_EMIT_NEW_BIALU_IMM (cfg, OP_COMPARE_IMM, -1, is_ref->dreg, MONO_GSHAREDVT_BOX_TYPE_NULLABLE);
-	MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_IBEQ, is_nullable_bb);
-	/* This will contain either the address of the unboxed vtype, or an address of the temporary where the ref is stored */
-	addr_reg = alloc_dreg (cfg, STACK_MP);
-	/* Non-ref case */
-	/* UNBOX */
-	NEW_BIALU_IMM (cfg, addr, OP_ADD_IMM, addr_reg, obj->dreg, MONO_ABI_SIZEOF (MonoObject));
-	MONO_ADD_INS (cfg->cbb, addr);
-	MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_BR, end_bb);
-	/* Ref case */
-	MONO_START_BB (cfg, is_ref_bb);
-	/* Save the ref to a temporary */
-	dreg = alloc_ireg (cfg);
-	EMIT_NEW_VARLOADA_VREG (cfg, addr, dreg, m_class_get_byval_arg (klass));
-	addr->dreg = addr_reg;
-	MONO_EMIT_NEW_STORE_MEMBASE (cfg, OP_STORE_MEMBASE_REG, addr->dreg, 0, obj->dreg);
-	MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_BR, end_bb);
-	/* Nullable case */
-	MONO_START_BB (cfg, is_nullable_bb);
-	{
-		MonoInst *unbox_addr = mini_emit_get_gsharedvt_info_klass (cfg, klass, MONO_RGCTX_INFO_NULLABLE_CLASS_UNBOX);
-		MonoInst *unbox_call;
-		MonoMethodSignature *unbox_sig;
-		unbox_sig = (MonoMethodSignature *)mono_mempool_alloc0 (cfg->mempool, MONO_SIZEOF_METHOD_SIGNATURE + (1 * sizeof (MonoType *)));
-		unbox_sig->ret = m_class_get_byval_arg (klass);
-		unbox_sig->param_count = 1;
-		unbox_sig->params [0] = mono_get_object_type ();
-		if (cfg->llvm_only)
-			unbox_call = mini_emit_llvmonly_calli (cfg, unbox_sig, &obj, unbox_addr );
-		else
-			unbox_call = mini_emit_calli (cfg, unbox_sig, &obj, unbox_addr , NULL, NULL);
-		EMIT_NEW_VARLOADA_VREG (cfg, unbox_addr , unbox_call->dreg, m_class_get_byval_arg (klass));
-		unbox_addr ->dreg = addr_reg;
-	}
-	MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_BR, end_bb);
-	/* End */
-	MONO_START_BB (cfg, end_bb);
-	/* LDOBJ */
-	EMIT_NEW_LOAD_MEMBASE_TYPE (cfg, ins, m_class_get_byval_arg (klass), addr_reg, 0);
-	return ins;
-}
-/*
- * Returns NULL and set the cfg exception on error.
- */
-static MonoInst*
-handle_alloc (MonoCompile *cfg, MonoClass *klass, gboolean for_box, int context_used)
-{
-	MonoInst *iargs [2];
-	MonoJitICallId alloc_ftn;
-	if (mono_class_get_flags (klass) & TYPE_ATTRIBUTE_ABSTRACT) {
-		char* full_name = mono_type_get_full_name (klass);
-		mono_cfg_set_exception (cfg, MONO_EXCEPTION_MONO_ERROR);
-		mono_error_set_member_access (cfg->error, "Cannot create an abstract class: %s", full_name);
-		g_free (full_name);
-		return NULL;
-	}
-	if (context_used) {
-		gboolean known_instance_size = !mini_is_gsharedvt_klass (klass);
-		MonoMethod *managed_alloc = mono_gc_get_managed_allocator (klass, for_box, known_instance_size);
-		iargs [0] = mini_emit_get_rgctx_klass (cfg, context_used, klass, MONO_RGCTX_INFO_VTABLE);
-		alloc_ftn = MONO_JIT_ICALL_ves_icall_object_new_specific;
-		if (managed_alloc) {
-			if (known_instance_size) {
-				int size = mono_class_instance_size (klass);
-				if (size < MONO_ABI_SIZEOF (MonoObject))
-					g_error ("Invalid size %d for class %s", size, mono_type_get_full_name (klass));
-				EMIT_NEW_ICONST (cfg, iargs [1], size);
-			}
-			return mono_emit_method_call (cfg, managed_alloc, iargs, NULL);
-		}
-		return mono_emit_jit_icall_id (cfg, alloc_ftn, iargs);
-	}
-	if (cfg->compile_aot && cfg->cbb->out_of_line && m_class_get_type_token (klass) && m_class_get_image (klass) == mono_defaults.corlib && !mono_class_is_ginst (klass)) {
-		/* This happens often in argument checking code, eg. throw new FooException... */
-		/* Avoid relocations and save some space by calling a helper function specialized to mscorlib */
-		EMIT_NEW_ICONST (cfg, iargs [0], mono_metadata_token_index (m_class_get_type_token (klass)));
-		alloc_ftn = MONO_JIT_ICALL_mono_helper_newobj_mscorlib;
-	} else {
-		MonoVTable *vtable = mono_class_vtable_checked (klass, cfg->error);
-		if (!is_ok (cfg->error)) {
-			mono_cfg_set_exception (cfg, MONO_EXCEPTION_MONO_ERROR);
-			return NULL;
-		}
-		MonoMethod *managed_alloc = mono_gc_get_managed_allocator (klass, for_box, TRUE);
-		if (managed_alloc) {
-			int size = mono_class_instance_size (klass);
-			if (size < MONO_ABI_SIZEOF (MonoObject))
-				g_error ("Invalid size %d for class %s", size, mono_type_get_full_name (klass));
-			EMIT_NEW_VTABLECONST (cfg, iargs [0], vtable);
-			EMIT_NEW_ICONST (cfg, iargs [1], size);
-			return mono_emit_method_call (cfg, managed_alloc, iargs, NULL);
-		}
-		alloc_ftn = MONO_JIT_ICALL_ves_icall_object_new_specific;
-		EMIT_NEW_VTABLECONST (cfg, iargs [0], vtable);
-	}
-	return mono_emit_jit_icall_id (cfg, alloc_ftn, iargs);
-}
-/*
- * Returns NULL and set the cfg exception on error.
- */
-MonoInst*
-mini_emit_box (MonoCompile *cfg, MonoInst *val, MonoClass *klass, int context_used)
-{
-	MonoInst *alloc, *ins;
-	if (G_UNLIKELY (m_class_is_byreflike (klass))) {
-		mono_error_set_invalid_program (cfg->error, "Cannot box IsByRefLike type '%s.%s'", m_class_get_name_space (klass), m_class_get_name (klass));
-		mono_cfg_set_exception (cfg, MONO_EXCEPTION_INVALID_PROGRAM);
-		return NULL;
-	}
-	if (mono_class_is_nullable (klass)) {
-		MonoMethod* method = get_method_nofail (klass, "Box", 1, 0);
-		if (context_used) {
-			if (cfg->llvm_only) {
-				MonoInst *addr;
-				MonoMethodSignature *sig = mono_method_signature_internal (method);
-				if (mini_is_gsharedvt_klass (klass))
-					addr = mini_emit_get_gsharedvt_info_klass (cfg, klass,
-															   MONO_RGCTX_INFO_NULLABLE_CLASS_BOX);
-				else
-					addr = emit_get_rgctx_method (cfg, context_used, method,
-												  MONO_RGCTX_INFO_METHOD_FTNDESC);
-				cfg->interp_in_signatures = g_slist_prepend_mempool (cfg->mempool, cfg->interp_in_signatures, sig);
-				return mini_emit_llvmonly_calli (cfg, sig, &val, addr);
-			} else {
-				/* FIXME: What if the class is shared?  We might not
-				   have to get the method address from the RGCTX. */
-				MonoInst *addr = emit_get_rgctx_method (cfg, context_used, method,
-														MONO_RGCTX_INFO_GENERIC_METHOD_CODE);
-				MonoInst *rgctx = emit_get_rgctx (cfg, context_used);
-				return mini_emit_calli (cfg, mono_method_signature_internal (method), &val, addr, NULL, rgctx);
-			}
-		} else {
-			MonoInst *rgctx_arg = NULL;
-			if (need_mrgctx_arg (cfg, method))
-				rgctx_arg = emit_get_rgctx_method (cfg, context_used, method,
-												   MONO_RGCTX_INFO_METHOD_RGCTX);
-			return mini_emit_method_call_full (cfg, method, NULL, FALSE, &val, NULL, NULL, rgctx_arg);
-		}
-	}
-	if (mini_is_gsharedvt_klass (klass)) {
-		MonoBasicBlock *is_ref_bb, *is_nullable_bb, *end_bb;
-		MonoInst *res, *is_ref, *src_var, *addr;
-		int dreg;
-		dreg = alloc_ireg (cfg);
-		NEW_BBLOCK (cfg, is_ref_bb);
-		NEW_BBLOCK (cfg, is_nullable_bb);
-		NEW_BBLOCK (cfg, end_bb);
-		is_ref = mini_emit_get_gsharedvt_info_klass (cfg, klass, MONO_RGCTX_INFO_CLASS_BOX_TYPE);
-		MONO_EMIT_NEW_BIALU_IMM (cfg, OP_COMPARE_IMM, -1, is_ref->dreg, MONO_GSHAREDVT_BOX_TYPE_REF);
-		MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_IBEQ, is_ref_bb);
-		MONO_EMIT_NEW_BIALU_IMM (cfg, OP_COMPARE_IMM, -1, is_ref->dreg, MONO_GSHAREDVT_BOX_TYPE_NULLABLE);
-		MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_IBEQ, is_nullable_bb);
-		/* Non-ref case */
-		alloc = handle_alloc (cfg, klass, TRUE, context_used);
-		if (!alloc)
-			return NULL;
-		EMIT_NEW_STORE_MEMBASE_TYPE (cfg, ins, m_class_get_byval_arg (klass), alloc->dreg, MONO_ABI_SIZEOF (MonoObject), val->dreg);
-		ins->opcode = OP_STOREV_MEMBASE;
-		EMIT_NEW_UNALU (cfg, res, OP_MOVE, dreg, alloc->dreg);
-		res->type = STACK_OBJ;
-		res->klass = klass;
-		MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_BR, end_bb);
-		/* Ref case */
-		MONO_START_BB (cfg, is_ref_bb);
-		/* val is a vtype, so has to load the value manually */
-		src_var = get_vreg_to_inst (cfg, val->dreg);
-		if (!src_var)
-			src_var = mono_compile_create_var_for_vreg (cfg, m_class_get_byval_arg (klass), OP_LOCAL, val->dreg);
-		EMIT_NEW_VARLOADA (cfg, addr, src_var, src_var->inst_vtype);
-		MONO_EMIT_NEW_LOAD_MEMBASE (cfg, dreg, addr->dreg, 0);
-		MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_BR, end_bb);
-		/* Nullable case */
-		MONO_START_BB (cfg, is_nullable_bb);
-		{
-			MonoInst *box_addr = mini_emit_get_gsharedvt_info_klass (cfg, klass,
-													MONO_RGCTX_INFO_NULLABLE_CLASS_BOX);
-			MonoInst *box_call;
-			MonoMethodSignature *box_sig;
-			/*
-			 * klass is Nullable<T>, need to call Nullable<T>.Box () using a gsharedvt signature, but we cannot
-			 * construct that method at JIT time, so have to do things by hand.
-			 */
-			box_sig = (MonoMethodSignature *)mono_mempool_alloc0 (cfg->mempool, MONO_SIZEOF_METHOD_SIGNATURE + (1 * sizeof (MonoType *)));
-			box_sig->ret = mono_get_object_type ();
-			box_sig->param_count = 1;
-			box_sig->params [0] = m_class_get_byval_arg (klass);
-			if (cfg->llvm_only)
-				box_call = mini_emit_llvmonly_calli (cfg, box_sig, &val, box_addr);
-			else
-				box_call = mini_emit_calli (cfg, box_sig, &val, box_addr, NULL, NULL);
-			EMIT_NEW_UNALU (cfg, res, OP_MOVE, dreg, box_call->dreg);
-			res->type = STACK_OBJ;
-			res->klass = klass;
-		}
-		MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_BR, end_bb);
-		MONO_START_BB (cfg, end_bb);
-		return res;
-	}
-	alloc = handle_alloc (cfg, klass, TRUE, context_used);
-	if (!alloc)
-		return NULL;
-	EMIT_NEW_STORE_MEMBASE_TYPE (cfg, ins, m_class_get_byval_arg (klass), alloc->dreg, MONO_ABI_SIZEOF (MonoObject), val->dreg);
-	return alloc;
-}
-static gboolean
-method_needs_stack_walk (MonoCompile *cfg, MonoMethod *cmethod)
-{
-	if (cmethod->klass == mono_defaults.systemtype_class) {
-		if (!strcmp (cmethod->name, "GetType"))
-			return TRUE;
-	}
-	/*
-	 * Methods which do stack walks are marked with [System.Security.DynamicSecurityMethod] in the bcl.
-	 * This check won't work for StackCrawlMark.LookForMyCallersCaller, but thats not currently by the
-	 * stack walk code anyway.
-	 */
-	return (cmethod->flags & METHOD_ATTRIBUTE_REQSECOBJ) != 0;
-}
-G_GNUC_UNUSED MonoInst*
-mini_handle_enum_has_flag (MonoCompile *cfg, MonoClass *klass, MonoInst *enum_this, int enum_val_reg, MonoInst *enum_flag)
-{
-	MonoType *enum_type = mono_type_get_underlying_type (m_class_get_byval_arg (klass));
-	guint32 load_opc = mono_type_to_load_membase (cfg, enum_type);
-	gboolean is_i4;
-	switch (enum_type->type) {
-	case MONO_TYPE_I8:
-	case MONO_TYPE_U8:
-#if SIZEOF_REGISTER == 8
-	case MONO_TYPE_I:
-	case MONO_TYPE_U:
-#endif
-		is_i4 = FALSE;
-		break;
-	default:
-		is_i4 = TRUE;
-		break;
-	}
-	{
-		MonoInst *load = NULL, *and_, *cmp, *ceq;
-		int enum_reg = is_i4 ? alloc_ireg (cfg) : alloc_lreg (cfg);
-		int and_reg = is_i4 ? alloc_ireg (cfg) : alloc_lreg (cfg);
-		int dest_reg = alloc_ireg (cfg);
-		if (enum_this) {
-			EMIT_NEW_LOAD_MEMBASE (cfg, load, load_opc, enum_reg, enum_this->dreg, 0);
-		} else {
-			g_assert (enum_val_reg != -1);
-			enum_reg = enum_val_reg;
-		}
-		EMIT_NEW_BIALU (cfg, and_, is_i4 ? OP_IAND : OP_LAND, and_reg, enum_reg, enum_flag->dreg);
-		EMIT_NEW_BIALU (cfg, cmp, is_i4 ? OP_ICOMPARE : OP_LCOMPARE, -1, and_reg, enum_flag->dreg);
-		EMIT_NEW_UNALU (cfg, ceq, is_i4 ? OP_ICEQ : OP_LCEQ, dest_reg, -1);
-		ceq->type = STACK_I4;
-		if (!is_i4) {
-			load = load ? mono_decompose_opcode (cfg, load) : NULL;
-			and_ = mono_decompose_opcode (cfg, and_);
-			cmp = mono_decompose_opcode (cfg, cmp);
-			ceq = mono_decompose_opcode (cfg, ceq);
-		}
-		return ceq;
-	}
-}
-static void
-emit_set_deopt_il_offset (MonoCompile *cfg, int offset)
-{
-	MonoInst *ins;
-	if (!(cfg->deopt && cfg->method == cfg->current_method))
-		return;
-	EMIT_NEW_VARLOADA (cfg, ins, cfg->il_state_var, NULL);
-	MONO_EMIT_NEW_STORE_MEMBASE_IMM (cfg, OP_STOREI4_MEMBASE_IMM, ins->dreg, MONO_STRUCT_OFFSET (MonoMethodILState, il_offset), offset);
-}
-static MonoInst*
-emit_get_rgctx_dele_tramp_info (MonoCompile *cfg, int context_used,
-								MonoClass *klass, MonoMethod *method, gboolean is_virtual, MonoRgctxInfoType rgctx_type)
-{
-	MonoDelegateClassMethodPair *info;
-	MonoJumpInfoRgctxEntry *entry;
-	info = (MonoDelegateClassMethodPair *)mono_mempool_alloc0 (cfg->mempool, sizeof (MonoDelegateClassMethodPair));
-	info->klass = klass;
-	info->method = method;
-	info->is_virtual = is_virtual;
-	if (!context_used) {
-		MonoInst *ins;
-		g_assert (rgctx_type == MONO_RGCTX_INFO_DELEGATE_TRAMP_INFO);
-		if (cfg->compile_aot) {
-			EMIT_NEW_AOTCONST (cfg, ins, MONO_PATCH_INFO_DELEGATE_INFO, info);
-		} else {
-			MonoDelegateTrampInfo *tramp_info = mono_create_delegate_trampoline_info (klass, method, is_virtual);
-			EMIT_NEW_PCONST (cfg, ins, tramp_info);
-		}
-		return ins;
-	}
-	entry = mono_patch_info_rgctx_entry_new (cfg->mempool, cfg->method, context_used_is_mrgctx (cfg, context_used), MONO_PATCH_INFO_DELEGATE_INFO, info, rgctx_type);
-	return emit_rgctx_fetch (cfg, context_used, entry);
-}
-/*
- * Returns NULL and set the cfg exception on error.
- */
-static G_GNUC_UNUSED MonoInst*
-handle_delegate_ctor (MonoCompile *cfg, MonoClass *klass, MonoInst *target, MonoMethod *method, int target_method_context_used, int invoke_context_used, gboolean is_virtual)
-{
-	MonoInst *ptr;
-	int dreg;
-	MonoInst *obj, *info_ins;
-	if (is_virtual && !cfg->llvm_only) {
-		MonoMethod *invoke = mono_get_delegate_invoke_internal (klass);
-		g_assert (invoke);
-		if (invoke_context_used || !mono_get_delegate_virtual_invoke_impl (mono_method_signature_internal (invoke), target_method_context_used ? NULL : method))
-			return NULL;
-	}
-	obj = handle_alloc (cfg, klass, FALSE, invoke_context_used);
-	if (!obj)
-		return NULL;
-	/* Inline the contents of mini_init_delegate */
-	/* Set target field */
-	/* Optimize away setting of NULL target */
-	if (!MONO_INS_IS_PCONST_NULL (target)) {
-		if (!(method->flags & METHOD_ATTRIBUTE_STATIC)) {
-			MONO_EMIT_NEW_BIALU_IMM (cfg, OP_COMPARE_IMM, -1, target->dreg, 0);
-			MONO_EMIT_NEW_COND_EXC (cfg, EQ, "NullReferenceException");
-		}
-		if (!mini_debug_options.weak_memory_model)
-			mini_emit_memory_barrier (cfg, MONO_MEMORY_BARRIER_REL);
-		MONO_EMIT_NEW_STORE_MEMBASE (cfg, OP_STORE_MEMBASE_REG, obj->dreg, MONO_STRUCT_OFFSET (MonoDelegate, target), target->dreg);
-		if (cfg->gen_write_barriers) {
-			dreg = alloc_preg (cfg);
-			EMIT_NEW_BIALU_IMM (cfg, ptr, OP_PADD_IMM, dreg, obj->dreg, MONO_STRUCT_OFFSET (MonoDelegate, target));
-			mini_emit_write_barrier (cfg, ptr, target);
-		}
-	}
-	info_ins = emit_get_rgctx_dele_tramp_info (cfg, target_method_context_used | invoke_context_used, klass, method, is_virtual, MONO_RGCTX_INFO_DELEGATE_TRAMP_INFO);
-	if (cfg->llvm_only) {
-		MonoInst *args [] = {
-			obj,
-			info_ins
-		};
-		mono_emit_jit_icall (cfg, mini_llvmonly_init_delegate, args);
-		return obj;
-	}
-	/* Set invoke_info field */
-	MONO_EMIT_NEW_STORE_MEMBASE (cfg, OP_STORE_MEMBASE_REG, obj->dreg, MONO_STRUCT_OFFSET (MonoDelegate, invoke_info), info_ins->dreg);
-	/* Set method field */
-	if (target_method_context_used || invoke_context_used) {
-		dreg = alloc_preg (cfg);
-		MONO_EMIT_NEW_LOAD_MEMBASE (cfg, dreg, info_ins->dreg, MONO_STRUCT_OFFSET (MonoDelegateTrampInfo, method));
-		MONO_EMIT_NEW_STORE_MEMBASE (cfg, OP_STORE_MEMBASE_REG, obj->dreg, MONO_STRUCT_OFFSET (MonoDelegate, method), dreg);
-	} else {
-		MonoInst *method_ins = emit_get_rgctx_method (cfg, target_method_context_used, method, MONO_RGCTX_INFO_METHOD);
-		MONO_EMIT_NEW_STORE_MEMBASE (cfg, OP_STORE_MEMBASE_REG, obj->dreg, MONO_STRUCT_OFFSET (MonoDelegate, method), method_ins->dreg);
-	}
-	/* Set invoke_impl field */
-	dreg = alloc_preg (cfg);
-	MONO_EMIT_NEW_LOAD_MEMBASE (cfg, dreg, info_ins->dreg, MONO_STRUCT_OFFSET (MonoDelegateTrampInfo, invoke_impl));
-	MONO_EMIT_NEW_STORE_MEMBASE (cfg, OP_STORE_MEMBASE_REG, obj->dreg, MONO_STRUCT_OFFSET (MonoDelegate, invoke_impl), dreg);
-	if (!is_virtual) {
-		dreg = alloc_preg (cfg);
-		MONO_EMIT_NEW_LOAD_MEMBASE (cfg, dreg, info_ins->dreg, MONO_STRUCT_OFFSET (MonoDelegateTrampInfo, method_ptr));
-		MONO_EMIT_NEW_STORE_MEMBASE (cfg, OP_STORE_MEMBASE_REG, obj->dreg, MONO_STRUCT_OFFSET (MonoDelegate, method_ptr), dreg);
-	}
-	if (is_virtual) {
-		dreg = alloc_preg (cfg);
-		MONO_EMIT_NEW_ICONST (cfg, dreg, 1);
-		MONO_EMIT_NEW_STORE_MEMBASE (cfg, OP_STOREI1_MEMBASE_REG, obj->dreg, MONO_STRUCT_OFFSET (MonoDelegate, method_is_virtual), dreg);
-	}
-	/* All the checks which are in mono_delegate_ctor () are done by the delegate trampoline */
-	return obj;
-}
-/*
- * handle_constrained_gsharedvt_call:
- *
- *   Handle constrained calls where the receiver is a gsharedvt type.
- * Return the instruction representing the call. Set the cfg exception on failure.
- */
-static MonoInst*
-handle_constrained_gsharedvt_call (MonoCompile *cfg, MonoMethod *cmethod, MonoMethodSignature *fsig, MonoInst **sp, MonoClass *constrained_class,
-								   gboolean *ref_emit_widen)
-{
-	MonoInst *ins = NULL;
-	gboolean emit_widen = *ref_emit_widen;
-	gboolean supported;
-	MonoJumpInfoVirtMethod *info;
-	MonoJumpInfoRgctxEntry *entry;
-	MonoInst *call_info_ins;
-	int context_used;
-	MonoBasicBlock *end_bb = NULL, *slowpath_bb = NULL;
-	MonoInst *calls [2];
-	MonoInst *args [7];
-	MonoInst *orig_receiver = sp [0];
-	/*
-	 * The calls are of the form:
-	 * .constrained T_GSHAREDVT
-	 * callvirt <method>
-	 *
-	 * There are 3 basic cases:
-	 * - T is a vtype and the called method is a vtype method (ie. on T).
-	 *   In this case a normal call is made.
-	 * - T is a vtype, and the called method is a method on a reference type
-	 *   (i.e. a method on Object/Valuetype/Enum)
-	 *   In this case the receiver needs to be boxed.
-	 * - T is a reference type.
-	 *   In this case, it needs to be dereferenced (since its type is T&), and
-	 *   a virtual call is made based on its runtime type.
-	 *
-	 * This is implemented by precomputing some data into an rgctx slot, then
-	 * passing that data to jit icalls.
-	 */
-	supported = ((cmethod->klass == mono_defaults.object_class) || mono_class_is_interface (cmethod->klass) || (!m_class_is_valuetype (cmethod->klass) && m_class_get_image (cmethod->klass) != mono_defaults.corlib));
-	if (supported)
-		supported = (MONO_TYPE_IS_VOID (fsig->ret) || MONO_TYPE_IS_PRIMITIVE (fsig->ret) || MONO_TYPE_IS_REFERENCE (fsig->ret) || MONO_TYPE_ISSTRUCT (fsig->ret) || m_class_is_enumtype (mono_class_from_mono_type_internal (fsig->ret)) || mini_is_gsharedvt_type (fsig->ret));
-	if (supported) {
-		if (fsig->param_count == 0 || (!fsig->hasthis && fsig->param_count == 1)) {
-			supported = TRUE;
-		} else {
-			supported = TRUE;
-			for (int i = 0; i < fsig->param_count; ++i) {
-				if (!(m_type_is_byref (fsig->params [i]) || MONO_TYPE_IS_PRIMITIVE (fsig->params [i]) || MONO_TYPE_IS_REFERENCE (fsig->params [i]) || MONO_TYPE_ISSTRUCT (fsig->params [i]) || mini_is_gsharedvt_type (fsig->params [i])))
-					supported = FALSE;
-			}
-		}
-	}
-	if (!supported)
-		GSHAREDVT_FAILURE (CEE_CALLVIRT);
-	/* rgctx entry containing precomputed data */
-	context_used = mono_method_check_context_used (cmethod) | mono_class_check_context_used (constrained_class);
-	info = (MonoJumpInfoVirtMethod *)mono_mempool_alloc0 (cfg->mempool, sizeof (MonoJumpInfoVirtMethod));
-	info->klass = constrained_class;
-	info->method = cmethod;
-	entry = mono_patch_info_rgctx_entry_new (cfg->mempool, cfg->method, context_used_is_mrgctx (cfg, context_used), MONO_PATCH_INFO_VIRT_METHOD, info, MONO_RGCTX_INFO_GSHAREDVT_CONSTRAINED_CALL_INFO);
-	call_info_ins = emit_rgctx_fetch (cfg, context_used, entry);
-	/*
-	 * Fastpath: call mono_gsharedvt_constrained_call_fast, which returns
-	 * both the boxed/unboxed etc. receiver and the address to call, then
-	 * do an indirect call.
-	 */
-	calls [0] = NULL;
-	if (fsig->hasthis && (fsig->ret->type == MONO_TYPE_VOID || MONO_TYPE_IS_PRIMITIVE (fsig->ret) || MONO_TYPE_IS_REFERENCE (fsig->ret)) && !mini_is_gsharedvt_signature (fsig)) {
-		/* Call mono_gsharedvt_constrained_call_fast (receiver, info, &new_receiver) */
-		args [0] = sp [0];
-		args [1] = call_info_ins;
-		int receiver_vreg = alloc_preg (cfg);
-		MONO_EMIT_NEW_PCONST (cfg, receiver_vreg, NULL);
-		EMIT_NEW_VARLOADA_VREG (cfg, args [2], receiver_vreg, mono_get_int_type ());
-		/* This returns the address/ftndesc to call */
-		MonoInst *code_ins = mono_emit_jit_icall (cfg, mono_gsharedvt_constrained_call_fast, args);
-		NEW_BBLOCK (cfg, end_bb);
-		NEW_BBLOCK (cfg, slowpath_bb);
-		/* If NULL, go to slowpath */
-		MONO_EMIT_NEW_BIALU_IMM (cfg, OP_COMPARE_IMM, -1, code_ins->dreg, 0);
-		MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_PBEQ, slowpath_bb);
-		/* Change the receiver to the new receiver returned by mono_gsharedvt_constrained_call_fast () */
-		int tmp_reg = alloc_preg (cfg);
-		EMIT_NEW_UNALU (cfg, ins, OP_MOVE, tmp_reg, receiver_vreg);
-		sp [0] = ins;
-		if (cfg->llvm_only)
-			calls [0] = mini_emit_llvmonly_calli (cfg, fsig, sp, code_ins);
-		else
-			calls [0] = mini_emit_calli (cfg, fsig, sp, code_ins, NULL, NULL);
-		MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_BR, end_bb);
-		MONO_START_BB (cfg, slowpath_bb);
-	}
-	/*
-	 * Slowpath: store the arguments to an array on the stack, then call
-	 * mono_gsharedvt_constrained_call () which computes the target method and calls it using
-	 * runtime invoke.
-	 */
-	if (fsig->hasthis)
-		args [0] = orig_receiver;
-	else
-		EMIT_NEW_PCONST (cfg, args [0], NULL);
-	args [1] = emit_get_rgctx_method (cfg, mono_method_check_context_used (cmethod), cmethod, MONO_RGCTX_INFO_METHOD);
-	args [2] = mini_emit_get_rgctx_klass (cfg, mono_class_check_context_used (constrained_class), constrained_class, MONO_RGCTX_INFO_KLASS);
-	args [3] = call_info_ins;
-	MonoInst *is_gsharedvt_ins = NULL, *args_ins = NULL;
-	/* !fsig->hasthis is for the wrapper for the Object.GetType () icall or static virtual methods */
-	if ((fsig->hasthis || m_method_is_static (cmethod)) && fsig->param_count) {
-		/* Call mono_gsharedvt_constrained_call () */
-		gboolean has_gsharedvt = FALSE;
-		for (int i = 0; i < fsig->param_count; ++i) {
-			if (mini_is_gsharedvt_type (fsig->params [i]))
-				has_gsharedvt = TRUE;
-		}
-		/* Pass an array of bools which signal whenever the corresponding argument is a gsharedvt ref type */
-		if (has_gsharedvt) {
-			MONO_INST_NEW (cfg, ins, OP_LOCALLOC_IMM);
-			ins->dreg = alloc_preg (cfg);
-			ins->inst_imm = fsig->param_count;
-			MONO_ADD_INS (cfg->cbb, ins);
-			is_gsharedvt_ins = ins;
-		} else {
-			EMIT_NEW_PCONST (cfg, is_gsharedvt_ins, 0);
-		}
-		/* Pass the arguments using a localloc-ed array using the format expected by runtime_invoke () */
-		MONO_INST_NEW (cfg, ins, OP_LOCALLOC_IMM);
-		ins->dreg = alloc_preg (cfg);
-		ins->inst_imm = fsig->param_count * sizeof (target_mgreg_t);
-		MONO_ADD_INS (cfg->cbb, ins);
-		args_ins = ins;
-		for (int i = 0; i < fsig->param_count; ++i) {
-			int addr_reg;
-			if (mini_is_gsharedvt_type (fsig->params [i])) {
-				ins = mini_emit_get_gsharedvt_info_klass (cfg, mono_class_from_mono_type_internal (fsig->params [i]), MONO_RGCTX_INFO_CLASS_BOX_TYPE);
-				MONO_EMIT_NEW_STORE_MEMBASE (cfg, OP_STOREI1_MEMBASE_REG, is_gsharedvt_ins->dreg, i, ins->dreg);
-			} else if (has_gsharedvt) {
-				MONO_EMIT_NEW_STORE_MEMBASE_IMM (cfg, OP_STOREI1_MEMBASE_IMM, is_gsharedvt_ins->dreg, i, 0);
-			}
-			MonoInst *arg = sp [i + fsig->hasthis];
-			if (mini_is_gsharedvt_type (fsig->params [i]) || MONO_TYPE_IS_PRIMITIVE (fsig->params [i]) || MONO_TYPE_ISSTRUCT (fsig->params [i])) {
-				EMIT_NEW_VARLOADA_VREG (cfg, ins, arg->dreg, fsig->params [i]);
-				addr_reg = ins->dreg;
-				EMIT_NEW_STORE_MEMBASE (cfg, ins, OP_STORE_MEMBASE_REG, args_ins->dreg, i * sizeof (target_mgreg_t), addr_reg);
-			} else {
-				EMIT_NEW_STORE_MEMBASE (cfg, ins, OP_STORE_MEMBASE_REG, args_ins->dreg, i * sizeof (target_mgreg_t), arg->dreg);
-			}
-		}
-	} else {
-		EMIT_NEW_ICONST (cfg, is_gsharedvt_ins, 0);
-		EMIT_NEW_ICONST (cfg, args_ins, 0);
-	}
-	args [4] = is_gsharedvt_ins;
-	args [5] = args_ins;
-	ins = mono_emit_jit_icall (cfg, mono_gsharedvt_constrained_call, args);
-	emit_widen = FALSE;
-	/* Unbox the return value */
-	if (mini_is_gsharedvt_type (fsig->ret)) {
-		ins = handle_unbox_gsharedvt (cfg, mono_class_from_mono_type_internal (fsig->ret), ins);
-	} else if (MONO_TYPE_IS_PRIMITIVE (fsig->ret) || MONO_TYPE_ISSTRUCT (fsig->ret) || m_class_is_enumtype (mono_class_from_mono_type_internal (fsig->ret))) {
-		MonoInst *add;
-		/* Unbox */
-		NEW_BIALU_IMM (cfg, add, OP_ADD_IMM, alloc_dreg (cfg, STACK_MP), ins->dreg, MONO_ABI_SIZEOF (MonoObject));
-		MONO_ADD_INS (cfg->cbb, add);
-		/* Load value */
-		NEW_LOAD_MEMBASE_TYPE (cfg, ins, fsig->ret, add->dreg, 0);
-		MONO_ADD_INS (cfg->cbb, ins);
-	}
-	calls [1] = ins;
-	/* Merge fastpath/slowpath */
-	if (slowpath_bb) {
-		MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_BR, end_bb);
-		MONO_START_BB (cfg, end_bb);
-	}
-	if (calls [0] && fsig->ret->type != MONO_TYPE_VOID)
-		calls [0]->dreg = calls [1]->dreg;
-	*ref_emit_widen = emit_widen;
-	return calls [1];
- exception_exit:
-	return NULL;
-}
-static void
-mono_emit_load_got_addr (MonoCompile *cfg)
-{
-	MonoInst *getaddr, *dummy_use;
-	if (!cfg->got_var || cfg->got_var_allocated)
-		return;
-	MONO_INST_NEW (cfg, getaddr, OP_LOAD_GOTADDR);
-	getaddr->cil_code = cfg->header->code;
-	getaddr->dreg = cfg->got_var->dreg;
-	/* Add it to the start of the first bblock */
-	if (cfg->bb_entry->code) {
-		getaddr->next = cfg->bb_entry->code;
-		cfg->bb_entry->code = getaddr;
-	}
-	else
-		MONO_ADD_INS (cfg->bb_entry, getaddr);
-	cfg->got_var_allocated = TRUE;
-	/*
-	 * Add a dummy use to keep the got_var alive, since real uses might
-	 * only be generated by the back ends.
-	 * Add it to end_bblock, so the variable's lifetime covers the whole
-	 * method.
-	 * It would be better to make the usage of the got var explicit in all
-	 * cases when the backend needs it (i.e. calls, throw etc.), so this
-	 * wouldn't be needed.
-	 */
-	NEW_DUMMY_USE (cfg, dummy_use, cfg->got_var);
-	MONO_ADD_INS (cfg->bb_exit, dummy_use);
-}
-static MonoMethod*
-get_constrained_method (MonoCompile *cfg, MonoImage *image, guint32 token,
-						MonoMethod *cil_method, MonoClass *constrained_class,
-						MonoGenericContext *generic_context)
-{
-	MonoMethod *cmethod = cil_method;
-	gboolean constrained_is_generic_param =
-		m_class_get_byval_arg (constrained_class)->type == MONO_TYPE_VAR ||
-		m_class_get_byval_arg (constrained_class)->type == MONO_TYPE_MVAR;
-	if (cfg->current_method->wrapper_type != MONO_WRAPPER_NONE) {
-		if (cfg->verbose_level > 2)
-			printf ("DM Constrained call to %s\n", mono_type_get_full_name (constrained_class));
-		if (!(constrained_is_generic_param &&
-			  cfg->gshared)) {
-			cmethod = mono_get_method_constrained_with_method (image, cil_method, constrained_class, generic_context, cfg->error);
-			CHECK_CFG_ERROR;
-		}
-	} else {
-		if (cfg->verbose_level > 2)
-			printf ("Constrained call to %s\n", mono_type_get_full_name (constrained_class));
-		if (constrained_is_generic_param && cfg->gshared) {
-			/*
-			 * This is needed since get_method_constrained can't find
-			 * the method in klass representing a type var.
-			 * The type var is guaranteed to be a reference type in this
-			 * case.
-			 */
-			if (!mini_is_gsharedvt_klass (constrained_class))
-				g_assert (!m_class_is_valuetype (cmethod->klass));
-		} else {
-			cmethod = mono_get_method_constrained_checked (image, token, constrained_class, generic_context, &cil_method, cfg->error);
-			CHECK_CFG_ERROR;
-		}
-	}
-	return cmethod;
- mono_error_exit:
-	return NULL;
-}
-static gboolean
-method_does_not_return (MonoMethod *method)
-{
-	return m_class_get_image (method->klass) == mono_defaults.corlib &&
-		!strcmp (m_class_get_name (method->klass), "ThrowHelper") &&
-		strstr (method->name, "Throw") == method->name &&
-		!method->is_inflated;
-}
-static int inline_limit, llvm_jit_inline_limit, llvm_aot_inline_limit;
-static gboolean inline_limit_inited;
-static gboolean
-mono_method_check_inlining (MonoCompile *cfg, MonoMethod *method)
-{
-	MonoMethodHeaderSummary header;
-	MonoVTable *vtable;
-	int limit;
-#ifdef MONO_ARCH_SOFT_FLOAT_FALLBACK
-	MonoMethodSignature *sig = mono_method_signature_internal (method);
-	int i;
-#endif
-	if (cfg->disable_inline)
-		return FALSE;
-	if (cfg->gsharedvt)
-		return FALSE;
-	if (cfg->inline_depth > 10)
-		return FALSE;
-	if (!mono_method_get_header_summary (method, &header))
-		return FALSE;
-	/*runtime, icall and pinvoke are checked by summary call*/
-	if ((method->iflags & METHOD_IMPL_ATTRIBUTE_NOINLINING) ||
-	    (method->iflags & METHOD_IMPL_ATTRIBUTE_SYNCHRONIZED) ||
-	    header.has_clauses)
-		return FALSE;
-	if (method->flags & METHOD_ATTRIBUTE_REQSECOBJ)
-		/* Used to mark methods containing StackCrawlMark locals */
-		return FALSE;
-	/* also consider num_locals? */
-	/* Do the size check early to avoid creating vtables */
-	if (!inline_limit_inited) {
-		char *inlinelimit;
-		if ((inlinelimit = g_getenv ("MONO_INLINELIMIT"))) {
-			inline_limit = atoi (inlinelimit);
-			llvm_jit_inline_limit = inline_limit;
-			llvm_aot_inline_limit = inline_limit;
-			g_free (inlinelimit);
-		} else {
-			inline_limit = INLINE_LENGTH_LIMIT;
-			llvm_jit_inline_limit = LLVM_JIT_INLINE_LENGTH_LIMIT;
-			llvm_aot_inline_limit = LLVM_AOT_INLINE_LENGTH_LIMIT;
-		}
-		inline_limit_inited = TRUE;
-	}
-	if (COMPILE_LLVM (cfg)) {
-		if (cfg->compile_aot)
-			limit = llvm_aot_inline_limit;
-		else
-			limit = llvm_jit_inline_limit;
-	} else {
-		limit = inline_limit;
-	}
-	if (header.code_size >= GINT_TO_UINT32(limit) && !(method->iflags & METHOD_IMPL_ATTRIBUTE_AGGRESSIVE_INLINING))
-		return FALSE;
-	/*
-	 * if we can initialize the class of the method right away, we do,
-	 * otherwise we don't allow inlining if the class needs initialization,
-	 * since it would mean inserting a call to mono_runtime_class_init()
-	 * inside the inlined code
-	 */
-	if (cfg->gshared && m_class_has_cctor (method->klass) && mini_class_check_context_used (cfg, method->klass))
-		return FALSE;
-	{
-		/* The AggressiveInlining hint is a good excuse to force that cctor to run. */
-		if ((cfg->opt & MONO_OPT_AGGRESSIVE_INLINING) || method->iflags & METHOD_IMPL_ATTRIBUTE_AGGRESSIVE_INLINING) {
-			if (m_class_has_cctor (method->klass)) {
-				ERROR_DECL (error);
-				vtable = mono_class_vtable_checked (method->klass, error);
-				if (!is_ok (error)) {
-					mono_error_cleanup (error);
-					return FALSE;
-				}
-				if (!cfg->compile_aot) {
-					if (!mono_runtime_class_init_full (vtable, error)) {
-						mono_error_cleanup (error);
-						return FALSE;
-					}
-				}
-			}
-		} else if (mono_class_is_before_field_init (method->klass)) {
-			if (cfg->run_cctors && m_class_has_cctor (method->klass)) {
-				ERROR_DECL (error);
-				/*FIXME it would easier and lazier to just use mono_class_try_get_vtable */
-				if (!m_class_get_runtime_vtable (method->klass))
-					/* No vtable created yet */
-					return FALSE;
-				vtable = mono_class_vtable_checked (method->klass, error);
-				if (!is_ok (error)) {
-					mono_error_cleanup (error);
-					return FALSE;
-				}
-				/* This makes so that inline cannot trigger */
-				/* .cctors: too many apps depend on them */
-				/* running with a specific order... */
-				if (! vtable->initialized)
-					return FALSE;
-				if (!mono_runtime_class_init_full (vtable, error)) {
-					mono_error_cleanup (error);
-					return FALSE;
-				}
-			}
-		} else if (mono_class_needs_cctor_run (method->klass, NULL)) {
-			ERROR_DECL (error);
-			if (!m_class_get_runtime_vtable (method->klass))
-				/* No vtable created yet */
-				return FALSE;
-			vtable = mono_class_vtable_checked (method->klass, error);
-			if (!is_ok (error)) {
-				mono_error_cleanup (error);
-				return FALSE;
-			}
-			if (!vtable->initialized)
-				return FALSE;
-		}
-	}
-#ifdef MONO_ARCH_SOFT_FLOAT_FALLBACK
-	if (mono_arch_is_soft_float ()) {
-		/* FIXME: */
-		if (sig->ret && sig->ret->type == MONO_TYPE_R4)
-			return FALSE;
-		for (i = 0; i < sig->param_count; ++i)
-			if (!m_type_is_byref (sig->params [i]) && sig->params [i]->type == MONO_TYPE_R4)
-				return FALSE;
-	}
-#endif
-	if (g_list_find (cfg->dont_inline, method))
-		return FALSE;
-	if (mono_profiler_get_call_instrumentation_flags (method))
-		return FALSE;
-	if (mono_profiler_coverage_instrumentation_enabled (method))
-		return FALSE;
-	if (method_does_not_return (method))
-		return FALSE;
-	MonoAotModule *amodule = m_class_get_image (method->klass)->aot_module;
-	if (amodule && (amodule != AOT_MODULE_NOT_FOUND) && (mono_aot_get_module_flags (amodule) & MONO_AOT_FILE_FLAG_WITH_LLVM)) {
-		ERROR_DECL (error);
-		mono_class_init_internal (method->klass);
-		gpointer addr = mono_aot_get_method (method, error);
-		if (addr && is_ok (error)) {
-			MonoAotMethodFlags flags = mono_aot_get_method_flags (addr);
-                        if (flags & MONO_AOT_METHOD_FLAG_HAS_LLVM_INTRINSICS)
-                                return FALSE;
-		}
-	}
-	return TRUE;
-}
-static gboolean
-mini_field_access_needs_cctor_run (MonoCompile *cfg, MonoMethod *method, MonoClass *klass, MonoVTable *vtable)
-{
-	if (!cfg->compile_aot) {
-		g_assert (vtable);
-		if (vtable->initialized)
-			return FALSE;
-	}
-	if (mono_class_is_before_field_init (klass)) {
-		if (cfg->method == method)
-			return FALSE;
-	}
-	if (!mono_class_needs_cctor_run (klass, method))
-		return FALSE;
-	if (! (method->flags & METHOD_ATTRIBUTE_STATIC) && (klass == method->klass))
-		/* The initialization is already done before the method is called */
-		return FALSE;
-	return TRUE;
-}
-int
-mini_emit_sext_index_reg (MonoCompile *cfg, MonoInst *index, gboolean *need_sext)
-{
-	int index_reg = index->dreg;
-	int index2_reg;
-	*need_sext = FALSE;
-#if SIZEOF_REGISTER == 8
-	if (index->type != STACK_I4)
-		return index_reg;
-	/* The array reg is 64 bits but the index reg is only 32 */
-	if (cfg->opt & MONO_OPT_ABCREM) {
-		/*
-		 * abcrem can't handle the OP_SEXT_I4, so add this after abcrem,
-		 * during OP_BOUNDS_CHECK decomposition, and in the implementation
-		 * of OP_X86_LEA for llvm.
-		 */
-		index2_reg = index_reg;
-		*need_sext = TRUE;
-	} else {
-		index2_reg = alloc_preg (cfg);
-		MONO_EMIT_NEW_UNALU (cfg, OP_SEXT_I4, index2_reg, index_reg);
-	}
-#else
-	if (index->type == STACK_I8) {
-		index2_reg = alloc_preg (cfg);
-		MONO_EMIT_NEW_UNALU (cfg, OP_LCONV_TO_I4, index2_reg, index_reg);
-	} else {
-		index2_reg = index_reg;
-	}
-#endif
-	return index2_reg;
-}
-MonoInst*
-mini_emit_ldelema_1_ins (MonoCompile *cfg, MonoClass *klass, MonoInst *arr, MonoInst *index, gboolean bcheck, gboolean bounded)
-{
-	MonoInst *ins;
-	guint32 size;
-	int mult_reg, add_reg, array_reg, index2_reg, bounds_reg, lower_bound_reg, realidx2_reg;
-	int context_used;
-	if (mini_is_gsharedvt_variable_klass (klass)) {
-		size = -1;
-	} else {
-		mono_class_init_internal (klass);
-		size = mono_class_array_element_size (klass);
-	}
-	mult_reg = alloc_preg (cfg);
-	array_reg = arr->dreg;
-	gboolean need_sext;
-	realidx2_reg = index2_reg = mini_emit_sext_index_reg (cfg, index, &need_sext);
-	if (bounded) {
-		bounds_reg = alloc_preg (cfg);
-		lower_bound_reg = alloc_preg (cfg);
-		realidx2_reg = alloc_preg (cfg);
-		MonoBasicBlock *is_null_bb = NULL;
-		NEW_BBLOCK (cfg, is_null_bb);
-		MONO_EMIT_NEW_PCONST (cfg, lower_bound_reg, NULL);
-		MONO_EMIT_NEW_LOAD_MEMBASE (cfg, bounds_reg, arr->dreg, MONO_STRUCT_OFFSET (MonoArray, bounds));
-		MONO_EMIT_NEW_BIALU_IMM (cfg, OP_COMPARE_IMM, -1, bounds_reg, 0);
-		MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_PBEQ, is_null_bb);
-		MONO_EMIT_NEW_LOAD_MEMBASE_OP (cfg, OP_LOADI4_MEMBASE, lower_bound_reg, bounds_reg, MONO_STRUCT_OFFSET (MonoArrayBounds, lower_bound));
-		MONO_START_BB (cfg, is_null_bb);
-		MONO_EMIT_NEW_BIALU (cfg, OP_PSUB, realidx2_reg, index2_reg, lower_bound_reg);
-	}
-	if (bcheck)
-		MONO_EMIT_BOUNDS_CHECK (cfg, array_reg, MonoArray, max_length, realidx2_reg, need_sext);
-#if defined(TARGET_X86) || defined(TARGET_AMD64)
-	if (size == 1 || size == 2 || size == 4 || size == 8) {
-		static const int fast_log2 [] = { 1, 0, 1, -1, 2, -1, -1, -1, 3 };
-		EMIT_NEW_X86_LEA (cfg, ins, array_reg, realidx2_reg, fast_log2 [size], MONO_STRUCT_OFFSET (MonoArray, vector));
-		ins->klass = klass;
-		ins->type = STACK_MP;
-		return ins;
-	}
-#endif
-	add_reg = alloc_ireg_mp (cfg);
-	if (size == -1) {
-		MonoInst *rgctx_ins;
-		/* gsharedvt */
-		g_assert (cfg->gshared);
-		context_used = mini_class_check_context_used (cfg, klass);
-		g_assert (context_used);
-		rgctx_ins = mini_emit_get_gsharedvt_info_klass (cfg, klass, MONO_RGCTX_INFO_ARRAY_ELEMENT_SIZE);
-		MONO_EMIT_NEW_BIALU (cfg, OP_IMUL, mult_reg, realidx2_reg, rgctx_ins->dreg);
-	} else {
-		MONO_EMIT_NEW_BIALU_IMM (cfg, OP_MUL_IMM, mult_reg, realidx2_reg, size);
-	}
-	MONO_EMIT_NEW_BIALU (cfg, OP_PADD, add_reg, array_reg, mult_reg);
-	NEW_BIALU_IMM (cfg, ins, OP_PADD_IMM, add_reg, add_reg, MONO_STRUCT_OFFSET (MonoArray, vector));
-	ins->klass = klass;
-	ins->type = STACK_MP;
-	MONO_ADD_INS (cfg->cbb, ins);
-	return ins;
-}
-static MonoInst*
-mini_emit_ldelema_2_ins (MonoCompile *cfg, MonoClass *klass, MonoInst *arr, MonoInst *index_ins1, MonoInst *index_ins2)
-{
-	int bounds_reg = alloc_preg (cfg);
-	int add_reg = alloc_ireg_mp (cfg);
-	int mult_reg = alloc_preg (cfg);
-	int mult2_reg = alloc_preg (cfg);
-	int low1_reg = alloc_preg (cfg);
-	int low2_reg = alloc_preg (cfg);
-	int high1_reg = alloc_preg (cfg);
-	int high2_reg = alloc_preg (cfg);
-	int realidx1_reg = alloc_preg (cfg);
-	int realidx2_reg = alloc_preg (cfg);
-	int sum_reg = alloc_preg (cfg);
-	int index1, index2;
-	MonoInst *ins;
-	guint32 size;
-	mono_class_init_internal (klass);
-	size = mono_class_array_element_size (klass);
-	index1 = index_ins1->dreg;
-	index2 = index_ins2->dreg;
-#if SIZEOF_REGISTER == 8
-	/* The array reg is 64 bits but the index reg is only 32 */
-	if (COMPILE_LLVM (cfg)) {
-		/* Not needed */
-	} else {
-		int tmpreg = alloc_preg (cfg);
-		MONO_EMIT_NEW_UNALU (cfg, OP_SEXT_I4, tmpreg, index1);
-		index1 = tmpreg;
-		tmpreg = alloc_preg (cfg);
-		MONO_EMIT_NEW_UNALU (cfg, OP_SEXT_I4, tmpreg, index2);
-		index2 = tmpreg;
-	}
-#else
-#endif
-	/* range checking */
-	MONO_EMIT_NEW_LOAD_MEMBASE_FAULT (cfg, bounds_reg,
-				       arr->dreg, MONO_STRUCT_OFFSET (MonoArray, bounds));
-	MONO_EMIT_NEW_LOAD_MEMBASE_OP (cfg, OP_LOADI4_MEMBASE, low1_reg,
-				       bounds_reg, MONO_STRUCT_OFFSET (MonoArrayBounds, lower_bound));
-	MONO_EMIT_NEW_BIALU (cfg, OP_PSUB, realidx1_reg, index1, low1_reg);
-	MONO_EMIT_NEW_LOAD_MEMBASE_OP (cfg, OP_LOADI4_MEMBASE, high1_reg,
-				       bounds_reg, MONO_STRUCT_OFFSET (MonoArrayBounds, length));
-	MONO_EMIT_NEW_BIALU (cfg, OP_COMPARE, -1, high1_reg, realidx1_reg);
-	MONO_EMIT_NEW_COND_EXC (cfg, LE_UN, "IndexOutOfRangeException");
-	MONO_EMIT_NEW_LOAD_MEMBASE_OP (cfg, OP_LOADI4_MEMBASE, low2_reg,
-				       bounds_reg, sizeof (MonoArrayBounds) + MONO_STRUCT_OFFSET (MonoArrayBounds, lower_bound));
-	MONO_EMIT_NEW_BIALU (cfg, OP_PSUB, realidx2_reg, index2, low2_reg);
-	MONO_EMIT_NEW_LOAD_MEMBASE_OP (cfg, OP_LOADI4_MEMBASE, high2_reg,
-				       bounds_reg, sizeof (MonoArrayBounds) + MONO_STRUCT_OFFSET (MonoArrayBounds, length));
-	MONO_EMIT_NEW_BIALU (cfg, OP_COMPARE, -1, high2_reg, realidx2_reg);
-	MONO_EMIT_NEW_COND_EXC (cfg, LE_UN, "IndexOutOfRangeException");
-	MONO_EMIT_NEW_BIALU (cfg, OP_PMUL, mult_reg, high2_reg, realidx1_reg);
-	MONO_EMIT_NEW_BIALU (cfg, OP_PADD, sum_reg, mult_reg, realidx2_reg);
-	MONO_EMIT_NEW_BIALU_IMM (cfg, OP_PMUL_IMM, mult2_reg, sum_reg, size);
-	MONO_EMIT_NEW_BIALU (cfg, OP_PADD, add_reg, mult2_reg, arr->dreg);
-	NEW_BIALU_IMM (cfg, ins, OP_PADD_IMM, add_reg, add_reg, MONO_STRUCT_OFFSET (MonoArray, vector));
-	ins->type = STACK_MP;
-	ins->klass = klass;
-	MONO_ADD_INS (cfg->cbb, ins);
-	return ins;
-}
-static MonoInst*
-mini_emit_ldelema_ins (MonoCompile *cfg, MonoMethod *cmethod, MonoInst **sp, guchar *ip, gboolean is_set)
-{
-	int rank;
-	MonoInst *addr;
-	MonoMethod *addr_method;
-	int element_size;
-	MonoClass *eclass = m_class_get_element_class (cmethod->klass);
-	gboolean bounded = m_class_get_byval_arg (cmethod->klass) ? m_class_get_byval_arg (cmethod->klass)->type == MONO_TYPE_ARRAY : FALSE;
-	rank = mono_method_signature_internal (cmethod)->param_count - (is_set? 1: 0);
-	if (rank == 1)
-		return mini_emit_ldelema_1_ins (cfg, eclass, sp [0], sp [1], TRUE, bounded);
-	/* emit_ldelema_2 depends on OP_LMUL */
-	if (!cfg->backend->emulate_mul_div && rank == 2 && (cfg->opt & MONO_OPT_INTRINS) && !mini_is_gsharedvt_variable_klass (eclass)) {
-		return mini_emit_ldelema_2_ins (cfg, eclass, sp [0], sp [1], sp [2]);
-	}
-	if (mini_is_gsharedvt_variable_klass (eclass))
-		element_size = 0;
-	else
-		element_size = mono_class_array_element_size (eclass);
-	addr_method = mono_marshal_get_array_address (rank, element_size);
-	addr = mono_emit_method_call (cfg, addr_method, sp, NULL);
-	return addr;
-}
-static gboolean
-mini_class_is_reference (MonoClass *klass)
-{
-	return mini_type_is_reference (m_class_get_byval_arg (klass));
-}
-MonoInst*
-mini_emit_array_store (MonoCompile *cfg, MonoClass *klass, MonoInst **sp, gboolean safety_checks)
-{
-	if (safety_checks && mini_class_is_reference (klass) &&
-		!(MONO_INS_IS_PCONST_NULL (sp [2]))) {
-		MonoClass *obj_array = mono_array_class_get_cached (mono_defaults.object_class);
-		MonoMethod *helper;
-		MonoInst *iargs [3];
-		if (sp [0]->type != STACK_OBJ)
-			return NULL;
-		if (sp [2]->type != STACK_OBJ)
-			return NULL;
-		MonoInst *index_ins = sp [1];
-#if SIZEOF_REGISTER == 8
-		if (sp [1]->type == STACK_I4) {
-			guint32 dreg = alloc_preg (cfg);
-			guint32 sreg = index_ins->dreg;
-			EMIT_NEW_UNALU (cfg, index_ins, OP_SEXT_I4, dreg, sreg);
-		}
-#endif
-		iargs [2] = sp [2];
-		iargs [1] = index_ins;
-		iargs [0] = sp [0];
-		MonoClass *array_class = sp [0]->klass;
-		if (array_class && m_class_get_rank (array_class) == 1) {
-			MonoClass *eclass = m_class_get_element_class (array_class);
-			if (m_class_is_sealed (eclass)) {
-				helper = mono_marshal_get_virtual_stelemref (array_class);
-				/* Make a non-virtual call if possible */
-				return mono_emit_method_call (cfg, helper, iargs, NULL);
-			}
-		}
-		helper = mono_marshal_get_virtual_stelemref (obj_array);
-		if (!helper->slot)
-			mono_class_setup_vtable (obj_array);
-		g_assert (helper->slot);
-		return mono_emit_method_call (cfg, helper, iargs, sp [0]);
-	} else {
-		MonoInst *ins;
-		if (mini_is_gsharedvt_variable_klass (klass)) {
-			MonoInst *addr;
-			addr = mini_emit_ldelema_1_ins (cfg, klass, sp [0], sp [1], TRUE, FALSE);
-			EMIT_NEW_STORE_MEMBASE_TYPE (cfg, ins, m_class_get_byval_arg (klass), addr->dreg, 0, sp [2]->dreg);
-			ins->opcode = OP_STOREV_MEMBASE;
-		} else if (sp [1]->opcode == OP_ICONST) {
-			int array_reg = sp [0]->dreg;
-			int index_reg = sp [1]->dreg;
-			size_t offset = (mono_class_array_element_size (klass) * sp [1]->inst_c0) + MONO_STRUCT_OFFSET (MonoArray, vector);
-			if (SIZEOF_REGISTER == 8 && COMPILE_LLVM (cfg) && sp [1]->inst_c0 < 0)
-				MONO_EMIT_NEW_UNALU (cfg, OP_ZEXT_I4, index_reg, index_reg);
-			if (safety_checks)
-				MONO_EMIT_BOUNDS_CHECK (cfg, array_reg, MonoArray, max_length, index_reg, FALSE);
-			EMIT_NEW_STORE_MEMBASE_TYPE (cfg, ins, m_class_get_byval_arg (klass), array_reg, (target_mgreg_t)offset, sp [2]->dreg);
-		} else {
-			MonoInst *addr = mini_emit_ldelema_1_ins (cfg, klass, sp [0], sp [1], safety_checks, FALSE);
-			if (!mini_debug_options.weak_memory_model && mini_class_is_reference (klass))
-				mini_emit_memory_barrier (cfg, MONO_MEMORY_BARRIER_REL);
-			EMIT_NEW_STORE_MEMBASE_TYPE (cfg, ins, m_class_get_byval_arg (klass), addr->dreg, 0, sp [2]->dreg);
-			if (mini_class_is_reference (klass))
-				mini_emit_write_barrier (cfg, addr, sp [2]);
-		}
-		return ins;
-	}
-}
-MonoInst*
-mini_emit_memory_barrier (MonoCompile *cfg, int kind)
-{
-	MonoInst *ins = NULL;
-	MONO_INST_NEW (cfg, ins, OP_MEMORY_BARRIER);
-	MONO_ADD_INS (cfg->cbb, ins);
-	ins->backend.memory_barrier_kind = kind;
-	return ins;
-}
-/*
- * This entry point could be used later for arbitrary method
- * redirection.
- */
-inline static MonoInst*
-mini_redirect_call (MonoCompile *cfg, MonoMethod *method,
-					MonoMethodSignature *signature, MonoInst **args, MonoInst *this_ins)
-{
-	if (method->klass == mono_defaults.string_class) {
-		/* managed string allocation support */
-		if (strcmp (method->name, "FastAllocateString") == 0) {
-			MonoInst *iargs [2];
-			MonoVTable *vtable = mono_class_vtable_checked (method->klass, cfg->error);
-			MonoMethod *managed_alloc = NULL;
-			mono_error_assert_ok (cfg->error); /*Should not fail since it System.String*/
-#ifndef MONO_CROSS_COMPILE
-			managed_alloc = mono_gc_get_managed_allocator (method->klass, FALSE, FALSE);
-#endif
-			if (!managed_alloc)
-				return NULL;
-			EMIT_NEW_VTABLECONST (cfg, iargs [0], vtable);
-			iargs [1] = args [0];
-			return mono_emit_method_call (cfg, managed_alloc, iargs, this_ins);
-		}
-	}
-	return NULL;
-}
-static void
-mono_save_args (MonoCompile *cfg, MonoMethodSignature *sig, MonoInst **sp)
-{
-	MonoInst *store, *temp;
-	for (guint i = 0; i < sig->param_count + sig->hasthis; ++i) {
-		MonoType *argtype = (sig->hasthis && (i == 0)) ? type_from_stack_type (*sp) : sig->params [i - sig->hasthis];
-		/*
-		 * FIXME: We should use *args++ = sp [0], but that would mean the arg
-		 * would be different than the MonoInst's used to represent arguments, and
-		 * the ldelema implementation can't deal with that.
-		 * Solution: When ldelema is used on an inline argument, create a var for
-		 * it, emit ldelema on that var, and emit the saving code below in
-		 * inline_method () if needed.
-		 */
-		temp = mono_compile_create_var (cfg, argtype, OP_LOCAL);
-		cfg->args [i] = temp;
-		/* This uses cfg->args [i] which is set by the preceding line */
-		EMIT_NEW_ARGSTORE (cfg, store, i, *sp);
-		store->cil_code = sp [0]->cil_code;
-		sp++;
-	}
-}
-#define MONO_INLINE_CALLED_LIMITED_METHODS 1
-#define MONO_INLINE_CALLER_LIMITED_METHODS 1
-#if (MONO_INLINE_CALLED_LIMITED_METHODS)
-static gboolean
-check_inline_called_method_name_limit (MonoMethod *called_method)
-{
-	int strncmp_result;
-	static const char *limit = NULL;
-	if (limit == NULL) {
-		const char *limit_string = g_getenv ("MONO_INLINE_CALLED_METHOD_NAME_LIMIT");
-		if (limit_string != NULL)
-			limit = limit_string;
-		else
-			limit = "";
-	}
-	if (limit [0] != '\0') {
-		char *called_method_name = mono_method_full_name (called_method, TRUE);
-		strncmp_result = strncmp (called_method_name, limit, strlen (limit));
-		g_free (called_method_name);
-		return (strncmp_result == 0);
-	} else {
-		return TRUE;
-	}
-}
-#endif
-#if (MONO_INLINE_CALLER_LIMITED_METHODS)
-static gboolean
-check_inline_caller_method_name_limit (MonoMethod *caller_method)
-{
-	int strncmp_result;
-	static const char *limit = NULL;
-	if (limit == NULL) {
-		const char *limit_string = g_getenv ("MONO_INLINE_CALLER_METHOD_NAME_LIMIT");
-		if (limit_string != NULL) {
-			limit = limit_string;
-		} else {
-			limit = "";
-		}
-	}
-	if (limit [0] != '\0') {
-		char *caller_method_name = mono_method_full_name (caller_method, TRUE);
-		strncmp_result = strncmp (caller_method_name, limit, strlen (limit));
-		g_free (caller_method_name);
-		return (strncmp_result == 0);
-	} else {
-		return TRUE;
-	}
-}
-#endif
-void
-mini_emit_init_rvar (MonoCompile *cfg, int dreg, MonoType *rtype)
-{
-	static double r8_0 = 0.0;
-	static float r4_0 = 0.0;
-	MonoInst *ins;
-	int t;
-	rtype = mini_get_underlying_type (rtype);
-	t = rtype->type;
-	if (m_type_is_byref (rtype)) {
-		MONO_EMIT_NEW_PCONST (cfg, dreg, NULL);
-	} else if (t >= MONO_TYPE_BOOLEAN && t <= MONO_TYPE_U4) {
-		MONO_EMIT_NEW_ICONST (cfg, dreg, 0);
-	} else if (t == MONO_TYPE_I8 || t == MONO_TYPE_U8) {
-		MONO_EMIT_NEW_I8CONST (cfg, dreg, 0);
-	} else if (cfg->r4fp && t == MONO_TYPE_R4) {
-		MONO_INST_NEW (cfg, ins, OP_R4CONST);
-		ins->type = STACK_R4;
-		ins->inst_p0 = (void*)&r4_0;
-		ins->dreg = dreg;
-		MONO_ADD_INS (cfg->cbb, ins);
-	} else if (t == MONO_TYPE_R4 || t == MONO_TYPE_R8) {
-		MONO_INST_NEW (cfg, ins, OP_R8CONST);
-		ins->type = STACK_R8;
-		ins->inst_p0 = (void*)&r8_0;
-		ins->dreg = dreg;
-		MONO_ADD_INS (cfg->cbb, ins);
-	} else if ((t == MONO_TYPE_VALUETYPE) || (t == MONO_TYPE_TYPEDBYREF) ||
-		   ((t == MONO_TYPE_GENERICINST) && mono_type_generic_inst_is_valuetype (rtype))) {
-		MONO_EMIT_NEW_VZERO (cfg, dreg, mono_class_from_mono_type_internal (rtype));
-	} else if (((t == MONO_TYPE_VAR) || (t == MONO_TYPE_MVAR)) && mini_type_var_is_vt (rtype)) {
-		MONO_EMIT_NEW_VZERO (cfg, dreg, mono_class_from_mono_type_internal (rtype));
-	} else {
-		MONO_EMIT_NEW_PCONST (cfg, dreg, NULL);
-	}
-}
-static void
-emit_dummy_init_rvar (MonoCompile *cfg, int dreg, MonoType *rtype)
-{
-	int t;
-	rtype = mini_get_underlying_type (rtype);
-	t = rtype->type;
-	if (m_type_is_byref (rtype)) {
-		MONO_EMIT_NEW_DUMMY_INIT (cfg, dreg, OP_DUMMY_PCONST);
-	} else if (t >= MONO_TYPE_BOOLEAN && t <= MONO_TYPE_U4) {
-		MONO_EMIT_NEW_DUMMY_INIT (cfg, dreg, OP_DUMMY_ICONST);
-	} else if (t == MONO_TYPE_I8 || t == MONO_TYPE_U8) {
-		MONO_EMIT_NEW_DUMMY_INIT (cfg, dreg, OP_DUMMY_I8CONST);
-	} else if (cfg->r4fp && t == MONO_TYPE_R4) {
-		MONO_EMIT_NEW_DUMMY_INIT (cfg, dreg, OP_DUMMY_R4CONST);
-	} else if (t == MONO_TYPE_R4 || t == MONO_TYPE_R8) {
-		MONO_EMIT_NEW_DUMMY_INIT (cfg, dreg, OP_DUMMY_R8CONST);
-	} else if ((t == MONO_TYPE_VALUETYPE) || (t == MONO_TYPE_TYPEDBYREF) ||
-		   ((t == MONO_TYPE_GENERICINST) && mono_type_generic_inst_is_valuetype (rtype))) {
-		MONO_EMIT_NEW_DUMMY_INIT (cfg, dreg, OP_DUMMY_VZERO);
-	} else if (((t == MONO_TYPE_VAR) || (t == MONO_TYPE_MVAR)) && mini_type_var_is_vt (rtype)) {
-		MONO_EMIT_NEW_DUMMY_INIT (cfg, dreg, OP_DUMMY_VZERO);
-	} else {
-		mini_emit_init_rvar (cfg, dreg, rtype);
-	}
-}
-/* If INIT is FALSE, emit dummy initialization statements to keep the IR valid */
-static void
-emit_init_local (MonoCompile *cfg, int local, MonoType *type, gboolean init)
-{
-	MonoInst *var = cfg->locals [local];
-	if (COMPILE_SOFT_FLOAT (cfg)) {
-		MonoInst *store;
-		int reg = alloc_dreg (cfg, (MonoStackType)var->type);
-		mini_emit_init_rvar (cfg, reg, type);
-		EMIT_NEW_LOCSTORE (cfg, store, local, cfg->cbb->last_ins);
-	} else {
-		if (init)
-			mini_emit_init_rvar (cfg, var->dreg, type);
-		else
-			emit_dummy_init_rvar (cfg, var->dreg, type);
-	}
-}
-int
-mini_inline_method (MonoCompile *cfg, MonoMethod *cmethod, MonoMethodSignature *fsig, MonoInst **sp, guchar *ip, guint real_offset, gboolean inline_always)
-{
-	return inline_method (cfg, cmethod, fsig, sp, ip, real_offset, inline_always, NULL);
-}
-static gboolean
-aggressive_inline_method (MonoCompile *cfg, MonoMethod *cmethod)
-{
-	gboolean aggressive_inline = m_method_is_aggressive_inlining (cmethod);
-	if (aggressive_inline)
-		aggressive_inline = !mono_simd_unsupported_aggressive_inline_intrinsic_type (cfg, cmethod);
-	return aggressive_inline;
-}
-/*
- * inline_method:
- *
- * Return the cost of inlining CMETHOD, or zero if it should not be inlined.
- */
-static int
-inline_method (MonoCompile *cfg, MonoMethod *cmethod, MonoMethodSignature *fsig, MonoInst **sp,
-			   guchar *ip, guint real_offset, gboolean inline_always, gboolean *is_empty)
-{
-	ERROR_DECL (error);
-	MonoInst *ins, *rvar = NULL;
-	MonoMethodHeader *cheader;
-	MonoBasicBlock *ebblock, *sbblock;
-	int i, costs;
-	MonoInst **prev_locals, **prev_args;
-	MonoType **prev_arg_types;
-	guint prev_real_offset;
-	GHashTable *prev_cbb_hash;
-	MonoBasicBlock **prev_cil_offset_to_bb;
-	MonoBasicBlock *prev_cbb;
-	const guchar *prev_ip;
-	guchar *prev_cil_start;
-	guint32 prev_cil_offset_to_bb_len;
-	MonoMethod *prev_current_method;
-	MonoGenericContext *prev_generic_context;
-	gboolean ret_var_set, prev_ret_var_set, prev_disable_inline, virtual_ = FALSE;
-	g_assert (cfg->exception_type == MONO_EXCEPTION_NONE);
-#if (MONO_INLINE_CALLED_LIMITED_METHODS)
-	if ((! inline_always) && ! check_inline_called_method_name_limit (cmethod))
-		return 0;
-#endif
-#if (MONO_INLINE_CALLER_LIMITED_METHODS)
-	if ((! inline_always) && ! check_inline_caller_method_name_limit (cfg->method))
-		return 0;
-#endif
-	if (!fsig)
-		fsig = mono_method_signature_internal (cmethod);
-	if (cfg->verbose_level > 2)
-		printf ("INLINE START %p %s -> %s\n", cmethod,  mono_method_full_name (cfg->method, TRUE), mono_method_full_name (cmethod, TRUE));
-	if (!cmethod->inline_info) {
-		cfg->stat_inlineable_methods++;
-		cmethod->inline_info = 1;
-	}
-	if (is_empty)
-		*is_empty = FALSE;
-	/* allocate local variables */
-	cheader = mono_method_get_header_checked (cmethod, error);
-	if (!cheader) {
-		if (inline_always) {
-			mono_cfg_set_exception (cfg, MONO_EXCEPTION_MONO_ERROR);
-			mono_error_move (cfg->error, error);
-		} else {
-			mono_error_cleanup (error);
-		}
-		return 0;
-	}
-	if (is_empty && cheader->code_size == 1 && cheader->code [0] == CEE_RET)
-		*is_empty = TRUE;
-	/* allocate space to store the return value */
-	if (!MONO_TYPE_IS_VOID (fsig->ret)) {
-		rvar = mono_compile_create_var (cfg, fsig->ret, OP_LOCAL);
-	}
-	prev_locals = cfg->locals;
-	cfg->locals = (MonoInst **)mono_mempool_alloc0 (cfg->mempool, cheader->num_locals * sizeof (MonoInst*));
-	for (i = 0; i < cheader->num_locals; ++i)
-		cfg->locals [i] = mono_compile_create_var (cfg, cheader->locals [i], OP_LOCAL);
-	/* allocate start and end blocks */
-	/* This is needed so if the inline is aborted, we can clean up */
-	NEW_BBLOCK (cfg, sbblock);
-	sbblock->real_offset = real_offset;
-	NEW_BBLOCK (cfg, ebblock);
-	ebblock->block_num = cfg->num_bblocks++;
-	ebblock->real_offset = real_offset;
-	prev_args = cfg->args;
-	prev_arg_types = cfg->arg_types;
-	prev_ret_var_set = cfg->ret_var_set;
-	prev_real_offset = cfg->real_offset;
-	prev_cbb_hash = cfg->cbb_hash;
-	prev_cil_offset_to_bb = cfg->cil_offset_to_bb;
-	prev_cil_offset_to_bb_len = cfg->cil_offset_to_bb_len;
-	prev_cil_start = cfg->cil_start;
-	prev_ip = cfg->ip;
-	prev_cbb = cfg->cbb;
-	prev_current_method = cfg->current_method;
-	prev_generic_context = cfg->generic_context;
-	prev_disable_inline = cfg->disable_inline;
-	cfg->ret_var_set = FALSE;
-	cfg->inline_depth ++;
-	if (ip && *ip == CEE_CALLVIRT && !(cmethod->flags & METHOD_ATTRIBUTE_STATIC))
-		virtual_ = TRUE;
-	costs = mono_method_to_ir (cfg, cmethod, sbblock, ebblock, rvar, sp, real_offset, virtual_);
-	ret_var_set = cfg->ret_var_set;
-	cfg->real_offset = prev_real_offset;
-	cfg->cbb_hash = prev_cbb_hash;
-	cfg->cil_offset_to_bb = prev_cil_offset_to_bb;
-	cfg->cil_offset_to_bb_len = prev_cil_offset_to_bb_len;
-	cfg->cil_start = prev_cil_start;
-	cfg->ip = prev_ip;
-	cfg->locals = prev_locals;
-	cfg->args = prev_args;
-	cfg->arg_types = prev_arg_types;
-	cfg->current_method = prev_current_method;
-	cfg->generic_context = prev_generic_context;
-	cfg->ret_var_set = prev_ret_var_set;
-	cfg->disable_inline = prev_disable_inline;
-	cfg->inline_depth --;
-	if ((costs >= 0 && costs < 60) || inline_always || (costs >= 0 && aggressive_inline_method (cfg, cmethod))) {
-		if (cfg->verbose_level > 2)
-			printf ("INLINE END %s -> %s\n", mono_method_full_name (cfg->method, TRUE), mono_method_full_name (cmethod, TRUE));
-		mono_error_assert_ok (cfg->error);
-		cfg->stat_inlined_methods++;
-		/* always add some code to avoid block split failures */
-		MONO_INST_NEW (cfg, ins, OP_NOP);
-		MONO_ADD_INS (prev_cbb, ins);
-		prev_cbb->next_bb = sbblock;
-		link_bblock (cfg, prev_cbb, sbblock);
-		/*
-		 * Get rid of the begin and end bblocks if possible to aid local
-		 * optimizations.
-		 */
-		if (prev_cbb->out_count == 1)
-			mono_merge_basic_blocks (cfg, prev_cbb, sbblock);
-		if ((prev_cbb->out_count == 1) && (prev_cbb->out_bb [0]->in_count == 1) && (prev_cbb->out_bb [0] != ebblock))
-			mono_merge_basic_blocks (cfg, prev_cbb, prev_cbb->out_bb [0]);
-		if ((ebblock->in_count == 1) && ebblock->in_bb [0]->out_count == 1) {
-			MonoBasicBlock *prev = ebblock->in_bb [0];
-			if (prev->next_bb == ebblock) {
-				mono_merge_basic_blocks (cfg, prev, ebblock);
-				cfg->cbb = prev;
-				if ((prev_cbb->out_count == 1) && (prev_cbb->out_bb [0]->in_count == 1) && (prev_cbb->out_bb [0] == prev)) {
-					mono_merge_basic_blocks (cfg, prev_cbb, prev);
-					cfg->cbb = prev_cbb;
-				}
-			} else {
-				/* There could be a bblock after 'prev', and making 'prev' the current bb could cause problems */
-				cfg->cbb = ebblock;
-			}
-		} else {
-			/*
-			 * Its possible that the rvar is set in some prev bblock, but not in others.
-			 * (#1835).
-			 */
-			if (rvar) {
-				MonoBasicBlock *bb;
-				for (i = 0; i < ebblock->in_count; ++i) {
-					bb = ebblock->in_bb [i];
-					if (bb->last_ins && bb->last_ins->opcode == OP_NOT_REACHED) {
-						cfg->cbb = bb;
-						mini_emit_init_rvar (cfg, rvar->dreg, fsig->ret);
-					}
-				}
-			}
-			cfg->cbb = ebblock;
-		}
-		if (rvar) {
-			/*
-			 * If the inlined method contains only a throw, then the ret var is not
-			 * set, so set it to a dummy value.
-			 */
-			if (!ret_var_set)
-				mini_emit_init_rvar (cfg, rvar->dreg, fsig->ret);
-			EMIT_NEW_TEMPLOAD (cfg, ins, rvar->inst_c0);
-			*sp++ = ins;
-		}
-		cfg->headers_to_free = g_slist_prepend_mempool (cfg->mempool, cfg->headers_to_free, cheader);
-		return costs + 1;
-	} else {
-		if (cfg->verbose_level > 2) {
-			const char *msg = mono_error_get_message (cfg->error);
-			printf ("INLINE ABORTED %s (cost %d) %s\n", mono_method_full_name (cmethod, TRUE), costs, msg ? msg : "");
-		}
-		cfg->exception_type = MONO_EXCEPTION_NONE;
-		clear_cfg_error (cfg);
-		/* This gets rid of the newly added bblocks */
-		cfg->cbb = prev_cbb;
-	}
-	cfg->headers_to_free = g_slist_prepend_mempool (cfg->mempool, cfg->headers_to_free, cheader);
-	return 0;
-}
-/*
- * Some of these comments may well be out-of-date.
- * Design decisions: we do a single pass over the IL code (and we do bblock
- * splitting/merging in the few cases when it's required: a back jump to an IL
- * address that was not already seen as bblock starting point).
- * Code is validated as we go (full verification is still better left to metadata/verify.c).
- * Complex operations are decomposed in simpler ones right away. We need to let the
- * arch-specific code peek and poke inside this process somehow (except when the
- * optimizations can take advantage of the full semantic info of coarse opcodes).
- * All the opcodes of the form opcode.s are 'normalized' to opcode.
- * MonoInst->opcode initially is the IL opcode or some simplification of that
- * (OP_LOAD, OP_STORE). The arch-specific code may rearrange it to an arch-specific
- * opcode with value bigger than OP_LAST.
- * At this point the IR can be handed over to an interpreter, a dumb code generator
- * or to the optimizing code generator that will translate it to SSA form.
- *
- * Profiling directed optimizations.
- * We may compile by default with few or no optimizations and instrument the code
- * or the user may indicate what methods to optimize the most either in a config file
- * or through repeated runs where the compiler applies offline the optimizations to
- * each method and then decides if it was worth it.
- */
-#define CHECK_TYPE(ins) if (!(ins)->type) UNVERIFIED
-#define CHECK_STACK(num) if ((sp - stack_start) < (num)) UNVERIFIED
-#define CHECK_STACK_OVF() if (((sp - stack_start) + 1) > header->max_stack) UNVERIFIED
-#define CHECK_ARG(num) if ((unsigned)(num) >= (unsigned)num_args) UNVERIFIED
-#define CHECK_LOCAL(num) if ((unsigned)(num) >= (unsigned)header->num_locals) UNVERIFIED
-#define CHECK_OPSIZE(size) if ((size) < 1 || ip + (size) > end) UNVERIFIED
-#define CHECK_UNVERIFIABLE(cfg) if (cfg->unverifiable) UNVERIFIED
-#define CHECK_TYPELOAD(klass) if (!(klass) || mono_class_has_failure (klass)) TYPE_LOAD_ERROR ((klass))
-#define CLEAR_TYPELOAD_EXCEPTION(cfg) if (cfg->exception_type == MONO_EXCEPTION_TYPE_LOAD) { clear_cfg_error (cfg); cfg->exception_type = MONO_EXCEPTION_NONE; }
-#define CLASS_HAS_FAILURE(klass) (!(klass) || mono_class_has_failure (klass))
-#define HANDLE_TYPELOAD_ERROR(cfg,klass) do { \
-		if (!cfg->compile_aot) \
-			TYPE_LOAD_ERROR ((klass)); \
-		emit_type_load_failure (cfg, klass); \
-		CLEAR_TYPELOAD_EXCEPTION (cfg); \
-	} while (0)
-/* offset from br.s -> br like opcodes */
-#define BIG_BRANCH_OFFSET 13
-static gboolean
-ip_in_bb (MonoCompile *cfg, MonoBasicBlock *bb, const guint8* ip)
-{
-	MonoBasicBlock *b = cfg->cil_offset_to_bb [ip - cfg->cil_start];
-	return b == NULL || b == bb;
-}
-static int
-get_basic_blocks (MonoCompile *cfg, MonoMethodHeader* header, guint real_offset, guchar *start, guchar *end, guchar **pos)
-{
-	guchar *ip = start;
-	guchar *target;
-	int i;
-	guint cli_addr;
-	MonoBasicBlock *bblock;
-	const MonoOpcode *opcode;
-	while (ip < end) {
-		cli_addr = GPTRDIFF_TO_UINT (ip - start);
-		i = mono_opcode_value ((const guint8 **)&ip, end);
-		if (i < 0)
-			UNVERIFIED;
-		opcode = &mono_opcodes [i];
-		switch (opcode->argument) {
-		case MonoInlineNone:
-			ip++;
-			break;
-		case MonoInlineString:
-		case MonoInlineType:
-		case MonoInlineField:
-		case MonoInlineMethod:
-		case MonoInlineTok:
-		case MonoInlineSig:
-		case MonoShortInlineR:
-		case MonoInlineI:
-			ip += 5;
-			break;
-		case MonoInlineVar:
-			ip += 3;
-			break;
-		case MonoShortInlineVar:
-		case MonoShortInlineI:
-			ip += 2;
-			break;
-		case MonoShortInlineBrTarget:
-			target = start + cli_addr + 2 + (signed char)ip [1];
-			GET_BBLOCK (cfg, bblock, target);
-			ip += 2;
-			if (ip < end)
-				GET_BBLOCK (cfg, bblock, ip);
-			break;
-		case MonoInlineBrTarget:
-			target = start + cli_addr + 5 + (gint32)read32 (ip + 1);
-			GET_BBLOCK (cfg, bblock, target);
-			ip += 5;
-			if (ip < end)
-				GET_BBLOCK (cfg, bblock, ip);
-			break;
-		case MonoInlineSwitch: {
-			guint32 n = read32 (ip + 1);
-			guint32 j;
-			ip += 5;
-			cli_addr += 5 + 4 * n;
-			target = start + cli_addr;
-			GET_BBLOCK (cfg, bblock, target);
-			for (j = 0; j < n; ++j) {
-				target = start + cli_addr + (gint32)read32 (ip);
-				GET_BBLOCK (cfg, bblock, target);
-				ip += 4;
-			}
-			break;
-		}
-		case MonoInlineR:
-		case MonoInlineI8:
-			ip += 9;
-			break;
-		default:
-			g_assert_not_reached ();
-		}
-		if (i == CEE_THROW) {
-			guchar *bb_start = ip - 1;
-			/* Find the start of the bblock containing the throw */
-			bblock = NULL;
-			while ((bb_start >= start) && !bblock) {
-				bblock = cfg->cil_offset_to_bb [(bb_start) - start];
-				bb_start --;
-			}
-			if (bblock)
-				bblock->out_of_line = 1;
-		}
-	}
-	return 0;
-unverified:
-exception_exit:
-	*pos = ip;
-	return 1;
-}
-static MonoMethod *
-mini_get_method_allow_open (MonoMethod *m, guint32 token, MonoClass *klass, MonoGenericContext *context, MonoError *error)
-{
-	MonoMethod *method;
-	error_init (error);
-	if (m->wrapper_type != MONO_WRAPPER_NONE) {
-		method = (MonoMethod *)mono_method_get_wrapper_data (m, token);
-		if (context) {
-			method = mono_class_inflate_generic_method_checked (method, context, error);
-		}
-	} else {
-		method = mono_get_method_checked (m_class_get_image (m->klass), token, klass, context, error);
-	}
-	return method;
-}
-static MonoMethod *
-mini_get_method (MonoCompile *cfg, MonoMethod *m, guint32 token, MonoClass *klass, MonoGenericContext *context)
-{
-	ERROR_DECL (error);
-	MonoMethod *method = mini_get_method_allow_open (m, token, klass, context, cfg ? cfg->error : error);
-	if (method && cfg && !cfg->gshared && mono_class_is_open_constructed_type (m_class_get_byval_arg (method->klass))) {
-		mono_error_set_bad_image (cfg->error, m_class_get_image (cfg->method->klass), "Method with open type while not compiling gshared");
-		method = NULL;
-	}
-	if (!method && !cfg)
-		mono_error_cleanup (error); /* FIXME don't swallow the error */
-	return method;
-}
-static MonoMethodSignature*
-mini_get_signature (MonoMethod *method, guint32 token, MonoGenericContext *context, MonoError *error)
-{
-	MonoMethodSignature *fsig;
-	error_init (error);
-	if (method->wrapper_type != MONO_WRAPPER_NONE) {
-		fsig = (MonoMethodSignature *)mono_method_get_wrapper_data (method, token);
-	} else {
-		fsig = mono_metadata_parse_signature_checked (m_class_get_image (method->klass), token, error);
-		return_val_if_nok (error, NULL);
-	}
-	if (context) {
-		fsig = mono_inflate_generic_signature(fsig, context, error);
-	}
-	return fsig;
-}
-/*
- * Return the original method is a wrapper is specified. We can only access
- * the custom attributes from the original method.
- */
-static MonoMethod*
-get_original_method (MonoMethod *method)
-{
-	if (method->wrapper_type == MONO_WRAPPER_NONE)
-		return method;
-	/* native code (which is like Critical) can call any managed method XXX FIXME XXX to validate all usages */
-	if (method->wrapper_type == MONO_WRAPPER_NATIVE_TO_MANAGED)
-		return NULL;
-	/* in other cases we need to find the original method */
-	return mono_marshal_method_from_wrapper (method);
-}
-static guchar*
-il_read_op (guchar *ip, guchar *end, guchar first_byte, MonoOpcodeEnum desired_il_op)
-{
-	if (G_LIKELY (ip < end) && G_UNLIKELY (*ip == first_byte)) {
-		MonoOpcodeEnum il_op = MonoOpcodeEnum_Invalid;
-		const guchar *temp_ip = ip;
-		const int size = mono_opcode_value_and_size (&temp_ip, end, &il_op);
-		return (G_LIKELY (size > 0) && G_UNLIKELY (il_op == desired_il_op)) ? (ip + size) : NULL;
-	}
-	return NULL;
-}
-static guchar*
-il_read_op_and_token (guchar *ip, guchar *end, guchar first_byte, MonoOpcodeEnum desired_il_op, guint32 *token)
-{
-	ip = il_read_op (ip, end, first_byte, desired_il_op);
-	if (ip)
-		*token = read32 (ip - 4); // could be +1 or +2 from start
-	return ip;
-}
-static guchar*
-il_read_branch_and_target (guchar *ip, guchar *end, guchar first_byte, MonoOpcodeEnum desired_il_op, int size, guchar **target)
-{
-	ip = il_read_op (ip, end, first_byte, desired_il_op);
-	if (ip) {
-		gint32 delta = 0;
-		switch (size) {
-		case  1:
-			delta = (signed char)ip [-1];
-			break;
-		case  4:
-			delta = (gint32)read32 (ip - 4);
-			break;
-		}
-		*target = ip + delta;
-		return ip;
-	}
-	return NULL;
-}
-#define il_read_brtrue(ip, end, target) 	(il_read_branch_and_target (ip, end, CEE_BRTRUE,    MONO_CEE_BRTRUE,    4, target))
-#define il_read_brtrue_s(ip, end, target) 	(il_read_branch_and_target (ip, end, CEE_BRTRUE_S,  MONO_CEE_BRTRUE_S,  1, target))
-#define il_read_brfalse(ip, end, target) 	(il_read_branch_and_target (ip, end, CEE_BRFALSE,   MONO_CEE_BRFALSE,   4, target))
-#define il_read_brfalse_s(ip, end, target) 	(il_read_branch_and_target (ip, end, CEE_BRFALSE_S, MONO_CEE_BRFALSE_S, 1, target))
-#define il_read_dup(ip, end) 			(il_read_op 		   (ip, end, CEE_DUP, MONO_CEE_DUP))
-#define il_read_newobj(ip, end, token) 		(il_read_op_and_token 	   (ip, end, CEE_NEW_OBJ, MONO_CEE_NEWOBJ, token))
-#define il_read_ldtoken(ip, end, token) 	(il_read_op_and_token 	   (ip, end, CEE_LDTOKEN, MONO_CEE_LDTOKEN, token))
-#define il_read_call(ip, end, token) 		(il_read_op_and_token      (ip, end, CEE_CALL, MONO_CEE_CALL, token))
-#define il_read_callvirt(ip, end, token)	(il_read_op_and_token 	   (ip, end, CEE_CALLVIRT, MONO_CEE_CALLVIRT, token))
-#define il_read_initobj(ip, end, token)         (il_read_op_and_token 	   (ip, end, CEE_PREFIX1, MONO_CEE_INITOBJ, token))
-#define il_read_constrained(ip, end, token)     (il_read_op_and_token      (ip, end, CEE_PREFIX1, MONO_CEE_CONSTRAINED_, token))
-#define il_read_unbox_any(ip, end, token)     (il_read_op_and_token      (ip, end, CEE_UNBOX_ANY, MONO_CEE_UNBOX_ANY, token))
-/*
- * Check that the IL instructions at ip are the array initialization
- * sequence and return the pointer to the data and the size.
- */
-static const char*
-initialize_array_data (MonoCompile *cfg, MonoMethod *method, gboolean aot, guchar *ip,
-		guchar *end, MonoClass *klass, guint32 len, int *out_size,
-		guint32 *out_field_token, MonoOpcodeEnum *il_op, guchar **next_ip)
-{
-	/*
-	 * newarr[System.Int32]
-	 * dup
-	 * ldtoken field valuetype ...
-	 * call void class [mscorlib]System.Runtime.CompilerServices.RuntimeHelpers::InitializeArray(class [mscorlib]System.Array, valuetype [mscorlib]System.RuntimeFieldHandle)
-	 */
-	guint32 token;
-	guint32 field_token;
-	if  ((ip = il_read_dup (ip, end))
-			&& ip_in_bb (cfg, cfg->cbb, ip)
-			&& (ip = il_read_ldtoken (ip, end, &field_token))
-			&& IS_FIELD_DEF (field_token)
-			&& ip_in_bb (cfg, cfg->cbb, ip)
-			&& (ip = il_read_call (ip, end, &token))) {
-		ERROR_DECL (error);
-		guint32 rva;
-		const char *data_ptr;
-		int size = 0;
-		MonoMethod *cmethod;
-		MonoClass *dummy_class;
-		MonoClassField *field = mono_field_from_token_checked (m_class_get_image (method->klass), field_token, &dummy_class, NULL, error);
-		int dummy_align;
-		if (!field) {
-			mono_error_cleanup (error); /* FIXME don't swallow the error */
-			return NULL;
-		}
-		*out_field_token = field_token;
-		cmethod = mini_get_method (NULL, method, token, NULL, NULL);
-		if (!cmethod)
-			return NULL;
-		if (strcmp (cmethod->name, "InitializeArray") || strcmp (m_class_get_name (cmethod->klass), "RuntimeHelpers") || m_class_get_image (cmethod->klass) != mono_defaults.corlib)
-			return NULL;
-		switch (mini_get_underlying_type (m_class_get_byval_arg (klass))->type) {
-		case MONO_TYPE_I1:
-		case MONO_TYPE_U1:
-			size = 1; break;
-		/* we need to swap on big endian, so punt. Should we handle R4 and R8 as well? */
-#if TARGET_BYTE_ORDER == G_LITTLE_ENDIAN
-		case MONO_TYPE_I2:
-		case MONO_TYPE_U2:
-			size = 2; break;
-		case MONO_TYPE_I4:
-		case MONO_TYPE_U4:
-		case MONO_TYPE_R4:
-			size = 4; break;
-		case MONO_TYPE_R8:
-		case MONO_TYPE_I8:
-		case MONO_TYPE_U8:
-			size = 8; break;
-#endif
-		default:
-			return NULL;
-		}
-		size *= len;
-		if (size > mono_type_size (field->type, &dummy_align))
-		    return NULL;
-		*out_size = size;
-		/*g_print ("optimized in %s: size: %d, numelems: %d\n", method->name, size, newarr->inst_newa_len->inst_c0);*/
-		MonoImage *method_klass_image = m_class_get_image (method->klass);
-		if (!image_is_dynamic (method_klass_image)) {
-			guint32 field_index = mono_metadata_token_index (field_token);
-			mono_metadata_field_info (method_klass_image, field_index - 1, NULL, &rva, NULL);
-			data_ptr = mono_image_rva_map (method_klass_image, rva);
-			/*g_print ("field: 0x%08x, rva: %d, rva_ptr: %p\n", read32 (ip + 2), rva, data_ptr);*/
-			/* for aot code we do the lookup on load */
-			if (aot && data_ptr)
-				data_ptr = (const char *)GUINT_TO_POINTER (rva);
-		} else {
-			/*FIXME is it possible to AOT a SRE assembly not meant to be saved? */
-			g_assert (!aot);
-			data_ptr = mono_field_get_data (field);
-		}
-		if (!data_ptr)
-			return NULL;
-		*il_op = MONO_CEE_CALL;
-		*next_ip = ip;
-		return data_ptr;
-	}
-	return NULL;
-}
-static void
-set_exception_type_from_invalid_il (MonoCompile *cfg, MonoMethod *method, guchar *ip)
-{
-	ERROR_DECL (error);
-	char *method_fname = mono_method_full_name (method, TRUE);
-	char *method_code;
-	MonoMethodHeader *header = mono_method_get_header_checked (method, error);
-	if (!header) {
-		method_code = g_strdup_printf ("could not parse method body due to %s", mono_error_get_message (error));
-		mono_error_cleanup (error);
-	} else if (header->code_size == 0)
-		method_code = g_strdup ("method body is empty.");
-	else
-		method_code = mono_disasm_code_one (NULL, method, ip, NULL);
-	mono_cfg_set_exception_invalid_program (cfg, g_strdup_printf ("Invalid IL code in %s: %s\n", method_fname, method_code));
- 	g_free (method_fname);
- 	g_free (method_code);
-	cfg->headers_to_free = g_slist_prepend_mempool (cfg->mempool, cfg->headers_to_free, header);
-}
-guint32
-mono_type_to_stloc_coerce (MonoType *type)
-{
-	if (m_type_is_byref (type))
-		return 0;
-	type = mini_get_underlying_type (type);
-handle_enum:
-	switch (type->type) {
-	case MONO_TYPE_I1:
-		return OP_ICONV_TO_I1;
-	case MONO_TYPE_U1:
-		return OP_ICONV_TO_U1;
-	case MONO_TYPE_I2:
-		return OP_ICONV_TO_I2;
-	case MONO_TYPE_U2:
-		return OP_ICONV_TO_U2;
-	case MONO_TYPE_I4:
-	case MONO_TYPE_U4:
-	case MONO_TYPE_I:
-	case MONO_TYPE_U:
-	case MONO_TYPE_PTR:
-	case MONO_TYPE_FNPTR:
-	case MONO_TYPE_CLASS:
-	case MONO_TYPE_STRING:
-	case MONO_TYPE_OBJECT:
-	case MONO_TYPE_SZARRAY:
-	case MONO_TYPE_ARRAY:
-	case MONO_TYPE_I8:
-	case MONO_TYPE_U8:
-	case MONO_TYPE_R4:
-	case MONO_TYPE_R8:
-	case MONO_TYPE_TYPEDBYREF:
-	case MONO_TYPE_GENERICINST:
-		return 0;
-	case MONO_TYPE_VALUETYPE:
-		if (m_class_is_enumtype (type->data.klass)) {
-			type = mono_class_enum_basetype_internal (type->data.klass);
-			goto handle_enum;
-		}
-		return 0;
-	case MONO_TYPE_VAR:
-	case MONO_TYPE_MVAR: //TODO I believe we don't need to handle gsharedvt as there won't be match and, for example, u1 is not covariant to u32
-		return 0;
-	default:
-		g_error ("unknown type 0x%02x in mono_type_to_stloc_coerce", type->type);
-	}
-	return -1;
-}
-static void
-emit_stloc_ir (MonoCompile *cfg, MonoInst **sp, MonoMethodHeader *header, int n)
-{
-	MonoInst *ins;
-	guint32 coerce_op = mono_type_to_stloc_coerce (header->locals [n]);
-	if (coerce_op) {
-		if (cfg->cbb->last_ins == sp [0] && sp [0]->opcode == coerce_op) {
-			if (cfg->verbose_level > 2)
-				printf ("Found existing coercing is enough for stloc\n");
-		} else {
-			MONO_INST_NEW (cfg, ins, coerce_op);
-			ins->dreg = alloc_ireg (cfg);
-			ins->sreg1 = sp [0]->dreg;
-			ins->type = STACK_I4;
-			ins->klass = mono_class_from_mono_type_internal (header->locals [n]);
-			MONO_ADD_INS (cfg->cbb, ins);
-			*sp = mono_decompose_opcode (cfg, ins);
-		}
-	}
-	guint32 opcode = mono_type_to_regmove (cfg, header->locals [n]);
-	if (!cfg->deopt && (opcode == OP_MOVE) && cfg->cbb->last_ins == sp [0]  &&
-			((sp [0]->opcode == OP_ICONST) || (sp [0]->opcode == OP_I8CONST))) {
-		/* Optimize reg-reg moves away */
-		/*
-		 * Can't optimize other opcodes, since sp[0] might point to
-		 * the last ins of a decomposed opcode.
-		 */
-		sp [0]->dreg = (cfg)->locals [n]->dreg;
-	} else {
-		EMIT_NEW_LOCSTORE (cfg, ins, n, *sp);
-	}
-}
-static void
-emit_starg_ir (MonoCompile *cfg, MonoInst **sp, int n)
-{
-	MonoInst *ins;
-	guint32 coerce_op = mono_type_to_stloc_coerce (cfg->arg_types [n]);
-	if (coerce_op) {
-		if (cfg->cbb->last_ins == sp [0] && sp [0]->opcode == coerce_op) {
-			if (cfg->verbose_level > 2)
-				printf ("Found existing coercing is enough for starg\n");
-		} else {
-			MONO_INST_NEW (cfg, ins, coerce_op);
-			ins->dreg = alloc_ireg (cfg);
-			ins->sreg1 = sp [0]->dreg;
-			ins->type = STACK_I4;
-			ins->klass = mono_class_from_mono_type_internal (cfg->arg_types [n]);
-			MONO_ADD_INS (cfg->cbb, ins);
-			*sp = mono_decompose_opcode (cfg, ins);
-		}
-	}
-	EMIT_NEW_ARGSTORE (cfg, ins, n, *sp);
-}
-/*
- * ldloca inhibits many optimizations so try to get rid of it in common
- * cases.
- */
-static guchar *
-emit_optimized_ldloca_ir (MonoCompile *cfg, guchar *ip, guchar *end, int local)
-{
-	guint32 token;
-	MonoClass *klass;
-	MonoType *type;
-	guchar *start = ip;
-	if  ((ip = il_read_initobj (ip, end, &token)) && ip_in_bb (cfg, cfg->cbb, start + 1)) {
-		/* From the INITOBJ case */
-		klass = mini_get_class (cfg->current_method, token, cfg->generic_context);
-		if (CLASS_HAS_FAILURE (klass)) {
-			HANDLE_TYPELOAD_ERROR (cfg, klass);
-		}
-		type = mini_get_underlying_type (m_class_get_byval_arg (klass));
-		emit_init_local (cfg, local, type, TRUE);
-		return ip;
-	}
- exception_exit:
-	return NULL;
-}
-static MonoInst*
-handle_call_res_devirt (MonoCompile *cfg, MonoMethod *cmethod, MonoInst *call_res)
-{
-	MonoClass *ret_klass = mini_handle_call_res_devirt (cmethod);
-	if (ret_klass) {
-		MonoInst *typed_objref;
-		MONO_INST_NEW (cfg, typed_objref, OP_TYPED_OBJREF);
-		typed_objref->type = STACK_OBJ;
-		typed_objref->dreg = alloc_ireg_ref (cfg);
-		typed_objref->sreg1 = call_res->dreg;
-		typed_objref->klass = ret_klass;
-		MONO_ADD_INS (cfg->cbb, typed_objref);
-		call_res = typed_objref;
-		/* Force decompose */
-		cfg->flags |= MONO_CFG_NEEDS_DECOMPOSE;
-		cfg->cbb->needs_decompose = TRUE;
-	}
-	return call_res;
-}
-static gboolean
-is_exception_class (MonoClass *klass)
-{
-	if (G_LIKELY (m_class_get_supertypes (klass)))
-		return mono_class_has_parent_fast (klass, mono_defaults.exception_class);
-	while (klass) {
-		if (klass == mono_defaults.exception_class)
-			return TRUE;
-		klass = m_class_get_parent (klass);
-	}
-	return FALSE;
-}
-/*
- * is_jit_optimizer_disabled:
- *
- *   Determine whenever M's assembly has a DebuggableAttribute with the
- * IsJITOptimizerDisabled flag set.
- */
-static gboolean
-is_jit_optimizer_disabled (MonoMethod *m)
-{
-	MonoAssembly *ass = m_class_get_image (m->klass)->assembly;
-	g_assert (ass);
-	if (ass->jit_optimizer_disabled_inited)
-		return ass->jit_optimizer_disabled;
-	return mono_assembly_is_jit_optimizer_disabled (ass);
-}
-gboolean
-mono_is_supported_tailcall_helper (gboolean value, const char *svalue)
-{
-	if (!value)
-		mono_tailcall_print ("%s %s\n", __func__, svalue);
-	return value;
-}
-static gboolean
-mono_is_not_supported_tailcall_helper (gboolean value, const char *svalue, MonoMethod *method, MonoMethod *cmethod)
-{
-	if (value && mono_tailcall_print_enabled ()) {
-		const char *lparen = strchr (svalue, ' ') ? "(" : "";
-		const char *rparen = *lparen ? ")" : "";
-		mono_tailcall_print ("%s %s -> %s %s%s%s:%d\n", __func__, method->name, cmethod->name, lparen, svalue, rparen, value);
-	}
-	return value;
-}
-#define IS_NOT_SUPPORTED_TAILCALL(x) (mono_is_not_supported_tailcall_helper((x), #x, method, cmethod))
-static gboolean
-is_supported_tailcall (MonoCompile *cfg, const guint8 *ip, MonoMethod *method, MonoMethod *cmethod, MonoMethodSignature *fsig,
-	gboolean virtual_, gboolean extra_arg, gboolean *ptailcall_calli)
-{
-	gboolean tailcall = TRUE;
-	gboolean tailcall_calli = TRUE;
-	if (IS_NOT_SUPPORTED_TAILCALL (virtual_ && !cfg->backend->have_op_tailcall_membase))
-		tailcall = FALSE;
-	if (IS_NOT_SUPPORTED_TAILCALL (!cfg->backend->have_op_tailcall_reg))
-		tailcall_calli = FALSE;
-	if (!tailcall && !tailcall_calli)
-		goto exit;
-	if (       IS_NOT_SUPPORTED_TAILCALL (cmethod && fsig->hasthis && m_class_is_valuetype (cmethod->klass)) // This might point to the current method's stack. Emit range check?
-		|| IS_NOT_SUPPORTED_TAILCALL (cmethod && (cmethod->flags & METHOD_ATTRIBUTE_PINVOKE_IMPL))
-		|| IS_NOT_SUPPORTED_TAILCALL (fsig->pinvoke) // i.e. if !cmethod (calli)
-		|| IS_NOT_SUPPORTED_TAILCALL (cfg->method->save_lmf)
-		|| IS_NOT_SUPPORTED_TAILCALL (!cmethod && fsig->hasthis) // FIXME could be valuetype to current frame; range check
-		|| IS_NOT_SUPPORTED_TAILCALL (cmethod && cmethod->wrapper_type && cmethod->wrapper_type != MONO_WRAPPER_DYNAMIC_METHOD)
-		|| IS_NOT_SUPPORTED_TAILCALL (extra_arg && !cfg->backend->have_volatile_non_param_register)
-		|| IS_NOT_SUPPORTED_TAILCALL (cfg->gsharedvt)
-		) {
-		tailcall_calli = FALSE;
-		tailcall = FALSE;
-		goto exit;
-	}
-	for (int i = 0; i < fsig->param_count; ++i) {
-		if (IS_NOT_SUPPORTED_TAILCALL (m_type_is_byref (fsig->params [i]) || fsig->params [i]->type == MONO_TYPE_PTR || fsig->params [i]->type == MONO_TYPE_FNPTR)) {
-			tailcall_calli = FALSE;
-			tailcall = FALSE; // These can point to the current method's stack. Emit range check?
-			goto exit;
-		}
-	}
-	MonoMethodSignature *caller_signature;
-	MonoMethodSignature *callee_signature;
-	caller_signature = mono_method_signature_internal (method);
-	callee_signature = cmethod ? mono_method_signature_internal (cmethod) : fsig;
-	g_assert (caller_signature);
-	g_assert (callee_signature);
-	if (IS_NOT_SUPPORTED_TAILCALL (mini_get_underlying_type (caller_signature->ret)->type != mini_get_underlying_type (callee_signature->ret)->type)
-		|| IS_NOT_SUPPORTED_TAILCALL (!mono_arch_tailcall_supported (cfg, caller_signature, callee_signature, virtual_))) {
-		tailcall_calli = FALSE;
-		tailcall = FALSE;
-		goto exit;
-	}
-	/* Debugging support */
-#if 0
-	if (!mono_debug_count ()) {
-		tailcall_calli = FALSE;
-		tailcall = FALSE;
-		goto exit;
-	}
-#endif
-	if (tailcall_calli && IS_NOT_SUPPORTED_TAILCALL (mini_should_check_stack_pointer (cfg)))
-		tailcall_calli = FALSE;
-exit:
-	mono_tailcall_print ("tail.%s %s -> %s tailcall:%d tailcall_calli:%d gshared:%d extra_arg:%d virtual_:%d\n",
-			mono_opcode_name (*ip), method->name, cmethod ? cmethod->name : "calli", tailcall, tailcall_calli,
-			cfg->gshared, extra_arg, virtual_);
-	*ptailcall_calli = tailcall_calli;
-	return tailcall;
-}
-/*
- * is_addressable_valuetype_load
- *
- *    Returns true if a previous load can be done without doing an extra copy, given the new instruction ip and the type of the object being loaded ldtype
- */
-static gboolean
-is_addressable_valuetype_load (MonoCompile* cfg, guint8* ip, MonoType* ldtype)
-{
-	/* Avoid loading a struct just to load one of its fields */
-	gboolean is_load_instruction = (*ip == CEE_LDFLD);
-	gboolean is_in_previous_bb = ip_in_bb(cfg, cfg->cbb, ip);
-	gboolean is_struct = MONO_TYPE_ISSTRUCT(ldtype);
-	return is_load_instruction && is_in_previous_bb && is_struct;
-}
-/*
- * check_get_virtual_method_assumptions:
- * 
- * This shadows mono_class_get_virtual_method, but instead of actually resolving
- * the virtual method, this only checks if mono_class_get_virtual_method would
- * succeed. This is in place because that function fails catastrophically in some
- * cases, bringing down the entire runtime. Returns TRUE if the function is safe 
- * to call, FALSE otherwise.
- */
-static gboolean
-check_get_virtual_method_assumptions (MonoClass* klass, MonoMethod* method)
-{
-	if (m_class_is_abstract(klass))
-		return FALSE;
-	if (((method->flags & METHOD_ATTRIBUTE_FINAL) || !(method->flags & METHOD_ATTRIBUTE_VIRTUAL)))
-		return TRUE;
-	mono_class_setup_vtable (klass);
-	if (m_class_get_vtable (klass) == NULL)
-		return FALSE;
-	if (method->slot == -1) {
-		if (method->is_inflated) {
-			if (((MonoMethodInflated*)method)->declaring->slot == -1)
-				return FALSE;
-		} else {
-			return FALSE;
-		}
-	}
-	if (method->slot != -1 && mono_class_is_interface (method->klass)) {
-		gboolean variance_used = FALSE;
-		int iface_offset = mono_class_interface_offset_with_variance (klass, method->klass, &variance_used);
-		if (iface_offset <= 0)
-			return FALSE;
-    }
-	if (method->is_inflated)
-		return FALSE;
-	return TRUE;
-}
-/*
- * try_prepare_objaddr_callvirt_optimization:
- * 
- * Determine in a load+callvirt optimization can be performed and if so,
- * resolve the callvirt target method, so that it can behave as call.
- * Returns null, if the optimization cannot be performed.
- */
-static MonoMethod*
-try_prepare_objaddr_callvirt_optimization (MonoCompile *cfg, guchar *next_ip, guchar* end, MonoMethod *method, MonoGenericContext* generic_context, MonoType *param_type)
-{
-	g_assert(param_type);
-	MonoClass *klass = mono_class_from_mono_type_internal (param_type);
-	if (cfg->compile_aot || cfg->compile_llvm || !klass || !mono_class_is_def (klass))
-		return NULL;
-	guchar* callvirt_ip;
-	guint32 callvirt_proc_token;
-	if (!(callvirt_ip = il_read_callvirt (next_ip, end, &callvirt_proc_token)) ||
-		!ip_in_bb (cfg, cfg->cbb, callvirt_ip))
-		return NULL;
-	MonoMethod* iface_method = mini_get_method (cfg, method, callvirt_proc_token, NULL, generic_context);
-	if (!iface_method ||
-		iface_method->is_generic ||
-		iface_method->dynamic || 					// Reflection.Emit-generated methods should have this flag
-		!strcmp (iface_method->name, "GetHashCode") || // the callvirt handler itself optimizes those
-		(iface_method->iflags & METHOD_IMPL_ATTRIBUTE_RUNTIME))
-		return NULL;
-	MonoMethodSignature* iface_method_sig;
-	if (!((iface_method_sig = mono_method_signature_internal (iface_method)) &&
-		iface_method_sig->hasthis && 
-		iface_method_sig->param_count == 0 && 
-		!iface_method_sig->has_type_parameters &&
-		iface_method_sig->generic_param_count == 0))
-		return NULL;
-	if (!check_get_virtual_method_assumptions (klass, iface_method))
-		return NULL;
-	ERROR_DECL (struct_method_error);
-	MonoMethod* struct_method = mono_class_get_virtual_method (klass, iface_method, struct_method_error);
-	if (is_ok (struct_method_error)) {
-		if (!struct_method || !MONO_METHOD_IS_FINAL (struct_method))
-			return NULL;
-		MonoMethodSignature* struct_method_sig = mono_method_signature_internal (struct_method);
-		if (!struct_method_sig ||
-			struct_method_sig->has_type_parameters ||
-			!mono_method_can_access_method (method, struct_method)) {
-			return NULL;
-			}
-	} else {
-		mono_error_cleanup (struct_method_error);
-		return NULL;
-	}
-	return struct_method;
-}
-/*
- * handle_ctor_call:
- *
- *   Handle calls made to ctors from NEWOBJ opcodes.
- */
-static void
-handle_ctor_call (MonoCompile *cfg, MonoMethod *cmethod, MonoMethodSignature *fsig, int context_used,
-				  MonoInst **sp, guint8 *ip, int *inline_costs)
-{
-	MonoInst *rgctx_arg = NULL, *callvirt_this_arg = NULL, *ins;
-	if (cmethod && (ins = mini_emit_inst_for_ctor (cfg, cmethod, fsig, sp))) {
-		g_assert (MONO_TYPE_IS_VOID (fsig->ret));
-		CHECK_CFG_EXCEPTION;
-		return;
-	}
-	if ((cfg->opt & MONO_OPT_INLINE) && mono_method_check_inlining (cfg, cmethod) &&
-			   !mono_class_is_subclass_of_internal (cmethod->klass, mono_defaults.exception_class, FALSE)) {
-		int costs;
-		costs = inline_method (cfg, cmethod, fsig, sp, ip, cfg->real_offset, FALSE, NULL);
-		if (costs) {
-			cfg->real_offset += 5;
-			*inline_costs += costs - 5;
-			return;
-		}
-	}
-	if (mono_class_generic_sharing_enabled (cmethod->klass) && mono_method_is_generic_sharable (cmethod, TRUE)) {
-		MonoRgctxAccess access = mini_get_rgctx_access_for_method (cmethod);
-		if (access == MONO_RGCTX_ACCESS_MRGCTX) {
-			rgctx_arg = emit_get_rgctx_method (cfg, context_used,
-												cmethod, MONO_RGCTX_INFO_METHOD_RGCTX);
-		} else {
-			g_assert (access == MONO_RGCTX_ACCESS_THIS);
-		}
-	}
-	/* Avoid virtual calls to ctors if possible */
-	if (!context_used && !rgctx_arg) {
-		if (!m_method_is_aggressive_inlining (cfg->current_method) && !m_method_is_aggressive_inlining (cmethod))
-			INLINE_FAILURE ("ctor call");
-		if (cfg->gsharedvt && mini_is_gsharedvt_signature (fsig))
-			GSHAREDVT_FAILURE(*ip);
-		mini_emit_method_call_full (cfg, cmethod, fsig, FALSE, sp, callvirt_this_arg, NULL, NULL);
-	} else if (cfg->gsharedvt && mini_is_gsharedvt_signature (fsig)) {
-		MonoInst *addr;
-		addr = emit_get_rgctx_gsharedvt_call (cfg, context_used, fsig, cmethod, MONO_RGCTX_INFO_METHOD_GSHAREDVT_OUT_TRAMPOLINE);
-		if (cfg->llvm_only) {
-			mini_emit_llvmonly_calli (cfg, fsig, sp, addr);
-		} else {
-			mini_emit_calli (cfg, fsig, sp, addr, NULL, rgctx_arg);
-		}
-	} else if (context_used &&
-			   ((!mono_method_is_generic_sharable_full (cmethod, TRUE, FALSE, FALSE) ||
-				 !mono_class_generic_sharing_enabled (cmethod->klass)) || cfg->gsharedvt)) {
-		MonoInst *cmethod_addr;
-		/* Generic calls made out of gsharedvt methods cannot be patched, so use an indirect call */
-		if (cfg->llvm_only) {
-			MonoInst *addr = emit_get_rgctx_method (cfg, context_used, cmethod,
-													MONO_RGCTX_INFO_METHOD_FTNDESC);
-			/* Need wrappers for this signature to be able to enter interpreter */
-			cfg->interp_in_signatures = g_slist_prepend_mempool (cfg->mempool, cfg->interp_in_signatures, fsig);
-			mini_emit_llvmonly_calli (cfg, fsig, sp, addr);
-		} else {
-			cmethod_addr = emit_get_rgctx_method (cfg, context_used,
-												  cmethod, MONO_RGCTX_INFO_GENERIC_METHOD_CODE);
-			mini_emit_calli (cfg, fsig, sp, cmethod_addr, NULL, rgctx_arg);
-		}
-	} else {
-		INLINE_FAILURE ("ctor call");
-		ins = mini_emit_method_call_full (cfg, cmethod, fsig, FALSE, sp,
-						  callvirt_this_arg, NULL, rgctx_arg);
-	}
- exception_exit:
-	return;
-}
-typedef struct {
-	MonoMethod *method;
-	gboolean inst_tailcall;
-} HandleCallData;
-/*
- * handle_constrained_call:
- *
- *   Handle constrained calls. Return a MonoInst* representing the call or NULL.
- * May overwrite sp [0] and modify the ref_... parameters.
- */
-static MonoInst*
-handle_constrained_call (MonoCompile *cfg, MonoMethod *cmethod, MonoMethodSignature *fsig, MonoClass *constrained_class, MonoInst **sp,
-						 HandleCallData *cdata, MonoMethod **ref_cmethod, gboolean *ref_virtual, gboolean *ref_emit_widen)
-{
-	MonoInst *ins, *addr;
-	MonoMethod *method = cdata->method;
-	gboolean constrained_partial_call = FALSE;
-	gboolean constrained_is_generic_param =
-		m_class_get_byval_arg (constrained_class)->type == MONO_TYPE_VAR ||
-		m_class_get_byval_arg (constrained_class)->type == MONO_TYPE_MVAR;
-	MonoType *gshared_constraint = NULL;
-	if (constrained_is_generic_param && cfg->gshared) {
-		if (!mini_is_gsharedvt_klass (constrained_class)) {
-			g_assert (!m_class_is_valuetype (cmethod->klass));
-			if (!mini_type_is_reference (m_class_get_byval_arg (constrained_class)))
-				constrained_partial_call = TRUE;
-			MonoType *t = m_class_get_byval_arg (constrained_class);
-			MonoGenericParam *gparam = t->data.generic_param;
-			gshared_constraint = gparam->gshared_constraint;
-		}
-	}
-	if (mini_is_gsharedvt_klass (constrained_class)) {
-		if ((cmethod->klass != mono_defaults.object_class) && m_class_is_valuetype (constrained_class) && m_class_is_valuetype (cmethod->klass)) {
-			/* The 'Own method' case below */
-		} else if (m_class_get_image (cmethod->klass) != mono_defaults.corlib && !mono_class_is_interface (cmethod->klass) && !m_class_is_valuetype (cmethod->klass)) {
-			/* 'The type parameter is instantiated as a reference type' case below. */
-		} else {
-			ins = handle_constrained_gsharedvt_call (cfg, cmethod, fsig, sp, constrained_class, ref_emit_widen);
-			CHECK_CFG_EXCEPTION;
-			g_assert (ins);
-			if (cdata->inst_tailcall) // FIXME
-				mono_tailcall_print ("missed tailcall constrained_class %s -> %s\n", method->name, cmethod->name);
-			return ins;
-		}
-	}
-	if (m_method_is_static (cmethod)) {
-		/* Call to an abstract static method, handled normally */
-		return NULL;
-	} else if (constrained_partial_call) {
-		gboolean need_box = TRUE;
-		/*
-		 * The receiver is a valuetype, but the exact type is not known at compile time. This means the
-		 * called method is not known at compile time either. The called method could end up being
-		 * one of the methods on the parent classes (object/valuetype/enum), in which case we need
-		 * to box the receiver.
-		 * A simple solution would be to box always and make a normal virtual call, but that would
-		 * be bad performance wise.
-		 */
-		if (mono_class_is_interface (cmethod->klass) && mono_class_is_ginst (cmethod->klass) &&
-		    (cmethod->flags & METHOD_ATTRIBUTE_ABSTRACT)) {
-			/*
-			 * The parent classes implement no generic interfaces, so the called method will be a vtype method, so no boxing necessary.
-			 */
-			/* If the method is not abstract, it's a default interface method, and we need to box */
-			need_box = FALSE;
-		}
-		if (gshared_constraint && MONO_TYPE_IS_PRIMITIVE (gshared_constraint) && cmethod->klass == mono_defaults.object_class &&
-			!strcmp (cmethod->name, "GetHashCode")) {
-			/*
-			 * The receiver is constrained to a primitive type or an enum with the same basetype.
-			 * Enum.GetHashCode () returns the hash code of the underlying type (see comments in Enum.cs),
-			 * so the constrained call can be replaced with a normal call to the basetype GetHashCode ()
-			 * method.
-			 */
-			MonoClass *gshared_constraint_class = mono_class_from_mono_type_internal (gshared_constraint);
-			cmethod = get_method_nofail (gshared_constraint_class, cmethod->name, 0, 0);
-			g_assert (cmethod);
-			*ref_cmethod = cmethod;
-			*ref_virtual = FALSE;
-			if (cfg->verbose_level)
-				printf (" -> %s\n", mono_method_get_full_name (cmethod));
-			return NULL;
-		}
-		if (!(cmethod->flags & METHOD_ATTRIBUTE_VIRTUAL) && (cmethod->klass == mono_defaults.object_class || cmethod->klass == m_class_get_parent (mono_defaults.enum_class) || cmethod->klass == mono_defaults.enum_class)) {
-			/* The called method is not virtual, i.e. Object:GetType (), the receiver is a vtype, has to box */
-			EMIT_NEW_LOAD_MEMBASE_TYPE (cfg, ins, m_class_get_byval_arg (constrained_class), sp [0]->dreg, 0);
-			ins->klass = constrained_class;
-			sp [0] = mini_emit_box (cfg, ins, constrained_class, mono_class_check_context_used (constrained_class));
-			CHECK_CFG_EXCEPTION;
-		} else if (need_box) {
-			MonoInst *box_type;
-			MonoBasicBlock *is_ref_bb, *end_bb;
-			MonoInst *nonbox_call, *nonbox_addr;
-			/*
-			 * Determine at runtime whenever the called method is defined on object/valuetype/enum, and emit a boxing call
-			 * if needed.
-			 * FIXME: It is possible to inline the called method in a lot of cases, i.e. for T_INT,
-			 * the no-box case goes to a method in Int32, while the box case goes to a method in Enum.
-			 */
-			nonbox_addr = emit_get_rgctx_virt_method (cfg, mono_class_check_context_used (constrained_class), constrained_class, cmethod, MONO_RGCTX_INFO_VIRT_METHOD_CODE);
-			NEW_BBLOCK (cfg, is_ref_bb);
-			NEW_BBLOCK (cfg, end_bb);
-			box_type = emit_get_rgctx_virt_method (cfg, mono_class_check_context_used (constrained_class), constrained_class, cmethod, MONO_RGCTX_INFO_VIRT_METHOD_BOX_TYPE);
-			MONO_EMIT_NEW_BIALU_IMM (cfg, OP_COMPARE_IMM, -1, box_type->dreg, MONO_GSHAREDVT_BOX_TYPE_REF);
-			MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_IBEQ, is_ref_bb);
-			/* Non-ref case */
-			if (cfg->llvm_only)
-				/* nonbox_addr is an ftndesc in this case */
-				nonbox_call = mini_emit_llvmonly_calli (cfg, fsig, sp, nonbox_addr);
-			else
-				nonbox_call = (MonoInst*)mini_emit_calli (cfg, fsig, sp, nonbox_addr, NULL, NULL);
-			MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_BR, end_bb);
-			/* Ref case */
-			MONO_START_BB (cfg, is_ref_bb);
-			EMIT_NEW_LOAD_MEMBASE_TYPE (cfg, ins, m_class_get_byval_arg (constrained_class), sp [0]->dreg, 0);
-			ins->klass = constrained_class;
-			sp [0] = mini_emit_box (cfg, ins, constrained_class, mono_class_check_context_used (constrained_class));
-			CHECK_CFG_EXCEPTION;
-			if (cfg->llvm_only)
-				ins = mini_emit_llvmonly_calli (cfg, fsig, sp, nonbox_addr);
-			else
-				ins = (MonoInst*)mini_emit_calli (cfg, fsig, sp, nonbox_addr, NULL, NULL);
-			MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_BR, end_bb);
-			MONO_START_BB (cfg, end_bb);
-			cfg->cbb = end_bb;
-			nonbox_call->dreg = ins->dreg;
-			if (cdata->inst_tailcall) // FIXME
-				mono_tailcall_print ("missed tailcall constrained_partial_need_box %s -> %s\n", method->name, cmethod->name);
-			return ins;
-		} else {
-			g_assert (mono_class_is_interface (cmethod->klass));
-			addr = emit_get_rgctx_virt_method (cfg, mono_class_check_context_used (constrained_class), constrained_class, cmethod, MONO_RGCTX_INFO_VIRT_METHOD_CODE);
-			if (cfg->llvm_only)
-				ins = mini_emit_llvmonly_calli (cfg, fsig, sp, addr);
-			else
-				ins = (MonoInst*)mini_emit_calli (cfg, fsig, sp, addr, NULL, NULL);
-			if (cdata->inst_tailcall) // FIXME
-				mono_tailcall_print ("missed tailcall constrained_partial %s -> %s\n", method->name, cmethod->name);
-			return ins;
-		}
-	} else if (!m_class_is_valuetype (constrained_class)) {
-		int dreg = alloc_ireg_ref (cfg);
-		/*
-		 * The type parameter is instantiated as a reference
-		 * type.  We have a managed pointer on the stack, so
-		 * we need to dereference it here.
-		 */
-		EMIT_NEW_LOAD_MEMBASE (cfg, ins, OP_LOAD_MEMBASE, dreg, sp [0]->dreg, 0);
-		ins->type = STACK_OBJ;
-		sp [0] = ins;
-	} else if (cmethod->klass == mono_defaults.object_class || cmethod->klass == m_class_get_parent (mono_defaults.enum_class) || cmethod->klass == mono_defaults.enum_class) {
-		/*
-		 * The type parameter is instantiated as a valuetype,
-		 * but that type doesn't override the method we're
-		 * calling, so we need to box `this'.
-		 */
-		EMIT_NEW_LOAD_MEMBASE_TYPE (cfg, ins, m_class_get_byval_arg (constrained_class), sp [0]->dreg, 0);
-		ins->klass = constrained_class;
-		sp [0] = mini_emit_box (cfg, ins, constrained_class, mono_class_check_context_used (constrained_class));
-		CHECK_CFG_EXCEPTION;
-	} else {
-		if (cmethod->klass != constrained_class) {
-			/* Enums/default interface methods */
-			EMIT_NEW_LOAD_MEMBASE_TYPE (cfg, ins, m_class_get_byval_arg (constrained_class), sp [0]->dreg, 0);
-			ins->klass = constrained_class;
-			sp [0] = mini_emit_box (cfg, ins, constrained_class, mono_class_check_context_used (constrained_class));
-			CHECK_CFG_EXCEPTION;
-		}
-		*ref_virtual = FALSE;
-	}
- exception_exit:
-	return NULL;
-}
-static void
-emit_setret (MonoCompile *cfg, MonoInst *val)
-{
-	MonoType *ret_type = mini_get_underlying_type (mono_method_signature_internal (cfg->method)->ret);
-	MonoInst *ins;
-	if (mini_type_to_stind (cfg, ret_type) == CEE_STOBJ) {
-		MonoInst *ret_addr;
-		if (!cfg->vret_addr) {
-			EMIT_NEW_VARSTORE (cfg, ins, cfg->ret, ret_type, val);
-		} else {
-			EMIT_NEW_RETLOADA (cfg, ret_addr);
-			MonoClass *ret_class = mono_class_from_mono_type_internal (ret_type);
-			if (mini_class_is_simd (cfg, ret_class))
-				EMIT_NEW_STORE_MEMBASE (cfg, ins, OP_STOREX_MEMBASE, ret_addr->dreg, 0, val->dreg);
-			else
-				EMIT_NEW_STORE_MEMBASE (cfg, ins, OP_STOREV_MEMBASE, ret_addr->dreg, 0, val->dreg);
-			ins->klass = ret_class;
-		}
-	} else {
-#ifdef MONO_ARCH_SOFT_FLOAT_FALLBACK
-		if (COMPILE_SOFT_FLOAT (cfg) && !m_type_is_byref (ret_type) && ret_type->type == MONO_TYPE_R4) {
-			MonoInst *conv;
-			MonoInst *iargs [ ] = { val };
-			conv = mono_emit_jit_icall (cfg, mono_fload_r4_arg, iargs);
-			mono_arch_emit_setret (cfg, cfg->method, conv);
-		} else {
-			mono_arch_emit_setret (cfg, cfg->method, val);
-		}
-#else
-		mono_arch_emit_setret (cfg, cfg->method, val);
-#endif
-	}
-}
-/*
- * Emit a call to enter the interpreter for methods with filter clauses.
- */
-static void
-emit_llvmonly_interp_entry (MonoCompile *cfg, MonoMethodHeader *header)
-{
-	MonoInst *ins;
-	MonoInst **iargs;
-	MonoMethodSignature *sig = mono_method_signature_internal (cfg->method);
-	MonoInst *ftndesc;
-	cfg->interp_in_signatures = g_slist_prepend_mempool (cfg->mempool, cfg->interp_in_signatures, sig);
-	/*
-	 * Emit a call to the interp entry function. We emit it here instead of the llvm backend since
-	 * calling conventions etc. are easier to handle here. The LLVM backend will only emit the
-	 * entry/exit bblocks.
-	 */
-	g_assert (cfg->cbb == cfg->bb_init);
-	if (cfg->gsharedvt && mini_is_gsharedvt_variable_signature (sig)) {
-		/*
-		 * Would have to generate a gsharedvt out wrapper which calls the interp entry wrapper, but
-		 * the gsharedvt out wrapper might not exist if the caller is also a gsharedvt method since
-		 * the concrete signature of the call might not exist in the program.
-		 * So transition directly to the interpreter without the wrappers.
-		 */
-		MonoInst *args_ins;
-		MONO_INST_NEW (cfg, ins, OP_LOCALLOC_IMM);
-		ins->dreg = alloc_preg (cfg);
-		ins->inst_imm = sig->param_count * sizeof (target_mgreg_t);
-		MONO_ADD_INS (cfg->cbb, ins);
-		args_ins = ins;
-		for (unsigned int i = 0; i < sig->hasthis + sig->param_count; ++i) {
-			MonoInst *arg_addr_ins;
-			EMIT_NEW_VARLOADA ((cfg), arg_addr_ins, cfg->args [i], cfg->arg_types [i]);
-			EMIT_NEW_STORE_MEMBASE (cfg, ins, OP_STORE_MEMBASE_REG, args_ins->dreg, i * sizeof (target_mgreg_t), arg_addr_ins->dreg);
-		}
-		MonoInst *ret_var = NULL;
-		MonoInst *ret_arg_ins;
-		if (!MONO_TYPE_IS_VOID (sig->ret)) {
-			ret_var = mono_compile_create_var (cfg, sig->ret, OP_LOCAL);
-			EMIT_NEW_VARLOADA (cfg, ret_arg_ins, ret_var, sig->ret);
-		} else {
-			EMIT_NEW_PCONST (cfg, ret_arg_ins, NULL);
-		}
-		iargs = g_newa (MonoInst*, 3);
-		iargs [0] = emit_get_rgctx_method (cfg, -1, cfg->method, MONO_RGCTX_INFO_INTERP_METHOD);
-		iargs [1] = ret_arg_ins;
-		iargs [2] = args_ins;
-		mono_emit_jit_icall_id (cfg, MONO_JIT_ICALL_mini_llvmonly_interp_entry_gsharedvt, iargs);
-		if (!MONO_TYPE_IS_VOID (sig->ret))
-			EMIT_NEW_VARLOAD (cfg, ins, ret_var, sig->ret);
-		else
-			ins = NULL;
-	} else {
-		/* Obtain the interp entry function */
-		ftndesc = emit_get_rgctx_method (cfg, -1, cfg->method, MONO_RGCTX_INFO_LLVMONLY_INTERP_ENTRY);
-		/* Call it */
-		iargs = g_newa (MonoInst*, sig->param_count + 1);
-		for (unsigned int i = 0; i < sig->param_count + sig->hasthis; ++i)
-			EMIT_NEW_ARGLOAD (cfg, iargs [i], i);
-		ins = mini_emit_llvmonly_calli (cfg, sig, iargs, ftndesc);
-	}
-	/* Do a normal return */
-	if (cfg->ret) {
-		emit_setret (cfg, ins);
-		/*
-		 * Since only bb_entry/bb_exit is emitted if interp_entry_only is set,
-		 * its possible that the return value becomes an OP_PHI node whose inputs
-		 * are not emitted. Make it volatile to prevent that.
-		 */
-		cfg->ret->flags |= MONO_INST_VOLATILE;
-	}
-	MONO_INST_NEW (cfg, ins, OP_BR);
-	ins->inst_target_bb = cfg->bb_exit;
-	MONO_ADD_INS (cfg->cbb, ins);
-	link_bblock (cfg, cfg->cbb, cfg->bb_exit);
-}
-static void
-method_make_alwaysthrow_typeloadfailure (MonoCompile* cfg, MonoClass* klass)
-{
-	for (gint16 i = cfg->bb_entry->out_count - 1; i >= 0; i--) {
-		if (cfg->bb_entry->out_bb [i] != cfg->bb_init) {
-			mono_unlink_bblock (cfg, cfg->bb_entry, cfg->bb_entry->out_bb [i]);
-			mono_remove_bblock (cfg, cfg->bb_entry->out_bb [i]);
-		}
-	}
-	for (gint16 i = cfg->bb_init->out_count - 1; i >= 0; i--) {
-		if (cfg->bb_init->out_bb [i] != cfg->bb_exit) {
-			mono_unlink_bblock (cfg, cfg->bb_init, cfg->bb_init->out_bb [i]);
-			mono_remove_bblock (cfg, cfg->bb_init->out_bb [i]);
-		}
-	}
-	cfg->cbb = cfg->bb_init;
-	MonoBasicBlock* bb;
-	NEW_BBLOCK (cfg, bb);
-	bb->cil_code = NULL;
-	bb->cil_length = 0;
-	cfg->cbb->next_bb = bb;
-	cfg->cbb = bb;
-	emit_type_load_failure (cfg, klass);
-	MonoInst* ins;
-	MONO_INST_NEW (cfg, ins, OP_NOT_REACHED);
-	MONO_ADD_INS (cfg->cbb, ins);
-	ADD_BBLOCK (cfg, bb);
-	mono_link_bblock (cfg, cfg->bb_init, bb);
-	mono_link_bblock (cfg, bb, cfg->bb_exit);
-	cfg->disable_inline = TRUE;
-}
-typedef union _MonoOpcodeParameter {
-	gint32 i32;
-	gint64 i64;
-	float f;
-	double d;
-	guchar *branch_target;
-} MonoOpcodeParameter;
-typedef struct _MonoOpcodeInfo {
-	guint constant : 4; // private
-	gint  pops     : 3; // public -1 means variable
-	gint  pushes   : 3; // public -1 means variable
-} MonoOpcodeInfo;
-static const MonoOpcodeInfo*
-mono_opcode_decode (guchar *ip, guint op_size, MonoOpcodeEnum il_op, MonoOpcodeParameter *parameter)
-{
-#define Push0 (0)
-#define Pop0 (0)
-#define Push1 (1)
-#define Pop1 (1)
-#define PushI (1)
-#define PopI (1)
-#define PushI8 (1)
-#define PopI8 (1)
-#define PushRef (1)
-#define PopRef (1)
-#define PushR4 (1)
-#define PopR4 (1)
-#define PushR8 (1)
-#define PopR8 (1)
-#define VarPush (-1)
-#define VarPop (-1)
-	static const MonoOpcodeInfo mono_opcode_info [ ] = {
-#define OPDEF(name, str, pops, pushes, param, param_constant, a, b, c, flow) {param_constant + 1, pops, pushes },
-#include "mono/cil/opcode.def"
-#undef OPDEF
-	};
-#undef Push0
-#undef Pop0
-#undef Push1
-#undef Pop1
-#undef PushI
-#undef PopI
-#undef PushI8
-#undef PopI8
-#undef PushRef
-#undef PopRef
-#undef PushR4
-#undef PopR4
-#undef PushR8
-#undef PopR8
-#undef VarPush
-#undef VarPop
-	gint32 delta;
-	guchar *next_ip = ip + op_size;
-	const MonoOpcodeInfo *info = &mono_opcode_info [il_op];
-	switch (mono_opcodes [il_op].argument) {
-	case MonoInlineNone:
-		parameter->i32 = (int)info->constant - 1;
-		break;
-	case MonoInlineString:
-	case MonoInlineType:
-	case MonoInlineField:
-	case MonoInlineMethod:
-	case MonoInlineTok:
-	case MonoInlineSig:
-	case MonoShortInlineR:
-	case MonoInlineI:
-		parameter->i32 = read32 (next_ip - 4);
-		break;
-	case MonoShortInlineI:
-		parameter->i32 = (signed char)next_ip [-1];
-		break;
-	case MonoInlineVar:
-		parameter->i32 = read16 (next_ip - 2);
-		break;
-	case MonoShortInlineVar:
-		parameter->i32 = next_ip [-1];
-		break;
-	case MonoInlineR:
-	case MonoInlineI8:
-		parameter->i64 = read64 (next_ip - 8);
-		break;
-	case MonoShortInlineBrTarget:
-		delta = (signed char)next_ip [-1];
-		goto branch_target;
-	case MonoInlineBrTarget:
-		delta = (gint32)read32 (next_ip - 4);
-branch_target:
-		parameter->branch_target = delta + next_ip;
-		break;
-	case MonoInlineSwitch: // complicated
-		break;
-	default:
-		g_error ("%s %d %d\n", __func__, il_op, mono_opcodes [il_op].argument);
-	}
-	return info;
-}
-/*
- * mono_method_to_ir:
- *
- * Translate the .net IL into linear IR.
- *
- * @start_bblock: if not NULL, the starting basic block, used during inlining.
- * @end_bblock: if not NULL, the ending basic block, used during inlining.
- * @return_var: if not NULL, the place where the return value is stored, used during inlining.
- * @inline_args: if not NULL, contains the arguments to the inline call
- * @inline_offset: if not zero, the real offset from the inline call, or zero otherwise.
- * @is_virtual_call: whether this method is being called as a result of a call to callvirt
- *
- * This method is used to turn ECMA IL into Mono's internal Linear IR
- * reprensetation.  It is used both for entire methods, as well as
- * inlining existing methods.  In the former case, the @start_bblock,
- * @end_bblock, @return_var, @inline_args are all set to NULL, and the
- * inline_offset is set to zero.
- *
- * Returns: the inline cost, or -1 if there was an error processing this method.
- */
-int
-mono_method_to_ir (MonoCompile *cfg, MonoMethod *method, MonoBasicBlock *start_bblock, MonoBasicBlock *end_bblock,
-		   MonoInst *return_var, MonoInst **inline_args,
-		   guint inline_offset, gboolean is_virtual_call)
-{
-	ERROR_DECL (error);
-	MonoInst *array_new_localalloc_ins = NULL;
-	MonoInst *ins, **sp, **stack_start;
-	MonoBasicBlock *tblock = NULL;
-	MonoBasicBlock *init_localsbb = NULL, *init_localsbb2 = NULL;
-	MonoSimpleBasicBlock *bb = NULL, *original_bb = NULL;
-	MonoMethod *method_definition;
-	MonoInst **arg_array;
-	MonoMethodHeader *header;
-	MonoImage *image;
-	guint32 token, ins_flag;
-	MonoClass *klass;
-	MonoClass *constrained_class = NULL;
-	gboolean save_last_error = FALSE;
-	guchar *ip, *end, *target, *err_pos;
-	MonoMethodSignature *sig;
-	MonoGenericContext *generic_context = NULL;
-	MonoGenericContainer *generic_container = NULL;
-	MonoType **param_types;
-	int n, start_new_bblock;
-	int num_calls = 0, inline_costs = 0;
-	guint num_args;
-	GSList *class_inits = NULL;
-	gboolean dont_verify, dont_verify_stloc, readonly = FALSE;
-	int context_used;
-	gboolean init_locals, seq_points, skip_dead_blocks;
-	gboolean sym_seq_points = FALSE;
-	MonoDebugMethodInfo *minfo;
-	MonoBitSet *seq_point_locs = NULL;
-	MonoBitSet *seq_point_set_locs = NULL;
-	const char *ovf_exc = NULL;
-	gboolean emitted_funccall_seq_point = FALSE;
-	gboolean detached_before_ret = FALSE;
-	gboolean ins_has_side_effect;
-	MonoMethod* cmethod_override = NULL; // this is ised in call/callvirt handler to override the method to be called (e.g. from box handler)
-	if (!cfg->disable_inline)
-		cfg->disable_inline = (method->iflags & METHOD_IMPL_ATTRIBUTE_NOOPTIMIZATION) || is_jit_optimizer_disabled (method);
-	cfg->current_method = method;
-	image = m_class_get_image (method->klass);
-	/* serialization and xdomain stuff may need access to private fields and methods */
-	dont_verify = FALSE;
- 	dont_verify |= method->wrapper_type == MONO_WRAPPER_MANAGED_TO_NATIVE; /* bug #77896 */
-	/* still some type unsafety issues in marshal wrappers... (unknown is PtrToStructure) */
-	dont_verify_stloc = method->wrapper_type == MONO_WRAPPER_MANAGED_TO_NATIVE;
-	dont_verify_stloc |= method->wrapper_type == MONO_WRAPPER_OTHER;
-	dont_verify_stloc |= method->wrapper_type == MONO_WRAPPER_NATIVE_TO_MANAGED;
-	dont_verify_stloc |= method->wrapper_type == MONO_WRAPPER_STELEMREF;
-	header = mono_method_get_header_checked (method, cfg->error);
-	if (!header) {
-		mono_cfg_set_exception (cfg, MONO_EXCEPTION_MONO_ERROR);
-		goto exception_exit;
-	} else {
-		cfg->headers_to_free = g_slist_prepend_mempool (cfg->mempool, cfg->headers_to_free, header);
-	}
-	generic_container = mono_method_get_generic_container (method);
-	sig = mono_method_signature_internal (method);
-	num_args = sig->hasthis + sig->param_count;
-	ip = (guchar*)header->code;
-	cfg->cil_start = ip;
-	end = ip + header->code_size;
-	cfg->stat_cil_code_size += header->code_size;
-	seq_points = cfg->gen_seq_points && cfg->method == method;
-	if (method->wrapper_type == MONO_WRAPPER_NATIVE_TO_MANAGED) {
-		/* We could hit a seq point before attaching to the JIT (#8338) */
-		seq_points = FALSE;
-	}
-	if (method->wrapper_type == MONO_WRAPPER_OTHER)	{
-		WrapperInfo *info = mono_marshal_get_wrapper_info (method);
-		if (info->subtype == WRAPPER_SUBTYPE_INTERP_IN) {
-			/* We could hit a seq point before attaching to the JIT (#8338) */
-			seq_points = FALSE;
-		}
-	}
-	if (cfg->prof_coverage) {
-		if (cfg->compile_aot)
-			g_error ("Coverage profiling is not supported with AOT.");
-		INLINE_FAILURE ("coverage profiling");
-		cfg->coverage_info = mono_profiler_coverage_alloc (cfg->method, header->code_size);
-	}
-	if ((cfg->gen_sdb_seq_points && cfg->method == method) || cfg->prof_coverage) {
-		minfo = mono_debug_lookup_method (method);
-		if (minfo) {
-			MonoSymSeqPoint *sps;
-			int n_il_offsets;
-			mono_debug_get_seq_points (minfo, NULL, NULL, NULL, &sps, &n_il_offsets);
-			seq_point_locs = mono_bitset_mem_new (mono_mempool_alloc0 (cfg->mempool, mono_bitset_alloc_size (header->code_size, 0)), header->code_size, 0);
-			seq_point_set_locs = mono_bitset_mem_new (mono_mempool_alloc0 (cfg->mempool, mono_bitset_alloc_size (header->code_size, 0)), header->code_size, 0);
-			sym_seq_points = TRUE;
-			for (int i = 0; i < n_il_offsets; ++i) {
-				if (GINT_TO_UINT32(sps [i].il_offset) < header->code_size)
-					mono_bitset_set_fast (seq_point_locs, sps [i].il_offset);
-			}
-			g_free (sps);
-			MonoDebugMethodAsyncInfo* asyncMethod = mono_debug_lookup_method_async_debug_info (method);
-			if (asyncMethod) {
-				for (int i = 0; asyncMethod != NULL && i < asyncMethod->num_awaits; i++)
-				{
-					mono_bitset_set_fast (seq_point_locs, asyncMethod->resume_offsets[i]);
-					mono_bitset_set_fast (seq_point_locs, asyncMethod->yield_offsets[i]);
-				}
-				mono_debug_free_method_async_debug_info (asyncMethod);
-			}
-		} else if (!method->wrapper_type && !method->dynamic && mono_debug_image_has_debug_info (m_class_get_image (method->klass))) {
-			/* Methods without line number info like auto-generated property accessors */
-			seq_point_locs = mono_bitset_mem_new (mono_mempool_alloc0 (cfg->mempool, mono_bitset_alloc_size (header->code_size, 0)), header->code_size, 0);
-			seq_point_set_locs = mono_bitset_mem_new (mono_mempool_alloc0 (cfg->mempool, mono_bitset_alloc_size (header->code_size, 0)), header->code_size, 0);
-			sym_seq_points = TRUE;
-		}
-	}
-	/*
-	 * Methods without init_locals set could cause asserts in various passes
-	 * (#497220). To work around this, we emit dummy initialization opcodes
-	 * (OP_DUMMY_ICONST etc.) which generate no code. These are only supported
-	 * on some platforms.
-	 */
-	if (cfg->opt & MONO_OPT_UNSAFE)
-		init_locals = header->init_locals;
-	else
-		init_locals = TRUE;
-	method_definition = method;
-	while (method_definition->is_inflated) {
-		MonoMethodInflated *imethod = (MonoMethodInflated *) method_definition;
-		method_definition = imethod->declaring;
-	}
-	if (sig->is_inflated)
-		generic_context = mono_method_get_context (method);
-	else if (generic_container)
-		generic_context = &generic_container->context;
-	cfg->generic_context = generic_context;
-	if (!cfg->gshared) {
-		gboolean check_type_parameter = TRUE;
-		if (method->wrapper_type == MONO_WRAPPER_OTHER) {
-			WrapperInfo *info = mono_marshal_get_wrapper_info (method);
-			g_assert (info);
-			if (info->subtype == WRAPPER_SUBTYPE_UNSAFE_ACCESSOR)
-				check_type_parameter = FALSE;
-		}
-		if (check_type_parameter)
-			g_assert (!sig->has_type_parameters);
-	}
-	if (sig->generic_param_count && method->wrapper_type == MONO_WRAPPER_NONE) {
-		g_assert (method->is_inflated);
-		g_assert (mono_method_get_context (method)->method_inst);
-	}
-	if (method->is_inflated && mono_method_get_context (method)->method_inst)
-		g_assert (sig->generic_param_count);
-	if (cfg->method == method) {
-		cfg->real_offset = 0;
-	} else {
-		cfg->real_offset = inline_offset;
-	}
-	cfg->cil_offset_to_bb = (MonoBasicBlock **)mono_mempool_alloc0 (cfg->mempool, sizeof (MonoBasicBlock*) * header->code_size);
-	cfg->cil_offset_to_bb_len = header->code_size;
-	if (cfg->verbose_level > 2)
-		printf ("method to IR %s\n", mono_method_full_name (method, TRUE));
-	param_types = (MonoType **)mono_mempool_alloc (cfg->mempool, sizeof (MonoType*) * num_args);
-	if (sig->hasthis)
-		param_types [0] = m_class_is_valuetype (method->klass) ? m_class_get_this_arg (method->klass) : m_class_get_byval_arg (method->klass);
-	for (n = 0; n < sig->param_count; ++n)
-		param_types [n + sig->hasthis] = sig->params [n];
-	cfg->arg_types = param_types;
-	cfg->dont_inline = g_list_prepend (cfg->dont_inline, method);
-	if (cfg->method == method) {
-		/* ENTRY BLOCK */
-		NEW_BBLOCK (cfg, start_bblock);
-		cfg->bb_entry = start_bblock;
-		start_bblock->cil_code = NULL;
-		start_bblock->cil_length = 0;
-		/* EXIT BLOCK */
-		NEW_BBLOCK (cfg, end_bblock);
-		cfg->bb_exit = end_bblock;
-		end_bblock->cil_code = NULL;
-		end_bblock->cil_length = 0;
-		end_bblock->flags |= BB_INDIRECT_JUMP_TARGET;
-		g_assert (cfg->num_bblocks == 2);
-		arg_array = cfg->args;
-		if (header->num_clauses) {
-			cfg->spvars = g_hash_table_new (NULL, NULL);
-			cfg->exvars = g_hash_table_new (NULL, NULL);
-		}
-		cfg->clause_is_dead = mono_mempool_alloc0 (cfg->mempool, sizeof (gboolean) * header->num_clauses);
-		/* handle exception clauses */
-		for (unsigned int i = 0; i < header->num_clauses; ++i) {
-			MonoBasicBlock *try_bb;
-			MonoExceptionClause *clause = &header->clauses [i];
-			GET_BBLOCK (cfg, try_bb, ip + clause->try_offset);
-			try_bb->real_offset = clause->try_offset;
-			try_bb->try_start = TRUE;
-			GET_BBLOCK (cfg, tblock, ip + clause->handler_offset);
-			tblock->real_offset = clause->handler_offset;
-			tblock->flags |= BB_EXCEPTION_HANDLER;
-			if (clause->flags == MONO_EXCEPTION_CLAUSE_FINALLY)
-				mono_create_exvar_for_offset (cfg, clause->handler_offset);
-			/*
-			 * Linking the try block with the EH block hinders inlining as we won't be able to
-			 * merge the bblocks from inlining and produce an artificial hole for no good reason.
-			 */
-			if (COMPILE_LLVM (cfg))
-				link_bblock (cfg, try_bb, tblock);
-			if (*(ip + clause->handler_offset) == CEE_POP)
-				tblock->flags |= BB_EXCEPTION_DEAD_OBJ;
-			if (clause->flags == MONO_EXCEPTION_CLAUSE_FINALLY ||
-			    clause->flags == MONO_EXCEPTION_CLAUSE_FILTER ||
-			    clause->flags == MONO_EXCEPTION_CLAUSE_FAULT) {
-				MONO_INST_NEW (cfg, ins, OP_START_HANDLER);
-				MONO_ADD_INS (tblock, ins);
-				if (seq_points && clause->flags != MONO_EXCEPTION_CLAUSE_FINALLY && clause->flags != MONO_EXCEPTION_CLAUSE_FILTER) {
-					/* finally clauses already have a seq point */
-					/* seq points for filter clauses are emitted below */
-					NEW_SEQ_POINT (cfg, ins, clause->handler_offset, TRUE);
-					MONO_ADD_INS (tblock, ins);
-				}
-				/* todo: is a fault block unsafe to optimize? */
-				if (clause->flags == MONO_EXCEPTION_CLAUSE_FAULT)
-					tblock->flags |= BB_EXCEPTION_UNSAFE;
-			}
-			/*printf ("clause try IL_%04x to IL_%04x handler %d at IL_%04x to IL_%04x\n", clause->try_offset, clause->try_offset + clause->try_len, clause->flags, clause->handler_offset, clause->handler_offset + clause->handler_len);
-			  while (p < end) {
-			  printf ("%s", mono_disasm_code_one (NULL, method, p, &p));
-			  }*/
-			/* catch and filter blocks get the exception object on the stack */
-			if (clause->flags == MONO_EXCEPTION_CLAUSE_NONE ||
-			    clause->flags == MONO_EXCEPTION_CLAUSE_FILTER) {
-				/* mostly like handle_stack_args (), but just sets the input args */
-				/* printf ("handling clause at IL_%04x\n", clause->handler_offset); */
-				tblock->in_scount = 1;
-				tblock->in_stack = (MonoInst **)mono_mempool_alloc (cfg->mempool, sizeof (MonoInst*));
-				tblock->in_stack [0] = mono_create_exvar_for_offset (cfg, clause->handler_offset);
-				cfg->cbb = tblock;
-#ifdef MONO_CONTEXT_SET_LLVM_EXC_REG
-				/* The EH code passes in the exception in a register to both JITted and LLVM compiled code */
-				if (!cfg->compile_llvm) {
-					MONO_INST_NEW (cfg, ins, OP_GET_EX_OBJ);
-					ins->dreg = tblock->in_stack [0]->dreg;
-					MONO_ADD_INS (tblock, ins);
-				}
-#else
-				MonoInst *dummy_use;
-				/*
-				 * Add a dummy use for the exvar so its liveness info will be
-				 * correct.
-				 */
-				EMIT_NEW_DUMMY_USE (cfg, dummy_use, tblock->in_stack [0]);
-#endif
-				if (seq_points && clause->flags == MONO_EXCEPTION_CLAUSE_FILTER) {
-					NEW_SEQ_POINT (cfg, ins, clause->handler_offset, TRUE);
-					MONO_ADD_INS (tblock, ins);
-				}
-				if (clause->flags == MONO_EXCEPTION_CLAUSE_FILTER) {
-					GET_BBLOCK (cfg, tblock, ip + clause->data.filter_offset);
-					tblock->flags |= BB_EXCEPTION_HANDLER;
-					tblock->real_offset = clause->data.filter_offset;
-					tblock->in_scount = 1;
-					tblock->in_stack = (MonoInst **)mono_mempool_alloc (cfg->mempool, sizeof (MonoInst*));
-					/* The filter block shares the exvar with the handler block */
-					tblock->in_stack [0] = mono_create_exvar_for_offset (cfg, clause->handler_offset);
-					MONO_INST_NEW (cfg, ins, OP_START_HANDLER);
-					MONO_ADD_INS (tblock, ins);
-				}
-			}
-			if (clause->flags != MONO_EXCEPTION_CLAUSE_FILTER &&
-					clause->data.catch_class &&
-					cfg->gshared &&
-					mono_class_check_context_used (clause->data.catch_class)) {
-				/*
-				 * In shared generic code with catch
-				 * clauses containing type variables
-				 * the exception handling code has to
-				 * be able to get to the rgctx.
-				 * Therefore we have to make sure that
-				 * the vtable/mrgctx argument (for
-				 * static or generic methods) or the
-				 * "this" argument (for non-static
-				 * methods) are live.
-				 */
-				if ((method->flags & METHOD_ATTRIBUTE_STATIC) ||
-						mini_method_get_context (method)->method_inst ||
-						m_class_is_valuetype (method->klass)) {
-					mono_get_vtable_var (cfg);
-				} else {
-					MonoInst *dummy_use;
-					EMIT_NEW_DUMMY_USE (cfg, dummy_use, arg_array [0]);
-				}
-			}
-		}
-	} else {
-		arg_array = g_newa (MonoInst*, num_args);
-		cfg->cbb = start_bblock;
-		cfg->args = arg_array;
-		mono_save_args (cfg, sig, inline_args);
-	}
-	if (cfg->method == method && cfg->self_init && cfg->compile_aot && !COMPILE_LLVM (cfg)) {
-		MonoMethod *wrapper;
-		MonoInst *args [2];
-		int idx;
-		/*
-		 * Emit code to initialize this method by calling the init wrapper emitted by LLVM.
-		 * This is not efficient right now, but its only used for the methods which fail
-		 * LLVM compilation.
-		 * FIXME: Optimize this
-		 */
-		g_assert (!cfg->gshared);
-		wrapper = mono_marshal_get_aot_init_wrapper (AOT_INIT_METHOD);
-		/* Emit this into the entry bb so it comes before the GC safe point which depends on an inited GOT */
-		cfg->cbb = cfg->bb_entry;
-		idx = mono_aot_get_method_index (cfg->method);
-		EMIT_NEW_ICONST (cfg, args [0], idx);
-		/* Dummy */
-		EMIT_NEW_ICONST (cfg, args [1], 0);
-		mono_emit_method_call (cfg, wrapper, args, NULL);
-	}
-	if (cfg->llvm_only)
-		g_assert (cfg->interp);
-	if (cfg->llvm_only && cfg->interp && cfg->method == method && !cfg->deopt && !cfg->interp_entry_only) {
-		if (header->num_clauses) {
-			for (guint i = 0; i < header->num_clauses; ++i) {
-				MonoExceptionClause *clause = &header->clauses [i];
-				/* Finally clauses are checked after the remove_finally pass */
-				if (clause->flags != MONO_EXCEPTION_CLAUSE_FINALLY)
-					cfg->interp_entry_only = TRUE;
-			}
-		}
-	}
-	/* we use a separate basic block for the initialization code */
-	NEW_BBLOCK (cfg, init_localsbb);
-	if (cfg->method == method)
-		cfg->bb_init = init_localsbb;
-	init_localsbb->real_offset = cfg->real_offset;
-	start_bblock->next_bb = init_localsbb;
-	link_bblock (cfg, start_bblock, init_localsbb);
-	init_localsbb2 = init_localsbb;
-	cfg->cbb = init_localsbb;
-	/*
-	 * If the method receives an mrgctx, store all rgctx entries in mrgctx->entries instead of in the
-	 * class rgctx.
-	 * Disable for gsharedvt for now since the handling of gsharedvt related rgctx entries for
-	 * MONO_PATCH_INFO_GSHARED_METHOD_INFO is not implemented yet.
-	 */
-	if (cfg->gshared && cfg->method == method && cfg->rgctx_access == MONO_RGCTX_ACCESS_MRGCTX) {
-		MonoGSharedMethodInfo *info;
-		MonoInst *args [2];
-		/* Allocate into permanent memory since its the key in MonoJumpInfo */
-		info = (MonoGSharedMethodInfo *)mono_mem_manager_alloc0 (cfg->mem_manager, sizeof (MonoGSharedMethodInfo));
-		/* Will be copied into permanent memory in mini_method_compile () */
-		info->method = cfg->method;
-		info->count_entries = 16;
-		info->entries = (MonoRuntimeGenericContextInfoTemplate *)mono_mempool_alloc0 (cfg->mempool, sizeof (MonoRuntimeGenericContextInfoTemplate) * info->count_entries);
-		cfg->gshared_info = info;
-		args [0] = mono_get_mrgctx_var (cfg);
-		if (COMPILE_LLVM (cfg) || cfg->backend->have_init_mrgctx) {
-			if (COMPILE_LLVM (cfg))
-				/* OP_INIT_MRGCTX emits it itself */
-				EMIT_NEW_PCONST (cfg, args [1], NULL);
-			else if (cfg->compile_aot)
-				args [1] = mini_emit_runtime_constant (cfg, MONO_PATCH_INFO_GSHARED_METHOD_INFO, info);
-			else
-				EMIT_NEW_PCONST (cfg, args [1], info);
-			cfg->init_method_rgctx_ins_arg = args [1];
-			MONO_INST_NEW (cfg, ins, OP_INIT_MRGCTX);
-			ins->sreg1 = args [0]->dreg;
-			ins->sreg2 = args [1]->dreg;
-			MONO_ADD_INS (cfg->cbb, ins);
-			cfg->init_method_rgctx_ins = ins;
-			cfg->has_calls = TRUE;
-		} else {
-			MonoBasicBlock *end_bb;
-			int mrgctx_reg, entries_reg;
-			NEW_BBLOCK (cfg, end_bb);
-			mrgctx_reg = mono_get_mrgctx_var (cfg)->dreg;
-			entries_reg = alloc_preg (cfg);
-			MONO_EMIT_NEW_LOAD_MEMBASE (cfg, entries_reg, mrgctx_reg, MONO_STRUCT_OFFSET (MonoMethodRuntimeGenericContext, entries));
-			cfg->init_method_rgctx_ins_load = cfg->cbb->last_ins;
-			MONO_EMIT_NEW_BIALU_IMM (cfg, OP_COMPARE_IMM, -1, entries_reg, 0);
-			MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_PBNE_UN, end_bb);
-			/* Slowpath */
-			cfg->cbb->out_of_line = TRUE;
-			if (cfg->compile_aot)
-				args [1] = mini_emit_runtime_constant (cfg, MONO_PATCH_INFO_GSHARED_METHOD_INFO, info);
-			else
-				EMIT_NEW_PCONST (cfg, args [1], info);
-			cfg->init_method_rgctx_ins_arg = args [1];
-			cfg->init_method_rgctx_ins = mono_emit_jit_icall (cfg, mini_init_method_rgctx, args);
-			MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_BR, end_bb);
-			MONO_START_BB (cfg, end_bb);
-			init_localsbb = cfg->cbb;
-			init_localsbb2 = cfg->cbb;
-		}
-	}
-	if (cfg->gsharedvt && cfg->method == method) {
-		MonoGSharedVtMethodInfo *info;
-		MonoInst *var, *locals_var;
-		int dreg;
-		info = (MonoGSharedVtMethodInfo *)mono_mempool_alloc0 (cfg->mempool, sizeof (MonoGSharedVtMethodInfo));
-		info->method = cfg->method;
-		info->count_entries = 16;
-		info->entries = (MonoRuntimeGenericContextInfoTemplate *)mono_mempool_alloc0 (cfg->mempool, sizeof (MonoRuntimeGenericContextInfoTemplate) * info->count_entries);
-		cfg->gsharedvt_info = info;
-		var = mono_compile_create_var (cfg, mono_get_int_type (), OP_LOCAL);
-		/*
-		 * Decomposing ldaddr creates uses for this and gsharedvt_locals_var, so
-		 * when we emit an ldaddr, we emit dummy uses for these in handle_gsharedvt_ldaddr ().
-		 */
-		cfg->gsharedvt_info_var = var;
-		ins = emit_get_rgctx_gsharedvt_method (cfg, mini_method_check_context_used (cfg, method), method, info);
-		MONO_EMIT_NEW_UNALU (cfg, OP_MOVE, var->dreg, ins->dreg);
-		/* Allocate locals */
-		locals_var = mono_compile_create_var (cfg, mono_get_int_type (), OP_LOCAL);
-		/* prevent it from being register allocated */
-		cfg->gsharedvt_locals_var = locals_var;
-		dreg = alloc_ireg (cfg);
-		MONO_EMIT_NEW_LOAD_MEMBASE_OP (cfg, OP_LOADI4_MEMBASE, dreg, var->dreg, MONO_STRUCT_OFFSET (MonoGSharedVtMethodRuntimeInfo, locals_size));
-		MONO_INST_NEW (cfg, ins, OP_LOCALLOC);
-		ins->dreg = locals_var->dreg;
-		ins->sreg1 = dreg;
-		MONO_ADD_INS (cfg->cbb, ins);
-		cfg->gsharedvt_locals_var_ins = ins;
-		cfg->flags |= MONO_CFG_HAS_ALLOCA;
-		/*
-		if (init_locals)
-			ins->flags |= MONO_INST_INIT;
-		*/
-		if (cfg->llvm_only) {
-			init_localsbb = cfg->cbb;
-			init_localsbb2 = cfg->cbb;
-		}
-	}
-	if (cfg->deopt) {
-		/*
-		 * Push an LMFExt frame which points to a MonoMethodILState structure.
-		 */
-		emit_push_lmf (cfg);
-		/* The type doesn't matter, the llvm backend will use the correct type */
-		MonoInst *il_state_var = mono_compile_create_var (cfg, mono_get_int_type (), OP_LOCAL);
-		il_state_var->flags |= MONO_INST_VOLATILE;
-		cfg->il_state_var = il_state_var;
-		EMIT_NEW_VARLOADA (cfg, ins, cfg->il_state_var, NULL);
-		int il_state_addr_reg = ins->dreg;
-		/* il_state->method = method */
-		MonoInst *method_ins = emit_get_rgctx_method (cfg, -1, cfg->method, MONO_RGCTX_INFO_METHOD);
-		MONO_EMIT_NEW_STORE_MEMBASE (cfg, OP_STORE_MEMBASE_REG, il_state_addr_reg, MONO_STRUCT_OFFSET (MonoMethodILState, method), method_ins->dreg);
-		EMIT_NEW_VARLOADA (cfg, ins, cfg->lmf_var, NULL);
-		int lmf_reg = ins->dreg;
-		/* lmf->kind = MONO_LMFEXT_IL_STATE */
-		MONO_EMIT_NEW_STORE_MEMBASE_IMM (cfg, OP_STOREI4_MEMBASE_IMM, lmf_reg, MONO_STRUCT_OFFSET (MonoLMFExt, kind), MONO_LMFEXT_IL_STATE);
-		/* lmf->il_state = il_state */
-		MONO_EMIT_NEW_STORE_MEMBASE (cfg, OP_STORE_MEMBASE_REG, lmf_reg, MONO_STRUCT_OFFSET (MonoLMFExt, il_state), il_state_addr_reg);
-		/* emit_get_rgctx_method () might create new bblocks */
-		if (cfg->llvm_only) {
-			init_localsbb = cfg->cbb;
-			init_localsbb2 = cfg->cbb;
-		}
-	}
-	if (cfg->llvm_only && cfg->interp && cfg->method == method) {
-		if (cfg->interp_entry_only)
-			emit_llvmonly_interp_entry (cfg, header);
-	}
-	/* FIRST CODE BLOCK */
-	NEW_BBLOCK (cfg, tblock);
-	tblock->cil_code = ip;
-	cfg->cbb = tblock;
-	cfg->ip = ip;
-	init_localsbb->next_bb = cfg->cbb;
-	link_bblock (cfg, init_localsbb, cfg->cbb);
-	ADD_BBLOCK (cfg, tblock);
-	CHECK_CFG_EXCEPTION;
-	if (header->code_size == 0)
-		UNVERIFIED;
-	if (get_basic_blocks (cfg, header, cfg->real_offset, ip, end, &err_pos)) {
-		ip = err_pos;
-		UNVERIFIED;
-	}
-	if (cfg->method == method) {
-		int breakpoint_id = mono_debugger_method_has_breakpoint (method);
-		if (breakpoint_id) {
-			if (COMPILE_LLVM (cfg)) {
-				mono_emit_jit_icall (cfg, mono_break, NULL);
-			} else {
-				MONO_INST_NEW (cfg, ins, OP_BREAK);
-				MONO_ADD_INS (cfg->cbb, ins);
-			}
-		}
-		mono_debug_init_method (cfg, cfg->cbb, breakpoint_id);
-	}
-	for (n = 0; n < header->num_locals; ++n) {
-		if (header->locals [n]->type == MONO_TYPE_VOID && !m_type_is_byref (header->locals [n]))
-			UNVERIFIED;
-	}
-	class_inits = NULL;
-	/* We force the vtable variable here for all shared methods
-	   for the possibility that they might show up in a stack
-	   trace where their exact instantiation is needed. */
-	if (cfg->gshared && method == cfg->method) {
-		if ((method->flags & METHOD_ATTRIBUTE_STATIC) ||
-				mini_method_get_context (method)->method_inst ||
-				m_class_is_valuetype (method->klass)) {
-			mono_get_vtable_var (cfg);
-		} else {
-			/* FIXME: Is there a better way to do this?
-			   We need the variable live for the duration
-			   of the whole method. */
-			if (!COMPILE_LLVM (cfg))
-				cfg->args [0]->flags |= MONO_INST_VOLATILE;
-		}
-	}
-	/* add a check for this != NULL to inlined methods */
-	if (is_virtual_call) {
-		MonoInst *arg_ins;
-		if (!(cfg->llvm_only && m_class_is_valuetype (method->klass) && header->code_size == 1 && header->code [0] == CEE_RET)) {
-			NEW_ARGLOAD (cfg, arg_ins, 0);
-			MONO_ADD_INS (cfg->cbb, arg_ins);
-			MONO_EMIT_NEW_CHECK_THIS (cfg, arg_ins->dreg);
-		}
-	}
-	skip_dead_blocks = !dont_verify;
-	if (skip_dead_blocks) {
-		original_bb = bb = mono_basic_block_split (method, cfg->error, header);
-		CHECK_CFG_ERROR;
-		g_assert (bb);
-	}
-	if (cfg->gsharedvt_min) {
-		if (mini_is_gsharedvt_variable_signature (sig))
-			GSHAREDVT_FAILURE (*cfg->cil_start);
-		for (int i = 0; i < header->num_locals; ++i) {
-			if (mini_is_gsharedvt_variable_type (header->locals [i]))
-				GSHAREDVT_FAILURE (*cfg->cil_start);
-		}
-	}
-	/* we use a spare stack slot in SWITCH and NEWOBJ and others */
-	stack_start = sp = (MonoInst **)mono_mempool_alloc0 (cfg->mempool, sizeof (MonoInst*) * (header->max_stack + 1));
-	ins_flag = 0;
-	start_new_bblock = 0;
-	MonoOpcodeEnum il_op; il_op = MonoOpcodeEnum_Invalid;
-	emit_set_deopt_il_offset (cfg, GPTRDIFF_TO_INT (ip - cfg->cil_start));
-	for (guchar *next_ip = ip; ip < end; ip = next_ip) {
-		MonoOpcodeEnum previous_il_op = il_op;
-		const guchar *tmp_ip = ip;
-		const int op_size = mono_opcode_value_and_size (&tmp_ip, end, &il_op);
-		CHECK_OPSIZE (op_size);
-		next_ip += op_size;
-		if (cfg->method == method)
-			cfg->real_offset = GPTRDIFF_TO_UINT (ip - header->code);
-		else
-			cfg->real_offset = inline_offset;
-		cfg->ip = ip;
-		context_used = 0;
-		if (start_new_bblock) {
-			cfg->cbb->cil_length = GPTRDIFF_TO_INT32 (ip - cfg->cbb->cil_code);
-			if (start_new_bblock == 2) {
-				g_assert (ip == tblock->cil_code);
-			} else {
-				GET_BBLOCK (cfg, tblock, ip);
-			}
-			cfg->cbb->next_bb = tblock;
-			cfg->cbb = tblock;
-			start_new_bblock = 0;
-			for (int i = 0; i < cfg->cbb->in_scount; ++i) {
-				if (cfg->verbose_level > 3)
-					printf ("loading %d from temp %d\n", i, (int)cfg->cbb->in_stack [i]->inst_c0);
-				EMIT_NEW_TEMPLOAD (cfg, ins, cfg->cbb->in_stack [i]->inst_c0);
-				*sp++ = ins;
-			}
-			if (class_inits)
-				g_slist_free (class_inits);
-			class_inits = NULL;
-			emit_set_deopt_il_offset (cfg, GPTRDIFF_TO_INT (ip - cfg->cil_start));
-		} else {
-			if ((tblock = cfg->cil_offset_to_bb [ip - cfg->cil_start]) && (tblock != cfg->cbb)) {
-				if (sp != stack_start) {
-					link_bblock (cfg, cfg->cbb, tblock);
-					handle_stack_args (cfg, stack_start, GPTRDIFF_TO_INT (sp - stack_start));
-					sp = stack_start;
-					CHECK_UNVERIFIABLE (cfg);
-				} else {
-					if (!(cfg->cbb->last_ins && cfg->cbb->last_ins->opcode == OP_NOT_REACHED))
-						link_bblock (cfg, cfg->cbb, tblock);
-				}
-				cfg->cbb->next_bb = tblock;
-				cfg->cbb = tblock;
-				for (int i = 0; i < cfg->cbb->in_scount; ++i) {
-					if (cfg->verbose_level > 3)
-						printf ("loading %d from temp %d\n", i, (int)cfg->cbb->in_stack [i]->inst_c0);
-					EMIT_NEW_TEMPLOAD (cfg, ins, cfg->cbb->in_stack [i]->inst_c0);
-					*sp++ = ins;
-				}
-				g_slist_free (class_inits);
-				class_inits = NULL;
-				emit_set_deopt_il_offset (cfg, GPTRDIFF_TO_INT (ip - cfg->cil_start));
-			}
-		}
-		/*
-		 * Methods with AggressiveInline flag could be inlined even if the class has a cctor.
-		 * This might create a branch so emit it in the first code bblock instead of into initlocals_bb.
-		 */
-		if (ip - header->code == 0 && cfg->method != method && cfg->compile_aot && (method->iflags & METHOD_IMPL_ATTRIBUTE_AGGRESSIVE_INLINING) && mono_class_needs_cctor_run (method->klass, method))
-			emit_class_init (cfg, method->klass, FALSE);
-		if (skip_dead_blocks) {
-			int ip_offset = GPTRDIFF_TO_INT (ip - header->code);
-			if (ip_offset == bb->end)
-				bb = bb->next;
-			if (bb->dead) {
-				g_assert (op_size > 0); /*The BB formation pass must catch all bad ops*/
-				if (cfg->verbose_level > 3) printf ("SKIPPING DEAD OP at %x\n", ip_offset);
-				if (ip_offset + op_size == bb->end) {
-					MONO_INST_NEW (cfg, ins, OP_NOP);
-					MONO_ADD_INS (cfg->cbb, ins);
-					start_new_bblock = 1;
-				}
-				continue;
-			}
-		}
-		/*
-		 * Sequence points are points where the debugger can place a breakpoint.
-		 * Currently, we generate these automatically at points where the IL
-		 * stack is empty.
-		 */
-		if (seq_points && ((!sym_seq_points && (sp == stack_start)) || (sym_seq_points && mono_bitset_test_fast (seq_point_locs, ip - header->code)))) {
-			/*
-			 * Make methods interruptible at the beginning, and at the targets of
-			 * backward branches.
-			 * Also, do this at the start of every bblock in methods with clauses too,
-			 * to be able to handle instructions with inprecise control flow like
-			 * throw/endfinally.
-			 * Backward branches are handled at the end of method-to-ir ().
-			 */
-			gboolean intr_loc = ip == header->code || (!cfg->cbb->last_ins && cfg->header->num_clauses);
-			gboolean sym_seq_point = sym_seq_points && mono_bitset_test_fast (seq_point_locs, ip - header->code);
-			/* Avoid sequence points on empty IL like .volatile */
-			NEW_SEQ_POINT (cfg, ins, GPTRDIFF_TO_TMREG (ip - header->code), intr_loc);
-			if ((sp != stack_start) && !sym_seq_point)
-				ins->flags |= MONO_INST_NONEMPTY_STACK;
-			MONO_ADD_INS (cfg->cbb, ins);
-			if (sym_seq_points)
-				mono_bitset_set_fast (seq_point_set_locs, ip - header->code);
-			if (cfg->prof_coverage) {
-				ptrdiff_t cil_offset = ip - header->code;
-				gpointer counter = &cfg->coverage_info->data [cil_offset].count;
-				cfg->coverage_info->data [cil_offset].cil_code = ip;
-				if (mono_arch_opcode_supported (OP_ATOMIC_ADD_I4)) {
-					MonoInst *one_ins, *load_ins;
-					EMIT_NEW_PCONST (cfg, load_ins, counter);
-					EMIT_NEW_ICONST (cfg, one_ins, 1);
-					MONO_INST_NEW (cfg, ins, OP_ATOMIC_ADD_I4);
-					ins->dreg = mono_alloc_ireg (cfg);
-					ins->inst_basereg = load_ins->dreg;
-					ins->inst_offset = 0;
-					ins->sreg2 = one_ins->dreg;
-					ins->type = STACK_I4;
-					MONO_ADD_INS (cfg->cbb, ins);
-				} else {
-					EMIT_NEW_PCONST (cfg, ins, counter);
-					MONO_EMIT_NEW_STORE_MEMBASE_IMM (cfg, OP_STORE_MEMBASE_IMM, ins->dreg, 0, 1);
-				}
-			}
-		}
-		cfg->cbb->real_offset = cfg->real_offset;
-		if (cfg->verbose_level > 3)
-			printf ("converting (in B%d: stack: %d) %s", cfg->cbb->block_num, GPTRDIFF_TO_INT (sp - stack_start), mono_disasm_code_one (NULL, method, ip, NULL));
-		/*
-		 * This is used to compute BB_HAS_SIDE_EFFECTS, which is used for the elimination of
-		 * foreach finally clauses, so only IL opcodes which occur in such clauses
-		 * need to set this.
-		 */
-		ins_has_side_effect = TRUE;
-		gboolean emit_widen = TRUE;
-		gboolean tailcall = FALSE;
-		gboolean common_call = FALSE;
-		MonoInst *keep_this_alive = NULL;
-		MonoMethod *cmethod = NULL;
-		MonoMethodSignature *fsig = NULL;
-		gboolean need_seq_point = FALSE;
-		gboolean push_res = TRUE;
-		gboolean skip_ret = FALSE;
-		gboolean tailcall_remove_ret = FALSE;
-		MonoOpcodeParameter parameter;
-		const MonoOpcodeInfo* info = mono_opcode_decode (ip, op_size, il_op, &parameter);
-		g_assert (info);
-		n = parameter.i32;
-		token = parameter.i32;
-		target = parameter.branch_target;
-		const int pushes = info->pushes;
-		const int pops = info->pops;
-		if (pushes >= 0 && pops >= 0) {
-			g_assert (pushes - pops <= 1);
-			if (pushes - pops == 1)
-				CHECK_STACK_OVF ();
-		}
-		if (pops >= 0)
-			CHECK_STACK (pops);
-		switch (il_op) {
-		case MONO_CEE_NOP:
-			if (seq_points && !sym_seq_points && sp != stack_start) {
-				/*
-				 * The C# compiler uses these nops to notify the JIT that it should
-				 * insert seq points.
-				 */
-				NEW_SEQ_POINT (cfg, ins, GPTRDIFF_TO_TMREG (ip - header->code), FALSE);
-				MONO_ADD_INS (cfg->cbb, ins);
-			}
-			if (cfg->keep_cil_nops)
-				MONO_INST_NEW (cfg, ins, OP_HARD_NOP);
-			else
-				MONO_INST_NEW (cfg, ins, OP_NOP);
-			MONO_ADD_INS (cfg->cbb, ins);
-			emitted_funccall_seq_point = FALSE;
-			ins_has_side_effect = FALSE;
-			break;
-		case MONO_CEE_BREAK:
-			if (mini_should_insert_breakpoint (cfg->method)) {
-				ins = mono_emit_jit_icall (cfg, mono_debugger_agent_user_break, NULL);
-			} else {
-				MONO_INST_NEW (cfg, ins, OP_NOP);
-				MONO_ADD_INS (cfg->cbb, ins);
-			}
-			break;
-		case MONO_CEE_LDARG_0:
-		case MONO_CEE_LDARG_1:
-		case MONO_CEE_LDARG_2:
-		case MONO_CEE_LDARG_3:
-		case MONO_CEE_LDARG_S:
-		case MONO_CEE_LDARG:
-			CHECK_ARG (n);
-			if (next_ip < end && is_addressable_valuetype_load (cfg, next_ip, cfg->arg_types [n])) {
-				EMIT_NEW_ARGLOADA (cfg, ins, n);
-			} else {
-				EMIT_NEW_ARGLOAD (cfg, ins, n);
-			}
-			*sp++ = ins;
-			/*if (!m_method_is_icall (method)) */{
-				MonoMethod* callvirt_target = try_prepare_objaddr_callvirt_optimization (cfg, next_ip, end, method, generic_context, param_types [n]);
-				if (callvirt_target)
-					cmethod_override = callvirt_target;
-			}
-			break;
-		case MONO_CEE_LDLOC_0:
-		case MONO_CEE_LDLOC_1:
-		case MONO_CEE_LDLOC_2:
-		case MONO_CEE_LDLOC_3:
-		case MONO_CEE_LDLOC_S:
-		case MONO_CEE_LDLOC:
-			CHECK_LOCAL (n);
-			if (next_ip < end && is_addressable_valuetype_load (cfg, next_ip, header->locals [n])) {
-				EMIT_NEW_LOCLOADA (cfg, ins, n);
-			} else {
-				EMIT_NEW_LOCLOAD (cfg, ins, n);
-			}
-			*sp++ = ins;
-			break;
-		case MONO_CEE_STLOC_0:
-		case MONO_CEE_STLOC_1:
-		case MONO_CEE_STLOC_2:
-		case MONO_CEE_STLOC_3:
-		case MONO_CEE_STLOC_S:
-		case MONO_CEE_STLOC:
-			CHECK_LOCAL (n);
-			--sp;
-			*sp = convert_value (cfg, header->locals [n], *sp);
-			if (!dont_verify_stloc && target_type_is_incompatible (cfg, header->locals [n], *sp))
-				UNVERIFIED;
-			emit_stloc_ir (cfg, sp, header, n);
-			inline_costs += 1;
-			break;
-		case MONO_CEE_LDARGA_S:
-		case MONO_CEE_LDARGA:
-			CHECK_ARG (n);
-			NEW_ARGLOADA (cfg, ins, n);
-			MONO_ADD_INS (cfg->cbb, ins);
-			*sp++ = ins;
-			break;
-		case MONO_CEE_STARG_S:
-		case MONO_CEE_STARG:
-			--sp;
-			CHECK_ARG (n);
-			*sp = convert_value (cfg, param_types [n], *sp);
-			if (!dont_verify_stloc && target_type_is_incompatible (cfg, param_types [n], *sp))
-				UNVERIFIED;
-			emit_starg_ir (cfg, sp, n);
-			break;
-		case MONO_CEE_LDLOCA:
-		case MONO_CEE_LDLOCA_S: {
-			guchar *ldloca_ip;
-			CHECK_LOCAL (n);
-			if ((ldloca_ip = emit_optimized_ldloca_ir (cfg, next_ip, end, n))) {
-				next_ip = ldloca_ip;
-				il_op = MONO_CEE_INITOBJ;
-				inline_costs += 1;
-				break;
-			}
-			ins_has_side_effect = FALSE;
-			EMIT_NEW_LOCLOADA (cfg, ins, n);
-			*sp++ = ins;
-			break;
-		}
-		case MONO_CEE_LDNULL:
-			EMIT_NEW_PCONST (cfg, ins, NULL);
-			ins->type = STACK_OBJ;
-			*sp++ = ins;
-			break;
-		case MONO_CEE_LDC_I4_M1:
-		case MONO_CEE_LDC_I4_0:
-		case MONO_CEE_LDC_I4_1:
-		case MONO_CEE_LDC_I4_2:
-		case MONO_CEE_LDC_I4_3:
-		case MONO_CEE_LDC_I4_4:
-		case MONO_CEE_LDC_I4_5:
-		case MONO_CEE_LDC_I4_6:
-		case MONO_CEE_LDC_I4_7:
-		case MONO_CEE_LDC_I4_8:
-		case MONO_CEE_LDC_I4_S:
-		case MONO_CEE_LDC_I4:
-			EMIT_NEW_ICONST (cfg, ins, n);
-			*sp++ = ins;
-			break;
-		case MONO_CEE_LDC_I8:
-			MONO_INST_NEW (cfg, ins, OP_I8CONST);
-			ins->type = STACK_I8;
-			ins->dreg = alloc_dreg (cfg, STACK_I8);
-			ins->inst_l = parameter.i64;
-			MONO_ADD_INS (cfg->cbb, ins);
-			*sp++ = ins;
-			break;
-		case MONO_CEE_LDC_R4: {
-			float *f;
-			gboolean use_aotconst = FALSE;
-#ifdef TARGET_POWERPC
-			/* FIXME: Clean this up */
-			if (cfg->compile_aot)
-				use_aotconst = TRUE;
-#endif
-			/* FIXME: we should really allocate this only late in the compilation process */
-			f = (float *)mono_mem_manager_alloc (cfg->mem_manager, sizeof (float));
-			if (use_aotconst) {
-				MonoInst *cons;
-				int dreg;
-				EMIT_NEW_AOTCONST (cfg, cons, MONO_PATCH_INFO_R4, f);
-				dreg = alloc_freg (cfg);
-				EMIT_NEW_LOAD_MEMBASE (cfg, ins, OP_LOADR4_MEMBASE, dreg, cons->dreg, 0);
-				ins->type = GINT_TO_UINT8 (cfg->r4_stack_type);
-			} else {
-				MONO_INST_NEW (cfg, ins, OP_R4CONST);
-				ins->type = GINT_TO_UINT8 (cfg->r4_stack_type);
-				ins->dreg = alloc_dreg (cfg, STACK_R8);
-				ins->inst_p0 = f;
-				MONO_ADD_INS (cfg->cbb, ins);
-			}
-			*f = parameter.f;
-			*sp++ = ins;
-			break;
-		}
-		case MONO_CEE_LDC_R8: {
-			double *d;
-			gboolean use_aotconst = FALSE;
-#ifdef TARGET_POWERPC
-			/* FIXME: Clean this up */
-			if (cfg->compile_aot)
-				use_aotconst = TRUE;
-#endif
-			/* FIXME: we should really allocate this only late in the compilation process */
-			d = (double *)mono_mem_manager_alloc (cfg->mem_manager, sizeof (double));
-			if (use_aotconst) {
-				MonoInst *cons;
-				int dreg;
-				EMIT_NEW_AOTCONST (cfg, cons, MONO_PATCH_INFO_R8, d);
-				dreg = alloc_freg (cfg);
-				EMIT_NEW_LOAD_MEMBASE (cfg, ins, OP_LOADR8_MEMBASE, dreg, cons->dreg, 0);
-				ins->type = STACK_R8;
-			} else {
-				MONO_INST_NEW (cfg, ins, OP_R8CONST);
-				ins->type = STACK_R8;
-				ins->dreg = alloc_dreg (cfg, STACK_R8);
-				ins->inst_p0 = d;
-				MONO_ADD_INS (cfg->cbb, ins);
-			}
-			*d = parameter.d;
-			*sp++ = ins;
-			break;
-		}
-		case MONO_CEE_DUP: {
-			MonoInst *temp, *store;
-			sp--;
-			ins = *sp;
-			klass = ins->klass;
-			temp = mono_compile_create_var (cfg, type_from_stack_type (ins), OP_LOCAL);
-			EMIT_NEW_TEMPSTORE (cfg, store, temp->inst_c0, ins);
-			EMIT_NEW_TEMPLOAD (cfg, ins, temp->inst_c0);
-			ins->klass = klass;
-			*sp++ = ins;
-			EMIT_NEW_TEMPLOAD (cfg, ins, temp->inst_c0);
-			ins->klass = klass;
-			*sp++ = ins;
-			inline_costs += 2;
-			break;
-		}
-		case MONO_CEE_POP:
-			--sp;
-			break;
-		case MONO_CEE_JMP: {
-			MonoCallInst *call;
-			INLINE_FAILURE ("jmp");
-			GSHAREDVT_FAILURE (il_op);
-			if (stack_start != sp)
-				UNVERIFIED;
-			/* FIXME: check the signature matches */
-			cmethod = mini_get_method (cfg, method, token, NULL, generic_context);
-			CHECK_CFG_ERROR;
-			if (cfg->gshared && mono_method_check_context_used (cmethod))
-				GENERIC_SHARING_FAILURE (CEE_JMP);
-			mini_profiler_emit_tail_call (cfg, cmethod);
-			fsig = mono_method_signature_internal (cmethod);
-			int nargs = fsig->param_count + fsig->hasthis;
-			if (cfg->llvm_only) {
-				MonoInst **args;
-				args = (MonoInst **)mono_mempool_alloc (cfg->mempool, sizeof (MonoInst*) * nargs);
-				for (int i = 0; i < nargs; ++i)
-					EMIT_NEW_ARGLOAD (cfg, args [i], i);
-				ins = mini_emit_method_call_full (cfg, cmethod, fsig, TRUE, args, NULL, NULL, NULL);
-				/*
-				 * The code in mono-basic-block.c treats the rest of the code as dead, but we
-				 * have to emit a normal return since llvm expects it.
-				 */
-				if (cfg->ret)
-					emit_setret (cfg, ins);
-				MONO_INST_NEW (cfg, ins, OP_BR);
-				ins->inst_target_bb = end_bblock;
-				MONO_ADD_INS (cfg->cbb, ins);
-				link_bblock (cfg, cfg->cbb, end_bblock);
-				break;
-			} else {
-				/* Handle tailcalls similarly to calls */
-				DISABLE_AOT (cfg);
-				mini_emit_tailcall_parameters (cfg, fsig);
-				MONO_INST_NEW_CALL (cfg, call, OP_TAILCALL);
-				call->method = cmethod;
-				call->tailcall = TRUE;
-				call->signature = fsig;
-				call->args = (MonoInst **)mono_mempool_alloc (cfg->mempool, sizeof (MonoInst*) * nargs);
-				call->inst.inst_p0 = cmethod;
-				for (int i = 0; i < nargs; ++i)
-					EMIT_NEW_ARGLOAD (cfg, call->args [i], i);
-				if (mini_type_is_vtype (mini_get_underlying_type (call->signature->ret)))
-					call->vret_var = cfg->vret_addr;
-				mono_arch_emit_call (cfg, call);
-				cfg->param_area = MAX(cfg->param_area, call->stack_usage);
-				MONO_ADD_INS (cfg->cbb, (MonoInst*)call);
-			}
-			start_new_bblock = 1;
-			break;
-		}
-		case MONO_CEE_CALLI: {
-			MonoInst *addr;
-			MonoInst *callee = NULL;
-			common_call = TRUE; // i.e. skip_ret/push_res/seq_point logic
-			cmethod = NULL;
-			gboolean const inst_tailcall = G_UNLIKELY (debug_tailcall_try_all
-							? (next_ip < end && next_ip [0] == CEE_RET)
-							: ((ins_flag & MONO_INST_TAILCALL) != 0));
-			ins = NULL;
-			CHECK_STACK (1);
-			--sp;
-			addr = *sp;
-			g_assert (addr);
-			fsig = mini_get_signature (method, token, generic_context, cfg->error);
-			CHECK_CFG_ERROR;
-			if (cfg->gsharedvt_min && mini_is_gsharedvt_variable_signature (fsig))
-				GSHAREDVT_FAILURE (il_op);
-#ifdef MONO_ARCH_HAVE_SWIFTCALL
-			/*
-			 * We need to modify the signature of the swiftcall calli to account for the lowering of Swift structs.
- 			 * This is done by replacing struct arguments on stack with a lowered sequence and updating the signature.
-			 */
-			if (fsig->pinvoke && mono_method_signature_has_ext_callconv (fsig, MONO_EXT_CALLCONV_SWIFTCALL)) {
-				g_assert (!fsig->hasthis); // Swift P/Invoke calls shouldn't contain 'this'
-				n = fsig->param_count;
-				sp -= n;
-				MonoInst **old_params = (MonoInst**) mono_mempool_alloc (cfg->mempool, sizeof (MonoInst*) * n);
-				for (int idx_param = 0; idx_param < n; ++idx_param) {
-					old_params [idx_param] = sp [idx_param];
-				}
-				GArray *new_params = g_array_sized_new (FALSE, FALSE, sizeof (MonoType*), n);
-				uint32_t new_param_count = 0;
-				MonoClass *swift_self = mono_class_try_get_swift_self_class ();
-				MonoClass *swift_self_t = mono_class_try_get_swift_self_t_class ();
-				MonoClass *swift_error = mono_class_try_get_swift_error_class ();
-				MonoClass *swift_indirect_result = mono_class_try_get_swift_indirect_result_class ();
-				/*
-				 * Go through the lowered arguments, if the argument is a struct, 
-				 * we need to replace it with a sequence of lowered arguments.
-				 * Also record the updated parameters for the new signature.
-				 */
-				for (int idx_param = 0; idx_param < n; ++idx_param) {
-					MonoType *ptype = fsig->params [idx_param];
-					MonoClass *klass = mono_class_from_mono_type_internal (ptype);
-					MonoGenericClass *gklass = mono_class_try_get_generic_class (klass);
-					if (mono_type_is_struct (ptype) && !(klass == swift_self || klass == swift_error || klass == swift_indirect_result)) {
-						SwiftPhysicalLowering lowered_swift_struct = mono_marshal_get_swift_physical_lowering (ptype, FALSE);
-						MonoInst *struct_base_address =  mono_compile_create_var (cfg, mono_get_int_type (), OP_LOCAL);
-						CHECK_ARG (idx_param);
-						NEW_ARGLOADA (cfg, struct_base_address, idx_param);
-						MONO_ADD_INS (cfg->cbb, struct_base_address);
-						if (!lowered_swift_struct.by_reference) {
-							for (uint32_t idx_lowered = 0; idx_lowered < lowered_swift_struct.num_lowered_elements; ++idx_lowered) {
-								MonoInst *lowered_arg = mini_emit_memory_load (cfg, lowered_swift_struct.lowered_elements [idx_lowered], struct_base_address, lowered_swift_struct.offsets [idx_lowered], 0);
-								*sp++ = lowered_arg;
-								g_array_append_val (new_params, lowered_swift_struct.lowered_elements [idx_lowered]);
-								++new_param_count;
-							}
-						} else {
-							if (gklass && (gklass->container_class == swift_self_t)) {
-								ptype = mono_class_get_byref_type (swift_self);
-								struct_base_address->klass = mono_defaults.int_class;
-							} else {
-								ptype = mono_class_get_byref_type (klass);
-							}
-							*sp++ = struct_base_address;
-							g_array_append_val (new_params, ptype);
-							++new_param_count;
-						}
-					} else {
-						*sp++ = old_params [idx_param];
-						++new_param_count;
-						g_array_append_val (new_params, ptype);
-					}
-				}
-				fsig = mono_metadata_signature_dup_new_params (cfg->mempool, NULL, fsig, new_param_count, (MonoType**)new_params->data);
-				g_array_free (new_params, TRUE);
-			}
-#endif
-			if (method->dynamic && fsig->pinvoke) {
-				MonoInst *args [3];
-				/*
-				 * This is a call through a function pointer using a pinvoke
-				 * signature. Have to create a wrapper and call that instead.
-				 * FIXME: This is very slow, need to create a wrapper at JIT time
-				 * instead based on the signature.
-				 */
-				EMIT_NEW_IMAGECONST (cfg, args [0], ((MonoDynamicMethod*)method)->assembly->image);
-				EMIT_NEW_PCONST (cfg, args [1], fsig);
-				args [2] = addr;
-				addr = mono_emit_jit_icall (cfg, mono_get_native_calli_wrapper, args);
-			}
-			if (!method->dynamic && fsig->pinvoke &&
-			    !method->wrapper_type) {
-				/* MONO_WRAPPER_DYNAMIC_METHOD dynamic method handled above in the
-				method->dynamic case; for other wrapper types assume the code knows
-				what its doing and added its own GC transitions */
-				gboolean skip_gc_trans = mono_method_signature_has_ext_callconv (fsig, MONO_EXT_CALLCONV_SUPPRESS_GC_TRANSITION);
-				if (!skip_gc_trans) {
-#if 0
-					fprintf (stderr, "generating wrapper for calli in method %s with wrapper type %s\n", method->name, mono_wrapper_type_to_str (method->wrapper_type));
-#endif
-					if (cfg->compile_aot)
-						cfg->pinvoke_calli_signatures = g_slist_prepend_mempool (cfg->mempool, cfg->pinvoke_calli_signatures, fsig);
-					if (fsig->has_type_parameters) {
-						cfg->prefer_instances = TRUE;
-						GENERIC_SHARING_FAILURE (CEE_CALLI);
-					}
-					/* Call the wrapper that will do the GC transition instead */
-					MonoMethod *wrapper = mono_marshal_get_native_func_wrapper_indirect (method->klass, fsig, cfg->compile_aot);
-					fsig = mono_method_signature_internal (wrapper);
-					n = fsig->param_count - 1; /* wrapper has extra fnptr param */
-					CHECK_STACK (n);
-					/* move the args to allow room for 'this' in the first position */
-					while (n--) {
-						--sp;
-						sp [1] = sp [0];
-					}
-					sp[0] = addr; /* n+1 args, first arg is the address of the indirect method to call */
-					g_assert (!fsig->hasthis && !fsig->pinvoke);
-					ins = mono_emit_method_call (cfg, wrapper, /*args*/sp, NULL);
-					goto calli_end;
-				}
-			}
-			n = fsig->param_count + fsig->hasthis;
-			CHECK_STACK (n);
-			if (n == 0 && fsig->call_convention == MONO_CALL_THISCALL)
-				mono_cfg_set_exception_invalid_program(cfg, "thiscall with 0 arguments");
-			sp -= n;
-			if (!(cfg->method->wrapper_type && cfg->method->wrapper_type != MONO_WRAPPER_DYNAMIC_METHOD) && check_call_signature (cfg, fsig, sp)) {
-				if (break_on_unverified ())
-					check_call_signature (cfg, fsig, sp); // Again, step through it.
-				UNVERIFIED;
-			}
-			inline_costs += CALL_COST * MIN(10, num_calls++);
-			/*
-			 * Making generic calls out of gsharedvt methods.
-			 * This needs to be used for all generic calls, not just ones with a gsharedvt signature, to avoid
-			 * patching gshared method addresses into a gsharedvt method.
-			 */
-			if (cfg->gsharedvt && mini_is_gsharedvt_signature (fsig)) {
-				/*
-				 * We pass the address to the gsharedvt trampoline in the rgctx reg
-				 */
-				callee = addr;
-				g_assert (addr); // Doubles as boolean after tailcall check.
-			}
-			inst_tailcall && is_supported_tailcall (cfg, ip, method, NULL, fsig,
-						FALSE/*virtual irrelevant*/, addr != NULL, &tailcall);
-			if (save_last_error)
-				mono_emit_jit_icall (cfg, mono_marshal_clear_last_error, NULL);
-			if (callee) {
-				if (method->wrapper_type != MONO_WRAPPER_DELEGATE_INVOKE)
-					/* Not tested */
-					GSHAREDVT_FAILURE (il_op);
-				if (cfg->llvm_only)
-					GSHAREDVT_FAILURE (il_op);
-				addr = emit_get_rgctx_sig (cfg, context_used, fsig, MONO_RGCTX_INFO_SIG_GSHAREDVT_OUT_TRAMPOLINE_CALLI);
-				ins = (MonoInst*)mini_emit_calli_full (cfg, fsig, sp, addr, NULL, callee, tailcall);
-				goto calli_end;
-			}
-			/* Prevent inlining of methods with indirect calls */
-			INLINE_FAILURE ("indirect call");
-			if (addr->opcode == OP_PCONST || addr->opcode == OP_AOTCONST || addr->opcode == OP_GOT_ENTRY) {
-				MonoJumpInfoType info_type;
-				gpointer info_data;
-				/*
-				 * Instead of emitting an indirect call, emit a direct call
-				 * with the contents of the aotconst as the patch info.
-				 */
-				if (addr->opcode == OP_PCONST || addr->opcode == OP_AOTCONST) {
-					info_type = (MonoJumpInfoType)addr->inst_c1;
-					info_data = addr->inst_p0;
-				} else {
-					info_type = (MonoJumpInfoType)addr->inst_right->inst_c1;
-					info_data = addr->inst_right->inst_left;
-				}
-				if (info_type == MONO_PATCH_INFO_ICALL_ADDR) {
-					tailcall = FALSE;
-					ins = (MonoInst*)mini_emit_abs_call (cfg, MONO_PATCH_INFO_ICALL_ADDR_CALL, info_data, fsig, sp);
-					NULLIFY_INS (addr);
-					goto calli_end;
-				} else if (info_type == MONO_PATCH_INFO_JIT_ICALL_ADDR
-						|| info_type == MONO_PATCH_INFO_SPECIFIC_TRAMPOLINE_LAZY_FETCH_ADDR) {
-					tailcall = FALSE;
-					ins = (MonoInst*)mini_emit_abs_call (cfg, info_type, info_data, fsig, sp);
-					NULLIFY_INS (addr);
-					goto calli_end;
-				}
-			}
-			/* Some wrappers use calli with ftndesc-es */
-			if (cfg->llvm_only && !(cfg->method->wrapper_type &&
-									cfg->method->wrapper_type != MONO_WRAPPER_DYNAMIC_METHOD &&
-									cfg->method->wrapper_type != MONO_WRAPPER_DELEGATE_INVOKE))
-				ins = mini_emit_llvmonly_calli (cfg, fsig, sp, addr);
-			else
-				ins = (MonoInst*)mini_emit_calli_full (cfg, fsig, sp, addr, NULL, NULL, tailcall);
-			goto calli_end;
-		}
-		case MONO_CEE_CALL:
-		case MONO_CEE_CALLVIRT: {
-			MonoInst *addr; addr = NULL;
-			int array_rank; array_rank = 0;
-			gboolean virtual_; virtual_ = il_op == MONO_CEE_CALLVIRT;
-			gboolean pass_imt_from_rgctx; pass_imt_from_rgctx = FALSE;
-			MonoInst *imt_arg; imt_arg = NULL;
-			gboolean pass_mrgctx; pass_mrgctx = FALSE;
-			MonoInst *vtable_arg; vtable_arg = NULL;
-			gboolean check_this; check_this = FALSE;
-			gboolean delegate_invoke; delegate_invoke = FALSE;
-			gboolean direct_icall; direct_icall = FALSE;
-			gboolean tailcall_calli; tailcall_calli = FALSE;
-			gboolean noreturn; noreturn = FALSE;
-			gboolean gshared_static_virtual; gshared_static_virtual = FALSE;
-#ifdef TARGET_WASM
-			gboolean needs_stack_walk; needs_stack_walk = FALSE;
-#endif
-			common_call = FALSE;
-			gboolean called_is_supported_tailcall; called_is_supported_tailcall = FALSE;
-			MonoMethod *tailcall_method; tailcall_method = NULL;
-			MonoMethod *tailcall_cmethod; tailcall_cmethod = NULL;
-			MonoMethodSignature *tailcall_fsig; tailcall_fsig = NULL;
-			gboolean tailcall_virtual; tailcall_virtual = FALSE;
-			gboolean tailcall_extra_arg; tailcall_extra_arg = FALSE;
-			gboolean inst_tailcall; inst_tailcall = G_UNLIKELY (debug_tailcall_try_all
-							? (next_ip < end && next_ip [0] == CEE_RET)
-							: ((ins_flag & MONO_INST_TAILCALL) != 0));
-			gboolean make_generic_call_out_of_gsharedvt_method = FALSE;
-			gboolean will_have_imt_arg = FALSE;
-			ins = NULL;
-			/* Used to pass arguments to called functions */
-			HandleCallData cdata;
-			memset (&cdata, 0, sizeof (HandleCallData));
-			if (cmethod_override) {
-				cmethod = cmethod_override;
-				cmethod_override = NULL;
-				virtual_ = FALSE;
-			} else {
-				cmethod = mini_get_method (cfg, method, token, NULL, generic_context);
-			}
-			CHECK_CFG_ERROR;
-			if (cfg->verbose_level > 3)
-				printf ("cmethod = %s\n", mono_method_get_full_name (cmethod));
-			MonoMethod *cil_method; cil_method = cmethod;
-			if (constrained_class) {
-				if (m_method_is_static (cil_method) && mini_class_check_context_used (cfg, constrained_class)) {
-					/* get_constrained_method () doesn't work on the gparams used by generic sharing */
-					gshared_static_virtual = TRUE;
-					if (!cfg->gsharedvt)
-						/*
-						 * We can't resolve these calls at compile time, and they are used in
-						 * perf-sensitive code in the BCL, so ask the AOT compiler to try to use specific instances
-						 * instead of this gshared method.
-						 */
-						cfg->prefer_instances = TRUE;
-				} else {
-					cmethod = get_constrained_method (cfg, image, token, cil_method, constrained_class, generic_context);
-					CHECK_CFG_ERROR;
-					if (mono_class_has_dim_conflicts (constrained_class) &&
-							mono_class_is_method_ambiguous (constrained_class, cil_method))
-						mono_emit_jit_icall (cfg, mono_throw_ambiguous_implementation, NULL);
-					if (m_class_is_enumtype (constrained_class) && !strcmp (cmethod->name, "GetHashCode")) {
-						/* Use the corresponding method from the base type to avoid boxing */
-						MonoType *base_type = mono_class_enum_basetype_internal (constrained_class);
-						g_assert (base_type);
-						constrained_class = mono_class_from_mono_type_internal (base_type);
-						cmethod = get_method_nofail (constrained_class, cmethod->name, 0, 0);
-						g_assert (cmethod);
-					}
-				}
-			}
-			if (!dont_verify && !cfg->skip_visibility) {
-				MonoMethod *target_method = cil_method;
-				if (method->is_inflated) {
-					MonoGenericContainer *container = mono_method_get_generic_container(method_definition);
-					MonoGenericContext *context = (container != NULL ? &container->context : NULL);
-					target_method = mini_get_method_allow_open (method, token, NULL, context, cfg->error);
-					CHECK_CFG_ERROR;
-				}
-				if (!mono_method_can_access_method (method_definition, target_method) &&
-					!mono_method_can_access_method (method, cil_method))
-					emit_method_access_failure (cfg, method, cil_method);
-			}
-			if (cfg->llvm_only && cmethod && method_needs_stack_walk (cfg, cmethod)) {
-				if (cfg->interp && !cfg->interp_entry_only) {
-					/* Use the interpreter instead */
-					cfg->exception_message = g_strdup ("stack walk");
-					cfg->disable_llvm = TRUE;
-				}
-#ifdef TARGET_WASM
-				else {
-					needs_stack_walk = TRUE;
-				}
-#endif
-			}
-			if (!virtual_ && (cmethod->flags & METHOD_ATTRIBUTE_ABSTRACT) && !gshared_static_virtual) {
-				if (!mono_class_is_interface (method->klass))
-					emit_bad_image_failure (cfg, method, cil_method);
-				else
-					virtual_ = TRUE;
-			}
-			if (!m_class_is_inited (cmethod->klass))
-				if (!mono_class_init_internal (cmethod->klass))
-					TYPE_LOAD_ERROR (cmethod->klass);
-			fsig = mono_method_signature_internal (cmethod);
-			if (!fsig)
-				LOAD_ERROR;
-			if (cmethod->iflags & METHOD_IMPL_ATTRIBUTE_INTERNAL_CALL &&
-				mini_class_is_system_array (cmethod->klass)) {
-				array_rank = m_class_get_rank (cmethod->klass);
-			} else if ((cmethod->iflags & METHOD_IMPL_ATTRIBUTE_INTERNAL_CALL) && direct_icalls_enabled (cfg, cmethod)) {
-				direct_icall = TRUE;
-			} else if (fsig->pinvoke) {
-				if (cmethod->flags & METHOD_ATTRIBUTE_PINVOKE_IMPL) {
-					/*
-					 * Avoid calling mono_marshal_get_native_wrapper () too early, it might call managed
-					 * callbacks on netcore.
-					 */
-					fsig = mono_metadata_signature_dup_mempool (cfg->mempool, fsig);
-					fsig->pinvoke = FALSE;
-				} else {
-					MonoMethod *wrapper = mono_marshal_get_native_wrapper (cmethod, TRUE, cfg->compile_aot);
-					fsig = mono_method_signature_internal (wrapper);
-				}
-			} else if (constrained_class) {
-			} else {
-				fsig = mono_method_get_signature_checked (cmethod, image, token, generic_context, cfg->error);
-				CHECK_CFG_ERROR;
-			}
-			if (cfg->llvm_only && !cfg->method->wrapper_type && (!cmethod || cmethod->is_inflated))
-				cfg->signatures = g_slist_prepend_mempool (cfg->mempool, cfg->signatures, fsig);
-			if (cfg->gsharedvt_min && mini_is_gsharedvt_variable_signature (fsig))
-				GSHAREDVT_FAILURE (il_op);
-			/* See code below */
-			if (cmethod->klass == mono_defaults.monitor_class && !strcmp (cmethod->name, "Enter") && mono_method_signature_internal (cmethod)->param_count == 1) {
-				MonoBasicBlock *tbb;
-				GET_BBLOCK (cfg, tbb, next_ip);
-				if (tbb->try_start && MONO_REGION_FLAGS(tbb->region) == MONO_EXCEPTION_CLAUSE_FINALLY) {
-					/*
-					 * We want to extend the try block to cover the call, but we can't do it if the
-					 * call is made directly since its followed by an exception check.
-					 */
-					direct_icall = FALSE;
-				}
-			}
-			mono_save_token_info (cfg, image, token, cil_method);
-			if (!(seq_point_locs && mono_bitset_test_fast (seq_point_locs, next_ip - header->code)))
-				need_seq_point = TRUE;
-			/* Don't support calls made using type arguments for now */
-			/*
-			  if (cfg->gsharedvt) {
-			  if (mini_is_gsharedvt_signature (fsig))
-			  GSHAREDVT_FAILURE (il_op);
-			  }
-			*/
-			if (cmethod->string_ctor && method->wrapper_type != MONO_WRAPPER_RUNTIME_INVOKE)
-				g_assert_not_reached ();
-			n = fsig->param_count + fsig->hasthis;
-			if (!cfg->gshared && mono_class_is_gtd (cmethod->klass))
-				UNVERIFIED;
-			if (!cfg->gshared)
-				g_assertf (!mono_method_check_context_used (cmethod), "cmethod is %s", mono_method_get_full_name (cmethod));
-			CHECK_STACK (n);
-			sp -= n;
-			if (virtual_ && cmethod && sp [0] && sp [0]->opcode == OP_TYPED_OBJREF) {
-				error_init_reuse (error);
-				MonoMethod *new_cmethod = mono_class_get_virtual_method (sp [0]->klass, cmethod, error);
-				if (is_ok (error)) {
-					cmethod = new_cmethod;
-					virtual_ = FALSE;
-				} else {
-					mono_error_cleanup (error);
-				}
-			}
-			if (cmethod && method_does_not_return (cmethod)) {
-				cfg->cbb->out_of_line = TRUE;
-				noreturn = TRUE;
-			}
-			cdata.method = method;
-			cdata.inst_tailcall = inst_tailcall;
-			/*
-			 * We have the `constrained.' prefix opcode.
-			 */
-			if (constrained_class) {
-				ins = handle_constrained_call (cfg, cmethod, fsig, constrained_class, sp, &cdata, &cmethod, &virtual_, &emit_widen);
-				CHECK_CFG_EXCEPTION;
-				if (!gshared_static_virtual)
-					constrained_class = NULL;
-				if (ins)
-					goto call_end;
-			}
-			for (int i = 0; i < fsig->param_count; ++i)
-				sp [i + fsig->hasthis] = convert_value (cfg, fsig->params [i], sp [i + fsig->hasthis]);
-			if (check_call_signature (cfg, fsig, sp)) {
-				if (break_on_unverified ())
-					check_call_signature (cfg, fsig, sp); // Again, step through it.
-				UNVERIFIED;
-			}
-			if ((m_class_get_parent (cmethod->klass) == mono_defaults.multicastdelegate_class) && !strcmp (cmethod->name, "Invoke"))
-				delegate_invoke = TRUE;
-			/*
-			 * Implement a workaround for the inherent races involved in locking:
-			 * Monitor.Enter ()
-			 * try {
-			 * } finally {
-			 *    Monitor.Exit ()
-			 * }
-			 * If a thread abort happens between the call to Monitor.Enter () and the start of the
-			 * try block, the Exit () won't be executed, see:
-			 * http://www.bluebytesoftware.com/blog/2007/01/30/MonitorEnterThreadAbortsAndOrphanedLocks.aspx
-			 * To work around this, we extend such try blocks to include the last x bytes
-			 * of the Monitor.Enter () call.
-			 */
-			if (cmethod->klass == mono_defaults.monitor_class && !strcmp (cmethod->name, "Enter") && mono_method_signature_internal (cmethod)->param_count == 1) {
-				MonoBasicBlock *tbb;
-				GET_BBLOCK (cfg, tbb, next_ip);
-				/*
-				 * Only extend try blocks with a finally, to avoid catching exceptions thrown
-				 * from Monitor.Enter like ArgumentNullException.
-				 */
-				if (tbb->try_start && MONO_REGION_FLAGS(tbb->region) == MONO_EXCEPTION_CLAUSE_FINALLY) {
-					/* Mark this bblock as needing to be extended */
-					tbb->extend_try_block = TRUE;
-				}
-			}
-			/* Conversion to a JIT intrinsic */
-			gboolean ins_type_initialized;
-			if ((ins = mini_emit_inst_for_method (cfg, cmethod, fsig, sp, &ins_type_initialized))) {
-				if (!MONO_TYPE_IS_VOID (fsig->ret)) {
-					if (!ins_type_initialized)
-						mini_type_to_eval_stack_type ((cfg), fsig->ret, ins);
-					emit_widen = FALSE;
-				}
-				if (inst_tailcall) // FIXME
-					mono_tailcall_print ("missed tailcall intrins %s -> %s\n", method->name, cmethod->name);
-				goto call_end;
-			}
-			CHECK_CFG_ERROR;
-			/*
-			 * If the callee is a shared method, then its static cctor
-			 * might not get called after the call was patched.
-			 */
-			if (cfg->gshared && cmethod->klass != method->klass && mono_class_is_ginst (cmethod->klass) && mono_method_is_generic_sharable (cmethod, TRUE) && mono_class_needs_cctor_run (cmethod->klass, method)) {
-				emit_class_init (cfg, cmethod->klass, FALSE);
-				CHECK_TYPELOAD (cmethod->klass);
-			}
-			/* Inlining */
-			if ((cfg->opt & MONO_OPT_INLINE) && !inst_tailcall && !gshared_static_virtual &&
-				(!virtual_ || !(cmethod->flags & METHOD_ATTRIBUTE_VIRTUAL) || MONO_METHOD_IS_FINAL (cmethod)) &&
-			    mono_method_check_inlining (cfg, cmethod)) {
-				int costs;
-				gboolean always = FALSE;
-				gboolean is_empty = FALSE;
-				if (cmethod->iflags & METHOD_IMPL_ATTRIBUTE_INTERNAL_CALL) {
-					/* Prevent inlining of methods that call wrappers */
-					INLINE_FAILURE ("wrapper call");
-					cmethod = mono_marshal_get_native_wrapper (cmethod, TRUE, FALSE);
-					always = TRUE;
-				}
-				costs = inline_method (cfg, cmethod, fsig, sp, ip, cfg->real_offset, always, &is_empty);
-				if (costs) {
-					cfg->real_offset += 5;
-					if (!MONO_TYPE_IS_VOID (fsig->ret))
-						/* *sp is already set by inline_method */
-						ins = *sp;
-					inline_costs += costs;
-					if (inst_tailcall) // FIXME
-						mono_tailcall_print ("missed tailcall inline %s -> %s\n", method->name, cmethod->name);
-					if (is_empty)
-						ins_has_side_effect = FALSE;
-					goto call_end;
-				}
-			}
-			pass_mrgctx = need_mrgctx_arg (cfg, cmethod);
-			if (cfg->gshared) {
-				MonoGenericContext *cmethod_context = mono_method_get_context (cmethod);
-				context_used = mini_method_check_context_used (cfg, cmethod);
-				if (!context_used && gshared_static_virtual)
-					context_used = mini_class_check_context_used (cfg, constrained_class);
-				if (context_used && mono_class_is_interface (cmethod->klass) && !m_method_is_static (cmethod)) {
-					/* Generic method interface
-					   calls are resolved via a
-					   helper function and don't
-					   need an imt. */
-					if (!cmethod_context || !cmethod_context->method_inst)
-						pass_imt_from_rgctx = TRUE;
-				}
-				/*
-				 * If a shared method calls another
-				 * shared method then the caller must
-				 * have a generic sharing context
-				 * because the magic trampoline
-				 * requires it.  FIXME: We shouldn't
-				 * have to force the vtable/mrgctx
-				 * variable here.  Instead there
-				 * should be a flag in the cfg to
-				 * request a generic sharing context.
-				 */
-				if (context_used &&
-				    ((cfg->method->flags & METHOD_ATTRIBUTE_STATIC) || m_class_is_valuetype (cfg->method->klass)))
-					mono_get_vtable_var (cfg);
-			}
-			if (pass_mrgctx) {
-				g_assert (!vtable_arg);
-				if (!cfg->compile_aot) {
-					/*
-					 * emit_get_rgctx_method () calls mono_class_vtable () so check
-					 * for type load errors before.
-					 */
-					mono_class_setup_vtable (cmethod->klass);
-					CHECK_TYPELOAD (cmethod->klass);
-				}
-				vtable_arg = emit_get_rgctx_method (cfg, context_used, cmethod, MONO_RGCTX_INFO_METHOD_RGCTX);
-				if ((!(cmethod->flags & METHOD_ATTRIBUTE_VIRTUAL) || MONO_METHOD_IS_FINAL (cmethod)) && !delegate_invoke) {
-					if (virtual_)
-						check_this = TRUE;
-					virtual_ = FALSE;
-				}
-			}
-			if (pass_imt_from_rgctx) {
-				imt_arg = emit_get_rgctx_method (cfg, context_used,
-					cmethod, MONO_RGCTX_INFO_METHOD);
-				g_assert (imt_arg);
-			}
-			if (check_this)
-				MONO_EMIT_NEW_CHECK_THIS (cfg, sp [0]->dreg);
-			/* Calling virtual generic methods */
-			gboolean virtual_generic; virtual_generic = FALSE;
-			gboolean virtual_generic_imt; virtual_generic_imt = FALSE;
-			if (virtual_ && (cmethod->flags & METHOD_ATTRIBUTE_VIRTUAL) &&
-			    !MONO_METHOD_IS_FINAL (cmethod) &&
-			    fsig->generic_param_count &&
-				!(cfg->gsharedvt && mini_is_gsharedvt_signature (fsig)) &&
-				!cfg->llvm_only) {
-				g_assert (fsig->is_inflated);
-				virtual_generic = TRUE;
-				/* Prevent inlining of methods that contain indirect calls */
-				INLINE_FAILURE ("virtual generic call");
-				if (cfg->gsharedvt && mini_is_gsharedvt_signature (fsig))
-					GSHAREDVT_FAILURE (il_op);
-				if (cfg->backend->have_generalized_imt_trampoline && cfg->backend->gshared_supported && cmethod->wrapper_type == MONO_WRAPPER_NONE) {
-					virtual_generic_imt = TRUE;
-					g_assert (!imt_arg);
-					if (!context_used)
-						g_assert (cmethod->is_inflated);
-					imt_arg = emit_get_rgctx_method (cfg, context_used, cmethod, MONO_RGCTX_INFO_METHOD);
-					g_assert (imt_arg);
-					virtual_ = TRUE;
-					vtable_arg = NULL;
-				}
-			}
-			/*
-			 * Making generic calls out of gsharedvt methods.
-			 * This needs to be used for all generic calls, not just ones with a gsharedvt signature, to avoid
-			 * patching gshared method addresses into a gsharedvt method.
-			 */
-			if (cfg->gsharedvt && (mini_is_gsharedvt_signature (fsig) || cmethod->is_inflated || mono_class_is_ginst (cmethod->klass)) &&
-				!(m_class_get_rank (cmethod->klass) && m_class_get_byval_arg (cmethod->klass)->type != MONO_TYPE_SZARRAY) &&
-				(!(cfg->llvm_only && virtual_ && (cmethod->flags & METHOD_ATTRIBUTE_VIRTUAL)))) {
-				make_generic_call_out_of_gsharedvt_method = TRUE;
-				if (virtual_) {
-					if (fsig->generic_param_count) {
-						will_have_imt_arg = TRUE;
-					} else if (mono_class_is_interface (cmethod->klass) && !imt_arg) {
-						will_have_imt_arg = TRUE;
-					}
-				}
-			}
-			/* Tail prefix / tailcall optimization */
-			/* FIXME: Enabling TAILC breaks some inlining/stack trace/etc tests.
-				  Inlining and stack traces are not guaranteed however. */
-			/* FIXME: runtime generic context pointer for jumps? */
-			/* FIXME: handle this for generic sharing eventually */
-			tailcall_extra_arg = vtable_arg || imt_arg || will_have_imt_arg || mono_class_is_interface (cmethod->klass);
-			tailcall = inst_tailcall && is_supported_tailcall (cfg, ip, method, cmethod, fsig,
-						virtual_, tailcall_extra_arg, &tailcall_calli);
-			called_is_supported_tailcall = TRUE;
-			tailcall_method = method;
-			tailcall_cmethod = cmethod;
-			tailcall_fsig = fsig;
-			tailcall_virtual = virtual_;
-			if (virtual_generic) {
-				if (virtual_generic_imt) {
-					if (tailcall) {
-						/* Prevent inlining of methods with tailcalls (the call stack would be altered) */
-						INLINE_FAILURE ("tailcall");
-					}
-					common_call = TRUE;
-					goto call_end;
-				}
-				MonoInst *this_temp, *this_arg_temp, *store;
-				MonoInst *iargs [4];
-				this_temp = mono_compile_create_var (cfg, type_from_stack_type (sp [0]), OP_LOCAL);
-				NEW_TEMPSTORE (cfg, store, this_temp->inst_c0, sp [0]);
-				MONO_ADD_INS (cfg->cbb, store);
-				/* FIXME: This should be a managed pointer */
-				this_arg_temp = mono_compile_create_var (cfg, mono_get_int_type (), OP_LOCAL);
-				EMIT_NEW_TEMPLOAD (cfg, iargs [0], this_temp->inst_c0);
-				iargs [1] = emit_get_rgctx_method (cfg, context_used, cmethod, MONO_RGCTX_INFO_METHOD);
-				EMIT_NEW_TEMPLOADA (cfg, iargs [2], this_arg_temp->inst_c0);
-				addr = mono_emit_jit_icall (cfg, mono_helper_compile_generic_method, iargs);
-				EMIT_NEW_TEMPLOAD (cfg, sp [0], this_arg_temp->inst_c0);
-				ins = (MonoInst*)mini_emit_calli (cfg, fsig, sp, addr, NULL, NULL);
-				if (inst_tailcall) // FIXME
-					mono_tailcall_print ("missed tailcall virtual generic %s -> %s\n", method->name, cmethod->name);
-				goto call_end;
-			}
-			CHECK_CFG_ERROR;
-			/* Tail recursion elimination */
-			if (((cfg->opt & MONO_OPT_TAILCALL) || inst_tailcall) && il_op == MONO_CEE_CALL && cmethod == method && next_ip < end && next_ip [0] == CEE_RET && !vtable_arg) {
-				gboolean has_vtargs = FALSE;
-				int i;
-				/* Prevent inlining of methods with tailcalls (the call stack would be altered) */
-				INLINE_FAILURE ("tailcall");
-				/* keep it simple */
-				for (i = fsig->param_count - 1; !has_vtargs && i >= 0; i--)
-					has_vtargs = MONO_TYPE_ISSTRUCT (mono_method_signature_internal (cmethod)->params [i]);
-				if (!has_vtargs) {
-					if (need_seq_point) {
-						emit_seq_point (cfg, method, ip, FALSE, TRUE);
-						need_seq_point = FALSE;
-					}
-					for (i = 0; i < n; ++i)
-						EMIT_NEW_ARGSTORE (cfg, ins, i, sp [i]);
-					mini_profiler_emit_tail_call (cfg, cmethod);
-					MONO_INST_NEW (cfg, ins, OP_BR);
-					MONO_ADD_INS (cfg->cbb, ins);
-					tblock = start_bblock->out_bb [0];
-					link_bblock (cfg, cfg->cbb, tblock);
-					ins->inst_target_bb = tblock;
-					start_new_bblock = 1;
-					/* skip the CEE_RET, too */
-					if (ip_in_bb (cfg, cfg->cbb, next_ip))
-						skip_ret = TRUE;
-					push_res = FALSE;
-					need_seq_point = FALSE;
-					goto call_end;
-				}
-			}
-			inline_costs += CALL_COST * MIN(10, num_calls++);
-			/*
-			 * Synchronized wrappers.
-			 * Its hard to determine where to replace a method with its synchronized
-			 * wrapper without causing an infinite recursion. The current solution is
-			 * to add the synchronized wrapper in the trampolines, and to
-			 * change the called method to a dummy wrapper, and resolve that wrapper
-			 * to the real method in mono_jit_compile_method ().
-			 */
-			if (cfg->method->wrapper_type == MONO_WRAPPER_SYNCHRONIZED) {
-				MonoMethod *orig = mono_marshal_method_from_wrapper (cfg->method);
-				if (cmethod == orig || (cmethod->is_inflated && mono_method_get_declaring_generic_method (cmethod) == orig)) {
-					cmethod = mono_marshal_get_synchronized_inner_wrapper (cmethod);
-				}
-			}
-			/*
-			 * Making generic calls out of gsharedvt methods.
-			 * This needs to be used for all generic calls, not just ones with a gsharedvt signature, to avoid
-			 * patching gshared method addresses into a gsharedvt method.
-			 */
-			if (make_generic_call_out_of_gsharedvt_method) {
-				if (virtual_) {
-					if (fsig->hasthis && method->klass == mono_defaults.object_class)
-						GSHAREDVT_FAILURE (il_op);
-					if (fsig->generic_param_count) {
-						/* virtual generic call */
-						g_assert (!imt_arg);
-						g_assert (will_have_imt_arg);
-						/* Same as the virtual generic case above */
-						imt_arg = emit_get_rgctx_method (cfg, context_used,
-														 cmethod, MONO_RGCTX_INFO_METHOD);
-						g_assert (imt_arg);
-					} else if (mono_class_is_interface (cmethod->klass) && !imt_arg) {
-						/* This can happen when we call a fully instantiated iface method */
-						g_assert (will_have_imt_arg);
-						imt_arg = emit_get_rgctx_method (cfg, context_used,
-														 cmethod, MONO_RGCTX_INFO_METHOD);
-						g_assert (imt_arg);
-					}
-					/* This is not needed, as the trampoline code will pass one, and it might be passed in the same reg as the imt arg */
-					vtable_arg = NULL;
-				}
-				if ((m_class_get_parent (cmethod->klass) == mono_defaults.multicastdelegate_class) && (!strcmp (cmethod->name, "Invoke")))
-					keep_this_alive = sp [0];
-				MonoRgctxInfoType info_type;
-				if (virtual_ && (cmethod->flags & METHOD_ATTRIBUTE_VIRTUAL))
-					info_type = MONO_RGCTX_INFO_METHOD_GSHAREDVT_OUT_TRAMPOLINE_VIRT;
-				else
-					info_type = MONO_RGCTX_INFO_METHOD_GSHAREDVT_OUT_TRAMPOLINE;
-				addr = emit_get_rgctx_gsharedvt_call (cfg, context_used, fsig, cmethod, info_type);
-				if (cfg->llvm_only) {
-					ins = mini_emit_llvmonly_calli (cfg, fsig, sp, addr);
-					if (inst_tailcall) // FIXME
-						mono_tailcall_print ("missed tailcall llvmonly gsharedvt %s -> %s\n", method->name, cmethod->name);
-				} else {
-					tailcall = tailcall_calli;
-					ins = (MonoInst*)mini_emit_calli_full (cfg, fsig, sp, addr, imt_arg, vtable_arg, tailcall);
-					tailcall_remove_ret |= tailcall;
-				}
-				goto call_end;
-			}
-			/* Generic sharing */
-			/*
-			 * Calls to generic methods from shared code cannot go through the trampoline infrastructure
-			 * in some cases, because the called method might end up being different on every call.
-			 * Load the called method address from the rgctx and do an indirect call in these cases.
-			 * Use this if the callee is gsharedvt sharable too, since
-			 * at runtime we might find an instantiation so the call cannot
-			 * be patched (the 'no_patch' code path in mini-trampolines.c).
-			 */
-			gboolean gshared_indirect;
-			gshared_indirect = context_used && !imt_arg && !array_rank && !delegate_invoke;
-			if (gshared_indirect)
-				gshared_indirect = (!mono_method_is_generic_sharable_full (cmethod, TRUE, FALSE, FALSE) ||
-									!mono_class_generic_sharing_enabled (cmethod->klass) ||
-									gshared_static_virtual);
-			if (gshared_indirect)
-				gshared_indirect = (!virtual_ || MONO_METHOD_IS_FINAL (cmethod) ||
-									!(cmethod->flags & METHOD_ATTRIBUTE_VIRTUAL));
-			if (gshared_indirect) {
-				INLINE_FAILURE ("gshared");
-				g_assert (cfg->gshared && cmethod);
-				g_assert (!addr);
-				if (fsig->hasthis)
-					MONO_EMIT_NEW_CHECK_THIS (cfg, sp [0]->dreg);
-				if (cfg->llvm_only) {
-					if (cfg->gsharedvt && mini_is_gsharedvt_variable_signature (fsig)) {
-						/* Handled in handle_constrained_gsharedvt_call () */
-						g_assert (!gshared_static_virtual);
-						addr = emit_get_rgctx_method (cfg, context_used, cmethod, MONO_RGCTX_INFO_GSHAREDVT_OUT_WRAPPER);
-					} else {
-						if (gshared_static_virtual)
-							addr = emit_get_rgctx_virt_method (cfg, -1, constrained_class, cmethod, MONO_RGCTX_INFO_VIRT_METHOD_CODE);
-						else
-							addr = emit_get_rgctx_method (cfg, context_used, cmethod, MONO_RGCTX_INFO_METHOD_FTNDESC);
-					}
-					ins = mini_emit_llvmonly_calli (cfg, fsig, sp, addr);
-					if (inst_tailcall) // FIXME
-						mono_tailcall_print ("missed tailcall context_used_llvmonly %s -> %s\n", method->name, cmethod->name);
-				} else {
-					if (gshared_static_virtual) {
-						/*
-						 * cmethod is a static interface method, the actual called method at runtime
-						 * needs to be computed using constrained_class and cmethod.
-						 */
-						addr = emit_get_rgctx_virt_method (cfg, -1, constrained_class, cmethod, MONO_RGCTX_INFO_VIRT_METHOD_CODE);
-					} else {
-						addr = emit_get_rgctx_method (cfg, context_used, cmethod, MONO_RGCTX_INFO_GENERIC_METHOD_CODE);
-					}
-					if (inst_tailcall)
-						mono_tailcall_print ("%s tailcall_calli#2 %s -> %s\n", tailcall_calli ? "making" : "missed", method->name, cmethod->name);
-					tailcall = tailcall_calli;
-					ins = (MonoInst*)mini_emit_calli_full (cfg, fsig, sp, addr, imt_arg, vtable_arg, tailcall);
-					tailcall_remove_ret |= tailcall;
-				}
-				goto call_end;
-			}
-			/* Direct calls to icalls */
-			if (direct_icall) {
-				MonoMethod *wrapper;
-				int costs;
-				/* Inline the wrapper */
-				wrapper = mono_marshal_get_native_wrapper (cmethod, TRUE, cfg->compile_aot);
-				costs = inline_method (cfg, wrapper, fsig, sp, ip, cfg->real_offset, TRUE, NULL);
-				g_assert (costs > 0);
-				cfg->real_offset += 5;
-				if (!MONO_TYPE_IS_VOID (fsig->ret))
-					/* *sp is already set by inline_method */
-					ins = *sp;
-				inline_costs += costs;
-				if (inst_tailcall) // FIXME
-					mono_tailcall_print ("missed tailcall direct_icall %s -> %s\n", method->name, cmethod->name);
-				goto call_end;
-			}
-			/* Array methods */
-			if (array_rank) {
-				MonoInst *ldelema_addr;
-				if (strcmp (cmethod->name, "Set") == 0) { /* array Set */
-					MonoInst *val = sp [fsig->param_count];
-					if (val->type == STACK_OBJ) {
-						MonoInst *iargs [ ] = { sp [0], val };
-						mono_emit_jit_icall (cfg, mono_helper_stelem_ref_check, iargs);
-					}
-					ldelema_addr = mini_emit_ldelema_ins (cfg, cmethod, sp, ip, TRUE);
-					if (!mini_debug_options.weak_memory_model && val->type == STACK_OBJ)
-						mini_emit_memory_barrier (cfg, MONO_MEMORY_BARRIER_REL);
-					EMIT_NEW_STORE_MEMBASE_TYPE (cfg, ins, fsig->params [fsig->param_count - 1], ldelema_addr->dreg, 0, val->dreg);
-					if (cfg->gen_write_barriers && val->type == STACK_OBJ && !MONO_INS_IS_PCONST_NULL (val))
-						mini_emit_write_barrier (cfg, ldelema_addr, val);
-					if (cfg->gen_write_barriers && mini_is_gsharedvt_klass (cmethod->klass))
-						GSHAREDVT_FAILURE (il_op);
-				} else if (strcmp (cmethod->name, "Get") == 0) { /* array Get */
-					ldelema_addr = mini_emit_ldelema_ins (cfg, cmethod, sp, ip, FALSE);
-					EMIT_NEW_LOAD_MEMBASE_TYPE (cfg, ins, fsig->ret, ldelema_addr->dreg, 0);
-				} else if (strcmp (cmethod->name, "Address") == 0) { /* array Address */
-					if (!m_class_is_valuetype (m_class_get_element_class (cmethod->klass)) && !readonly)
-						mini_emit_check_array_type (cfg, sp [0], cmethod->klass);
-					CHECK_TYPELOAD (cmethod->klass);
-					readonly = FALSE;
-					ldelema_addr = mini_emit_ldelema_ins (cfg, cmethod, sp, ip, FALSE);
-					ins = ldelema_addr;
-				} else {
-					g_assert_not_reached ();
-				}
-				emit_widen = FALSE;
-				if (inst_tailcall) // FIXME
-					mono_tailcall_print ("missed tailcall array_rank %s -> %s\n", method->name, cmethod->name);
-				goto call_end;
-			}
-			ins = mini_redirect_call (cfg, cmethod, fsig, sp, virtual_ ? sp [0] : NULL);
-			if (ins) {
-				if (inst_tailcall) // FIXME
-					mono_tailcall_print ("missed tailcall redirect %s -> %s\n", method->name, cmethod->name);
-				goto call_end;
-			}
-			/* Tail prefix / tailcall optimization */
-			if (tailcall) {
-				/* Prevent inlining of methods with tailcalls (the call stack would be altered) */
-				INLINE_FAILURE ("tailcall");
-			}
-			/*
-			 * Virtual calls in llvm-only mode.
-			 */
-			if (cfg->llvm_only && virtual_ && cmethod && (cmethod->flags & METHOD_ATTRIBUTE_VIRTUAL)) {
-				ins = mini_emit_llvmonly_virtual_call (cfg, cmethod, fsig, context_used, sp);
-				goto call_end;
-			}
-			/* Common call */
-			if (!(cfg->opt & MONO_OPT_AGGRESSIVE_INLINING) && !(method->iflags & METHOD_IMPL_ATTRIBUTE_AGGRESSIVE_INLINING) && !(cmethod->iflags & METHOD_IMPL_ATTRIBUTE_AGGRESSIVE_INLINING) && !method_does_not_return (cmethod))
-				INLINE_FAILURE ("call");
-			common_call = TRUE;
-#ifdef TARGET_WASM
-			/* Push an LMF so these frames can be enumerated during stack walks by mono_arch_unwind_frame () */
-			if (needs_stack_walk && !cfg->deopt) {
-				MonoInst *method_ins;
-				int lmf_reg;
-				emit_push_lmf (cfg);
-				EMIT_NEW_VARLOADA (cfg, ins, cfg->lmf_var, NULL);
-				lmf_reg = ins->dreg;
-				/* The lmf->method field will be used to look up the MonoJitInfo for this method */
-				method_ins = emit_get_rgctx_method (cfg, mono_method_check_context_used (cfg->method), cfg->method, MONO_RGCTX_INFO_METHOD);
-				EMIT_NEW_STORE_MEMBASE (cfg, ins, OP_STORE_MEMBASE_REG, lmf_reg, MONO_STRUCT_OFFSET (MonoLMF, method), method_ins->dreg);
-			}
-#endif
-call_end:
-			g_assert (!called_is_supported_tailcall || tailcall_method == method);
-			g_assert (!called_is_supported_tailcall || !tailcall || tailcall_cmethod == cmethod);
-			g_assert (!called_is_supported_tailcall || tailcall_fsig == fsig);
-			g_assert (!called_is_supported_tailcall || tailcall_virtual == virtual_);
-			if (common_call) // FIXME goto call_end && !common_call often skips tailcall processing.
-				ins = mini_emit_method_call_full (cfg, cmethod, fsig, tailcall, sp, virtual_ ? sp [0] : NULL,
-												  imt_arg, vtable_arg);
-			/*
-			 * Handle devirt of some A.B.C calls by replacing the result of A.B with a OP_TYPED_OBJREF instruction, so the .C
-			 * call can be devirtualized above.
-			 */
-			if (cmethod)
-				ins = handle_call_res_devirt (cfg, cmethod, ins);
-#ifdef TARGET_WASM
-			if (common_call && needs_stack_walk && !cfg->deopt)
-				emit_pop_lmf (cfg);
-#endif
-			if (noreturn) {
-				MONO_INST_NEW (cfg, ins, OP_NOT_REACHED);
-				MONO_ADD_INS (cfg->cbb, ins);
-			}
-calli_end:
-			if ((tailcall_remove_ret || (common_call && tailcall)) && !cfg->llvm_only) {
-				link_bblock (cfg, cfg->cbb, end_bblock);
-				start_new_bblock = 1;
-				/*
-				 * OP_TAILCALL has no return value, so skip the CEE_RET if it is
-				 * only reachable from this call.
-				 */
-				GET_BBLOCK (cfg, tblock, next_ip);
-				if (tblock == cfg->cbb || tblock->in_count == 0)
-					skip_ret = TRUE;
-				push_res = FALSE;
-				need_seq_point = FALSE;
-			}
-			if (ins_flag & MONO_INST_TAILCALL)
-				mini_test_tailcall (cfg, tailcall);
-			/* End of call, INS should contain the result of the call, if any */
-			if (push_res && !MONO_TYPE_IS_VOID (fsig->ret)) {
-				g_assert (ins);
-				if (emit_widen)
-					*sp++ = mono_emit_widen_call_res (cfg, ins, fsig);
-				else
-					*sp++ = ins;
-			}
-			if (save_last_error) {
-				save_last_error = FALSE;
-#ifdef TARGET_WIN32
-				MONO_INST_NEW (cfg, ins, OP_GET_LAST_ERROR);
-				ins->dreg = alloc_dreg (cfg, STACK_I4);
-				ins->type = STACK_I4;
-				MONO_ADD_INS (cfg->cbb, ins);
-				mono_emit_jit_icall (cfg, mono_marshal_set_last_error_windows, &ins);
-#else
-				mono_emit_jit_icall (cfg, mono_marshal_set_last_error, NULL);
-#endif
-			}
-			if (keep_this_alive) {
-				MonoInst *dummy_use;
-				/* See mini_emit_method_call_full () */
-				EMIT_NEW_DUMMY_USE (cfg, dummy_use, keep_this_alive);
-			}
-			if (cfg->llvm_only && cmethod && method_needs_stack_walk (cfg, cmethod)) {
-				/*
-				 * Clang can convert these calls to tailcalls which screw up the stack
-				 * walk. This happens even when the -fno-optimize-sibling-calls
-				 * option is passed to clang.
-				 * Work around this by emitting a dummy call.
-				 */
-				mono_emit_jit_icall (cfg, mono_dummy_jit_icall, NULL);
-			}
-			CHECK_CFG_EXCEPTION;
-			if (skip_ret) {
-				g_assert (next_ip [0] == CEE_RET);
-				next_ip += 1;
-				il_op = MonoOpcodeEnum_Invalid; // Call or ret? Unclear.
-			}
-			ins_flag = 0;
-			constrained_class = NULL;
-			if (need_seq_point) {
-				if (!(method->flags & METHOD_IMPL_ATTRIBUTE_NATIVE)) {
-					if (emitted_funccall_seq_point) {
-						if (cfg->last_seq_point)
-							cfg->last_seq_point->flags |= MONO_INST_NESTED_CALL;
-					}
-					else
-						emitted_funccall_seq_point = TRUE;
-				}
-				emit_seq_point (cfg, method, next_ip, FALSE, TRUE);
-			}
-			break;
-		}
-		case MONO_CEE_RET:
-			if (!detached_before_ret)
-				mini_profiler_emit_leave (cfg, sig->ret->type != MONO_TYPE_VOID ? sp [-1] : NULL);
-			g_assert (!method_does_not_return (method));
-			if (cfg->method != method) {
-				/* return from inlined method */
-				/*
-				 * If in_count == 0, that means the ret is unreachable due to
-				 * being preceded by a throw. In that case, inline_method () will
-				 * handle setting the return value
-				 * (test case: test_0_inline_throw ()).
-				 */
-				if (return_var && cfg->cbb->in_count) {
-					MonoType *ret_type = mono_method_signature_internal (method)->ret;
-					MonoInst *store;
-					CHECK_STACK (1);
-					--sp;
-					*sp = convert_value (cfg, ret_type, *sp);
-					if ((method->wrapper_type == MONO_WRAPPER_DYNAMIC_METHOD || method->wrapper_type == MONO_WRAPPER_NONE) && target_type_is_incompatible (cfg, ret_type, *sp))
-						UNVERIFIED;
-					EMIT_NEW_TEMPSTORE (cfg, store, return_var->inst_c0, *sp);
-					cfg->ret_var_set = TRUE;
-				}
-			} else {
-				if (cfg->lmf_var && cfg->cbb->in_count && (!cfg->llvm_only || cfg->deopt))
-					emit_pop_lmf (cfg);
-				if (cfg->ret) {
-					MonoType *ret_type = mini_get_underlying_type (mono_method_signature_internal (method)->ret);
-					if (seq_points && !sym_seq_points) {
-						/*
-						 * Place a seq point here too even through the IL stack is not
-						 * empty, so a step over on
-						 * call <FOO>
-						 * ret
-						 * will work correctly.
-						 */
-						NEW_SEQ_POINT (cfg, ins, GPTRDIFF_TO_TMREG (ip - header->code), TRUE);
-						MONO_ADD_INS (cfg->cbb, ins);
-					}
-					g_assert (!return_var);
-					CHECK_STACK (1);
-					--sp;
-					*sp = convert_value (cfg, ret_type, *sp);
-					if ((method->wrapper_type == MONO_WRAPPER_DYNAMIC_METHOD || method->wrapper_type == MONO_WRAPPER_NONE) && target_type_is_incompatible (cfg, ret_type, *sp))
-						UNVERIFIED;
-					emit_setret (cfg, *sp);
-				}
-			}
-			if (sp != stack_start)
-				UNVERIFIED;
-			MONO_INST_NEW (cfg, ins, OP_BR);
-			ins->inst_target_bb = end_bblock;
-			MONO_ADD_INS (cfg->cbb, ins);
-			link_bblock (cfg, cfg->cbb, end_bblock);
-			start_new_bblock = 1;
-			break;
-		case MONO_CEE_BR_S:
-			MONO_INST_NEW (cfg, ins, OP_BR);
-			GET_BBLOCK (cfg, tblock, target);
-			link_bblock (cfg, cfg->cbb, tblock);
-			ins->inst_target_bb = tblock;
-			if (sp != stack_start) {
-				handle_stack_args (cfg, stack_start, GPTRDIFF_TO_INT (sp - stack_start));
-				sp = stack_start;
-				CHECK_UNVERIFIABLE (cfg);
-			}
-			MONO_ADD_INS (cfg->cbb, ins);
-			start_new_bblock = 1;
-			inline_costs += BRANCH_COST;
-			break;
-		case MONO_CEE_BEQ_S:
-		case MONO_CEE_BGE_S:
-		case MONO_CEE_BGT_S:
-		case MONO_CEE_BLE_S:
-		case MONO_CEE_BLT_S:
-		case MONO_CEE_BNE_UN_S:
-		case MONO_CEE_BGE_UN_S:
-		case MONO_CEE_BGT_UN_S:
-		case MONO_CEE_BLE_UN_S:
-		case MONO_CEE_BLT_UN_S:
-			MONO_INST_NEW (cfg, ins, il_op + BIG_BRANCH_OFFSET);
-			ADD_BINCOND (NULL);
-			sp = stack_start;
-			inline_costs += BRANCH_COST;
-			break;
-		case MONO_CEE_BR:
-			MONO_INST_NEW (cfg, ins, OP_BR);
-			GET_BBLOCK (cfg, tblock, target);
-			link_bblock (cfg, cfg->cbb, tblock);
-			ins->inst_target_bb = tblock;
-			if (sp != stack_start) {
-				handle_stack_args (cfg, stack_start, GPTRDIFF_TO_INT (sp - stack_start));
-				sp = stack_start;
-				CHECK_UNVERIFIABLE (cfg);
-			}
-			MONO_ADD_INS (cfg->cbb, ins);
-			start_new_bblock = 1;
-			inline_costs += BRANCH_COST;
-			break;
-		case MONO_CEE_BRFALSE_S:
-		case MONO_CEE_BRTRUE_S:
-		case MONO_CEE_BRFALSE:
-		case MONO_CEE_BRTRUE: {
-			MonoInst *cmp;
-			gboolean is_true = il_op == MONO_CEE_BRTRUE_S || il_op == MONO_CEE_BRTRUE;
-			if (sp [-1]->type == STACK_VTYPE || sp [-1]->type == STACK_R8)
-				UNVERIFIED;
-			sp--;
-			GET_BBLOCK (cfg, tblock, target);
-			link_bblock (cfg, cfg->cbb, tblock);
-			GET_BBLOCK (cfg, tblock, next_ip);
-			link_bblock (cfg, cfg->cbb, tblock);
-			if (sp != stack_start) {
-				handle_stack_args (cfg, stack_start, GPTRDIFF_TO_INT (sp - stack_start));
-				CHECK_UNVERIFIABLE (cfg);
-			}
-			MONO_INST_NEW(cfg, cmp, OP_ICOMPARE_IMM);
-			cmp->sreg1 = sp [0]->dreg;
-			type_from_op (cfg, cmp, sp [0], NULL);
-			CHECK_TYPE (cmp);
-#if SIZEOF_REGISTER == 4
-			if (cmp->opcode == OP_LCOMPARE_IMM) {
-				/* Convert it to OP_LCOMPARE */
-				MONO_INST_NEW (cfg, ins, OP_I8CONST);
-				ins->type = STACK_I8;
-				ins->dreg = alloc_dreg (cfg, STACK_I8);
-				ins->inst_l = 0;
-				MONO_ADD_INS (cfg->cbb, ins);
-				cmp->opcode = OP_LCOMPARE;
-				cmp->sreg2 = ins->dreg;
-			}
-#endif
-			MONO_ADD_INS (cfg->cbb, cmp);
-			MONO_INST_NEW (cfg, ins, is_true ? CEE_BNE_UN : CEE_BEQ);
-			type_from_op (cfg, ins, sp [0], NULL);
-			MONO_ADD_INS (cfg->cbb, ins);
-			ins->inst_many_bb = (MonoBasicBlock **)mono_mempool_alloc (cfg->mempool, sizeof (gpointer) * 2);
-			GET_BBLOCK (cfg, tblock, target);
-			ins->inst_true_bb = tblock;
-			GET_BBLOCK (cfg, tblock, next_ip);
-			ins->inst_false_bb = tblock;
-			start_new_bblock = 2;
-			sp = stack_start;
-			inline_costs += BRANCH_COST;
-			break;
-		}
-		case MONO_CEE_BEQ:
-		case MONO_CEE_BGE:
-		case MONO_CEE_BGT:
-		case MONO_CEE_BLE:
-		case MONO_CEE_BLT:
-		case MONO_CEE_BNE_UN:
-		case MONO_CEE_BGE_UN:
-		case MONO_CEE_BGT_UN:
-		case MONO_CEE_BLE_UN:
-		case MONO_CEE_BLT_UN:
-			MONO_INST_NEW (cfg, ins, il_op);
-			ADD_BINCOND (NULL);
-			sp = stack_start;
-			inline_costs += BRANCH_COST;
-			break;
-		case MONO_CEE_SWITCH: {
-			MonoInst *src1;
-			MonoBasicBlock **targets;
-			MonoBasicBlock *default_bblock;
-			MonoJumpInfoBBTable *table;
-			int offset_reg = alloc_preg (cfg);
-			int target_reg = alloc_preg (cfg);
-			int table_reg = alloc_preg (cfg);
-			int sum_reg = alloc_preg (cfg);
-			gboolean use_op_switch;
-			n = read32 (ip + 1);
-			--sp;
-			src1 = sp [0];
-			if ((src1->type != STACK_I4) && (src1->type != STACK_PTR))
-				UNVERIFIED;
-			ip += 5;
-			GET_BBLOCK (cfg, default_bblock, next_ip);
-			default_bblock->flags |= BB_INDIRECT_JUMP_TARGET;
-			targets = (MonoBasicBlock **)mono_mempool_alloc (cfg->mempool, sizeof (MonoBasicBlock*) * n);
-			for (int i = 0; i < n; ++i) {
-				GET_BBLOCK (cfg, tblock, next_ip + (gint32)read32 (ip));
-				targets [i] = tblock;
-				targets [i]->flags |= BB_INDIRECT_JUMP_TARGET;
-				ip += 4;
-			}
-			if (sp != stack_start) {
-				/*
-				 * Link the current bb with the targets as well, so handle_stack_args
-				 * will set their in_stack correctly.
-				 */
-				link_bblock (cfg, cfg->cbb, default_bblock);
-				for (int i = 0; i < n; ++i)
-					link_bblock (cfg, cfg->cbb, targets [i]);
-				handle_stack_args (cfg, stack_start, GPTRDIFF_TO_INT (sp - stack_start));
-				sp = stack_start;
-				CHECK_UNVERIFIABLE (cfg);
-				/* Undo the links */
-				mono_unlink_bblock (cfg, cfg->cbb, default_bblock);
-				for (int i = 0; i < n; ++i)
-					mono_unlink_bblock (cfg, cfg->cbb, targets [i]);
-			}
-			MONO_EMIT_NEW_BIALU_IMM (cfg, OP_ICOMPARE_IMM, -1, src1->dreg, n);
-			MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_IBGE_UN, default_bblock);
-			for (int i = 0; i < n; ++i)
-				link_bblock (cfg, cfg->cbb, targets [i]);
-			table = (MonoJumpInfoBBTable *)mono_mempool_alloc (cfg->mempool, sizeof (MonoJumpInfoBBTable));
-			table->table = targets;
-			table->table_size = n;
-			use_op_switch = FALSE;
-#ifdef TARGET_ARM
-			/* ARM implements SWITCH statements differently */
-			/* FIXME: Make it use the generic implementation */
-			if (!cfg->compile_aot)
-				use_op_switch = TRUE;
-#endif
-			if (COMPILE_LLVM (cfg))
-				use_op_switch = TRUE;
-			cfg->cbb->has_jump_table = 1;
-			if (use_op_switch) {
-				MONO_INST_NEW (cfg, ins, OP_SWITCH);
-				ins->sreg1 = src1->dreg;
-				ins->inst_p0 = table;
-				ins->inst_many_bb = targets;
-				ins->klass = (MonoClass *)GUINT_TO_POINTER (n);
-				MONO_ADD_INS (cfg->cbb, ins);
-			} else {
-				if (TARGET_SIZEOF_VOID_P == 8)
-					MONO_EMIT_NEW_BIALU_IMM (cfg, OP_SHL_IMM, offset_reg, src1->dreg, 3);
-				else
-					MONO_EMIT_NEW_BIALU_IMM (cfg, OP_SHL_IMM, offset_reg, src1->dreg, 2);
-#if SIZEOF_REGISTER == 8
-				/* The upper word might not be zero, and we add it to a 64 bit address later */
-				MONO_EMIT_NEW_UNALU (cfg, OP_ZEXT_I4, offset_reg, offset_reg);
-#endif
-				if (cfg->compile_aot) {
-					MONO_EMIT_NEW_AOTCONST (cfg, table_reg, table, MONO_PATCH_INFO_SWITCH);
-				} else {
-					MONO_INST_NEW (cfg, ins, OP_JUMP_TABLE);
-					ins->inst_c1 = MONO_PATCH_INFO_SWITCH;
-					ins->inst_p0 = table;
-					ins->dreg = table_reg;
-					MONO_ADD_INS (cfg->cbb, ins);
-				}
-				/* FIXME: Use load_memindex */
-				MONO_EMIT_NEW_BIALU (cfg, OP_PADD, sum_reg, table_reg, offset_reg);
-				MONO_EMIT_NEW_LOAD_MEMBASE (cfg, target_reg, sum_reg, 0);
-				MONO_EMIT_NEW_UNALU (cfg, OP_BR_REG, -1, target_reg);
-			}
-			start_new_bblock = 1;
-			inline_costs += BRANCH_COST * 2;
-			break;
-		}
-		case MONO_CEE_LDIND_I1:
-		case MONO_CEE_LDIND_U1:
-		case MONO_CEE_LDIND_I2:
-		case MONO_CEE_LDIND_U2:
-		case MONO_CEE_LDIND_I4:
-		case MONO_CEE_LDIND_U4:
-		case MONO_CEE_LDIND_I8:
-		case MONO_CEE_LDIND_I:
-		case MONO_CEE_LDIND_R4:
-		case MONO_CEE_LDIND_R8:
-		case MONO_CEE_LDIND_REF:
-			--sp;
-			if (!(ins_flag & MONO_INST_NONULLCHECK))
-				MONO_EMIT_NULL_CHECK (cfg, sp [0]->dreg, FALSE);
-			ins = mini_emit_memory_load (cfg, m_class_get_byval_arg (ldind_to_type (il_op)), sp [0], 0, ins_flag);
-			*sp++ = ins;
-			ins_flag = 0;
-			break;
-		case MONO_CEE_STIND_REF:
-		case MONO_CEE_STIND_I1:
-		case MONO_CEE_STIND_I2:
-		case MONO_CEE_STIND_I4:
-		case MONO_CEE_STIND_I8:
-		case MONO_CEE_STIND_R4:
-		case MONO_CEE_STIND_R8:
-		case MONO_CEE_STIND_I: {
-			sp -= 2;
-			if (il_op == MONO_CEE_STIND_REF && sp [1]->type != STACK_OBJ) {
-				/* stind.ref must only be used with object references. */
-				UNVERIFIED;
-			}
-			if (il_op == MONO_CEE_STIND_R4 && sp [1]->type == STACK_R8)
-				sp [1] = convert_value (cfg, m_class_get_byval_arg (mono_defaults.single_class), sp [1]);
-			mini_emit_memory_store (cfg, m_class_get_byval_arg (stind_to_type (il_op)), sp [0], sp [1], ins_flag);
-			ins_flag = 0;
-			inline_costs += 1;
-			break;
-		}
-		case MONO_CEE_MUL: {
-			MONO_INST_NEW (cfg, ins, il_op);
-			sp -= 2;
-			ins->sreg1 = sp [0]->dreg;
-			ins->sreg2 = sp [1]->dreg;
-			type_from_op (cfg, ins, sp [0], sp [1]);
-			CHECK_TYPE (ins);
-			if (((sp [0]->type == STACK_R4 && sp [1]->type == STACK_R8) ||
-			     (sp [0]->type == STACK_R8 && sp [1]->type == STACK_R4)))
-				add_widen_op (cfg, ins, &sp [0], &sp [1]);
-			ins->dreg = alloc_dreg ((cfg), (MonoStackType)(ins)->type);
-			/* Use the immediate opcodes if possible */
-			int imm_opcode; imm_opcode = mono_op_to_op_imm_noemul (ins->opcode);
-			if ((sp [1]->opcode == OP_ICONST) && mono_arch_is_inst_imm (ins->opcode, imm_opcode, sp [1]->inst_c0)) {
-				if (imm_opcode != -1) {
-					ins->opcode = GINT_TO_OPCODE (imm_opcode);
-					ins->inst_p1 = (gpointer)(gssize)(sp [1]->inst_c0);
-					ins->sreg2 = -1;
-					NULLIFY_INS (sp [1]);
-				}
-			}
-			MONO_ADD_INS ((cfg)->cbb, (ins));
-			*sp++ = mono_decompose_opcode (cfg, ins);
-			break;
-		}
-		case MONO_CEE_ADD:
-		case MONO_CEE_SUB:
-		case MONO_CEE_DIV:
-		case MONO_CEE_DIV_UN:
-		case MONO_CEE_REM:
-		case MONO_CEE_REM_UN:
-		case MONO_CEE_AND:
-		case MONO_CEE_OR:
-		case MONO_CEE_XOR:
-		case MONO_CEE_SHL:
-		case MONO_CEE_SHR:
-		case MONO_CEE_SHR_UN: {
-			MONO_INST_NEW (cfg, ins, il_op);
-			sp -= 2;
-			ins->sreg1 = sp [0]->dreg;
-			ins->sreg2 = sp [1]->dreg;
-			type_from_op (cfg, ins, sp [0], sp [1]);
-			CHECK_TYPE (ins);
-			add_widen_op (cfg, ins, &sp [0], &sp [1]);
-			ins->dreg = alloc_dreg ((cfg), (MonoStackType)(ins)->type);
-			/* Use the immediate opcodes if possible */
-			int imm_opcode; imm_opcode = mono_op_to_op_imm_noemul (ins->opcode);
-			if (((sp [1]->opcode == OP_ICONST) || (sp [1]->opcode == OP_I8CONST)) &&
-			    mono_arch_is_inst_imm (ins->opcode, imm_opcode, sp [1]->opcode == OP_ICONST ? sp [1]->inst_c0 : sp [1]->inst_l)) {
-				if (imm_opcode != -1) {
-					ins->opcode = GINT_TO_OPCODE (imm_opcode);
-					if (sp [1]->opcode == OP_I8CONST) {
-#if SIZEOF_REGISTER == 8
-						ins->inst_imm = sp [1]->inst_l;
-#else
-						ins->inst_l = sp [1]->inst_l;
-#endif
-					} else {
-						ins->inst_imm = (gssize)(sp [1]->inst_c0);
-					}
-					ins->sreg2 = -1;
-					/* Might be followed by an instruction added by add_widen_op */
-					if (sp [1]->next == NULL)
-						NULLIFY_INS (sp [1]);
-				}
-			}
-			MONO_ADD_INS ((cfg)->cbb, (ins));
-			*sp++ = mono_decompose_opcode (cfg, ins);
-			break;
-		}
-		case MONO_CEE_NEG:
-		case MONO_CEE_NOT:
-		case MONO_CEE_CONV_I1:
-		case MONO_CEE_CONV_I2:
-		case MONO_CEE_CONV_I4:
-		case MONO_CEE_CONV_R4:
-		case MONO_CEE_CONV_R8:
-		case MONO_CEE_CONV_U4:
-		case MONO_CEE_CONV_I8:
-		case MONO_CEE_CONV_U8:
-		case MONO_CEE_CONV_OVF_I8:
-		case MONO_CEE_CONV_OVF_U8:
-		case MONO_CEE_CONV_R_UN:
-			/* Special case this earlier so we have long constants in the IR */
-			if ((il_op == MONO_CEE_CONV_I8 || il_op == MONO_CEE_CONV_U8) && (sp [-1]->opcode == OP_ICONST)) {
-				int data = GTMREG_TO_INT (sp [-1]->inst_c0);
-				sp [-1]->opcode = OP_I8CONST;
-				sp [-1]->type = STACK_I8;
-#if SIZEOF_REGISTER == 8
-				if (il_op == MONO_CEE_CONV_U8)
-					sp [-1]->inst_c0 = (guint32)data;
-				else
-					sp [-1]->inst_c0 = data;
-#else
-				if (il_op == MONO_CEE_CONV_U8)
-					sp [-1]->inst_l = (guint32)data;
-				else
-					sp [-1]->inst_l = data;
-#endif
-				sp [-1]->dreg = alloc_dreg (cfg, STACK_I8);
-			}
-			else {
-				ADD_UNOP (il_op);
-			}
-			break;
-		case MONO_CEE_CONV_OVF_I4:
-		case MONO_CEE_CONV_OVF_I1:
-		case MONO_CEE_CONV_OVF_I2:
-		case MONO_CEE_CONV_OVF_I:
-		case MONO_CEE_CONV_OVF_I1_UN:
-		case MONO_CEE_CONV_OVF_I2_UN:
-		case MONO_CEE_CONV_OVF_I4_UN:
-		case MONO_CEE_CONV_OVF_I8_UN:
-		case MONO_CEE_CONV_OVF_I_UN:
-			if (sp [-1]->type == STACK_R8 || sp [-1]->type == STACK_R4) {
-				/* floats are always signed, _UN has no effect */
-				ADD_UNOP (CEE_CONV_OVF_I8);
-				if (il_op == MONO_CEE_CONV_OVF_I1_UN)
-					ADD_UNOP (MONO_CEE_CONV_OVF_I1);
-				else if (il_op == MONO_CEE_CONV_OVF_I2_UN)
-					ADD_UNOP (MONO_CEE_CONV_OVF_I2);
-				else if (il_op == MONO_CEE_CONV_OVF_I4_UN)
-					ADD_UNOP (MONO_CEE_CONV_OVF_I4);
-				else if (il_op == MONO_CEE_CONV_OVF_I8_UN)
-					;
-				else
-					ADD_UNOP (il_op);
-			} else {
-				ADD_UNOP (il_op);
-			}
-			break;
-		case MONO_CEE_CONV_OVF_U1:
-		case MONO_CEE_CONV_OVF_U2:
-		case MONO_CEE_CONV_OVF_U4:
-		case MONO_CEE_CONV_OVF_U:
-		case MONO_CEE_CONV_OVF_U1_UN:
-		case MONO_CEE_CONV_OVF_U2_UN:
-		case MONO_CEE_CONV_OVF_U4_UN:
-		case MONO_CEE_CONV_OVF_U8_UN:
-		case MONO_CEE_CONV_OVF_U_UN:
-			if (sp [-1]->type == STACK_R8 || sp [-1]->type == STACK_R4) {
-				/* floats are always signed, _UN has no effect */
-				ADD_UNOP (CEE_CONV_OVF_U8);
-				if (TARGET_SIZEOF_VOID_P == 8 && il_op == MONO_CEE_CONV_OVF_U)
-					sp [-1]->type = STACK_PTR; // no additional conversion needed
-				else
-					ADD_UNOP (il_op);
-			} else {
-				ADD_UNOP (il_op);
-			}
-			break;
-		case MONO_CEE_CONV_U2:
-		case MONO_CEE_CONV_U1:
-		case MONO_CEE_CONV_U:
-		case MONO_CEE_CONV_I:
-			ADD_UNOP (il_op);
-			CHECK_CFG_EXCEPTION;
-			break;
-		case MONO_CEE_ADD_OVF:
-		case MONO_CEE_ADD_OVF_UN:
-		case MONO_CEE_MUL_OVF:
-		case MONO_CEE_MUL_OVF_UN:
-		case MONO_CEE_SUB_OVF:
-		case MONO_CEE_SUB_OVF_UN:
-			MONO_INST_NEW (cfg, ins, il_op);
-			sp -= 2;
-			ins->sreg1 = sp [0]->dreg;
-			ins->sreg2 = sp [1]->dreg;
-			type_from_op (cfg, ins, sp [0], sp [1]);
-			CHECK_TYPE (ins);
-			if (ovf_exc)
-				ins->inst_exc_name = ovf_exc;
-			else
-				ins->inst_exc_name = "OverflowException";
-			/* Have to insert a widening op */
-			add_widen_op (cfg, ins, &sp [0], &sp [1]);
-			ins->dreg = alloc_dreg (cfg, (MonoStackType)(ins)->type);
-			MONO_ADD_INS ((cfg)->cbb, ins);
-			/* The opcode might be emulated, so need to special case this */
-			if (ovf_exc && mono_find_jit_opcode_emulation (ins->opcode)) {
-				switch (ins->opcode) {
-				case OP_IMUL_OVF_UN:
-					/* This opcode is just a placeholder, it will be emulated also */
-					ins->opcode = OP_IMUL_OVF_UN_OOM;
-					break;
-				case OP_LMUL_OVF_UN:
-					/* This opcode is just a placeholder, it will be emulated also */
-					ins->opcode = OP_LMUL_OVF_UN_OOM;
-					break;
-				default:
-					g_assert_not_reached ();
-				}
-			}
-			ovf_exc = NULL;
-			*sp++ = mono_decompose_opcode (cfg, ins);
-			break;
-		case MONO_CEE_CPOBJ:
-			GSHAREDVT_FAILURE (il_op);
-			GSHAREDVT_FAILURE (*ip);
-			klass = mini_get_class (method, token, generic_context);
-			CHECK_TYPELOAD (klass);
-			sp -= 2;
-			mini_emit_memory_copy (cfg, sp [0], sp [1], klass, FALSE, ins_flag);
-			ins_flag = 0;
-			break;
-		case MONO_CEE_LDOBJ: {
-			int loc_index = -1;
-			int stloc_len = 0;
-			--sp;
-			klass = mini_get_class (method, token, generic_context);
-			CHECK_TYPELOAD (klass);
-			/* Optimize the common ldobj+stloc combination */
-			if (next_ip < end) {
-				switch (next_ip [0]) {
-				case MONO_CEE_STLOC_S:
-					CHECK_OPSIZE (7);
-					loc_index = next_ip [1];
-					stloc_len = 2;
-					break;
-				case MONO_CEE_STLOC_0:
-				case MONO_CEE_STLOC_1:
-				case MONO_CEE_STLOC_2:
-				case MONO_CEE_STLOC_3:
-					loc_index = next_ip [0] - CEE_STLOC_0;
-					stloc_len = 1;
-					break;
-				default:
-					break;
-				}
-			}
-			if ((loc_index != -1) && ip_in_bb (cfg, cfg->cbb, next_ip)) {
-				CHECK_LOCAL (loc_index);
-				EMIT_NEW_LOAD_MEMBASE_TYPE (cfg, ins, m_class_get_byval_arg (klass), sp [0]->dreg, 0);
-				ins->dreg = cfg->locals [loc_index]->dreg;
-				ins->flags |= ins_flag;
-				il_op = (MonoOpcodeEnum)next_ip [0];
-				next_ip += stloc_len;
-				if (ins_flag & MONO_INST_VOLATILE) {
-					/* Volatile loads have acquire semantics, see 12.6.7 in Ecma 335 */
-					mini_emit_memory_barrier (cfg, MONO_MEMORY_BARRIER_ACQ);
-				}
-				ins_flag = 0;
-				break;
-			}
-			/* Optimize the ldobj+stobj combination */
-			if (next_ip + 4 < end && next_ip [0] == CEE_STOBJ && ip_in_bb (cfg, cfg->cbb, next_ip) && read32 (next_ip + 1) == token) {
-				CHECK_STACK (1);
-				sp --;
-				mini_emit_memory_copy (cfg, sp [0], sp [1], klass, FALSE, ins_flag);
-				il_op = (MonoOpcodeEnum)next_ip [0];
-				next_ip += 5;
-				ins_flag = 0;
-				break;
-			}
-			if (!(ins_flag & MONO_INST_NONULLCHECK))
-				MONO_EMIT_NULL_CHECK (cfg, sp [0]->dreg, FALSE);
-			ins = mini_emit_memory_load (cfg, m_class_get_byval_arg (klass), sp [0], 0, ins_flag);
-			*sp++ = ins;
-			ins_flag = 0;
-			inline_costs += 1;
-			break;
-		}
-		case MONO_CEE_LDSTR:
-			if (method->wrapper_type == MONO_WRAPPER_DYNAMIC_METHOD) {
-				EMIT_NEW_PCONST (cfg, ins, mono_method_get_wrapper_data (method, n));
-				ins->type = STACK_OBJ;
-				*sp = ins;
-			}
-			else if (method->wrapper_type != MONO_WRAPPER_NONE) {
-				MonoInst *iargs [1];
-				char *str = (char *)mono_method_get_wrapper_data (method, n);
-				if (cfg->compile_aot)
-					EMIT_NEW_LDSTRLITCONST (cfg, iargs [0], str);
-				else
-					EMIT_NEW_PCONST (cfg, iargs [0], str);
-				*sp = mono_emit_jit_icall (cfg, mono_string_new_wrapper_internal, iargs);
-			} else {
-				{
-					if (cfg->cbb->out_of_line) {
-						MonoInst *iargs [2];
-						if (image == mono_defaults.corlib) {
-							/*
-							 * Avoid relocations in AOT and save some space by using a
-							 * version of helper_ldstr specialized to mscorlib.
-							 */
-							EMIT_NEW_ICONST (cfg, iargs [0], mono_metadata_token_index (n));
-							*sp = mono_emit_jit_icall (cfg, mono_helper_ldstr_mscorlib, iargs);
-						} else {
-							/* Avoid creating the string object */
-							EMIT_NEW_IMAGECONST (cfg, iargs [0], image);
-							EMIT_NEW_ICONST (cfg, iargs [1], mono_metadata_token_index (n));
-							*sp = mono_emit_jit_icall (cfg, mono_helper_ldstr, iargs);
-						}
-					}
-					else
-					if (cfg->compile_aot) {
-						NEW_LDSTRCONST (cfg, ins, image, n);
-						*sp = ins;
-						MONO_ADD_INS (cfg->cbb, ins);
-					}
-					else {
-						NEW_PCONST (cfg, ins, NULL);
-						ins->type = STACK_OBJ;
-						ins->inst_p0 = mono_ldstr_checked (image, mono_metadata_token_index (n), cfg->error);
-						CHECK_CFG_ERROR;
-						if (!ins->inst_p0)
-							OUT_OF_MEMORY_FAILURE;
-						*sp = ins;
-						MONO_ADD_INS (cfg->cbb, ins);
-					}
-				}
-			}
-			sp++;
-			break;
-		case MONO_CEE_NEWOBJ: {
-			MonoInst *iargs [2];
-			MonoInst this_ins;
-			MonoInst *alloc;
-			MonoInst *vtable_arg = NULL;
-			cmethod = mini_get_method (cfg, method, token, NULL, generic_context);
-			CHECK_CFG_ERROR;
-			fsig = mono_method_get_signature_checked (cmethod, image, token, generic_context, cfg->error);
-			CHECK_CFG_ERROR;
-			mono_save_token_info (cfg, image, token, cmethod);
-			if (mono_class_has_failure (cmethod->klass) || !mono_class_init_internal (cmethod->klass))
-				TYPE_LOAD_ERROR (cmethod->klass);
-			context_used = mini_method_check_context_used (cfg, cmethod);
-			if (!dont_verify && !cfg->skip_visibility) {
-				MonoMethod *cil_method = cmethod;
-				MonoMethod *target_method = cil_method;
-				if (method->is_inflated) {
-					MonoGenericContainer *container = mono_method_get_generic_container(method_definition);
-					MonoGenericContext *context = (container != NULL ? &container->context : NULL);
-					target_method = mini_get_method_allow_open (method, token, NULL, context, cfg->error);
-					CHECK_CFG_ERROR;
-				}
-				if (!mono_method_can_access_method (method_definition, target_method) &&
-					!mono_method_can_access_method (method, cil_method))
-					emit_method_access_failure (cfg, method, cil_method);
-			}
-			if (cfg->gshared && cmethod && cmethod->klass != method->klass && mono_class_is_ginst (cmethod->klass) && mono_method_is_generic_sharable (cmethod, TRUE) && mono_class_needs_cctor_run (cmethod->klass, method)) {
-				emit_class_init (cfg, cmethod->klass, FALSE);
-				CHECK_TYPELOAD (cmethod->klass);
-			}
-			/*
-			if (cfg->gsharedvt) {
-				if (mini_is_gsharedvt_variable_signature (sig))
-					GSHAREDVT_FAILURE (il_op);
-			}
-			*/
-			n = fsig->param_count;
-			CHECK_STACK (n);
-			if (cfg->gsharedvt_min && mini_is_gsharedvt_variable_signature (fsig))
-				GSHAREDVT_FAILURE (il_op);
-			/*
-			 * Generate smaller code for the common newobj <exception> instruction in
-			 * argument checking code.
-			 */
-			if (cfg->cbb->out_of_line && m_class_get_image (cmethod->klass) == mono_defaults.corlib &&
-				is_exception_class (cmethod->klass) && n <= 2 &&
-			    ((n < 1) || (!m_type_is_byref (fsig->params [0]) && fsig->params [0]->type == MONO_TYPE_STRING)) &&
-			    ((n < 2) || (!m_type_is_byref (fsig->params [1]) && fsig->params [1]->type == MONO_TYPE_STRING))) {
-				MonoInst *ex_iargs [3];
-				sp -= n;
-				EMIT_NEW_ICONST (cfg, ex_iargs [0], m_class_get_type_token (cmethod->klass));
-				switch (n) {
-				case 0:
-					*sp ++ = mono_emit_jit_icall (cfg, mono_create_corlib_exception_0, ex_iargs);
-					break;
-				case 1:
-					ex_iargs [1] = sp [0];
-					*sp ++ = mono_emit_jit_icall (cfg, mono_create_corlib_exception_1, ex_iargs);
-					break;
-				case 2:
-					ex_iargs [1] = sp [0];
-					ex_iargs [2] = sp [1];
-					*sp ++ = mono_emit_jit_icall (cfg, mono_create_corlib_exception_2, ex_iargs);
-					break;
-				default:
-					g_assert_not_reached ();
-				}
-				inline_costs += 5;
-				break;
-			}
-			/* move the args to allow room for 'this' in the first position */
-			while (n--) {
-				--sp;
-				sp [1] = sp [0];
-			}
-			for (int i = 0; i < fsig->param_count; ++i)
-				sp [i + fsig->hasthis] = convert_value (cfg, fsig->params [i], sp [i + fsig->hasthis]);
-			/* check_call_signature () requires sp[0] to be set */
-			this_ins.type = STACK_OBJ;
-			sp [0] = &this_ins;
-			if (check_call_signature (cfg, fsig, sp))
-				UNVERIFIED;
-			iargs [0] = NULL;
-			if (mini_class_is_system_array (cmethod->klass)) {
-				*sp = emit_get_rgctx_method (cfg, context_used,
-											 cmethod, MONO_RGCTX_INFO_METHOD);
-				MonoJitICallId function = MONO_JIT_ICALL_ZeroIsReserved;
-				int rank = m_class_get_rank (cmethod->klass);
-				int param_count = fsig->param_count;
-				/* Optimize the common cases, use ctor using length for each rank (no lbound). */
-				if (param_count == rank) {
-					switch (param_count) {
-					case 1: function = MONO_JIT_ICALL_mono_array_new_1;
-						break;
-					case 2: function = MONO_JIT_ICALL_mono_array_new_2;
-						break;
-					case 3: function = MONO_JIT_ICALL_mono_array_new_3;
-						break;
-					case 4: function = MONO_JIT_ICALL_mono_array_new_4;
-						break;
-					default:
-						break;
-					}
-				}
-				/* Regular case, rank > 4 or legnth, lbound specified per rank. */
-				if (function == MONO_JIT_ICALL_ZeroIsReserved) {
-					if  (!array_new_localalloc_ins) {
-						MONO_INST_NEW (cfg, array_new_localalloc_ins, OP_LOCALLOC_IMM);
-						array_new_localalloc_ins->dreg = alloc_preg (cfg);
-						cfg->flags |= MONO_CFG_HAS_ALLOCA;
-						MONO_ADD_INS (init_localsbb, array_new_localalloc_ins);
-					}
-					array_new_localalloc_ins->inst_imm = MAX (array_new_localalloc_ins->inst_imm, param_count * GUINT_TO_INT(sizeof (target_mgreg_t)));
-					int dreg = array_new_localalloc_ins->dreg;
-					if (2 * rank == param_count) {
-						/* [lbound, length, lbound, length, ...]
-						 * mono_array_new_n_icall expects a non-interleaved list of
-						 * lbounds and lengths, so deinterleave here.
-						 */
-						for (int l = 0; l < 2; ++l) {
-							int src = l;
-							int dst = l * rank;
-							for (int r = 0; r < rank; ++r, src += 2, ++dst) {
-								NEW_STORE_MEMBASE (cfg, ins, OP_STORE_MEMBASE_REG, dreg, dst * sizeof (target_mgreg_t), sp [src + 1]->dreg);
-								MONO_ADD_INS (cfg->cbb, ins);
-							}
-						}
-					} else {
-						/* [length, length, length, ...] */
-						for (int i = 0; i < param_count; ++i) {
-							NEW_STORE_MEMBASE (cfg, ins, OP_STORE_MEMBASE_REG, dreg, i * sizeof (target_mgreg_t), sp [i + 1]->dreg);
-							MONO_ADD_INS (cfg->cbb, ins);
-						}
-					}
-					EMIT_NEW_ICONST (cfg, ins, param_count);
-					sp [1] = ins;
-					EMIT_NEW_UNALU (cfg, ins, OP_MOVE, alloc_preg (cfg), dreg);
-					ins->type = STACK_PTR;
-					sp [2] = ins;
-					function = MONO_JIT_ICALL_mono_array_new_n_icall;
-				}
-				alloc = mono_emit_jit_icall_id (cfg, function, sp);
-			} else if (cmethod->string_ctor) {
-				g_assert (!context_used);
-				g_assert (!vtable_arg);
-				/* we simply pass a null pointer */
-				EMIT_NEW_PCONST (cfg, *sp, NULL);
-				/* now call the string ctor */
-				alloc = mini_emit_method_call_full (cfg, cmethod, fsig, FALSE, sp, NULL, NULL, NULL);
-			} else {
-				if (m_class_is_valuetype (cmethod->klass)) {
-					iargs [0] = mono_compile_create_var (cfg, m_class_get_byval_arg (cmethod->klass), OP_LOCAL);
-					mini_emit_init_rvar (cfg, iargs [0]->dreg, m_class_get_byval_arg (cmethod->klass));
-					EMIT_NEW_TEMPLOADA (cfg, *sp, iargs [0]->inst_c0);
-					alloc = NULL;
-					/*
-					 * The code generated by mini_emit_virtual_call () expects
-					 * iargs [0] to be a boxed instance, but luckily the vcall
-					 * will be transformed into a normal call there.
-					 */
-				} else if (context_used) {
-					alloc = handle_alloc (cfg, cmethod->klass, FALSE, context_used);
-					*sp = alloc;
-				} else {
-					MonoVTable *vtable = NULL;
-					if (!cfg->compile_aot)
-						vtable = mono_class_vtable_checked (cmethod->klass, cfg->error);
-					CHECK_CFG_ERROR;
-					CHECK_TYPELOAD (cmethod->klass);
-					/*
-					 * TypeInitializationExceptions thrown from the mono_runtime_class_init
-					 * call in mono_jit_runtime_invoke () can abort the finalizer thread.
-					 * As a workaround, we call class cctors before allocating objects.
-					 */
-					if (mini_field_access_needs_cctor_run (cfg, method, cmethod->klass, vtable) && !(g_slist_find (class_inits, cmethod->klass))) {
-						emit_class_init (cfg, cmethod->klass, TRUE);
-						if (cfg->verbose_level > 2)
-							printf ("class %s.%s needs init call for ctor\n", m_class_get_name_space (cmethod->klass), m_class_get_name (cmethod->klass));
-						class_inits = g_slist_prepend (class_inits, cmethod->klass);
-					}
-					alloc = handle_alloc (cfg, cmethod->klass, FALSE, 0);
-					*sp = alloc;
-				}
-				CHECK_CFG_EXCEPTION; /*for handle_alloc*/
-				if (alloc)
-					MONO_EMIT_NEW_UNALU (cfg, OP_NOT_NULL, -1, alloc->dreg);
-				/* Now call the actual ctor */
-				int ctor_inline_costs = 0;
-				handle_ctor_call (cfg, cmethod, fsig, context_used, sp, ip, &ctor_inline_costs);
-				if (!COMPILE_LLVM(cfg) || !(cmethod->iflags & METHOD_IMPL_ATTRIBUTE_AGGRESSIVE_INLINING))
-					inline_costs += ctor_inline_costs;
-				CHECK_CFG_EXCEPTION;
-			}
-			if (alloc == NULL) {
-				/* Valuetype */
-				EMIT_NEW_TEMPLOAD (cfg, ins, iargs [0]->inst_c0);
-				mini_type_to_eval_stack_type (cfg, m_class_get_byval_arg (ins->klass), ins);
-				*sp++= ins;
-			} else {
-				*sp++ = alloc;
-			}
-			inline_costs += 5;
-			if (!(seq_point_locs && mono_bitset_test_fast (seq_point_locs, next_ip - header->code)))
-				emit_seq_point (cfg, method, next_ip, FALSE, TRUE);
-			break;
-		}
-		case MONO_CEE_CASTCLASS:
-		case MONO_CEE_ISINST: {
-			--sp;
-			klass = mini_get_class (method, token, generic_context);
-			CHECK_TYPELOAD (klass);
-			if (sp [0]->type != STACK_OBJ)
-				UNVERIFIED;
-			MONO_INST_NEW (cfg, ins, (il_op == MONO_CEE_ISINST) ? OP_ISINST : OP_CASTCLASS);
-			ins->dreg = alloc_preg (cfg);
-			ins->sreg1 = (*sp)->dreg;
-			ins->klass = klass;
-			ins->type = STACK_OBJ;
-			MONO_ADD_INS (cfg->cbb, ins);
-			CHECK_CFG_EXCEPTION;
-			*sp++ = ins;
-			cfg->flags |= MONO_CFG_HAS_TYPE_CHECK;
-			break;
-		}
-		case MONO_CEE_UNBOX_ANY: {
-			MonoInst *res, *addr;
-			--sp;
-			klass = mini_get_class (method, token, generic_context);
-			CHECK_TYPELOAD (klass);
-			mono_save_token_info (cfg, image, token, klass);
-			context_used = mini_class_check_context_used (cfg, klass);
-			if (cfg->gsharedvt_min && mini_is_gsharedvt_variable_klass (klass))
-				GSHAREDVT_FAILURE (il_op);
-			if (mini_is_gsharedvt_klass (klass)) {
-				res = handle_unbox_gsharedvt (cfg, klass, *sp);
-				inline_costs += 2;
-			} else if (mini_class_is_reference (klass)) {
-				if (MONO_INS_IS_PCONST_NULL (*sp)) {
-					EMIT_NEW_PCONST (cfg, res, NULL);
-					res->type = STACK_OBJ;
-				} else {
-					MONO_INST_NEW (cfg, res, OP_CASTCLASS);
-					res->dreg = alloc_preg (cfg);
-					res->sreg1 = (*sp)->dreg;
-					res->klass = klass;
-					res->type = STACK_OBJ;
-					MONO_ADD_INS (cfg->cbb, res);
-					cfg->flags |= MONO_CFG_HAS_TYPE_CHECK;
-				}
-			} else if (mono_class_is_nullable (klass)) {
-				res = handle_unbox_nullable (cfg, *sp, klass, context_used);
-			} else {
-				addr = mini_handle_unbox (cfg, klass, *sp, context_used);
-				/* LDOBJ */
-				EMIT_NEW_LOAD_MEMBASE_TYPE (cfg, ins, m_class_get_byval_arg (klass), addr->dreg, 0);
-				res = ins;
-				inline_costs += 2;
-			}
-			*sp ++ = res;
-			break;
-		}
-		case MONO_CEE_BOX: {
-			MonoInst *val;
-			MonoClass *enum_class;
-			MonoMethod *has_flag;
-			MonoMethodSignature *has_flag_sig;
-			--sp;
-			val = *sp;
-			klass = mini_get_class (method, token, generic_context);
-			CHECK_TYPELOAD (klass);
-			mono_save_token_info (cfg, image, token, klass);
-			context_used = mini_class_check_context_used (cfg, klass);
-			if (mini_class_is_reference (klass)) {
-				*sp++ = val;
-				break;
-			}
-			val = convert_value (cfg, m_class_get_byval_arg (klass), val);
-			if (klass == mono_defaults.void_class)
-				UNVERIFIED;
-			/* frequent check in generic code: box (struct), brtrue */
-			/*
-			 * Look for:
-			 *
-			 *   <push int/long ptr>
-			 *   <push int/long>
-			 *   box MyFlags
-			 *   constrained. MyFlags
-			 *   callvirt instance bool class [mscorlib] System.Enum::HasFlag (class [mscorlib] System.Enum)
-			 *
-			 * If we find this sequence and the operand types on box and constrained
-			 * are equal, we can emit a specialized instruction sequence instead of
-			 * the very slow HasFlag () call.
-			 * This code sequence is generated by older mcs/csc, the newer one is handled in
-			 * emit_inst_for_method ().
-			 */
-			guint32 constrained_token;
-			guint32 callvirt_token;
-			if ((cfg->opt & MONO_OPT_INTRINS) &&
-			    next_ip < end && ip_in_bb (cfg, cfg->cbb, next_ip) &&
-			    (ip = il_read_constrained (next_ip, end, &constrained_token)) &&
-			    ip_in_bb (cfg, cfg->cbb, ip) &&
-			    (ip = il_read_callvirt (ip, end, &callvirt_token)) &&
-			    ip_in_bb (cfg, cfg->cbb, ip) &&
-			    m_class_is_enumtype (klass) &&
-			    (enum_class = mini_get_class (method, constrained_token, generic_context)) &&
-			    (has_flag = mini_get_method (cfg, method, callvirt_token, NULL, generic_context)) &&
-			    has_flag->klass == mono_defaults.enum_class &&
-			    !strcmp (has_flag->name, "HasFlag") &&
-			    (has_flag_sig = mono_method_signature_internal (has_flag)) &&
-			    has_flag_sig->hasthis &&
-			    has_flag_sig->param_count == 1) {
-				CHECK_TYPELOAD (enum_class);
-				if (enum_class == klass) {
-					MonoInst *enum_this, *enum_flag;
-					next_ip = ip;
-					il_op = MONO_CEE_CALLVIRT;
-					--sp;
-					enum_this = sp [0];
-					enum_flag = sp [1];
-					*sp++ = mini_handle_enum_has_flag (cfg, klass, enum_this, -1, enum_flag);
-					break;
-				}
-			}
-			guint32 unbox_any_token;
-			/*
-			 * Common in generic code:
-			 * box T1, unbox.any T2.
-			 */
-			if ((cfg->opt & MONO_OPT_INTRINS) &&
-			    next_ip < end && ip_in_bb (cfg, cfg->cbb, next_ip) &&
-			    (ip = il_read_unbox_any (next_ip, end, &unbox_any_token))) {
-				MonoClass *unbox_klass = mini_get_class (method, unbox_any_token, generic_context);
-				CHECK_TYPELOAD (unbox_klass);
-				if (klass == unbox_klass) {
-					next_ip = ip;
-					*sp++ = val;
-					break;
-				}
-			}
-			guint32 gettype_token;
-			if ((ip = il_read_call(next_ip, end, &gettype_token)) && ip_in_bb (cfg, cfg->cbb, ip)) {
-				MonoMethod* gettype_method = mini_get_method (cfg, method, gettype_token, NULL, generic_context);
-				if (!strcmp (gettype_method->name, "GetType") && gettype_method->klass == mono_defaults.object_class) {
-					mono_class_init_internal(klass);
-					if (mono_class_get_checked (m_class_get_image (klass), m_class_get_type_token (klass), error) == klass) {
-						if (cfg->compile_aot) {
-							EMIT_NEW_TYPE_FROM_HANDLE_CONST (cfg, ins, m_class_get_image (klass), m_class_get_type_token (klass), generic_context);
-						} else {
-							MonoType *klass_type = m_class_get_byval_arg (klass);
-							MonoReflectionType* reflection_type = mono_type_get_object_checked (klass_type, cfg->error);
-							EMIT_NEW_PCONST (cfg, ins, reflection_type);
-						}
-						ins->type = STACK_OBJ;
-						ins->klass = mono_defaults.systemtype_class;
-						*sp++ = ins;
-						next_ip = ip;
-						break;
-					}
-				}
-			}
-			guchar* ldnull_ip;
-			if ((ldnull_ip = il_read_op (next_ip, end, CEE_LDNULL, MONO_CEE_LDNULL)) && ip_in_bb (cfg, cfg->cbb, ldnull_ip)) {
-				gboolean is_eq = FALSE, is_neq = FALSE;
-				if ((ip = il_read_op (ldnull_ip, end, CEE_PREFIX1, MONO_CEE_CEQ)))
-					is_eq = TRUE;
-				else if ((ip = il_read_op (ldnull_ip, end, CEE_PREFIX1, MONO_CEE_CGT_UN)))
-					is_neq = TRUE;
-				if ((is_eq || is_neq) && ip_in_bb (cfg, cfg->cbb, ip) &&
-					!mono_class_is_nullable (klass) && !mini_is_gsharedvt_klass (klass)) {
-					next_ip = ip;
-					il_op = (MonoOpcodeEnum) (is_eq ? CEE_LDC_I4_0 : CEE_LDC_I4_1);
-					EMIT_NEW_ICONST (cfg, ins, is_eq ? 0 : 1);
-					ins->type = STACK_I4;
-					*sp++ = ins;
-					break;
-				}
-			}
-			guint32 isinst_tk = 0;
-			if ((ip = il_read_op_and_token (next_ip, end, CEE_ISINST, MONO_CEE_ISINST, &isinst_tk)) &&
-				ip_in_bb (cfg, cfg->cbb, ip)) {
-				MonoClass *isinst_class = mini_get_class (method, isinst_tk, generic_context);
-				if (!mono_class_is_nullable (klass) && !mono_class_is_nullable (isinst_class) &&
-					!mini_is_gsharedvt_variable_klass (klass) && !mini_is_gsharedvt_variable_klass (isinst_class) &&
-					!mono_class_is_open_constructed_type (m_class_get_byval_arg (klass)) &&
-					!mono_class_is_open_constructed_type (m_class_get_byval_arg (isinst_class))) {
-					guchar* br_ip = NULL;
-					if ((br_ip = il_read_brtrue (ip, end, &target)) || (br_ip = il_read_brtrue_s (ip, end, &target)) ||
-						(br_ip = il_read_brfalse (ip, end, &target)) || (br_ip = il_read_brfalse_s (ip, end, &target))) {
-						gboolean isinst = mono_class_is_assignable_from_internal (isinst_class, klass);
-						next_ip = ip;
-						il_op = (MonoOpcodeEnum) (isinst ? CEE_LDC_I4_1 : CEE_LDC_I4_0);
-						EMIT_NEW_ICONST (cfg, ins, isinst ? 1 : 0);
-						ins->type = STACK_I4;
-						*sp++ = ins;
-						break;
-					}
-					ldnull_ip = NULL;
-					if ((ldnull_ip = il_read_op (ip, end, CEE_LDNULL, MONO_CEE_LDNULL)) && ip_in_bb (cfg, cfg->cbb, ldnull_ip)) {
-						gboolean is_eq = FALSE, is_neq = FALSE;
-						if ((ip = il_read_op (ldnull_ip, end, CEE_PREFIX1, MONO_CEE_CEQ)))
-							is_eq = TRUE;
-						else if ((ip = il_read_op (ldnull_ip, end, CEE_PREFIX1, MONO_CEE_CGT_UN)))
-							is_neq = TRUE;
-						if ((is_eq || is_neq) && ip_in_bb (cfg, cfg->cbb, ip) &&
-							!mono_class_is_nullable (klass) && !mini_is_gsharedvt_klass (klass)) {
-							gboolean isinst = mono_class_is_assignable_from_internal (isinst_class, klass);
-							next_ip = ip;
-							if (is_eq)
-								isinst = !isinst;
-							il_op = (MonoOpcodeEnum) (isinst ? CEE_LDC_I4_1 : CEE_LDC_I4_0);
-							EMIT_NEW_ICONST (cfg, ins, isinst ? 1 : 0);
-							ins->type = STACK_I4;
-							*sp++ = ins;
-							break;
-						}
-					}
-					guchar* unbox_ip = NULL;
-					guint32 unbox_token = 0;
-					if ((unbox_ip = il_read_unbox_any (ip, end, &unbox_token)) && ip_in_bb (cfg, cfg->cbb, unbox_ip)) {
-						MonoClass *unbox_klass = mini_get_class (method, unbox_token, generic_context);
-						CHECK_TYPELOAD (unbox_klass);
-						if (!mono_class_is_nullable (unbox_klass) &&
-							!mini_is_gsharedvt_klass (unbox_klass) &&
-							klass == isinst_class &&
-							klass == unbox_klass)
-						{
-							*sp++ = val;
-							next_ip = unbox_ip;
-							break;
-						}
-					}
-				}
-			}
-			guint32 callvirt_proc_token;
-			if (!((cfg->compile_aot || cfg->compile_llvm) && !mono_class_is_def(klass)) && // we cannot devirtualize in AOT when using generics
-				next_ip < end &&
-				il_read_callvirt (next_ip, end, &callvirt_proc_token) &&
-				ip_in_bb (cfg, cfg->cbb, next_ip) ) {
-				MonoMethod* iface_method;
-				MonoMethodSignature* iface_method_sig;
-				if (val &&
-					val->flags != MONO_INST_FAULT && // not null
-					!mono_class_is_nullable (klass) &&
-					!mini_is_gsharedvt_klass (klass) &&
-					(iface_method = mini_get_method (cfg, method, callvirt_proc_token, NULL, generic_context)) &&
-					(iface_method_sig = mono_method_signature_internal (iface_method)) && // callee signture is healthy
-					iface_method_sig->hasthis && 
-					iface_method_sig->param_count == 0 && // the callee has no args (other than this)
-					!iface_method_sig->has_type_parameters &&
-					iface_method_sig->generic_param_count == 0) { // and no type params, apparently virtual generic methods require special handling
-					if (!m_class_is_inited (iface_method->klass)) {
-						if (!mono_class_init_internal (iface_method->klass))
-							TYPE_LOAD_ERROR (iface_method->klass);
-					}
-					ERROR_DECL (struct_method_error);
-					MonoMethod* struct_method = mono_class_get_virtual_method (klass, iface_method, struct_method_error);
-					if (is_ok (struct_method_error)) {
-						MonoMethodSignature* struct_method_sig = mono_method_signature_internal (struct_method);
-						if (!struct_method ||
-							!MONO_METHOD_IS_FINAL (struct_method) ||
-							!struct_method_sig ||
-							struct_method_sig->has_type_parameters ||
-							!mono_method_can_access_method (method, struct_method)) {
-						} else if (val->opcode == OP_TYPED_OBJREF) {
-							*sp++ = val;
-							cmethod_override = struct_method;
-							break;
-						} else {
-							MonoInst* srcvar = get_vreg_to_inst (cfg, val->dreg);
-							if (!srcvar)
-								srcvar = mono_compile_create_var_for_vreg (cfg, m_class_get_byval_arg (klass), OP_LOCAL, val->dreg);
-							EMIT_NEW_VARLOADA (cfg, ins, srcvar, m_class_get_byval_arg (klass));
-							*sp++= ins;
-							cmethod_override = struct_method;
-							break;
-						}
-					} else {
-						mono_error_cleanup (struct_method_error);
-					}
-				} 
-			}			
-			gboolean is_true;
-			if (!mono_class_is_nullable (klass) &&
-				!mini_is_gsharedvt_klass (klass) &&
-				next_ip < end && ip_in_bb (cfg, cfg->cbb, next_ip) &&
-				( (is_true = !!(ip = il_read_brtrue   (next_ip, end, &target))) ||
-				  (is_true = !!(ip = il_read_brtrue_s (next_ip, end, &target))) ||
-					       (ip = il_read_brfalse  (next_ip, end, &target))  ||
-					       (ip = il_read_brfalse_s (next_ip, end, &target)))) {
-				int dreg;
-				MonoBasicBlock *true_bb, *false_bb;
-				il_op = (MonoOpcodeEnum)next_ip [0];
-				next_ip = ip;
-				if (cfg->verbose_level > 3) {
-					printf ("converting (in B%d: stack: %d) %s", cfg->cbb->block_num, GPTRDIFF_TO_INT (sp - stack_start), mono_disasm_code_one (NULL, method, ip, NULL));
-					printf ("<box+brtrue opt>\n");
-				}
-				/*
-				 * We need to link both bblocks, since it is needed for handling stack
-				 * arguments correctly (See test_0_box_brtrue_opt_regress_81102).
-				 * Branching to only one of them would lead to inconsistencies, so
-				 * generate an ICONST+BRTRUE, the branch opts will get rid of them.
-				 */
-				GET_BBLOCK (cfg, true_bb, target);
-				GET_BBLOCK (cfg, false_bb, next_ip);
-				mono_link_bblock (cfg, cfg->cbb, true_bb);
-				mono_link_bblock (cfg, cfg->cbb, false_bb);
-				if (sp != stack_start) {
-					handle_stack_args (cfg, stack_start, GPTRDIFF_TO_INT (sp - stack_start));
-					sp = stack_start;
-					CHECK_UNVERIFIABLE (cfg);
-				}
-				if (COMPILE_LLVM (cfg)) {
-					dreg = alloc_ireg (cfg);
-					MONO_EMIT_NEW_ICONST (cfg, dreg, 0);
-					MONO_EMIT_NEW_BIALU_IMM (cfg, OP_COMPARE_IMM, -1, dreg, is_true ? 0 : 1);
-					MONO_EMIT_NEW_BRANCH_BLOCK2 (cfg, OP_IBEQ, true_bb, false_bb);
-				} else {
-					/* The JIT can't eliminate the iconst+compare */
-					MONO_INST_NEW (cfg, ins, OP_BR);
-					ins->inst_target_bb = is_true ? true_bb : false_bb;
-					MONO_ADD_INS (cfg->cbb, ins);
-				}
-				start_new_bblock = 1;
-				break;
-			}
-			if (m_class_is_enumtype (klass) && !mini_is_gsharedvt_klass (klass) && !(val->type == STACK_I8 && TARGET_SIZEOF_VOID_P == 4)) {
-				/* Can't do this with 64 bit enums on 32 bit since the vtype decomp pass is ran after the long decomp pass */
-				if (val->opcode == OP_ICONST) {
-					MONO_INST_NEW (cfg, ins, OP_BOX_ICONST);
-					ins->type = STACK_OBJ;
-					ins->klass = klass;
-					ins->inst_c0 = val->inst_c0;
-					ins->dreg = alloc_dreg (cfg, (MonoStackType)val->type);
-				} else {
-					MONO_INST_NEW (cfg, ins, OP_BOX);
-					ins->type = STACK_OBJ;
-					ins->klass = klass;
-					ins->sreg1 = val->dreg;
-					ins->dreg = alloc_dreg (cfg, (MonoStackType)val->type);
-				}
-				MONO_ADD_INS (cfg->cbb, ins);
-				*sp++ = ins;
-			} else {
-				if (target_type_is_incompatible (cfg, m_class_get_byval_arg (klass), val))
-					UNVERIFIED;
-				*sp++ = mini_emit_box (cfg, val, klass, context_used);
-			}
-			CHECK_CFG_EXCEPTION;
-			inline_costs += 1;
-			break;
-		}
-		case MONO_CEE_UNBOX: {
-			--sp;
-			klass = mini_get_class (method, token, generic_context);
-			CHECK_TYPELOAD (klass);
-			mono_save_token_info (cfg, image, token, klass);
-			context_used = mini_class_check_context_used (cfg, klass);
-			if (mono_class_is_nullable (klass)) {
-				MonoInst *val;
-				val = handle_unbox_nullable (cfg, *sp, klass, context_used);
-				EMIT_NEW_VARLOADA (cfg, ins, get_vreg_to_inst (cfg, val->dreg), m_class_get_byval_arg (val->klass));
-				*sp++= ins;
-			} else {
-				ins = mini_handle_unbox (cfg, klass, *sp, context_used);
-				*sp++ = ins;
-			}
-			inline_costs += 2;
-			break;
-		}
-		case MONO_CEE_LDFLD:
-		case MONO_CEE_LDFLDA:
-		case MONO_CEE_STFLD:
-		case MONO_CEE_LDSFLD:
-		case MONO_CEE_LDSFLDA:
-		case MONO_CEE_STSFLD: {
-			MonoClassField *field;
-			guint foffset;
-			gpointer addr = NULL;
-			gboolean is_instance;
-			gboolean is_special_static;
-			MonoType *ftype;
-			MonoInst *store_val = NULL;
-			MonoInst *thread_ins;
-			ins = NULL;
-			is_instance = (il_op == MONO_CEE_LDFLD || il_op == MONO_CEE_LDFLDA || il_op == MONO_CEE_STFLD);
-			if (is_instance) {
-				if (il_op == MONO_CEE_STFLD) {
-					sp -= 2;
-					store_val = sp [1];
-				} else {
-					--sp;
-				}
-				if (sp [0]->type == STACK_I4 || sp [0]->type == STACK_I8 || sp [0]->type == STACK_R8)
-					UNVERIFIED;
-				if (il_op != MONO_CEE_LDFLD && sp [0]->type == STACK_VTYPE)
-					UNVERIFIED;
-			} else {
-				if (il_op == MONO_CEE_STSFLD) {
-					sp--;
-					store_val = sp [0];
-				}
-			}
-			if (method->wrapper_type != MONO_WRAPPER_NONE) {
-				field = (MonoClassField *)mono_method_get_wrapper_data (method, token);
-				klass = m_field_get_parent (field);
-			}
-			else {
-				klass = NULL;
-				field = mono_field_from_token_checked (image, token, &klass, generic_context, cfg->error);
-				if (!field || CLASS_HAS_FAILURE (klass)) {
-						HANDLE_TYPELOAD_ERROR (cfg, klass);
-						if (cfg->error->error_code == MONO_ERROR_BAD_IMAGE)
-							clear_cfg_error (cfg);
-						if (il_op == MONO_CEE_LDFLDA || il_op == MONO_CEE_LDSFLDA) {
-							EMIT_NEW_PCONST (cfg, *sp, NULL);
-							sp++;
-						} else if (il_op == MONO_CEE_LDFLD || il_op == MONO_CEE_LDSFLD) {
-							method_make_alwaysthrow_typeloadfailure (cfg, klass);
-							goto all_bbs_done;
-						}
-						break;	
-				}
-				CHECK_CFG_ERROR;
-			}
-			if (!dont_verify && !cfg->skip_visibility && !mono_method_can_access_field (method, field))
-				FIELD_ACCESS_FAILURE (method, field);
-			mono_class_init_internal (klass);
-			mono_class_setup_fields (klass);
-			ftype = mono_field_get_type_internal (field);
-			/*
-			 * LDFLD etc. is usable on static fields as well, so convert those cases to
-			 * the static case.
-			 */
-			if (is_instance && ftype->attrs & FIELD_ATTRIBUTE_STATIC) {
-				switch (il_op) {
-				case MONO_CEE_LDFLD:
-					il_op = MONO_CEE_LDSFLD;
-					break;
-				case MONO_CEE_STFLD:
-					il_op = MONO_CEE_STSFLD;
-					break;
-				case MONO_CEE_LDFLDA:
-					il_op = MONO_CEE_LDSFLDA;
-					break;
-				default:
-					g_assert_not_reached ();
-				}
-				is_instance = FALSE;
-			}
-			context_used = mini_class_check_context_used (cfg, klass);
-			if (il_op == MONO_CEE_LDSFLD) {
-				ins = mini_emit_inst_for_field_load (cfg, field);
-				if (ins) {
-					*sp++ = ins;
-					goto field_access_end;
-				}
-			}
-			/* INSTANCE CASE */
-			if (is_instance)
-				g_assert (field->offset);
-			/* metadata-update: no hot reload in the JIT.  But if it was supported,
-			 * field->offset here could be wrong for added (m_field_is_from_update)
-			 * fields */
-			foffset = m_class_is_valuetype (klass) ? field->offset - MONO_ABI_SIZEOF (MonoObject): field->offset;
-			if (il_op == MONO_CEE_STFLD) {
-				sp [1] = convert_value (cfg, field->type, sp [1]);
-				if (target_type_is_incompatible (cfg, field->type, sp [1]))
-					UNVERIFIED;
-				{
-					MonoInst *store;
-					MONO_EMIT_NULL_CHECK (cfg, sp [0]->dreg, foffset > mono_target_pagesize ());
-					if (ins_flag & MONO_INST_VOLATILE) {
-						/* Volatile stores have release semantics, see 12.6.7 in Ecma 335 */
-						mini_emit_memory_barrier (cfg, MONO_MEMORY_BARRIER_REL);
-					}
-					if (mini_is_gsharedvt_klass (klass)) {
-						MonoInst *offset_ins;
-						context_used = mini_class_check_context_used (cfg, klass);
-						offset_ins = emit_get_gsharedvt_info (cfg, field, MONO_RGCTX_INFO_FIELD_OFFSET);
-						/* The value is offset by 1 */
-						EMIT_NEW_BIALU_IMM (cfg, ins, OP_PSUB_IMM, offset_ins->dreg, offset_ins->dreg, 1);
-						int dreg = alloc_ireg_mp (cfg);
-						EMIT_NEW_BIALU (cfg, ins, OP_PADD, dreg, sp [0]->dreg, offset_ins->dreg);
-						if (cfg->gen_write_barriers && mini_type_to_stind (cfg, field->type) == CEE_STIND_REF && !MONO_INS_IS_PCONST_NULL (sp [1])) {
-							store = mini_emit_storing_write_barrier (cfg, ins, sp [1]);
-						} else {
-							/* The decomposition will call mini_emit_memory_copy () which will emit a wbarrier if needed */
-							EMIT_NEW_STORE_MEMBASE_TYPE (cfg, store, field->type, dreg, 0, sp [1]->dreg);
-						}
-					} else {
-						if (cfg->gen_write_barriers && mini_type_to_stind (cfg, field->type) == CEE_STIND_REF && !MONO_INS_IS_PCONST_NULL (sp [1])) {
-							/* insert call to write barrier */
-							MonoInst *ptr;
-							int dreg;
-							dreg = alloc_ireg_mp (cfg);
-							EMIT_NEW_BIALU_IMM (cfg, ptr, OP_PADD_IMM, dreg, sp [0]->dreg, foffset);
-							store = mini_emit_storing_write_barrier (cfg, ptr, sp [1]);
-						} else {
-							if (MONO_TYPE_ISSTRUCT (field->type))
-								/* The decomposition might end up calling a copy/wbarrier function which doesn't do null checks */
-								MONO_EMIT_EXPLICIT_NULL_CHECK (cfg, sp [0]->dreg);
-							EMIT_NEW_STORE_MEMBASE_TYPE (cfg, store, field->type, sp [0]->dreg, foffset, sp [1]->dreg);
-						}
-					}
-					if (sp [0]->opcode != OP_LDADDR)
-						store->flags |= MONO_INST_FAULT;
-					store->flags |= ins_flag;
-				}
-				goto field_access_end;
-			}
-			if (is_instance) {
-				if (sp [0]->type == STACK_VTYPE) {
-					MonoInst *var;
-					/* Have to compute the address of the variable */
-					var = get_vreg_to_inst (cfg, sp [0]->dreg);
-					if (!var)
-						var = mono_compile_create_var_for_vreg (cfg, m_class_get_byval_arg (klass), OP_LOCAL, sp [0]->dreg);
-					else
-						g_assert (var->klass == klass);
-					EMIT_NEW_VARLOADA (cfg, ins, var, m_class_get_byval_arg (var->klass));
-					sp [0] = ins;
-				}
-				if (il_op == MONO_CEE_LDFLDA) {
-					if (sp [0]->type == STACK_OBJ || sp [0]->type == STACK_PTR) {
-						MONO_EMIT_NEW_BIALU_IMM (cfg, OP_COMPARE_IMM, -1, sp [0]->dreg, 0);
-						MONO_EMIT_NEW_COND_EXC (cfg, EQ, "NullReferenceException");
-					}
-					int dreg = alloc_ireg_mp (cfg);
-					if (mini_is_gsharedvt_klass (klass)) {
-						MonoInst *offset_ins;
-						offset_ins = emit_get_gsharedvt_info (cfg, field, MONO_RGCTX_INFO_FIELD_OFFSET);
-						/* The value is offset by 1 */
-						EMIT_NEW_BIALU_IMM (cfg, ins, OP_PSUB_IMM, offset_ins->dreg, offset_ins->dreg, 1);
-						EMIT_NEW_BIALU (cfg, ins, OP_PADD, dreg, sp [0]->dreg, offset_ins->dreg);
-					} else {
-						EMIT_NEW_BIALU_IMM (cfg, ins, OP_PADD_IMM, dreg, sp [0]->dreg, foffset);
-					}
-					ins->klass = mono_class_from_mono_type_internal (field->type);
-					ins->type = STACK_MP;
-					*sp++ = ins;
-				} else {
-					MonoInst *load;
-					MONO_EMIT_NULL_CHECK (cfg, sp [0]->dreg, foffset > mono_target_pagesize ());
-					if (sp [0]->opcode == OP_LDADDR && m_class_is_simd_type (klass) && cfg->opt & MONO_OPT_SIMD) {
-						ins = mono_emit_simd_field_load (cfg, field, sp [0]);
-						if (ins) {
-							*sp++ = ins;
-							goto field_access_end;
-						}
-					}
-					MonoInst *field_add_inst = sp [0];
-					if (mini_is_gsharedvt_klass (klass)) {
-						MonoInst *offset_ins;
-						offset_ins = emit_get_gsharedvt_info (cfg, field, MONO_RGCTX_INFO_FIELD_OFFSET);
-						/* The value is offset by 1 */
-						EMIT_NEW_BIALU_IMM (cfg, ins, OP_PSUB_IMM, offset_ins->dreg, offset_ins->dreg, 1);
-						EMIT_NEW_BIALU (cfg, field_add_inst, OP_PADD, alloc_ireg_mp (cfg), sp [0]->dreg, offset_ins->dreg);
-						foffset = 0;
-					}
-					load = mini_emit_memory_load (cfg, field->type, field_add_inst, foffset, ins_flag);
-					if (sp [0]->opcode != OP_LDADDR)
-						load->flags |= MONO_INST_FAULT;
-					*sp++ = load;
-				}
-			}
-			if (is_instance)
-				goto field_access_end;
-			/* STATIC CASE */
-			context_used = mini_class_check_context_used (cfg, klass);
-			if (ftype->attrs & FIELD_ATTRIBUTE_LITERAL) {
-				mono_error_set_field_missing (cfg->error, m_field_get_parent (field), field->name, NULL, "Using static instructions with literal field");
-				CHECK_CFG_ERROR;
-			}
-			/* The special_static_fields field is init'd in mono_class_vtable, so it needs
-			 * to be called here.
-			 */
-			if (!context_used) {
-				mono_class_vtable_checked (klass, cfg->error);
-				CHECK_CFG_ERROR;
-				CHECK_TYPELOAD (klass);
-			}
-			is_special_static = mono_class_field_is_special_static (field);
-			if (is_special_static) {
-				addr = mono_special_static_field_get_offset (field, cfg->error);
-				CHECK_CFG_ERROR;
-				CHECK_TYPELOAD (klass);
-			} else {
-				addr = NULL;
-			}
-			if (is_special_static && ((gsize)addr & 0x80000000) == 0)
-				thread_ins = mono_create_tls_get (cfg, TLS_KEY_THREAD);
-			else
-				thread_ins = NULL;
-			/* Generate IR to compute the field address */
-			if (is_special_static && ((gsize)addr & 0x80000000) == 0 && thread_ins &&
-				!(context_used && cfg->gsharedvt && mini_is_gsharedvt_klass (klass))) {
-				/*
-				 * Fast access to TLS data
-				 * Inline version of get_thread_static_data () in
-				 * threads.c.
-				 */
-				guint32 offset;
-				int idx, static_data_reg, array_reg, dreg;
-				static_data_reg = alloc_ireg (cfg);
-				MONO_EMIT_NEW_LOAD_MEMBASE (cfg, static_data_reg, thread_ins->dreg, MONO_STRUCT_OFFSET (MonoInternalThread, static_data));
-				if (cfg->compile_aot || context_used) {
-					int offset_reg, offset2_reg, idx_reg;
-					/* For TLS variables, this will return the TLS offset */
-					if (context_used) {
-						MonoInst *addr_ins = emit_get_rgctx_field (cfg, context_used, field, MONO_RGCTX_INFO_FIELD_OFFSET);
-						/* The value is offset by 1 */
-						EMIT_NEW_BIALU_IMM (cfg, ins, OP_PSUB_IMM, addr_ins->dreg, addr_ins->dreg, 1);
-					} else {
-						EMIT_NEW_SFLDACONST (cfg, ins, field);
-					}
-					offset_reg = ins->dreg;
-					MONO_EMIT_NEW_BIALU_IMM (cfg, OP_IAND_IMM, offset_reg, offset_reg, 0x7fffffff);
-					idx_reg = alloc_ireg (cfg);
-					MONO_EMIT_NEW_BIALU_IMM (cfg, OP_IAND_IMM, idx_reg, offset_reg, 0x3f);
-					MONO_EMIT_NEW_BIALU_IMM (cfg, OP_ISHL_IMM, idx_reg, idx_reg, TARGET_SIZEOF_VOID_P == 8 ? 3 : 2);
-					MONO_EMIT_NEW_BIALU (cfg, OP_PADD, static_data_reg, static_data_reg, idx_reg);
-					array_reg = alloc_ireg (cfg);
-					MONO_EMIT_NEW_LOAD_MEMBASE (cfg, array_reg, static_data_reg, 0);
-					offset2_reg = alloc_ireg (cfg);
-					MONO_EMIT_NEW_BIALU_IMM (cfg, OP_ISHR_UN_IMM, offset2_reg, offset_reg, 6);
-					MONO_EMIT_NEW_BIALU_IMM (cfg, OP_IAND_IMM, offset2_reg, offset2_reg, 0x1ffffff);
-					dreg = alloc_ireg (cfg);
-					EMIT_NEW_BIALU (cfg, ins, OP_PADD, dreg, array_reg, offset2_reg);
-				} else {
-					offset = (gsize)addr & 0x7fffffff;
-					idx = offset & 0x3f;
-					array_reg = alloc_ireg (cfg);
-					MONO_EMIT_NEW_LOAD_MEMBASE (cfg, array_reg, static_data_reg, idx * TARGET_SIZEOF_VOID_P);
-					dreg = alloc_ireg (cfg);
-					EMIT_NEW_BIALU_IMM (cfg, ins, OP_ADD_IMM, dreg, array_reg, ((offset >> 6) & 0x1ffffff));
-				}
-			} else if ((cfg->compile_aot && is_special_static) ||
-					(context_used && is_special_static)) {
-				MonoInst *iargs [1];
-				g_assert (m_field_get_parent (field));
-				if (context_used) {
-					iargs [0] = emit_get_rgctx_field (cfg, context_used,
-						field, MONO_RGCTX_INFO_CLASS_FIELD);
-				} else {
-					EMIT_NEW_FIELDCONST (cfg, iargs [0], field);
-				}
-				ins = mono_emit_jit_icall (cfg, mono_class_static_field_address, iargs);
-			} else if (context_used) {
-				MonoInst *static_data;
-				/*
-				g_print ("sharing static field access in %s.%s.%s - depth %d offset %d\n",
-					method->klass->name_space, method->klass->name, method->name,
-					depth, field->offset);
-				*/
-				if (mono_class_needs_cctor_run (klass, method))
-					emit_class_init (cfg, klass, TRUE);
-				/*
-				 * The pointer we're computing here is
-				 *
-				 *   super_info.static_data + field->offset
-				 */
-				static_data = mini_emit_get_rgctx_klass (cfg, context_used,
-					klass, MONO_RGCTX_INFO_STATIC_DATA);
-				if (mini_is_gsharedvt_klass (klass)) {
-					MonoInst *offset_ins;
-					offset_ins = emit_get_rgctx_field (cfg, context_used, field, MONO_RGCTX_INFO_FIELD_OFFSET);
-					/* The value is offset by 1 */
-					EMIT_NEW_BIALU_IMM (cfg, ins, OP_PSUB_IMM, offset_ins->dreg, offset_ins->dreg, 1);
-					int dreg = alloc_ireg_mp (cfg);
-					EMIT_NEW_BIALU (cfg, ins, OP_PADD, dreg, static_data->dreg, offset_ins->dreg);
-				} else if (field->offset == 0) {
-					ins = static_data;
-				} else {
-					int addr_reg = mono_alloc_preg (cfg);
-					EMIT_NEW_BIALU_IMM (cfg, ins, OP_PADD_IMM, addr_reg, static_data->dreg, field->offset);
-				}
-			} else if (cfg->compile_aot && addr) {
-				MonoInst *iargs [1];
-				g_assert (m_field_get_parent (field));
-				EMIT_NEW_FIELDCONST (cfg, iargs [0], field);
-				ins = mono_emit_jit_icall (cfg, mono_class_static_field_address, iargs);
-			} else {
-				MonoVTable *vtable = NULL;
-				if (!cfg->compile_aot)
-					vtable = mono_class_vtable_checked (klass, cfg->error);
-				CHECK_CFG_ERROR;
-				CHECK_TYPELOAD (klass);
-				if (!addr) {
-					if (mini_field_access_needs_cctor_run (cfg, method, klass, vtable)) {
-						if (!(g_slist_find (class_inits, klass))) {
-							emit_class_init (cfg, klass, TRUE);
-							if (cfg->verbose_level > 2)
-								printf ("class %s.%s needs init call for %s\n", m_class_get_name_space (klass), m_class_get_name (klass), mono_field_get_name (field));
-							class_inits = g_slist_prepend (class_inits, klass);
-						}
-					} else {
-						if (cfg->run_cctors) {
-							/* This makes so that inline cannot trigger */
-							/* .cctors: too many apps depend on them */
-							/* running with a specific order... */
-							g_assert (vtable);
-							if (!vtable->initialized && m_class_has_cctor (vtable->klass))
-								INLINE_FAILURE ("class init");
-							if (!mono_runtime_class_init_full (vtable, cfg->error)) {
-								mono_cfg_set_exception (cfg, MONO_EXCEPTION_MONO_ERROR);
-								goto exception_exit;
-							}
-						}
-					}
-					if (cfg->compile_aot)
-						EMIT_NEW_SFLDACONST (cfg, ins, field);
-					else {
-						g_assert (vtable);
-						addr = mono_static_field_get_addr (vtable, field);
-						g_assert (addr);
-						EMIT_NEW_PCONST (cfg, ins, addr);
-					}
-				} else {
-					MonoInst *iargs [1];
-					EMIT_NEW_ICONST (cfg, iargs [0], GPOINTER_TO_UINT (addr));
-					ins = mono_emit_jit_icall (cfg, mono_get_special_static_data, iargs);
-				}
-			}
-			/* Generate IR to do the actual load/store operation */
-			if ((il_op == MONO_CEE_STFLD || il_op == MONO_CEE_STSFLD)) {
-				if (ins_flag & MONO_INST_VOLATILE) {
-					/* Volatile stores have release semantics, see 12.6.7 in Ecma 335 */
-					mini_emit_memory_barrier (cfg, MONO_MEMORY_BARRIER_REL);
-				} else if (!mini_debug_options.weak_memory_model && mini_type_is_reference (ftype)) {
-					mini_emit_memory_barrier (cfg, MONO_MEMORY_BARRIER_REL);
-				}
-			}
-			if (il_op == MONO_CEE_LDSFLDA) {
-				ins->klass = mono_class_from_mono_type_internal (ftype);
-				ins->type = STACK_PTR;
-				*sp++ = ins;
-			} else if (il_op == MONO_CEE_STSFLD) {
-				MonoInst *store;
-				if (m_class_get_mem_manager (m_field_get_parent (field))->collectible && (mini_type_is_reference (ftype) || m_class_has_references (mono_class_from_mono_type_internal (ftype)))) {
-					/* These are stored on the GC heap, so they need GC barriers */
-					mini_emit_memory_store (cfg, ftype, ins, store_val, 0);
-				} else {
-					EMIT_NEW_STORE_MEMBASE_TYPE (cfg, store, ftype, ins->dreg, 0, store_val->dreg);
-					store->flags |= ins_flag;
-				}
-			} else {
-				gboolean is_const = FALSE;
-				MonoVTable *vtable = NULL;
-				addr = NULL;
-				if (!context_used) {
-					vtable = mono_class_vtable_checked (klass, cfg->error);
-					CHECK_CFG_ERROR;
-					CHECK_TYPELOAD (klass);
-				}
-				if ((ftype->attrs & FIELD_ATTRIBUTE_INIT_ONLY) && (((addr = mono_aot_readonly_field_override (field)) != NULL) ||
-						(!context_used && !cfg->compile_aot && vtable->initialized))) {
-					int ro_type = ftype->type;
-					if (!addr)
-						addr = mono_static_field_get_addr (vtable, field);
-					if (ro_type == MONO_TYPE_VALUETYPE && m_class_is_enumtype (ftype->data.klass)) {
-						ro_type = mono_class_enum_basetype_internal (ftype->data.klass)->type;
-					}
-					GSHAREDVT_FAILURE (il_op);
-					/* printf ("RO-FIELD %s.%s:%s\n", klass->name_space, klass->name, mono_field_get_name (field));*/
-					is_const = TRUE;
-					switch (ro_type) {
-					case MONO_TYPE_BOOLEAN:
-					case MONO_TYPE_U1:
-						EMIT_NEW_ICONST (cfg, *sp, *((guint8 *)addr));
-						sp++;
-						break;
-					case MONO_TYPE_I1:
-						EMIT_NEW_ICONST (cfg, *sp, *((gint8 *)addr));
-						sp++;
-						break;
-					case MONO_TYPE_CHAR:
-					case MONO_TYPE_U2:
-						EMIT_NEW_ICONST (cfg, *sp, *((guint16 *)addr));
-						sp++;
-						break;
-					case MONO_TYPE_I2:
-						EMIT_NEW_ICONST (cfg, *sp, *((gint16 *)addr));
-						sp++;
-						break;
-						break;
-					case MONO_TYPE_I4:
-						EMIT_NEW_ICONST (cfg, *sp, *((gint32 *)addr));
-						sp++;
-						break;
-					case MONO_TYPE_U4:
-						EMIT_NEW_ICONST (cfg, *sp, *((guint32 *)addr));
-						sp++;
-						break;
-					case MONO_TYPE_I:
-					case MONO_TYPE_U:
-					case MONO_TYPE_PTR:
-					case MONO_TYPE_FNPTR:
-						EMIT_NEW_PCONST (cfg, *sp, *((gpointer *)addr));
-						mini_type_to_eval_stack_type ((cfg), field->type, *sp);
-						sp++;
-						break;
-					case MONO_TYPE_STRING:
-					case MONO_TYPE_OBJECT:
-					case MONO_TYPE_CLASS:
-					case MONO_TYPE_SZARRAY:
-					case MONO_TYPE_ARRAY:
-						if (!mono_gc_is_moving ()) {
-							EMIT_NEW_PCONST (cfg, *sp, *((gpointer *)addr));
-							mini_type_to_eval_stack_type ((cfg), field->type, *sp);
-							sp++;
-						} else {
-							is_const = FALSE;
-						}
-						break;
-					case MONO_TYPE_I8:
-					case MONO_TYPE_U8:
-						EMIT_NEW_I8CONST (cfg, *sp, *((gint64 *)addr));
-						sp++;
-						break;
-					case MONO_TYPE_R4:
-					case MONO_TYPE_R8:
-					case MONO_TYPE_VALUETYPE:
-					default:
-						is_const = FALSE;
-						break;
-					}
-				}
-				if (!is_const) {
-					if (!ins)
-						EMIT_NEW_PCONST (cfg, ins, 0);
-					MonoInst *load;
-					EMIT_NEW_LOAD_MEMBASE_TYPE (cfg, load, field->type, ins->dreg, 0);
-					load->flags |= ins_flag;
-					*sp++ = load;
-				}
-			}
-field_access_end:
-			if ((il_op == MONO_CEE_LDFLD || il_op == MONO_CEE_LDSFLD) && (ins_flag & MONO_INST_VOLATILE)) {
-				/* Volatile loads have acquire semantics, see 12.6.7 in Ecma 335 */
-				mini_emit_memory_barrier (cfg, MONO_MEMORY_BARRIER_ACQ);
-			}
-			ins_flag = 0;
-			break;
-		}
-		case MONO_CEE_STOBJ:
-			sp -= 2;
-			klass = mini_get_class (method, token, generic_context);
-			CHECK_TYPELOAD (klass);
-			/* FIXME: should check item at sp [1] is compatible with the type of the store. */
-			mini_emit_memory_store (cfg, m_class_get_byval_arg (klass), sp [0], sp [1], ins_flag);
-			ins_flag = 0;
-			inline_costs += 1;
-			break;
-			/*
-			 * Array opcodes
-			 */
-		case MONO_CEE_NEWARR: {
-			MonoInst *len_ins;
-			const char *data_ptr;
-			int data_size = 0;
-			guint32 field_token;
-			--sp;
-			klass = mini_get_class (method, token, generic_context);
-			CHECK_TYPELOAD (klass);
-			if (m_class_get_byval_arg (klass)->type == MONO_TYPE_VOID)
-				UNVERIFIED;
-			context_used = mini_class_check_context_used (cfg, klass);
-			if (sp [0]->type == STACK_I8 && TARGET_SIZEOF_VOID_P == 4) {
-				MONO_INST_NEW (cfg, ins, OP_LCONV_TO_OVF_U4);
-				ins->sreg1 = sp [0]->dreg;
-				ins->type = STACK_I4;
-				ins->dreg = alloc_ireg (cfg);
-				MONO_ADD_INS (cfg->cbb, ins);
-				*sp = mono_decompose_opcode (cfg, ins);
-			}
-#if defined(TARGET_S390X) || defined(TARGET_POWERPC64)
-			/* The array allocator expects a 64-bit input, and we cannot rely
-			   on the high bits of a 32-bit result, so we have to extend.  */
-			if (sp [0]->type == STACK_I4 && TARGET_SIZEOF_VOID_P == 8) {
-				MONO_INST_NEW (cfg, ins, OP_ICONV_TO_I8);
-				ins->sreg1 = sp [0]->dreg;
-				ins->type = STACK_I8;
-				ins->dreg = alloc_ireg (cfg);
-				MONO_ADD_INS (cfg->cbb, ins);
-				*sp = mono_decompose_opcode (cfg, ins);
-			}
-#endif
-			if (context_used) {
-				MonoInst *args [3];
-				MonoClass *array_class = mono_class_create_array (klass, 1);
-				MonoMethod *managed_alloc = mono_gc_get_managed_array_allocator (array_class);
-				/* FIXME: Use OP_NEWARR and decompose later to help abcrem */
-				/* vtable */
-				args [0] = mini_emit_get_rgctx_klass (cfg, context_used,
-					array_class, MONO_RGCTX_INFO_VTABLE);
-				/* array len */
-				args [1] = sp [0];
-				if (managed_alloc)
-					ins = mono_emit_method_call (cfg, managed_alloc, args, NULL);
-				else
-					ins = mono_emit_jit_icall (cfg, ves_icall_array_new_specific, args);
-			} else {
-				/* Decompose later since it is needed by abcrem */
-				MonoClass *array_type = mono_class_create_array (klass, 1);
-				mono_class_vtable_checked (array_type, cfg->error);
-				CHECK_CFG_ERROR;
-				CHECK_TYPELOAD (array_type);
-				MONO_INST_NEW (cfg, ins, OP_NEWARR);
-				ins->dreg = alloc_ireg_ref (cfg);
-				ins->sreg1 = sp [0]->dreg;
-				ins->inst_newa_class = klass;
-				ins->type = STACK_OBJ;
-				ins->klass = array_type;
-				MONO_ADD_INS (cfg->cbb, ins);
-				cfg->flags |= MONO_CFG_NEEDS_DECOMPOSE;
-				cfg->cbb->needs_decompose = TRUE;
-				/* Needed so mono_emit_load_get_addr () gets called */
-				mono_get_got_var (cfg);
-			}
-			len_ins = sp [0];
-			ip += 5;
-			*sp++ = ins;
-			inline_costs += 1;
-			/*
-			 * we inline/optimize the initialization sequence if possible.
-			 * we should also allocate the array as not cleared, since we spend as much time clearing to 0 as initializing
-			 * for small sizes open code the memcpy
-			 * ensure the rva field is big enough
-			 */
-			if ((cfg->opt & MONO_OPT_INTRINS) && next_ip < end
-					&& ip_in_bb (cfg, cfg->cbb, next_ip)
-					&& (len_ins->opcode == OP_ICONST)
-					&& (data_ptr = initialize_array_data (cfg, method,
-						cfg->compile_aot, next_ip, end, klass,
-						GTMREG_TO_UINT32 (len_ins->inst_c0), &data_size, &field_token,
-						&il_op, &next_ip))) {
-				MonoMethod *memcpy_method = mini_get_memcpy_method ();
-				MonoInst *iargs [3];
-				int add_reg = alloc_ireg_mp (cfg);
-				EMIT_NEW_BIALU_IMM (cfg, iargs [0], OP_PADD_IMM, add_reg, ins->dreg, MONO_STRUCT_OFFSET (MonoArray, vector));
-				if (cfg->compile_aot) {
-					EMIT_NEW_AOTCONST_TOKEN (cfg, iargs [1], MONO_PATCH_INFO_RVA, m_class_get_image (method->klass), field_token, STACK_PTR, NULL);
-				} else {
-					EMIT_NEW_PCONST (cfg, iargs [1], (char*)data_ptr);
-				}
-				EMIT_NEW_ICONST (cfg, iargs [2], data_size);
-				mono_emit_method_call (cfg, memcpy_method, iargs, NULL);
-			}
-			break;
-		}
-		case MONO_CEE_LDLEN:
-			--sp;
-			if (sp [0]->type != STACK_OBJ)
-				UNVERIFIED;
-			MONO_INST_NEW (cfg, ins, OP_LDLEN);
-			ins->dreg = alloc_preg (cfg);
-			ins->sreg1 = sp [0]->dreg;
-			ins->inst_imm = MONO_STRUCT_OFFSET (MonoArray, max_length);
-			ins->type = STACK_I4;
-			/* This flag will be inherited by the decomposition */
-			ins->flags |= MONO_INST_FAULT | MONO_INST_INVARIANT_LOAD;
-			MONO_ADD_INS (cfg->cbb, ins);
-			cfg->flags |= MONO_CFG_NEEDS_DECOMPOSE;
-			cfg->cbb->needs_decompose = TRUE;
-			MONO_EMIT_NEW_UNALU (cfg, OP_NOT_NULL, -1, sp [0]->dreg);
-			*sp++ = ins;
-			break;
-		case MONO_CEE_LDELEMA:
-			sp -= 2;
-			if (sp [0]->type != STACK_OBJ)
-				UNVERIFIED;
-			cfg->flags |= MONO_CFG_HAS_LDELEMA;
-			klass = mini_get_class (method, token, generic_context);
-			CHECK_TYPELOAD (klass);
-			/* we need to make sure that this array is exactly the type it needs
-			 * to be for correctness. the wrappers are lax with their usage
-			 * so we need to ignore them here
-			 */
-			if (!m_class_is_valuetype (klass) && method->wrapper_type == MONO_WRAPPER_NONE && !readonly) {
-				MonoClass *array_class = mono_class_create_array (klass, 1);
-				mini_emit_check_array_type (cfg, sp [0], array_class);
-				CHECK_TYPELOAD (array_class);
-			}
-			readonly = FALSE;
-			ins = mini_emit_ldelema_1_ins (cfg, klass, sp [0], sp [1], TRUE, FALSE);
-			*sp++ = ins;
-			break;
-		case MONO_CEE_LDELEM:
-		case MONO_CEE_LDELEM_I1:
-		case MONO_CEE_LDELEM_U1:
-		case MONO_CEE_LDELEM_I2:
-		case MONO_CEE_LDELEM_U2:
-		case MONO_CEE_LDELEM_I4:
-		case MONO_CEE_LDELEM_U4:
-		case MONO_CEE_LDELEM_I8:
-		case MONO_CEE_LDELEM_I:
-		case MONO_CEE_LDELEM_R4:
-		case MONO_CEE_LDELEM_R8:
-		case MONO_CEE_LDELEM_REF: {
-			MonoInst *addr;
-			sp -= 2;
-			if (il_op == MONO_CEE_LDELEM) {
-				klass = mini_get_class (method, token, generic_context);
-				CHECK_TYPELOAD (klass);
-				mono_class_init_internal (klass);
-			}
-			else
-				klass = array_access_to_klass (il_op);
-			if (sp [0]->type != STACK_OBJ)
-				UNVERIFIED;
-			cfg->flags |= MONO_CFG_HAS_LDELEMA;
-			if (mini_is_gsharedvt_variable_klass (klass)) {
-				addr = mini_emit_ldelema_1_ins (cfg, klass, sp [0], sp [1], TRUE, FALSE);
-				EMIT_NEW_LOAD_MEMBASE_TYPE (cfg, ins, m_class_get_byval_arg (klass), addr->dreg, 0);
-				ins->opcode = OP_LOADV_MEMBASE;
-			} else if (sp [1]->opcode == OP_ICONST) {
-				int array_reg = sp [0]->dreg;
-				int index_reg = sp [1]->dreg;
-				size_t offset = (mono_class_array_element_size (klass) * sp [1]->inst_c0) + MONO_STRUCT_OFFSET (MonoArray, vector);
-				if (SIZEOF_REGISTER == 8 && COMPILE_LLVM (cfg) && sp [1]->inst_c0 < 0)
-					MONO_EMIT_NEW_UNALU (cfg, OP_ZEXT_I4, index_reg, index_reg);
-				MONO_EMIT_BOUNDS_CHECK (cfg, array_reg, MonoArray, max_length, index_reg, FALSE);
-				EMIT_NEW_LOAD_MEMBASE_TYPE (cfg, ins, m_class_get_byval_arg (klass), array_reg, (target_mgreg_t)offset);
-			} else {
-				addr = mini_emit_ldelema_1_ins (cfg, klass, sp [0], sp [1], TRUE, FALSE);
-				EMIT_NEW_LOAD_MEMBASE_TYPE (cfg, ins, m_class_get_byval_arg (klass), addr->dreg, 0);
-			}
-			*sp++ = ins;
-			break;
-		}
-		case MONO_CEE_STELEM_I:
-		case MONO_CEE_STELEM_I1:
-		case MONO_CEE_STELEM_I2:
-		case MONO_CEE_STELEM_I4:
-		case MONO_CEE_STELEM_I8:
-		case MONO_CEE_STELEM_R4:
-		case MONO_CEE_STELEM_R8:
-		case MONO_CEE_STELEM_REF:
-		case MONO_CEE_STELEM: {
-			sp -= 3;
-			cfg->flags |= MONO_CFG_HAS_LDELEMA;
-			if (il_op == MONO_CEE_STELEM) {
-				klass = mini_get_class (method, token, generic_context);
-				CHECK_TYPELOAD (klass);
-				mono_class_init_internal (klass);
-			}
-			else
-				klass = array_access_to_klass (il_op);
-			if (sp [0]->type != STACK_OBJ)
-				UNVERIFIED;
-			sp [2] = convert_value (cfg, m_class_get_byval_arg (klass), sp [2]);
-			mini_emit_array_store (cfg, klass, sp, TRUE);
-			inline_costs += 1;
-			break;
-		}
-		case MONO_CEE_CKFINITE: {
-			--sp;
-			if (cfg->llvm_only) {
-				MonoInst *iargs [1];
-				iargs [0] = sp [0];
-				*sp++ = mono_emit_jit_icall (cfg, mono_ckfinite, iargs);
-			} else  {
-				sp [0] = convert_value (cfg, m_class_get_byval_arg (mono_defaults.double_class), sp [0]);
-				MONO_INST_NEW (cfg, ins, OP_CKFINITE);
-				ins->sreg1 = sp [0]->dreg;
-				ins->dreg = alloc_freg (cfg);
-				ins->type = STACK_R8;
-				MONO_ADD_INS (cfg->cbb, ins);
-				*sp++ = mono_decompose_opcode (cfg, ins);
-			}
-			break;
-		}
-		case MONO_CEE_REFANYVAL: {
-			MonoInst *src_var, *src;
-			int klass_reg = alloc_preg (cfg);
-			int dreg = alloc_preg (cfg);
-			GSHAREDVT_FAILURE (il_op);
-			MONO_INST_NEW (cfg, ins, il_op);
-			--sp;
-			klass = mini_get_class (method, token, generic_context);
-			CHECK_TYPELOAD (klass);
-			context_used = mini_class_check_context_used (cfg, klass);
-			src_var = get_vreg_to_inst (cfg, sp [0]->dreg);
-			if (!src_var)
-				src_var = mono_compile_create_var_for_vreg (cfg, m_class_get_byval_arg (mono_defaults.typed_reference_class), OP_LOCAL, sp [0]->dreg);
-			EMIT_NEW_VARLOADA (cfg, src, src_var, src_var->inst_vtype);
-			MONO_EMIT_NEW_LOAD_MEMBASE (cfg, klass_reg, src->dreg, MONO_STRUCT_OFFSET (MonoTypedRef, klass));
-			if (context_used) {
-				MonoInst *klass_ins;
-				klass_ins = mini_emit_get_rgctx_klass (cfg, context_used,
-						klass, MONO_RGCTX_INFO_KLASS);
-				MONO_EMIT_NEW_BIALU (cfg, OP_COMPARE, -1, klass_reg, klass_ins->dreg);
-				MONO_EMIT_NEW_COND_EXC (cfg, NE_UN, "InvalidCastException");
-			} else {
-				mini_emit_class_check (cfg, klass_reg, klass);
-			}
-			EMIT_NEW_LOAD_MEMBASE (cfg, ins, OP_LOAD_MEMBASE, dreg, src->dreg, MONO_STRUCT_OFFSET (MonoTypedRef, value));
-			ins->type = STACK_MP;
-			ins->klass = klass;
-			*sp++ = ins;
-			break;
-		}
-		case MONO_CEE_MKREFANY: {
-			MonoInst *loc, *addr;
-			GSHAREDVT_FAILURE (il_op);
-			MONO_INST_NEW (cfg, ins, il_op);
-			--sp;
-			klass = mini_get_class (method, token, generic_context);
-			CHECK_TYPELOAD (klass);
-			context_used = mini_class_check_context_used (cfg, klass);
-			loc = mono_compile_create_var (cfg, m_class_get_byval_arg (mono_defaults.typed_reference_class), OP_LOCAL);
-			EMIT_NEW_TEMPLOADA (cfg, addr, loc->inst_c0);
-			MonoInst *const_ins = mini_emit_get_rgctx_klass (cfg, context_used, klass, MONO_RGCTX_INFO_KLASS);
-			int type_reg = alloc_preg (cfg);
-			MONO_EMIT_NEW_STORE_MEMBASE (cfg, OP_STOREP_MEMBASE_REG, addr->dreg, MONO_STRUCT_OFFSET (MonoTypedRef, klass), const_ins->dreg);
-			MONO_EMIT_NEW_BIALU_IMM (cfg, OP_ADD_IMM, type_reg, const_ins->dreg, m_class_offsetof_byval_arg ());
-			MONO_EMIT_NEW_STORE_MEMBASE (cfg, OP_STOREP_MEMBASE_REG, addr->dreg, MONO_STRUCT_OFFSET (MonoTypedRef, type), type_reg);
-			MONO_EMIT_NEW_STORE_MEMBASE (cfg, OP_STOREP_MEMBASE_REG, addr->dreg, MONO_STRUCT_OFFSET (MonoTypedRef, value), sp [0]->dreg);
-			EMIT_NEW_TEMPLOAD (cfg, ins, loc->inst_c0);
-			ins->type = STACK_VTYPE;
-			ins->klass = mono_defaults.typed_reference_class;
-			*sp++ = ins;
-			break;
-		}
-		case MONO_CEE_LDTOKEN: {
-			gpointer handle;
-			MonoClass *handle_class;
-			if (method->wrapper_type == MONO_WRAPPER_DYNAMIC_METHOD ||
-					method->wrapper_type == MONO_WRAPPER_SYNCHRONIZED) {
-				handle = mono_method_get_wrapper_data (method, n);
-				handle_class = (MonoClass *)mono_method_get_wrapper_data (method, n + 1);
-				if (handle_class == mono_defaults.typehandle_class)
-					handle = m_class_get_byval_arg ((MonoClass*)handle);
-			}
-			else {
-				handle = mono_ldtoken_checked (image, n, &handle_class, generic_context, cfg->error);
-				CHECK_CFG_ERROR;
-			}
-			if (!handle)
-				LOAD_ERROR;
-			mono_class_init_internal (handle_class);
-			if (cfg->gshared) {
-				if (mono_metadata_token_table (n) == MONO_TABLE_TYPEDEF ||
-						mono_metadata_token_table (n) == MONO_TABLE_TYPEREF) {
-					/* This case handles ldtoken
-					   of an open type, like for
-					   typeof(Gen<>). */
-					context_used = 0;
-				} else if (handle_class == mono_defaults.typehandle_class) {
-					context_used = mini_class_check_context_used (cfg, mono_class_from_mono_type_internal ((MonoType *)handle));
-				} else if (handle_class == mono_defaults.fieldhandle_class)
-					context_used = mini_class_check_context_used (cfg, m_field_get_parent (((MonoClassField*)handle)));
-				else if (handle_class == mono_defaults.methodhandle_class)
-					context_used = mini_method_check_context_used (cfg, (MonoMethod *)handle);
-				else
-					g_assert_not_reached ();
-			}
-			{
-				if ((next_ip + 4 < end) && ip_in_bb (cfg, cfg->cbb, next_ip) &&
-					((next_ip [0] == CEE_CALL) || (next_ip [0] == CEE_CALLVIRT)) &&
-					(cmethod = mini_get_method (cfg, method, read32 (next_ip + 1), NULL, generic_context)) &&
-					(cmethod->klass == mono_defaults.systemtype_class) &&
-					(strcmp (cmethod->name, "GetTypeFromHandle") == 0)) {
-					MonoClass *tclass = mono_class_from_mono_type_internal ((MonoType *)handle);
-					mono_class_init_internal (tclass);
-					guchar *is_vt_ip;
-					guint32 is_vt_token;
-					if ((is_vt_ip = il_read_call (next_ip + 5, end, &is_vt_token)) && ip_in_bb (cfg, cfg->cbb, is_vt_ip)) {
-						MonoMethod *is_vt_method = mini_get_method (cfg, method, is_vt_token, NULL, generic_context);
-						if (is_vt_method->klass == mono_defaults.systemtype_class &&
-							!mini_is_gsharedvt_variable_klass (tclass) &&
-							!mono_class_is_open_constructed_type (m_class_get_byval_arg (tclass)) &&
-							!strcmp ("get_IsValueType", is_vt_method->name)) {
-							next_ip = is_vt_ip;
-							EMIT_NEW_ICONST (cfg, ins, m_class_is_valuetype (tclass) ? 1 : 0);
-							ins->type = STACK_I4;
-							*sp++ = ins;
-							break;
-						}
-					}
-					if (context_used) {
-						MONO_INST_NEW (cfg, ins, OP_RTTYPE);
-						ins->dreg = alloc_ireg_ref (cfg);
-						ins->inst_p0 = tclass;
-						ins->type = STACK_OBJ;
-						MONO_ADD_INS (cfg->cbb, ins);
-						cfg->flags |= MONO_CFG_NEEDS_DECOMPOSE;
-						cfg->cbb->needs_decompose = TRUE;
-					} else if (cfg->compile_aot) {
-						if (method->wrapper_type) {
-							error_init (error); //got to do it since there are multiple conditionals below
-							if (mono_class_get_checked (m_class_get_image (tclass), m_class_get_type_token (tclass), error) == tclass && !generic_context) {
-								/* Special case for static synchronized wrappers */
-								EMIT_NEW_TYPE_FROM_HANDLE_CONST (cfg, ins, m_class_get_image (tclass), m_class_get_type_token (tclass), generic_context);
-							} else {
-								mono_error_cleanup (error); /* FIXME don't swallow the error */
-								/* FIXME: n is not a normal token */
-								DISABLE_AOT (cfg);
-								EMIT_NEW_PCONST (cfg, ins, NULL);
-							}
-						} else {
-							EMIT_NEW_TYPE_FROM_HANDLE_CONST (cfg, ins, image, n, generic_context);
-						}
-					} else {
-						MonoReflectionType *rt = mono_type_get_object_checked ((MonoType *)handle, cfg->error);
-						CHECK_CFG_ERROR;
-						EMIT_NEW_PCONST (cfg, ins, rt);
-					}
-					ins->type = STACK_OBJ;
-					ins->klass = mono_defaults.runtimetype_class;
-					il_op = (MonoOpcodeEnum)next_ip [0];
-					next_ip += 5;
-				} else {
-					MonoInst *addr, *vtvar;
-					vtvar = mono_compile_create_var (cfg, m_class_get_byval_arg (handle_class), OP_LOCAL);
-					if (context_used) {
-						if (handle_class == mono_defaults.typehandle_class) {
-							ins = mini_emit_get_rgctx_klass (cfg, context_used,
-									mono_class_from_mono_type_internal ((MonoType *)handle),
-									MONO_RGCTX_INFO_TYPE);
-						} else if (handle_class == mono_defaults.methodhandle_class) {
-							ins = emit_get_rgctx_method (cfg, context_used,
-									(MonoMethod *)handle, MONO_RGCTX_INFO_METHOD);
-						} else if (handle_class == mono_defaults.fieldhandle_class) {
-							ins = emit_get_rgctx_field (cfg, context_used,
-									(MonoClassField *)handle, MONO_RGCTX_INFO_CLASS_FIELD);
-						} else {
-							g_assert_not_reached ();
-						}
-					} else if (cfg->compile_aot) {
-						EMIT_NEW_LDTOKENCONST (cfg, ins, image, n, generic_context);
-					} else {
-						EMIT_NEW_PCONST (cfg, ins, handle);
-					}
-					EMIT_NEW_TEMPLOADA (cfg, addr, vtvar->inst_c0);
-					MONO_EMIT_NEW_STORE_MEMBASE (cfg, OP_STORE_MEMBASE_REG, addr->dreg, 0, ins->dreg);
-					EMIT_NEW_TEMPLOAD (cfg, ins, vtvar->inst_c0);
-					if (handle_class == mono_defaults.fieldhandle_class) {
-						ins->opcode = OP_LDTOKEN_FIELD;
-						ins->inst_c0 = n;
-						ins->inst_p1 = handle;
-						cfg->flags |= MONO_CFG_NEEDS_DECOMPOSE;
-						cfg->cbb->needs_decompose = TRUE;
-					}
-				}
-			}
-			*sp++ = ins;
-			break;
-		}
-		case MONO_CEE_THROW:
-			if (sp [-1]->type != STACK_OBJ)
-				UNVERIFIED;
-			MONO_INST_NEW (cfg, ins, OP_THROW);
-			--sp;
-			ins->sreg1 = sp [0]->dreg;
-			cfg->cbb->out_of_line = TRUE;
-			MONO_ADD_INS (cfg->cbb, ins);
-			MONO_INST_NEW (cfg, ins, OP_NOT_REACHED);
-			MONO_ADD_INS (cfg->cbb, ins);
-			sp = stack_start;
-			link_bblock (cfg, cfg->cbb, end_bblock);
-			start_new_bblock = 1;
-			/* This can complicate code generation for llvm since the return value might not be defined */
-			if (COMPILE_LLVM (cfg))
-				INLINE_FAILURE ("throw");
-			break;
-		case MONO_CEE_ENDFINALLY:
-			if (!ip_in_finally_clause (cfg, GPTRDIFF_TO_INT (ip - header->code)))
-				UNVERIFIED;
-			/* mono_save_seq_point_info () depends on this */
-			if (sp != stack_start)
-				emit_seq_point (cfg, method, ip, FALSE, FALSE);
-			MONO_INST_NEW (cfg, ins, OP_ENDFINALLY);
-			MONO_ADD_INS (cfg->cbb, ins);
-			start_new_bblock = 1;
-			ins_has_side_effect = FALSE;
-			/*
-			 * Control will leave the method so empty the stack, otherwise
-			 * the next basic block will start with a nonempty stack.
-			 */
-			while (sp != stack_start) {
-				sp--;
-			}
-			break;
-		case MONO_CEE_LEAVE:
-		case MONO_CEE_LEAVE_S: {
-			GList *handlers;
-			/* empty the stack */
-			g_assert (sp >= stack_start);
-			sp = stack_start;
-			/*
-			 * If this leave statement is in a catch block, check for a
-			 * pending exception, and rethrow it if necessary.
-			 * We avoid doing this in runtime invoke wrappers, since those are called
-			 * by native code which excepts the wrapper to catch all exceptions.
-			 */
-			for (unsigned int i = 0; i < header->num_clauses; ++i) {
-				MonoExceptionClause *clause = &header->clauses [i];
-				/*
-				 * Use <= in the final comparison to handle clauses with multiple
-				 * leave statements, like in bug #78024.
-				 * The ordering of the exception clauses guarantees that we find the
-				 * innermost clause.
-				 */
-				if (MONO_OFFSET_IN_HANDLER (clause, GPTRDIFF_TO_UINT32(ip - header->code)) && (clause->flags == MONO_EXCEPTION_CLAUSE_NONE) && GPTRDIFF_TO_UINT32(ip - header->code + ((il_op == MONO_CEE_LEAVE) ? 5 : 2)) <= (clause->handler_offset + clause->handler_len) && method->wrapper_type != MONO_WRAPPER_RUNTIME_INVOKE) {
-					MonoInst *exc_ins;
-					MonoBasicBlock *dont_throw;
-					/*
-					  MonoInst *load;
-					  NEW_TEMPLOAD (cfg, load, mono_find_exvar_for_offset (cfg, clause->handler_offset)->inst_c0);
-					*/
-					exc_ins = mono_emit_jit_icall (cfg, mono_thread_get_undeniable_exception, NULL);
-					NEW_BBLOCK (cfg, dont_throw);
-					/*
-					 * Currently, we always rethrow the abort exception, despite the
-					 * fact that this is not correct. See thread6.cs for an example.
-					 * But propagating the abort exception is more important than
-					 * getting the semantics right.
-					 */
-					MONO_EMIT_NEW_BIALU_IMM (cfg, OP_COMPARE_IMM, -1, exc_ins->dreg, 0);
-					MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_PBEQ, dont_throw);
-					MONO_EMIT_NEW_UNALU (cfg, OP_THROW, -1, exc_ins->dreg);
-					MONO_START_BB (cfg, dont_throw);
-				}
-			}
-#ifdef ENABLE_LLVM
-			cfg->cbb->try_end = (intptr_t)(ip - header->code);
-#endif
-			if ((handlers = mono_find_leave_clauses (cfg, ip, target))) {
-				GList *tmp;
-				/*
-				 * For each finally clause that we exit we need to invoke the finally block.
-				 * After each invocation we need to add try holes for all the clauses that
-				 * we already exited.
-				 */
-				for (tmp = handlers; tmp; tmp = tmp->next) {
-					MonoLeaveClause *leave = (MonoLeaveClause *) tmp->data;
-					MonoExceptionClause *clause = leave->clause;
-					if (clause->flags != MONO_EXCEPTION_CLAUSE_FINALLY)
-						continue;
-					MonoInst *abort_exc = (MonoInst *)mono_find_exvar_for_offset (cfg, clause->handler_offset);
-					MonoBasicBlock *dont_throw;
-					/*
-					 * Emit instrumentation code before linking the basic blocks below as this
-					 * will alter cfg->cbb.
-					 */
-					mini_profiler_emit_call_finally (cfg, header, ip, leave->index, clause);
-					tblock = cfg->cil_offset_to_bb [clause->handler_offset];
-					g_assert (tblock);
-					link_bblock (cfg, cfg->cbb, tblock);
-					MONO_EMIT_NEW_PCONST (cfg, abort_exc->dreg, 0);
-					MONO_INST_NEW (cfg, ins, OP_CALL_HANDLER);
-					ins->inst_target_bb = tblock;
-					ins->inst_eh_blocks = tmp;
-					MONO_ADD_INS (cfg->cbb, ins);
-					cfg->cbb->has_call_handler = 1;
-					/* Throw exception if exvar is set */
-					/* FIXME Do we need this for calls from catch/filter ? */
-					NEW_BBLOCK (cfg, dont_throw);
-					MONO_EMIT_NEW_BIALU_IMM (cfg, OP_COMPARE_IMM, -1, abort_exc->dreg, 0);
-					MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_PBEQ, dont_throw);
-					mono_emit_jit_icall (cfg, ves_icall_thread_finish_async_abort, NULL);
-					cfg->cbb->clause_holes = tmp;
-					MONO_START_BB (cfg, dont_throw);
-					cfg->cbb->clause_holes = tmp;
-					if (COMPILE_LLVM (cfg)) {
-						MonoBasicBlock *target_bb;
-						/*
-						 * Link the finally bblock with the target, since it will
-						 * conceptually branch there.
-						 */
-						GET_BBLOCK (cfg, tblock, cfg->cil_start + clause->handler_offset + clause->handler_len - 1);
-						GET_BBLOCK (cfg, target_bb, target);
-						link_bblock (cfg, tblock, target_bb);
-					}
-				}
-			}
-			MONO_INST_NEW (cfg, ins, OP_BR);
-			MONO_ADD_INS (cfg->cbb, ins);
-			GET_BBLOCK (cfg, tblock, target);
-			link_bblock (cfg, cfg->cbb, tblock);
-			ins->inst_target_bb = tblock;
-			start_new_bblock = 1;
-			break;
-		}
-		/*
-		 * Mono specific opcodes
-		 */
-		case MONO_CEE_MONO_ICALL: {
-			g_assert (method->wrapper_type != MONO_WRAPPER_NONE);
-			const MonoJitICallId jit_icall_id = (MonoJitICallId)token;
-			MonoJitICallInfo * const jit_icall_info = mono_find_jit_icall_info (jit_icall_id);
-#ifndef MONO_ARCH_HAVE_SWIFTCALL
-			if (mono_method_signature_has_ext_callconv (method->signature, MONO_EXT_CALLCONV_SWIFTCALL)) {
-				emit_not_supported_failure (cfg);
-			}
-#endif
-			CHECK_STACK (jit_icall_info->sig->param_count);
-			sp -= jit_icall_info->sig->param_count;
-			if (token == MONO_JIT_ICALL_mono_threads_attach_coop) {
-				MonoInst *addr;
-				MonoBasicBlock *next_bb;
-				if (cfg->compile_aot) {
-					/*
-					 * This is called on unattached threads, so it cannot go through the trampoline
-					 * infrastructure. Use an indirect call through a got slot initialized at load time
-					 * instead.
-					 */
-					EMIT_NEW_AOTCONST (cfg, addr, MONO_PATCH_INFO_JIT_ICALL_ADDR_NOCALL, GUINT_TO_POINTER (jit_icall_id));
-					ins = mini_emit_calli (cfg, jit_icall_info->sig, sp, addr, NULL, NULL);
-				} else {
-					ins = mono_emit_jit_icall_id (cfg, jit_icall_id, sp);
-				}
-				/*
-				 * Parts of the initlocals code needs to come after this, since it might call methods like memset.
-				 * Also profiling needs to be after attach.
-				 */
-				init_localsbb2 = cfg->cbb;
-				NEW_BBLOCK (cfg, next_bb);
-				MONO_START_BB (cfg, next_bb);
-			} else {
-				if (token == MONO_JIT_ICALL_mono_threads_detach_coop) {
-					/* can't emit profiling code after a detach, so emit it now */
-					mini_profiler_emit_leave (cfg, NULL);
-					detached_before_ret = TRUE;
-				}
-				ins = mono_emit_jit_icall_id (cfg, jit_icall_id, sp);
-			}
-			if (!MONO_TYPE_IS_VOID (jit_icall_info->sig->ret))
-				*sp++ = ins;
-			inline_costs += CALL_COST * MIN(10, num_calls++);
-			break;
-		}
-		MonoJumpInfoType ldptr_type;
-		case MONO_CEE_MONO_LDPTR_CARD_TABLE:
-			ldptr_type = MONO_PATCH_INFO_GC_CARD_TABLE_ADDR;
-			goto mono_ldptr;
-		case MONO_CEE_MONO_LDPTR_NURSERY_START:
-			ldptr_type = MONO_PATCH_INFO_GC_NURSERY_START;
-			goto mono_ldptr;
-		case MONO_CEE_MONO_LDPTR_NURSERY_BITS:
-			ldptr_type = MONO_PATCH_INFO_GC_NURSERY_BITS;
-			goto mono_ldptr;
-		case MONO_CEE_MONO_LDPTR_INT_REQ_FLAG:
-			ldptr_type = MONO_PATCH_INFO_INTERRUPTION_REQUEST_FLAG;
-			goto mono_ldptr;
-		case MONO_CEE_MONO_LDPTR_PROFILER_ALLOCATION_COUNT:
-			ldptr_type = MONO_PATCH_INFO_PROFILER_ALLOCATION_COUNT;
-mono_ldptr:
-			g_assert (method->wrapper_type != MONO_WRAPPER_NONE);
-			ins = mini_emit_runtime_constant (cfg, ldptr_type, NULL);
-			*sp++ = ins;
-			inline_costs += CALL_COST * MIN(10, num_calls++);
-			break;
-		case MONO_CEE_MONO_LDPTR: {
-			gpointer ptr;
-			g_assert (method->wrapper_type != MONO_WRAPPER_NONE);
-			ptr = mono_method_get_wrapper_data (method, token);
-			EMIT_NEW_PCONST (cfg, ins, ptr);
-			*sp++ = ins;
-			inline_costs += CALL_COST * MIN(10, num_calls++);
-			/* Can't embed random pointers into AOT code */
-			DISABLE_AOT (cfg);
-			break;
-		}
-		case MONO_CEE_MONO_JIT_ICALL_ADDR:
-			g_assert (method->wrapper_type != MONO_WRAPPER_NONE);
-			EMIT_NEW_JIT_ICALL_ADDRCONST (cfg, ins, GUINT_TO_POINTER (token));
-			*sp++ = ins;
-			inline_costs += CALL_COST * MIN(10, num_calls++);
-			break;
-		case MONO_CEE_MONO_ICALL_ADDR: {
-			gpointer ptr;
-			g_assert (method->wrapper_type != MONO_WRAPPER_NONE);
-			cmethod = (MonoMethod *)mono_method_get_wrapper_data (method, token);
-			if (cfg->compile_aot) {
-				if (cfg->direct_pinvoke && ip + 6 < end && (ip [6] == CEE_POP)) {
-					/*
-					 * This is generated by emit_native_wrapper () to resolve the pinvoke address
-					 * before the call, its not needed when using direct pinvoke.
-					 * This is not an optimization, but its used to avoid looking up pinvokes
-					 * on platforms which don't support dlopen ().
-					 */
-					EMIT_NEW_PCONST (cfg, ins, NULL);
-				} else {
-					EMIT_NEW_AOTCONST (cfg, ins, MONO_PATCH_INFO_ICALL_ADDR, cmethod);
-				}
-			} else {
-				ptr = mono_lookup_internal_call (cmethod);
-				g_assert (ptr);
-				EMIT_NEW_PCONST (cfg, ins, ptr);
-			}
-			*sp++ = ins;
-			break;
-		}
-		case MONO_CEE_MONO_VTADDR: {
-			g_assert (method->wrapper_type != MONO_WRAPPER_NONE);
-			MonoInst *src_var, *src;
-			--sp;
-			src_var = get_vreg_to_inst (cfg, sp [0]->dreg);
-			EMIT_NEW_VARLOADA ((cfg), (src), src_var, src_var->inst_vtype);
-			*sp++ = src;
-			break;
-		}
-		case MONO_CEE_MONO_NEWOBJ: {
-			g_assert (method->wrapper_type != MONO_WRAPPER_NONE);
-			MonoInst *iargs [2];
-			klass = (MonoClass *)mono_method_get_wrapper_data (method, token);
-			mono_class_init_internal (klass);
-			NEW_CLASSCONST (cfg, iargs [0], klass);
-			MONO_ADD_INS (cfg->cbb, iargs [0]);
-			*sp++ = mono_emit_jit_icall (cfg, ves_icall_object_new, iargs);
-			inline_costs += CALL_COST * MIN(10, num_calls++);
-			break;
-		}
-		case MONO_CEE_MONO_OBJADDR:
-			g_assert (method->wrapper_type != MONO_WRAPPER_NONE);
-			--sp;
-			MONO_INST_NEW (cfg, ins, OP_MOVE);
-			ins->dreg = alloc_ireg_mp (cfg);
-			ins->sreg1 = sp [0]->dreg;
-			ins->type = STACK_MP;
-			MONO_ADD_INS (cfg->cbb, ins);
-			*sp++ = ins;
-			break;
-		case MONO_CEE_MONO_LDNATIVEOBJ:
-			/*
-			 * Similar to LDOBJ, but instead load the unmanaged
-			 * representation of the vtype to the stack.
-			 */
-			g_assert (method->wrapper_type != MONO_WRAPPER_NONE);
-			--sp;
-			klass = (MonoClass *)mono_method_get_wrapper_data (method, token);
-			g_assert (m_class_is_valuetype (klass));
-			mono_class_init_internal (klass);
-			{
-				MonoInst *src, *dest, *temp;
-				src = sp [0];
-				temp = mono_compile_create_var (cfg, m_class_get_byval_arg (klass), OP_LOCAL);
-				temp->backend.is_pinvoke = 1;
-				EMIT_NEW_TEMPLOADA (cfg, dest, temp->inst_c0);
-				mini_emit_memory_copy (cfg, dest, src, klass, TRUE, 0);
-				EMIT_NEW_TEMPLOAD (cfg, dest, temp->inst_c0);
-				dest->type = STACK_VTYPE;
-				dest->klass = klass;
-				*sp ++ = dest;
-			}
-			break;
-		case MONO_CEE_MONO_RETOBJ: {
-			/*
-			 * Same as RET, but return the native representation of a vtype
-			 * to the caller.
-			 */
-			g_assert (method->wrapper_type != MONO_WRAPPER_NONE);
-			g_assert (cfg->ret);
-			g_assert (mono_method_signature_internal (method)->pinvoke);
-			--sp;
-			klass = (MonoClass *)mono_method_get_wrapper_data (method, token);
-			if (!cfg->vret_addr) {
-				g_assert (cfg->ret_var_is_local);
-				EMIT_NEW_VARLOADA (cfg, ins, cfg->ret, cfg->ret->inst_vtype);
-			} else {
-				EMIT_NEW_RETLOADA (cfg, ins);
-			}
-			mini_emit_memory_copy (cfg, ins, sp [0], klass, TRUE, 0);
-			if (sp != stack_start)
-				UNVERIFIED;
-			if (!detached_before_ret)
-				mini_profiler_emit_leave (cfg, sp [0]);
-			MONO_INST_NEW (cfg, ins, OP_BR);
-			ins->inst_target_bb = end_bblock;
-			MONO_ADD_INS (cfg->cbb, ins);
-			link_bblock (cfg, cfg->cbb, end_bblock);
-			start_new_bblock = 1;
-			break;
-		}
-		case MONO_CEE_MONO_SAVE_LMF:
-		case MONO_CEE_MONO_RESTORE_LMF:
-			g_assert (method->wrapper_type != MONO_WRAPPER_NONE);
-			break;
-		case MONO_CEE_MONO_CLASSCONST:
-			g_assert (method->wrapper_type != MONO_WRAPPER_NONE);
-			EMIT_NEW_CLASSCONST (cfg, ins, mono_method_get_wrapper_data (method, token));
-			*sp++ = ins;
-			inline_costs += CALL_COST * MIN(10, num_calls++);
-			break;
-		case MONO_CEE_MONO_METHODCONST:
-			g_assert (method->wrapper_type != MONO_WRAPPER_NONE);
-			EMIT_NEW_METHODCONST (cfg, ins, mono_method_get_wrapper_data (method, token));
-			*sp++ = ins;
-			break;
-		case MONO_CEE_MONO_PINVOKE_ADDR_CACHE: {
-			g_assert (method->wrapper_type != MONO_WRAPPER_NONE);
-			MonoMethod *pinvoke_method = (MonoMethod*)mono_method_get_wrapper_data (method, token);
-			/* This is a memory slot used by the wrapper */
-			if (cfg->compile_aot) {
-				EMIT_NEW_AOTCONST (cfg, ins, MONO_PATCH_INFO_METHOD_PINVOKE_ADDR_CACHE, pinvoke_method);
-			} else {
-				gpointer addr = mono_mem_manager_alloc0 (cfg->mem_manager, sizeof (gpointer));
-				EMIT_NEW_PCONST (cfg, ins, addr);
-			}
-			*sp++ = ins;
-			break;
-		}
-		case MONO_CEE_MONO_NOT_TAKEN:
-			g_assert (method->wrapper_type != MONO_WRAPPER_NONE);
-			cfg->cbb->out_of_line = TRUE;
-			break;
-		case MONO_CEE_MONO_TLS: {
-			MonoTlsKey key;
-			g_assert (method->wrapper_type != MONO_WRAPPER_NONE);
-			key = (MonoTlsKey)n;
-			g_assert (key < TLS_KEY_NUM);
-			ins = mono_create_tls_get (cfg, key);
-			g_assert (ins);
-			ins->type = STACK_PTR;
-			*sp++ = ins;
-			break;
-		}
-		case MONO_CEE_MONO_DYN_CALL: {
-			MonoCallInst *call;
-			/* It would be easier to call a trampoline, but that would put an
-			 * extra frame on the stack, confusing exception handling. So
-			 * implement it inline using an opcode for now.
-			 */
-			g_assert (method->wrapper_type != MONO_WRAPPER_NONE);
-			if (!cfg->dyn_call_var) {
-				cfg->dyn_call_var = mono_compile_create_var (cfg, mono_get_int_type (), OP_LOCAL);
-				/* prevent it from being register allocated */
-				cfg->dyn_call_var->flags |= MONO_INST_VOLATILE;
-			}
-			/* Has to use a call inst since local regalloc expects it */
-			MONO_INST_NEW_CALL (cfg, call, OP_DYN_CALL);
-			ins = (MonoInst*)call;
-			sp -= 2;
-			ins->sreg1 = sp [0]->dreg;
-			ins->sreg2 = sp [1]->dreg;
-			MONO_ADD_INS (cfg->cbb, ins);
-			cfg->param_area = MAX (cfg->param_area, GINT_TO_UINT(cfg->backend->dyn_call_param_area));
-			/* OP_DYN_CALL might need to allocate a dynamically sized param area */
-			cfg->flags |= MONO_CFG_HAS_ALLOCA;
-			inline_costs += CALL_COST * MIN(10, num_calls++);
-			break;
-		}
-		case MONO_CEE_MONO_MEMORY_BARRIER: {
-			g_assert (method->wrapper_type != MONO_WRAPPER_NONE);
-			mini_emit_memory_barrier (cfg, (int)n);
-			break;
-		}
-		case MONO_CEE_MONO_ATOMIC_STORE_I4: {
-			g_assert (method->wrapper_type != MONO_WRAPPER_NONE);
-			g_assert (mono_arch_opcode_supported (OP_ATOMIC_STORE_I4));
-			sp -= 2;
-			MONO_INST_NEW (cfg, ins, OP_ATOMIC_STORE_I4);
-			ins->dreg = sp [0]->dreg;
-			ins->sreg1 = sp [1]->dreg;
-			ins->backend.memory_barrier_kind = (int)n;
-			MONO_ADD_INS (cfg->cbb, ins);
-			break;
-		}
-		case MONO_CEE_MONO_LD_DELEGATE_METHOD_PTR: {
-			CHECK_STACK (1);
-			--sp;
-			int dreg = alloc_preg (cfg);
-			EMIT_NEW_LOAD_MEMBASE (cfg, ins, OP_LOAD_MEMBASE, dreg, sp [0]->dreg, MONO_STRUCT_OFFSET (MonoDelegate, method_ptr));
-			*sp++ = ins;
-			break;
-		}
-		case MONO_CEE_MONO_CALLI_EXTRA_ARG: {
-			MonoInst *addr;
-			MonoInst *arg;
-			/*
-			 * This is the same as CEE_CALLI, but passes an additional argument
-			 * to the called method in llvmonly mode.
-			 * This is only used by delegate invoke wrappers to call the
-			 * actual delegate method.
-			 */
-			g_assert (method->wrapper_type == MONO_WRAPPER_DELEGATE_INVOKE);
-			ins = NULL;
-			cmethod = NULL;
-			CHECK_STACK (1);
-			--sp;
-			addr = *sp;
-			fsig = mini_get_signature (method, token, generic_context, cfg->error);
-			CHECK_CFG_ERROR;
-			if (cfg->llvm_only)
-				cfg->signatures = g_slist_prepend_mempool (cfg->mempool, cfg->signatures, fsig);
-			n = fsig->param_count + fsig->hasthis + 1;
-			CHECK_STACK (n);
-			sp -= n;
-			arg = sp [n - 1];
-			if (cfg->llvm_only) {
-				/*
-				 * The lowest bit of 'arg' determines whenever the callee uses the gsharedvt
-				 * cconv. This is set by mono_init_delegate ().
-				 */
-				if (cfg->gsharedvt && mini_is_gsharedvt_variable_signature (fsig)) {
-					MonoInst *callee = addr;
-					MonoInst *call, *localloc_ins;
-					MonoBasicBlock *is_gsharedvt_bb, *end_bb;
-					int low_bit_reg = alloc_preg (cfg);
-					NEW_BBLOCK (cfg, is_gsharedvt_bb);
-					NEW_BBLOCK (cfg, end_bb);
-					MONO_EMIT_NEW_BIALU_IMM (cfg, OP_PAND_IMM, low_bit_reg, arg->dreg, 1);
-					MONO_EMIT_NEW_BIALU_IMM (cfg, OP_COMPARE_IMM, -1, low_bit_reg, 0);
-					MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_PBNE_UN, is_gsharedvt_bb);
-					/* Normal case: callee uses a normal cconv, have to add an out wrapper */
-					addr = emit_get_rgctx_sig (cfg, context_used,
-											   fsig, MONO_RGCTX_INFO_SIG_GSHAREDVT_OUT_TRAMPOLINE_CALLI);
-					/*
-					 * ADDR points to a gsharedvt-out wrapper, have to pass <callee, arg> as an extra arg.
-					 */
-					MONO_INST_NEW (cfg, ins, OP_LOCALLOC_IMM);
-					ins->dreg = alloc_preg (cfg);
-					ins->inst_imm = 2 * TARGET_SIZEOF_VOID_P;
-					MONO_ADD_INS (cfg->cbb, ins);
-					localloc_ins = ins;
-					cfg->flags |= MONO_CFG_HAS_ALLOCA;
-					MONO_EMIT_NEW_STORE_MEMBASE (cfg, OP_STORE_MEMBASE_REG, localloc_ins->dreg, 0, callee->dreg);
-					MONO_EMIT_NEW_STORE_MEMBASE (cfg, OP_STORE_MEMBASE_REG, localloc_ins->dreg, TARGET_SIZEOF_VOID_P, arg->dreg);
-					call = mini_emit_extra_arg_calli (cfg, fsig, sp, localloc_ins->dreg, addr);
-					MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_BR, end_bb);
-					/* Gsharedvt case: callee uses a gsharedvt cconv, no conversion is needed */
-					MONO_START_BB (cfg, is_gsharedvt_bb);
-					MONO_EMIT_NEW_BIALU_IMM (cfg, OP_PXOR_IMM, arg->dreg, arg->dreg, 1);
-					ins = mini_emit_extra_arg_calli (cfg, fsig, sp, arg->dreg, callee);
-					ins->dreg = call->dreg;
-					MONO_START_BB (cfg, end_bb);
-				} else {
-					/* Caller uses a normal calling conv */
-					MonoInst *callee = addr;
-					MonoInst *call, *localloc_ins;
-					MonoBasicBlock *is_gsharedvt_bb, *end_bb;
-					int low_bit_reg = alloc_preg (cfg);
-					NEW_BBLOCK (cfg, is_gsharedvt_bb);
-					NEW_BBLOCK (cfg, end_bb);
-					MONO_EMIT_NEW_BIALU_IMM (cfg, OP_PAND_IMM, low_bit_reg, arg->dreg, 1);
-					MONO_EMIT_NEW_BIALU_IMM (cfg, OP_COMPARE_IMM, -1, low_bit_reg, 0);
-					MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_PBNE_UN, is_gsharedvt_bb);
-					/* Normal case: callee uses a normal cconv, no conversion is needed */
-					call = mini_emit_extra_arg_calli (cfg, fsig, sp, arg->dreg, callee);
-					MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_BR, end_bb);
-					/* Gsharedvt case: callee uses a gsharedvt cconv, have to add an in wrapper */
-					MONO_START_BB (cfg, is_gsharedvt_bb);
-					MONO_EMIT_NEW_BIALU_IMM (cfg, OP_PXOR_IMM, arg->dreg, arg->dreg, 1);
-					NEW_AOTCONST (cfg, addr, MONO_PATCH_INFO_GSHAREDVT_IN_WRAPPER, fsig);
-					MONO_ADD_INS (cfg->cbb, addr);
-					/*
-					 * ADDR points to a gsharedvt-in wrapper, have to pass <callee, arg> as an extra arg.
-					 */
-					MONO_INST_NEW (cfg, ins, OP_LOCALLOC_IMM);
-					ins->dreg = alloc_preg (cfg);
-					ins->inst_imm = 2 * TARGET_SIZEOF_VOID_P;
-					MONO_ADD_INS (cfg->cbb, ins);
-					localloc_ins = ins;
-					cfg->flags |= MONO_CFG_HAS_ALLOCA;
-					MONO_EMIT_NEW_STORE_MEMBASE (cfg, OP_STORE_MEMBASE_REG, localloc_ins->dreg, 0, callee->dreg);
-					MONO_EMIT_NEW_STORE_MEMBASE (cfg, OP_STORE_MEMBASE_REG, localloc_ins->dreg, TARGET_SIZEOF_VOID_P, arg->dreg);
-					ins = mini_emit_extra_arg_calli (cfg, fsig, sp, localloc_ins->dreg, addr);
-					ins->dreg = call->dreg;
-					MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_BR, end_bb);
-					MONO_START_BB (cfg, end_bb);
-				}
-			} else {
-				/* Same as CEE_CALLI */
-				if (cfg->gsharedvt && mini_is_gsharedvt_signature (fsig)) {
-					/*
-					 * We pass the address to the gsharedvt trampoline in the rgctx reg
-					 */
-					MonoInst *callee = addr;
-					addr = emit_get_rgctx_sig (cfg, context_used,
-											   fsig, MONO_RGCTX_INFO_SIG_GSHAREDVT_OUT_TRAMPOLINE_CALLI);
-					ins = (MonoInst*)mini_emit_calli (cfg, fsig, sp, addr, NULL, callee);
-				} else {
-					ins = (MonoInst*)mini_emit_calli (cfg, fsig, sp, addr, NULL, NULL);
-				}
-			}
-			if (!MONO_TYPE_IS_VOID (fsig->ret))
-				*sp++ = mono_emit_widen_call_res (cfg, ins, fsig);
-			CHECK_CFG_EXCEPTION;
-			ins_flag = 0;
-			constrained_class = NULL;
-			break;
-		}
-		case MONO_CEE_MONO_LDDOMAIN: {
-			MonoDomain *domain = mono_get_root_domain ();
-			g_assert (method->wrapper_type != MONO_WRAPPER_NONE);
-			EMIT_NEW_PCONST (cfg, ins, cfg->compile_aot ? NULL : domain);
-			*sp++ = ins;
-			break;
-		}
-		case MONO_CEE_MONO_SAVE_LAST_ERROR:
-			g_assert (method->wrapper_type != MONO_WRAPPER_NONE);
-			save_last_error = TRUE;
-			break;
-		case MONO_CEE_MONO_GET_RGCTX_ARG:
-			g_assert (method->wrapper_type != MONO_WRAPPER_NONE);
-			mono_create_rgctx_var (cfg);
-			MONO_INST_NEW (cfg, ins, OP_MOVE);
-			ins->dreg = alloc_dreg (cfg, STACK_PTR);
-			ins->sreg1 = cfg->rgctx_var->dreg;
-			ins->type = STACK_PTR;
-			MONO_ADD_INS (cfg->cbb, ins);
-			*sp++ = ins;
-			break;
-		case MONO_CEE_MONO_GET_SP: {
-			/* Used by COOP only, so this is good enough */
-			MonoInst *var = mono_compile_create_var (cfg, mono_get_int_type (), OP_LOCAL);
-			EMIT_NEW_VARLOADA (cfg, ins, var, NULL);
-			*sp++ = ins;
-			break;
-		}
-		case MONO_CEE_MONO_REMAP_OVF_EXC:
-			/* Remap the exception thrown by the next _OVF opcode */
-			g_assert (method->wrapper_type != MONO_WRAPPER_NONE);
-			ovf_exc = (const char*)mono_method_get_wrapper_data (method, token);
-			break;
-		case MONO_CEE_ARGLIST: {
-			/* somewhat similar to LDTOKEN */
-			MonoInst *addr, *vtvar;
-			vtvar = mono_compile_create_var (cfg, m_class_get_byval_arg (mono_defaults.argumenthandle_class), OP_LOCAL);
-			EMIT_NEW_TEMPLOADA (cfg, addr, vtvar->inst_c0);
-			EMIT_NEW_UNALU (cfg, ins, OP_ARGLIST, -1, addr->dreg);
-			EMIT_NEW_TEMPLOAD (cfg, ins, vtvar->inst_c0);
-			ins->type = STACK_VTYPE;
-			ins->klass = mono_defaults.argumenthandle_class;
-			*sp++ = ins;
-			break;
-		}
-		case MONO_CEE_CEQ:
-		case MONO_CEE_CGT:
-		case MONO_CEE_CGT_UN:
-		case MONO_CEE_CLT:
-		case MONO_CEE_CLT_UN: {
-			MonoInst *cmp, *arg1, *arg2;
-			sp -= 2;
-			arg1 = sp [0];
-			arg2 = sp [1];
-			/*
-			 * The following transforms:
-			 *    CEE_CEQ    into OP_CEQ
-			 *    CEE_CGT    into OP_CGT
-			 *    CEE_CGT_UN into OP_CGT_UN
-			 *    CEE_CLT    into OP_CLT
-			 *    CEE_CLT_UN into OP_CLT_UN
-			 */
-			MONO_INST_NEW (cfg, cmp, (OP_CEQ - CEE_CEQ) + ip [1]);
-			MONO_INST_NEW (cfg, ins, cmp->opcode);
-			cmp->sreg1 = arg1->dreg;
-			cmp->sreg2 = arg2->dreg;
-			type_from_op (cfg, cmp, arg1, arg2);
-			CHECK_TYPE (cmp);
-			add_widen_op (cfg, cmp, &arg1, &arg2);
-			if ((arg1->type == STACK_I8) || ((TARGET_SIZEOF_VOID_P == 8) && ((arg1->type == STACK_PTR) || (arg1->type == STACK_OBJ) || (arg1->type == STACK_MP))))
-				cmp->opcode = OP_LCOMPARE;
-			else if (arg1->type == STACK_R4)
-				cmp->opcode = OP_RCOMPARE;
-			else if (arg1->type == STACK_R8)
-				cmp->opcode = OP_FCOMPARE;
-			else
-				cmp->opcode = OP_ICOMPARE;
-			MONO_ADD_INS (cfg->cbb, cmp);
-			ins->type = STACK_I4;
-			ins->dreg = alloc_dreg (cfg, (MonoStackType)ins->type);
-			type_from_op (cfg, ins, arg1, arg2);
-			if (cmp->opcode == OP_FCOMPARE || cmp->opcode == OP_RCOMPARE) {
-				/*
-				 * The backends expect the fceq opcodes to do the
-				 * comparison too.
-				 */
-				ins->sreg1 = cmp->sreg1;
-				ins->sreg2 = cmp->sreg2;
-				NULLIFY_INS (cmp);
-			}
-			MONO_ADD_INS (cfg->cbb, ins);
-			*sp++ = ins;
-			break;
-		}
-		case MONO_CEE_LDFTN: {
-			MonoInst *argconst;
-			MonoMethod *cil_method;
-			gboolean gshared_static_virtual = FALSE;
-			cil_method = cmethod = mini_get_method (cfg, method, n, NULL, generic_context);
-			CHECK_CFG_ERROR;
-			if (!dont_verify && !cfg->skip_visibility && !mono_method_can_access_method (method, cmethod))
-				emit_method_access_failure (cfg, method, cil_method);
-			if (constrained_class) {
-				if (m_method_is_static (cmethod) && mini_class_check_context_used (cfg, constrained_class)) {
-					gshared_static_virtual = TRUE;
-				} else {
-					cmethod = get_constrained_method (cfg, image, n, cmethod, constrained_class, generic_context);
-					CHECK_CFG_ERROR;
-					if (mono_class_has_dim_conflicts (constrained_class) &&
-							mono_class_is_method_ambiguous (constrained_class, cil_method))
-						mono_emit_jit_icall (cfg, mono_throw_ambiguous_implementation, NULL);
-					constrained_class = NULL;
-				}
-			} else {
-				mono_save_token_info (cfg, image, n, cmethod);
-			}
-			mono_class_init_internal (cmethod->klass);
-			context_used = mini_method_check_context_used (cfg, cmethod);
-			const gboolean has_unmanaged_callers_only =
-				cmethod->wrapper_type == MONO_WRAPPER_NONE &&
-				mono_method_has_unmanaged_callers_only_attribute (cmethod);
-			/*
-			 * Optimize the common case of ldftn+delegate creation
-			 */
-			if (!gshared_static_virtual && (sp > stack_start) && (next_ip + 4 < end) && ip_in_bb (cfg, cfg->cbb, next_ip) && (next_ip [0] == CEE_NEWOBJ)) {
-				MonoMethod *ctor_method = mini_get_method (cfg, method, read32 (next_ip + 1), NULL, generic_context);
-				if (ctor_method && (m_class_get_parent (ctor_method->klass) == mono_defaults.multicastdelegate_class)) {
-					MonoInst *target_ins, *handle_ins;
-					MonoMethod *invoke;
-					int invoke_context_used;
-					if (G_UNLIKELY (has_unmanaged_callers_only)) {
-						mono_error_set_not_supported (cfg->error, "Cannot create delegate from method with UnmanagedCallersOnlyAttribute");
-						CHECK_CFG_ERROR;
-					}
-					invoke = mono_get_delegate_invoke_internal (ctor_method->klass);
-					if (!invoke || !mono_method_signature_internal (invoke))
-						LOAD_ERROR;
-					invoke_context_used = mini_method_check_context_used (cfg, invoke);
-					target_ins = sp [-1];
-					if (!(cmethod->flags & METHOD_ATTRIBUTE_STATIC)) {
-						/*BAD IMPL: We must not add a null check for virtual invoke delegates.*/
-						if (mono_method_signature_internal (invoke)->param_count == mono_method_signature_internal (cmethod)->param_count) {
-							MONO_EMIT_NEW_BIALU_IMM (cfg, OP_COMPARE_IMM, -1, target_ins->dreg, 0);
-							MONO_EMIT_NEW_COND_EXC (cfg, EQ, "ArgumentException");
-						}
-					}
-					if ((invoke_context_used == 0 || !cfg->gsharedvt) || cfg->llvm_only) {
-						if (cfg->verbose_level > 3)
-							g_print ("converting (in B%d: stack: %d) %s", cfg->cbb->block_num, GPTRDIFF_TO_INT (sp - stack_start), mono_disasm_code_one (NULL, method, ip + 6, NULL));
-						if ((handle_ins = handle_delegate_ctor (cfg, ctor_method->klass, target_ins, cmethod, context_used, invoke_context_used, FALSE))) {
-							sp --;
-							*sp = handle_ins;
-							CHECK_CFG_EXCEPTION;
-							sp ++;
-							next_ip += 5;
-							il_op = MONO_CEE_NEWOBJ;
-							break;
-						} else {
-							CHECK_CFG_ERROR;
-						}
-					}
-				}
-			}
-			/* UnmanagedCallersOnlyAttribute means ldftn should return a method callable from native */
-			if (G_UNLIKELY (has_unmanaged_callers_only)) {
-				if (G_UNLIKELY (cmethod->flags & METHOD_ATTRIBUTE_PINVOKE_IMPL)) {
-					emit_not_supported_failure (cfg);
-					EMIT_NEW_PCONST (cfg, ins, NULL);
-					*sp++ = ins;
-					inline_costs += CALL_COST * MIN(10, num_calls++);
-					break;
-				}
-				MonoClass *delegate_klass = NULL;
-				MonoGCHandle target_handle = 0;
-				ERROR_DECL (wrapper_error);
-				MonoMethod *wrapped_cmethod;
-				wrapped_cmethod = mono_marshal_get_managed_wrapper (cmethod, delegate_klass, target_handle, wrapper_error);
-				if (!is_ok (wrapper_error)) {
-					/* if we couldn't create a wrapper because cmethod isn't supposed to have an
-					UnmanagedCallersOnly attribute, follow CoreCLR behavior and throw when the
-					method with the ldftn is executing, not when it is being compiled. */
-					char *err_msg = mono_mem_manager_strdup (cfg->mem_manager, mono_error_get_message (wrapper_error));
-					emit_invalid_program_with_msg (cfg, err_msg);
-					mono_error_cleanup (wrapper_error);
-					EMIT_NEW_PCONST (cfg, ins, NULL);
-					*sp++ = ins;
-					inline_costs += CALL_COST * MIN(10, num_calls++);
-					break;
-				} else {
-					cmethod = wrapped_cmethod;
-				}
-			}
-			if (gshared_static_virtual) {
-				argconst = emit_get_rgctx_virt_method (cfg, -1, constrained_class, cmethod, MONO_RGCTX_INFO_VIRT_METHOD);
-				constrained_class = NULL;
-			} else {
-				argconst = emit_get_rgctx_method (cfg, context_used, cmethod, MONO_RGCTX_INFO_METHOD);
-			}
-			ins = mono_emit_jit_icall (cfg, mono_ldftn, &argconst);
-			*sp++ = ins;
-			inline_costs += CALL_COST * MIN(10, num_calls++);
-			break;
-		}
-		case MONO_CEE_LDVIRTFTN: {
-			MonoInst *args [2];
-			cmethod = mini_get_method (cfg, method, n, NULL, generic_context);
-			CHECK_CFG_ERROR;
-			mono_class_init_internal (cmethod->klass);
-			context_used = mini_method_check_context_used (cfg, cmethod);
-			/*
-			 * Optimize the common case of ldvirtftn+delegate creation
-			 */
-			if (previous_il_op == MONO_CEE_DUP && (sp > stack_start) && (next_ip + 4 < end) && ip_in_bb (cfg, cfg->cbb, next_ip) && (next_ip [0] == CEE_NEWOBJ)) {
-				MonoMethod *ctor_method = mini_get_method (cfg, method, read32 (next_ip + 1), NULL, generic_context);
-				if (ctor_method && (m_class_get_parent (ctor_method->klass) == mono_defaults.multicastdelegate_class)) {
-					MonoInst *target_ins, *handle_ins;
-					MonoMethod *invoke;
-					int invoke_context_used;
-					const gboolean is_virtual = (cmethod->flags & METHOD_ATTRIBUTE_VIRTUAL) != 0;
-					invoke = mono_get_delegate_invoke_internal (ctor_method->klass);
-					if (!invoke || !mono_method_signature_internal (invoke))
-						LOAD_ERROR;
-					invoke_context_used = mini_method_check_context_used (cfg, invoke);
-					target_ins = sp [-1];
-					if (invoke_context_used == 0 || !cfg->gsharedvt || cfg->llvm_only) {
-						if (cfg->verbose_level > 3)
-							g_print ("converting (in B%d: stack: %d) %s", cfg->cbb->block_num, GPTRDIFF_TO_INT (sp - stack_start), mono_disasm_code_one (NULL, method, ip + 6, NULL));
-						if ((handle_ins = handle_delegate_ctor (cfg, ctor_method->klass, target_ins, cmethod, context_used, invoke_context_used, is_virtual))) {
-							sp -= 2;
-							*sp = handle_ins;
-							CHECK_CFG_EXCEPTION;
-							next_ip += 5;
-							previous_il_op = MONO_CEE_NEWOBJ;
-							sp ++;
-							break;
-						} else {
-							CHECK_CFG_ERROR;
-						}
-					}
-				}
-			}
-			--sp;
-			args [0] = *sp;
-			args [1] = emit_get_rgctx_method (cfg, context_used,
-											  cmethod, MONO_RGCTX_INFO_METHOD);
-			if (context_used)
-				*sp++ = mono_emit_jit_icall (cfg, mono_ldvirtfn_gshared, args);
-			else
-				*sp++ = mono_emit_jit_icall (cfg, mono_ldvirtfn, args);
-			inline_costs += CALL_COST * MIN(10, num_calls++);
-			break;
-		}
-		case MONO_CEE_LOCALLOC: {
-			MonoBasicBlock *non_zero_bb, *end_bb;
-			int alloc_ptr = alloc_preg (cfg);
-			--sp;
-			if (sp != stack_start)
-				UNVERIFIED;
-			if (cfg->method != method)
-				/*
-				 * Inlining this into a loop in a parent could lead to
-				 * stack overflows which is different behavior than the
-				 * non-inlined case, thus disable inlining in this case.
-				 */
-				INLINE_FAILURE("localloc");
-			NEW_BBLOCK (cfg, non_zero_bb);
-			NEW_BBLOCK (cfg, end_bb);
-			/* if size != zero */
-			MONO_EMIT_NEW_BIALU_IMM (cfg, OP_COMPARE_IMM, -1, sp [0]->dreg, 0);
-			MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_PBNE_UN, non_zero_bb);
-			MONO_EMIT_NEW_PCONST (cfg, alloc_ptr, NULL);
-			MONO_EMIT_NEW_BRANCH_BLOCK (cfg, OP_BR, end_bb);
-			MONO_START_BB (cfg, non_zero_bb);
-			MONO_INST_NEW (cfg, ins, OP_LOCALLOC);
-			ins->dreg = alloc_ptr;
-			ins->sreg1 = sp [0]->dreg;
-			ins->type = STACK_PTR;
-			MONO_ADD_INS (cfg->cbb, ins);
-			cfg->flags |= MONO_CFG_HAS_ALLOCA;
-			if (header->init_locals)
-				ins->flags |= MONO_INST_INIT;
-			MONO_START_BB (cfg, end_bb);
-			EMIT_NEW_UNALU (cfg, ins, OP_MOVE, alloc_preg (cfg), alloc_ptr);
-			ins->type = STACK_PTR;
-			*sp++ = ins;
-			break;
-		}
-		case MONO_CEE_ENDFILTER: {
-			MonoExceptionClause *clause, *nearest;
-			--sp;
-			if ((sp != stack_start) || (sp [0]->type != STACK_I4))
-				UNVERIFIED;
-			MONO_INST_NEW (cfg, ins, OP_ENDFILTER);
-			ins->sreg1 = (*sp)->dreg;
-			MONO_ADD_INS (cfg->cbb, ins);
-			start_new_bblock = 1;
-			nearest = NULL;
-			for (guint cc = 0; cc < header->num_clauses; ++cc) {
-				clause = &header->clauses [cc];
-				if ((clause->flags & MONO_EXCEPTION_CLAUSE_FILTER) &&
-					(GPTRDIFF_TO_UINT32(next_ip - header->code) > clause->data.filter_offset && GPTRDIFF_TO_UINT32(next_ip - header->code) <= clause->handler_offset) &&
-				    (!nearest || (clause->data.filter_offset < nearest->data.filter_offset)))
-					nearest = clause;
-			}
-			g_assert (nearest);
-			if ((next_ip - header->code) != nearest->handler_offset)
-				UNVERIFIED;
-			break;
-		}
-		case MONO_CEE_UNALIGNED_:
-			ins_flag |= MONO_INST_UNALIGNED;
-			/* FIXME: record alignment? we can assume 1 for now */
-			break;
-		case MONO_CEE_VOLATILE_:
-			ins_flag |= MONO_INST_VOLATILE;
-			break;
-		case MONO_CEE_TAIL_:
-			ins_flag   |= MONO_INST_TAILCALL;
-			cfg->flags |= MONO_CFG_HAS_TAILCALL;
-			/* Can't inline tailcalls at this time */
-			inline_costs += 100000;
-			break;
-		case MONO_CEE_INITOBJ:
-			klass = mini_get_class (method, token, generic_context);
-			if (CLASS_HAS_FAILURE (klass)) {
-				HANDLE_TYPELOAD_ERROR (cfg, klass);
-				inline_costs += 10;
-				break; // reached only in AOT
-			}
-			--sp;
-			if (mini_class_is_reference (klass))
-				MONO_EMIT_NEW_STORE_MEMBASE_IMM (cfg, OP_STORE_MEMBASE_IMM, sp [0]->dreg, 0, 0);
-			else
-				mini_emit_initobj (cfg, *sp, NULL, klass);
-			inline_costs += 1;
-			break;
-		case MONO_CEE_CONSTRAINED_:
-			constrained_class = mini_get_class (method, token, generic_context);
-			CHECK_TYPELOAD (constrained_class);
-			ins_has_side_effect = FALSE;
-			break;
-		case MONO_CEE_CPBLK:
-			sp -= 3;
-			mini_emit_memory_copy_bytes (cfg, sp [0], sp [1], sp [2], ins_flag);
-			ins_flag = 0;
-			inline_costs += 1;
-			break;
-		case MONO_CEE_INITBLK:
-			sp -= 3;
-			mini_emit_memory_init_bytes (cfg, sp [0], sp [1], sp [2], ins_flag);
-			ins_flag = 0;
-			inline_costs += 1;
-			break;
-		case MONO_CEE_NO_:
-			if (ip [2] & CEE_NO_TYPECHECK)
-				ins_flag |= MONO_INST_NOTYPECHECK;
-			if (ip [2] & CEE_NO_RANGECHECK)
-				ins_flag |= MONO_INST_NORANGECHECK;
-			if (ip [2] & CEE_NO_NULLCHECK)
-				ins_flag |= MONO_INST_NONULLCHECK;
-			break;
-		case MONO_CEE_RETHROW: {
-			MonoInst *load;
-			int handler_offset = -1;
-			for (unsigned int i = 0; i < header->num_clauses; ++i) {
-				MonoExceptionClause *clause = &header->clauses [i];
-				if (MONO_OFFSET_IN_HANDLER (clause, GPTRDIFF_TO_UINT32(ip - header->code)) && !(clause->flags & MONO_EXCEPTION_CLAUSE_FINALLY)) {
-					handler_offset = clause->handler_offset;
-					break;
-				}
-			}
-			cfg->cbb->flags |= BB_EXCEPTION_UNSAFE;
-			if (handler_offset == -1)
-				UNVERIFIED;
-			EMIT_NEW_TEMPLOAD (cfg, load, mono_find_exvar_for_offset (cfg, handler_offset)->inst_c0);
-			MONO_INST_NEW (cfg, ins, OP_RETHROW);
-			ins->sreg1 = load->dreg;
-			MONO_ADD_INS (cfg->cbb, ins);
-			MONO_INST_NEW (cfg, ins, OP_NOT_REACHED);
-			MONO_ADD_INS (cfg->cbb, ins);
-			sp = stack_start;
-			link_bblock (cfg, cfg->cbb, end_bblock);
-			start_new_bblock = 1;
-			break;
-		}
-		case MONO_CEE_MONO_RETHROW: {
-			if (sp [-1]->type != STACK_OBJ)
-				UNVERIFIED;
-			MONO_INST_NEW (cfg, ins, OP_RETHROW);
-			--sp;
-			ins->sreg1 = sp [0]->dreg;
-			cfg->cbb->out_of_line = TRUE;
-			MONO_ADD_INS (cfg->cbb, ins);
-			MONO_INST_NEW (cfg, ins, OP_NOT_REACHED);
-			MONO_ADD_INS (cfg->cbb, ins);
-			sp = stack_start;
-			link_bblock (cfg, cfg->cbb, end_bblock);
-			start_new_bblock = 1;
-			/* This can complicate code generation for llvm since the return value might not be defined */
-			if (COMPILE_LLVM (cfg))
-				INLINE_FAILURE ("mono_rethrow");
-			break;
-		}
-		case MONO_CEE_SIZEOF: {
-			guint32 val;
-			int ialign;
-			if (mono_metadata_token_table (token) == MONO_TABLE_TYPESPEC && !image_is_dynamic (m_class_get_image (method->klass)) && !generic_context) {
-				MonoType *type = mono_type_create_from_typespec_checked (image, token, cfg->error);
-				CHECK_CFG_ERROR;
-				val = mono_type_size (type, &ialign);
-				EMIT_NEW_ICONST (cfg, ins, val);
-			} else {
-				klass = mini_get_class (method, token, generic_context);
-				if (CLASS_HAS_FAILURE (klass)) {
-					HANDLE_TYPELOAD_ERROR (cfg, klass);
-					EMIT_NEW_ICONST(cfg, ins, 0);
-					*sp++ = ins;
-					break;
-				}
-				if (mini_is_gsharedvt_klass (klass)) {
-					ins = mini_emit_get_gsharedvt_info_klass (cfg, klass, MONO_RGCTX_INFO_CLASS_SIZEOF);
-					ins->type = STACK_I4;
-				} else {
-					val = mono_type_size (m_class_get_byval_arg (klass), &ialign);
-					EMIT_NEW_ICONST (cfg, ins, val);
-				}
-			}
-			*sp++ = ins;
-			break;
-		}
-		case MONO_CEE_REFANYTYPE: {
-			MonoInst *src_var, *src;
-			GSHAREDVT_FAILURE (il_op);
-			--sp;
-			src_var = get_vreg_to_inst (cfg, sp [0]->dreg);
-			if (!src_var)
-				src_var = mono_compile_create_var_for_vreg (cfg, m_class_get_byval_arg (mono_defaults.typed_reference_class), OP_LOCAL, sp [0]->dreg);
-			EMIT_NEW_VARLOADA (cfg, src, src_var, src_var->inst_vtype);
-			EMIT_NEW_LOAD_MEMBASE_TYPE (cfg, ins, m_class_get_byval_arg (mono_defaults.typehandle_class), src->dreg, MONO_STRUCT_OFFSET (MonoTypedRef, type));
-			*sp++ = ins;
-			break;
-		}
-		case MONO_CEE_READONLY_:
-			readonly = TRUE;
-			break;
-		case MONO_CEE_UNUSED56:
-		case MONO_CEE_UNUSED57:
-		case MONO_CEE_UNUSED70:
-		case MONO_CEE_UNUSED:
-		case MONO_CEE_UNUSED99:
-		case MONO_CEE_UNUSED58:
-		case MONO_CEE_UNUSED1:
-			UNVERIFIED;
-		default:
-			g_warning ("opcode 0x%02x not handled", il_op);
-			UNVERIFIED;
-		}
-		if (ins_has_side_effect)
-			cfg->cbb->flags |= BB_HAS_SIDE_EFFECTS;
-	}
-	if (start_new_bblock != 1)
-		UNVERIFIED;
-all_bbs_done:
-	cfg->cbb->cil_length = GPTRDIFF_TO_INT32 (ip - cfg->cbb->cil_code);
-	if (cfg->cbb->next_bb) {
-		/* This could already be set because of inlining, #693905 */
-		MonoBasicBlock *cbb = cfg->cbb;
-		while (cbb->next_bb)
-			cbb = cbb->next_bb;
-		cbb->next_bb = end_bblock;
-	} else {
-		cfg->cbb->next_bb = end_bblock;
-	}
-#if defined(TARGET_POWERPC) || defined(TARGET_X86)
-	if (cfg->compile_aot)
-		/* FIXME: The plt slots require a GOT var even if the method doesn't use it */
-		mono_get_got_var (cfg);
-#endif
-#ifdef TARGET_WASM
-	if (cfg->lmf_var && !cfg->deopt) {
-		cfg->cbb = init_localsbb;
-		EMIT_NEW_VARLOADA (cfg, ins, cfg->lmf_var, NULL);
-		int lmf_reg = ins->dreg;
-		EMIT_NEW_STORE_MEMBASE (cfg, ins, OP_STORE_MEMBASE_IMM, lmf_reg, MONO_STRUCT_OFFSET (MonoLMF, previous_lmf), 0);
-	}
-#endif
-	if (cfg->method == method && cfg->got_var)
-		mono_emit_load_got_addr (cfg);
-	if (init_localsbb) {
-		cfg->cbb = init_localsbb;
-		cfg->ip = NULL;
-		for (int i = 0; i < header->num_locals; ++i) {
-			/*
-			 * Vtype initialization might need to be done after CEE_JIT_ATTACH, since it can make calls to memset (),
-			 * which need the trampoline code to work.
-			 */
-			if (MONO_TYPE_ISSTRUCT (header->locals [i]))
-				cfg->cbb = init_localsbb2;
-			else
-				cfg->cbb = init_localsbb;
-			emit_init_local (cfg, i, header->locals [i], init_locals);
-		}
-	}
-	if (cfg->init_ref_vars && cfg->method == method) {
-		/* Emit initialization for ref vars */
-		for (guint i = 0; i < cfg->num_varinfo; ++i) {
-			MonoInst *var_ins = cfg->varinfo [i];
-			if (var_ins->opcode == OP_LOCAL && var_ins->type == STACK_OBJ)
-				MONO_EMIT_NEW_PCONST (cfg, var_ins->dreg, NULL);
-		}
-	}
-	if (cfg->lmf_var && cfg->method == method && !cfg->llvm_only) {
-		cfg->cbb = init_localsbb;
-		emit_push_lmf (cfg);
-	}
-	/* emit profiler enter code after a jit attach if there is one */
-	cfg->cbb = init_localsbb2;
-	mini_profiler_emit_enter (cfg);
-	cfg->cbb = init_localsbb;
-	if (seq_points) {
-		MonoBasicBlock *cbb;
-		/*
-		 * Make seq points at backward branch targets interruptible.
-		 */
-		for (cbb = cfg->bb_entry; cbb; cbb = cbb->next_bb)
-			if (cbb->code && cbb->in_count > 1 && cbb->code->opcode == OP_SEQ_POINT)
-				cbb->code->flags |= MONO_INST_SINGLE_STEP_LOC;
-	}
-	/* Add a sequence point for method entry/exit events */
-	if (seq_points && cfg->gen_sdb_seq_points) {
-		NEW_SEQ_POINT (cfg, ins, METHOD_ENTRY_IL_OFFSET, FALSE);
-		MONO_ADD_INS (init_localsbb, ins);
-		NEW_SEQ_POINT (cfg, ins, METHOD_EXIT_IL_OFFSET, FALSE);
-		MONO_ADD_INS (cfg->bb_exit, ins);
-	}
-	/*
-	 * Add seq points for IL offsets which have line number info, but wasn't generated a seq point during JITting because
-	 * the code they refer to was dead (#11880).
-	 */
-	if (sym_seq_points) {
-		for (guint32 i = 0; i < header->code_size; ++i) {
-			if (mono_bitset_test_fast (seq_point_locs, i) && !mono_bitset_test_fast (seq_point_set_locs, i)) {
-				MonoInst *seq_point_ins;
-				NEW_SEQ_POINT (cfg, seq_point_ins, i, FALSE);
-				mono_add_seq_point (cfg, NULL, seq_point_ins, SEQ_POINT_NATIVE_OFFSET_DEAD_CODE);
-			}
-		}
-	}
-	cfg->ip = NULL;
-	if (cfg->method == method) {
-		compute_bb_regions (cfg);
-	} else {
-		MonoBasicBlock *cbb;
-		/* get_most_deep_clause () in mini-llvm.c depends on this for inlined bblocks */
-		for (cbb = start_bblock; cbb != end_bblock; cbb  = cbb->next_bb) {
-			cbb->real_offset = inline_offset;
-		}
-	}
-	if (inline_costs < 0) {
-		char *mname;
-		/* Method is too large */
-		mname = mono_method_full_name (method, TRUE);
-		mono_cfg_set_exception_invalid_program (cfg, g_strdup_printf ("Method %s is too complex.", mname));
-		g_free (mname);
-	}
-	if ((cfg->verbose_level > 2) && (cfg->method == method))
-		mono_print_code (cfg, "AFTER METHOD-TO-IR");
-	goto cleanup;
-mono_error_exit:
-	if (cfg->verbose_level > 3)
-		g_print ("exiting due to error\n");
-	g_assert (!is_ok (cfg->error));
-	goto cleanup;
- exception_exit:
-	if (cfg->verbose_level > 3)
-		g_print ("exiting due to exception\n");
-	g_assert (cfg->exception_type != MONO_EXCEPTION_NONE);
-	goto cleanup;
- unverified:
-	if (cfg->verbose_level > 3)
-		g_print ("exiting due to invalid il\n");
-	set_exception_type_from_invalid_il (cfg, method, ip);
-	goto cleanup;
- cleanup:
-	g_slist_free (class_inits);
-	mono_basic_block_free (original_bb);
-	cfg->dont_inline = g_list_remove (cfg->dont_inline, method);
-	if (cfg->exception_type)
-		return -1;
-	else
-		return inline_costs;
-}
-static int
-store_membase_reg_to_store_membase_imm (int opcode)
-{
-	switch (opcode) {
-	case OP_STORE_MEMBASE_REG:
-		return OP_STORE_MEMBASE_IMM;
-	case OP_STOREI1_MEMBASE_REG:
-		return OP_STOREI1_MEMBASE_IMM;
-	case OP_STOREI2_MEMBASE_REG:
-		return OP_STOREI2_MEMBASE_IMM;
-	case OP_STOREI4_MEMBASE_REG:
-		return OP_STOREI4_MEMBASE_IMM;
-	case OP_STOREI8_MEMBASE_REG:
-		return OP_STOREI8_MEMBASE_IMM;
-	default:
-		g_assert_not_reached ();
-	}
-	return -1;
-}
-int
-mono_op_to_op_imm (int opcode)
-{
-	switch (opcode) {
-	case OP_IADD:
-		return OP_IADD_IMM;
-	case OP_ISUB:
-		return OP_ISUB_IMM;
-	case OP_IDIV:
-		return OP_IDIV_IMM;
-	case OP_IDIV_UN:
-		return OP_IDIV_UN_IMM;
-	case OP_IREM:
-		return OP_IREM_IMM;
-	case OP_IREM_UN:
-		return OP_IREM_UN_IMM;
-	case OP_IMUL:
-		return OP_IMUL_IMM;
-	case OP_IAND:
-		return OP_IAND_IMM;
-	case OP_IOR:
-		return OP_IOR_IMM;
-	case OP_IXOR:
-		return OP_IXOR_IMM;
-	case OP_ISHL:
-		return OP_ISHL_IMM;
-	case OP_ISHR:
-		return OP_ISHR_IMM;
-	case OP_ISHR_UN:
-		return OP_ISHR_UN_IMM;
-	case OP_LADD:
-		return OP_LADD_IMM;
-	case OP_LSUB:
-		return OP_LSUB_IMM;
-	case OP_LAND:
-		return OP_LAND_IMM;
-	case OP_LOR:
-		return OP_LOR_IMM;
-	case OP_LXOR:
-		return OP_LXOR_IMM;
-	case OP_LSHL:
-		return OP_LSHL_IMM;
-	case OP_LSHR:
-		return OP_LSHR_IMM;
-	case OP_LSHR_UN:
-		return OP_LSHR_UN_IMM;
-#if SIZEOF_REGISTER == 8
-	case OP_LMUL:
-		return OP_LMUL_IMM;
-	case OP_LREM:
-		return OP_LREM_IMM;
-#endif
-	case OP_COMPARE:
-		return OP_COMPARE_IMM;
-	case OP_ICOMPARE:
-		return OP_ICOMPARE_IMM;
-	case OP_LCOMPARE:
-		return OP_LCOMPARE_IMM;
-	case OP_STORE_MEMBASE_REG:
-		return OP_STORE_MEMBASE_IMM;
-	case OP_STOREI1_MEMBASE_REG:
-		return OP_STOREI1_MEMBASE_IMM;
-	case OP_STOREI2_MEMBASE_REG:
-		return OP_STOREI2_MEMBASE_IMM;
-	case OP_STOREI4_MEMBASE_REG:
-		return OP_STOREI4_MEMBASE_IMM;
-#if defined(TARGET_X86) || defined (TARGET_AMD64)
-	case OP_X86_PUSH:
-		return OP_X86_PUSH_IMM;
-	case OP_X86_COMPARE_MEMBASE_REG:
-		return OP_X86_COMPARE_MEMBASE_IMM;
-#endif
-#if defined(TARGET_AMD64)
-	case OP_AMD64_ICOMPARE_MEMBASE_REG:
-		return OP_AMD64_ICOMPARE_MEMBASE_IMM;
-#endif
-	case OP_VOIDCALL_REG:
-		return OP_VOIDCALL;
-	case OP_CALL_REG:
-		return OP_CALL;
-	case OP_LCALL_REG:
-		return OP_LCALL;
-	case OP_FCALL_REG:
-		return OP_FCALL;
-	case OP_LOCALLOC:
-		return OP_LOCALLOC_IMM;
-	}
-	return -1;
-}
-int
-mono_load_membase_to_load_mem (int opcode)
-{
-#if defined(TARGET_X86) || defined(TARGET_AMD64)
-	switch (opcode) {
-	case OP_LOAD_MEMBASE:
-		return OP_LOAD_MEM;
-	case OP_LOADU1_MEMBASE:
-		return OP_LOADU1_MEM;
-	case OP_LOADU2_MEMBASE:
-		return OP_LOADU2_MEM;
-	case OP_LOADI4_MEMBASE:
-		return OP_LOADI4_MEM;
-	case OP_LOADU4_MEMBASE:
-		return OP_LOADU4_MEM;
-#if SIZEOF_REGISTER == 8
-	case OP_LOADI8_MEMBASE:
-		return OP_LOADI8_MEM;
-#endif
-	}
-#endif
-	return -1;
-}
-static int
-op_to_op_dest_membase (int store_opcode, int opcode)
-{
-#if defined(TARGET_X86)
-	if (!((store_opcode == OP_STORE_MEMBASE_REG) || (store_opcode == OP_STOREI4_MEMBASE_REG)))
-		return -1;
-	switch (opcode) {
-	case OP_IADD:
-		return OP_X86_ADD_MEMBASE_REG;
-	case OP_ISUB:
-		return OP_X86_SUB_MEMBASE_REG;
-	case OP_IAND:
-		return OP_X86_AND_MEMBASE_REG;
-	case OP_IOR:
-		return OP_X86_OR_MEMBASE_REG;
-	case OP_IXOR:
-		return OP_X86_XOR_MEMBASE_REG;
-	case OP_ADD_IMM:
-	case OP_IADD_IMM:
-		return OP_X86_ADD_MEMBASE_IMM;
-	case OP_SUB_IMM:
-	case OP_ISUB_IMM:
-		return OP_X86_SUB_MEMBASE_IMM;
-	case OP_AND_IMM:
-	case OP_IAND_IMM:
-		return OP_X86_AND_MEMBASE_IMM;
-	case OP_OR_IMM:
-	case OP_IOR_IMM:
-		return OP_X86_OR_MEMBASE_IMM;
-	case OP_XOR_IMM:
-	case OP_IXOR_IMM:
-		return OP_X86_XOR_MEMBASE_IMM;
-	case OP_MOVE:
-		return OP_NOP;
-	}
-#endif
-#if defined(TARGET_AMD64)
-	if (!((store_opcode == OP_STORE_MEMBASE_REG) || (store_opcode == OP_STOREI4_MEMBASE_REG) || (store_opcode == OP_STOREI8_MEMBASE_REG)))
-		return -1;
-	switch (opcode) {
-	case OP_IADD:
-		return OP_X86_ADD_MEMBASE_REG;
-	case OP_ISUB:
-		return OP_X86_SUB_MEMBASE_REG;
-	case OP_IAND:
-		return OP_X86_AND_MEMBASE_REG;
-	case OP_IOR:
-		return OP_X86_OR_MEMBASE_REG;
-	case OP_IXOR:
-		return OP_X86_XOR_MEMBASE_REG;
-	case OP_IADD_IMM:
-		return OP_X86_ADD_MEMBASE_IMM;
-	case OP_ISUB_IMM:
-		return OP_X86_SUB_MEMBASE_IMM;
-	case OP_IAND_IMM:
-		return OP_X86_AND_MEMBASE_IMM;
-	case OP_IOR_IMM:
-		return OP_X86_OR_MEMBASE_IMM;
-	case OP_IXOR_IMM:
-		return OP_X86_XOR_MEMBASE_IMM;
-	case OP_LADD:
-		return OP_AMD64_ADD_MEMBASE_REG;
-	case OP_LSUB:
-		return OP_AMD64_SUB_MEMBASE_REG;
-	case OP_LAND:
-		return OP_AMD64_AND_MEMBASE_REG;
-	case OP_LOR:
-		return OP_AMD64_OR_MEMBASE_REG;
-	case OP_LXOR:
-		return OP_AMD64_XOR_MEMBASE_REG;
-	case OP_ADD_IMM:
-	case OP_LADD_IMM:
-		return OP_AMD64_ADD_MEMBASE_IMM;
-	case OP_SUB_IMM:
-	case OP_LSUB_IMM:
-		return OP_AMD64_SUB_MEMBASE_IMM;
-	case OP_AND_IMM:
-	case OP_LAND_IMM:
-		return OP_AMD64_AND_MEMBASE_IMM;
-	case OP_OR_IMM:
-	case OP_LOR_IMM:
-		return OP_AMD64_OR_MEMBASE_IMM;
-	case OP_XOR_IMM:
-	case OP_LXOR_IMM:
-		return OP_AMD64_XOR_MEMBASE_IMM;
-	case OP_MOVE:
-		return OP_NOP;
-	}
-#endif
-	return -1;
-}
-static int
-op_to_op_store_membase (int store_opcode, int opcode)
-{
-#if defined(TARGET_X86) || defined(TARGET_AMD64)
-	switch (opcode) {
-	case OP_ICEQ:
-		if (store_opcode == OP_STOREI1_MEMBASE_REG)
-			return OP_X86_SETEQ_MEMBASE;
-	case OP_CNE:
-		if (store_opcode == OP_STOREI1_MEMBASE_REG)
-			return OP_X86_SETNE_MEMBASE;
-	}
-#endif
-	return -1;
-}
-static int
-op_to_op_src1_membase (MonoCompile *cfg, int load_opcode, int opcode)
-{
-#ifdef TARGET_X86
-	/* FIXME: This has sign extension issues */
-	/*
-	if ((opcode == OP_ICOMPARE_IMM) && (load_opcode == OP_LOADU1_MEMBASE))
-		return OP_X86_COMPARE_MEMBASE8_IMM;
-	*/
-	if (!((load_opcode == OP_LOAD_MEMBASE) || (load_opcode == OP_LOADI4_MEMBASE) || (load_opcode == OP_LOADU4_MEMBASE)))
-		return -1;
-	switch (opcode) {
-	case OP_X86_PUSH:
-		return OP_X86_PUSH_MEMBASE;
-	case OP_COMPARE_IMM:
-	case OP_ICOMPARE_IMM:
-		return OP_X86_COMPARE_MEMBASE_IMM;
-	case OP_COMPARE:
-	case OP_ICOMPARE:
-		return OP_X86_COMPARE_MEMBASE_REG;
-	}
-#endif
-#ifdef TARGET_AMD64
-	/* FIXME: This has sign extension issues */
-	/*
-	if ((opcode == OP_ICOMPARE_IMM) && (load_opcode == OP_LOADU1_MEMBASE))
-		return OP_X86_COMPARE_MEMBASE8_IMM;
-	*/
-	switch (opcode) {
-	case OP_X86_PUSH:
-		if ((load_opcode == OP_LOAD_MEMBASE && !cfg->backend->ilp32) || (load_opcode == OP_LOADI8_MEMBASE))
-			return OP_X86_PUSH_MEMBASE;
-		break;
-		/* FIXME: This only works for 32 bit immediates
-	case OP_COMPARE_IMM:
-	case OP_LCOMPARE_IMM:
-		if ((load_opcode == OP_LOAD_MEMBASE) || (load_opcode == OP_LOADI8_MEMBASE))
-			return OP_AMD64_COMPARE_MEMBASE_IMM;
-		*/
-	case OP_ICOMPARE_IMM:
-		if ((load_opcode == OP_LOADI4_MEMBASE) || (load_opcode == OP_LOADU4_MEMBASE))
-			return OP_AMD64_ICOMPARE_MEMBASE_IMM;
-		break;
-	case OP_COMPARE:
-	case OP_LCOMPARE:
-		if (cfg->backend->ilp32 && load_opcode == OP_LOAD_MEMBASE)
-			return OP_AMD64_ICOMPARE_MEMBASE_REG;
-		if ((load_opcode == OP_LOAD_MEMBASE && !cfg->backend->ilp32) || (load_opcode == OP_LOADI8_MEMBASE))
-			return OP_AMD64_COMPARE_MEMBASE_REG;
-		break;
-	case OP_ICOMPARE:
-		if ((load_opcode == OP_LOADI4_MEMBASE) || (load_opcode == OP_LOADU4_MEMBASE))
-			return OP_AMD64_ICOMPARE_MEMBASE_REG;
-		break;
-	}
-#endif
-	return -1;
-}
-static int
-op_to_op_src2_membase (MonoCompile *cfg, int load_opcode, int opcode)
-{
-#ifdef TARGET_X86
-	if (!((load_opcode == OP_LOAD_MEMBASE) || (load_opcode == OP_LOADI4_MEMBASE) || (load_opcode == OP_LOADU4_MEMBASE)))
-		return -1;
-	switch (opcode) {
-	case OP_COMPARE:
-	case OP_ICOMPARE:
-		return OP_X86_COMPARE_REG_MEMBASE;
-	case OP_IADD:
-		return OP_X86_ADD_REG_MEMBASE;
-	case OP_ISUB:
-		return OP_X86_SUB_REG_MEMBASE;
-	case OP_IAND:
-		return OP_X86_AND_REG_MEMBASE;
-	case OP_IOR:
-		return OP_X86_OR_REG_MEMBASE;
-	case OP_IXOR:
-		return OP_X86_XOR_REG_MEMBASE;
-	}
-#endif
-#ifdef TARGET_AMD64
-	if ((load_opcode == OP_LOADI4_MEMBASE) || (load_opcode == OP_LOADU4_MEMBASE) || (load_opcode == OP_LOAD_MEMBASE && cfg->backend->ilp32)) {
-		switch (opcode) {
-		case OP_ICOMPARE:
-			return OP_AMD64_ICOMPARE_REG_MEMBASE;
-		case OP_IADD:
-			return OP_X86_ADD_REG_MEMBASE;
-		case OP_ISUB:
-			return OP_X86_SUB_REG_MEMBASE;
-		case OP_IAND:
-			return OP_X86_AND_REG_MEMBASE;
-		case OP_IOR:
-			return OP_X86_OR_REG_MEMBASE;
-		case OP_IXOR:
-			return OP_X86_XOR_REG_MEMBASE;
-		}
-	} else if ((load_opcode == OP_LOADI8_MEMBASE) || (load_opcode == OP_LOAD_MEMBASE && !cfg->backend->ilp32)) {
-		switch (opcode) {
-		case OP_COMPARE:
-		case OP_LCOMPARE:
-			return OP_AMD64_COMPARE_REG_MEMBASE;
-		case OP_LADD:
-			return OP_AMD64_ADD_REG_MEMBASE;
-		case OP_LSUB:
-			return OP_AMD64_SUB_REG_MEMBASE;
-		case OP_LAND:
-			return OP_AMD64_AND_REG_MEMBASE;
-		case OP_LOR:
-			return OP_AMD64_OR_REG_MEMBASE;
-		case OP_LXOR:
-			return OP_AMD64_XOR_REG_MEMBASE;
-		}
-	}
-#endif
-	return -1;
-}
-int
-mono_op_to_op_imm_noemul (int opcode)
-{
-MONO_DISABLE_WARNING(4065) // switch with default but no case
-	switch (opcode) {
-#if SIZEOF_REGISTER == 4 && !defined(MONO_ARCH_NO_EMULATE_LONG_SHIFT_OPS)
-	case OP_LSHR:
-	case OP_LSHL:
-	case OP_LSHR_UN:
-		return -1;
-#endif
-#if defined(MONO_ARCH_EMULATE_MUL_DIV) || defined(MONO_ARCH_EMULATE_DIV)
-	case OP_IDIV:
-	case OP_IDIV_UN:
-	case OP_IREM:
-	case OP_IREM_UN:
-		return -1;
-#endif
-#if defined(MONO_ARCH_EMULATE_MUL_DIV)
-	case OP_IMUL:
-		return -1;
-#endif
-	default:
-		return mono_op_to_op_imm (opcode);
-	}
-MONO_RESTORE_WARNING
-}
-gboolean
-mono_op_no_side_effects (int opcode)
-{
-	/* FIXME: Add more instructions */
-	/* INEG sets the condition codes, and the OP_LNEG decomposition depends on this on x86 */
-	switch (opcode) {
-	case OP_MOVE:
-	case OP_FMOVE:
-	case OP_VMOVE:
-	case OP_XMOVE:
-	case OP_RMOVE:
-	case OP_VZERO:
-	case OP_XZERO:
-	case OP_XONES:
-	case OP_XCONST:
-	case OP_ICONST:
-	case OP_I8CONST:
-	case OP_ADD_IMM:
-	case OP_R8CONST:
-	case OP_LADD_IMM:
-	case OP_ISUB_IMM:
-	case OP_IADD_IMM:
-	case OP_LNEG:
-	case OP_ISUB:
-	case OP_CMOV_IGE:
-	case OP_ISHL_IMM:
-	case OP_ISHR_IMM:
-	case OP_ISHR_UN_IMM:
-	case OP_IAND_IMM:
-	case OP_ICONV_TO_U1:
-	case OP_ICONV_TO_I1:
-	case OP_SEXT_I4:
-	case OP_LCONV_TO_U1:
-	case OP_ICONV_TO_U2:
-	case OP_ICONV_TO_I2:
-	case OP_LCONV_TO_I2:
-	case OP_LDADDR:
-	case OP_PHI:
-	case OP_NOP:
-	case OP_ZEXT_I4:
-	case OP_NOT_NULL:
-	case OP_IL_SEQ_POINT:
-	case OP_RTTYPE:
-#if defined(TARGET_X86) || defined(TARGET_AMD64) || defined(TARGET_WASM) || defined(TARGET_ARM64)
-	case OP_EXTRACT_I1:
-	case OP_EXTRACT_I2:
-	case OP_EXTRACT_I4:
-	case OP_EXTRACT_I8:
-	case OP_EXTRACT_R4:
-	case OP_EXTRACT_R8:
-#endif
-		return TRUE;
-	default:
-		return FALSE;
-	}
-}
-gboolean
-mono_ins_no_side_effects (MonoInst *ins)
-{
-	if (mono_op_no_side_effects (ins->opcode))
-		return TRUE;
-	if (ins->opcode == OP_AOTCONST) {
-		MonoJumpInfoType type = (MonoJumpInfoType)(intptr_t)ins->inst_p1;
-		switch (type) {
-		case MONO_PATCH_INFO_TYPE_FROM_HANDLE:
-		case MONO_PATCH_INFO_LDSTR:
-		case MONO_PATCH_INFO_VTABLE:
-		case MONO_PATCH_INFO_METHOD_RGCTX:
-			return TRUE;
-		}
-	}
-	return FALSE;
-}
-/**
- * mono_handle_global_vregs:
- *
- *   Make vregs used in more than one bblock 'global', i.e. allocate a variable
- * for them.
- */
-void
-mono_handle_global_vregs (MonoCompile *cfg)
-{
-	gint32 *vreg_to_bb;
-	MonoBasicBlock *bb;
-	vreg_to_bb = (gint32 *)mono_mempool_alloc0 (cfg->mempool, sizeof (gint32*) * cfg->next_vreg + 1);
-	/* Find local vregs used in more than one bb */
-	for (bb = cfg->bb_entry; bb; bb = bb->next_bb) {
-		MonoInst *ins = bb->code;
-		int block_num = bb->block_num;
-		if (cfg->verbose_level > 2)
-			printf ("\nHANDLE-GLOBAL-VREGS BLOCK %d:\n", bb->block_num);
-		cfg->cbb = bb;
-		for (; ins; ins = ins->next) {
-			const char *spec = INS_INFO (ins->opcode);
-			int regtype = 0, regindex;
-			gint32 prev_bb;
-			if (G_UNLIKELY (cfg->verbose_level > 2))
-				mono_print_ins (ins);
-			g_assert (ins->opcode >= MONO_CEE_LAST);
-			for (regindex = 0; regindex < 4; regindex ++) {
-				int vreg = 0;
-				if (regindex == 0) {
-					regtype = spec [MONO_INST_DEST];
-					if (regtype == ' ')
-						continue;
-					vreg = ins->dreg;
-				} else if (regindex == 1) {
-					regtype = spec [MONO_INST_SRC1];
-					if (regtype == ' ')
-						continue;
-					vreg = ins->sreg1;
-				} else if (regindex == 2) {
-					regtype = spec [MONO_INST_SRC2];
-					if (regtype == ' ')
-						continue;
-					vreg = ins->sreg2;
-				} else if (regindex == 3) {
-					regtype = spec [MONO_INST_SRC3];
-					if (regtype == ' ')
-						continue;
-					vreg = ins->sreg3;
-				}
-#if SIZEOF_REGISTER == 4
-				/* In the LLVM case, the long opcodes are not decomposed */
-				if (regtype == 'l' && !COMPILE_LLVM (cfg)) {
-					/*
-					 * Since some instructions reference the original long vreg,
-					 * and some reference the two component vregs, it is quite hard
-					 * to determine when it needs to be global. So be conservative.
-					 */
-					if (!get_vreg_to_inst (cfg, vreg)) {
-						mono_compile_create_var_for_vreg (cfg, m_class_get_byval_arg (mono_defaults.int64_class), OP_LOCAL, vreg);
-						if (cfg->verbose_level > 2)
-							printf ("LONG VREG R%d made global.\n", vreg);
-					}
-					/*
-					 * Make the component vregs volatile since the optimizations can
-					 * get confused otherwise.
-					 */
-					get_vreg_to_inst (cfg, MONO_LVREG_LS (vreg))->flags |= MONO_INST_VOLATILE;
-					get_vreg_to_inst (cfg, MONO_LVREG_MS (vreg))->flags |= MONO_INST_VOLATILE;
-				}
-#endif
-				g_assert (vreg != -1);
-				prev_bb = vreg_to_bb [vreg];
-				if (prev_bb == 0) {
-					/* 0 is a valid block num */
-					vreg_to_bb [vreg] = block_num + 1;
-				} else if ((prev_bb != block_num + 1) && (prev_bb != -1)) {
-					if (((regtype == 'i' && (vreg < MONO_MAX_IREGS))) || (regtype == 'f' && (vreg < MONO_MAX_FREGS)))
-						continue;
-					if (!get_vreg_to_inst (cfg, vreg)) {
-						if (G_UNLIKELY (cfg->verbose_level > 2))
-							printf ("VREG R%d used in BB%d and BB%d made global.\n", vreg, vreg_to_bb [vreg], block_num);
-						switch (regtype) {
-						case 'i':
-							if (vreg_is_ref (cfg, vreg))
-								mono_compile_create_var_for_vreg (cfg, mono_get_object_type (), OP_LOCAL, vreg);
-							else
-								mono_compile_create_var_for_vreg (cfg, mono_get_int_type (), OP_LOCAL, vreg);
-							break;
-						case 'l':
-							mono_compile_create_var_for_vreg (cfg, m_class_get_byval_arg (mono_defaults.int64_class), OP_LOCAL, vreg);
-							break;
-						case 'f':
-							mono_compile_create_var_for_vreg (cfg, m_class_get_byval_arg (mono_defaults.double_class), OP_LOCAL, vreg);
-							break;
-						case 'v':
-						case 'x':
-							mono_compile_create_var_for_vreg (cfg, m_class_get_byval_arg (ins->klass), OP_LOCAL, vreg);
-							break;
-						default:
-							g_assert_not_reached ();
-						}
-					}
-					/* Flag as having been used in more than one bb */
-					vreg_to_bb [vreg] = -1;
-				}
-			}
-		}
-	}
-	/* If a variable is used in only one bblock, convert it into a local vreg */
-	for (guint i = 0; i < cfg->num_varinfo; i++) {
-		MonoInst *var = cfg->varinfo [i];
-		MonoMethodVar *vmv = MONO_VARINFO (cfg, i);
-		switch (var->type) {
-		case STACK_I4:
-		case STACK_OBJ:
-		case STACK_PTR:
-		case STACK_MP:
-		case STACK_VTYPE:
-#if SIZEOF_REGISTER == 8
-		case STACK_I8:
-#endif
-#if !defined(TARGET_X86)
-		/* Enabling this screws up the fp stack on x86 */
-		case STACK_R8:
-#endif
-			if (mono_arch_is_soft_float ())
-				break;
-			/*
-			if (var->type == STACK_VTYPE && cfg->gsharedvt && mini_is_gsharedvt_variable_type (var->inst_vtype))
-				break;
-			*/
-			/* Arguments are implicitly global */
-			/* Putting R4 vars into registers doesn't work currently */
-			/* The gsharedvt vars are implicitly referenced by ldaddr opcodes, but those opcodes are only generated later */
-			if ((var->opcode != OP_ARG) && (var != cfg->ret) && !(var->flags & (MONO_INST_VOLATILE|MONO_INST_INDIRECT)) && (vreg_to_bb [var->dreg] != -1) && (m_class_get_byval_arg (var->klass)->type != MONO_TYPE_R4) && !cfg->disable_vreg_to_lvreg && var != cfg->gsharedvt_info_var && var != cfg->gsharedvt_locals_var && var != cfg->lmf_addr_var) {
-				/*
-				 * Make that the variable's liveness interval doesn't contain a call, since
-				 * that would cause the lvreg to be spilled, making the whole optimization
-				 * useless.
-				 */
-				/* This is too slow for JIT compilation */
-#if 0
-				if (cfg->compile_aot && vreg_to_bb [var->dreg]) {
-					MonoInst *ins;
-					int def_index, call_index, ins_index;
-					gboolean spilled = FALSE;
-					def_index = -1;
-					call_index = -1;
-					ins_index = 0;
-					for (ins = vreg_to_bb [var->dreg]->code; ins; ins = ins->next) {
-						const char *spec = INS_INFO (ins->opcode);
-						if ((spec [MONO_INST_DEST] != ' ') && (ins->dreg == var->dreg))
-							def_index = ins_index;
-						if (((spec [MONO_INST_SRC1] != ' ') && (ins->sreg1 == var->dreg)) ||
-							((spec [MONO_INST_SRC1] != ' ') && (ins->sreg1 == var->dreg))) {
-							if (call_index > def_index) {
-								spilled = TRUE;
-								break;
-							}
-						}
-						if (MONO_IS_CALL (ins))
-							call_index = ins_index;
-						ins_index ++;
-					}
-					if (spilled)
-						break;
-				}
-#endif
-				if (G_UNLIKELY (cfg->verbose_level > 2))
-					printf ("CONVERTED R%d(%d) TO VREG.\n", var->dreg, vmv->idx);
-				var->flags |= MONO_INST_IS_DEAD;
-				cfg->vreg_to_inst [var->dreg] = NULL;
-			}
-			break;
-		}
-	}
-	/*
-	 * Compress the varinfo and vars tables so the liveness computation is faster and
-	 * takes up less space.
-	 */
-	guint pos = 0;
-	for (guint i = 0; i < cfg->num_varinfo; ++i) {
-		MonoInst *var = cfg->varinfo [i];
-		if (pos < i && cfg->locals_start == i)
-			cfg->locals_start = pos;
-		if (!(var->flags & MONO_INST_IS_DEAD)) {
-			if (pos < i) {
-				cfg->varinfo [pos] = cfg->varinfo [i];
-				cfg->varinfo [pos]->inst_c0 = pos;
-				memcpy (&cfg->vars [pos], &cfg->vars [i], sizeof (MonoMethodVar));
-				cfg->vars [pos].idx = pos;
-#if SIZEOF_REGISTER == 4
-				if (cfg->varinfo [pos]->type == STACK_I8) {
-					/* Modify the two component vars too */
-					MonoInst *var1;
-					var1 = get_vreg_to_inst (cfg, MONO_LVREG_LS (cfg->varinfo [pos]->dreg));
-					var1->inst_c0 = pos;
-					var1 = get_vreg_to_inst (cfg, MONO_LVREG_MS (cfg->varinfo [pos]->dreg));
-					var1->inst_c0 = pos;
-				}
-#endif
-			}
-			pos ++;
-		}
-	}
-	cfg->num_varinfo = pos;
-	if (cfg->locals_start > cfg->num_varinfo)
-		cfg->locals_start = cfg->num_varinfo;
-}
-/*
- * mono_allocate_gsharedvt_vars:
- *
- *   Allocate variables with gsharedvt types to entries in the MonoGSharedVtMethodRuntimeInfo.entries array.
- * Initialize cfg->gsharedvt_vreg_to_idx with the mapping between vregs and indexes.
- */
-void
-mono_allocate_gsharedvt_vars (MonoCompile *cfg)
-{
-	cfg->gsharedvt_vreg_to_idx = (int *)mono_mempool_alloc0 (cfg->mempool, sizeof (int) * cfg->next_vreg);
-	for (guint i = 0; i < cfg->num_varinfo; ++i) {
-		MonoInst *ins = cfg->varinfo [i];
-		int idx;
-		if (mini_is_gsharedvt_variable_type (ins->inst_vtype)) {
-			if (i >= cfg->locals_start) {
-				/* Local */
-				idx = get_gsharedvt_info_slot (cfg, ins->inst_vtype, MONO_RGCTX_INFO_LOCAL_OFFSET);
-				cfg->gsharedvt_vreg_to_idx [ins->dreg] = idx + 1;
-				ins->opcode = OP_GSHAREDVT_LOCAL;
-				ins->inst_imm = idx;
-			} else {
-				/* Arg */
-				cfg->gsharedvt_vreg_to_idx [ins->dreg] = -1;
-				ins->opcode = OP_GSHAREDVT_ARG_REGOFFSET;
-			}
-		}
-	}
-}
-/**
- * mono_spill_global_vars:
- *
- *   Generate spill code for variables which are not allocated to registers,
- * and replace vregs with their allocated hregs. *need_local_opts is set to TRUE if
- * code is generated which could be optimized by the local optimization passes.
- */
-void
-mono_spill_global_vars (MonoCompile *cfg, gboolean *need_local_opts)
-{
-	MonoBasicBlock *bb;
-	char spec2 [16];
-	int orig_next_vreg;
-	guint32 *vreg_to_lvreg;
-	guint32 *lvregs;
-	guint32 i, lvregs_len, lvregs_size;
-	gboolean dest_has_lvreg = FALSE;
-	MonoStackType stacktypes [128];
-	MonoInst **live_range_start, **live_range_end;
-	MonoBasicBlock **live_range_start_bb, **live_range_end_bb;
-	*need_local_opts = FALSE;
-	memset (spec2, 0, sizeof (spec2));
-	/* FIXME: Move this function to mini.c */
-	stacktypes [(int)'i'] = STACK_PTR;
-	stacktypes [(int)'l'] = STACK_I8;
-	stacktypes [(int)'f'] = STACK_R8;
-	stacktypes [(int)'x'] = STACK_VTYPE;
-#if SIZEOF_REGISTER == 4
-	/* Create MonoInsts for longs */
-	for (i = 0; i < cfg->num_varinfo; i++) {
-		MonoInst *ins = cfg->varinfo [i];
-		if ((ins->opcode != OP_REGVAR) && !(ins->flags & MONO_INST_IS_DEAD)) {
-			switch (ins->type) {
-			case STACK_R8:
-			case STACK_I8: {
-				MonoInst *tree;
-				if (ins->type == STACK_R8 && !COMPILE_SOFT_FLOAT (cfg))
-					break;
-				g_assert (ins->opcode == OP_REGOFFSET);
-				tree = get_vreg_to_inst (cfg, MONO_LVREG_LS (ins->dreg));
-				g_assert (tree);
-				tree->opcode = OP_REGOFFSET;
-				tree->inst_basereg = ins->inst_basereg;
-				tree->inst_offset = ins->inst_offset + MINI_LS_WORD_OFFSET;
-				tree = get_vreg_to_inst (cfg, MONO_LVREG_MS (ins->dreg));
-				g_assert (tree);
-				tree->opcode = OP_REGOFFSET;
-				tree->inst_basereg = ins->inst_basereg;
-				tree->inst_offset = ins->inst_offset + MINI_MS_WORD_OFFSET;
-				break;
-			}
-			default:
-				break;
-			}
-		}
-	}
-#endif
-	if (cfg->compute_gc_maps) {
-		/* registers need liveness info even for !non refs */
-		for (i = 0; i < cfg->num_varinfo; i++) {
-			MonoInst *ins = cfg->varinfo [i];
-			if (ins->opcode == OP_REGVAR)
-				ins->flags |= MONO_INST_GC_TRACK;
-		}
-	}
-	/* FIXME: widening and truncation */
-	/*
-	 * As an optimization, when a variable allocated to the stack is first loaded into
-	 * an lvreg, we will remember the lvreg and use it the next time instead of loading
-	 * the variable again.
-	 */
-	orig_next_vreg = cfg->next_vreg;
-	vreg_to_lvreg = (guint32 *)mono_mempool_alloc0 (cfg->mempool, sizeof (guint32) * cfg->next_vreg);
-	lvregs_size = 1024;
-	lvregs = (guint32 *)mono_mempool_alloc (cfg->mempool, sizeof (guint32) * lvregs_size);
-	lvregs_len = 0;
-	/*
-	 * These arrays contain the first and last instructions accessing a given
-	 * variable.
-	 * Since we emit bblocks in the same order we process them here, and we
-	 * don't split live ranges, these will precisely describe the live range of
-	 * the variable, i.e. the instruction range where a valid value can be found
-	 * in the variables location.
-	 * The live range is computed using the liveness info computed by the liveness pass.
-	 * We can't use vmv->range, since that is an abstract live range, and we need
-	 * one which is instruction precise.
-	 * FIXME: Variables used in out-of-line bblocks have a hole in their live range.
-	 */
-	/* FIXME: Only do this if debugging info is requested */
-	live_range_start = g_new0 (MonoInst*, cfg->next_vreg);
-	live_range_end = g_new0 (MonoInst*, cfg->next_vreg);
-	live_range_start_bb = g_new (MonoBasicBlock*, cfg->next_vreg);
-	live_range_end_bb = g_new (MonoBasicBlock*, cfg->next_vreg);
-	/* Add spill loads/stores */
-	for (bb = cfg->bb_entry; bb; bb = bb->next_bb) {
-		MonoInst *ins;
-		if (cfg->verbose_level > 2)
-			printf ("\nSPILL BLOCK %d:\n", bb->block_num);
-		/* Clear vreg_to_lvreg array */
-		for (i = 0; i < lvregs_len; i++)
-			vreg_to_lvreg [lvregs [i]] = 0;
-		lvregs_len = 0;
-		cfg->cbb = bb;
-		MONO_BB_FOR_EACH_INS (bb, ins) {
-			const char *spec = INS_INFO (ins->opcode);
-			int regtype, srcindex, sreg, tmp_reg, prev_dreg, num_sregs;
-			gboolean store, no_lvreg;
-			int sregs [MONO_MAX_SRC_REGS];
-			if (G_UNLIKELY (cfg->verbose_level > 2))
-				mono_print_ins (ins);
-			if (ins->opcode == OP_NOP)
-				continue;
-			/*
-			 * We handle LDADDR here as well, since it can only be decomposed
-			 * when variable addresses are known.
-			 */
-			if (ins->opcode == OP_LDADDR) {
-				MonoInst *var = (MonoInst *)ins->inst_p0;
-				if (var->opcode == OP_VTARG_ADDR) {
-					/* Happens on SPARC/S390 where vtypes are passed by reference */
-					MonoInst *vtaddr = var->inst_left;
-					if (vtaddr->opcode == OP_REGVAR) {
-						ins->opcode = OP_MOVE;
-						ins->sreg1 = vtaddr->dreg;
-					}
-					else if (var->inst_left->opcode == OP_REGOFFSET) {
-						ins->opcode = OP_LOAD_MEMBASE;
-						ins->inst_basereg = vtaddr->inst_basereg;
-						ins->inst_offset = vtaddr->inst_offset;
-					} else
-						NOT_IMPLEMENTED;
-				} else if (cfg->gsharedvt && cfg->gsharedvt_vreg_to_idx [var->dreg] < 0) {
-					/* gsharedvt arg passed by ref */
-					g_assert (var->opcode == OP_GSHAREDVT_ARG_REGOFFSET);
-					ins->opcode = OP_LOAD_MEMBASE;
-					ins->inst_basereg = var->inst_basereg;
-					ins->inst_offset = var->inst_offset;
-				} else if (cfg->gsharedvt && cfg->gsharedvt_vreg_to_idx [var->dreg]) {
-					MonoInst *load, *load2, *load3;
-					int idx = cfg->gsharedvt_vreg_to_idx [var->dreg] - 1;
-					int reg1, reg2, reg3;
-					MonoInst *info_var = cfg->gsharedvt_info_var;
-					MonoInst *locals_var = cfg->gsharedvt_locals_var;
-					/*
-					 * gsharedvt local.
-					 * Compute the address of the local as gsharedvt_locals_var + gsharedvt_info_var->locals_offsets [idx].
-					 */
-					g_assert (var->opcode == OP_GSHAREDVT_LOCAL);
-					g_assert (info_var);
-					g_assert (locals_var);
-					/* Mark the instruction used to compute the locals var as used */
-					cfg->gsharedvt_locals_var_ins = NULL;
-					/* Load the offset */
-					if (info_var->opcode == OP_REGOFFSET) {
-						reg1 = alloc_ireg (cfg);
-						NEW_LOAD_MEMBASE (cfg, load, OP_LOAD_MEMBASE, reg1, info_var->inst_basereg, info_var->inst_offset);
-					} else if (info_var->opcode == OP_REGVAR) {
-						load = NULL;
-						reg1 = info_var->dreg;
-					} else {
-						g_assert_not_reached ();
-					}
-					reg2 = alloc_ireg (cfg);
-					NEW_LOAD_MEMBASE (cfg, load2, OP_LOADI4_MEMBASE, reg2, reg1, MONO_STRUCT_OFFSET (MonoGSharedVtMethodRuntimeInfo, entries) + (idx * TARGET_SIZEOF_VOID_P));
-					/* Load the locals area address */
-					reg3 = alloc_ireg (cfg);
-					if (locals_var->opcode == OP_REGOFFSET) {
-						NEW_LOAD_MEMBASE (cfg, load3, OP_LOAD_MEMBASE, reg3, locals_var->inst_basereg, locals_var->inst_offset);
-					} else if (locals_var->opcode == OP_REGVAR) {
-						NEW_UNALU (cfg, load3, OP_MOVE, reg3, locals_var->dreg);
-					} else {
-						g_assert_not_reached ();
-					}
-					/* Compute the address */
-					ins->opcode = OP_PADD;
-					ins->sreg1 = reg3;
-					ins->sreg2 = reg2;
-					mono_bblock_insert_before_ins (bb, ins, load3);
-					mono_bblock_insert_before_ins (bb, load3, load2);
-					if (load)
-						mono_bblock_insert_before_ins (bb, load2, load);
-				} else {
-					g_assert (var->opcode == OP_REGOFFSET);
-					ins->opcode = OP_ADD_IMM;
-					ins->sreg1 = var->inst_basereg;
-					ins->inst_imm = var->inst_offset;
-				}
-				*need_local_opts = TRUE;
-				spec = INS_INFO (ins->opcode);
-			}
-			if (ins->opcode < MONO_CEE_LAST) {
-				mono_print_ins (ins);
-				g_assert_not_reached ();
-			}
-			/*
-			 * Store opcodes have destbasereg in the dreg, but in reality, it is an
-			 * src register.
-			 * FIXME:
-			 */
-			if (MONO_IS_STORE_MEMBASE (ins)) {
-				tmp_reg = ins->dreg;
-				ins->dreg = ins->sreg2;
-				ins->sreg2 = tmp_reg;
-				store = TRUE;
-				spec2 [MONO_INST_DEST] = ' ';
-				spec2 [MONO_INST_SRC1] = spec [MONO_INST_SRC1];
-				spec2 [MONO_INST_SRC2] = spec [MONO_INST_DEST];
-				spec2 [MONO_INST_SRC3] = ' ';
-				spec = spec2;
-			} else if (MONO_IS_STORE_MEMINDEX (ins))
-				g_assert_not_reached ();
-			else
-				store = FALSE;
-			no_lvreg = FALSE;
-			if (G_UNLIKELY (cfg->verbose_level > 2)) {
-				printf ("\t %.3s %d", spec, ins->dreg);
-				num_sregs = mono_inst_get_src_registers (ins, sregs);
-				for (srcindex = 0; srcindex < num_sregs; ++srcindex)
-					printf (" %d", sregs [srcindex]);
-				printf ("\n");
-			}
-			/***************/
-			/*    DREG     */
-			/***************/
-			regtype = spec [MONO_INST_DEST];
-			g_assert (((ins->dreg == -1) && (regtype == ' ')) || ((ins->dreg != -1) && (regtype != ' ')));
-			prev_dreg = -1;
-			int dreg_using_dest_to_membase_op = -1;
-			if ((ins->dreg != -1) && get_vreg_to_inst (cfg, ins->dreg)) {
-				MonoInst *var = get_vreg_to_inst (cfg, ins->dreg);
-				MonoInst *store_ins;
-				int store_opcode;
-				MonoInst *def_ins = ins;
-				int dreg = ins->dreg; /* The original vreg */
-				store_opcode = mono_type_to_store_membase (cfg, var->inst_vtype);
-				if (var->opcode == OP_REGVAR) {
-					ins->dreg = var->dreg;
-				} else if ((ins->dreg == ins->sreg1) && (spec [MONO_INST_DEST] == 'i') && (spec [MONO_INST_SRC1] == 'i') && !vreg_to_lvreg [ins->dreg] && (op_to_op_dest_membase (store_opcode, ins->opcode) != -1)) {
-					/*
-					 * Instead of emitting a load+store, use a _membase opcode.
-					 */
-					g_assert (var->opcode == OP_REGOFFSET);
-					if (ins->opcode == OP_MOVE) {
-						NULLIFY_INS (ins);
-						def_ins = NULL;
-					} else {
-						dreg_using_dest_to_membase_op = ins->dreg;
-						ins->opcode = GINT_TO_OPCODE (op_to_op_dest_membase (store_opcode, ins->opcode));
-						ins->inst_basereg = var->inst_basereg;
-						ins->inst_offset = var->inst_offset;
-						ins->dreg = -1;
-					}
-					spec = INS_INFO (ins->opcode);
-				} else {
-					guint32 lvreg;
-					g_assert (var->opcode == OP_REGOFFSET);
-					prev_dreg = ins->dreg;
-					/* Invalidate any previous lvreg for this vreg */
-					vreg_to_lvreg [ins->dreg] = 0;
-					lvreg = 0;
-					if (COMPILE_SOFT_FLOAT (cfg) && store_opcode == OP_STORER8_MEMBASE_REG) {
-						regtype = 'l';
-						store_opcode = OP_STOREI8_MEMBASE_REG;
-					}
-					ins->dreg = alloc_dreg (cfg, stacktypes [regtype]);
-#if SIZEOF_REGISTER != 8
-					if (regtype == 'l') {
-						NEW_STORE_MEMBASE (cfg, store_ins, OP_STOREI4_MEMBASE_REG, var->inst_basereg, var->inst_offset + MINI_LS_WORD_OFFSET, MONO_LVREG_LS (ins->dreg));
-						mono_bblock_insert_after_ins (bb, ins, store_ins);
-						NEW_STORE_MEMBASE (cfg, store_ins, OP_STOREI4_MEMBASE_REG, var->inst_basereg, var->inst_offset + MINI_MS_WORD_OFFSET, MONO_LVREG_MS (ins->dreg));
-						mono_bblock_insert_after_ins (bb, ins, store_ins);
-						def_ins = store_ins;
-					}
-					else
-#endif
-					{
-						g_assert (store_opcode != OP_STOREV_MEMBASE);
-						/* Try to fuse the store into the instruction itself */
-						/* FIXME: Add more instructions */
-						if (!lvreg && ((ins->opcode == OP_ICONST) || ((ins->opcode == OP_I8CONST) && (ins->inst_c0 == 0)))) {
-							ins->opcode = GINT_TO_OPCODE (store_membase_reg_to_store_membase_imm (store_opcode));
-							ins->inst_imm = ins->inst_c0;
-							ins->inst_destbasereg = var->inst_basereg;
-							ins->inst_offset = var->inst_offset;
-							spec = INS_INFO (ins->opcode);
-						} else if (!lvreg && ((ins->opcode == OP_MOVE) || (ins->opcode == OP_FMOVE) || (ins->opcode == OP_LMOVE) || (ins->opcode == OP_RMOVE))) {
-							ins->opcode = GINT_TO_OPCODE (store_opcode);
-							ins->inst_destbasereg = var->inst_basereg;
-							ins->inst_offset = var->inst_offset;
-							no_lvreg = TRUE;
-							tmp_reg = ins->dreg;
-							ins->dreg = ins->sreg2;
-							ins->sreg2 = tmp_reg;
-							store = TRUE;
-							spec2 [MONO_INST_DEST] = ' ';
-							spec2 [MONO_INST_SRC1] = spec [MONO_INST_SRC1];
-							spec2 [MONO_INST_SRC2] = spec [MONO_INST_DEST];
-							spec2 [MONO_INST_SRC3] = ' ';
-							spec = spec2;
-						} else if (!lvreg && (op_to_op_store_membase (store_opcode, ins->opcode) != -1)) {
-							ins->opcode = GINT_TO_OPCODE (op_to_op_store_membase (store_opcode, ins->opcode));
-							ins->dreg = -1;
-							ins->inst_basereg = var->inst_basereg;
-							ins->inst_offset = var->inst_offset;
-							spec = INS_INFO (ins->opcode);
-						} else {
-							/* printf ("INS: "); mono_print_ins (ins); */
-							/* Create a store instruction */
-							NEW_STORE_MEMBASE (cfg, store_ins, store_opcode, var->inst_basereg, var->inst_offset, ins->dreg);
-							if (store_ins->opcode == OP_STOREX_MEMBASE)
-								mini_type_to_eval_stack_type (cfg, var->inst_vtype, store_ins);
-							/* Insert it after the instruction */
-							mono_bblock_insert_after_ins (bb, ins, store_ins);
-							def_ins = store_ins;
-							/*
-							 * We can't assign ins->dreg to var->dreg here, since the
-							 * sregs could use it. So set a flag, and do it after
-							 * the sregs.
-							 */
-							if (!((var)->flags & (MONO_INST_VOLATILE|MONO_INST_INDIRECT)))
-								dest_has_lvreg = TRUE;
-						}
-					}
-				}
-				if (def_ins && !live_range_start [dreg]) {
-					live_range_start [dreg] = def_ins;
-					live_range_start_bb [dreg] = bb;
-				}
-				if (cfg->compute_gc_maps && def_ins && (var->flags & MONO_INST_GC_TRACK)) {
-					MonoInst *tmp;
-					MONO_INST_NEW (cfg, tmp, OP_GC_LIVENESS_DEF);
-					tmp->inst_c1 = dreg;
-					mono_bblock_insert_after_ins (bb, def_ins, tmp);
-				}
-			}
-			/************/
-			/*  SREGS   */
-			/************/
-			num_sregs = mono_inst_get_src_registers (ins, sregs);
-			for (srcindex = 0; srcindex < 3; ++srcindex) {
-				regtype = spec [MONO_INST_SRC1 + srcindex];
-				sreg = sregs [srcindex];
-				g_assert (((sreg == -1) && (regtype == ' ')) || ((sreg != -1) && (regtype != ' ')));
-				if ((sreg != -1) && get_vreg_to_inst (cfg, sreg)) {
-					MonoInst *var = get_vreg_to_inst (cfg, sreg);
-					MonoInst *use_ins = ins;
-					MonoInst *load_ins;
-					guint32 load_opcode;
-					if (var->opcode == OP_REGVAR) {
-						sregs [srcindex] = var->dreg;
-						live_range_end [sreg] = use_ins;
-						live_range_end_bb [sreg] = bb;
-						if (cfg->compute_gc_maps && var->dreg < orig_next_vreg && (var->flags & MONO_INST_GC_TRACK)) {
-							MonoInst *tmp;
-							MONO_INST_NEW (cfg, tmp, OP_GC_LIVENESS_USE);
-							/* var->dreg is a hreg */
-							tmp->inst_c1 = sreg;
-							mono_bblock_insert_after_ins (bb, ins, tmp);
-						}
-						continue;
-					}
-					g_assert (var->opcode == OP_REGOFFSET);
-					load_opcode = mono_type_to_load_membase (cfg, var->inst_vtype);
-					g_assert (load_opcode != OP_LOADV_MEMBASE);
-					if (vreg_to_lvreg [sreg]) {
-						g_assert (vreg_to_lvreg [sreg] != -1);
-						/* The variable is already loaded to an lvreg */
-						if (G_UNLIKELY (cfg->verbose_level > 2))
-							printf ("\t\tUse lvreg R%d for R%d.\n", vreg_to_lvreg [sreg], sreg);
-						sregs [srcindex] = vreg_to_lvreg [sreg];
-						continue;
-					}
-					/* Try to fuse the load into the instruction */
-					if ((srcindex == 0) && (op_to_op_src1_membase (cfg, load_opcode, ins->opcode) != -1)) {
-						ins->opcode = GINT_TO_OPCODE (op_to_op_src1_membase (cfg, load_opcode, ins->opcode));
-						sregs [0] = var->inst_basereg;
-						ins->inst_offset = var->inst_offset;
-					} else if ((srcindex == 1) && (op_to_op_src2_membase (cfg, load_opcode, ins->opcode) != -1)) {
-						ins->opcode = GINT_TO_OPCODE (op_to_op_src2_membase (cfg, load_opcode, ins->opcode));
-						sregs [1] = var->inst_basereg;
-						ins->inst_offset = var->inst_offset;
-					} else {
-						if (MONO_IS_REAL_MOVE (ins)) {
-							ins->opcode = OP_NOP;
-							sreg = ins->dreg;
-						} else {
-							sreg = alloc_dreg (cfg, stacktypes [regtype]);
-							if (!((var)->flags & (MONO_INST_VOLATILE|MONO_INST_INDIRECT)) && !no_lvreg) {
-								if (var->dreg == prev_dreg) {
-									/*
-									 * sreg refers to the value loaded by the load
-									 * emitted below, but we need to use ins->dreg
-									 * since it refers to the store emitted earlier.
-									 */
-									sreg = ins->dreg;
-								}
-								g_assert (sreg != -1);
-								if (var->dreg == dreg_using_dest_to_membase_op) {
-									if (cfg->verbose_level > 2)
-										printf ("\tCan't cache R%d because it's part of a dreg dest_membase optimization\n", var->dreg);
-								} else {
-									vreg_to_lvreg [var->dreg] = sreg;
-								}
-								if (lvregs_len >= lvregs_size) {
-									guint32 *new_lvregs = mono_mempool_alloc0 (cfg->mempool, sizeof (guint32) * lvregs_size * 2);
-									memcpy (new_lvregs, lvregs, sizeof (guint32) * lvregs_size);
-									lvregs = new_lvregs;
-									lvregs_size *= 2;
-								}
-								lvregs [lvregs_len ++] = var->dreg;
-							}
-						}
-						sregs [srcindex] = sreg;
-#if SIZEOF_REGISTER != 8
-						if (regtype == 'l') {
-							NEW_LOAD_MEMBASE (cfg, load_ins, OP_LOADI4_MEMBASE, MONO_LVREG_MS (sreg), var->inst_basereg, var->inst_offset + MINI_MS_WORD_OFFSET);
-							mono_bblock_insert_before_ins (bb, ins, load_ins);
-							NEW_LOAD_MEMBASE (cfg, load_ins, OP_LOADI4_MEMBASE, MONO_LVREG_LS (sreg), var->inst_basereg, var->inst_offset + MINI_LS_WORD_OFFSET);
-							mono_bblock_insert_before_ins (bb, ins, load_ins);
-							use_ins = load_ins;
-						}
-						else
-#endif
-						{
-#if SIZEOF_REGISTER == 4
-							g_assert (load_opcode != OP_LOADI8_MEMBASE);
-#endif
-							NEW_LOAD_MEMBASE (cfg, load_ins, load_opcode, sreg, var->inst_basereg, var->inst_offset);
-							if (load_ins->opcode == OP_LOADX_MEMBASE)
-								mini_type_to_eval_stack_type (cfg, var->inst_vtype, load_ins);
-							mono_bblock_insert_before_ins (bb, ins, load_ins);
-							use_ins = load_ins;
-						}
-						if (cfg->verbose_level > 2)
-							mono_print_ins_index (0, use_ins);
-					}
-					if (var->dreg < orig_next_vreg) {
-						live_range_end [var->dreg] = use_ins;
-						live_range_end_bb [var->dreg] = bb;
-					}
-					if (cfg->compute_gc_maps && var->dreg < orig_next_vreg && (var->flags & MONO_INST_GC_TRACK)) {
-						MonoInst *tmp;
-						MONO_INST_NEW (cfg, tmp, OP_GC_LIVENESS_USE);
-						tmp->inst_c1 = var->dreg;
-						mono_bblock_insert_after_ins (bb, ins, tmp);
-					}
-				}
-			}
-			mono_inst_set_src_registers (ins, sregs);
-			if (dest_has_lvreg) {
-				g_assert (ins->dreg != -1);
-				vreg_to_lvreg [prev_dreg] = ins->dreg;
-				if (lvregs_len >= lvregs_size) {
-					guint32 *new_lvregs = mono_mempool_alloc0 (cfg->mempool, sizeof (guint32) * lvregs_size * 2);
-					memcpy (new_lvregs, lvregs, sizeof (guint32) * lvregs_size);
-					lvregs = new_lvregs;
-					lvregs_size *= 2;
-				}
-				lvregs [lvregs_len ++] = prev_dreg;
-				dest_has_lvreg = FALSE;
-			}
-			if (store) {
-				tmp_reg = ins->dreg;
-				ins->dreg = ins->sreg2;
-				ins->sreg2 = tmp_reg;
-			}
-			if (MONO_IS_CALL (ins)) {
-				/* Clear vreg_to_lvreg array */
-				for (i = 0; i < lvregs_len; i++)
-					vreg_to_lvreg [lvregs [i]] = 0;
-				lvregs_len = 0;
-			} else if (ins->opcode == OP_NOP) {
-				ins->dreg = -1;
-				MONO_INST_NULLIFY_SREGS (ins);
-			}
-			if (cfg->verbose_level > 2)
-				mono_print_ins_index (1, ins);
-		}
-		/* Extend the live range based on the liveness info */
-		if (cfg->compute_precise_live_ranges && bb->live_out_set && bb->code) {
-			for (i = 0; i < cfg->num_varinfo; i ++) {
-				MonoMethodVar *vi = MONO_VARINFO (cfg, i);
-				if (vreg_is_volatile (cfg, vi->vreg))
-					/* The liveness info is incomplete */
-					continue;
-				if (mono_bitset_test_fast (bb->live_in_set, i) && !live_range_start [vi->vreg]) {
-					/* Live from at least the first ins of this bb */
-					live_range_start [vi->vreg] = bb->code;
-					live_range_start_bb [vi->vreg] = bb;
-				}
-				if (mono_bitset_test_fast (bb->live_out_set, i)) {
-					/* Live at least until the last ins of this bb */
-					live_range_end [vi->vreg] = bb->last_ins;
-					live_range_end_bb [vi->vreg] = bb;
-				}
-			}
-		}
-	}
-	/*
-	 * Emit LIVERANGE_START/LIVERANGE_END opcodes, the backend will implement them
-	 * by storing the current native offset into MonoMethodVar->live_range_start/end.
-	 */
-	if (cfg->compute_precise_live_ranges && cfg->comp_done & MONO_COMP_LIVENESS) {
-		for (i = 0; i < cfg->num_varinfo; ++i) {
-			int vreg = MONO_VARINFO (cfg, i)->vreg;
-			MonoInst *ins;
-			if (live_range_start [vreg]) {
-				MONO_INST_NEW (cfg, ins, OP_LIVERANGE_START);
-				ins->inst_c0 = i;
-				ins->inst_c1 = vreg;
-				mono_bblock_insert_after_ins (live_range_start_bb [vreg], live_range_start [vreg], ins);
-			}
-			if (live_range_end [vreg]) {
-				MONO_INST_NEW (cfg, ins, OP_LIVERANGE_END);
-				ins->inst_c0 = i;
-				ins->inst_c1 = vreg;
-				if (live_range_end [vreg] == live_range_end_bb [vreg]->last_ins)
-					mono_add_ins_to_end (live_range_end_bb [vreg], ins);
-				else
-					mono_bblock_insert_after_ins (live_range_end_bb [vreg], live_range_end [vreg], ins);
-			}
-		}
-	}
-	if (cfg->gsharedvt_locals_var_ins) {
-		/* Nullify if unused */
-		cfg->gsharedvt_locals_var_ins->opcode = OP_PCONST;
-		cfg->gsharedvt_locals_var_ins->inst_imm = 0;
-	}
-	g_free (live_range_start);
-	g_free (live_range_end);
-	g_free (live_range_start_bb);
-	g_free (live_range_end_bb);
-}
-/**
- * FIXME:
- * - use 'iadd' instead of 'int_add'
- * - handling ovf opcodes: decompose in method_to_ir.
- * - unify iregs/fregs
- *   -> partly done, the missing parts are:
- *   - a more complete unification would involve unifying the hregs as well, so
- *     code wouldn't need if (fp) all over the place. but that would mean the hregs
- *     would no longer map to the machine hregs, so the code generators would need to
- *     be modified. Also, on ia64 for example, niregs + nfregs > 256 -> bitmasks
- *     wouldn't work any more. Duplicating the code in mono_local_regalloc () into
- *     fp/non-fp branches speeds it up by about 15%.
- * - use sext/zext opcodes instead of shifts
- * - add OP_ICALL
- * - get rid of TEMPLOADs if possible and use vregs instead
- * - clean up usage of OP_P/OP_ opcodes
- * - cleanup usage of DUMMY_USE
- * - cleanup the setting of ins->type for MonoInst's which are pushed on the
- *   stack
- * - set the stack type and allocate a dreg in the EMIT_NEW macros
- * - get rid of all the <foo>2 stuff when the new JIT is ready.
- * - make sure handle_stack_args () is called before the branch is emitted
- * - when the new IR is done, get rid of all unused stuff
- * - COMPARE/BEQ as separate instructions or unify them ?
- *   - keeping them separate allows specialized compare instructions like
- *     compare_imm, compare_membase
- *   - most back ends unify fp compare+branch, fp compare+ceq
- * - integrate mono_save_args into inline_method
- * - get rid of the empty bblocks created by MONO_EMIT_NEW_BRACH_BLOCK2
- * - handle long shift opts on 32 bit platforms somehow: they require
- *   3 sregs (2 for arg1 and 1 for arg2)
- * - make byref a 'normal' type.
- * - use vregs for bb->out_stacks if possible, handle_global_vreg will make them a
- *   variable if needed.
- * - do not start a new IL level bblock when cfg->cbb is changed by a function call
- *   like inline_method.
- * - remove inlining restrictions
- * - fix LNEG and enable cfold of INEG
- * - generalize x86 optimizations like ldelema as a peephole optimization
- * - add store_mem_imm for amd64
- * - optimize the loading of the interruption flag in the managed->native wrappers
- * - avoid special handling of OP_NOP in passes
- * - move code inserting instructions into one function/macro.
- * - try a coalescing phase after liveness analysis
- * - add float -> vreg conversion + local optimizations on !x86
- * - figure out how to handle decomposed branches during optimizations, ie.
- *   compare+branch, op_jump_table+op_br etc.
- * - promote RuntimeXHandles to vregs
- * - vtype cleanups:
- *   - add a NEW_VARLOADA_VREG macro
- * - the vtype optimizations are blocked by the LDADDR opcodes generated for
- *   accessing vtype fields.
- * - get rid of I8CONST on 64 bit platforms
- * - dealing with the increase in code size due to branches created during opcode
- *   decomposition:
- *   - use extended basic blocks
- *     - all parts of the JIT
- *     - handle_global_vregs () && local regalloc
- *   - avoid introducing global vregs during decomposition, like 'vtable' in isinst
- * - sources of increase in code size:
- *   - vtypes
- *   - long compares
- *   - isinst and castclass
- *   - lvregs not allocated to global registers even if used multiple times
- * - call cctors outside the JIT, to make -v output more readable and JIT timings more
- *   meaningful.
- * - check for fp stack leakage in other opcodes too. (-> 'exceptions' optimization)
- * - add all micro optimizations from the old JIT
- * - put tree optimizations into the deadce pass
- * - decompose op_start_handler/op_endfilter/op_endfinally earlier using an arch
- *   specific function.
- * - unify the float comparison opcodes with the other comparison opcodes, i.e.
- *   fcompare + branchCC.
- * - create a helper function for allocating a stack slot, taking into account
- *   MONO_CFG_HAS_SPILLUP.
- * - merge r68207.
- * - optimize mono_regstate2_alloc_int/float.
- * - fix the pessimistic handling of variables accessed in exception handler blocks.
- * - need to write a tree optimization pass, but the creation of trees is difficult, i.e.
- *   parts of the tree could be separated by other instructions, killing the tree
- *   arguments, or stores killing loads etc. Also, should we fold loads into other
- *   instructions if the result of the load is used multiple times ?
- * - make the REM_IMM optimization in mini-x86.c arch-independent.
- * - LAST MERGE: 108395.
- * - when returning vtypes in registers, generate IR and append it to the end of the
- *   last bb instead of doing it in the epilog.
- * - change the store opcodes so they use sreg1 instead of dreg to store the base register.
- */
-/*
-NOTES
------
-- When to decompose opcodes:
-  - earlier: this makes some optimizations hard to implement, since the low level IR
-  no longer contains the necessary information. But it is easier to do.
-  - later: harder to implement, enables more optimizations.
-- Branches inside bblocks:
-  - created when decomposing complex opcodes.
-    - branches to another bblock: harmless, but not tracked by the branch
-      optimizations, so need to branch to a label at the start of the bblock.
-    - branches to inside the same bblock: very problematic, trips up the local
-      reg allocator. Can be fixed by spitting the current bblock, but that is a
-      complex operation, since some local vregs can become global vregs etc.
-- Local/global vregs:
-  - local vregs: temporary vregs used inside one bblock. Assigned to hregs by the
-    local register allocator.
-  - global vregs: used in more than one bblock. Have an associated MonoMethodVar
-    structure, created by mono_create_var (). Assigned to hregs or the stack by
-    the global register allocator.
-- When to do optimizations like alu->alu_imm:
-  - earlier -> saves work later on since the IR will be smaller/simpler
-  - later -> can work on more instructions
-- Handling of valuetypes:
-  - When a vtype is pushed on the stack, a new temporary is created, an
-    instruction computing its address (LDADDR) is emitted and pushed on
-    the stack. Need to optimize cases when the vtype is used immediately as in
-    argument passing, stloc etc.
-- Instead of the to_end stuff in the old JIT, simply call the function handling
-  the values on the stack before emitting the last instruction of the bb.
-*/
-#else /* !DISABLE_JIT */
-MONO_EMPTY_SOURCE_FILE (method_to_ir);
-#endif /* !DISABLE_JIT */

--- a/src/native/corehost/hostfxr.h
+++ b//dev/null
@@ -1,141 +0,0 @@
-#ifndef HAVE_HOSTFXR_H
-#define HAVE_HOSTFXR_H
-#include <stddef.h>
-#include <stdint.h>
-#ifdef __cplusplus
-extern "C"
-{
-#endif // __cplusplus
-#if defined(_WIN32)
-    #define HOSTFXR_CALLTYPE __cdecl
-    #ifdef _WCHAR_T_DEFINED
-        typedef wchar_t char_t;
-    #else
-        typedef unsigned short char_t;
-    #endif
-#else
-    #define HOSTFXR_CALLTYPE
-    typedef char char_t;
-#endif
-enum hostfxr_delegate_type
-{
-    hdt_com_activation,
-    hdt_load_in_memory_assembly,
-    hdt_winrt_activation,
-    hdt_com_register,
-    hdt_com_unregister,
-    hdt_load_assembly_and_get_function_pointer,
-    hdt_get_function_pointer,
-    hdt_load_assembly,
-    hdt_load_assembly_bytes,
-};
-typedef int32_t(HOSTFXR_CALLTYPE *hostfxr_main_fn)(const int argc, const char_t **argv);
-typedef int32_t(HOSTFXR_CALLTYPE *hostfxr_main_startupinfo_fn)(
-    const int argc,
-    const char_t **argv,
-    const char_t *host_path,
-    const char_t *dotnet_root,
-    const char_t *app_path);
-typedef int32_t(HOSTFXR_CALLTYPE* hostfxr_main_bundle_startupinfo_fn)(
-    const int argc,
-    const char_t** argv,
-    const char_t* host_path,
-    const char_t* dotnet_root,
-    const char_t* app_path,
-    int64_t bundle_header_offset);
-typedef void(HOSTFXR_CALLTYPE *hostfxr_error_writer_fn)(const char_t *message);
-typedef hostfxr_error_writer_fn(HOSTFXR_CALLTYPE *hostfxr_set_error_writer_fn)(hostfxr_error_writer_fn error_writer);
-typedef void* hostfxr_handle;
-struct hostfxr_initialize_parameters
-{
-    size_t size;
-    const char_t *host_path;
-    const char_t *dotnet_root;
-};
-typedef int32_t(HOSTFXR_CALLTYPE *hostfxr_initialize_for_dotnet_command_line_fn)(
-    int argc,
-    const char_t **argv,
-    const struct hostfxr_initialize_parameters *parameters,
-    /*out*/ hostfxr_handle *host_context_handle);
-typedef int32_t(HOSTFXR_CALLTYPE *hostfxr_initialize_for_runtime_config_fn)(
-    const char_t *runtime_config_path,
-    const struct hostfxr_initialize_parameters *parameters,
-    /*out*/ hostfxr_handle *host_context_handle);
-typedef int32_t(HOSTFXR_CALLTYPE *hostfxr_get_runtime_property_value_fn)(
-    const hostfxr_handle host_context_handle,
-    const char_t *name,
-    /*out*/ const char_t **value);
-typedef int32_t(HOSTFXR_CALLTYPE *hostfxr_set_runtime_property_value_fn)(
-    const hostfxr_handle host_context_handle,
-    const char_t *name,
-    const char_t *value);
-typedef int32_t(HOSTFXR_CALLTYPE *hostfxr_get_runtime_properties_fn)(
-    const hostfxr_handle host_context_handle,
-    /*inout*/ size_t * count,
-    /*out*/ const char_t **keys,
-    /*out*/ const char_t **values);
-typedef int32_t(HOSTFXR_CALLTYPE *hostfxr_run_app_fn)(const hostfxr_handle host_context_handle);
-typedef int32_t(HOSTFXR_CALLTYPE *hostfxr_get_runtime_delegate_fn)(
-    const hostfxr_handle host_context_handle,
-    enum hostfxr_delegate_type type,
-    /*out*/ void **delegate);
-typedef int32_t(HOSTFXR_CALLTYPE *hostfxr_close_fn)(const hostfxr_handle host_context_handle);
-struct hostfxr_dotnet_environment_sdk_info
-{
-    size_t size;
-    const char_t* version;
-    const char_t* path;
-};
-struct hostfxr_dotnet_environment_framework_info
-{
-    size_t size;
-    const char_t* name;
-    const char_t* version;
-    const char_t* path;
-};
-struct hostfxr_dotnet_environment_info
-{
-    size_t size;
-    const char_t* hostfxr_version;
-    const char_t* hostfxr_commit_hash;
-    size_t sdk_count;
-    const struct hostfxr_dotnet_environment_sdk_info* sdks;
-    size_t framework_count;
-    const struct hostfxr_dotnet_environment_framework_info* frameworks;
-};
-typedef void(HOSTFXR_CALLTYPE* hostfxr_get_dotnet_environment_info_result_fn)(
-    const struct hostfxr_dotnet_environment_info* info,
-    void* result_context);
-typedef int32_t(HOSTFXR_CALLTYPE* hostfxr_get_dotnet_environment_info_fn)(
-    const char_t* dotnet_root,
-    void* reserved,
-    hostfxr_get_dotnet_environment_info_result_fn result,
-    void* result_context);
-struct hostfxr_framework_result
-{
-    size_t size;
-    const char_t* name;
-    const char_t* requested_version;
-    const char_t* resolved_version;
-    const char_t* resolved_path;
-};
-struct hostfxr_resolve_frameworks_result
-{
-    size_t size;
-    size_t resolved_count;
-    const struct hostfxr_framework_result* resolved_frameworks;
-    size_t unresolved_count;
-    const struct hostfxr_framework_result* unresolved_frameworks;
-};
-typedef void (HOSTFXR_CALLTYPE* hostfxr_resolve_frameworks_result_fn)(
-    const struct hostfxr_resolve_frameworks_result* result,
-    void* result_context);
-typedef int32_t(HOSTFXR_CALLTYPE* hostfxr_resolve_frameworks_for_runtime_config_fn)(
-    const char_t* runtime_config_path,
-    /*opt*/ const struct hostfxr_initialize_parameters* parameters,
-    /*opt*/ hostfxr_resolve_frameworks_result_fn callback,
-    /*opt*/ void* result_context);
-#ifdef __cplusplus
-}
-#endif // __cplusplus
-#endif // HAVE_HOSTFXR_H
