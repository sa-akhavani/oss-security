# ====================================================================
# FILE: hazelcast-spring/src/main/java/com/hazelcast/spring/transaction/HazelcastTransactionManager.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 1-50 ---
     1| /*
     2|  * Copyright (c) 2008-2021, Hazelcast, Inc. All Rights Reserved.
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.spring.transaction;
    17| import com.hazelcast.core.HazelcastInstance;
    18| import com.hazelcast.transaction.TransactionContext;
    19| import com.hazelcast.transaction.TransactionOptions;
    20| import org.springframework.transaction.CannotCreateTransactionException;
    21| import org.springframework.transaction.NoTransactionException;
    22| import org.springframework.transaction.TransactionDefinition;
    23| import org.springframework.transaction.TransactionException;
    24| import org.springframework.transaction.TransactionSystemException;
    25| import org.springframework.transaction.support.AbstractPlatformTransactionManager;
    26| import org.springframework.transaction.support.DefaultTransactionStatus;
    27| import org.springframework.transaction.support.ResourceTransactionManager;
    28| import org.springframework.transaction.support.SmartTransactionObject;
    29| import org.springframework.transaction.support.TransactionSynchronizationManager;
    30| import java.util.concurrent.TimeUnit;
    31| /**
    32|  * {@link org.springframework.transaction.PlatformTransactionManager} implementation
    33|  * for a single {@link HazelcastInstance}. Binds a Hazelcast {@link TransactionContext}
    34|  * from the instance to the thread (as it is already bounded by Hazelcast itself) and makes it available for access.
    35|  * <p>
    36|  * <i>Note:</i> This transaction manager doesn't supports nested transactions, since Hazelcast doesn't support them either.
    37|  *
    38|  * @author Balint Krivan
    39|  * @see #getTransactionContext(HazelcastInstance)
    40|  * @see #getTransactionContext()
    41|  */
    42| public class HazelcastTransactionManager extends AbstractPlatformTransactionManager implements ResourceTransactionManager {
    43|     private HazelcastInstance hazelcastInstance;
    44|     public HazelcastTransactionManager(HazelcastInstance hazelcastInstance) {
    45|         this.hazelcastInstance = hazelcastInstance;
    46|     }
    47|     /**
    48|      * Returns the transaction context for the given Hazelcast instance bounded to the current thread.
    49|      *
    50|      * @throws NoTransactionException if the transaction context cannot be found

# --- HUNK 2: Lines 74-137 ---
    74|         HazelcastTransactionObject txObject = new HazelcastTransactionObject();
    75|         TransactionContextHolder transactionContextHolder =
    76|                 (TransactionContextHolder) TransactionSynchronizationManager.getResource(hazelcastInstance);
    77|         if (transactionContextHolder != null) {
    78|             if (logger.isDebugEnabled()) {
    79|                 logger.debug("Found thread-bound TransactionContext [" + transactionContextHolder.getContext() + "]");
    80|             }
    81|             txObject.setTransactionContextHolder(transactionContextHolder, false);
    82|         }
    83|         return txObject;
    84|     }
    85|     @Override
    86|     protected boolean isExistingTransaction(Object transaction) throws TransactionException {
    87|         return ((HazelcastTransactionObject) transaction).hasTransaction();
    88|     }
    89|     @Override
    90|     protected void doBegin(Object transaction, TransactionDefinition definition) throws TransactionException {
    91|         HazelcastTransactionObject txObject = (HazelcastTransactionObject) transaction;
    92|         try {
    93|             if (txObject.getTransactionContextHolder() == null) {
    94|                 TransactionContext transactionContext = getTransactionContext(definition);
    95|                 txObject.setTransactionContextHolder(new TransactionContextHolder(transactionContext), true);
    96|             }
    97|             txObject.getTransactionContextHolder().beginTransaction();
    98|             if (txObject.isNewTransactionContextHolder()) {
    99|                 TransactionSynchronizationManager.bindResource(hazelcastInstance, txObject.getTransactionContextHolder());
   100|             }
   101|         } catch (Throwable ex) {
   102|             closeTransactionContextAfterFailedBegin(txObject);
   103|             throw new CannotCreateTransactionException("Could not begin Hazelcast transaction", ex);
   104|         }
   105|     }
   106|     private TransactionContext getTransactionContext(TransactionDefinition definition) {
   107|         TransactionOptions options = TransactionOptions.getDefault();
   108|         if (definition.getTimeout() != TransactionDefinition.TIMEOUT_DEFAULT) {
   109|             options.setTimeout(definition.getTimeout(), TimeUnit.SECONDS);
   110|         } else if (getDefaultTimeout() != TransactionDefinition.TIMEOUT_DEFAULT) {
   111|             options.setTimeout(getDefaultTimeout(), TimeUnit.SECONDS);
   112|         }
   113|         TransactionContext transactionContext = hazelcastInstance.newTransactionContext(options);
   114|         if (logger.isDebugEnabled()) {
   115|             logger.debug("Opened new TransactionContext [" + transactionContext + "]");
   116|         }
   117|         return transactionContext;
   118|     }
   119|     private void closeTransactionContextAfterFailedBegin(HazelcastTransactionObject txObject) {
   120|         if (txObject.isNewTransactionContextHolder()) {
   121|             TransactionContext context = txObject.getTransactionContextHolder().getContext();
   122|             try {
   123|                 context.rollbackTransaction();
   124|             } catch (Throwable ex) {
   125|                 logger.debug("Could not rollback Hazelcast transaction after failed transaction begin", ex);
   126|             }
   127|             txObject.setTransactionContextHolder(null, false);
   128|         }
   129|     }
   130|     @Override
   131|     protected void doCommit(DefaultTransactionStatus status) throws TransactionException {
   132|         HazelcastTransactionObject txObject = (HazelcastTransactionObject) status.getTransaction();
   133|         if (status.isDebug()) {
   134|             logger.debug("Committing Hazelcast transaction on TransactionContext ["
   135|                     + txObject.getTransactionContextHolder().getContext() + "]");
   136|         }
   137|         try {


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/aws/AwsMetadataApi.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 2-185 ---
     2|  * Copyright (c) 2008-2021, Hazelcast, Inc. All Rights Reserved.
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.aws;
    17| import com.hazelcast.internal.json.Json;
    18| import com.hazelcast.internal.json.JsonObject;
    19| import com.hazelcast.logging.ILogger;
    20| import com.hazelcast.logging.Logger;
    21| import com.hazelcast.spi.utils.RestClient;
    22| import com.hazelcast.spi.exception.RestClientException;
    23| import java.util.Optional;
    24| import java.time.Instant;
    25| import static com.hazelcast.aws.AwsRequestUtils.createRestClient;
    26| import static com.hazelcast.spi.utils.RestClient.HTTP_NOT_FOUND;
    27| import static com.hazelcast.spi.utils.RestClient.HTTP_OK;
    28| /**
    29|  * Responsible for connecting to AWS EC2 and ECS Metadata API.
    30|  *
    31|  * @see <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html">EC2 Instance Metatadata</a>
    32|  * @see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html">ECS Task IAM Role Metadata</a>
    33|  * @see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-metadata-endpoint.html">ECS Task Metadata</a>
    34|  */
    35| class AwsMetadataApi {
    36|     private static final ILogger LOGGER = Logger.getLogger(AwsMetadataApi.class);
    37|     private static final String EC2_METADATA_ENDPOINT = "http://169.254.169.254/latest/meta-data";
    38|     private static final String ECS_IAM_ROLE_METADATA_ENDPOINT = "http://169.254.170.2" + System.getenv(
    39|         "AWS_CONTAINER_CREDENTIALS_RELATIVE_URI");
    40|     private static final String EC2_METADATA_TOKEN_ENDPOINT = "http://169.254.169.254/latest/api/token";
    41|     private static final String ECS_TASK_METADATA_ENDPOINT = System.getenv("ECS_CONTAINER_METADATA_URI");
    42|     private static final String SECURITY_CREDENTIALS_URI = "/iam/security-credentials/";
    43|     private static final long METADATA_TOKEN_TTL_SECONDS = 21600;
    44|     private final String ec2MetadataEndpoint;
    45|     private final String ec2MetadataTokenEndpoint;
    46|     private final String ecsIamRoleEndpoint;
    47|     private final String ecsTaskMetadataEndpoint;
    48|     private final AwsConfig awsConfig;
    49|     private String metadataToken;
    50|     private Instant metadataExpiry;
    51|     AwsMetadataApi(AwsConfig awsConfig) {
    52|         this.ec2MetadataEndpoint = EC2_METADATA_ENDPOINT;
    53|         this.ec2MetadataTokenEndpoint = EC2_METADATA_TOKEN_ENDPOINT;
    54|         this.ecsIamRoleEndpoint = ECS_IAM_ROLE_METADATA_ENDPOINT;
    55|         this.ecsTaskMetadataEndpoint = ECS_TASK_METADATA_ENDPOINT;
    56|         this.awsConfig = awsConfig;
    57|     }
    58|     /**
    59|      * For test purposes only.
    60|      */
    61|     AwsMetadataApi(String ec2MetadataEndpoint, String ecsIamRoleEndpoint, String ecsTaskMetadataEndpoint,
    62|                    String ec2MetadataTokenEndpoint, AwsConfig awsConfig) {
    63|         this.ec2MetadataEndpoint = ec2MetadataEndpoint;
    64|         this.ec2MetadataTokenEndpoint = ec2MetadataTokenEndpoint;
    65|         this.ecsIamRoleEndpoint = ecsIamRoleEndpoint;
    66|         this.ecsTaskMetadataEndpoint = ecsTaskMetadataEndpoint;
    67|         this.awsConfig = awsConfig;
    68|     }
    69|     String availabilityZoneEc2() {
    70|         String uri = ec2MetadataEndpoint.concat("/placement/availability-zone/");
    71|         return metadataClient(uri, awsConfig).get().getBody();
    72|     }
    73|     Optional<String> placementGroupEc2() {
    74|         return getOptionalMetadata(ec2MetadataEndpoint.concat("/placement/group-name/"), "placement group");
    75|     }
    76|     Optional<String> placementPartitionNumberEc2() {
    77|         return getOptionalMetadata(ec2MetadataEndpoint.concat("/placement/partition-number/"), "partition number");
    78|     }
    79|     /**
    80|      * Resolves an optional metadata that exists for some instances only.
    81|      * HTTP_OK and HTTP_NOT_FOUND responses are assumed valid. Any other
    82|      * response code or an exception thrown during retries will yield
    83|      * a warning log and an empty result will be returned.
    84|      *
    85|      * @param uri  Metadata URI
    86|      * @param loggedName  Metadata name to be used when logging.
    87|      * @return  The metadata if the endpoint exists, empty otherwise.
    88|      */
    89|     private Optional<String> getOptionalMetadata(String uri, String loggedName) {
    90|         RestClient.Response response;
    91|         try {
    92|             response = metadataClient(uri, awsConfig)
    93|                     .expectResponseCodes(HTTP_OK, HTTP_NOT_FOUND)
    94|                     .get();
    95|         } catch (Exception e) {
    96|             LOGGER.warning(String.format("Could not resolve the %s metadata", loggedName));
    97|             return Optional.empty();
    98|         }
    99|         int responseCode = response.getCode();
   100|         if (responseCode == HTTP_OK) {
   101|             return Optional.of(response.getBody());
   102|         } else if (responseCode == HTTP_NOT_FOUND) {
   103|             LOGGER.fine(String.format("No %s information is found.", loggedName));
   104|             return Optional.empty();
   105|         } else {
   106|             throw new RuntimeException(String.format("Unexpected response code: %d", responseCode));
   107|         }
   108|     }
   109|     private JsonObject getTaskMetadata() {
   110|         String uri = ecsTaskMetadataEndpoint.concat("/task");
   111|         String response = createRestClient(uri, awsConfig).get().getBody();
   112|         return Json.parse(response).asObject();
   113|     }
   114|     String defaultIamRoleEc2() {
   115|         String uri = ec2MetadataEndpoint.concat(SECURITY_CREDENTIALS_URI);
   116|         return metadataClient(uri, awsConfig).get().getBody();
   117|     }
   118|     AwsCredentials credentialsEc2(String iamRole) {
   119|         String uri = ec2MetadataEndpoint.concat(SECURITY_CREDENTIALS_URI).concat(iamRole);
   120|         String response = metadataClient(uri, awsConfig).get().getBody();
   121|         return parseCredentials(response);
   122|     }
   123|     AwsCredentials credentialsEcs() {
   124|         String response = createRestClient(ecsIamRoleEndpoint, awsConfig).get().getBody();
   125|         return parseCredentials(response);
   126|     }
   127|     private static AwsCredentials parseCredentials(String response) {
   128|         JsonObject role = Json.parse(response).asObject();
   129|         return AwsCredentials.builder()
   130|             .setAccessKey(role.getString("AccessKeyId", null))
   131|             .setSecretKey(role.getString("SecretAccessKey", null))
   132|             .setToken(role.getString("Token", null))
   133|             .build();
   134|     }
   135|     EcsMetadata metadataEcs() {
   136|         String response = createRestClient(ecsTaskMetadataEndpoint, awsConfig).get().getBody();
   137|         return parseEcsMetadata(response);
   138|     }
   139|     private EcsMetadata parseEcsMetadata(String response) {
   140|         JsonObject metadata = Json.parse(response).asObject();
   141|         JsonObject labels = metadata.get("Labels").asObject();
   142|         String taskArn = labels.get("com.amazonaws.ecs.task-arn").asString();
   143|         String clusterArn = labels.get("com.amazonaws.ecs.cluster").asString();
   144|         return new EcsMetadata(taskArn, clusterArn);
   145|     }
   146|     static class EcsMetadata {
   147|         private final String taskArn;
   148|         private final String clusterArn;
   149|         EcsMetadata(String taskArn, String clusterArn) {
   150|             this.taskArn = taskArn;
   151|             this.clusterArn = clusterArn;
   152|         }
   153|         String getTaskArn() {
   154|             return taskArn;
   155|         }
   156|         String getClusterArn() {
   157|             return clusterArn;
   158|         }
   159|     }
   160|     RestClient metadataClient(String url, AwsConfig awsConfig) {
   161|         try {
   162|             return createRestClient(url, awsConfig)
   163|                 .withHeader("X-aws-ec2-metadata-token", metadataToken());
   164|         } catch (RestClientException ignored) {
   165|             return createRestClient(url, awsConfig);
   166|         }
   167|     }
   168|     String metadataToken() {
   169|         if (!tokenValid()) {
   170|             metadataToken = retrieveToken();
   171|         }
   172|         return metadataToken;
   173|     }
   174|     String retrieveToken() {
   175|         String response = createRestClient(ec2MetadataTokenEndpoint, awsConfig)
   176|             .withHeader("X-aws-ec2-metadata-token-ttl-seconds", Long.toString(METADATA_TOKEN_TTL_SECONDS))
   177|             .put()
   178|             .getBody();
   179|         metadataExpiry = Instant.now().plusSeconds(METADATA_TOKEN_TTL_SECONDS / 2);
   180|         return response;
   181|     }
   182|     boolean tokenValid() {
   183|         return metadataExpiry != null && metadataExpiry.isAfter(Instant.now());
   184|     }
   185| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/dynamicconfig/AddCacheConfigMessageTask.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 9-106 ---
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.dynamicconfig;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.DynamicConfigAddCacheConfigCodec;
    19| import com.hazelcast.config.CachePartitionLostListenerConfig;
    20| import com.hazelcast.config.CacheSimpleConfig;
    21| import com.hazelcast.config.CacheSimpleConfig.ExpiryPolicyFactoryConfig;
    22| import com.hazelcast.config.InMemoryFormat;
    23| import com.hazelcast.instance.impl.Node;
    24| import com.hazelcast.internal.dynamicconfig.DynamicConfigurationAwareConfig;
    25| import com.hazelcast.internal.nio.Connection;
    26| import com.hazelcast.nio.serialization.IdentifiedDataSerializable;
    27| import java.util.ArrayList;
    28| import java.util.List;
    29| @SuppressWarnings("checkstyle:npathcomplexity")
    30| public class AddCacheConfigMessageTask
    31|         extends AbstractAddConfigMessageTask<DynamicConfigAddCacheConfigCodec.RequestParameters> {
    32|     public AddCacheConfigMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    33|         super(clientMessage, node, connection);
    34|     }
    35|     @Override
    36|     protected DynamicConfigAddCacheConfigCodec.RequestParameters decodeClientMessage(ClientMessage clientMessage) {
    37|         return DynamicConfigAddCacheConfigCodec.decodeRequest(clientMessage);
    38|     }
    39|     @Override
    40|     protected ClientMessage encodeResponse(Object response) {
    41|         return DynamicConfigAddCacheConfigCodec.encodeResponse();
    42|     }
    43|     @Override
    44|     protected IdentifiedDataSerializable getConfig() {
    45|         CacheSimpleConfig config = new CacheSimpleConfig();
    46|         config.setAsyncBackupCount(parameters.asyncBackupCount);
    47|         config.setBackupCount(parameters.backupCount);
    48|         config.setCacheEntryListeners(parameters.cacheEntryListeners);
    49|         config.setCacheLoader(parameters.cacheLoader);
    50|         config.setCacheLoaderFactory(parameters.cacheLoaderFactory);
    51|         config.setCacheWriter(parameters.cacheWriter);
    52|         config.setCacheWriterFactory(parameters.cacheWriterFactory);
    53|         config.setDisablePerEntryInvalidationEvents(parameters.disablePerEntryInvalidationEvents);
    54|         if (parameters.evictionConfig != null) {
    55|             config.setEvictionConfig(parameters.evictionConfig.asEvictionConfg(serializationService));
    56|         }
    57|         if (parameters.expiryPolicyFactoryClassName != null) {
    58|             config.setExpiryPolicyFactory(parameters.expiryPolicyFactoryClassName);
    59|         } else if (parameters.timedExpiryPolicyFactoryConfig != null) {
    60|             ExpiryPolicyFactoryConfig expiryPolicyFactoryConfig =
    61|                     new ExpiryPolicyFactoryConfig(parameters.timedExpiryPolicyFactoryConfig);
    62|             config.setExpiryPolicyFactoryConfig(expiryPolicyFactoryConfig);
    63|         }
    64|         if (parameters.eventJournalConfig != null) {
    65|             config.setEventJournalConfig(parameters.eventJournalConfig);
    66|         }
    67|         if (parameters.hotRestartConfig != null) {
    68|             config.setHotRestartConfig(parameters.hotRestartConfig);
    69|         }
    70|         config.setInMemoryFormat(InMemoryFormat.valueOf(parameters.inMemoryFormat));
    71|         config.setKeyType(parameters.keyType);
    72|         config.setManagementEnabled(parameters.managementEnabled);
    73|         if (parameters.mergePolicy != null) {
    74|             config.setMergePolicyConfig(mergePolicyConfig(parameters.mergePolicy, parameters.mergeBatchSize));
    75|         }
    76|         config.setName(parameters.name);
    77|         if (parameters.partitionLostListenerConfigs != null && !parameters.partitionLostListenerConfigs.isEmpty()) {
    78|             List<CachePartitionLostListenerConfig> listenerConfigs = (List<CachePartitionLostListenerConfig>)
    79|                     adaptListenerConfigs(parameters.partitionLostListenerConfigs);
    80|             config.setPartitionLostListenerConfigs(listenerConfigs);
    81|         } else {
    82|             config.setPartitionLostListenerConfigs(new ArrayList<>());
    83|         }
    84|         config.setSplitBrainProtectionName(parameters.splitBrainProtectionName);
    85|         config.setReadThrough(parameters.readThrough);
    86|         config.setStatisticsEnabled(parameters.statisticsEnabled);
    87|         config.setValueType(parameters.valueType);
    88|         config.setWanReplicationRef(parameters.wanReplicationRef);
    89|         config.setWriteThrough(parameters.writeThrough);
    90|         if (parameters.isMerkleTreeConfigExists && parameters.merkleTreeConfig != null) {
    91|             config.setMerkleTreeConfig(parameters.merkleTreeConfig);
    92|         }
    93|         return config;
    94|     }
    95|     @Override
    96|     public String getMethodName() {
    97|         return "addCacheConfig";
    98|     }
    99|     @Override
   100|     protected boolean checkStaticConfigDoesNotExist(IdentifiedDataSerializable config) {
   101|         DynamicConfigurationAwareConfig nodeConfig = (DynamicConfigurationAwareConfig) nodeEngine.getConfig();
   102|         CacheSimpleConfig cacheConfig = (CacheSimpleConfig) config;
   103|         return nodeConfig.checkStaticConfigDoesNotExist(nodeConfig.getStaticConfig().getCacheConfigs(),
   104|                 cacheConfig.getName(), cacheConfig);
   105|     }
   106| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/executorservice/ExecutorServiceCancelOnAddressMessageTask.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 4-75 ---
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.executorservice;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.ExecutorServiceCancelOnMemberCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractTargetMessageTask;
    20| import com.hazelcast.executor.impl.DistributedExecutorService;
    21| import com.hazelcast.executor.impl.operations.CancellationOperation;
    22| import com.hazelcast.instance.impl.Node;
    23| import com.hazelcast.internal.nio.Connection;
    24| import com.hazelcast.security.permission.ActionConstants;
    25| import com.hazelcast.security.permission.ExecutorServicePermission;
    26| import com.hazelcast.spi.impl.operationservice.Operation;
    27| import java.security.Permission;
    28| import java.util.UUID;
    29| public class ExecutorServiceCancelOnAddressMessageTask
    30|         extends AbstractTargetMessageTask<ExecutorServiceCancelOnMemberCodec.RequestParameters> {
    31|     public ExecutorServiceCancelOnAddressMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    32|         super(clientMessage, node, connection);
    33|     }
    34|     @Override
    35|     protected Operation prepareOperation() {
    36|         return new CancellationOperation(parameters.uuid, parameters.interrupt);
    37|     }
    38|     @Override
    39|     protected UUID getTargetUuid() {
    40|         return parameters.memberUUID;
    41|     }
    42|     @Override
    43|     protected ExecutorServiceCancelOnMemberCodec.RequestParameters decodeClientMessage(ClientMessage clientMessage) {
    44|         return ExecutorServiceCancelOnMemberCodec.decodeRequest(clientMessage);
    45|     }
    46|     @Override
    47|     protected ClientMessage encodeResponse(Object response) {
    48|         return ExecutorServiceCancelOnMemberCodec.encodeResponse((Boolean) response);
    49|     }
    50|     @Override
    51|     public String getDistributedObjectName() {
    52|         DistributedExecutorService service = getService(getServiceName());
    53|         return service.getName(parameters.uuid);
    54|     }
    55|     @Override
    56|     public String getServiceName() {
    57|         return DistributedExecutorService.SERVICE_NAME;
    58|     }
    59|     @Override
    60|     public Permission getRequiredPermission() {
    61|         String name = getDistributedObjectName();
    62|         if (name == null) {
    63|             name = ExecutorServicePermission.EMPTY_EXECUTOR_NAME;
    64|         }
    65|         return new ExecutorServicePermission(name, ActionConstants.ACTION_MODIFY);
    66|     }
    67|     @Override
    68|     public String getMethodName() {
    69|         return "cancel";
    70|     }
    71|     @Override
    72|     public Object[] getParameters() {
    73|         return null;
    74|     }
    75| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/executorservice/ExecutorServiceCancelOnPartitionMessageTask.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 4-69 ---
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.executorservice;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.ExecutorServiceCancelOnPartitionCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractPartitionMessageTask;
    20| import com.hazelcast.executor.impl.DistributedExecutorService;
    21| import com.hazelcast.executor.impl.operations.CancellationOperation;
    22| import com.hazelcast.instance.impl.Node;
    23| import com.hazelcast.internal.nio.Connection;
    24| import com.hazelcast.security.permission.ActionConstants;
    25| import com.hazelcast.security.permission.ExecutorServicePermission;
    26| import com.hazelcast.spi.impl.operationservice.Operation;
    27| import java.security.Permission;
    28| public class ExecutorServiceCancelOnPartitionMessageTask
    29|         extends AbstractPartitionMessageTask<ExecutorServiceCancelOnPartitionCodec.RequestParameters> {
    30|     public ExecutorServiceCancelOnPartitionMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    31|         super(clientMessage, node, connection);
    32|     }
    33|     @Override
    34|     protected Operation prepareOperation() {
    35|         return new CancellationOperation(parameters.uuid, parameters.interrupt);
    36|     }
    37|     @Override
    38|     protected ExecutorServiceCancelOnPartitionCodec.RequestParameters decodeClientMessage(ClientMessage clientMessage) {
    39|         return ExecutorServiceCancelOnPartitionCodec.decodeRequest(clientMessage);
    40|     }
    41|     protected ClientMessage encodeResponse(Object response) {
    42|         return ExecutorServiceCancelOnPartitionCodec.encodeResponse((Boolean) response);
    43|     }
    44|     @Override
    45|     public String getDistributedObjectName() {
    46|         DistributedExecutorService service = getService(getServiceName());
    47|         return service.getName(parameters.uuid);
    48|     }
    49|     @Override
    50|     public String getServiceName() {
    51|         return DistributedExecutorService.SERVICE_NAME;
    52|     }
    53|     @Override
    54|     public Permission getRequiredPermission() {
    55|         String name = getDistributedObjectName();
    56|         if (name == null) {
    57|             name = ExecutorServicePermission.EMPTY_EXECUTOR_NAME;
    58|         }
    59|         return new ExecutorServicePermission(name, ActionConstants.ACTION_MODIFY);
    60|     }
    61|     @Override
    62|     public String getMethodName() {
    63|         return "cancel";
    64|     }
    65|     @Override
    66|     public Object[] getParameters() {
    67|         return null;
    68|     }
    69| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/executorservice/ExecutorServiceIsShutdownMessageTask.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 3-64 ---
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.executorservice;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.ExecutorServiceIsShutdownCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractCallableMessageTask;
    20| import com.hazelcast.executor.impl.DistributedExecutorService;
    21| import com.hazelcast.instance.impl.Node;
    22| import com.hazelcast.internal.nio.Connection;
    23| import com.hazelcast.security.permission.ActionConstants;
    24| import com.hazelcast.security.permission.ExecutorServicePermission;
    25| import java.security.Permission;
    26| public class ExecutorServiceIsShutdownMessageTask
    27|         extends AbstractCallableMessageTask<String> {
    28|     public ExecutorServiceIsShutdownMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    29|         super(clientMessage, node, connection);
    30|     }
    31|     @Override
    32|     protected Object call() throws Exception {
    33|         final DistributedExecutorService service = getService(DistributedExecutorService.SERVICE_NAME);
    34|         return service.isShutdown(parameters);
    35|     }
    36|     @Override
    37|     protected String decodeClientMessage(ClientMessage clientMessage) {
    38|         return ExecutorServiceIsShutdownCodec.decodeRequest(clientMessage);
    39|     }
    40|     @Override
    41|     protected ClientMessage encodeResponse(Object response) {
    42|         return ExecutorServiceIsShutdownCodec.encodeResponse((Boolean) response);
    43|     }
    44|     @Override
    45|     public String getServiceName() {
    46|         return DistributedExecutorService.SERVICE_NAME;
    47|     }
    48|     @Override
    49|     public Permission getRequiredPermission() {
    50|         return new ExecutorServicePermission(parameters, ActionConstants.ACTION_READ);
    51|     }
    52|     @Override
    53|     public String getDistributedObjectName() {
    54|         return parameters;
    55|     }
    56|     @Override
    57|     public String getMethodName() {
    58|         return "isShutdown";
    59|     }
    60|     @Override
    61|     public Object[] getParameters() {
    62|         return null;
    63|     }
    64| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/executorservice/ExecutorServiceShutdownMessageTask.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 3-65 ---
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.executorservice;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.ExecutorServiceShutdownCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractCallableMessageTask;
    20| import com.hazelcast.executor.impl.DistributedExecutorService;
    21| import com.hazelcast.instance.impl.Node;
    22| import com.hazelcast.internal.nio.Connection;
    23| import com.hazelcast.security.permission.ActionConstants;
    24| import com.hazelcast.security.permission.ExecutorServicePermission;
    25| import java.security.Permission;
    26| public class ExecutorServiceShutdownMessageTask
    27|         extends AbstractCallableMessageTask<String> {
    28|     public ExecutorServiceShutdownMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    29|         super(clientMessage, node, connection);
    30|     }
    31|     @Override
    32|     protected Object call() throws Exception {
    33|         final DistributedExecutorService service = getService(DistributedExecutorService.SERVICE_NAME);
    34|         service.shutdownExecutor(parameters);
    35|         return null;
    36|     }
    37|     @Override
    38|     protected String decodeClientMessage(ClientMessage clientMessage) {
    39|         return ExecutorServiceShutdownCodec.decodeRequest(clientMessage);
    40|     }
    41|     @Override
    42|     protected ClientMessage encodeResponse(Object response) {
    43|         return ExecutorServiceShutdownCodec.encodeResponse();
    44|     }
    45|     @Override
    46|     public String getServiceName() {
    47|         return DistributedExecutorService.SERVICE_NAME;
    48|     }
    49|     @Override
    50|     public Permission getRequiredPermission() {
    51|         return new ExecutorServicePermission(parameters, ActionConstants.ACTION_MODIFY);
    52|     }
    53|     @Override
    54|     public String getDistributedObjectName() {
    55|         return parameters;
    56|     }
    57|     @Override
    58|     public String getMethodName() {
    59|         return "shutdown";
    60|     }
    61|     @Override
    62|     public Object[] getParameters() {
    63|         return null;
    64|     }
    65| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/executorservice/ExecutorServiceSubmitToAddressMessageTask.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 6-47 ---
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.executorservice;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.ExecutorServiceSubmitToMemberCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractTargetMessageTask;
    20| import com.hazelcast.executor.impl.DistributedExecutorService;
    21| import com.hazelcast.executor.impl.operations.MemberCallableTaskOperation;
    22| import com.hazelcast.instance.impl.Node;
    23| import com.hazelcast.internal.nio.Connection;
    24| import com.hazelcast.internal.serialization.Data;
    25| import com.hazelcast.security.SecurityContext;
    26| import com.hazelcast.security.permission.ActionConstants;
    27| import com.hazelcast.security.permission.ExecutorServicePermission;
    28| import com.hazelcast.spi.impl.operationservice.Operation;
    29| import javax.security.auth.Subject;
    30| import java.security.Permission;
    31| import java.util.UUID;
    32| import java.util.concurrent.Callable;
    33| public class ExecutorServiceSubmitToAddressMessageTask
    34|         extends AbstractTargetMessageTask<ExecutorServiceSubmitToMemberCodec.RequestParameters> {
    35|     public ExecutorServiceSubmitToAddressMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    36|         super(clientMessage, node, connection);
    37|     }
    38|     @Override
    39|     protected UUID getTargetUuid() {
    40|         return parameters.memberUUID;
    41|     }
    42|     @Override
    43|     protected Operation prepareOperation() {
    44|         SecurityContext securityContext = clientEngine.getSecurityContext();
    45|         Data callableData = parameters.callable;
    46|         if (securityContext != null) {
    47|             Subject subject = endpoint.getSubject();

# --- HUNK 2: Lines 56-90 ---
    56|         }
    57|         MemberCallableTaskOperation op = new MemberCallableTaskOperation(parameters.name, parameters.uuid, callableData);
    58|         op.setCallerUuid(endpoint.getUuid());
    59|         return op;
    60|     }
    61|     @Override
    62|     protected ExecutorServiceSubmitToMemberCodec.RequestParameters decodeClientMessage(ClientMessage clientMessage) {
    63|         return ExecutorServiceSubmitToMemberCodec.decodeRequest(clientMessage);
    64|     }
    65|     @Override
    66|     protected ClientMessage encodeResponse(Object response) {
    67|         Data data = serializationService.toData(response);
    68|         return ExecutorServiceSubmitToMemberCodec.encodeResponse(data);
    69|     }
    70|     @Override
    71|     public String getServiceName() {
    72|         return DistributedExecutorService.SERVICE_NAME;
    73|     }
    74|     @Override
    75|     public Permission getRequiredPermission() {
    76|         return new ExecutorServicePermission(parameters.name, ActionConstants.ACTION_MODIFY);
    77|     }
    78|     @Override
    79|     public String getDistributedObjectName() {
    80|         return parameters.name;
    81|     }
    82|     @Override
    83|     public String getMethodName() {
    84|         return null;
    85|     }
    86|     @Override
    87|     public Object[] getParameters() {
    88|         return null;
    89|     }
    90| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/executorservice/ExecutorServiceSubmitToPartitionMessageTask.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 6-47 ---
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.executorservice;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.ExecutorServiceSubmitToPartitionCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractPartitionMessageTask;
    20| import com.hazelcast.executor.impl.DistributedExecutorService;
    21| import com.hazelcast.executor.impl.operations.CallableTaskOperation;
    22| import com.hazelcast.instance.impl.Node;
    23| import com.hazelcast.internal.nio.Connection;
    24| import com.hazelcast.internal.serialization.Data;
    25| import com.hazelcast.security.SecurityContext;
    26| import com.hazelcast.security.permission.ActionConstants;
    27| import com.hazelcast.security.permission.ExecutorServicePermission;
    28| import com.hazelcast.spi.impl.operationservice.Operation;
    29| import javax.security.auth.Subject;
    30| import java.security.Permission;
    31| import java.util.concurrent.Callable;
    32| public class ExecutorServiceSubmitToPartitionMessageTask
    33|         extends AbstractPartitionMessageTask<ExecutorServiceSubmitToPartitionCodec.RequestParameters> {
    34|     public ExecutorServiceSubmitToPartitionMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    35|         super(clientMessage, node, connection);
    36|     }
    37|     @Override
    38|     protected Operation prepareOperation() {
    39|         SecurityContext securityContext = clientEngine.getSecurityContext();
    40|         Data callableData = parameters.callable;
    41|         if (securityContext != null) {
    42|             Subject subject = endpoint.getSubject();
    43|             Object taskObject = serializationService.toObject(parameters.callable);
    44|             Callable callable;
    45|             if (taskObject instanceof Runnable) {
    46|                 callable = securityContext.createSecureCallable(subject, (Runnable) taskObject);
    47|             } else {

# --- HUNK 2: Lines 49-83 ---
    49|             }
    50|             callableData = serializationService.toData(callable);
    51|         }
    52|         return new CallableTaskOperation(parameters.name, parameters.uuid, callableData);
    53|     }
    54|     @Override
    55|     protected ExecutorServiceSubmitToPartitionCodec.RequestParameters decodeClientMessage(ClientMessage clientMessage) {
    56|         return ExecutorServiceSubmitToPartitionCodec.decodeRequest(clientMessage);
    57|     }
    58|     @Override
    59|     protected ClientMessage encodeResponse(Object response) {
    60|         Data data = serializationService.toData(response);
    61|         return ExecutorServiceSubmitToPartitionCodec.encodeResponse(data);
    62|     }
    63|     @Override
    64|     public String getServiceName() {
    65|         return DistributedExecutorService.SERVICE_NAME;
    66|     }
    67|     @Override
    68|     public Permission getRequiredPermission() {
    69|         return new ExecutorServicePermission(parameters.name, ActionConstants.ACTION_MODIFY);
    70|     }
    71|     @Override
    72|     public String getDistributedObjectName() {
    73|         return parameters.name;
    74|     }
    75|     @Override
    76|     public String getMethodName() {
    77|         return null;
    78|     }
    79|     @Override
    80|     public Object[] getParameters() {
    81|         return null;
    82|     }
    83| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/executorservice/durable/DurableExecutorDisposeResultMessageTask.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 3-65 ---
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.executorservice.durable;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.DurableExecutorDisposeResultCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractPartitionMessageTask;
    20| import com.hazelcast.durableexecutor.impl.operations.DisposeResultOperation;
    21| import com.hazelcast.instance.impl.Node;
    22| import com.hazelcast.internal.nio.Connection;
    23| import com.hazelcast.security.permission.ActionConstants;
    24| import com.hazelcast.security.permission.DurableExecutorServicePermission;
    25| import com.hazelcast.spi.impl.operationservice.Operation;
    26| import java.security.Permission;
    27| import static com.hazelcast.durableexecutor.impl.DistributedDurableExecutorService.SERVICE_NAME;
    28| public class DurableExecutorDisposeResultMessageTask
    29|         extends AbstractPartitionMessageTask<DurableExecutorDisposeResultCodec.RequestParameters> {
    30|     public DurableExecutorDisposeResultMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    31|         super(clientMessage, node, connection);
    32|     }
    33|     @Override
    34|     protected Operation prepareOperation() {
    35|         return new DisposeResultOperation(parameters.name, parameters.sequence);
    36|     }
    37|     @Override
    38|     protected DurableExecutorDisposeResultCodec.RequestParameters decodeClientMessage(ClientMessage clientMessage) {
    39|         return DurableExecutorDisposeResultCodec.decodeRequest(clientMessage);
    40|     }
    41|     @Override
    42|     protected ClientMessage encodeResponse(Object response) {
    43|         return DurableExecutorDisposeResultCodec.encodeResponse();
    44|     }
    45|     @Override
    46|     public String getServiceName() {
    47|         return SERVICE_NAME;
    48|     }
    49|     @Override
    50|     public Permission getRequiredPermission() {
    51|         return new DurableExecutorServicePermission(parameters.name, ActionConstants.ACTION_MODIFY);
    52|     }
    53|     @Override
    54|     public String getDistributedObjectName() {
    55|         return parameters.name;
    56|     }
    57|     @Override
    58|     public String getMethodName() {
    59|         return null;
    60|     }
    61|     @Override
    62|     public Object[] getParameters() {
    63|         return null;
    64|     }
    65| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/executorservice/durable/DurableExecutorIsShutdownMessageTask.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 3-65 ---
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.executorservice.durable;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.DurableExecutorIsShutdownCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractCallableMessageTask;
    20| import com.hazelcast.durableexecutor.impl.DistributedDurableExecutorService;
    21| import com.hazelcast.instance.impl.Node;
    22| import com.hazelcast.internal.nio.Connection;
    23| import com.hazelcast.security.permission.ActionConstants;
    24| import com.hazelcast.security.permission.DurableExecutorServicePermission;
    25| import java.security.Permission;
    26| import static com.hazelcast.durableexecutor.impl.DistributedDurableExecutorService.SERVICE_NAME;
    27| public class DurableExecutorIsShutdownMessageTask
    28|         extends AbstractCallableMessageTask<String> {
    29|     public DurableExecutorIsShutdownMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    30|         super(clientMessage, node, connection);
    31|     }
    32|     @Override
    33|     protected Object call() throws Exception {
    34|         DistributedDurableExecutorService service = getService(SERVICE_NAME);
    35|         return service.isShutdown(parameters);
    36|     }
    37|     @Override
    38|     protected String decodeClientMessage(ClientMessage clientMessage) {
    39|         return DurableExecutorIsShutdownCodec.decodeRequest(clientMessage);
    40|     }
    41|     @Override
    42|     protected ClientMessage encodeResponse(Object response) {
    43|         return DurableExecutorIsShutdownCodec.encodeResponse((Boolean) response);
    44|     }
    45|     @Override
    46|     public String getServiceName() {
    47|         return SERVICE_NAME;
    48|     }
    49|     @Override
    50|     public Permission getRequiredPermission() {
    51|         return new DurableExecutorServicePermission(parameters, ActionConstants.ACTION_READ);
    52|     }
    53|     @Override
    54|     public String getDistributedObjectName() {
    55|         return parameters;
    56|     }
    57|     @Override
    58|     public String getMethodName() {
    59|         return "isShutdown";
    60|     }
    61|     @Override
    62|     public Object[] getParameters() {
    63|         return null;
    64|     }
    65| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/executorservice/durable/DurableExecutorRetrieveAndDisposeResultMessageTask.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 4-67 ---
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.executorservice.durable;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.DurableExecutorRetrieveAndDisposeResultCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractPartitionMessageTask;
    20| import com.hazelcast.durableexecutor.impl.operations.RetrieveAndDisposeResultOperation;
    21| import com.hazelcast.instance.impl.Node;
    22| import com.hazelcast.internal.nio.Connection;
    23| import com.hazelcast.internal.serialization.Data;
    24| import com.hazelcast.security.permission.ActionConstants;
    25| import com.hazelcast.security.permission.DurableExecutorServicePermission;
    26| import com.hazelcast.spi.impl.operationservice.Operation;
    27| import java.security.Permission;
    28| import static com.hazelcast.durableexecutor.impl.DistributedDurableExecutorService.SERVICE_NAME;
    29| public class DurableExecutorRetrieveAndDisposeResultMessageTask
    30|         extends AbstractPartitionMessageTask<DurableExecutorRetrieveAndDisposeResultCodec.RequestParameters> {
    31|     public DurableExecutorRetrieveAndDisposeResultMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    32|         super(clientMessage, node, connection);
    33|     }
    34|     @Override
    35|     protected Operation prepareOperation() {
    36|         return new RetrieveAndDisposeResultOperation(parameters.name, parameters.sequence);
    37|     }
    38|     @Override
    39|     protected DurableExecutorRetrieveAndDisposeResultCodec.RequestParameters decodeClientMessage(ClientMessage clientMessage) {
    40|         return DurableExecutorRetrieveAndDisposeResultCodec.decodeRequest(clientMessage);
    41|     }
    42|     @Override
    43|     protected ClientMessage encodeResponse(Object response) {
    44|         Data data = serializationService.toData(response);
    45|         return DurableExecutorRetrieveAndDisposeResultCodec.encodeResponse(data);
    46|     }
    47|     @Override
    48|     public String getServiceName() {
    49|         return SERVICE_NAME;
    50|     }
    51|     @Override
    52|     public Permission getRequiredPermission() {
    53|         return new DurableExecutorServicePermission(parameters.name, ActionConstants.ACTION_READ, ActionConstants.ACTION_MODIFY);
    54|     }
    55|     @Override
    56|     public String getDistributedObjectName() {
    57|         return parameters.name;
    58|     }
    59|     @Override
    60|     public String getMethodName() {
    61|         return null;
    62|     }
    63|     @Override
    64|     public Object[] getParameters() {
    65|         return null;
    66|     }
    67| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/executorservice/durable/DurableExecutorRetrieveResultMessageTask.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 4-67 ---
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.executorservice.durable;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.DurableExecutorRetrieveResultCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractPartitionMessageTask;
    20| import com.hazelcast.durableexecutor.impl.operations.RetrieveResultOperation;
    21| import com.hazelcast.instance.impl.Node;
    22| import com.hazelcast.internal.nio.Connection;
    23| import com.hazelcast.internal.serialization.Data;
    24| import com.hazelcast.security.permission.ActionConstants;
    25| import com.hazelcast.security.permission.DurableExecutorServicePermission;
    26| import com.hazelcast.spi.impl.operationservice.Operation;
    27| import java.security.Permission;
    28| import static com.hazelcast.durableexecutor.impl.DistributedDurableExecutorService.SERVICE_NAME;
    29| public class DurableExecutorRetrieveResultMessageTask
    30|         extends AbstractPartitionMessageTask<DurableExecutorRetrieveResultCodec.RequestParameters> {
    31|     public DurableExecutorRetrieveResultMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    32|         super(clientMessage, node, connection);
    33|     }
    34|     @Override
    35|     protected Operation prepareOperation() {
    36|         return new RetrieveResultOperation(parameters.name, parameters.sequence);
    37|     }
    38|     @Override
    39|     protected DurableExecutorRetrieveResultCodec.RequestParameters decodeClientMessage(ClientMessage clientMessage) {
    40|         return DurableExecutorRetrieveResultCodec.decodeRequest(clientMessage);
    41|     }
    42|     @Override
    43|     protected ClientMessage encodeResponse(Object response) {
    44|         Data data = serializationService.toData(response);
    45|         return DurableExecutorRetrieveResultCodec.encodeResponse(data);
    46|     }
    47|     @Override
    48|     public String getServiceName() {
    49|         return SERVICE_NAME;
    50|     }
    51|     @Override
    52|     public Permission getRequiredPermission() {
    53|         return new DurableExecutorServicePermission(parameters.name, ActionConstants.ACTION_READ);
    54|     }
    55|     @Override
    56|     public String getDistributedObjectName() {
    57|         return parameters.name;
    58|     }
    59|     @Override
    60|     public String getMethodName() {
    61|         return null;
    62|     }
    63|     @Override
    64|     public Object[] getParameters() {
    65|         return null;
    66|     }
    67| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/executorservice/durable/DurableExecutorShutdownMessageTask.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 3-66 ---
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.executorservice.durable;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.DurableExecutorShutdownCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractCallableMessageTask;
    20| import com.hazelcast.durableexecutor.impl.DistributedDurableExecutorService;
    21| import com.hazelcast.instance.impl.Node;
    22| import com.hazelcast.internal.nio.Connection;
    23| import com.hazelcast.security.permission.ActionConstants;
    24| import com.hazelcast.security.permission.DurableExecutorServicePermission;
    25| import java.security.Permission;
    26| import static com.hazelcast.durableexecutor.impl.DistributedDurableExecutorService.SERVICE_NAME;
    27| public class DurableExecutorShutdownMessageTask
    28|         extends AbstractCallableMessageTask<String> {
    29|     public DurableExecutorShutdownMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    30|         super(clientMessage, node, connection);
    31|     }
    32|     @Override
    33|     protected Object call() throws Exception {
    34|         DistributedDurableExecutorService service = getService(SERVICE_NAME);
    35|         service.shutdownExecutor(parameters);
    36|         return null;
    37|     }
    38|     @Override
    39|     protected String decodeClientMessage(ClientMessage clientMessage) {
    40|         return DurableExecutorShutdownCodec.decodeRequest(clientMessage);
    41|     }
    42|     @Override
    43|     protected ClientMessage encodeResponse(Object response) {
    44|         return DurableExecutorShutdownCodec.encodeResponse();
    45|     }
    46|     @Override
    47|     public String getServiceName() {
    48|         return SERVICE_NAME;
    49|     }
    50|     @Override
    51|     public Permission getRequiredPermission() {
    52|         return new DurableExecutorServicePermission(parameters, ActionConstants.ACTION_MODIFY);
    53|     }
    54|     @Override
    55|     public String getDistributedObjectName() {
    56|         return parameters;
    57|     }
    58|     @Override
    59|     public String getMethodName() {
    60|         return "shutdown";
    61|     }
    62|     @Override
    63|     public Object[] getParameters() {
    64|         return null;
    65|     }
    66| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/executorservice/durable/DurableExecutorSubmitToPartitionMessageTask.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 5-46 ---
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.executorservice.durable;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.DurableExecutorSubmitToPartitionCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractPartitionMessageTask;
    20| import com.hazelcast.durableexecutor.impl.operations.TaskOperation;
    21| import com.hazelcast.instance.impl.Node;
    22| import com.hazelcast.internal.nio.Connection;
    23| import com.hazelcast.internal.serialization.Data;
    24| import com.hazelcast.security.SecurityContext;
    25| import com.hazelcast.security.permission.ActionConstants;
    26| import com.hazelcast.security.permission.DurableExecutorServicePermission;
    27| import com.hazelcast.spi.impl.operationservice.Operation;
    28| import javax.security.auth.Subject;
    29| import java.security.Permission;
    30| import java.util.concurrent.Callable;
    31| import static com.hazelcast.durableexecutor.impl.DistributedDurableExecutorService.SERVICE_NAME;
    32| public class DurableExecutorSubmitToPartitionMessageTask
    33|         extends AbstractPartitionMessageTask<DurableExecutorSubmitToPartitionCodec.RequestParameters> {
    34|     public DurableExecutorSubmitToPartitionMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    35|         super(clientMessage, node, connection);
    36|     }
    37|     @Override
    38|     protected Operation prepareOperation() {
    39|         SecurityContext securityContext = clientEngine.getSecurityContext();
    40|         Data callableData = parameters.callable;
    41|         if (securityContext != null) {
    42|             Subject subject = endpoint.getSubject();
    43|             Object taskObject = serializationService.toObject(parameters.callable);
    44|             Callable callable;
    45|             if (taskObject instanceof Runnable) {
    46|                 callable = securityContext.createSecureCallable(subject, (Runnable) taskObject);

# --- HUNK 2: Lines 48-82 ---
    48|                 callable = securityContext.createSecureCallable(subject, (Callable<? extends Object>) taskObject);
    49|             }
    50|             callableData = serializationService.toData(callable);
    51|         }
    52|         return new TaskOperation(parameters.name, callableData);
    53|     }
    54|     @Override
    55|     protected DurableExecutorSubmitToPartitionCodec.RequestParameters decodeClientMessage(ClientMessage clientMessage) {
    56|         return DurableExecutorSubmitToPartitionCodec.decodeRequest(clientMessage);
    57|     }
    58|     @Override
    59|     protected ClientMessage encodeResponse(Object response) {
    60|         return DurableExecutorSubmitToPartitionCodec.encodeResponse((Integer) response);
    61|     }
    62|     @Override
    63|     public String getServiceName() {
    64|         return SERVICE_NAME;
    65|     }
    66|     @Override
    67|     public Permission getRequiredPermission() {
    68|         return new DurableExecutorServicePermission(parameters.name, ActionConstants.ACTION_MODIFY);
    69|     }
    70|     @Override
    71|     public String getDistributedObjectName() {
    72|         return parameters.name;
    73|     }
    74|     @Override
    75|     public String getMethodName() {
    76|         return null;
    77|     }
    78|     @Override
    79|     public Object[] getParameters() {
    80|         return null;
    81|     }
    82| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/scheduledexecutor/ScheduledExecutorSubmitToPartitionMessageTask.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 5-66 ---
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.scheduledexecutor;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.ScheduledExecutorSubmitToPartitionCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractPartitionMessageTask;
    20| import com.hazelcast.instance.impl.Node;
    21| import com.hazelcast.internal.nio.Connection;
    22| import com.hazelcast.scheduledexecutor.impl.DistributedScheduledExecutorService;
    23| import com.hazelcast.scheduledexecutor.impl.TaskDefinition;
    24| import com.hazelcast.scheduledexecutor.impl.operations.ScheduleTaskOperation;
    25| import com.hazelcast.security.SecurityContext;
    26| import com.hazelcast.security.permission.ActionConstants;
    27| import com.hazelcast.security.permission.ScheduledExecutorPermission;
    28| import com.hazelcast.spi.impl.operationservice.Operation;
    29| import javax.security.auth.Subject;
    30| import java.security.Permission;
    31| import java.util.concurrent.Callable;
    32| import java.util.concurrent.TimeUnit;
    33| public class ScheduledExecutorSubmitToPartitionMessageTask
    34|         extends AbstractPartitionMessageTask<ScheduledExecutorSubmitToPartitionCodec.RequestParameters> {
    35|     public ScheduledExecutorSubmitToPartitionMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    36|         super(clientMessage, node, connection);
    37|     }
    38|     @Override
    39|     protected Operation prepareOperation() {
    40|         Callable callable = serializationService.toObject(parameters.task);
    41|         SecurityContext securityContext = clientEngine.getSecurityContext();
    42|         if (securityContext != null) {
    43|             Subject subject = endpoint.getSubject();
    44|             callable = securityContext.createSecureCallable(subject, callable);
    45|             serializationService.getManagedContext().initialize(callable);
    46|         }
    47|         TaskDefinition def = new TaskDefinition(TaskDefinition.Type.getById(parameters.type),
    48|                 parameters.taskName, callable, parameters.initialDelayInMillis, parameters.periodInMillis,
    49|                 TimeUnit.MILLISECONDS, isAutoDisposable());
    50|         return new ScheduleTaskOperation(parameters.schedulerName, def);
    51|     }
    52|     @Override
    53|     protected ScheduledExecutorSubmitToPartitionCodec.RequestParameters decodeClientMessage(ClientMessage clientMessage) {
    54|         return ScheduledExecutorSubmitToPartitionCodec.decodeRequest(clientMessage);
    55|     }
    56|     @Override
    57|     protected ClientMessage encodeResponse(Object response) {
    58|         return ScheduledExecutorSubmitToPartitionCodec.encodeResponse();
    59|     }
    60|     @Override
    61|     public String getServiceName() {
    62|         return DistributedScheduledExecutorService.SERVICE_NAME;
    63|     }
    64|     @Override
    65|     public Permission getRequiredPermission() {
    66|         return new ScheduledExecutorPermission(parameters.schedulerName, ActionConstants.ACTION_MODIFY);


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/scheduledexecutor/ScheduledExecutorSubmitToTargetMessageTask.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 6-68 ---
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.scheduledexecutor;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.ScheduledExecutorSubmitToMemberCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractTargetMessageTask;
    20| import com.hazelcast.cluster.Member;
    21| import com.hazelcast.instance.impl.Node;
    22| import com.hazelcast.internal.nio.Connection;
    23| import com.hazelcast.scheduledexecutor.impl.DistributedScheduledExecutorService;
    24| import com.hazelcast.scheduledexecutor.impl.TaskDefinition;
    25| import com.hazelcast.scheduledexecutor.impl.operations.ScheduleTaskOperation;
    26| import com.hazelcast.security.SecurityContext;
    27| import com.hazelcast.security.permission.ActionConstants;
    28| import com.hazelcast.security.permission.ScheduledExecutorPermission;
    29| import com.hazelcast.spi.impl.operationservice.Operation;
    30| import javax.security.auth.Subject;
    31| import java.security.Permission;
    32| import java.util.UUID;
    33| import java.util.concurrent.Callable;
    34| import java.util.concurrent.TimeUnit;
    35| public class ScheduledExecutorSubmitToTargetMessageTask
    36|         extends AbstractTargetMessageTask<ScheduledExecutorSubmitToMemberCodec.RequestParameters> {
    37|     public ScheduledExecutorSubmitToTargetMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    38|         super(clientMessage, node, connection);
    39|     }
    40|     @Override
    41|     protected Operation prepareOperation() {
    42|         Callable callable = serializationService.toObject(parameters.task);
    43|         SecurityContext securityContext = clientEngine.getSecurityContext();
    44|         if (securityContext != null) {
    45|             Subject subject = endpoint.getSubject();
    46|             callable = securityContext.createSecureCallable(subject, callable);
    47|             serializationService.getManagedContext().initialize(callable);
    48|         }
    49|         TaskDefinition def = new TaskDefinition(TaskDefinition.Type.getById(parameters.type),
    50|                 parameters.taskName, callable, parameters.initialDelayInMillis, parameters.periodInMillis,
    51|                 TimeUnit.MILLISECONDS, isAutoDisposable());
    52|         return new ScheduleTaskOperation(parameters.schedulerName, def);
    53|     }
    54|     @Override
    55|     protected UUID getTargetUuid() {
    56|         return parameters.memberUuid;
    57|     }
    58|     @Override
    59|     protected ScheduledExecutorSubmitToMemberCodec.RequestParameters decodeClientMessage(ClientMessage clientMessage) {
    60|         return ScheduledExecutorSubmitToMemberCodec.decodeRequest(clientMessage);
    61|     }
    62|     @Override
    63|     protected ClientMessage encodeResponse(Object response) {
    64|         return ScheduledExecutorSubmitToMemberCodec.encodeResponse();
    65|     }
    66|     @Override
    67|     public String getServiceName() {
    68|         return DistributedScheduledExecutorService.SERVICE_NAME;


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/config/ConfigXmlGenerator.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 150-192 ---
   150|         reliableTopicXmlGenerator(gen, config);
   151|         liteMemberXmlGenerator(gen, config);
   152|         nativeMemoryXmlGenerator(gen, config);
   153|         persistenceXmlGenerator(gen, config);
   154|         flakeIdGeneratorXmlGenerator(gen, config);
   155|         crdtReplicationXmlGenerator(gen, config);
   156|         pnCounterXmlGenerator(gen, config);
   157|         splitBrainProtectionXmlGenerator(gen, config);
   158|         cpSubsystemConfig(gen, config);
   159|         metricsConfig(gen, config);
   160|         instanceTrackingConfig(gen, config);
   161|         sqlConfig(gen, config);
   162|         jetConfig(gen, config);
   163|         factoryWithPropertiesXmlGenerator(gen, "auditlog", config.getAuditlogConfig());
   164|         userCodeDeploymentConfig(gen, config);
   165|         xml.append("</hazelcast>");
   166|         String xmlString = xml.toString();
   167|         return formatted ? formatXml(xmlString, INDENT) : xmlString;
   168|     }
   169|     private String getOrMaskValue(String value) {
   170|         if (value == null) {
   171|             return null;
   172|         }
   173|         return maskSensitiveFields ? MASK_FOR_SENSITIVE_DATA : value;
   174|     }
   175|     private void managementCenterXmlGenerator(XmlGenerator gen, Config config) {
   176|         ManagementCenterConfig mcConfig = config.getManagementCenterConfig();
   177|         if (mcConfig != null) {
   178|             gen.open("management-center",
   179|                     "scripting-enabled", mcConfig.isScriptingEnabled());
   180|             trustedInterfacesXmlGenerator(gen, mcConfig.getTrustedInterfaces());
   181|             gen.close();
   182|         }
   183|     }
   184|     @SuppressWarnings("unchecked")
   185|     private static void collectionXmlGenerator(XmlGenerator gen, String type, Collection<? extends CollectionConfig> configs) {
   186|         if (CollectionUtil.isNotEmpty(configs)) {
   187|             for (CollectionConfig<? extends CollectionConfig> config : configs) {
   188|                 gen.open(type, "name", config.getName())
   189|                         .node("statistics-enabled", config.isStatisticsEnabled())
   190|                         .node("max-size", config.getMaxSize())
   191|                         .node("backup-count", config.getBackupCount())
   192|                         .node("async-backup-count", config.getAsyncBackupCount())

# --- HUNK 2: Lines 291-379 ---
   291|             if (upi != null) {
   292|                 gen.node("username-password", null, "username", upi.getUsername(), "password", getOrMaskValue(upi.getPassword()));
   293|             }
   294|             TokenIdentityConfig ti = c.getTokenIdentityConfig();
   295|             if (ti != null) {
   296|                 gen.node("token", getOrMaskValue(ti.getTokenEncoded()), "encoding", ti.getEncoding().toString());
   297|             }
   298|             kerberosIdentityGenerator(gen, c.getKerberosIdentityConfig());
   299|             gen.close();
   300|         }
   301|         gen.close();
   302|     }
   303|     private static void tlsAuthenticationGenerator(XmlGenerator gen, TlsAuthenticationConfig c) {
   304|         if (c == null) {
   305|             return;
   306|         }
   307|         XmlGenerator tlsGen = gen.open("tls", "roleAttribute", c.getRoleAttribute());
   308|         addClusterLoginElements(tlsGen, c)
   309|                 .close();
   310|     }
   311|     private void ldapAuthenticationGenerator(XmlGenerator gen, LdapAuthenticationConfig c) {
   312|         if (c == null) {
   313|             return;
   314|         }
   315|         addClusterLoginElements(gen.open("ldap"), c)
   316|                 .node("url", c.getUrl())
   317|                 .nodeIfContents("socket-factory-class-name", c.getSocketFactoryClassName())
   318|                 .nodeIfContents("parse-dn", c.getParseDn())
   319|                 .nodeIfContents("role-context", c.getRoleContext())
   320|                 .nodeIfContents("role-filter", c.getRoleFilter())
   321|                 .nodeIfContents("role-mapping-attribute", c.getRoleMappingAttribute())
   322|                 .nodeIfContents("role-mapping-mode", c.getRoleMappingMode())
   323|                 .nodeIfContents("role-name-attribute", c.getRoleNameAttribute())
   324|                 .nodeIfContents("role-recursion-max-depth", c.getRoleRecursionMaxDepth())
   325|                 .nodeIfContents("role-search-scope", c.getRoleSearchScope())
   326|                 .nodeIfContents("user-name-attribute", c.getUserNameAttribute())
   327|                 .nodeIfContents("system-user-dn", c.getSystemUserDn())
   328|                 .nodeIfContents("system-user-password", getOrMaskValue(c.getSystemUserPassword()))
   329|                 .nodeIfContents("system-authentication", c.getSystemAuthentication())
   330|                 .nodeIfContents("security-realm", c.getSecurityRealm())
   331|                 .nodeIfContents("password-attribute", c.getPasswordAttribute())
   332|                 .nodeIfContents("user-context", c.getUserContext())
   333|                 .nodeIfContents("user-filter", c.getUserFilter())
   334|                 .nodeIfContents("user-search-scope", c.getUserSearchScope())
   335|                 .nodeIfContents("skip-authentication", c.getSkipAuthentication())
   336|                 .close();
   337|     }
   338|     private void kerberosAuthenticationGenerator(XmlGenerator gen, KerberosAuthenticationConfig c) {
   339|         if (c == null) {
   340|             return;
   341|         }
   342|         XmlGenerator kerberosGen = gen.open("kerberos");
   343|         addClusterLoginElements(kerberosGen, c)
   344|                 .nodeIfContents("relax-flags-check", c.getRelaxFlagsCheck())
   345|                 .nodeIfContents("use-name-without-realm", c.getUseNameWithoutRealm())
   346|                 .nodeIfContents("security-realm", c.getSecurityRealm())
   347|                 .nodeIfContents("keytab-file", c.getKeytabFile())
   348|                 .nodeIfContents("principal", c.getPrincipal());
   349|         ldapAuthenticationGenerator(kerberosGen, c.getLdapAuthenticationConfig());
   350|         kerberosGen.close();
   351|     }
   352|     private void simpleAuthenticationGenerator(XmlGenerator gen, SimpleAuthenticationConfig c) {
   353|         if (c == null) {
   354|             return;
   355|         }
   356|         XmlGenerator simpleGen = gen.open("simple");
   357|         addClusterLoginElements(simpleGen, c).nodeIfContents("role-separator", c.getRoleSeparator());
   358|         for (String username : c.getUsernames()) {
   359|             simpleGen.open("user", "username", username, "password", getOrMaskValue(c.getPassword(username)));
   360|             for (String role : c.getRoles(username)) {
   361|                 simpleGen.node("role", role);
   362|             }
   363|             simpleGen.close();
   364|         }
   365|         simpleGen.close();
   366|     }
   367|     private static void kerberosIdentityGenerator(XmlGenerator gen, KerberosIdentityConfig c) {
   368|         if (c == null) {
   369|             return;
   370|         }
   371|         gen.open("kerberos")
   372|                 .nodeIfContents("realm", c.getRealm())
   373|                 .nodeIfContents("security-realm", c.getSecurityRealm())
   374|                 .nodeIfContents("keytab-file", c.getKeytabFile())
   375|                 .nodeIfContents("principal", c.getPrincipal())
   376|                 .nodeIfContents("service-name-prefix", c.getServiceNamePrefix())
   377|                 .nodeIfContents("spn", c.getSpn())
   378|                 .nodeIfContents("use-canonical-hostname", c.getUseCanonicalHostname())
   379|                 .close();


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/cp/internal/session/RaftSessionService.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 435-463 ---
   435|             } catch (Exception e) {
   436|                 if (logger.isFineEnabled()) {
   437|                     logger.fine("Could not close inactive sessions: " + sessions + " of " + groupId, e);
   438|                 }
   439|             }
   440|         }
   441|     }
   442|     @Override
   443|     public void provideDynamicMetrics(MetricDescriptor descriptor, MetricsCollectionContext context) {
   444|         MetricDescriptor root = descriptor.withPrefix("cp.session");
   445|         for (RaftSessionRegistry registry : registries.values()) {
   446|             CPGroupId groupId = registry.groupId();
   447|             for (CPSession session : registry.getSessions()) {
   448|                 MetricDescriptor desc = root.copy()
   449|                         .withDiscriminator("id", session.id() + "@" + groupId.getName())
   450|                         .withTag("sessionId", String.valueOf(session.id()))
   451|                         .withTag("group", groupId.getName());
   452|                 context.collect(desc.copy().withTag("endpoint", session.endpoint().toString()).withMetric("endpoint"), 0);
   453|                 context.collect(desc.copy().withTag("endpointType", session.endpointType().toString())
   454|                         .withMetric("endpointType"), 0);
   455|                 context.collect(desc.copy().withTag("endpointName", session.endpointName())
   456|                         .withMetric("endpointName"), 0);
   457|                 context.collect(desc.copy().withMetric("version"), session.version());
   458|                 context.collect(desc.copy().withUnit(ProbeUnit.MS).withMetric("creationTime"), session.creationTime());
   459|                 context.collect(desc.copy().withUnit(ProbeUnit.MS).withMetric("expirationTime"), session.expirationTime());
   460|             }
   461|         }
   462|     }
   463| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/internal/cluster/impl/ClusterJoinManager.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 569-611 ---
   569|         if (masterAddress.equals(target)) {
   570|             logger.fine("Cannot send master answer to " + target + " since it is the known master");
   571|             return;
   572|         }
   573|         MasterResponseOp op = new MasterResponseOp(masterAddress);
   574|         nodeEngine.getOperationService().send(op, target);
   575|     }
   576|     @SuppressWarnings("checkstyle:cyclomaticcomplexity")
   577|     private boolean checkIfJoinRequestFromAnExistingMember(JoinMessage joinMessage, ServerConnection connection) {
   578|         Address target = joinMessage.getAddress();
   579|         MemberImpl member = clusterService.getMember(target);
   580|         if (member == null) {
   581|             return checkIfUsingAnExistingMemberUuid(joinMessage);
   582|         }
   583|         if (joinMessage.getUuid().equals(member.getUuid())) {
   584|             sendMasterAnswer(target);
   585|             if (clusterService.isMaster() && !isMastershipClaimInProgress()) {
   586|                 if (logger.isFineEnabled()) {
   587|                     logger.fine(format("Ignoring join request, member already exists: %s", joinMessage));
   588|                 }
   589|                 MemberMap memberMap = clusterService.getMembershipManager().getMemberMap();
   590|                 boolean deferPartitionProcessing = isMemberRestartingWithPersistence(member.getAttributes())
   591|                         && isMemberRejoining(memberMap, member.getAddress(), member.getUuid());
   592|                 OnJoinOp preJoinOp = preparePreJoinOps();
   593|                 OnJoinOp postJoinOp = preparePostJoinOp();
   594|                 PartitionRuntimeState partitionRuntimeState = node.getPartitionService().createPartitionState();
   595|                 Operation op = new FinalizeJoinOp(member.getUuid(),
   596|                         clusterService.getMembershipManager().getMembersView(), preJoinOp, postJoinOp,
   597|                         clusterClock.getClusterTime(), clusterService.getClusterId(),
   598|                         clusterClock.getClusterStartTime(), clusterStateManager.getState(),
   599|                         clusterService.getClusterVersion(), partitionRuntimeState, deferPartitionProcessing);
   600|                 op.setCallerUuid(clusterService.getThisUuid());
   601|                 invokeClusterOp(op, target);
   602|             }
   603|             return true;
   604|         }
   605|         if (clusterService.isMaster() || target.equals(clusterService.getMasterAddress())) {
   606|             String msg = format("New join request has been received from an existing endpoint %s."
   607|                     + " Removing old member and processing join request...", member);
   608|             logger.warning(msg);
   609|             clusterService.suspectMember(member, msg, false);
   610|             ServerConnection existing = node.getServer().getConnectionManager(MEMBER).get(target);
   611|             if (existing != connection) {


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/internal/diagnostics/HealthMonitor.java
# Total hunks: 3
# ====================================================================
# --- HUNK 1: Lines 225-385 ---
   225|                 = metricRegistry.newLongGauge("os.totalPhysicalMemorySize");
   226|         final LongGauge osFreePhysicalMemorySize
   227|                 = metricRegistry.newLongGauge("os.freePhysicalMemorySize");
   228|         final LongGauge osTotalSwapSpaceSize
   229|                 = metricRegistry.newLongGauge("os.totalSwapSpaceSize");
   230|         final LongGauge osFreeSwapSpaceSize
   231|                 = metricRegistry.newLongGauge("os.freeSwapSpaceSize");
   232|         final LongGauge operationServiceExecutorQueueSize
   233|                 = metricRegistry.newLongGauge("operation.queueSize");
   234|         final LongGauge operationServiceExecutorPriorityQueueSize
   235|                 = metricRegistry.newLongGauge("operation.priorityQueueSize");
   236|         final LongGauge operationServiceResponseQueueSize
   237|                 = metricRegistry.newLongGauge("operation.responseQueueSize");
   238|         final LongGauge operationServiceRunningOperationsCount
   239|                 = metricRegistry.newLongGauge("operation.runningCount");
   240|         final LongGauge operationServiceCompletedOperationsCount
   241|                 = metricRegistry.newLongGauge("operation.completedCount");
   242|         final LongGauge operationServicePendingInvocationsCount
   243|                 = metricRegistry.newLongGauge("operation.invocations.pending");
   244|         final DoubleGauge operationServicePendingInvocationsPercentage
   245|                 = metricRegistry.newDoubleGauge("operation.invocations.usedPercentage");
   246|         final LongGauge proxyCount
   247|                 = metricRegistry.newLongGauge("proxy.proxyCount");
   248|         final LongGauge tcpConnectionActiveCount
   249|                 = metricRegistry.newLongGauge("tcp.connection.activeCount");
   250|         final LongGauge tcpConnectionCount
   251|                 = metricRegistry.newLongGauge("tcp.connection.count");
   252|         final LongGauge tcpConnectionClientCount
   253|                 = metricRegistry.newLongGauge("tcp.connection.clientCount");
   254|         private final StringBuilder sb = new StringBuilder();
   255|         private double memoryUsedOfTotalPercentage;
   256|         private double memoryUsedOfMaxPercentage;
   257|         private long runtimeUsedMemory0;
   258|         private long runtimeTotalMemory0;
   259|         private long runtimeMaxMemory0;
   260|         private double osProcessCpuLoad0;
   261|         private double osSystemCpuLoad0;
   262|         private double operationServicePendingInvocationsPercentage0;
   263|         private long operationServicePendingInvocationsCount0;
   264|         public void update() {
   265|             runtimeUsedMemory0 = runtimeUsedMemory.read();
   266|             runtimeTotalMemory0 = runtimeTotalMemory.read();
   267|             runtimeMaxMemory0 = runtimeMaxMemory.read();
   268|             osProcessCpuLoad0 = osProcessCpuLoad.read();
   269|             osSystemCpuLoad0 = osSystemCpuLoad.read();
   270|             operationServicePendingInvocationsPercentage0 = operationServicePendingInvocationsPercentage.read();
   271|             operationServicePendingInvocationsCount0 = operationServicePendingInvocationsCount.read();
   272|             memoryUsedOfTotalPercentage = (PERCENTAGE_MULTIPLIER * runtimeUsedMemory0) / runtimeTotalMemory0;
   273|             memoryUsedOfMaxPercentage = (PERCENTAGE_MULTIPLIER * runtimeUsedMemory0) / runtimeMaxMemory0;
   274|         }
   275|         boolean exceedsThreshold() {
   276|             if (memoryUsedOfMaxPercentage > thresholdMemoryPercentage) {
   277|                 return true;
   278|             }
   279|             if (osProcessCpuLoad0 > thresholdCPUPercentage) {
   280|                 return true;
   281|             }
   282|             if (osSystemCpuLoad0 > thresholdCPUPercentage) {
   283|                 return true;
   284|             }
   285|             if (operationServicePendingInvocationsPercentage0 > THRESHOLD_PERCENTAGE_INVOCATIONS) {
   286|                 return true;
   287|             }
   288|             if (operationServicePendingInvocationsCount0 > THRESHOLD_INVOCATIONS) {
   289|                 return true;
   290|             }
   291|             return false;
   292|         }
   293|         public String render() {
   294|             sb.setLength(0);
   295|             renderProcessors();
   296|             renderPhysicalMemory();
   297|             renderSwap();
   298|             renderHeap();
   299|             renderNativeMemory();
   300|             renderGc();
   301|             renderLoad();
   302|             renderThread();
   303|             renderCluster();
   304|             renderEvents();
   305|             renderExecutors();
   306|             renderOperationService();
   307|             renderProxy();
   308|             renderClient();
   309|             renderConnection();
   310|             return sb.toString();
   311|         }
   312|         private void renderConnection() {
   313|             sb.append("connection.active.count=")
   314|                     .append(tcpConnectionActiveCount.read()).append(", ");
   315|             sb.append("client.connection.count=")
   316|                     .append(tcpConnectionClientCount.read()).append(", ");
   317|             sb.append("connection.count=")
   318|                     .append(tcpConnectionCount.read());
   319|         }
   320|         private void renderClient() {
   321|             sb.append("clientEndpoint.count=")
   322|                     .append(clientEndpointCount.read()).append(", ");
   323|         }
   324|         private void renderProxy() {
   325|             sb.append("proxy.count=")
   326|                     .append(proxyCount.read()).append(", ");
   327|         }
   328|         private void renderLoad() {
   329|             sb.append("load.process").append('=')
   330|                     .append(format("%.2f", osProcessCpuLoad0)).append("%, ");
   331|             sb.append("load.system").append('=')
   332|                     .append(format("%.2f", osSystemCpuLoad0)).append("%, ");
   333|             double value = osSystemLoadAverage.read();
   334|             if (value < 0) {
   335|                 sb.append("load.systemAverage").append("=n/a ");
   336|             } else {
   337|                 sb.append("load.systemAverage").append('=')
   338|                         .append(format("%.2f", value)).append(", ");
   339|             }
   340|         }
   341|         private void renderProcessors() {
   342|             sb.append("processors=")
   343|                     .append(runtimeAvailableProcessors.read()).append(", ");
   344|         }
   345|         private void renderPhysicalMemory() {
   346|             sb.append("physical.memory.total=")
   347|                     .append(numberToUnit(osTotalPhysicalMemorySize.read())).append(", ");
   348|             sb.append("physical.memory.free=")
   349|                     .append(numberToUnit(osFreePhysicalMemorySize.read())).append(", ");
   350|         }
   351|         private void renderSwap() {
   352|             sb.append("swap.space.total=")
   353|                     .append(numberToUnit(osTotalSwapSpaceSize.read())).append(", ");
   354|             sb.append("swap.space.free=")
   355|                     .append(numberToUnit(osFreeSwapSpaceSize.read())).append(", ");
   356|         }
   357|         private void renderHeap() {
   358|             sb.append("heap.memory.used=")
   359|                     .append(numberToUnit(runtimeUsedMemory0)).append(", ");
   360|             sb.append("heap.memory.free=")
   361|                     .append(numberToUnit(runtimeFreeMemory.read())).append(", ");
   362|             sb.append("heap.memory.total=")
   363|                     .append(numberToUnit(runtimeTotalMemory0)).append(", ");
   364|             sb.append("heap.memory.max=")
   365|                     .append(numberToUnit(runtimeMaxMemory0)).append(", ");
   366|             sb.append("heap.memory.used/total=")
   367|                     .append(percentageString(memoryUsedOfTotalPercentage)).append(", ");
   368|             sb.append("heap.memory.used/max=")
   369|                     .append(percentageString(memoryUsedOfMaxPercentage)).append((", "));
   370|         }
   371|         private void renderEvents() {
   372|             sb.append("event.q.size=")
   373|                     .append(eventQueueSize.read()).append(", ");
   374|         }
   375|         private void renderCluster() {
   376|             sb.append("cluster.timeDiff=")
   377|                     .append(clusterTimeDiff.read()).append(", ");
   378|         }
   379|         private void renderThread() {
   380|             sb.append("thread.count=")
   381|                     .append(threadThreadCount.read()).append(", ");
   382|             sb.append("thread.peakCount=")
   383|                     .append(threadPeakThreadCount.read()).append(", ");
   384|         }
   385|         private void renderGc() {

# --- HUNK 2: Lines 440-482 ---
   440|                     .append(executorSystemQueueSize.read()).append(", ");
   441|             sb.append("executor.q.operations.size=")
   442|                     .append(operationServiceExecutorQueueSize.read()).append(", ");
   443|             sb.append("executor.q.priorityOperation.size=").
   444|                     append(operationServiceExecutorPriorityQueueSize.read()).append(", ");
   445|             sb.append("operations.completed.count=")
   446|                     .append(operationServiceCompletedOperationsCount.read()).append(", ");
   447|             sb.append("executor.q.mapLoad.size=")
   448|                     .append(executorMapLoadQueueSize.read()).append(", ");
   449|             sb.append("executor.q.mapLoadAllKeys.size=")
   450|                     .append(executorMapLoadAllKeysQueueSize.read()).append(", ");
   451|             sb.append("executor.q.cluster.size=")
   452|                     .append(executorClusterQueueSize.read()).append(", ");
   453|         }
   454|         private void renderOperationService() {
   455|             sb.append("executor.q.response.size=")
   456|                     .append(operationServiceResponseQueueSize.read()).append(", ");
   457|             sb.append("operations.running.count=")
   458|                     .append(operationServiceRunningOperationsCount.read()).append(", ");
   459|             sb.append("operations.pending.invocations.percentage=")
   460|                     .append(format("%.2f", operationServicePendingInvocationsPercentage0)).append("%, ");
   461|             sb.append("operations.pending.invocations.count=")
   462|                     .append(operationServicePendingInvocationsCount0).append(", ");
   463|         }
   464|     }
   465|     /**
   466|      * Given a number, returns that number as a percentage string.
   467|      *
   468|      * @param p the given number
   469|      * @return a string of the given number as a format float with two decimal places and a period
   470|      */
   471|     private static String percentageString(double p) {
   472|         return format("%.2f%%", p);
   473|     }
   474|     @SuppressWarnings("checkstyle:magicnumber")
   475|     private static String numberToUnit(long number) {
   476|         for (int i = 6; i > 0; i--) {
   477|             double step = Math.pow(1024, i);
   478|             if (number > step) {
   479|                 return format("%3.1f%s", number / step, UNITS[i]);
   480|             }
   481|         }
   482|         return Long.toString(number);


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/internal/eviction/ClearExpiredRecordsTask.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 75-121 ---
    75|         HazelcastProperties properties = nodeEngine.getProperties();
    76|         this.cleanupOperationCount = calculateCleanupOperationCount(properties, cleanupOpProperty, partitionCount,
    77|                 operationService.getPartitionThreadCount());
    78|         checkPositive(cleanupOperationCount, "cleanupOperationCount should be a positive number");
    79|         this.cleanupPercentage = properties.getInteger(cleanupPercentageProperty);
    80|         checkTrue(cleanupPercentage > 0 && cleanupPercentage <= 100,
    81|                 "cleanupPercentage should be in range (0,100]");
    82|         this.taskPeriodSeconds = properties.getSeconds(taskPeriodProperty);
    83|         this.cleanupEnabled = properties.getBoolean(cleanupEnabled);
    84|         this.toBackupSender = newToBackupSender(serviceName, newBackupExpiryOpSupplier(),
    85|                 newBackupExpiryOpFilter(), nodeEngine);
    86|     }
    87|     protected BiFunction<Integer, Integer, Boolean> newBackupExpiryOpFilter() {
    88|         return (partitionId, replicaIndex) -> {
    89|             IPartition partition = partitionService.getPartition(partitionId);
    90|             return partition.getReplicaAddress(replicaIndex) != null;
    91|         };
    92|     }
    93|     @Override
    94|     public void run() {
    95|         if (!nodeEngine.isStartCompleted()) {
    96|             return;
    97|         }
    98|         if (!singleRunPermit.compareAndSet(false, true)) {
    99|             return;
   100|         }
   101|         try {
   102|             runInternal();
   103|         } finally {
   104|             singleRunPermit.set(false);
   105|         }
   106|     }
   107|     private void runInternal() {
   108|         runningCleanupOperationsCount = 0;
   109|         long nowInMillis = nowInMillis();
   110|         boolean lostPartitionDetected = lostPartitionDetected();
   111|         List<T> containersToProcess = null;
   112|         for (int partitionId = 0; partitionId < partitionCount; partitionId++) {
   113|             T container = this.containers[partitionId];
   114|             IPartition partition = partitionService.getPartition(partitionId, false);
   115|             if (partition.isMigrating()) {
   116|                 continue;
   117|             }
   118|             if (partition.isLocal()) {
   119|                 if (lostPartitionDetected) {
   120|                     equalizeBackupSizeWithPrimary(container);
   121|                 }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/internal/metrics/MetricDescriptorConstants.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 319-361 ---
   319|     public static final String OPERATION_METRIC_PARTITION_OPERATION_THREAD_NORMAL_PENDING_COUNT = "normalPendingCount";
   320|     public static final String OPERATION_METRIC_PARTITION_OPERATION_THREAD_PRIORITY_PENDING_COUNT = "priorityPendingCount";
   321|     public static final String OPERATION_METRIC_PARKER_PARK_QUEUE_COUNT = "parkQueueCount";
   322|     public static final String OPERATION_METRIC_PARKER_TOTAL_PARKED_OPERATION_COUNT = "totalParkedOperationCount";
   323|     public static final String OPERATION_METRIC_INBOUND_RESPONSE_HANDLER_RESPONSE_QUEUE_SIZE = "responseQueueSize";
   324|     public static final String OPERATION_METRIC_INBOUND_RESPONSE_HANDLER_RESPONSES_NORMAL_COUNT = "responses.normalCount";
   325|     public static final String OPERATION_METRIC_INBOUND_RESPONSE_HANDLER_RESPONSES_TIMEOUT_COUNT = "responses.timeoutCount";
   326|     public static final String OPERATION_METRIC_INBOUND_RESPONSE_HANDLER_RESPONSES_BACKUP_COUNT = "responses.backupCount";
   327|     public static final String OPERATION_METRIC_INBOUND_RESPONSE_HANDLER_RESPONSES_ERROR_COUNT = "responses.errorCount";
   328|     public static final String OPERATION_METRIC_INBOUND_RESPONSE_HANDLER_RESPONSES_MISSING_COUNT = "responses.missingCount";
   329|     public static final String OPERATION_METRIC_INVOCATION_MONITOR_BACKUP_TIMEOUTS = "backupTimeouts";
   330|     public static final String OPERATION_METRIC_INVOCATION_MONITOR_NORMAL_TIMEOUTS = "normalTimeouts";
   331|     public static final String OPERATION_METRIC_INVOCATION_MONITOR_HEARTBEAT_PACKETS_RECEIVED = "heartbeatPacketsReceived";
   332|     public static final String OPERATION_METRIC_INVOCATION_MONITOR_HEARTBEAT_PACKETS_SENT = "heartbeatPacketsSent";
   333|     public static final String OPERATION_METRIC_INVOCATION_MONITOR_DELAYED_EXECUTION_COUNT = "delayedExecutionCount";
   334|     public static final String OPERATION_METRIC_INVOCATION_MONITOR_BACKUP_TIMEOUT_MILLIS = "backupTimeoutMillis";
   335|     public static final String OPERATION_METRIC_INVOCATION_MONITOR_INVOCATION_TIMEOUT_MILLIS = "invocationTimeoutMillis";
   336|     public static final String OPERATION_METRIC_INVOCATION_MONITOR_HEARTBEAT_BROADCAST_PERIOD_MILLIS =
   337|             "heartbeatBroadcastPeriodMillis";
   338|     public static final String OPERATION_METRIC_INVOCATION_MONITOR_INVOCATION_SCAN_PERIOD_MILLIS = "invocationScanPeriodMillis";
   339|     public static final String OPERATION_METRIC_INVOCATION_REGISTRY_INVOCATIONS_USED_PERCENTAGE = "usedPercentage";
   340|     public static final String OPERATION_METRIC_INVOCATION_REGISTRY_INVOCATIONS_LAST_CALL_ID = "lastCallId";
   341|     public static final String OPERATION_METRIC_INVOCATION_REGISTRY_INVOCATIONS_PENDING = "pending";
   342|     public static final String OPERATION_METRIC_OPERATION_RUNNER_EXECUTED_OPERATIONS_COUNT = "executedOperationsCount";
   343|     public static final String OPERATION_METRIC_OPERATION_SERVICE_ASYNC_OPERATIONS = "asyncOperations";
   344|     public static final String OPERATION_METRIC_OPERATION_SERVICE_TIMEOUT_COUNT = "operationTimeoutCount";
   345|     public static final String OPERATION_METRIC_OPERATION_SERVICE_CALL_TIMEOUT_COUNT = "callTimeoutCount";
   346|     public static final String OPERATION_METRIC_OPERATION_SERVICE_RETRY_COUNT = "retryCount";
   347|     public static final String OPERATION_METRIC_OPERATION_SERVICE_FAILED_BACKUPS = "failedBackups";
   348|     public static final String OS_FULL_METRIC_COMMITTED_VIRTUAL_MEMORY_SIZE = "os.committedVirtualMemorySize";
   349|     public static final String OS_FULL_METRIC_FREE_PHYSICAL_MEMORY_SIZE = "os.freePhysicalMemorySize";
   350|     public static final String OS_FULL_METRIC_FREE_SWAP_SPACE_SIZE = "os.freeSwapSpaceSize";
   351|     public static final String OS_FULL_METRIC_PROCESS_CPU_TIME = "os.processCpuTime";
   352|     public static final String OS_FULL_METRIC_TOTAL_PHYSICAL_MEMORY_SIZE = "os.totalPhysicalMemorySize";
   353|     public static final String OS_FULL_METRIC_TOTAL_SWAP_SPACE_SIZE = "os.totalSwapSpaceSize";
   354|     public static final String OS_FULL_METRIC_MAX_FILE_DESCRIPTOR_COUNT = "os.maxFileDescriptorCount";
   355|     public static final String OS_FULL_METRIC_OPEN_FILE_DESCRIPTOR_COUNT = "os.openFileDescriptorCount";
   356|     public static final String OS_FULL_METRIC_PROCESS_CPU_LOAD = "os.processCpuLoad";
   357|     public static final String OS_FULL_METRIC_SYSTEM_CPU_LOAD = "os.systemCpuLoad";
   358|     public static final String OS_FULL_METRIC_SYSTEM_LOAD_AVERAGE = "os.systemLoadAverage";
   359|     public static final String PARTITIONS_PREFIX = "partitions";
   360|     public static final String PARTITIONS_METRIC_PARTITION_SERVICE_MAX_BACKUP_COUNT = "maxBackupCount";
   361|     public static final String PARTITIONS_METRIC_PARTITION_SERVICE_MIGRATION_QUEUE_SIZE = "migrationQueueSize";


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/internal/networking/InboundPipeline.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 23-89 ---
    23|  * instances and the pipeline can be dynamically be modified.
    24|  *
    25|  * <h1>Spurious wakeups</h1>
    26|  * InboundHandlers/OutboundHandlers need to be able to deal with
    27|  * spurious wakeups. E.g. it could be that a PacketDecoder is called without
    28|  * any Packets being available.
    29|  *
    30|  * <h1>Automatic reprocessing on change</h1>
    31|  * When a change in the pipeline is detected, the pipeline is automatically
    32|  * reprocessed. For example when the ProtocolDecoder replaced itself by a
    33|  * PacketDecoder, the whole pipeline (in this case the PacketDecoder) is
    34|  * automatically reprocessed.
    35|  */
    36| public interface InboundPipeline {
    37|     /**
    38|      * Adds the handlers at the end of the pipeline.
    39|      *
    40|      * No verification is done if the handler is already added and a handler
    41|      * should only be added once.
    42|      *
    43|      * This method should only be made on the thread 'owning' the pipeline.
    44|      *
    45|      * @param handlers the handlers to add
    46|      * @return this
    47|      */
    48|     InboundPipeline addLast(InboundHandler... handlers);
    49|     /**
    50|      * Replaces the old InboundHandler by the new ones. So if there
    51|      * is a sequence of handlers [H1,H2,H3] and H2 gets replaced by [H4,H5]
    52|      * the new pipeline will be [H1,H4,H5,H3].
    53|      *
    54|      * No verification is done if any of the handlers is already added and a
    55|      * handler should only be added once.
    56|      *
    57|      * This method should only be made on the thread 'owning' the pipeline.
    58|      *
    59|      * @param oldHandler  the handler to replace
    60|      * @param newHandlers the new handlers to insert
    61|      * @return this
    62|      * @throws IllegalArgumentException is the oldHandler isn't part of this
    63|      *                                  pipeline.
    64|      */
    65|     InboundPipeline replace(InboundHandler oldHandler, InboundHandler... newHandlers);
    66|     /**
    67|      * Removes the given handler from the pipeline.
    68|      *
    69|      * This method should only be made on the thread 'owning' the pipeline.
    70|      *
    71|      * @param handler the handler to remove
    72|      * @return this
    73|      * @throws IllegalArgumentException is the handler isn't part of this
    74|      *                                  pipeline.
    75|      */
    76|     InboundPipeline remove(InboundHandler handler);
    77|     /**
    78|      * Wakes up the inbound pipeline and lets it to start reading again from the
    79|      * network.
    80|      *
    81|      * Even if there is no data to be read, it will cause at least one processing
    82|      * of the InboundPipeline. This will force any buffered data to be pushed
    83|      * through the InboundPipeline.
    84|      *
    85|      * This method is threadsafe and can safely be called from any thread.
    86|      *
    87|      * Calling it while it is already waken up will not do any damage, it will
    88|      * just cause some temporary overhead.
    89|      *


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/internal/networking/OutboundPipeline.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 8-74 ---
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.internal.networking;
    17| /**
    18|  * The outbound pipeline of a {@link Channel}. So all data that gets
    19|  * written to the network, goes through the outbound pipeline.
    20|  */
    21| public interface OutboundPipeline {
    22|     /**
    23|      * Adds the handlers at the end of the pipeline
    24|      *
    25|      * No verification is done if the handler is already added and a handler
    26|      * should only be added once.
    27|      *
    28|      * This method should only be made on the thread 'owning' the pipeline.
    29|      *
    30|      * @param handlers the handlers to add.
    31|      * @return this
    32|      */
    33|     OutboundPipeline addLast(OutboundHandler... handlers);
    34|     /**
    35|      * Replaces the old OutboundHandler by the new ones. So if there
    36|      * is a sequence of handlers [H1,H2,H3] and H2 gets replaced by [H4,H5]
    37|      * the new pipeline will be [H1,H4,H5,H3].
    38|      *
    39|      * No verification is done if any of the handlers is already added and a
    40|      * handler should only be added once.
    41|      *
    42|      * This method should only be made on the thread 'owning' the pipeline.
    43|      *
    44|      * @param oldHandler  the handlers to replace
    45|      * @param newHandlers the new handlers to insert.
    46|      * @return this
    47|      * @throws IllegalArgumentException is the oldHandler isn't part of this
    48|      *                                  pipeline.
    49|      */
    50|     OutboundPipeline replace(OutboundHandler oldHandler, OutboundHandler... newHandlers);
    51|     /**
    52|      * Removes the given handler from the pipeline.
    53|      *
    54|      * This method should only be made on the thread 'owning' the pipeline.
    55|      *
    56|      * @param handler the handler to remove.
    57|      * @return this
    58|      * @throws IllegalArgumentException is the handler isn't part of this
    59|      *                                  pipeline.
    60|      */
    61|     OutboundPipeline remove(OutboundHandler handler);
    62|     /**
    63|      * Request to flush all data to flush from the handlers to
    64|      * the network.
    65|      *
    66|      * It will cause at least one processing of the OutboundPipeline.
    67|      *
    68|      * This method is threadsafe and can safely be called from any thread.
    69|      *
    70|      * Calling it while there is nothing in the pipeline will not do any damage,
    71|      * apart from consuming cpu cycles.
    72|      *
    73|      * This can be used for example, with protocol or handshaking. So imagine
    74|      * there is a handshake decoder (e.g. protocol or TLS), that as soon as it


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/internal/server/tcp/MemberChannelInitializer.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 15-49 ---
    15|  */
    16| package com.hazelcast.internal.server.tcp;
    17| import com.hazelcast.config.EndpointConfig;
    18| import com.hazelcast.instance.EndpointQualifier;
    19| import com.hazelcast.instance.ProtocolType;
    20| import com.hazelcast.internal.networking.Channel;
    21| import com.hazelcast.internal.networking.InboundHandler;
    22| import com.hazelcast.internal.networking.OutboundHandler;
    23| import com.hazelcast.internal.server.ServerContext;
    24| import com.hazelcast.internal.server.ServerConnection;
    25| public class MemberChannelInitializer
    26|         extends AbstractChannelInitializer {
    27|     MemberChannelInitializer(ServerContext serverContext, EndpointConfig config) {
    28|         super(serverContext, config);
    29|     }
    30|     @Override
    31|     public void initChannel(Channel channel) {
    32|         ServerConnection connection = (TcpServerConnection) channel.attributeMap().get(ServerConnection.class);
    33|         OutboundHandler[] outboundHandlers = serverContext.createOutboundHandlers(EndpointQualifier.MEMBER, connection);
    34|         InboundHandler[] inboundHandlers = serverContext.createInboundHandlers(EndpointQualifier.MEMBER, connection);
    35|         OutboundHandler outboundHandler;
    36|         SingleProtocolEncoder protocolEncoder;
    37|         if (channel.isClientMode()) {
    38|             protocolEncoder = new SingleProtocolEncoder(outboundHandlers);
    39|             outboundHandler = new MemberProtocolEncoder(protocolEncoder);
    40|         } else {
    41|             protocolEncoder = new SingleProtocolEncoder(new MemberProtocolEncoder(outboundHandlers));
    42|             outboundHandler = protocolEncoder;
    43|         }
    44|         SingleProtocolDecoder protocolDecoder = new SingleProtocolDecoder(ProtocolType.MEMBER,
    45|                 inboundHandlers, protocolEncoder);
    46|         channel.outboundPipeline().addLast(outboundHandler);
    47|         channel.inboundPipeline().addLast(protocolDecoder);
    48|     }
    49| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/internal/server/tcp/MemberProtocolEncoder.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 9-73 ---
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.internal.server.tcp;
    17| import com.hazelcast.internal.networking.HandlerStatus;
    18| import com.hazelcast.internal.networking.OutboundHandler;
    19| import com.hazelcast.internal.nio.ConnectionType;
    20| import com.hazelcast.internal.server.ServerConnection;
    21| import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;
    22| import java.nio.ByteBuffer;
    23| import static com.hazelcast.internal.networking.HandlerStatus.CLEAN;
    24| import static com.hazelcast.internal.networking.HandlerStatus.DIRTY;
    25| import static com.hazelcast.internal.nio.IOUtil.compactOrClear;
    26| import static com.hazelcast.internal.nio.Protocols.CLUSTER;
    27| import static com.hazelcast.internal.nio.Protocols.PROTOCOL_LENGTH;
    28| import static com.hazelcast.internal.util.StringUtil.stringToBytes;
    29| /**
    30|  * Writes the member protocol header bytes (HZC) to dst buffer and replaces itself by the next {@link OutboundHandler
    31|  * OutboundHandlers}.
    32|  */
    33| public class MemberProtocolEncoder extends OutboundHandler<Void, ByteBuffer> {
    34|     private final OutboundHandler[] outboundHandlers;
    35|     /**
    36|      * @param next the {@link OutboundHandler} to replace this one in the outbound pipeline
    37|      *             upon match of protocol bytes
    38|      */
    39|     @SuppressFBWarnings("EI_EXPOSE_REP2")
    40|     public MemberProtocolEncoder(OutboundHandler... next) {
    41|         this.outboundHandlers = next;
    42|     }
    43|     @Override
    44|     public void handlerAdded() {
    45|         initDstBuffer(PROTOCOL_LENGTH, stringToBytes(CLUSTER));
    46|     }
    47|     @Override
    48|     public HandlerStatus onWrite() {
    49|         compactOrClear(dst);
    50|         try {
    51|             if (isProtocolBufferDrained()) {
    52|                 ServerConnection connection = (TcpServerConnection) channel.attributeMap().get(ServerConnection.class);
    53|                 connection.setConnectionType(ConnectionType.MEMBER);
    54|                 channel.outboundPipeline().replace(this, outboundHandlers);
    55|                 return CLEAN;
    56|             }
    57|             return DIRTY;
    58|         } finally {
    59|             dst.flip();
    60|         }
    61|     }
    62|     /**
    63|      * Checks if the protocol bytes have been drained.
    64|      *
    65|      * The protocol buffer is in write mode, so if position is 0, the protocol
    66|      * buffer has been drained.
    67|      *
    68|      * @return true if the protocol buffer has been drained.
    69|      */
    70|     private boolean isProtocolBufferDrained() {
    71|         return dst.position() == 0;
    72|     }
    73| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/internal/server/tcp/SingleProtocolDecoder.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 27-115 ---
    27| import static com.hazelcast.internal.nio.Protocols.UNEXPECTED_PROTOCOL;
    28| import static com.hazelcast.internal.util.StringUtil.bytesToString;
    29| /**
    30|  * Checks if the correct protocol is received then swaps itself with the next
    31|  * handler in the pipeline.
    32|  * <p>
    33|  * See also {@link SingleProtocolEncoder}
    34|  * </p>
    35|  */
    36| public class SingleProtocolDecoder
    37|         extends InboundHandler<ByteBuffer, Void> {
    38|     protected final InboundHandler[] inboundHandlers;
    39|     protected final ProtocolType supportedProtocol;
    40|     /**
    41|      * This flag is used to ensure that {@link #verifyProtocol(String)} is called only once
    42|      * with initial bytes of connection. Formerly, this method would be called multiple times
    43|      * with new incoming data, although it failed after its first call.
    44|      */
    45|     protected volatile boolean verifyProtocolCalled;
    46|     final SingleProtocolEncoder encoder;
    47|     public SingleProtocolDecoder(ProtocolType supportedProtocol, InboundHandler next, SingleProtocolEncoder encoder) {
    48|         this(supportedProtocol, new InboundHandler[]{next}, encoder);
    49|     }
    50|     /**
    51|      * Decodes first 3 incoming bytes, validates against {@code
    52|      * supportedProtocol} and, when matching, replaces itself in the inbound
    53|      * pipeline with the {@code next InboundHandler}s.
    54|      *
    55|      * @param supportedProtocol                 the {@link ProtocolType}
    56|      *                                          supported by this {@code
    57|      *                                          ProtocolDecoder}
    58|      * @param next                              the {@link InboundHandler}s to
    59|      *                                          replace this one in the inbound
    60|      *                                          pipeline upon match of protocol
    61|      *                                          bytes
    62|      * @param encoder                           a {@link SingleProtocolEncoder}
    63|      *                                          that will be notified when
    64|      *                                          non-matching protocol bytes have
    65|      *                                          been received
    66|      */
    67|     @SuppressFBWarnings("EI_EXPOSE_REP2")
    68|     public SingleProtocolDecoder(ProtocolType supportedProtocol, InboundHandler[] next,
    69|                                  SingleProtocolEncoder encoder) {
    70|         this.supportedProtocol = supportedProtocol;
    71|         this.inboundHandlers = next;
    72|         this.encoder = encoder;
    73|         this.verifyProtocolCalled = false;
    74|     }
    75|     @Override
    76|     public void handlerAdded() {
    77|         initSrcBuffer(PROTOCOL_LENGTH);
    78|     }
    79|     @Override
    80|     public HandlerStatus onRead() {
    81|         src.flip();
    82|         try {
    83|             if (src.remaining() < PROTOCOL_LENGTH) {
    84|                 return CLEAN;
    85|             }
    86|             boolean verifyProtocolPreviouslyCalled = verifyProtocolCalled;
    87|             if (verifyProtocolPreviouslyCalled || !verifyProtocol(loadProtocol())) {
    88|                 if (verifyProtocolPreviouslyCalled) {
    89|                     src.position(src.limit());
    90|                 }
    91|                 return CLEAN;
    92|             }
    93|             encoder.signalProtocolVerified();
    94|             initConnection();
    95|             setupNextDecoder();
    96|             return CLEAN;
    97|         } finally {
    98|             compactOrClear(src);
    99|         }
   100|     }
   101|     protected void setupNextDecoder() {
   102|         channel.inboundPipeline().replace(this, inboundHandlers);
   103|     }
   104|     protected boolean verifyProtocol(String incomingProtocol) {
   105|         verifyProtocolCalled = true;
   106|         if (!incomingProtocol.equals(supportedProtocol.getDescriptor())) {
   107|             handleUnexpectedProtocol(incomingProtocol);
   108|             encoder.signalWrongProtocol("Unsupported protocol exchange detected, expected protocol: "
   109|                     + supportedProtocol.name() + ", actual protocol or first three bytes are: " + incomingProtocol);
   110|             return false;
   111|         }
   112|         return true;
   113|     }
   114|     protected void handleUnexpectedProtocol(String incomingProtocol) {
   115|         if (incomingProtocol.equals(UNEXPECTED_PROTOCOL)) {


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/internal/server/tcp/SingleProtocolEncoder.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-104 ---
     1| /*
     2|  * Copyright (c) 2008-2021, Hazelcast, Inc. All Rights Reserved.
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.internal.server.tcp;
    17| import com.hazelcast.internal.networking.HandlerStatus;
    18| import com.hazelcast.internal.networking.OutboundHandler;
    19| import com.hazelcast.internal.nio.Protocols;
    20| import java.nio.ByteBuffer;
    21| import static com.hazelcast.internal.networking.HandlerStatus.BLOCKED;
    22| import static com.hazelcast.internal.networking.HandlerStatus.CLEAN;
    23| import static com.hazelcast.internal.networking.HandlerStatus.DIRTY;
    24| import static com.hazelcast.internal.nio.IOUtil.compactOrClear;
    25| import static com.hazelcast.internal.nio.Protocols.PROTOCOL_LENGTH;
    26| import static com.hazelcast.internal.nio.Protocols.UNEXPECTED_PROTOCOL;
    27| import static com.hazelcast.internal.util.StringUtil.stringToBytes;
    28| /**
    29|  * Together with {@link SingleProtocolDecoder}, this encoder-decoder pair is used to check if correct protocol is used.
    30|  * {@link SingleProtocolDecoder} checks if the proper protocol is received. If the protocol is correct, both encoder and decoder
    31|  * are replaced by the next handlers in the pipeline. If it isn't the {@link SingleProtocolEncoder} sends
    32|  * {@link Protocols#UNEXPECTED_PROTOCOL} response and throws a {@link ProtocolException}. Note that in client mode the
    33|  * {@link SingleProtocolEncoder} allows blocking packet writes until the (member-)protocol is confirmed.
    34|  */
    35| public class SingleProtocolEncoder extends OutboundHandler<Void, ByteBuffer> {
    36|     private final OutboundHandler[] outboundHandlers;
    37|     private boolean clusterProtocolBuffered;
    38|     private volatile boolean isDecoderVerifiedProtocol;
    39|     private volatile boolean isDecoderReceivedProtocol;
    40|     private volatile String exceptionMessage;
    41|     public SingleProtocolEncoder(OutboundHandler next) {
    42|         this(new OutboundHandler[]{next});
    43|     }
    44|     public SingleProtocolEncoder(OutboundHandler[] next) {
    45|         this.outboundHandlers = next;
    46|     }
    47|     @Override
    48|     public HandlerStatus onWrite() throws Exception {
    49|         compactOrClear(dst);
    50|         try {
    51|             if (!isDecoderReceivedProtocol) {
    52|                 return BLOCKED;
    53|             }
    54|             if (isDecoderVerifiedProtocol) {
    55|                 setupNextEncoder();
    56|                 return CLEAN;
    57|             }
    58|             if (!channel.isClientMode()) {
    59|                 if (!sendProtocol()) {
    60|                     return DIRTY;
    61|                 }
    62|             }
    63|             throw new ProtocolException(exceptionMessage);
    64|         } finally {
    65|             dst.flip();
    66|         }
    67|     }
    68|     private boolean sendProtocol() {
    69|         if (!clusterProtocolBuffered) {
    70|             clusterProtocolBuffered = true;
    71|             dst.put(stringToBytes(UNEXPECTED_PROTOCOL));
    72|             return false;
    73|         }
    74|         return isProtocolBufferDrained();
    75|     }
    76|     private void setupNextEncoder() {
    77|         channel.outboundPipeline().replace(this, outboundHandlers);
    78|     }
    79|     @Override
    80|     public void handlerAdded() {
    81|         initDstBuffer(PROTOCOL_LENGTH);
    82|     }
    83|     private boolean isProtocolBufferDrained() {
    84|         return dst.position() == 0;
    85|     }
    86|     public void signalProtocolVerified() {
    87|         isDecoderVerifiedProtocol = true;
    88|         isDecoderReceivedProtocol = true;
    89|         if (channel != null) {
    90|             channel.outboundPipeline().wakeup();
    91|         }
    92|     }
    93|     public void signalWrongProtocol(String exceptionMessage) {
    94|         this.exceptionMessage = exceptionMessage;
    95|         isDecoderVerifiedProtocol = false;
    96|         isDecoderReceivedProtocol = true;
    97|         if (channel != null) {
    98|             channel.outboundPipeline().wakeup();
    99|         }
   100|     }
   101|     public OutboundHandler getFirstOutboundHandler() {
   102|         return outboundHandlers[0];
   103|     }
   104| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/internal/util/phonehome/CloudInfoCollector.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 48-87 ---
    48|                        Path dockerFilepath) {
    49|         awsEndpoint = awsEndPoint;
    50|         azureEndpoint = azureEndPoint;
    51|         gcpEndpoint = gcpEndPoint;
    52|         kubernetesTokenPath = kubernetesTokenpath;
    53|         dockerFilePath = dockerFilepath;
    54|     }
    55|     @Override
    56|     public void forEachMetric(Node node, BiConsumer<PhoneHomeMetrics, String> metricsConsumer) {
    57|         if (environmentInfo != null) {
    58|             environmentInfo.forEach(metricsConsumer);
    59|             return;
    60|         }
    61|         Map<PhoneHomeMetrics, String> info = MapUtil.createHashMap(2);
    62|         if (MetricsCollector.fetchWebService(awsEndpoint)) {
    63|             info.put(PhoneHomeMetrics.CLOUD, "A");
    64|         } else if (MetricsCollector.fetchWebService(azureEndpoint)) {
    65|             info.put(PhoneHomeMetrics.CLOUD, "Z");
    66|         } else if (MetricsCollector.fetchWebService(gcpEndpoint)) {
    67|             info.put(PhoneHomeMetrics.CLOUD, "G");
    68|         } else if (MetricsCollector.fetchWebService(awsEndpoint, MetricsCollector.RESPONSE_UNAUTHORIZED)) {
    69|             info.put(PhoneHomeMetrics.CLOUD, "A");
    70|         } else {
    71|             info.put(PhoneHomeMetrics.CLOUD, "N");
    72|         }
    73|         try {
    74|             dockerFilePath.toRealPath();
    75|             try {
    76|                 kubernetesTokenPath.toRealPath();
    77|                 info.put(PhoneHomeMetrics.DOCKER, "K");
    78|             } catch (IOException e) {
    79|                 info.put(PhoneHomeMetrics.DOCKER, "D");
    80|             }
    81|         } catch (IOException e) {
    82|             info.put(PhoneHomeMetrics.DOCKER, "N");
    83|         }
    84|         environmentInfo = info;
    85|         environmentInfo.forEach(metricsConsumer);
    86|     }
    87| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/internal/util/phonehome/MetricsCollector.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 10-50 ---
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.internal.util.phonehome;
    17| import com.hazelcast.instance.impl.Node;
    18| import java.net.HttpURLConnection;
    19| import java.net.URL;
    20| import java.util.function.BiConsumer;
    21| import static com.hazelcast.internal.util.EmptyStatement.ignore;
    22| /**
    23|  * Class responsible for collecting phone home data (phone home metrics).
    24|  *
    25|  * @see PhoneHomeMetrics
    26|  */
    27| interface MetricsCollector {
    28|     int TIMEOUT = 2000;
    29|     int RESPONSE_OK = 200;
    30|     int RESPONSE_UNAUTHORIZED = 401;
    31|     int A_INTERVAL = 5;
    32|     int B_INTERVAL = 10;
    33|     int C_INTERVAL = 20;
    34|     int D_INTERVAL = 40;
    35|     int E_INTERVAL = 60;
    36|     int F_INTERVAL = 100;
    37|     int G_INTERVAL = 150;
    38|     int H_INTERVAL = 300;
    39|     int J_INTERVAL = 600;
    40|     /**
    41|      * Calls the {@code metricsConsumer} for each metric collected by this collector.
    42|      *
    43|      * @param node            this node
    44|      * @param metricsConsumer the consumer to call with the metric type and value
    45|      */
    46|     void forEachMetric(Node node, BiConsumer<PhoneHomeMetrics, String> metricsConsumer);
    47|     static String convertToLetter(int size) {
    48|         String letter;
    49|         if (size < A_INTERVAL) {
    50|             letter = "A";

# --- HUNK 2: Lines 52-95 ---
    52|             letter = "B";
    53|         } else if (size < C_INTERVAL) {
    54|             letter = "C";
    55|         } else if (size < D_INTERVAL) {
    56|             letter = "D";
    57|         } else if (size < E_INTERVAL) {
    58|             letter = "E";
    59|         } else if (size < F_INTERVAL) {
    60|             letter = "F";
    61|         } else if (size < G_INTERVAL) {
    62|             letter = "G";
    63|         } else if (size < H_INTERVAL) {
    64|             letter = "H";
    65|         } else if (size < J_INTERVAL) {
    66|             letter = "J";
    67|         } else {
    68|             letter = "I";
    69|         }
    70|         return letter;
    71|     }
    72|     static boolean fetchWebService(String urlStr, int responseCode) {
    73|         HttpURLConnection conn = null;
    74|         boolean response;
    75|         try {
    76|             URL url = new URL(urlStr);
    77|             conn = (HttpURLConnection) url.openConnection();
    78|             conn.setConnectTimeout(TIMEOUT);
    79|             conn.setReadTimeout(TIMEOUT);
    80|             conn.connect();
    81|             response = conn.getResponseCode() == responseCode;
    82|         } catch (Exception ignored) {
    83|             ignore(ignored);
    84|             return false;
    85|         } finally {
    86|             if (conn != null) {
    87|                 conn.disconnect();
    88|             }
    89|         }
    90|         return response;
    91|     }
    92|     static boolean fetchWebService(String url) {
    93|         return fetchWebService(url, RESPONSE_OK);
    94|     }
    95| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/jet/impl/JetInstanceImpl.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 5-141 ---
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.jet.impl;
    17| import com.hazelcast.cluster.Address;
    18| import com.hazelcast.cluster.Member;
    19| import com.hazelcast.core.MemberLeftException;
    20| import com.hazelcast.instance.impl.HazelcastInstanceImpl;
    21| import com.hazelcast.internal.util.Preconditions;
    22| import com.hazelcast.jet.Job;
    23| import com.hazelcast.jet.config.JetConfig;
    24| import com.hazelcast.jet.config.JobConfig;
    25| import com.hazelcast.jet.datamodel.Tuple2;
    26| import com.hazelcast.jet.impl.operation.GetJobIdsOperation;
    27| import com.hazelcast.jet.impl.operation.GetJobIdsOperation.GetJobIdsResult;
    28| import com.hazelcast.logging.ILogger;
    29| import com.hazelcast.map.impl.MapService;
    30| import com.hazelcast.spi.exception.TargetNotMemberException;
    31| import com.hazelcast.spi.impl.NodeEngineImpl;
    32| import javax.annotation.Nonnull;
    33| import java.util.ArrayList;
    34| import java.util.Collection;
    35| import java.util.HashMap;
    36| import java.util.List;
    37| import java.util.Map;
    38| import java.util.Map.Entry;
    39| import java.util.concurrent.CompletableFuture;
    40| import java.util.concurrent.ExecutionException;
    41| import static com.hazelcast.cluster.memberselector.MemberSelectors.DATA_MEMBER_SELECTOR;
    42| import static com.hazelcast.jet.datamodel.Tuple2.tuple2;
    43| import static com.hazelcast.jet.impl.util.ExceptionUtil.isOrHasCause;
    44| import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;
    45| import static java.util.Collections.singleton;
    46| /**
    47|  * Member-side {@code JetInstance} implementation
    48|  */
    49| public class JetInstanceImpl extends AbstractJetInstance<Address> {
    50|     private final NodeEngineImpl nodeEngine;
    51|     private final JetConfig config;
    52|     JetInstanceImpl(HazelcastInstanceImpl hazelcastInstance, JetConfig config) {
    53|         super(hazelcastInstance);
    54|         this.nodeEngine = hazelcastInstance.node.getNodeEngine();
    55|         this.config = config;
    56|     }
    57|     @Nonnull @Override
    58|     public JetConfig getConfig() {
    59|         return config;
    60|     }
    61|     @Override
    62|     public Address getMasterId() {
    63|         return Preconditions.checkNotNull(nodeEngine.getMasterAddress(), "Cluster has not elected a master");
    64|     }
    65|     @Override
    66|     public Map<Address, GetJobIdsResult> getJobsInt(String onlyName, Long onlyJobId) {
    67|         Map<Address, CompletableFuture<GetJobIdsResult>> futures = new HashMap<>();
    68|         Collection<Member> targetMembers = onlyName == null
    69|                 ? nodeEngine.getClusterService().getMembers(DATA_MEMBER_SELECTOR)
    70|                 : singleton(nodeEngine.getClusterService().getMembers().iterator().next());
    71|         GetJobIdsOperation masterOperation = new GetJobIdsOperation(onlyName, onlyJobId);
    72|         CompletableFuture<GetJobIdsResult> masterFuture = nodeEngine
    73|                 .getOperationService()
    74|                 .createMasterInvocationBuilder(JetServiceBackend.SERVICE_NAME, masterOperation)
    75|                 .invoke();
    76|         for (Member member : targetMembers) {
    77|             GetJobIdsOperation operation = new GetJobIdsOperation(onlyName, onlyJobId);
    78|             futures.put(member.getAddress(), nodeEngine
    79|                     .getOperationService()
    80|                     .createInvocationBuilder(JetServiceBackend.SERVICE_NAME, operation, member.getAddress())
    81|                     .invoke());
    82|         }
    83|         Map<Address, GetJobIdsResult> res = new HashMap<>(futures.size());
    84|         for (Entry<Address, CompletableFuture<GetJobIdsResult>> en : futures.entrySet()) {
    85|             GetJobIdsResult result;
    86|             try {
    87|                 result = en.getValue().get();
    88|             } catch (InterruptedException e) {
    89|                 Thread.currentThread().interrupt();
    90|                 result = GetJobIdsResult.EMPTY;
    91|             } catch (ExecutionException e) {
    92|                 if (isOrHasCause(e, MemberLeftException.class) || isOrHasCause(e, TargetNotMemberException.class)) {
    93|                     result = GetJobIdsResult.EMPTY;
    94|                 } else {
    95|                     throw new RuntimeException("Error when getting job IDs: " + e, e);
    96|                 }
    97|             }
    98|             res.put(en.getKey(), result);
    99|         }
   100|         res.put(null, filterNonLightJobs(masterFuture));
   101|         return res;
   102|     }
   103|     private GetJobIdsResult filterNonLightJobs(CompletableFuture<GetJobIdsResult> masterFuture) {
   104|         GetJobIdsResult result;
   105|         try {
   106|             result = masterFuture.get();
   107|         } catch (InterruptedException e) {
   108|             Thread.currentThread().interrupt();
   109|             return GetJobIdsResult.EMPTY;
   110|         } catch (Exception e) {
   111|             throw rethrow(e);
   112|         }
   113|         List<Tuple2<Long, Boolean>> nonLightJobs = new ArrayList<>();
   114|         for (int i = 0; i < result.getJobIds().length; i++) {
   115|             long jobId = result.getJobIds()[i];
   116|             if (result.getIsLightJobs()[i]) {
   117|                 continue;
   118|             }
   119|             nonLightJobs.add(tuple2(jobId, false));
   120|         }
   121|         return new GetJobIdsResult(nonLightJobs);
   122|     }
   123|     @Override
   124|     public void shutdown() {
   125|         try {
   126|             JetServiceBackend jetServiceBackend = nodeEngine.getService(JetServiceBackend.SERVICE_NAME);
   127|             jetServiceBackend.shutDownJobs();
   128|             super.shutdown();
   129|         } catch (Throwable t) {
   130|             throw rethrow(t);
   131|         }
   132|     }
   133|     /**
   134|      * Tells whether this member knows of the given object name.
   135|      * <p>
   136|      * Notes:
   137|      * <ul><li>
   138|      *     this member might not know it exists if the proxy creation operation went wrong
   139|      * </li><li>
   140|      *     this member might not know it was destroyed if the destroy operation went wrong
   141|      * </li><li>


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/jet/impl/util/ExceptionUtil.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 175-205 ---
   175|      * another JetException explaining the possible reason.
   176|      * <p>
   177|      * This is a hack to improve readability of this common exception.
   178|      *
   179|      * @param e the exception to handle
   180|      * @return the given exception wrapped, if it is a case of CCE for SerializedLambda
   181|      *     or the given exception otherwise
   182|      */
   183|     public static RuntimeException handleSerializedLambdaCce(HazelcastSerializationException e) {
   184|         Throwable cause = e.getCause();
   185|         while (cause != null) {
   186|             if (cause instanceof ClassCastException
   187|                     && cause.getMessage().startsWith("cannot assign instance of java.lang.invoke.SerializedLambda")) {
   188|                 throw new JetException("Class containing the lambda probably missing from class path, did you add it " +
   189|                         "using JobConfig.addClass()?: " + e, e);
   190|             }
   191|             cause = cause.getCause();
   192|         }
   193|         throw e;
   194|     }
   195|     /**
   196|      * Checks, if {@code t} itself or any exception in its cause chain is an
   197|      * instance of {@code classToFind}.
   198|      */
   199|     public static boolean isOrHasCause(Throwable t, Class<?> classToFind) {
   200|         while (t != null && t.getCause() != t && !classToFind.isAssignableFrom(t.getClass())) {
   201|             t = t.getCause();
   202|         }
   203|         return t != null && classToFind.isAssignableFrom(t.getClass());
   204|     }
   205| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/map/impl/EntryViews.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 12-67 ---
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.map.impl;
    17| import com.hazelcast.core.EntryView;
    18| import com.hazelcast.internal.serialization.Data;
    19| import com.hazelcast.internal.serialization.SerializationService;
    20| import com.hazelcast.map.impl.record.Record;
    21| import com.hazelcast.map.impl.recordstore.expiry.ExpiryMetadata;
    22| import com.hazelcast.map.impl.wan.WanMapEntryView;
    23| /**
    24|  * A class providing static factory methods that create various entry view objects.
    25|  */
    26| public final class EntryViews {
    27|     private EntryViews() {
    28|     }
    29|     public static <K, V> EntryView<K, V> createSimpleEntryView() {
    30|         return new SimpleEntryView<>();
    31|     }
    32|     public static <K, V> EntryView<K, V> createSimpleEntryView(K key, V value, Record<V> record,
    33|                                                                ExpiryMetadata expiryMetadata) {
    34|         return new SimpleEntryView<>(key, value)
    35|                 .withCost(record.getCost())
    36|                 .withVersion(record.getVersion())
    37|                 .withHits(record.getHits())
    38|                 .withLastAccessTime(record.getLastAccessTime())
    39|                 .withLastUpdateTime(calculateLastUpdateTime(record, expiryMetadata))
    40|                 .withCreationTime(record.getCreationTime())
    41|                 .withLastStoredTime(record.getLastStoredTime())
    42|                 .withTtl(expiryMetadata.getTtl())
    43|                 .withMaxIdle(expiryMetadata.getMaxIdle())
    44|                 .withExpirationTime(expiryMetadata.getExpirationTime());
    45|     }
    46|     public static <K, V> WanMapEntryView<K, V> createWanEntryView(Data key, Data value,
    47|                                                                   Record<V> record, ExpiryMetadata expiryMetadata,
    48|                                                                   SerializationService serializationService) {
    49|         return new WanMapEntryView<K, V>(key, value, serializationService)
    50|                 .withCost(record.getCost())
    51|                 .withVersion(record.getVersion())
    52|                 .withHits(record.getHits())
    53|                 .withLastAccessTime(record.getLastAccessTime())
    54|                 .withLastUpdateTime(calculateLastUpdateTime(record, expiryMetadata))
    55|                 .withCreationTime(record.getCreationTime())
    56|                 .withLastStoredTime(record.getLastStoredTime())
    57|                 .withTtl(expiryMetadata.getTtl())
    58|                 .withMaxIdle(expiryMetadata.getMaxIdle())
    59|                 .withExpirationTime(expiryMetadata.getExpirationTime());
    60|     }
    61|     private static <V> long calculateLastUpdateTime(Record<V> record, ExpiryMetadata expiryMetadata) {
    62|         if (expiryMetadata != ExpiryMetadata.NULL) {
    63|             return expiryMetadata.getLastUpdateTime();
    64|         }
    65|         return record.getLastUpdateTime();
    66|     }
    67| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/map/impl/MapPartitionAwareService.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-55 ---
     1| /*
     2|  * Copyright (c) 2008-2021, Hazelcast, Inc. All Rights Reserved.
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.map.impl;
    17| import com.hazelcast.cluster.Address;
    18| import com.hazelcast.spi.impl.NodeEngine;
    19| import com.hazelcast.internal.partition.PartitionAwareService;
    20| import com.hazelcast.spi.impl.eventservice.impl.EventServiceImpl;
    21| import com.hazelcast.spi.impl.eventservice.impl.EventServiceSegment;
    22| import com.hazelcast.internal.partition.IPartitionLostEvent;
    23| import java.util.Set;
    24| /**
    25|  * Defines partition-aware operations' behavior of map service.
    26|  * Currently, it only defines the behavior for partition lost occurrences
    27|  *
    28|  * @see IPartitionLostEvent
    29|  */
    30| class MapPartitionAwareService implements PartitionAwareService {
    31|     private final MapServiceContext mapServiceContext;
    32|     private final NodeEngine nodeEngine;
    33|     private final EventServiceImpl eventService;
    34|     MapPartitionAwareService(MapServiceContext mapServiceContext) {
    35|         this.mapServiceContext = mapServiceContext;
    36|         this.nodeEngine = mapServiceContext.getNodeEngine();
    37|         this.eventService = (EventServiceImpl) this.nodeEngine.getEventService();
    38|     }
    39|     @Override
    40|     public void onPartitionLost(IPartitionLostEvent partitionLostEvent) {
    41|         final Address thisAddress = nodeEngine.getThisAddress();
    42|         final int partitionId = partitionLostEvent.getPartitionId();
    43|         EventServiceSegment eventServiceSegment = eventService.getSegment(MapService.SERVICE_NAME, false);
    44|         if (eventServiceSegment == null) {
    45|             return;
    46|         }
    47|         Set<String> maps = eventServiceSegment.getRegistrations().keySet();
    48|         for (String mapName : maps) {
    49|             int totalBackupCount = nodeEngine.getConfig().getMapConfig(mapName).getTotalBackupCount();
    50|             if (totalBackupCount <= partitionLostEvent.getLostReplicaIndex()) {
    51|                 mapServiceContext.getMapEventPublisher().publishMapPartitionLostEvent(thisAddress, mapName, partitionId);
    52|             }
    53|         }
    54|     }
    55| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/map/impl/MapService.java
# Total hunks: 3
# ====================================================================
# --- HUNK 1: Lines 6-46 ---
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.map.impl;
    17| import com.hazelcast.cluster.ClusterState;
    18| import com.hazelcast.config.WanAcknowledgeType;
    19| import com.hazelcast.core.DistributedObject;
    20| import com.hazelcast.internal.cluster.ClusterStateListener;
    21| import com.hazelcast.internal.metrics.DynamicMetricsProvider;
    22| import com.hazelcast.internal.metrics.MetricDescriptor;
    23| import com.hazelcast.internal.metrics.MetricsCollectionContext;
    24| import com.hazelcast.internal.partition.FragmentedMigrationAwareService;
    25| import com.hazelcast.internal.partition.IPartitionLostEvent;
    26| import com.hazelcast.internal.partition.IPartitionService;
    27| import com.hazelcast.internal.partition.OffloadedReplicationPreparation;
    28| import com.hazelcast.internal.partition.PartitionAwareService;
    29| import com.hazelcast.internal.partition.PartitionMigrationEvent;
    30| import com.hazelcast.internal.partition.PartitionReplicationEvent;
    31| import com.hazelcast.internal.serialization.Data;
    32| import com.hazelcast.internal.services.ClientAwareService;
    33| import com.hazelcast.internal.services.DistributedObjectNamespace;
    34| import com.hazelcast.internal.services.LockInterceptorService;
    35| import com.hazelcast.internal.services.ManagedService;
    36| import com.hazelcast.internal.services.NotifiableEventListener;
    37| import com.hazelcast.internal.services.ObjectNamespace;
    38| import com.hazelcast.internal.services.PostJoinAwareService;
    39| import com.hazelcast.internal.services.RemoteService;
    40| import com.hazelcast.internal.services.ServiceNamespace;
    41| import com.hazelcast.internal.services.SplitBrainHandlerService;
    42| import com.hazelcast.internal.services.SplitBrainProtectionAwareService;
    43| import com.hazelcast.internal.services.StatisticsAwareService;
    44| import com.hazelcast.internal.services.TenantContextAwareService;
    45| import com.hazelcast.internal.services.TransactionalService;
    46| import com.hazelcast.internal.services.WanSupportingService;

# --- HUNK 2: Lines 72-116 ---
    72| import static com.hazelcast.internal.metrics.MetricDescriptorConstants.MAP_PREFIX_NEARCACHE;
    73| import static com.hazelcast.internal.metrics.MetricDescriptorConstants.MAP_TAG_INDEX;
    74| /**
    75|  * Defines map service behavior.
    76|  *
    77|  * @see MapManagedService
    78|  * @see MapMigrationAwareService
    79|  * @see MapTransactionalService
    80|  * @see MapRemoteService
    81|  * @see MapEventPublishingService
    82|  * @see MapPostJoinAwareService
    83|  * @see MapSplitBrainHandlerService
    84|  * @see WanMapSupportingService
    85|  * @see MapPartitionAwareService
    86|  * @see MapSplitBrainProtectionAwareService
    87|  * @see MapClientAwareService
    88|  * @see MapServiceContext
    89|  */
    90| @SuppressWarnings({"checkstyle:ClassFanOutComplexity", "checkstyle:MethodCount"})
    91| public class MapService implements ManagedService, FragmentedMigrationAwareService, TransactionalService, RemoteService,
    92|         EventPublishingService<Object, ListenerAdapter>, PostJoinAwareService,
    93|         SplitBrainHandlerService, WanSupportingService, StatisticsAwareService<LocalMapStats>,
    94|         PartitionAwareService, ClientAwareService, SplitBrainProtectionAwareService,
    95|         NotifiableEventListener, ClusterStateListener, LockInterceptorService<Data>,
    96|         DynamicMetricsProvider, TenantContextAwareService, OffloadedReplicationPreparation {
    97|     public static final String SERVICE_NAME = "hz:impl:mapService";
    98|     protected ManagedService managedService;
    99|     protected CountingMigrationAwareService migrationAwareService;
   100|     protected TransactionalService transactionalService;
   101|     protected RemoteService remoteService;
   102|     protected EventPublishingService eventPublishingService;
   103|     protected PostJoinAwareService postJoinAwareService;
   104|     protected SplitBrainHandlerService splitBrainHandlerService;
   105|     protected WanSupportingService wanSupportingService;
   106|     protected StatisticsAwareService statisticsAwareService;
   107|     protected PartitionAwareService partitionAwareService;
   108|     protected ClientAwareService clientAwareService;
   109|     protected MapSplitBrainProtectionAwareService splitBrainProtectionAwareService;
   110|     protected MapServiceContext mapServiceContext;
   111|     public MapService() {
   112|     }
   113|     @Override
   114|     public void dispatchEvent(Object event, ListenerAdapter listener) {
   115|         eventPublishingService.dispatchEvent(event, listener);
   116|     }

# --- HUNK 3: Lines 220-264 ---
   220|     public void onDeregister(Object service, String serviceName, String topic, EventRegistration registration) {
   221|         EventFilter filter = registration.getFilter();
   222|         if (!(filter instanceof EventListenerFilter) || !filter.eval(INVALIDATION.getType())) {
   223|             return;
   224|         }
   225|         MapContainer mapContainer = mapServiceContext.getMapContainer(topic);
   226|         mapContainer.decreaseInvalidationListenerCount();
   227|     }
   228|     public int getMigrationStamp() {
   229|         return migrationAwareService.getMigrationStamp();
   230|     }
   231|     public boolean validateMigrationStamp(int stamp) {
   232|         return migrationAwareService.validateMigrationStamp(stamp);
   233|     }
   234|     @Override
   235|     public void onClusterStateChange(ClusterState newState) {
   236|         mapServiceContext.onClusterStateChange(newState);
   237|     }
   238|     @Override
   239|     public void onBeforeLock(String distributedObjectName, Data key) {
   240|         IPartitionService partitionService = mapServiceContext.getNodeEngine().getPartitionService();
   241|         int partitionId = partitionService.getPartitionId(key);
   242|         RecordStore recordStore = mapServiceContext.getRecordStore(partitionId, distributedObjectName);
   243|         boolean owner = partitionService.isPartitionOwner(partitionId);
   244|         recordStore.getRecordOrNull(key, !owner);
   245|     }
   246|     public static ObjectNamespace getObjectNamespace(String mapName) {
   247|         return new DistributedObjectNamespace(SERVICE_NAME, mapName);
   248|     }
   249|     @Override
   250|     public void provideDynamicMetrics(MetricDescriptor descriptor, MetricsCollectionContext context) {
   251|         Map<String, LocalMapStats> stats = getStats();
   252|         if (stats == null) {
   253|             return;
   254|         }
   255|         for (Map.Entry<String, LocalMapStats> entry : stats.entrySet()) {
   256|             String mapName = entry.getKey();
   257|             LocalMapStats localInstanceStats = entry.getValue();
   258|             MetricDescriptor dsDescriptor = descriptor
   259|                     .copy()
   260|                     .withPrefix(MAP_PREFIX)
   261|                     .withDiscriminator(MAP_DISCRIMINATOR_NAME, mapName);
   262|             context.collect(dsDescriptor, localInstanceStats);
   263|             Map<String, LocalIndexStats> indexStats = localInstanceStats.getIndexStats();
   264|             for (Map.Entry<String, LocalIndexStats> indexEntry : indexStats.entrySet()) {


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/map/impl/operation/GetEntryViewOperation.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 16-56 ---
    16| package com.hazelcast.map.impl.operation;
    17| import com.hazelcast.core.EntryView;
    18| import com.hazelcast.core.OperationTimeoutException;
    19| import com.hazelcast.internal.locksupport.LockWaitNotifyKey;
    20| import com.hazelcast.internal.serialization.Data;
    21| import com.hazelcast.map.impl.EntryViews;
    22| import com.hazelcast.map.impl.MapDataSerializerHook;
    23| import com.hazelcast.map.impl.record.Record;
    24| import com.hazelcast.map.impl.recordstore.expiry.ExpiryMetadata;
    25| import com.hazelcast.spi.impl.operationservice.BlockingOperation;
    26| import com.hazelcast.spi.impl.operationservice.WaitNotifyKey;
    27| public class GetEntryViewOperation extends ReadonlyKeyBasedMapOperation implements BlockingOperation {
    28|     private EntryView<Data, Data> result;
    29|     public GetEntryViewOperation() {
    30|     }
    31|     public GetEntryViewOperation(String name, Data dataKey) {
    32|         super(name, dataKey);
    33|     }
    34|     @Override
    35|     protected void runInternal() {
    36|         Record record = recordStore.getRecordOrNull(dataKey, false);
    37|         if (record != null) {
    38|             Data value = mapServiceContext.toData(record.getValue());
    39|             ExpiryMetadata expiredMetadata = recordStore.getExpirySystem().getExpiredMetadata(dataKey);
    40|             result = EntryViews.createSimpleEntryView(dataKey, value, record, expiredMetadata);
    41|         }
    42|     }
    43|     @Override
    44|     public WaitNotifyKey getWaitKey() {
    45|         return new LockWaitNotifyKey(getServiceNamespace(), dataKey);
    46|     }
    47|     public boolean shouldWait() {
    48|         return recordStore.isTransactionallyLocked(dataKey)
    49|                 && !recordStore.canAcquireLock(dataKey, getCallerUuid(), getThreadId());
    50|     }
    51|     @Override
    52|     public void onWaitExpire() {
    53|         sendResponse(new OperationTimeoutException("Cannot read transactionally locked entry!"));
    54|     }
    55|     @Override
    56|     public Object getResponse() {


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/map/impl/operation/PartitionWideEntryOperation.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 119-160 ---
   119|         }, false);
   120|     }
   121|     private void runWithPartitionScanForNative() {
   122|         int totalEntryCount = recordStore.size();
   123|         responses = new MapEntries(totalEntryCount);
   124|         Queue<Object> outComes = new LinkedList<>();
   125|         operator = operator(this, entryProcessor, getPredicate());
   126|         recordStore.forEach((key, record) -> {
   127|             Data dataKey = toHeapData(key);
   128|             Data response = operator.operateOnKey(dataKey).getResult();
   129|             if (response != null) {
   130|                 responses.add(dataKey, response);
   131|             }
   132|             EntryEventType eventType = operator.getEventType();
   133|             if (eventType != null) {
   134|                 outComes.add(dataKey);
   135|                 outComes.add(operator.getOldValue());
   136|                 outComes.add(operator.getByPreferringDataNewValue());
   137|                 outComes.add(eventType);
   138|                 outComes.add(operator.getEntry().getNewTtl());
   139|             } else {
   140|                 operator.doPostOperateOps();
   141|             }
   142|         }, false);
   143|         while (!outComes.isEmpty()) {
   144|             Data dataKey = (Data) outComes.poll();
   145|             Object oldValue = outComes.poll();
   146|             Object newValue = outComes.poll();
   147|             EntryEventType eventType = (EntryEventType) outComes.poll();
   148|             long newTtl = (long) outComes.poll();
   149|             operator.init(dataKey, oldValue, newValue, null, eventType,
   150|                     null, newTtl).doPostOperateOps();
   151|         }
   152|     }
   153|     @Override
   154|     public Object getResponse() {
   155|         return responses;
   156|     }
   157|     @Override
   158|     public boolean shouldBackup() {
   159|         return mapContainer.getTotalBackupCount() > 0 && entryProcessor.getBackupProcessor() != null;
   160|     }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/map/impl/operation/PostJoinMapOperation.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 35-77 ---
    35| import com.hazelcast.spi.impl.operationservice.Operation;
    36| import com.hazelcast.spi.impl.operationservice.TargetAware;
    37| import java.io.IOException;
    38| import java.util.AbstractMap;
    39| import java.util.ArrayList;
    40| import java.util.Collections;
    41| import java.util.LinkedList;
    42| import java.util.List;
    43| import java.util.Map;
    44| import static com.hazelcast.internal.util.MapUtil.createHashMap;
    45| public class PostJoinMapOperation extends Operation implements IdentifiedDataSerializable, TargetAware {
    46|     private List<InterceptorInfo> interceptorInfoList = new LinkedList<>();
    47|     private List<AccumulatorInfo> infoList;
    48|     @Override
    49|     public String getServiceName() {
    50|         return MapService.SERVICE_NAME;
    51|     }
    52|     public void addMapInterceptors(MapContainer mapContainer) {
    53|         InterceptorRegistry interceptorRegistry = mapContainer.getInterceptorRegistry();
    54|         List<MapInterceptor> interceptorList = interceptorRegistry.getInterceptors();
    55|         if (interceptorList.isEmpty()) {
    56|             return;
    57|         }
    58|         Map<String, MapInterceptor> interceptorMap = interceptorRegistry.getId2InterceptorMap();
    59|         Map<MapInterceptor, String> revMap = createHashMap(interceptorMap.size());
    60|         for (Map.Entry<String, MapInterceptor> entry : interceptorMap.entrySet()) {
    61|             revMap.put(entry.getValue(), entry.getKey());
    62|         }
    63|         InterceptorInfo interceptorInfo = new InterceptorInfo(mapContainer.getName());
    64|         for (MapInterceptor interceptor : interceptorList) {
    65|             interceptorInfo.addInterceptor(revMap.get(interceptor), interceptor);
    66|         }
    67|         interceptorInfoList.add(interceptorInfo);
    68|     }
    69|     public static class InterceptorInfo implements IdentifiedDataSerializable {
    70|         private String mapName;
    71|         private final List<Map.Entry<String, MapInterceptor>> interceptors = new LinkedList<>();
    72|         InterceptorInfo(String mapName) {
    73|             this.mapName = mapName;
    74|         }
    75|         public InterceptorInfo() {
    76|         }
    77|         void addInterceptor(String id, MapInterceptor interceptor) {


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/map/impl/recordstore/DefaultRecordStore.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 159-198 ---
   159|     }
   160|     private void destroyMetadataStore() {
   161|         if (metadataStore != null) {
   162|             metadataStore.destroy();
   163|         }
   164|     }
   165|     @Override
   166|     public Record getRecord(Data key) {
   167|         return storage.get(key);
   168|     }
   169|     @Override
   170|     public Record putReplicatedRecord(Data dataKey, Record replicatedRecord,
   171|                                       ExpiryMetadata expiryMetadata,
   172|                                       boolean populateIndexes, long now) {
   173|         Record newRecord = createRecord(replicatedRecord, now);
   174|         storage.put(dataKey, newRecord);
   175|         expirySystem.add(dataKey, expiryMetadata.getTtl(),
   176|                 expiryMetadata.getMaxIdle(), expiryMetadata.getExpirationTime(),
   177|                 now, expiryMetadata.getLastUpdateTime());
   178|         mutationObserver.onReplicationPutRecord(dataKey, newRecord, populateIndexes);
   179|         return newRecord;
   180|     }
   181|     @Override
   182|     public void removeReplicatedRecord(Data dataKey, boolean backup) {
   183|         Record record = storage.get(dataKey);
   184|         if (record != null) {
   185|             mutationObserver.onRemoveRecord(dataKey, record, backup);
   186|             removeKeyFromExpirySystem(dataKey);
   187|             storage.removeRecord(dataKey, record);
   188|         }
   189|     }
   190|     @Override
   191|     public Record putBackup(Data dataKey, Record newRecord, ExpiryMetadata expiryMetadata,
   192|                             boolean putTransient, CallerProvenance provenance) {
   193|         return putBackupInternal(dataKey, newRecord.getValue(),
   194|                 expiryMetadata.getTtl(), expiryMetadata.getMaxIdle(), expiryMetadata.getExpirationTime(),
   195|                 putTransient, provenance, null);
   196|     }
   197|     @Override
   198|     public Record putBackup(Data dataKey, Record record, long ttl,

# --- HUNK 2: Lines 964-1006 ---
   964|                 false, null, false, true,
   965|                 null, callerAddress, true, false);
   966|     }
   967|     protected Object removeRecord(Data key, @Nonnull Record record,
   968|                                   long now, CallerProvenance provenance,
   969|                                   UUID transactionId) {
   970|         Object oldValue = record.getValue();
   971|         oldValue = mapServiceContext.interceptRemove(interceptorRegistry, oldValue);
   972|         if (oldValue != null) {
   973|             if (persistenceEnabledFor(provenance)) {
   974|                 mapDataStore.remove(key, now, transactionId);
   975|             }
   976|             onStore(record);
   977|         }
   978|         mutationObserver.onRemoveRecord(key, record, false);
   979|         removeKeyFromExpirySystem(key);
   980|         storage.removeRecord(key, record);
   981|         return oldValue;
   982|     }
   983|     @Override
   984|     public Record getRecordOrNull(Data key, boolean backup) {
   985|         long now = getNow();
   986|         return getRecordOrNull(key, now, backup);
   987|     }
   988|     protected Record getRecordOrNull(Data key, long now, boolean backup) {
   989|         Record record = storage.get(key);
   990|         if (record != null) {
   991|             return evictIfExpired(key, now, backup) ? null : record;
   992|         }
   993|         return null;
   994|     }
   995|     protected void onStore(Record record) {
   996|         if (record == null || mapDataStore == EMPTY_MAP_DATA_STORE) {
   997|             return;
   998|         }
   999|         record.onStore();
  1000|     }
  1001|     private void updateStoreStats() {
  1002|         if (!(mapDataStore instanceof WriteBehindStore)
  1003|                 || !mapContainer.getMapConfig().isPerEntryStatsEnabled()) {
  1004|             return;
  1005|         }
  1006|         long now = getNow();


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/map/impl/recordstore/RecordStore.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 381-426 ---
   381|     boolean isExpired(Data dataKey, long now, boolean backup);
   382|     /**
   383|      * Does post eviction operations like sending events
   384|      *
   385|      * @param dataValue    record to process
   386|      * @param expiryReason
   387|      */
   388|     void doPostEvictionOperations(@Nonnull Data dataKey, @Nonnull Object dataValue,
   389|                                   @Nonnull ExpiryReason expiryReason);
   390|     MapDataStore<Data, Object> getMapDataStore();
   391|     InvalidationQueue<ExpiredKey> getExpiredKeysQueue();
   392|     /**
   393|      * Returns the partition id this RecordStore belongs to.
   394|      *
   395|      * @return the partition id.
   396|      */
   397|     int getPartitionId();
   398|     /**
   399|      * Returns live record or null if record is already expired. Does not load missing keys from a map store.
   400|      *
   401|      * @param key      key to be accessed
   402|      * @param backup true if partition is a backup-partition otherwise set false
   403|      * @return live record or null
   404|      * @see #get
   405|      */
   406|     R getRecordOrNull(Data key, boolean backup);
   407|     /**
   408|      * Check if record is reachable according to TTL or idle times.
   409|      *
   410|      * @param now    current time in millis
   411|      * @param backup <code>true</code> if a backup
   412|      *               partition, otherwise <code>false</code>.
   413|      * @return {@code true} if record has been evicted
   414|      * due to the expiry, otherwise return {@code false}.
   415|      */
   416|     boolean evictIfExpired(Data key, long now, boolean backup);
   417|     void evictExpiredEntryAndPublishExpiryEvent(Data key, ExpiryReason expiryReason, boolean backup);
   418|     /**
   419|      * Evicts entries from this record-store.
   420|      *
   421|      * @param excludedKey this key has lowest priority to be selected for eviction
   422|      */
   423|     void evictEntries(Data excludedKey);
   424|     /**
   425|      * Returns <code>true</code> if eviction is allowed on this record-store, otherwise <code>false</code>
   426|      *


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/map/impl/tx/TxnLockAndGetOperation.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 35-75 ---
    35|     private boolean blockReads;
    36|     private UUID ownerUuid;
    37|     private VersionedValue response;
    38|     public TxnLockAndGetOperation() {
    39|     }
    40|     public TxnLockAndGetOperation(String name, Data dataKey, long timeout,
    41|                                   long ttl, UUID ownerUuid, boolean shouldLoad,
    42|                                   boolean blockReads) {
    43|         super(name, dataKey);
    44|         this.ownerUuid = ownerUuid;
    45|         this.shouldLoad = shouldLoad;
    46|         this.blockReads = blockReads;
    47|         this.ttl = ttl;
    48|         setWaitTimeout(timeout);
    49|     }
    50|     @Override
    51|     protected void runInternal() {
    52|         if (!recordStore.txnLock(getKey(), ownerUuid, getThreadId(), getCallId(), ttl, blockReads)) {
    53|             throw new TransactionException("Transaction couldn't obtain lock.");
    54|         }
    55|         Record record = recordStore.getRecordOrNull(dataKey, false);
    56|         if (record == null && shouldLoad) {
    57|             record = recordStore.loadRecordOrNull(dataKey, false, getCallerAddress());
    58|         }
    59|         Data value = record == null ? null : mapServiceContext.toData(record.getValue());
    60|         response = new VersionedValue(value, record == null ? 0 : record.getVersion());
    61|     }
    62|     public boolean shouldWait() {
    63|         return !recordStore.canAcquireLock(dataKey, ownerUuid, getThreadId());
    64|     }
    65|     @Override
    66|     public void onWaitExpire() {
    67|         sendResponse(null);
    68|     }
    69|     @Override
    70|     public Object getResponse() {
    71|         return response;
    72|     }
    73|     @Override
    74|     protected void writeInternal(ObjectDataOutput out) throws IOException {
    75|         super.writeInternal(out);


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/map/impl/tx/TxnSetOperation.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 48-88 ---
    48|                            Data value, long version, long ttl) {
    49|         super(name, dataKey, value);
    50|         this.version = version;
    51|         this.ttl = ttl;
    52|     }
    53|     @Override
    54|     public boolean shouldWait() {
    55|         return false;
    56|     }
    57|     @Override
    58|     public void innerBeforeRun() throws Exception {
    59|         super.innerBeforeRun();
    60|         if (!recordStore.canAcquireLock(dataKey, ownerUuid, threadId)) {
    61|             wbqCapacityCounter().decrement(transactionId);
    62|             throw new TransactionException("Cannot acquire lock UUID: " + ownerUuid + ", threadId: " + threadId);
    63|         }
    64|     }
    65|     @Override
    66|     protected void runInternal() {
    67|         recordStore.unlock(dataKey, ownerUuid, threadId, getCallId());
    68|         Record record = recordStore.getRecordOrNull(dataKey, false);
    69|         if (record == null || version == record.getVersion()) {
    70|             EventService eventService = getNodeEngine().getEventService();
    71|             if (eventService.hasEventRegistration(MapService.SERVICE_NAME, getName())) {
    72|                 oldValue = record == null ? null : mapServiceContext.toData(record.getValue());
    73|             }
    74|             eventType = record == null ? EntryEventType.ADDED : EntryEventType.UPDATED;
    75|             recordStore.setTxn(dataKey, dataValue, ttl, UNSET, transactionId);
    76|             shouldBackup = true;
    77|         }
    78|     }
    79|     @Override
    80|     public long getVersion() {
    81|         return version;
    82|     }
    83|     @Override
    84|     public void setVersion(long version) {
    85|         this.version = version;
    86|     }
    87|     @Override
    88|     public void setOwnerUuid(UUID ownerUuid) {


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/query/impl/getters/AbstractJsonGetter.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 177-217 ---
   177|      *
   178|      * @param parser
   179|      * @param pathCursor
   180|      * @return {@code true} if given attribute name exists in the current object
   181|      * @throws IOException
   182|      */
   183|     private boolean findAttribute(JsonParser parser, JsonPathCursor pathCursor,
   184|                                   boolean multiValue) throws IOException {
   185|         JsonToken token = parser.getCurrentToken();
   186|         if (token != START_OBJECT) {
   187|             return false;
   188|         }
   189|         while (true) {
   190|             token = parser.nextToken();
   191|             if (token == JsonToken.END_OBJECT) {
   192|                 return false;
   193|             }
   194|             if (pathCursor.getCurrent().equals(parser.getCurrentName())) {
   195|                 parser.nextToken();
   196|                 return true;
   197|             } else if (!multiValue) {
   198|                 parser.skipChildren();
   199|             }
   200|         }
   201|     }
   202|     /**
   203|      * Traverses given array. If {@code pathCursor#getNext()} is
   204|      * {@code null}, this method adds all the scalar values in current
   205|      * array to the result. Otherwise, it traverses all objects in
   206|      * given array and adds their scalar values named
   207|      * {@code pathCursor#getNext()} to the result.
   208|      *
   209|      * Assumes the parser points to an array.
   210|      *
   211|      * @param parser
   212|      * @param pathCursor
   213|      * @return All matches in the current array that conform to
   214|      * [any].lastPath search
   215|      * @throws IOException
   216|      */
   217|     @SuppressWarnings("checkstyle:cyclomaticcomplexity")


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/security/permission/ActionConstants.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 18-58 ---
    18| import com.hazelcast.cardinality.impl.CardinalityEstimatorService;
    19| import com.hazelcast.collection.impl.list.ListService;
    20| import com.hazelcast.collection.impl.queue.QueueService;
    21| import com.hazelcast.collection.impl.set.SetService;
    22| import com.hazelcast.cp.internal.datastructures.atomiclong.AtomicLongService;
    23| import com.hazelcast.cp.internal.datastructures.atomicref.AtomicRefService;
    24| import com.hazelcast.cp.internal.datastructures.countdownlatch.CountDownLatchService;
    25| import com.hazelcast.cp.internal.datastructures.lock.LockService;
    26| import com.hazelcast.cp.internal.datastructures.semaphore.SemaphoreService;
    27| import com.hazelcast.durableexecutor.impl.DistributedDurableExecutorService;
    28| import com.hazelcast.executor.impl.DistributedExecutorService;
    29| import com.hazelcast.flakeidgen.impl.FlakeIdGeneratorService;
    30| import com.hazelcast.internal.crdt.pncounter.PNCounterService;
    31| import com.hazelcast.internal.locksupport.LockSupportService;
    32| import com.hazelcast.internal.usercodedeployment.UserCodeDeploymentService;
    33| import com.hazelcast.jet.impl.JetServiceBackend;
    34| import com.hazelcast.map.impl.MapService;
    35| import com.hazelcast.multimap.impl.MultiMapService;
    36| import com.hazelcast.replicatedmap.impl.ReplicatedMapService;
    37| import com.hazelcast.ringbuffer.impl.RingbufferService;
    38| import com.hazelcast.scheduledexecutor.impl.DistributedScheduledExecutorService;
    39| import com.hazelcast.sql.impl.SqlInternalService;
    40| import com.hazelcast.topic.impl.TopicService;
    41| import com.hazelcast.topic.impl.reliable.ReliableTopicService;
    42| import java.security.Permission;
    43| import java.util.HashMap;
    44| import java.util.Map;
    45| @SuppressWarnings({"checkstyle:executablestatementcount"})
    46| public final class ActionConstants {
    47|     public static final String ACTION_ALL = "all";
    48|     public static final String ACTION_CREATE = "create";
    49|     public static final String ACTION_DESTROY = "destroy";
    50|     public static final String ACTION_MODIFY = "modify";
    51|     public static final String ACTION_READ = "read";
    52|     public static final String ACTION_REMOVE = "remove";
    53|     public static final String ACTION_LOCK = "lock";
    54|     public static final String ACTION_LISTEN = "listen";
    55|     public static final String ACTION_RELEASE = "release";
    56|     public static final String ACTION_ACQUIRE = "acquire";
    57|     public static final String ACTION_PUT = "put";
    58|     public static final String ACTION_ADD = "add";

# --- HUNK 2: Lines 81-121 ---
    81|         PERMISSION_FACTORY_MAP.put(AtomicLongService.SERVICE_NAME, AtomicLongPermission::new);
    82|         PERMISSION_FACTORY_MAP.put(CountDownLatchService.SERVICE_NAME, CountDownLatchPermission::new);
    83|         PERMISSION_FACTORY_MAP.put(SemaphoreService.SERVICE_NAME, SemaphorePermission::new);
    84|         PERMISSION_FACTORY_MAP.put(TopicService.SERVICE_NAME, TopicPermission::new);
    85|         PERMISSION_FACTORY_MAP.put(LockSupportService.SERVICE_NAME, LockPermission::new);
    86|         PERMISSION_FACTORY_MAP.put(LockService.SERVICE_NAME, LockPermission::new);
    87|         PERMISSION_FACTORY_MAP.put(DistributedExecutorService.SERVICE_NAME, ExecutorServicePermission::new);
    88|         PERMISSION_FACTORY_MAP.put(FlakeIdGeneratorService.SERVICE_NAME, FlakeIdGeneratorPermission::new);
    89|         PERMISSION_FACTORY_MAP.put(ReplicatedMapService.SERVICE_NAME, ReplicatedMapPermission::new);
    90|         PERMISSION_FACTORY_MAP.put(AtomicRefService.SERVICE_NAME, AtomicReferencePermission::new);
    91|         PERMISSION_FACTORY_MAP.put(CacheService.SERVICE_NAME, CachePermission::new);
    92|         PERMISSION_FACTORY_MAP.put(RingbufferService.SERVICE_NAME, RingBufferPermission::new);
    93|         PERMISSION_FACTORY_MAP.put(DistributedDurableExecutorService.SERVICE_NAME, DurableExecutorServicePermission::new);
    94|         PERMISSION_FACTORY_MAP.put(CardinalityEstimatorService.SERVICE_NAME, CardinalityEstimatorPermission::new);
    95|         PERMISSION_FACTORY_MAP.put(UserCodeDeploymentService.SERVICE_NAME,
    96|                 (name, actions) -> new UserCodeDeploymentPermission(actions));
    97|         PERMISSION_FACTORY_MAP.put(PNCounterService.SERVICE_NAME, PNCounterPermission::new);
    98|         PERMISSION_FACTORY_MAP.put(ReliableTopicService.SERVICE_NAME, ReliableTopicPermission::new);
    99|         PERMISSION_FACTORY_MAP.put(JetServiceBackend.SERVICE_NAME, (name, actions) -> new JobPermission(actions));
   100|         PERMISSION_FACTORY_MAP.put(SqlInternalService.SERVICE_NAME, SqlPermission::new);
   101|         PERMISSION_FACTORY_MAP.put(DistributedScheduledExecutorService.SERVICE_NAME, ScheduledExecutorPermission::new);
   102|     }
   103|     private ActionConstants() {
   104|     }
   105|     private interface PermissionFactory {
   106|         Permission create(String name, String... actions);
   107|     }
   108|     /**
   109|      * Creates a permission
   110|      *
   111|      * @param name        the permission name
   112|      * @param serviceName the service name
   113|      * @param actions     the actions
   114|      * @return the created Permission
   115|      * @throws java.lang.IllegalArgumentException if there is no service found with the given serviceName.
   116|      */
   117|     public static Permission getPermission(String name, String serviceName, String... actions) {
   118|         PermissionFactory permissionFactory = PERMISSION_FACTORY_MAP.get(serviceName);
   119|         if (permissionFactory == null) {
   120|             throw new IllegalArgumentException("No permissions found for service: " + serviceName);
   121|         }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/security/permission/DurableExecutorServicePermission.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-43 ---
     1| /*
     2|  * Copyright (c) 2008-2021, Hazelcast, Inc. All Rights Reserved.
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.security.permission;
    17| public class DurableExecutorServicePermission extends InstancePermission {
    18|     private static final int READ = 4;
    19|     private static final int MODIFY = 8;
    20|     private static final int ALL = CREATE | DESTROY | READ | MODIFY;
    21|     public DurableExecutorServicePermission(String name, String... actions) {
    22|         super(name, actions);
    23|     }
    24|     @Override
    25|     protected int initMask(String[] actions) {
    26|         int mask = NONE;
    27|         for (String action : actions) {
    28|             if (ActionConstants.ACTION_ALL.equals(action)) {
    29|                 return ALL;
    30|             }
    31|             if (ActionConstants.ACTION_CREATE.equals(action)) {
    32|                 mask |= CREATE;
    33|             } else if (ActionConstants.ACTION_DESTROY.equals(action)) {
    34|                 mask |= DESTROY;
    35|             } else if (ActionConstants.ACTION_READ.equals(action)) {
    36|                 mask |= READ;
    37|             } else if (ActionConstants.ACTION_MODIFY.equals(action)) {
    38|                 mask |= MODIFY;
    39|             }
    40|         }
    41|         return mask;
    42|     }
    43| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/security/permission/ExecutorServicePermission.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-48 ---
     1| /*
     2|  * Copyright (c) 2008-2021, Hazelcast, Inc. All Rights Reserved.
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.security.permission;
    17| public class ExecutorServicePermission extends InstancePermission {
    18|     /**
    19|      * The name of the executor used when no such executor
    20|      * is found for the client invocations.
    21|      */
    22|     public static final String EMPTY_EXECUTOR_NAME = "<EMPTY>";
    23|     private static final int READ = 4;
    24|     private static final int MODIFY = 8;
    25|     private static final int ALL = CREATE | DESTROY | READ | MODIFY;
    26|     public ExecutorServicePermission(String name, String... actions) {
    27|         super(name, actions);
    28|     }
    29|     @Override
    30|     protected int initMask(String[] actions) {
    31|         int mask = NONE;
    32|         for (String action : actions) {
    33|             if (ActionConstants.ACTION_ALL.equals(action)) {
    34|                 return ALL;
    35|             }
    36|             if (ActionConstants.ACTION_CREATE.equals(action)) {
    37|                 mask |= CREATE;
    38|             } else if (ActionConstants.ACTION_DESTROY.equals(action)) {
    39|                 mask |= DESTROY;
    40|             } else if (ActionConstants.ACTION_READ.equals(action)) {
    41|                 mask |= READ;
    42|             } else if (ActionConstants.ACTION_MODIFY.equals(action)) {
    43|                 mask |= MODIFY;
    44|             }
    45|         }
    46|         return mask;
    47|     }
    48| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/spi/impl/AbstractInvocationFuture.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 707-750 ---
   707|             return (V) resolved;
   708|         }
   709|         Throwable cause = ((ExceptionalResult) resolved).cause;
   710|         if (cause instanceof CancellationException) {
   711|             throw (CancellationException) cause;
   712|         } else if (cause instanceof CompletionException) {
   713|             throw (CompletionException) cause;
   714|         }
   715|         throw new CompletionException(cause);
   716|     }
   717|     /**
   718|      * @param value the resolved state of this future
   719|      * @return an {@link ExceptionalResult} wrapping a {@link Throwable} in case value is resolved
   720|      * to an exception, or the normal completion value. Subclasses may choose to treat
   721|      * specific normal completion values in a special way (eg deserialize when the completion
   722|      * value is an instance of {@code Data}.
   723|      */
   724|     protected Object resolve(Object value) {
   725|         return value;
   726|     }
   727|     protected ExceptionalResult toExceptionalResult(Object object) {
   728|         assert object instanceof ExceptionalResult;
   729|         return (ExceptionalResult) object;
   730|     }
   731|     protected V resolveAndThrowWithJoinConvention(Object state) {
   732|         Object value = resolve(state);
   733|         return returnOrThrowWithJoinConventions(value);
   734|     }
   735|     protected <U> void unblockApply(@Nonnull final Function<? super V, ? extends U> function,
   736|                                     @Nonnull Executor executor,
   737|                                     @Nonnull InternalCompletableFuture<U> future) {
   738|         final Object value = resolve(state);
   739|         if (cascadeException(value, future)) {
   740|             return;
   741|         }
   742|         try {
   743|             executor.execute(() -> {
   744|                 try {
   745|                     U result = function.apply((V) value);
   746|                     future.complete(result);
   747|                 } catch (Throwable t) {
   748|                     future.completeExceptionally(t);
   749|                 }
   750|             });

# --- HUNK 2: Lines 1070-1111 ---
  1070|         return complete0(value);
  1071|     }
  1072|     public final boolean completeExceptionallyInternal(Object value) {
  1073|         return complete0(wrapThrowable(value));
  1074|     }
  1075|     private boolean complete0(Object value) {
  1076|         for (; ; ) {
  1077|             final Object oldState = state;
  1078|             if (isDone(oldState)) {
  1079|                 warnIfSuspiciousDoubleCompletion(oldState, value);
  1080|                 return false;
  1081|             }
  1082|             if (compareAndSetState(oldState, value)) {
  1083|                 onComplete();
  1084|                 unblockAll(oldState, defaultExecutor());
  1085|                 return true;
  1086|             }
  1087|         }
  1088|     }
  1089|     protected void onComplete() {
  1090|         if (isCompletedExceptionally()) {
  1091|             super.completeExceptionally(toExceptionalResult(state).getCause());
  1092|         } else {
  1093|             super.complete((V) state);
  1094|         }
  1095|     }
  1096|     private void warnIfSuspiciousDoubleCompletion(Object s0, Object s1) {
  1097|         if (s0 != s1 && !(isStateCancelled(s0)) && !(isStateCancelled(s1))) {
  1098|             logger.warning(String.format("Future.complete(Object) on completed future. "
  1099|                             + "Request: %s, current value: %s, offered value: %s",
  1100|                     invocationToString(), s0, s1), new Exception());
  1101|         }
  1102|     }
  1103|     @Override
  1104|     public String toString() {
  1105|         Object state = getState();
  1106|         if (isDone(state)) {
  1107|             return "InvocationFuture{invocation=" + invocationToString() + ", value=" + state + '}';
  1108|         } else {
  1109|             return "InvocationFuture{invocation=" + invocationToString() + ", done=false}";
  1110|         }
  1111|     }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/spi/impl/NodeEngine.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 178-222 ---
   178|      * Deserializes an object.
   179|      * <p>
   180|      * This method can safely be called on an object that is already deserialized. In that case, that instance
   181|      * is returned.
   182|      * <p>
   183|      * If this method is called with {@code null}, {@code null} is returned.
   184|      *
   185|      * @param object the object to deserialize
   186|      * @param klazz  The class to instantiate when deserializing the object
   187|      * @return the deserialized object
   188|      * @throws com.hazelcast.nio.serialization.HazelcastSerializationException when deserialization fails
   189|      */
   190|     <T> T toObject(Object object, Class klazz);
   191|     /**
   192|      * Indicates that node is not shutting down or it has not already shut down
   193|      *
   194|      * @return {@code true} if node is not shutting down or it has not already shut down, {@code false} otherwise
   195|      */
   196|     boolean isRunning();
   197|     /**
   198|      * @return      {@code true} if this {@code Node} has completed startup, {@code false} otherwise.
   199|      * @see         com.hazelcast.instance.impl.NodeExtension#isStartCompleted()
   200|      */
   201|     boolean isStartCompleted();
   202|     /**
   203|      * Returns the HazelcastInstance that this {@link NodeEngine} belongs to.
   204|      *
   205|      * @return the HazelcastInstance
   206|      */
   207|     HazelcastInstance getHazelcastInstance();
   208|     /**
   209|      * Gets the service with the given name.
   210|      *
   211|      * @param serviceName the name of the service
   212|      * @param <T>         the type of the service
   213|      * @return the found service, or HazelcastException in case of failure ({@code null} will never be returned)
   214|      */
   215|     <T> T getService(@Nonnull String serviceName);
   216|     /**
   217|      * Gets the service for the given serviceName if it exists or null otherwise.
   218|      *
   219|      * @param serviceName the name of the shared service to get
   220|      * @param <T>         the type of the service
   221|      * @return the found service, or null if the service was not found
   222|      * @throws NullPointerException if the serviceName is {@code null}


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/spi/impl/NodeEngineImpl.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 328-371 ---
   328|     public TransactionManagerService getTransactionManagerService() {
   329|         return transactionManagerService;
   330|     }
   331|     @Override
   332|     public Data toData(Object object) {
   333|         return serializationService.toData(object);
   334|     }
   335|     @Override
   336|     public <T> T toObject(Object object) {
   337|         return serializationService.toObject(object);
   338|     }
   339|     @Override
   340|     public <T> T toObject(Object object, Class klazz) {
   341|         return serializationService.toObject(object, klazz);
   342|     }
   343|     @Override
   344|     public boolean isRunning() {
   345|         return node.isRunning();
   346|     }
   347|     @Override
   348|     public boolean isStartCompleted() {
   349|         return node.getNodeExtension().isStartCompleted();
   350|     }
   351|     @Override
   352|     public HazelcastInstance getHazelcastInstance() {
   353|         return node.hazelcastInstance;
   354|     }
   355|     @Override
   356|     public ILogger getLogger(String name) {
   357|         return loggingService.getLogger(name);
   358|     }
   359|     @Override
   360|     public ILogger getLogger(Class clazz) {
   361|         return loggingService.getLogger(clazz);
   362|     }
   363|     @Override
   364|     public HazelcastProperties getProperties() {
   365|         return node.getProperties();
   366|     }
   367|     @Override
   368|     public <T> T getService(@Nonnull String serviceName) {
   369|         T service = serviceManager.getService(serviceName);
   370|         if (service == null) {
   371|             if (isRunning()) {


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/spi/impl/operationservice/Operation.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 1-50 ---
     1| /*
     2|  * Copyright (c) 2008-2021, Hazelcast, Inc. All Rights Reserved.
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.spi.impl.operationservice;
    17| import com.hazelcast.cluster.Address;
    18| import com.hazelcast.core.MemberLeftException;
    19| import com.hazelcast.internal.cluster.ClusterClock;
    20| import com.hazelcast.internal.partition.InternalPartition;
    21| import com.hazelcast.internal.server.ServerConnection;
    22| import com.hazelcast.internal.util.UUIDSerializationUtil;
    23| import com.hazelcast.logging.ILogger;
    24| import com.hazelcast.logging.Logger;
    25| import com.hazelcast.nio.ObjectDataInput;
    26| import com.hazelcast.nio.ObjectDataOutput;
    27| import com.hazelcast.nio.serialization.DataSerializable;
    28| import com.hazelcast.spi.exception.RetryableException;
    29| import com.hazelcast.spi.exception.SilentException;
    30| import com.hazelcast.spi.exception.WrongTargetException;
    31| import com.hazelcast.spi.impl.NodeEngine;
    32| import com.hazelcast.spi.properties.ClusterProperty;
    33| import com.hazelcast.spi.tenantcontrol.TenantControl;
    34| import com.hazelcast.spi.tenantcontrol.TenantControl.Closeable;
    35| import com.hazelcast.spi.tenantcontrol.Tenantable;
    36| import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;
    37| import java.io.IOException;
    38| import java.util.UUID;
    39| import java.util.concurrent.Callable;
    40| import java.util.concurrent.atomic.AtomicLongFieldUpdater;
    41| import java.util.logging.Level;
    42| import static com.hazelcast.internal.util.EmptyStatement.ignore;
    43| import static com.hazelcast.internal.util.StringUtil.timeToString;
    44| import static com.hazelcast.spi.impl.operationservice.CallStatus.RESPONSE;
    45| import static com.hazelcast.spi.impl.operationservice.CallStatus.VOID;
    46| import static com.hazelcast.spi.impl.operationservice.CallStatus.WAIT;
    47| import static com.hazelcast.spi.impl.operationservice.ExceptionAction.RETRY_INVOCATION;
    48| import static com.hazelcast.spi.impl.operationservice.ExceptionAction.THROW_EXCEPTION;
    49| /**
    50|  * An operation could be compared to a {@link Runnable}. It contains logic that

# --- HUNK 2: Lines 490-546 ---
   490|      * @see #getWaitTimeout() for more detail.
   491|      */
   492|     public final void setWaitTimeout(long timeout) {
   493|         this.waitTimeout = timeout;
   494|         setFlag(timeout != -1, BITMASK_WAIT_TIMEOUT_SET);
   495|     }
   496|     /**
   497|      * Called when an <code>Exception</code>/<code>Error</code> is thrown
   498|      * during an invocation. Invocation process will continue, it will retry
   499|      * or fail according to returned <code>ExceptionAction</code>.
   500|      * <p>
   501|      * This method is called on caller side of the invocation.
   502|      *
   503|      * @param throwable <code>Exception</code>/<code>Error</code> thrown during
   504|      *                  invocation
   505|      * @return <code>ExceptionAction</code>
   506|      */
   507|     public ExceptionAction onInvocationException(Throwable throwable) {
   508|         return throwable instanceof RetryableException ? RETRY_INVOCATION : THROW_EXCEPTION;
   509|     }
   510|     /**
   511|      * Called when an <code>Exception</code>/<code>Error</code> is thrown
   512|      * during an invocation on master member. Invocation process will continue,
   513|      * it will retry or fail according to returned <code>ExceptionAction</code>.
   514|      * <p>
   515|      * This method is called on caller side of the invocation.
   516|      *
   517|      * @param throwable <code>Exception</code>/<code>Error</code> thrown during
   518|      *                  invocation
   519|      * @return <code>ExceptionAction</code>
   520|      */
   521|     public ExceptionAction onMasterInvocationException(Throwable throwable) {
   522|         if (throwable instanceof WrongTargetException || throwable instanceof MemberLeftException) {
   523|             return RETRY_INVOCATION;
   524|         }
   525|         return onInvocationException(throwable);
   526|     }
   527|     public UUID getCallerUuid() {
   528|         return callerUuid;
   529|     }
   530|     public Operation setCallerUuid(UUID callerUuid) {
   531|         this.callerUuid = callerUuid;
   532|         setFlag(callerUuid != null, BITMASK_CALLER_UUID_SET);
   533|         return this;
   534|     }
   535|     protected final ILogger getLogger() {
   536|         final NodeEngine ne = nodeEngine;
   537|         return ne != null ? ne.getLogger(getClass()) : Logger.getLogger(getClass());
   538|     }
   539|     void setFlag(boolean value, int bitmask) {
   540|         if (value) {
   541|             flags |= bitmask;
   542|         } else {
   543|             flags &= ~bitmask;
   544|         }
   545|     }
   546|     boolean isFlagSet(int bitmask) {


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/spi/impl/operationservice/OperationService.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 93-136 ---
    93|      * {@link com.hazelcast.spi.impl.operationexecutor.OperationExecutor#executeOnPartitions(PartitionTaskFactory, BitSet)}
    94|      *
    95|      * @param taskFactory the PartitionTaskFactory used to create
    96|      *                    operations.
    97|      * @param partitions  the partitions to execute an operation on.
    98|      * @throws NullPointerException if taskFactory or partitions is null.
    99|      */
   100|     void executeOnPartitions(PartitionTaskFactory taskFactory, BitSet partitions);
   101|     <E> InvocationFuture<E> invokeOnPartition(String serviceName, Operation op, int partitionId);
   102|     <E> InvocationFuture<E> invokeOnPartitionAsync(String serviceName, Operation op, int partitionId);
   103|     <E> InvocationFuture<E> invokeOnPartitionAsync(String serviceName, Operation op, int partitionId, int replicaIndex);
   104|     /**
   105|      * Executes an operation on a partition.
   106|      *
   107|      * @param op  the operation
   108|      * @param <E> the return type of the operation response
   109|      * @return the future.
   110|      */
   111|     <E> InvocationFuture<E> invokeOnPartition(Operation op);
   112|     <E> InvocationFuture<E> invokeOnTarget(String serviceName, Operation op, Address target);
   113|     <E> InvocationFuture<E> invokeOnMaster(String serviceName, Operation op);
   114|     InvocationBuilder createInvocationBuilder(String serviceName, Operation op, int partitionId);
   115|     InvocationBuilder createInvocationBuilder(String serviceName, Operation op, Address target);
   116|     InvocationBuilder createMasterInvocationBuilder(String serviceName, Operation op);
   117|     /**
   118|      * Invokes a set of operations on each partition.
   119|      * <p>
   120|      * This method blocks until the operations complete.
   121|      * <p>
   122|      * If the operations have sync backups, this method will <b>not</b> wait for their completion.
   123|      * Instead, it will return once the operations are completed on primary replicas of the
   124|      * given {@code partitions}.
   125|      *
   126|      * @param serviceName      the name of the service.
   127|      * @param operationFactory the factory responsible for creating operations
   128|      * @return a Map with partitionId as a key and the outcome of the operation
   129|      * as a value.
   130|      * @throws Exception
   131|      */
   132|     Map<Integer, Object> invokeOnAllPartitions(String serviceName, OperationFactory operationFactory)
   133|             throws Exception;
   134|     /**
   135|      * Invokes a set of operations on selected set of all partitions in an async way.
   136|      * <p>


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/spi/impl/operationservice/impl/InvocationBuilderImpl.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-62 ---
     1| /*
     2|  * Copyright (c) 2008-2021, Hazelcast, Inc. All Rights Reserved.
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.spi.impl.operationservice.impl;
    17| import com.hazelcast.cluster.Address;
    18| import com.hazelcast.spi.impl.operationservice.InvocationBuilder;
    19| import com.hazelcast.spi.impl.operationservice.Operation;
    20| import com.hazelcast.spi.impl.operationservice.impl.Invocation.Context;
    21| /**
    22|  * An {@link InvocationBuilder} that is tied to the {@link OperationServiceImpl}.
    23|  */
    24| final class InvocationBuilderImpl extends InvocationBuilder {
    25|     private final Context context;
    26|     private final boolean executeOnMaster;
    27|     private InvocationBuilderImpl(Context context, String serviceName, Operation op,
    28|                                   int partitionId, Address target, boolean executeOnMaster) {
    29|         super(serviceName, op, partitionId, target);
    30|         this.context = context;
    31|         this.executeOnMaster = executeOnMaster;
    32|     }
    33|     static InvocationBuilderImpl createForPartition(Context context, String serviceName, Operation op, int partitionId) {
    34|         return new InvocationBuilderImpl(context, serviceName, op, partitionId, null, false);
    35|     }
    36|     static InvocationBuilderImpl createForTarget(Context context, String serviceName, Operation op, Address target) {
    37|         return new InvocationBuilderImpl(context, serviceName, op, Operation.GENERIC_PARTITION_ID, target, false);
    38|     }
    39|     static InvocationBuilderImpl createForMaster(Context context, String serviceName, Operation op) {
    40|         return new InvocationBuilderImpl(context, serviceName, op, Operation.GENERIC_PARTITION_ID, null, true);
    41|     }
    42|     @Override
    43|     public InvocationFuture invoke() {
    44|         op.setServiceName(serviceName);
    45|         Invocation invocation;
    46|         if (executeOnMaster) {
    47|             invocation = new MasterInvocation(
    48|                     context, op, doneCallback, tryCount, tryPauseMillis,
    49|                     callTimeout, resultDeserialized, connectionManager);
    50|         } else if (target == null) {
    51|             op.setPartitionId(partitionId).setReplicaIndex(replicaIndex);
    52|             invocation = new PartitionInvocation(
    53|                     context, op, doneCallback, tryCount, tryPauseMillis, callTimeout, resultDeserialized,
    54|                     failOnIndeterminateOperationState, connectionManager);
    55|         } else {
    56|             invocation = new TargetInvocation(
    57|                     context, op, target, doneCallback, tryCount, tryPauseMillis,
    58|                     callTimeout, resultDeserialized, connectionManager);
    59|         }
    60|         return invocation.invoke();
    61|     }
    62| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/spi/impl/operationservice/impl/InvocationFuture.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 94-168 ---
    94|         if (response instanceof WrappableException) {
    95|             response = ((WrappableException) response).wrap();
    96|         } else if (response instanceof RuntimeException || response instanceof Error) {
    97|             response = cloneExceptionWithFixedAsyncStackTrace((Throwable) response);
    98|         }
    99|         if (response instanceof CancellationException) {
   100|             throw (CancellationException) response;
   101|         } else if (response instanceof ExecutionException) {
   102|             throw (ExecutionException) response;
   103|         } else if (response instanceof InterruptedException) {
   104|             throw (InterruptedException) response;
   105|         } else {
   106|             throw new ExecutionException((Throwable) response);
   107|         }
   108|     }
   109|     @SuppressWarnings({"checkstyle:npathcomplexity", "checkstyle:cyclomaticcomplexity"})
   110|     @Override
   111|     protected Object resolve(Object unresolved) {
   112|         if (unresolved == null) {
   113|             return null;
   114|         } else if (unresolved == INTERRUPTED || unresolved == CALL_TIMEOUT || unresolved == HEARTBEAT_TIMEOUT) {
   115|             return toExceptionalResult(unresolved);
   116|         } else if (unresolved.getClass() == Packet.class) {
   117|             NormalResponse response = invocation.context.serializationService.toObject(unresolved);
   118|             unresolved = response.getValue();
   119|         }
   120|         Object value = unresolved;
   121|         if (deserialize && value instanceof Data) {
   122|             value = invocation.context.serializationService.toObject(value);
   123|             if (value == null) {
   124|                 return null;
   125|             }
   126|         }
   127|         Throwable cause = (value instanceof ExceptionalResult)
   128|                 ? ((ExceptionalResult) value).getCause()
   129|                 : null;
   130|         if (invocation.shouldFailOnIndeterminateOperationState()
   131|                 && (value instanceof IndeterminateOperationState
   132|                 || cause instanceof IndeterminateOperationState)) {
   133|             value = wrapThrowable(new IndeterminateOperationStateException("indeterminate operation state",
   134|                     cause == null ? (Throwable) value : cause));
   135|         }
   136|         return value;
   137|     }
   138|     @Override
   139|     protected ExceptionalResult toExceptionalResult(Object object) {
   140|         if (object == INTERRUPTED) {
   141|             return new ExceptionalResult(
   142|                     new InterruptedException(invocation.op.getClass().getSimpleName() + " was interrupted. " + invocation));
   143|         } else if (object == CALL_TIMEOUT) {
   144|             return new ExceptionalResult(newOperationTimeoutException(false));
   145|         } else if (object == HEARTBEAT_TIMEOUT) {
   146|             return new ExceptionalResult(newOperationTimeoutException(true));
   147|         }
   148|         return super.toExceptionalResult(object);
   149|     }
   150|     private OperationTimeoutException newOperationTimeoutException(boolean heartbeatTimeout) {
   151|         StringBuilder sb = new StringBuilder();
   152|         if (heartbeatTimeout) {
   153|             sb.append(invocation.op.getClass().getSimpleName())
   154|                     .append(" invocation failed to complete due to operation-heartbeat-timeout. ");
   155|             sb.append("Current time: ").append(timeToString(currentTimeMillis())).append(". ");
   156|             sb.append("Start time: ").append(timeToString(invocation.firstInvocationTimeMillis)).append(". ");
   157|             sb.append("Total elapsed time: ")
   158|                     .append(currentTimeMillis() - invocation.firstInvocationTimeMillis).append(" ms. ");
   159|             long lastHeartbeatMillis = invocation.lastHeartbeatMillis;
   160|             sb.append("Last operation heartbeat: ");
   161|             appendHeartbeat(sb, lastHeartbeatMillis);
   162|             long lastHeartbeatFromMemberMillis = invocation.context.invocationMonitor
   163|                     .getLastMemberHeartbeatMillis(invocation.getTargetAddress());
   164|             sb.append("Last operation heartbeat from member: ");
   165|             appendHeartbeat(sb, lastHeartbeatFromMemberMillis);
   166|         } else {
   167|             sb.append(invocation.op.getClass().getSimpleName())
   168|                     .append(" got rejected before execution due to not starting within the operation-call-timeout of: ")


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/spi/impl/operationservice/impl/InvocationRegistry.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 19-59 ---
    19| import com.hazelcast.core.MemberLeftException;
    20| import com.hazelcast.internal.diagnostics.InvocationProfilerPlugin;
    21| import com.hazelcast.internal.metrics.MetricsRegistry;
    22| import com.hazelcast.internal.metrics.Probe;
    23| import com.hazelcast.internal.metrics.StaticMetricsProvider;
    24| import com.hazelcast.internal.util.LatencyDistribution;
    25| import com.hazelcast.internal.util.RuntimeAvailableProcessors;
    26| import com.hazelcast.logging.ILogger;
    27| import com.hazelcast.spi.impl.operationservice.Operation;
    28| import com.hazelcast.spi.impl.operationservice.impl.operations.PartitionIteratingOperation;
    29| import com.hazelcast.spi.impl.sequence.CallIdSequence;
    30| import com.hazelcast.spi.properties.HazelcastProperties;
    31| import java.util.Iterator;
    32| import java.util.Map;
    33| import java.util.Set;
    34| import java.util.concurrent.ConcurrentHashMap;
    35| import java.util.concurrent.ConcurrentMap;
    36| import static com.hazelcast.internal.metrics.MetricDescriptorConstants.OPERATION_METRIC_INVOCATION_REGISTRY_INVOCATIONS_LAST_CALL_ID;
    37| import static com.hazelcast.internal.metrics.MetricDescriptorConstants.OPERATION_METRIC_INVOCATION_REGISTRY_INVOCATIONS_PENDING;
    38| import static com.hazelcast.internal.metrics.MetricDescriptorConstants.OPERATION_METRIC_INVOCATION_REGISTRY_INVOCATIONS_USED_PERCENTAGE;
    39| import static com.hazelcast.internal.metrics.MetricDescriptorConstants.OPERATION_PREFIX_INVOCATIONS;
    40| import static com.hazelcast.internal.metrics.ProbeLevel.MANDATORY;
    41| import static com.hazelcast.internal.metrics.ProbeUnit.PERCENT;
    42| import static com.hazelcast.spi.impl.operationservice.OperationAccessor.deactivate;
    43| import static com.hazelcast.spi.impl.operationservice.OperationAccessor.setCallId;
    44| /**
    45|  * Responsible for the registration of all pending invocations.
    46|  * <p>
    47|  * By using the InvocationRegistry, the Invocation and its response(s) can be linked to each other.
    48|  * <p>
    49|  * When an invocation is registered, a callId is determined. Based on this call ID, when a
    50|  * {@link com.hazelcast.spi.impl.operationservice.impl.responses.Response} comes in, the
    51|  * appropriate invocation can be looked up.
    52|  * <p>
    53|  * Some ideas:
    54|  * <ul>
    55|  * <li>Use a ringbuffer to store all invocations instead of a CHM. The call ID can be used as sequence ID for this
    56|  * ringbuffer. It can be that you run in slots that have not been released; if that happens, just keep increasing
    57|  * the sequence (although you now get sequence-gaps).</li>
    58|  * <li>Pre-allocate all invocations. Because the ringbuffer has a fixed capacity, pre-allocation should be easy. Also
    59|  * the PartitionInvocation and TargetInvocation can be folded into Invocation.</li>

# --- HUNK 2: Lines 67-107 ---
    67|     private static final float LOAD_FACTOR = 0.75f;
    68|     private static final double HUNDRED_PERCENT = 100d;
    69|     @Probe(name = OPERATION_METRIC_INVOCATION_REGISTRY_INVOCATIONS_PENDING, level = MANDATORY)
    70|     private final ConcurrentMap<Long, Invocation> invocations;
    71|     private final ILogger logger;
    72|     private final CallIdSequence callIdSequence;
    73|     private final boolean profilerEnabled;
    74|     private final ConcurrentMap<Class, LatencyDistribution> latencyDistributions = new ConcurrentHashMap<>();
    75|     private volatile boolean alive = true;
    76|     public InvocationRegistry(ILogger logger, CallIdSequence callIdSequence, HazelcastProperties properties) {
    77|         this.logger = logger;
    78|         this.callIdSequence = callIdSequence;
    79|         int coreSize = RuntimeAvailableProcessors.get();
    80|         boolean reallyMultiCore = coreSize >= CORE_SIZE_CHECK;
    81|         int concurrencyLevel = reallyMultiCore ? coreSize * CORE_SIZE_FACTOR : CONCURRENCY_LEVEL;
    82|         this.invocations = new ConcurrentHashMap<>(INITIAL_CAPACITY, LOAD_FACTOR, concurrencyLevel);
    83|         this.profilerEnabled = properties.getInteger(InvocationProfilerPlugin.PERIOD_SECONDS) > 0;
    84|     }
    85|     @Override
    86|     public void provideStaticMetrics(MetricsRegistry registry) {
    87|         registry.registerStaticMetrics(this, OPERATION_PREFIX_INVOCATIONS);
    88|     }
    89|     @Probe(name = OPERATION_METRIC_INVOCATION_REGISTRY_INVOCATIONS_USED_PERCENTAGE, unit = PERCENT)
    90|     private double invocationsUsedPercentage() {
    91|         int maxConcurrentInvocations = callIdSequence.getMaxConcurrentInvocations();
    92|         if (maxConcurrentInvocations == Integer.MAX_VALUE) {
    93|             return 0;
    94|         }
    95|         return (HUNDRED_PERCENT * invocations.size()) / maxConcurrentInvocations;
    96|     }
    97|     @Probe(name = OPERATION_METRIC_INVOCATION_REGISTRY_INVOCATIONS_LAST_CALL_ID)
    98|     long getLastCallId() {
    99|         return callIdSequence.getLastCallId();
   100|     }
   101|     /**
   102|      * Registers an invocation.
   103|      *
   104|      * @param invocation The invocation to register.
   105|      * @return {@code false} when InvocationRegistry is not alive and registration is not successful, {@code true} otherwise
   106|      */
   107|     public boolean register(Invocation invocation) {


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/spi/impl/operationservice/impl/MasterInvocation.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-65 ---
     1| /*
     2|  * Copyright (c) 2008-2021, Hazelcast, Inc. All Rights Reserved.
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.spi.impl.operationservice.impl;
    17| import com.hazelcast.cluster.Address;
    18| import com.hazelcast.cluster.Member;
    19| import com.hazelcast.internal.server.ServerConnectionManager;
    20| import com.hazelcast.spi.impl.operationservice.ExceptionAction;
    21| import com.hazelcast.spi.impl.operationservice.Operation;
    22| /**
    23|  * An {@link Invocation} evaluates an Operation Invocation for a master member running on top of the
    24|  * {@link OperationServiceImpl}.
    25|  */
    26| final class MasterInvocation extends Invocation<Address> {
    27|     MasterInvocation(
    28|             Context context,
    29|             Operation op,
    30|             Runnable doneCallback,
    31|             int tryCount,
    32|             long tryPauseMillis,
    33|             long callTimeoutMillis,
    34|             boolean deserialize,
    35|             ServerConnectionManager connectionManager
    36|     ) {
    37|         super(context, op, doneCallback, tryCount, tryPauseMillis, callTimeoutMillis, deserialize, connectionManager);
    38|     }
    39|     MasterInvocation(
    40|             Context context,
    41|             Operation op,
    42|             int tryCount,
    43|             long tryPauseMillis,
    44|             long callTimeoutMillis,
    45|             boolean deserialize
    46|     ) {
    47|         this(context, op, null, tryCount, tryPauseMillis, callTimeoutMillis, deserialize, null);
    48|     }
    49|     @Override
    50|     Address getInvocationTarget() {
    51|         return context.clusterService.getMasterAddress();
    52|     }
    53|     @Override
    54|     Address toTargetAddress(Address target) {
    55|         return target;
    56|     }
    57|     @Override
    58|     Member toTargetMember(Address target) {
    59|         return context.clusterService.getMember(target);
    60|     }
    61|     @Override
    62|     ExceptionAction onException(Throwable t) {
    63|         return op.onMasterInvocationException(t);
    64|     }
    65| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/spi/impl/operationservice/impl/OperationServiceImpl.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 225-279 ---
   225|         return inboundResponseHandlerSupplier.responseQueueSize();
   226|     }
   227|     @Override
   228|     public void populate(LiveOperations liveOperations) {
   229|         operationExecutor.populate(liveOperations);
   230|         for (Operation op : asyncOperations) {
   231|             liveOperations.add(op.getCallerAddress(), op.getCallId());
   232|         }
   233|     }
   234|     @Override
   235|     public void execute(PartitionSpecificRunnable task) {
   236|         operationExecutor.execute(task);
   237|     }
   238|     @Override
   239|     public void executeOnPartitions(PartitionTaskFactory taskFactory, BitSet partitions) {
   240|         operationExecutor.executeOnPartitions(taskFactory, partitions);
   241|     }
   242|     @Override
   243|     public InvocationBuilder createInvocationBuilder(String serviceName, Operation op, int partitionId) {
   244|         checkNotNegative(partitionId, "Partition ID cannot be negative!");
   245|         return InvocationBuilderImpl.createForPartition(invocationContext, serviceName, op, partitionId)
   246|                 .setTryCount(invocationMaxRetryCount)
   247|                 .setTryPauseMillis(invocationRetryPauseMillis)
   248|                 .setFailOnIndeterminateOperationState(failOnIndeterminateOperationState);
   249|     }
   250|     @Override
   251|     public InvocationBuilder createInvocationBuilder(String serviceName, Operation op, Address target) {
   252|         checkNotNull(target, "Target cannot be null!");
   253|         return InvocationBuilderImpl.createForTarget(invocationContext, serviceName, op, target)
   254|                 .setTryCount(invocationMaxRetryCount)
   255|                 .setTryPauseMillis(invocationRetryPauseMillis);
   256|     }
   257|     @Override
   258|     public InvocationBuilder createMasterInvocationBuilder(String serviceName, Operation op) {
   259|         return InvocationBuilderImpl.createForMaster(invocationContext, serviceName, op)
   260|                 .setTryCount(invocationMaxRetryCount)
   261|                 .setTryPauseMillis(invocationRetryPauseMillis);
   262|     }
   263|     @Override
   264|     public void run(Operation op) {
   265|         operationExecutor.run(op);
   266|     }
   267|     @Override
   268|     public void execute(Operation op) {
   269|         operationExecutor.execute(op);
   270|     }
   271|     @Override
   272|     public boolean isRunAllowed(Operation op) {
   273|         return operationExecutor.isRunAllowed(op);
   274|     }
   275|     @Override
   276|     @SuppressWarnings("unchecked")
   277|     public <E> InvocationFuture<E> invokeOnPartition(String serviceName, Operation op, int partitionId) {
   278|         op.setServiceName(serviceName)
   279|                 .setPartitionId(partitionId)

# --- HUNK 2: Lines 293-338 ---
   293|         op.setServiceName(serviceName)
   294|                 .setPartitionId(partitionId)
   295|                 .setReplicaIndex(replicaIndex);
   296|         return new PartitionInvocation(
   297|                 invocationContext, op, invocationMaxRetryCount, invocationRetryPauseMillis,
   298|                 DEFAULT_CALL_TIMEOUT, DEFAULT_DESERIALIZE_RESULT, failOnIndeterminateOperationState).invokeAsync();
   299|     }
   300|     @Override
   301|     @SuppressWarnings("unchecked")
   302|     public <E> InvocationFuture<E> invokeOnPartition(Operation op) {
   303|         return new PartitionInvocation(
   304|                 invocationContext, op, invocationMaxRetryCount, invocationRetryPauseMillis,
   305|                 DEFAULT_CALL_TIMEOUT, DEFAULT_DESERIALIZE_RESULT, failOnIndeterminateOperationState).invoke();
   306|     }
   307|     @Override
   308|     @SuppressWarnings("unchecked")
   309|     public <E> InvocationFuture<E> invokeOnTarget(String serviceName, Operation op, Address target) {
   310|         op.setServiceName(serviceName);
   311|         return new TargetInvocation(invocationContext, op, target, invocationMaxRetryCount, invocationRetryPauseMillis,
   312|                 DEFAULT_CALL_TIMEOUT, DEFAULT_DESERIALIZE_RESULT).invoke();
   313|     }
   314|     @Override
   315|     public <E> InvocationFuture<E> invokeOnMaster(String serviceName, Operation op) {
   316|         op.setServiceName(serviceName);
   317|         return new MasterInvocation(invocationContext, op, invocationMaxRetryCount,
   318|                 invocationRetryPauseMillis, DEFAULT_CALL_TIMEOUT, DEFAULT_DESERIALIZE_RESULT).invoke();
   319|     }
   320|     @Override
   321|     public void onStartAsyncOperation(Operation op) {
   322|         asyncOperations.add(op);
   323|     }
   324|     @Override
   325|     public void onCompletionAsyncOperation(Operation op) {
   326|         asyncOperations.remove(op);
   327|     }
   328|     @Override
   329|     public boolean isCallTimedOut(Operation op) {
   330|         if (isJoinOperation(op) || isWanReplicationOperation(op)) {
   331|             return false;
   332|         }
   333|         long callTimeout = op.getCallTimeout();
   334|         long invocationTime = op.getInvocationTime();
   335|         long expireTime = invocationTime + callTimeout;
   336|         if (expireTime <= 0 || expireTime == Long.MAX_VALUE) {
   337|             return false;
   338|         }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/spi/impl/operationservice/impl/PartitionInvocation.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-51 ---
     1| /*
     2|  * Copyright (c) 2008-2021, Hazelcast, Inc. All Rights Reserved.
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.spi.impl.operationservice.impl;
    17| import com.hazelcast.cluster.Address;
    18| import com.hazelcast.cluster.ClusterState;
    19| import com.hazelcast.cluster.Member;
    20| import com.hazelcast.core.MemberLeftException;
    21| import com.hazelcast.internal.partition.InternalPartition;
    22| import com.hazelcast.internal.partition.PartitionReplica;
    23| import com.hazelcast.internal.server.ServerConnectionManager;
    24| import com.hazelcast.partition.NoDataMemberInClusterException;
    25| import com.hazelcast.spi.impl.operationservice.ExceptionAction;
    26| import com.hazelcast.spi.impl.operationservice.Operation;
    27| import com.hazelcast.spi.impl.operationservice.ReadonlyOperation;
    28| import static com.hazelcast.cluster.memberselector.MemberSelectors.DATA_MEMBER_SELECTOR;
    29| import static com.hazelcast.spi.impl.operationservice.ExceptionAction.THROW_EXCEPTION;
    30| /**
    31|  * An {@link Invocation} evaluates an Operation Invocation for a particular partition running on top of the
    32|  * {@link OperationServiceImpl}.
    33|  */
    34| final class PartitionInvocation extends Invocation<PartitionReplica> {
    35|     private final boolean failOnIndeterminateOperationState;
    36|     PartitionInvocation(Context context,
    37|                         Operation op,
    38|                         Runnable doneCallback,
    39|                         int tryCount,
    40|                         long tryPauseMillis,
    41|                         long callTimeoutMillis,
    42|                         boolean deserialize,
    43|                         boolean failOnIndeterminateOperationState,
    44|                         ServerConnectionManager connectionManager) {
    45|         super(context, op, doneCallback, tryCount, tryPauseMillis, callTimeoutMillis, deserialize, connectionManager);
    46|         this.failOnIndeterminateOperationState = failOnIndeterminateOperationState && !(op instanceof ReadonlyOperation);
    47|     }
    48|     PartitionInvocation(Context context,
    49|                         Operation op,
    50|                         int tryCount,
    51|                         long tryPauseMillis,


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/spi/impl/operationservice/impl/TargetInvocation.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-45 ---
     1| /*
     2|  * Copyright (c) 2008-2021, Hazelcast, Inc. All Rights Reserved.
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.spi.impl.operationservice.impl;
    17| import com.hazelcast.cluster.Address;
    18| import com.hazelcast.cluster.Member;
    19| import com.hazelcast.core.MemberLeftException;
    20| import com.hazelcast.internal.server.ServerConnectionManager;
    21| import com.hazelcast.spi.impl.operationservice.ExceptionAction;
    22| import com.hazelcast.spi.impl.operationservice.Operation;
    23| import static com.hazelcast.spi.impl.operationservice.ExceptionAction.THROW_EXCEPTION;
    24| /**
    25|  * An {@link Invocation} evaluates an Operation Invocation for a particular target running on top of the
    26|  * {@link OperationServiceImpl}.
    27|  */
    28| final class TargetInvocation extends Invocation<Address> {
    29|     private final Address target;
    30|     TargetInvocation(Context context,
    31|                      Operation op,
    32|                      Address target,
    33|                      Runnable doneCallback,
    34|                      int tryCount,
    35|                      long tryPauseMillis,
    36|                      long callTimeoutMillis,
    37|                      boolean deserialize,
    38|                      ServerConnectionManager connectionManager) {
    39|         super(context, op, doneCallback, tryCount, tryPauseMillis, callTimeoutMillis, deserialize, connectionManager);
    40|         this.target = target;
    41|     }
    42|     TargetInvocation(Context context,
    43|                      Operation op,
    44|                      Address target,
    45|                      int tryCount,


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/spi/utils/RestClient.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 89-131 ---
    89|         this.retries = retries;
    90|         return this;
    91|     }
    92|     public RestClient withCaCertificates(String caCertificate) {
    93|         this.caCertificate = caCertificate;
    94|         return this;
    95|     }
    96|     public RestClient expectResponseCodes(Integer... codes) {
    97|         if (expectedResponseCodes == null) {
    98|             expectedResponseCodes = new HashSet<>();
    99|         }
   100|         expectedResponseCodes.addAll(Arrays.asList(codes));
   101|         return this;
   102|     }
   103|     public Response get() {
   104|         return callWithRetries("GET");
   105|     }
   106|     public Response post() {
   107|         return callWithRetries("POST");
   108|     }
   109|     public Response put() {
   110|         return callWithRetries("PUT");
   111|     }
   112|     private Response callWithRetries(String method) {
   113|         return RetryUtils.retry(() -> call(method), retries);
   114|     }
   115|     private Response call(String method) {
   116|         HttpURLConnection connection = null;
   117|         try {
   118|             URL urlToConnect = new URL(url);
   119|             connection = (HttpURLConnection) urlToConnect.openConnection();
   120|             if (connection instanceof HttpsURLConnection && caCertificate != null) {
   121|                 ((HttpsURLConnection) connection).setSSLSocketFactory(buildSslSocketFactory());
   122|             }
   123|             connection.setReadTimeout((int) TimeUnit.SECONDS.toMillis(readTimeoutSeconds));
   124|             connection.setConnectTimeout((int) TimeUnit.SECONDS.toMillis(connectTimeoutSeconds));
   125|             connection.setRequestMethod(method);
   126|             for (Parameter header : headers) {
   127|                 connection.setRequestProperty(header.getKey(), header.getValue());
   128|             }
   129|             if (body != null) {
   130|                 byte[] bodyData = body.getBytes(StandardCharsets.UTF_8);
   131|                 connection.setDoOutput(true);

# --- HUNK 2: Lines 163-203 ---
   163|     }
   164|     private boolean isExpectedResponseCode(int responseCode) {
   165|         return expectedResponseCodes == null
   166|                 ? responseCode == HTTP_OK
   167|                 : expectedResponseCodes.contains(responseCode);
   168|     }
   169|     /**
   170|      * Builds SSL Socket Factory with the public CA Certificate from Kubernetes Master.
   171|      */
   172|     private SSLSocketFactory buildSslSocketFactory() {
   173|         try {
   174|             KeyStore keyStore = KeyStore.getInstance(KeyStore.getDefaultType());
   175|             keyStore.load(null, null);
   176|             int i = 0;
   177|             for (Certificate certificate : generateCertificates()) {
   178|                 String alias = String.format("ca-%d", i++);
   179|                 keyStore.setCertificateEntry(alias, certificate);
   180|             }
   181|             TrustManagerFactory tmf = TrustManagerFactory.getInstance(TrustManagerFactory.getDefaultAlgorithm());
   182|             tmf.init(keyStore);
   183|             SSLContext context = SSLContext.getInstance("TLS");
   184|             context.init(null, tmf.getTrustManagers(), null);
   185|             return context.getSocketFactory();
   186|         } catch (Exception e) {
   187|             throw new RestClientException("Failure in generating SSLSocketFactory", e);
   188|         }
   189|     }
   190|     /**
   191|      * Generates CA Certificate from the default CA Cert file or from the externally provided "ca-certificate" property.
   192|      */
   193|     private Collection<? extends Certificate> generateCertificates()
   194|             throws CertificateException {
   195|         InputStream caInput = null;
   196|         try {
   197|             CertificateFactory cf = CertificateFactory.getInstance("X.509");
   198|             caInput = new ByteArrayInputStream(caCertificate.getBytes(StandardCharsets.UTF_8));
   199|             return cf.generateCertificates(caInput);
   200|         } finally {
   201|             IOUtil.closeResource(caInput);
   202|         }
   203|     }

