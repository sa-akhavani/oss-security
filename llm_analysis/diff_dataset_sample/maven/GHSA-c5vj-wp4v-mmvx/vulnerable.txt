# ====================================================================
# FILE: hazelcast-spring/src/main/java/com/hazelcast/spring/transaction/HazelcastTransactionManager.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 1-48 ---
     1| /*
     2|  * Copyright (c) 2008-2021, Hazelcast, Inc. All Rights Reserved.
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.spring.transaction;
    17| import com.hazelcast.core.HazelcastInstance;
    18| import com.hazelcast.transaction.TransactionContext;
    19| import org.springframework.transaction.CannotCreateTransactionException;
    20| import org.springframework.transaction.NoTransactionException;
    21| import org.springframework.transaction.TransactionDefinition;
    22| import org.springframework.transaction.TransactionException;
    23| import org.springframework.transaction.TransactionSystemException;
    24| import org.springframework.transaction.support.AbstractPlatformTransactionManager;
    25| import org.springframework.transaction.support.DefaultTransactionStatus;
    26| import org.springframework.transaction.support.ResourceTransactionManager;
    27| import org.springframework.transaction.support.SmartTransactionObject;
    28| import org.springframework.transaction.support.TransactionSynchronizationManager;
    29| /**
    30|  * {@link org.springframework.transaction.PlatformTransactionManager} implementation
    31|  * for a single {@link HazelcastInstance}. Binds a Hazelcast {@link TransactionContext}
    32|  * from the instance to the thread (as it is already bounded by Hazelcast itself) and makes it available for access.
    33|  * <p>
    34|  * <i>Note:</i> This transaction manager doesn't supports nested transactions, since Hazelcast doesn't support them either.
    35|  *
    36|  * @author Balint Krivan
    37|  * @see #getTransactionContext(HazelcastInstance)
    38|  * @see #getTransactionContext()
    39|  */
    40| public class HazelcastTransactionManager extends AbstractPlatformTransactionManager implements ResourceTransactionManager {
    41|     private HazelcastInstance hazelcastInstance;
    42|     public HazelcastTransactionManager(HazelcastInstance hazelcastInstance) {
    43|         this.hazelcastInstance = hazelcastInstance;
    44|     }
    45|     /**
    46|      * Returns the transaction context for the given Hazelcast instance bounded to the current thread.
    47|      *
    48|      * @throws NoTransactionException if the transaction context cannot be found

# --- HUNK 2: Lines 72-125 ---
    72|         HazelcastTransactionObject txObject = new HazelcastTransactionObject();
    73|         TransactionContextHolder transactionContextHolder =
    74|                 (TransactionContextHolder) TransactionSynchronizationManager.getResource(hazelcastInstance);
    75|         if (transactionContextHolder != null) {
    76|             if (logger.isDebugEnabled()) {
    77|                 logger.debug("Found thread-bound TransactionContext [" + transactionContextHolder.getContext() + "]");
    78|             }
    79|             txObject.setTransactionContextHolder(transactionContextHolder, false);
    80|         }
    81|         return txObject;
    82|     }
    83|     @Override
    84|     protected boolean isExistingTransaction(Object transaction) throws TransactionException {
    85|         return ((HazelcastTransactionObject) transaction).hasTransaction();
    86|     }
    87|     @Override
    88|     protected void doBegin(Object transaction, TransactionDefinition definition) throws TransactionException {
    89|         HazelcastTransactionObject txObject = (HazelcastTransactionObject) transaction;
    90|         try {
    91|             if (txObject.getTransactionContextHolder() == null) {
    92|                 TransactionContext transactionContext = hazelcastInstance.newTransactionContext();
    93|                 if (logger.isDebugEnabled()) {
    94|                     logger.debug("Opened new TransactionContext [" + transactionContext + "]");
    95|                 }
    96|                 txObject.setTransactionContextHolder(new TransactionContextHolder(transactionContext), true);
    97|             }
    98|             txObject.getTransactionContextHolder().beginTransaction();
    99|             if (txObject.isNewTransactionContextHolder()) {
   100|                 TransactionSynchronizationManager.bindResource(hazelcastInstance, txObject.getTransactionContextHolder());
   101|             }
   102|         } catch (Throwable ex) {
   103|             closeTransactionContextAfterFailedBegin(txObject);
   104|             throw new CannotCreateTransactionException("Could not begin Hazelcast transaction", ex);
   105|         }
   106|     }
   107|     private void closeTransactionContextAfterFailedBegin(HazelcastTransactionObject txObject) {
   108|         if (txObject.isNewTransactionContextHolder()) {
   109|             TransactionContext context = txObject.getTransactionContextHolder().getContext();
   110|             try {
   111|                 context.rollbackTransaction();
   112|             } catch (Throwable ex) {
   113|                 logger.debug("Could not rollback Hazelcast transaction after failed transaction begin", ex);
   114|             }
   115|             txObject.setTransactionContextHolder(null, false);
   116|         }
   117|     }
   118|     @Override
   119|     protected void doCommit(DefaultTransactionStatus status) throws TransactionException {
   120|         HazelcastTransactionObject txObject = (HazelcastTransactionObject) status.getTransaction();
   121|         if (status.isDebug()) {
   122|             logger.debug("Committing Hazelcast transaction on TransactionContext ["
   123|                     + txObject.getTransactionContextHolder().getContext() + "]");
   124|         }
   125|         try {


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/aws/AwsMetadataApi.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 2-146 ---
     2|  * Copyright (c) 2008-2021, Hazelcast, Inc. All Rights Reserved.
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.aws;
    17| import com.hazelcast.internal.json.Json;
    18| import com.hazelcast.internal.json.JsonObject;
    19| import com.hazelcast.logging.ILogger;
    20| import com.hazelcast.logging.Logger;
    21| import com.hazelcast.spi.utils.RestClient;
    22| import java.util.Optional;
    23| import static com.hazelcast.aws.AwsRequestUtils.createRestClient;
    24| import static com.hazelcast.spi.utils.RestClient.HTTP_NOT_FOUND;
    25| import static com.hazelcast.spi.utils.RestClient.HTTP_OK;
    26| /**
    27|  * Responsible for connecting to AWS EC2 and ECS Metadata API.
    28|  *
    29|  * @see <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html">EC2 Instance Metatadata</a>
    30|  * @see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html">ECS Task IAM Role Metadata</a>
    31|  * @see <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-metadata-endpoint.html">ECS Task Metadata</a>
    32|  */
    33| class AwsMetadataApi {
    34|     private static final ILogger LOGGER = Logger.getLogger(AwsMetadataApi.class);
    35|     private static final String EC2_METADATA_ENDPOINT = "http://169.254.169.254/latest/meta-data";
    36|     private static final String ECS_IAM_ROLE_METADATA_ENDPOINT = "http://169.254.170.2" + System.getenv(
    37|         "AWS_CONTAINER_CREDENTIALS_RELATIVE_URI");
    38|     private static final String ECS_TASK_METADATA_ENDPOINT = System.getenv("ECS_CONTAINER_METADATA_URI");
    39|     private static final String SECURITY_CREDENTIALS_URI = "/iam/security-credentials/";
    40|     private final String ec2MetadataEndpoint;
    41|     private final String ecsIamRoleEndpoint;
    42|     private final String ecsTaskMetadataEndpoint;
    43|     private final AwsConfig awsConfig;
    44|     AwsMetadataApi(AwsConfig awsConfig) {
    45|         this.ec2MetadataEndpoint = EC2_METADATA_ENDPOINT;
    46|         this.ecsIamRoleEndpoint = ECS_IAM_ROLE_METADATA_ENDPOINT;
    47|         this.ecsTaskMetadataEndpoint = ECS_TASK_METADATA_ENDPOINT;
    48|         this.awsConfig = awsConfig;
    49|     }
    50|     /**
    51|      * For test purposes only.
    52|      */
    53|     AwsMetadataApi(String ec2MetadataEndpoint, String ecsIamRoleEndpoint, String ecsTaskMetadataEndpoint,
    54|                    AwsConfig awsConfig) {
    55|         this.ec2MetadataEndpoint = ec2MetadataEndpoint;
    56|         this.ecsIamRoleEndpoint = ecsIamRoleEndpoint;
    57|         this.ecsTaskMetadataEndpoint = ecsTaskMetadataEndpoint;
    58|         this.awsConfig = awsConfig;
    59|     }
    60|     String availabilityZoneEc2() {
    61|         String uri = ec2MetadataEndpoint.concat("/placement/availability-zone/");
    62|         return createRestClient(uri, awsConfig).get().getBody();
    63|     }
    64|     Optional<String> placementGroupEc2() {
    65|         return getOptionalMetadata(ec2MetadataEndpoint.concat("/placement/group-name/"), "placement group");
    66|     }
    67|     Optional<String> placementPartitionNumberEc2() {
    68|         return getOptionalMetadata(ec2MetadataEndpoint.concat("/placement/partition-number/"), "partition number");
    69|     }
    70|     /**
    71|      * Resolves an optional metadata that exists for some instances only.
    72|      * HTTP_OK and HTTP_NOT_FOUND responses are assumed valid. Any other
    73|      * response code or an exception thrown during retries will yield
    74|      * a warning log and an empty result will be returned.
    75|      *
    76|      * @param uri  Metadata URI
    77|      * @param loggedName  Metadata name to be used when logging.
    78|      * @return  The metadata if the endpoint exists, empty otherwise.
    79|      */
    80|     private Optional<String> getOptionalMetadata(String uri, String loggedName) {
    81|         RestClient.Response response;
    82|         try {
    83|             response = createRestClient(uri, awsConfig)
    84|                     .expectResponseCodes(HTTP_OK, HTTP_NOT_FOUND)
    85|                     .get();
    86|         } catch (Exception e) {
    87|             LOGGER.warning(String.format("Could not resolve the %s metadata", loggedName));
    88|             return Optional.empty();
    89|         }
    90|         int responseCode = response.getCode();
    91|         if (responseCode == HTTP_OK) {
    92|             return Optional.of(response.getBody());
    93|         } else if (responseCode == HTTP_NOT_FOUND) {
    94|             LOGGER.fine(String.format("No %s information is found.", loggedName));
    95|             return Optional.empty();
    96|         } else {
    97|             throw new RuntimeException(String.format("Unexpected response code: %d", responseCode));
    98|         }
    99|     }
   100|     String defaultIamRoleEc2() {
   101|         String uri = ec2MetadataEndpoint.concat(SECURITY_CREDENTIALS_URI);
   102|         return createRestClient(uri, awsConfig).get().getBody();
   103|     }
   104|     AwsCredentials credentialsEc2(String iamRole) {
   105|         String uri = ec2MetadataEndpoint.concat(SECURITY_CREDENTIALS_URI).concat(iamRole);
   106|         String response = createRestClient(uri, awsConfig).get().getBody();
   107|         return parseCredentials(response);
   108|     }
   109|     AwsCredentials credentialsEcs() {
   110|         String response = createRestClient(ecsIamRoleEndpoint, awsConfig).get().getBody();
   111|         return parseCredentials(response);
   112|     }
   113|     private static AwsCredentials parseCredentials(String response) {
   114|         JsonObject role = Json.parse(response).asObject();
   115|         return AwsCredentials.builder()
   116|             .setAccessKey(role.getString("AccessKeyId", null))
   117|             .setSecretKey(role.getString("SecretAccessKey", null))
   118|             .setToken(role.getString("Token", null))
   119|             .build();
   120|     }
   121|     EcsMetadata metadataEcs() {
   122|         String response = createRestClient(ecsTaskMetadataEndpoint, awsConfig).get().getBody();
   123|         return parseEcsMetadata(response);
   124|     }
   125|     private EcsMetadata parseEcsMetadata(String response) {
   126|         JsonObject metadata = Json.parse(response).asObject();
   127|         JsonObject labels = metadata.get("Labels").asObject();
   128|         String taskArn = labels.get("com.amazonaws.ecs.task-arn").asString();
   129|         String clusterArn = labels.get("com.amazonaws.ecs.cluster").asString();
   130|         return new EcsMetadata(taskArn, clusterArn);
   131|     }
   132|     static class EcsMetadata {
   133|         private final String taskArn;
   134|         private final String clusterArn;
   135|         EcsMetadata(String taskArn, String clusterArn) {
   136|             this.taskArn = taskArn;
   137|             this.clusterArn = clusterArn;
   138|         }
   139|         String getTaskArn() {
   140|             return taskArn;
   141|         }
   142|         String getClusterArn() {
   143|             return clusterArn;
   144|         }
   145|     }
   146| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/dynamicconfig/AddCacheConfigMessageTask.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 9-97 ---
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.dynamicconfig;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.DynamicConfigAddCacheConfigCodec;
    19| import com.hazelcast.config.CachePartitionLostListenerConfig;
    20| import com.hazelcast.config.CacheSimpleConfig;
    21| import com.hazelcast.config.CacheSimpleConfig.ExpiryPolicyFactoryConfig;
    22| import com.hazelcast.config.InMemoryFormat;
    23| import com.hazelcast.instance.impl.Node;
    24| import com.hazelcast.internal.dynamicconfig.DynamicConfigurationAwareConfig;
    25| import com.hazelcast.internal.nio.Connection;
    26| import com.hazelcast.nio.serialization.IdentifiedDataSerializable;
    27| import java.util.ArrayList;
    28| import java.util.List;
    29| public class AddCacheConfigMessageTask
    30|         extends AbstractAddConfigMessageTask<DynamicConfigAddCacheConfigCodec.RequestParameters> {
    31|     public AddCacheConfigMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    32|         super(clientMessage, node, connection);
    33|     }
    34|     @Override
    35|     protected DynamicConfigAddCacheConfigCodec.RequestParameters decodeClientMessage(ClientMessage clientMessage) {
    36|         return DynamicConfigAddCacheConfigCodec.decodeRequest(clientMessage);
    37|     }
    38|     @Override
    39|     protected ClientMessage encodeResponse(Object response) {
    40|         return DynamicConfigAddCacheConfigCodec.encodeResponse();
    41|     }
    42|     @Override
    43|     protected IdentifiedDataSerializable getConfig() {
    44|         CacheSimpleConfig config = new CacheSimpleConfig();
    45|         config.setAsyncBackupCount(parameters.asyncBackupCount);
    46|         config.setBackupCount(parameters.backupCount);
    47|         config.setCacheEntryListeners(parameters.cacheEntryListeners);
    48|         config.setCacheLoader(parameters.cacheLoader);
    49|         config.setCacheLoaderFactory(parameters.cacheLoaderFactory);
    50|         config.setCacheWriter(parameters.cacheWriter);
    51|         config.setCacheWriterFactory(parameters.cacheWriterFactory);
    52|         config.setDisablePerEntryInvalidationEvents(parameters.disablePerEntryInvalidationEvents);
    53|         config.setEvictionConfig(parameters.evictionConfig.asEvictionConfg(serializationService));
    54|         if (parameters.expiryPolicyFactoryClassName != null) {
    55|             config.setExpiryPolicyFactory(parameters.expiryPolicyFactoryClassName);
    56|         } else if (parameters.timedExpiryPolicyFactoryConfig != null) {
    57|             ExpiryPolicyFactoryConfig expiryPolicyFactoryConfig =
    58|                     new ExpiryPolicyFactoryConfig(parameters.timedExpiryPolicyFactoryConfig);
    59|             config.setExpiryPolicyFactoryConfig(expiryPolicyFactoryConfig);
    60|         }
    61|         config.setEventJournalConfig(parameters.eventJournalConfig);
    62|         config.setHotRestartConfig(parameters.hotRestartConfig);
    63|         config.setInMemoryFormat(InMemoryFormat.valueOf(parameters.inMemoryFormat));
    64|         config.setKeyType(parameters.keyType);
    65|         config.setManagementEnabled(parameters.managementEnabled);
    66|         config.setMergePolicyConfig(mergePolicyConfig(parameters.mergePolicy, parameters.mergeBatchSize));
    67|         config.setName(parameters.name);
    68|         if (parameters.partitionLostListenerConfigs != null && !parameters.partitionLostListenerConfigs.isEmpty()) {
    69|             List<CachePartitionLostListenerConfig> listenerConfigs = (List<CachePartitionLostListenerConfig>)
    70|                     adaptListenerConfigs(parameters.partitionLostListenerConfigs);
    71|             config.setPartitionLostListenerConfigs(listenerConfigs);
    72|         } else {
    73|             config.setPartitionLostListenerConfigs(new ArrayList<>());
    74|         }
    75|         config.setSplitBrainProtectionName(parameters.splitBrainProtectionName);
    76|         config.setReadThrough(parameters.readThrough);
    77|         config.setStatisticsEnabled(parameters.statisticsEnabled);
    78|         config.setValueType(parameters.valueType);
    79|         config.setWanReplicationRef(parameters.wanReplicationRef);
    80|         config.setWriteThrough(parameters.writeThrough);
    81|         if (parameters.isMerkleTreeConfigExists) {
    82|             config.setMerkleTreeConfig(parameters.merkleTreeConfig);
    83|         }
    84|         return config;
    85|     }
    86|     @Override
    87|     public String getMethodName() {
    88|         return "addCacheConfig";
    89|     }
    90|     @Override
    91|     protected boolean checkStaticConfigDoesNotExist(IdentifiedDataSerializable config) {
    92|         DynamicConfigurationAwareConfig nodeConfig = (DynamicConfigurationAwareConfig) nodeEngine.getConfig();
    93|         CacheSimpleConfig cacheConfig = (CacheSimpleConfig) config;
    94|         return nodeConfig.checkStaticConfigDoesNotExist(nodeConfig.getStaticConfig().getCacheConfigs(),
    95|                 cacheConfig.getName(), cacheConfig);
    96|     }
    97| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/executorservice/ExecutorServiceCancelOnAddressMessageTask.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 4-68 ---
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.executorservice;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.ExecutorServiceCancelOnMemberCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractTargetMessageTask;
    20| import com.hazelcast.executor.impl.DistributedExecutorService;
    21| import com.hazelcast.executor.impl.operations.CancellationOperation;
    22| import com.hazelcast.instance.impl.Node;
    23| import com.hazelcast.internal.nio.Connection;
    24| import com.hazelcast.spi.impl.operationservice.Operation;
    25| import java.security.Permission;
    26| import java.util.UUID;
    27| public class ExecutorServiceCancelOnAddressMessageTask
    28|         extends AbstractTargetMessageTask<ExecutorServiceCancelOnMemberCodec.RequestParameters> {
    29|     public ExecutorServiceCancelOnAddressMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    30|         super(clientMessage, node, connection);
    31|     }
    32|     @Override
    33|     protected Operation prepareOperation() {
    34|         return new CancellationOperation(parameters.uuid, parameters.interrupt);
    35|     }
    36|     @Override
    37|     protected UUID getTargetUuid() {
    38|         return parameters.memberUUID;
    39|     }
    40|     @Override
    41|     protected ExecutorServiceCancelOnMemberCodec.RequestParameters decodeClientMessage(ClientMessage clientMessage) {
    42|         return ExecutorServiceCancelOnMemberCodec.decodeRequest(clientMessage);
    43|     }
    44|     @Override
    45|     protected ClientMessage encodeResponse(Object response) {
    46|         return ExecutorServiceCancelOnMemberCodec.encodeResponse((Boolean) response);
    47|     }
    48|     @Override
    49|     public String getDistributedObjectName() {
    50|         return null;
    51|     }
    52|     @Override
    53|     public String getServiceName() {
    54|         return DistributedExecutorService.SERVICE_NAME;
    55|     }
    56|     @Override
    57|     public Permission getRequiredPermission() {
    58|         return null;
    59|     }
    60|     @Override
    61|     public String getMethodName() {
    62|         return "cancel";
    63|     }
    64|     @Override
    65|     public Object[] getParameters() {
    66|         return null;
    67|     }
    68| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/executorservice/ExecutorServiceCancelOnPartitionMessageTask.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 4-62 ---
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.executorservice;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.ExecutorServiceCancelOnPartitionCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractPartitionMessageTask;
    20| import com.hazelcast.executor.impl.DistributedExecutorService;
    21| import com.hazelcast.executor.impl.operations.CancellationOperation;
    22| import com.hazelcast.instance.impl.Node;
    23| import com.hazelcast.internal.nio.Connection;
    24| import com.hazelcast.spi.impl.operationservice.Operation;
    25| import java.security.Permission;
    26| public class ExecutorServiceCancelOnPartitionMessageTask
    27|         extends AbstractPartitionMessageTask<ExecutorServiceCancelOnPartitionCodec.RequestParameters> {
    28|     public ExecutorServiceCancelOnPartitionMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    29|         super(clientMessage, node, connection);
    30|     }
    31|     @Override
    32|     protected Operation prepareOperation() {
    33|         return new CancellationOperation(parameters.uuid, parameters.interrupt);
    34|     }
    35|     @Override
    36|     protected ExecutorServiceCancelOnPartitionCodec.RequestParameters decodeClientMessage(ClientMessage clientMessage) {
    37|         return ExecutorServiceCancelOnPartitionCodec.decodeRequest(clientMessage);
    38|     }
    39|     protected ClientMessage encodeResponse(Object response) {
    40|         return ExecutorServiceCancelOnPartitionCodec.encodeResponse((Boolean) response);
    41|     }
    42|     @Override
    43|     public String getDistributedObjectName() {
    44|         return null;
    45|     }
    46|     @Override
    47|     public String getServiceName() {
    48|         return DistributedExecutorService.SERVICE_NAME;
    49|     }
    50|     @Override
    51|     public Permission getRequiredPermission() {
    52|         return null;
    53|     }
    54|     @Override
    55|     public String getMethodName() {
    56|         return "cancel";
    57|     }
    58|     @Override
    59|     public Object[] getParameters() {
    60|         return null;
    61|     }
    62| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/executorservice/ExecutorServiceIsShutdownMessageTask.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 3-62 ---
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.executorservice;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.ExecutorServiceIsShutdownCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractCallableMessageTask;
    20| import com.hazelcast.executor.impl.DistributedExecutorService;
    21| import com.hazelcast.instance.impl.Node;
    22| import com.hazelcast.internal.nio.Connection;
    23| import java.security.Permission;
    24| public class ExecutorServiceIsShutdownMessageTask
    25|         extends AbstractCallableMessageTask<String> {
    26|     public ExecutorServiceIsShutdownMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    27|         super(clientMessage, node, connection);
    28|     }
    29|     @Override
    30|     protected Object call() throws Exception {
    31|         final DistributedExecutorService service = getService(DistributedExecutorService.SERVICE_NAME);
    32|         return service.isShutdown(parameters);
    33|     }
    34|     @Override
    35|     protected String decodeClientMessage(ClientMessage clientMessage) {
    36|         return ExecutorServiceIsShutdownCodec.decodeRequest(clientMessage);
    37|     }
    38|     @Override
    39|     protected ClientMessage encodeResponse(Object response) {
    40|         return ExecutorServiceIsShutdownCodec.encodeResponse((Boolean) response);
    41|     }
    42|     @Override
    43|     public String getServiceName() {
    44|         return DistributedExecutorService.SERVICE_NAME;
    45|     }
    46|     @Override
    47|     public Permission getRequiredPermission() {
    48|         return null;
    49|     }
    50|     @Override
    51|     public String getDistributedObjectName() {
    52|         return null;
    53|     }
    54|     @Override
    55|     public String getMethodName() {
    56|         return "isShutdown";
    57|     }
    58|     @Override
    59|     public Object[] getParameters() {
    60|         return null;
    61|     }
    62| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/executorservice/ExecutorServiceShutdownMessageTask.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 3-63 ---
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.executorservice;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.ExecutorServiceShutdownCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractCallableMessageTask;
    20| import com.hazelcast.executor.impl.DistributedExecutorService;
    21| import com.hazelcast.instance.impl.Node;
    22| import com.hazelcast.internal.nio.Connection;
    23| import java.security.Permission;
    24| public class ExecutorServiceShutdownMessageTask
    25|         extends AbstractCallableMessageTask<String> {
    26|     public ExecutorServiceShutdownMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    27|         super(clientMessage, node, connection);
    28|     }
    29|     @Override
    30|     protected Object call() throws Exception {
    31|         final DistributedExecutorService service = getService(DistributedExecutorService.SERVICE_NAME);
    32|         service.shutdownExecutor(parameters);
    33|         return null;
    34|     }
    35|     @Override
    36|     protected String decodeClientMessage(ClientMessage clientMessage) {
    37|         return ExecutorServiceShutdownCodec.decodeRequest(clientMessage);
    38|     }
    39|     @Override
    40|     protected ClientMessage encodeResponse(Object response) {
    41|         return ExecutorServiceShutdownCodec.encodeResponse();
    42|     }
    43|     @Override
    44|     public String getServiceName() {
    45|         return DistributedExecutorService.SERVICE_NAME;
    46|     }
    47|     @Override
    48|     public Permission getRequiredPermission() {
    49|         return null;
    50|     }
    51|     @Override
    52|     public String getDistributedObjectName() {
    53|         return null;
    54|     }
    55|     @Override
    56|     public String getMethodName() {
    57|         return "shutdown";
    58|     }
    59|     @Override
    60|     public Object[] getParameters() {
    61|         return null;
    62|     }
    63| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/executorservice/ExecutorServiceSubmitToAddressMessageTask.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 6-45 ---
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.executorservice;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.ExecutorServiceSubmitToMemberCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractTargetMessageTask;
    20| import com.hazelcast.executor.impl.DistributedExecutorService;
    21| import com.hazelcast.executor.impl.operations.MemberCallableTaskOperation;
    22| import com.hazelcast.instance.impl.Node;
    23| import com.hazelcast.internal.nio.Connection;
    24| import com.hazelcast.internal.serialization.Data;
    25| import com.hazelcast.security.SecurityContext;
    26| import com.hazelcast.spi.impl.operationservice.Operation;
    27| import javax.security.auth.Subject;
    28| import java.security.Permission;
    29| import java.util.UUID;
    30| import java.util.concurrent.Callable;
    31| public class ExecutorServiceSubmitToAddressMessageTask
    32|         extends AbstractTargetMessageTask<ExecutorServiceSubmitToMemberCodec.RequestParameters> {
    33|     public ExecutorServiceSubmitToAddressMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    34|         super(clientMessage, node, connection);
    35|     }
    36|     @Override
    37|     protected UUID getTargetUuid() {
    38|         return parameters.memberUUID;
    39|     }
    40|     @Override
    41|     protected Operation prepareOperation() {
    42|         SecurityContext securityContext = clientEngine.getSecurityContext();
    43|         Data callableData = parameters.callable;
    44|         if (securityContext != null) {
    45|             Subject subject = endpoint.getSubject();

# --- HUNK 2: Lines 54-88 ---
    54|         }
    55|         MemberCallableTaskOperation op = new MemberCallableTaskOperation(parameters.name, parameters.uuid, callableData);
    56|         op.setCallerUuid(endpoint.getUuid());
    57|         return op;
    58|     }
    59|     @Override
    60|     protected ExecutorServiceSubmitToMemberCodec.RequestParameters decodeClientMessage(ClientMessage clientMessage) {
    61|         return ExecutorServiceSubmitToMemberCodec.decodeRequest(clientMessage);
    62|     }
    63|     @Override
    64|     protected ClientMessage encodeResponse(Object response) {
    65|         Data data = serializationService.toData(response);
    66|         return ExecutorServiceSubmitToMemberCodec.encodeResponse(data);
    67|     }
    68|     @Override
    69|     public String getServiceName() {
    70|         return DistributedExecutorService.SERVICE_NAME;
    71|     }
    72|     @Override
    73|     public Permission getRequiredPermission() {
    74|         return null;
    75|     }
    76|     @Override
    77|     public String getDistributedObjectName() {
    78|         return parameters.name;
    79|     }
    80|     @Override
    81|     public String getMethodName() {
    82|         return null;
    83|     }
    84|     @Override
    85|     public Object[] getParameters() {
    86|         return null;
    87|     }
    88| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/executorservice/ExecutorServiceSubmitToPartitionMessageTask.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 6-45 ---
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.executorservice;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.ExecutorServiceSubmitToPartitionCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractPartitionMessageTask;
    20| import com.hazelcast.executor.impl.DistributedExecutorService;
    21| import com.hazelcast.executor.impl.operations.CallableTaskOperation;
    22| import com.hazelcast.instance.impl.Node;
    23| import com.hazelcast.internal.nio.Connection;
    24| import com.hazelcast.internal.serialization.Data;
    25| import com.hazelcast.security.SecurityContext;
    26| import com.hazelcast.spi.impl.operationservice.Operation;
    27| import javax.security.auth.Subject;
    28| import java.security.Permission;
    29| import java.util.concurrent.Callable;
    30| public class ExecutorServiceSubmitToPartitionMessageTask
    31|         extends AbstractPartitionMessageTask<ExecutorServiceSubmitToPartitionCodec.RequestParameters> {
    32|     public ExecutorServiceSubmitToPartitionMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    33|         super(clientMessage, node, connection);
    34|     }
    35|     @Override
    36|     protected Operation prepareOperation() {
    37|         SecurityContext securityContext = clientEngine.getSecurityContext();
    38|         Data callableData = parameters.callable;
    39|         if (securityContext != null) {
    40|             Subject subject = endpoint.getSubject();
    41|             Object taskObject = serializationService.toObject(parameters.callable);
    42|             Callable callable;
    43|             if (taskObject instanceof Runnable) {
    44|                 callable = securityContext.createSecureCallable(subject, (Runnable) taskObject);
    45|             } else {

# --- HUNK 2: Lines 47-81 ---
    47|             }
    48|             callableData = serializationService.toData(callable);
    49|         }
    50|         return new CallableTaskOperation(parameters.name, parameters.uuid, callableData);
    51|     }
    52|     @Override
    53|     protected ExecutorServiceSubmitToPartitionCodec.RequestParameters decodeClientMessage(ClientMessage clientMessage) {
    54|         return ExecutorServiceSubmitToPartitionCodec.decodeRequest(clientMessage);
    55|     }
    56|     @Override
    57|     protected ClientMessage encodeResponse(Object response) {
    58|         Data data = serializationService.toData(response);
    59|         return ExecutorServiceSubmitToPartitionCodec.encodeResponse(data);
    60|     }
    61|     @Override
    62|     public String getServiceName() {
    63|         return DistributedExecutorService.SERVICE_NAME;
    64|     }
    65|     @Override
    66|     public Permission getRequiredPermission() {
    67|         return null;
    68|     }
    69|     @Override
    70|     public String getDistributedObjectName() {
    71|         return parameters.name;
    72|     }
    73|     @Override
    74|     public String getMethodName() {
    75|         return null;
    76|     }
    77|     @Override
    78|     public Object[] getParameters() {
    79|         return null;
    80|     }
    81| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/executorservice/durable/DurableExecutorDisposeResultMessageTask.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 3-63 ---
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.executorservice.durable;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.DurableExecutorDisposeResultCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractPartitionMessageTask;
    20| import com.hazelcast.durableexecutor.impl.operations.DisposeResultOperation;
    21| import com.hazelcast.instance.impl.Node;
    22| import com.hazelcast.internal.nio.Connection;
    23| import com.hazelcast.spi.impl.operationservice.Operation;
    24| import java.security.Permission;
    25| import static com.hazelcast.durableexecutor.impl.DistributedDurableExecutorService.SERVICE_NAME;
    26| public class DurableExecutorDisposeResultMessageTask
    27|         extends AbstractPartitionMessageTask<DurableExecutorDisposeResultCodec.RequestParameters> {
    28|     public DurableExecutorDisposeResultMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    29|         super(clientMessage, node, connection);
    30|     }
    31|     @Override
    32|     protected Operation prepareOperation() {
    33|         return new DisposeResultOperation(parameters.name, parameters.sequence);
    34|     }
    35|     @Override
    36|     protected DurableExecutorDisposeResultCodec.RequestParameters decodeClientMessage(ClientMessage clientMessage) {
    37|         return DurableExecutorDisposeResultCodec.decodeRequest(clientMessage);
    38|     }
    39|     @Override
    40|     protected ClientMessage encodeResponse(Object response) {
    41|         return DurableExecutorDisposeResultCodec.encodeResponse();
    42|     }
    43|     @Override
    44|     public String getServiceName() {
    45|         return SERVICE_NAME;
    46|     }
    47|     @Override
    48|     public Permission getRequiredPermission() {
    49|         return null;
    50|     }
    51|     @Override
    52|     public String getDistributedObjectName() {
    53|         return parameters.name;
    54|     }
    55|     @Override
    56|     public String getMethodName() {
    57|         return null;
    58|     }
    59|     @Override
    60|     public Object[] getParameters() {
    61|         return null;
    62|     }
    63| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/executorservice/durable/DurableExecutorIsShutdownMessageTask.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 3-63 ---
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.executorservice.durable;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.DurableExecutorIsShutdownCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractCallableMessageTask;
    20| import com.hazelcast.durableexecutor.impl.DistributedDurableExecutorService;
    21| import com.hazelcast.instance.impl.Node;
    22| import com.hazelcast.internal.nio.Connection;
    23| import java.security.Permission;
    24| import static com.hazelcast.durableexecutor.impl.DistributedDurableExecutorService.SERVICE_NAME;
    25| public class DurableExecutorIsShutdownMessageTask
    26|         extends AbstractCallableMessageTask<String> {
    27|     public DurableExecutorIsShutdownMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    28|         super(clientMessage, node, connection);
    29|     }
    30|     @Override
    31|     protected Object call() throws Exception {
    32|         DistributedDurableExecutorService service = getService(SERVICE_NAME);
    33|         return service.isShutdown(parameters);
    34|     }
    35|     @Override
    36|     protected String decodeClientMessage(ClientMessage clientMessage) {
    37|         return DurableExecutorIsShutdownCodec.decodeRequest(clientMessage);
    38|     }
    39|     @Override
    40|     protected ClientMessage encodeResponse(Object response) {
    41|         return DurableExecutorIsShutdownCodec.encodeResponse((Boolean) response);
    42|     }
    43|     @Override
    44|     public String getServiceName() {
    45|         return SERVICE_NAME;
    46|     }
    47|     @Override
    48|     public Permission getRequiredPermission() {
    49|         return null;
    50|     }
    51|     @Override
    52|     public String getDistributedObjectName() {
    53|         return parameters;
    54|     }
    55|     @Override
    56|     public String getMethodName() {
    57|         return "isShutdown";
    58|     }
    59|     @Override
    60|     public Object[] getParameters() {
    61|         return null;
    62|     }
    63| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/executorservice/durable/DurableExecutorRetrieveAndDisposeResultMessageTask.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 4-65 ---
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.executorservice.durable;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.DurableExecutorRetrieveAndDisposeResultCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractPartitionMessageTask;
    20| import com.hazelcast.durableexecutor.impl.operations.RetrieveAndDisposeResultOperation;
    21| import com.hazelcast.instance.impl.Node;
    22| import com.hazelcast.internal.nio.Connection;
    23| import com.hazelcast.internal.serialization.Data;
    24| import com.hazelcast.spi.impl.operationservice.Operation;
    25| import java.security.Permission;
    26| import static com.hazelcast.durableexecutor.impl.DistributedDurableExecutorService.SERVICE_NAME;
    27| public class DurableExecutorRetrieveAndDisposeResultMessageTask
    28|         extends AbstractPartitionMessageTask<DurableExecutorRetrieveAndDisposeResultCodec.RequestParameters> {
    29|     public DurableExecutorRetrieveAndDisposeResultMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    30|         super(clientMessage, node, connection);
    31|     }
    32|     @Override
    33|     protected Operation prepareOperation() {
    34|         return new RetrieveAndDisposeResultOperation(parameters.name, parameters.sequence);
    35|     }
    36|     @Override
    37|     protected DurableExecutorRetrieveAndDisposeResultCodec.RequestParameters decodeClientMessage(ClientMessage clientMessage) {
    38|         return DurableExecutorRetrieveAndDisposeResultCodec.decodeRequest(clientMessage);
    39|     }
    40|     @Override
    41|     protected ClientMessage encodeResponse(Object response) {
    42|         Data data = serializationService.toData(response);
    43|         return DurableExecutorRetrieveAndDisposeResultCodec.encodeResponse(data);
    44|     }
    45|     @Override
    46|     public String getServiceName() {
    47|         return SERVICE_NAME;
    48|     }
    49|     @Override
    50|     public Permission getRequiredPermission() {
    51|         return null;
    52|     }
    53|     @Override
    54|     public String getDistributedObjectName() {
    55|         return parameters.name;
    56|     }
    57|     @Override
    58|     public String getMethodName() {
    59|         return null;
    60|     }
    61|     @Override
    62|     public Object[] getParameters() {
    63|         return null;
    64|     }
    65| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/executorservice/durable/DurableExecutorRetrieveResultMessageTask.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 4-65 ---
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.executorservice.durable;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.DurableExecutorRetrieveResultCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractPartitionMessageTask;
    20| import com.hazelcast.durableexecutor.impl.operations.RetrieveResultOperation;
    21| import com.hazelcast.instance.impl.Node;
    22| import com.hazelcast.internal.nio.Connection;
    23| import com.hazelcast.internal.serialization.Data;
    24| import com.hazelcast.spi.impl.operationservice.Operation;
    25| import java.security.Permission;
    26| import static com.hazelcast.durableexecutor.impl.DistributedDurableExecutorService.SERVICE_NAME;
    27| public class DurableExecutorRetrieveResultMessageTask
    28|         extends AbstractPartitionMessageTask<DurableExecutorRetrieveResultCodec.RequestParameters> {
    29|     public DurableExecutorRetrieveResultMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    30|         super(clientMessage, node, connection);
    31|     }
    32|     @Override
    33|     protected Operation prepareOperation() {
    34|         return new RetrieveResultOperation(parameters.name, parameters.sequence);
    35|     }
    36|     @Override
    37|     protected DurableExecutorRetrieveResultCodec.RequestParameters decodeClientMessage(ClientMessage clientMessage) {
    38|         return DurableExecutorRetrieveResultCodec.decodeRequest(clientMessage);
    39|     }
    40|     @Override
    41|     protected ClientMessage encodeResponse(Object response) {
    42|         Data data = serializationService.toData(response);
    43|         return DurableExecutorRetrieveResultCodec.encodeResponse(data);
    44|     }
    45|     @Override
    46|     public String getServiceName() {
    47|         return SERVICE_NAME;
    48|     }
    49|     @Override
    50|     public Permission getRequiredPermission() {
    51|         return null;
    52|     }
    53|     @Override
    54|     public String getDistributedObjectName() {
    55|         return parameters.name;
    56|     }
    57|     @Override
    58|     public String getMethodName() {
    59|         return null;
    60|     }
    61|     @Override
    62|     public Object[] getParameters() {
    63|         return null;
    64|     }
    65| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/executorservice/durable/DurableExecutorShutdownMessageTask.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 3-64 ---
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.executorservice.durable;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.DurableExecutorShutdownCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractCallableMessageTask;
    20| import com.hazelcast.durableexecutor.impl.DistributedDurableExecutorService;
    21| import com.hazelcast.instance.impl.Node;
    22| import com.hazelcast.internal.nio.Connection;
    23| import java.security.Permission;
    24| import static com.hazelcast.durableexecutor.impl.DistributedDurableExecutorService.SERVICE_NAME;
    25| public class DurableExecutorShutdownMessageTask
    26|         extends AbstractCallableMessageTask<String> {
    27|     public DurableExecutorShutdownMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    28|         super(clientMessage, node, connection);
    29|     }
    30|     @Override
    31|     protected Object call() throws Exception {
    32|         DistributedDurableExecutorService service = getService(SERVICE_NAME);
    33|         service.shutdownExecutor(parameters);
    34|         return null;
    35|     }
    36|     @Override
    37|     protected String decodeClientMessage(ClientMessage clientMessage) {
    38|         return DurableExecutorShutdownCodec.decodeRequest(clientMessage);
    39|     }
    40|     @Override
    41|     protected ClientMessage encodeResponse(Object response) {
    42|         return DurableExecutorShutdownCodec.encodeResponse();
    43|     }
    44|     @Override
    45|     public String getServiceName() {
    46|         return SERVICE_NAME;
    47|     }
    48|     @Override
    49|     public Permission getRequiredPermission() {
    50|         return null;
    51|     }
    52|     @Override
    53|     public String getDistributedObjectName() {
    54|         return parameters;
    55|     }
    56|     @Override
    57|     public String getMethodName() {
    58|         return "shutdown";
    59|     }
    60|     @Override
    61|     public Object[] getParameters() {
    62|         return null;
    63|     }
    64| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/executorservice/durable/DurableExecutorSubmitToPartitionMessageTask.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 5-44 ---
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.executorservice.durable;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.DurableExecutorSubmitToPartitionCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractPartitionMessageTask;
    20| import com.hazelcast.durableexecutor.impl.operations.TaskOperation;
    21| import com.hazelcast.instance.impl.Node;
    22| import com.hazelcast.internal.nio.Connection;
    23| import com.hazelcast.internal.serialization.Data;
    24| import com.hazelcast.security.SecurityContext;
    25| import com.hazelcast.spi.impl.operationservice.Operation;
    26| import javax.security.auth.Subject;
    27| import java.security.Permission;
    28| import java.util.concurrent.Callable;
    29| import static com.hazelcast.durableexecutor.impl.DistributedDurableExecutorService.SERVICE_NAME;
    30| public class DurableExecutorSubmitToPartitionMessageTask
    31|         extends AbstractPartitionMessageTask<DurableExecutorSubmitToPartitionCodec.RequestParameters> {
    32|     public DurableExecutorSubmitToPartitionMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    33|         super(clientMessage, node, connection);
    34|     }
    35|     @Override
    36|     protected Operation prepareOperation() {
    37|         SecurityContext securityContext = clientEngine.getSecurityContext();
    38|         Data callableData = parameters.callable;
    39|         if (securityContext != null) {
    40|             Subject subject = endpoint.getSubject();
    41|             Object taskObject = serializationService.toObject(parameters.callable);
    42|             Callable callable;
    43|             if (taskObject instanceof Runnable) {
    44|                 callable = securityContext.createSecureCallable(subject, (Runnable) taskObject);

# --- HUNK 2: Lines 46-80 ---
    46|                 callable = securityContext.createSecureCallable(subject, (Callable<? extends Object>) taskObject);
    47|             }
    48|             callableData = serializationService.toData(callable);
    49|         }
    50|         return new TaskOperation(parameters.name, callableData);
    51|     }
    52|     @Override
    53|     protected DurableExecutorSubmitToPartitionCodec.RequestParameters decodeClientMessage(ClientMessage clientMessage) {
    54|         return DurableExecutorSubmitToPartitionCodec.decodeRequest(clientMessage);
    55|     }
    56|     @Override
    57|     protected ClientMessage encodeResponse(Object response) {
    58|         return DurableExecutorSubmitToPartitionCodec.encodeResponse((Integer) response);
    59|     }
    60|     @Override
    61|     public String getServiceName() {
    62|         return SERVICE_NAME;
    63|     }
    64|     @Override
    65|     public Permission getRequiredPermission() {
    66|         return null;
    67|     }
    68|     @Override
    69|     public String getDistributedObjectName() {
    70|         return parameters.name;
    71|     }
    72|     @Override
    73|     public String getMethodName() {
    74|         return null;
    75|     }
    76|     @Override
    77|     public Object[] getParameters() {
    78|         return null;
    79|     }
    80| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/scheduledexecutor/ScheduledExecutorSubmitToPartitionMessageTask.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 5-58 ---
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.scheduledexecutor;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.ScheduledExecutorSubmitToPartitionCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractPartitionMessageTask;
    20| import com.hazelcast.instance.impl.Node;
    21| import com.hazelcast.internal.nio.Connection;
    22| import com.hazelcast.scheduledexecutor.impl.DistributedScheduledExecutorService;
    23| import com.hazelcast.scheduledexecutor.impl.TaskDefinition;
    24| import com.hazelcast.scheduledexecutor.impl.operations.ScheduleTaskOperation;
    25| import com.hazelcast.security.permission.ActionConstants;
    26| import com.hazelcast.security.permission.ScheduledExecutorPermission;
    27| import com.hazelcast.spi.impl.operationservice.Operation;
    28| import java.security.Permission;
    29| import java.util.concurrent.Callable;
    30| import java.util.concurrent.TimeUnit;
    31| public class ScheduledExecutorSubmitToPartitionMessageTask
    32|         extends AbstractPartitionMessageTask<ScheduledExecutorSubmitToPartitionCodec.RequestParameters> {
    33|     public ScheduledExecutorSubmitToPartitionMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    34|         super(clientMessage, node, connection);
    35|     }
    36|     @Override
    37|     protected Operation prepareOperation() {
    38|         Callable callable = serializationService.toObject(parameters.task);
    39|         TaskDefinition def = new TaskDefinition(TaskDefinition.Type.getById(parameters.type),
    40|                 parameters.taskName, callable, parameters.initialDelayInMillis, parameters.periodInMillis,
    41|                 TimeUnit.MILLISECONDS, isAutoDisposable());
    42|         return new ScheduleTaskOperation(parameters.schedulerName, def);
    43|     }
    44|     @Override
    45|     protected ScheduledExecutorSubmitToPartitionCodec.RequestParameters decodeClientMessage(ClientMessage clientMessage) {
    46|         return ScheduledExecutorSubmitToPartitionCodec.decodeRequest(clientMessage);
    47|     }
    48|     @Override
    49|     protected ClientMessage encodeResponse(Object response) {
    50|         return ScheduledExecutorSubmitToPartitionCodec.encodeResponse();
    51|     }
    52|     @Override
    53|     public String getServiceName() {
    54|         return DistributedScheduledExecutorService.SERVICE_NAME;
    55|     }
    56|     @Override
    57|     public Permission getRequiredPermission() {
    58|         return new ScheduledExecutorPermission(parameters.schedulerName, ActionConstants.ACTION_MODIFY);


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/client/impl/protocol/task/scheduledexecutor/ScheduledExecutorSubmitToTargetMessageTask.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 6-60 ---
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.client.impl.protocol.task.scheduledexecutor;
    17| import com.hazelcast.client.impl.protocol.ClientMessage;
    18| import com.hazelcast.client.impl.protocol.codec.ScheduledExecutorSubmitToMemberCodec;
    19| import com.hazelcast.client.impl.protocol.task.AbstractTargetMessageTask;
    20| import com.hazelcast.cluster.Member;
    21| import com.hazelcast.instance.impl.Node;
    22| import com.hazelcast.internal.nio.Connection;
    23| import com.hazelcast.scheduledexecutor.impl.DistributedScheduledExecutorService;
    24| import com.hazelcast.scheduledexecutor.impl.TaskDefinition;
    25| import com.hazelcast.scheduledexecutor.impl.operations.ScheduleTaskOperation;
    26| import com.hazelcast.security.permission.ActionConstants;
    27| import com.hazelcast.security.permission.ScheduledExecutorPermission;
    28| import com.hazelcast.spi.impl.operationservice.Operation;
    29| import java.security.Permission;
    30| import java.util.UUID;
    31| import java.util.concurrent.Callable;
    32| import java.util.concurrent.TimeUnit;
    33| public class ScheduledExecutorSubmitToTargetMessageTask
    34|         extends AbstractTargetMessageTask<ScheduledExecutorSubmitToMemberCodec.RequestParameters> {
    35|     public ScheduledExecutorSubmitToTargetMessageTask(ClientMessage clientMessage, Node node, Connection connection) {
    36|         super(clientMessage, node, connection);
    37|     }
    38|     @Override
    39|     protected Operation prepareOperation() {
    40|         Callable callable = serializationService.toObject(parameters.task);
    41|         TaskDefinition def = new TaskDefinition(TaskDefinition.Type.getById(parameters.type),
    42|                 parameters.taskName, callable, parameters.initialDelayInMillis, parameters.periodInMillis,
    43|                 TimeUnit.MILLISECONDS, isAutoDisposable());
    44|         return new ScheduleTaskOperation(parameters.schedulerName, def);
    45|     }
    46|     @Override
    47|     protected UUID getTargetUuid() {
    48|         return parameters.memberUuid;
    49|     }
    50|     @Override
    51|     protected ScheduledExecutorSubmitToMemberCodec.RequestParameters decodeClientMessage(ClientMessage clientMessage) {
    52|         return ScheduledExecutorSubmitToMemberCodec.decodeRequest(clientMessage);
    53|     }
    54|     @Override
    55|     protected ClientMessage encodeResponse(Object response) {
    56|         return ScheduledExecutorSubmitToMemberCodec.encodeResponse();
    57|     }
    58|     @Override
    59|     public String getServiceName() {
    60|         return DistributedScheduledExecutorService.SERVICE_NAME;


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/config/ConfigXmlGenerator.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 150-189 ---
   150|         reliableTopicXmlGenerator(gen, config);
   151|         liteMemberXmlGenerator(gen, config);
   152|         nativeMemoryXmlGenerator(gen, config);
   153|         persistenceXmlGenerator(gen, config);
   154|         flakeIdGeneratorXmlGenerator(gen, config);
   155|         crdtReplicationXmlGenerator(gen, config);
   156|         pnCounterXmlGenerator(gen, config);
   157|         splitBrainProtectionXmlGenerator(gen, config);
   158|         cpSubsystemConfig(gen, config);
   159|         metricsConfig(gen, config);
   160|         instanceTrackingConfig(gen, config);
   161|         sqlConfig(gen, config);
   162|         jetConfig(gen, config);
   163|         factoryWithPropertiesXmlGenerator(gen, "auditlog", config.getAuditlogConfig());
   164|         userCodeDeploymentConfig(gen, config);
   165|         xml.append("</hazelcast>");
   166|         String xmlString = xml.toString();
   167|         return formatted ? formatXml(xmlString, INDENT) : xmlString;
   168|     }
   169|     private String getOrMaskValue(String value) {
   170|         return maskSensitiveFields ? MASK_FOR_SENSITIVE_DATA : value;
   171|     }
   172|     private void managementCenterXmlGenerator(XmlGenerator gen, Config config) {
   173|         ManagementCenterConfig mcConfig = config.getManagementCenterConfig();
   174|         if (mcConfig != null) {
   175|             gen.open("management-center",
   176|                     "scripting-enabled", mcConfig.isScriptingEnabled());
   177|             trustedInterfacesXmlGenerator(gen, mcConfig.getTrustedInterfaces());
   178|             gen.close();
   179|         }
   180|     }
   181|     @SuppressWarnings("unchecked")
   182|     private static void collectionXmlGenerator(XmlGenerator gen, String type, Collection<? extends CollectionConfig> configs) {
   183|         if (CollectionUtil.isNotEmpty(configs)) {
   184|             for (CollectionConfig<? extends CollectionConfig> config : configs) {
   185|                 gen.open(type, "name", config.getName())
   186|                         .node("statistics-enabled", config.isStatisticsEnabled())
   187|                         .node("max-size", config.getMaxSize())
   188|                         .node("backup-count", config.getBackupCount())
   189|                         .node("async-backup-count", config.getAsyncBackupCount())

# --- HUNK 2: Lines 288-376 ---
   288|             if (upi != null) {
   289|                 gen.node("username-password", null, "username", upi.getUsername(), "password", getOrMaskValue(upi.getPassword()));
   290|             }
   291|             TokenIdentityConfig ti = c.getTokenIdentityConfig();
   292|             if (ti != null) {
   293|                 gen.node("token", getOrMaskValue(ti.getTokenEncoded()), "encoding", ti.getEncoding().toString());
   294|             }
   295|             kerberosIdentityGenerator(gen, c.getKerberosIdentityConfig());
   296|             gen.close();
   297|         }
   298|         gen.close();
   299|     }
   300|     private static void tlsAuthenticationGenerator(XmlGenerator gen, TlsAuthenticationConfig c) {
   301|         if (c == null) {
   302|             return;
   303|         }
   304|         XmlGenerator tlsGen = gen.open("tls", "roleAttribute", c.getRoleAttribute());
   305|         addClusterLoginElements(tlsGen, c)
   306|                 .close();
   307|     }
   308|     private static void ldapAuthenticationGenerator(XmlGenerator gen, LdapAuthenticationConfig c) {
   309|         if (c == null) {
   310|             return;
   311|         }
   312|         addClusterLoginElements(gen.open("ldap"), c)
   313|                 .node("url", c.getUrl())
   314|                 .nodeIfContents("socket-factory-class-name", c.getSocketFactoryClassName())
   315|                 .nodeIfContents("parse-dn", c.getParseDn())
   316|                 .nodeIfContents("role-context", c.getRoleContext())
   317|                 .nodeIfContents("role-filter", c.getRoleFilter())
   318|                 .nodeIfContents("role-mapping-attribute", c.getRoleMappingAttribute())
   319|                 .nodeIfContents("role-mapping-mode", c.getRoleMappingMode())
   320|                 .nodeIfContents("role-name-attribute", c.getRoleNameAttribute())
   321|                 .nodeIfContents("role-recursion-max-depth", c.getRoleRecursionMaxDepth())
   322|                 .nodeIfContents("role-search-scope", c.getRoleSearchScope())
   323|                 .nodeIfContents("user-name-attribute", c.getUserNameAttribute())
   324|                 .nodeIfContents("system-user-dn", c.getSystemUserDn())
   325|                 .nodeIfContents("system-user-password", c.getSystemUserPassword())
   326|                 .nodeIfContents("system-authentication", c.getSystemAuthentication())
   327|                 .nodeIfContents("security-realm", c.getSecurityRealm())
   328|                 .nodeIfContents("password-attribute", c.getPasswordAttribute())
   329|                 .nodeIfContents("user-context", c.getUserContext())
   330|                 .nodeIfContents("user-filter", c.getUserFilter())
   331|                 .nodeIfContents("user-search-scope", c.getUserSearchScope())
   332|                 .nodeIfContents("skip-authentication", c.getSkipAuthentication())
   333|                 .close();
   334|     }
   335|     private static void kerberosAuthenticationGenerator(XmlGenerator gen, KerberosAuthenticationConfig c) {
   336|         if (c == null) {
   337|             return;
   338|         }
   339|         XmlGenerator kerberosGen = gen.open("kerberos");
   340|         addClusterLoginElements(kerberosGen, c)
   341|                 .nodeIfContents("relax-flags-check", c.getRelaxFlagsCheck())
   342|                 .nodeIfContents("use-name-without-realm", c.getUseNameWithoutRealm())
   343|                 .nodeIfContents("security-realm", c.getSecurityRealm())
   344|                 .nodeIfContents("keytab-file", c.getKeytabFile())
   345|                 .nodeIfContents("principal", c.getPrincipal());
   346|         ldapAuthenticationGenerator(kerberosGen, c.getLdapAuthenticationConfig());
   347|         kerberosGen.close();
   348|     }
   349|     private static void simpleAuthenticationGenerator(XmlGenerator gen, SimpleAuthenticationConfig c) {
   350|         if (c == null) {
   351|             return;
   352|         }
   353|         XmlGenerator simpleGen = gen.open("simple");
   354|         addClusterLoginElements(simpleGen, c).nodeIfContents("role-separator", c.getRoleSeparator());
   355|         for (String username : c.getUsernames()) {
   356|             simpleGen.open("user", "username", username, "password", c.getPassword(username));
   357|             for (String role : c.getRoles(username)) {
   358|                 simpleGen.node("role", role);
   359|             }
   360|             simpleGen.close();
   361|         }
   362|         simpleGen.close();
   363|     }
   364|     private static void kerberosIdentityGenerator(XmlGenerator gen, KerberosIdentityConfig c) {
   365|         if (c == null) {
   366|             return;
   367|         }
   368|         gen.open("kerberos")
   369|                 .nodeIfContents("realm", c.getRealm())
   370|                 .nodeIfContents("security-realm", c.getSecurityRealm())
   371|                 .nodeIfContents("keytab-file", c.getKeytabFile())
   372|                 .nodeIfContents("principal", c.getPrincipal())
   373|                 .nodeIfContents("service-name-prefix", c.getServiceNamePrefix())
   374|                 .nodeIfContents("spn", c.getSpn())
   375|                 .nodeIfContents("use-canonical-hostname", c.getUseCanonicalHostname())
   376|                 .close();


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/cp/internal/session/RaftSessionService.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 435-461 ---
   435|             } catch (Exception e) {
   436|                 if (logger.isFineEnabled()) {
   437|                     logger.fine("Could not close inactive sessions: " + sessions + " of " + groupId, e);
   438|                 }
   439|             }
   440|         }
   441|     }
   442|     @Override
   443|     public void provideDynamicMetrics(MetricDescriptor descriptor, MetricsCollectionContext context) {
   444|         MetricDescriptor root = descriptor.withPrefix("cp.session");
   445|         for (RaftSessionRegistry registry : registries.values()) {
   446|             CPGroupId groupId = registry.groupId();
   447|             for (CPSession session : registry.getSessions()) {
   448|                 MetricDescriptor desc = root.copy()
   449|                         .withDiscriminator("id", session.id() + "@" + groupId.getName())
   450|                         .withTag("sessionId", String.valueOf(session.id()))
   451|                         .withTag("group", groupId.getName());
   452|                 context.collect(desc.copy().withTag("endpoint", session.endpoint().toString()).withMetric("endpoint"), 0);
   453|                 context.collect(desc.copy().withTag("endpointType", session.endpointType().toString())
   454|                         .withMetric("endpointType"), 0);
   455|                 context.collect(desc.copy().withMetric("version"), session.version());
   456|                 context.collect(desc.copy().withUnit(ProbeUnit.MS).withMetric("creationTime"), session.creationTime());
   457|                 context.collect(desc.copy().withUnit(ProbeUnit.MS).withMetric("expirationTime"), session.expirationTime());
   458|             }
   459|         }
   460|     }
   461| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/internal/cluster/impl/ClusterJoinManager.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 569-609 ---
   569|         if (masterAddress.equals(target)) {
   570|             logger.fine("Cannot send master answer to " + target + " since it is the known master");
   571|             return;
   572|         }
   573|         MasterResponseOp op = new MasterResponseOp(masterAddress);
   574|         nodeEngine.getOperationService().send(op, target);
   575|     }
   576|     @SuppressWarnings("checkstyle:cyclomaticcomplexity")
   577|     private boolean checkIfJoinRequestFromAnExistingMember(JoinMessage joinMessage, ServerConnection connection) {
   578|         Address target = joinMessage.getAddress();
   579|         MemberImpl member = clusterService.getMember(target);
   580|         if (member == null) {
   581|             return checkIfUsingAnExistingMemberUuid(joinMessage);
   582|         }
   583|         if (joinMessage.getUuid().equals(member.getUuid())) {
   584|             sendMasterAnswer(target);
   585|             if (clusterService.isMaster() && !isMastershipClaimInProgress()) {
   586|                 if (logger.isFineEnabled()) {
   587|                     logger.fine(format("Ignoring join request, member already exists: %s", joinMessage));
   588|                 }
   589|                 boolean deferPartitionProcessing = isMemberRestartingWithPersistence(member.getAttributes());
   590|                 OnJoinOp preJoinOp = preparePreJoinOps();
   591|                 OnJoinOp postJoinOp = preparePostJoinOp();
   592|                 PartitionRuntimeState partitionRuntimeState = node.getPartitionService().createPartitionState();
   593|                 Operation op = new FinalizeJoinOp(member.getUuid(),
   594|                         clusterService.getMembershipManager().getMembersView(), preJoinOp, postJoinOp,
   595|                         clusterClock.getClusterTime(), clusterService.getClusterId(),
   596|                         clusterClock.getClusterStartTime(), clusterStateManager.getState(),
   597|                         clusterService.getClusterVersion(), partitionRuntimeState, deferPartitionProcessing);
   598|                 op.setCallerUuid(clusterService.getThisUuid());
   599|                 invokeClusterOp(op, target);
   600|             }
   601|             return true;
   602|         }
   603|         if (clusterService.isMaster() || target.equals(clusterService.getMasterAddress())) {
   604|             String msg = format("New join request has been received from an existing endpoint %s."
   605|                     + " Removing old member and processing join request...", member);
   606|             logger.warning(msg);
   607|             clusterService.suspectMember(member, msg, false);
   608|             ServerConnection existing = node.getServer().getConnectionManager(MEMBER).get(target);
   609|             if (existing != connection) {


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/internal/diagnostics/HealthMonitor.java
# Total hunks: 3
# ====================================================================
# --- HUNK 1: Lines 225-372 ---
   225|                 = metricRegistry.newLongGauge("os.totalPhysicalMemorySize");
   226|         final LongGauge osFreePhysicalMemorySize
   227|                 = metricRegistry.newLongGauge("os.freePhysicalMemorySize");
   228|         final LongGauge osTotalSwapSpaceSize
   229|                 = metricRegistry.newLongGauge("os.totalSwapSpaceSize");
   230|         final LongGauge osFreeSwapSpaceSize
   231|                 = metricRegistry.newLongGauge("os.freeSwapSpaceSize");
   232|         final LongGauge operationServiceExecutorQueueSize
   233|                 = metricRegistry.newLongGauge("operation.queueSize");
   234|         final LongGauge operationServiceExecutorPriorityQueueSize
   235|                 = metricRegistry.newLongGauge("operation.priorityQueueSize");
   236|         final LongGauge operationServiceResponseQueueSize
   237|                 = metricRegistry.newLongGauge("operation.responseQueueSize");
   238|         final LongGauge operationServiceRunningOperationsCount
   239|                 = metricRegistry.newLongGauge("operation.runningCount");
   240|         final LongGauge operationServiceCompletedOperationsCount
   241|                 = metricRegistry.newLongGauge("operation.completedCount");
   242|         final LongGauge operationServicePendingInvocationsCount
   243|                 = metricRegistry.newLongGauge("operation.invocations.pending");
   244|         final DoubleGauge operationServicePendingInvocationsPercentage
   245|                 = metricRegistry.newDoubleGauge("operation.invocations.used");
   246|         final LongGauge proxyCount
   247|                 = metricRegistry.newLongGauge("proxy.proxyCount");
   248|         final LongGauge tcpConnectionActiveCount
   249|                 = metricRegistry.newLongGauge("tcp.connection.activeCount");
   250|         final LongGauge tcpConnectionCount
   251|                 = metricRegistry.newLongGauge("tcp.connection.count");
   252|         final LongGauge tcpConnectionClientCount
   253|                 = metricRegistry.newLongGauge("tcp.connection.clientCount");
   254|         private final StringBuilder sb = new StringBuilder();
   255|         private double memoryUsedOfTotalPercentage;
   256|         private double memoryUsedOfMaxPercentage;
   257|         public void update() {
   258|             memoryUsedOfTotalPercentage = (PERCENTAGE_MULTIPLIER * runtimeUsedMemory.read()) / runtimeTotalMemory.read();
   259|             memoryUsedOfMaxPercentage = (PERCENTAGE_MULTIPLIER * runtimeUsedMemory.read()) / runtimeMaxMemory.read();
   260|         }
   261|         boolean exceedsThreshold() {
   262|             if (memoryUsedOfMaxPercentage > thresholdMemoryPercentage) {
   263|                 return true;
   264|             }
   265|             if (osProcessCpuLoad.read() > thresholdCPUPercentage) {
   266|                 return true;
   267|             }
   268|             if (osSystemCpuLoad.read() > thresholdCPUPercentage) {
   269|                 return true;
   270|             }
   271|             if (operationServicePendingInvocationsPercentage.read() > THRESHOLD_PERCENTAGE_INVOCATIONS) {
   272|                 return true;
   273|             }
   274|             if (operationServicePendingInvocationsCount.read() > THRESHOLD_INVOCATIONS) {
   275|                 return true;
   276|             }
   277|             return false;
   278|         }
   279|         public String render() {
   280|             update();
   281|             sb.setLength(0);
   282|             renderProcessors();
   283|             renderPhysicalMemory();
   284|             renderSwap();
   285|             renderHeap();
   286|             renderNativeMemory();
   287|             renderGc();
   288|             renderLoad();
   289|             renderThread();
   290|             renderCluster();
   291|             renderEvents();
   292|             renderExecutors();
   293|             renderOperationService();
   294|             renderProxy();
   295|             renderClient();
   296|             renderConnection();
   297|             return sb.toString();
   298|         }
   299|         private void renderConnection() {
   300|             sb.append("connection.active.count=")
   301|                     .append(tcpConnectionActiveCount.read()).append(", ");
   302|             sb.append("client.connection.count=")
   303|                     .append(tcpConnectionClientCount.read()).append(", ");
   304|             sb.append("connection.count=")
   305|                     .append(tcpConnectionCount.read());
   306|         }
   307|         private void renderClient() {
   308|             sb.append("clientEndpoint.count=")
   309|                     .append(clientEndpointCount.read()).append(", ");
   310|         }
   311|         private void renderProxy() {
   312|             sb.append("proxy.count=")
   313|                     .append(proxyCount.read()).append(", ");
   314|         }
   315|         private void renderLoad() {
   316|             sb.append("load.process").append('=')
   317|                     .append(format("%.2f", osProcessCpuLoad.read())).append("%, ");
   318|             sb.append("load.system").append('=')
   319|                     .append(format("%.2f", osSystemCpuLoad.read())).append("%, ");
   320|             double value = osSystemLoadAverage.read();
   321|             if (value < 0) {
   322|                 sb.append("load.systemAverage").append("=n/a ");
   323|             } else {
   324|                 sb.append("load.systemAverage").append('=')
   325|                         .append(format("%.2f", osSystemLoadAverage.read())).append(", ");
   326|             }
   327|         }
   328|         private void renderProcessors() {
   329|             sb.append("processors=")
   330|                     .append(runtimeAvailableProcessors.read()).append(", ");
   331|         }
   332|         private void renderPhysicalMemory() {
   333|             sb.append("physical.memory.total=")
   334|                     .append(numberToUnit(osTotalPhysicalMemorySize.read())).append(", ");
   335|             sb.append("physical.memory.free=")
   336|                     .append(numberToUnit(osFreePhysicalMemorySize.read())).append(", ");
   337|         }
   338|         private void renderSwap() {
   339|             sb.append("swap.space.total=")
   340|                     .append(numberToUnit(osTotalSwapSpaceSize.read())).append(", ");
   341|             sb.append("swap.space.free=")
   342|                     .append(numberToUnit(osFreeSwapSpaceSize.read())).append(", ");
   343|         }
   344|         private void renderHeap() {
   345|             sb.append("heap.memory.used=")
   346|                     .append(numberToUnit(runtimeUsedMemory.read())).append(", ");
   347|             sb.append("heap.memory.free=")
   348|                     .append(numberToUnit(runtimeFreeMemory.read())).append(", ");
   349|             sb.append("heap.memory.total=")
   350|                     .append(numberToUnit(runtimeTotalMemory.read())).append(", ");
   351|             sb.append("heap.memory.max=")
   352|                     .append(numberToUnit(runtimeMaxMemory.read())).append(", ");
   353|             sb.append("heap.memory.used/total=")
   354|                     .append(percentageString(memoryUsedOfTotalPercentage)).append(", ");
   355|             sb.append("heap.memory.used/max=")
   356|                     .append(percentageString(memoryUsedOfMaxPercentage)).append((", "));
   357|         }
   358|         private void renderEvents() {
   359|             sb.append("event.q.size=")
   360|                     .append(eventQueueSize.read()).append(", ");
   361|         }
   362|         private void renderCluster() {
   363|             sb.append("cluster.timeDiff=")
   364|                     .append(clusterTimeDiff.read()).append(", ");
   365|         }
   366|         private void renderThread() {
   367|             sb.append("thread.count=")
   368|                     .append(threadThreadCount.read()).append(", ");
   369|             sb.append("thread.peakCount=")
   370|                     .append(threadPeakThreadCount.read()).append(", ");
   371|         }
   372|         private void renderGc() {

# --- HUNK 2: Lines 427-469 ---
   427|                     .append(executorSystemQueueSize.read()).append(", ");
   428|             sb.append("executor.q.operations.size=")
   429|                     .append(operationServiceExecutorQueueSize.read()).append(", ");
   430|             sb.append("executor.q.priorityOperation.size=").
   431|                     append(operationServiceExecutorPriorityQueueSize.read()).append(", ");
   432|             sb.append("operations.completed.count=")
   433|                     .append(operationServiceCompletedOperationsCount.read()).append(", ");
   434|             sb.append("executor.q.mapLoad.size=")
   435|                     .append(executorMapLoadQueueSize.read()).append(", ");
   436|             sb.append("executor.q.mapLoadAllKeys.size=")
   437|                     .append(executorMapLoadAllKeysQueueSize.read()).append(", ");
   438|             sb.append("executor.q.cluster.size=")
   439|                     .append(executorClusterQueueSize.read()).append(", ");
   440|         }
   441|         private void renderOperationService() {
   442|             sb.append("executor.q.response.size=")
   443|                     .append(operationServiceResponseQueueSize.read()).append(", ");
   444|             sb.append("operations.running.count=")
   445|                     .append(operationServiceRunningOperationsCount.read()).append(", ");
   446|             sb.append("operations.pending.invocations.percentage=")
   447|                     .append(format("%.2f", operationServicePendingInvocationsPercentage.read())).append("%, ");
   448|             sb.append("operations.pending.invocations.count=")
   449|                     .append(operationServicePendingInvocationsCount.read()).append(", ");
   450|         }
   451|     }
   452|     /**
   453|      * Given a number, returns that number as a percentage string.
   454|      *
   455|      * @param p the given number
   456|      * @return a string of the given number as a format float with two decimal places and a period
   457|      */
   458|     private static String percentageString(double p) {
   459|         return format("%.2f%%", p);
   460|     }
   461|     @SuppressWarnings("checkstyle:magicnumber")
   462|     private static String numberToUnit(long number) {
   463|         for (int i = 6; i > 0; i--) {
   464|             double step = Math.pow(1024, i);
   465|             if (number > step) {
   466|                 return format("%3.1f%s", number / step, UNITS[i]);
   467|             }
   468|         }
   469|         return Long.toString(number);


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/internal/eviction/ClearExpiredRecordsTask.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 75-118 ---
    75|         HazelcastProperties properties = nodeEngine.getProperties();
    76|         this.cleanupOperationCount = calculateCleanupOperationCount(properties, cleanupOpProperty, partitionCount,
    77|                 operationService.getPartitionThreadCount());
    78|         checkPositive(cleanupOperationCount, "cleanupOperationCount should be a positive number");
    79|         this.cleanupPercentage = properties.getInteger(cleanupPercentageProperty);
    80|         checkTrue(cleanupPercentage > 0 && cleanupPercentage <= 100,
    81|                 "cleanupPercentage should be in range (0,100]");
    82|         this.taskPeriodSeconds = properties.getSeconds(taskPeriodProperty);
    83|         this.cleanupEnabled = properties.getBoolean(cleanupEnabled);
    84|         this.toBackupSender = newToBackupSender(serviceName, newBackupExpiryOpSupplier(),
    85|                 newBackupExpiryOpFilter(), nodeEngine);
    86|     }
    87|     protected BiFunction<Integer, Integer, Boolean> newBackupExpiryOpFilter() {
    88|         return (partitionId, replicaIndex) -> {
    89|             IPartition partition = partitionService.getPartition(partitionId);
    90|             return partition.getReplicaAddress(replicaIndex) != null;
    91|         };
    92|     }
    93|     @Override
    94|     public void run() {
    95|         try {
    96|             if (!singleRunPermit.compareAndSet(false, true)) {
    97|                 return;
    98|             }
    99|             runInternal();
   100|         } finally {
   101|             singleRunPermit.set(false);
   102|         }
   103|     }
   104|     private void runInternal() {
   105|         runningCleanupOperationsCount = 0;
   106|         long nowInMillis = nowInMillis();
   107|         boolean lostPartitionDetected = lostPartitionDetected();
   108|         List<T> containersToProcess = null;
   109|         for (int partitionId = 0; partitionId < partitionCount; partitionId++) {
   110|             T container = this.containers[partitionId];
   111|             IPartition partition = partitionService.getPartition(partitionId, false);
   112|             if (partition.isMigrating()) {
   113|                 continue;
   114|             }
   115|             if (partition.isLocal()) {
   116|                 if (lostPartitionDetected) {
   117|                     equalizeBackupSizeWithPrimary(container);
   118|                 }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/internal/metrics/MetricDescriptorConstants.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 319-361 ---
   319|     public static final String OPERATION_METRIC_PARTITION_OPERATION_THREAD_NORMAL_PENDING_COUNT = "normalPendingCount";
   320|     public static final String OPERATION_METRIC_PARTITION_OPERATION_THREAD_PRIORITY_PENDING_COUNT = "priorityPendingCount";
   321|     public static final String OPERATION_METRIC_PARKER_PARK_QUEUE_COUNT = "parkQueueCount";
   322|     public static final String OPERATION_METRIC_PARKER_TOTAL_PARKED_OPERATION_COUNT = "totalParkedOperationCount";
   323|     public static final String OPERATION_METRIC_INBOUND_RESPONSE_HANDLER_RESPONSE_QUEUE_SIZE = "responseQueueSize";
   324|     public static final String OPERATION_METRIC_INBOUND_RESPONSE_HANDLER_RESPONSES_NORMAL_COUNT = "responses.normalCount";
   325|     public static final String OPERATION_METRIC_INBOUND_RESPONSE_HANDLER_RESPONSES_TIMEOUT_COUNT = "responses.timeoutCount";
   326|     public static final String OPERATION_METRIC_INBOUND_RESPONSE_HANDLER_RESPONSES_BACKUP_COUNT = "responses.backupCount";
   327|     public static final String OPERATION_METRIC_INBOUND_RESPONSE_HANDLER_RESPONSES_ERROR_COUNT = "responses.errorCount";
   328|     public static final String OPERATION_METRIC_INBOUND_RESPONSE_HANDLER_RESPONSES_MISSING_COUNT = "responses.missingCount";
   329|     public static final String OPERATION_METRIC_INVOCATION_MONITOR_BACKUP_TIMEOUTS = "backupTimeouts";
   330|     public static final String OPERATION_METRIC_INVOCATION_MONITOR_NORMAL_TIMEOUTS = "normalTimeouts";
   331|     public static final String OPERATION_METRIC_INVOCATION_MONITOR_HEARTBEAT_PACKETS_RECEIVED = "heartbeatPacketsReceived";
   332|     public static final String OPERATION_METRIC_INVOCATION_MONITOR_HEARTBEAT_PACKETS_SENT = "heartbeatPacketsSent";
   333|     public static final String OPERATION_METRIC_INVOCATION_MONITOR_DELAYED_EXECUTION_COUNT = "delayedExecutionCount";
   334|     public static final String OPERATION_METRIC_INVOCATION_MONITOR_BACKUP_TIMEOUT_MILLIS = "backupTimeoutMillis";
   335|     public static final String OPERATION_METRIC_INVOCATION_MONITOR_INVOCATION_TIMEOUT_MILLIS = "invocationTimeoutMillis";
   336|     public static final String OPERATION_METRIC_INVOCATION_MONITOR_HEARTBEAT_BROADCAST_PERIOD_MILLIS =
   337|             "heartbeatBroadcastPeriodMillis";
   338|     public static final String OPERATION_METRIC_INVOCATION_MONITOR_INVOCATION_SCAN_PERIOD_MILLIS = "invocationScanPeriodMillis";
   339|     public static final String OPERATION_METRIC_INVOCATION_REGISTRY_INVOCATIONS_USED_PERCENTAGE = "invocations.usedPercentage";
   340|     public static final String OPERATION_METRIC_INVOCATION_REGISTRY_INVOCATIONS_LAST_CALL_ID = "invocations.lastCallId";
   341|     public static final String OPERATION_METRIC_INVOCATION_REGISTRY_INVOCATIONS_PENDING = "invocations.pending";
   342|     public static final String OPERATION_METRIC_OPERATION_RUNNER_EXECUTED_OPERATIONS_COUNT = "executedOperationsCount";
   343|     public static final String OPERATION_METRIC_OPERATION_SERVICE_ASYNC_OPERATIONS = "asyncOperations";
   344|     public static final String OPERATION_METRIC_OPERATION_SERVICE_TIMEOUT_COUNT = "operationTimeoutCount";
   345|     public static final String OPERATION_METRIC_OPERATION_SERVICE_CALL_TIMEOUT_COUNT = "callTimeoutCount";
   346|     public static final String OPERATION_METRIC_OPERATION_SERVICE_RETRY_COUNT = "retryCount";
   347|     public static final String OPERATION_METRIC_OPERATION_SERVICE_FAILED_BACKUPS = "failedBackups";
   348|     public static final String OS_FULL_METRIC_COMMITTED_VIRTUAL_MEMORY_SIZE = "os.committedVirtualMemorySize";
   349|     public static final String OS_FULL_METRIC_FREE_PHYSICAL_MEMORY_SIZE = "os.freePhysicalMemorySize";
   350|     public static final String OS_FULL_METRIC_FREE_SWAP_SPACE_SIZE = "os.freeSwapSpaceSize";
   351|     public static final String OS_FULL_METRIC_PROCESS_CPU_TIME = "os.processCpuTime";
   352|     public static final String OS_FULL_METRIC_TOTAL_PHYSICAL_MEMORY_SIZE = "os.totalPhysicalMemorySize";
   353|     public static final String OS_FULL_METRIC_TOTAL_SWAP_SPACE_SIZE = "os.totalSwapSpaceSize";
   354|     public static final String OS_FULL_METRIC_MAX_FILE_DESCRIPTOR_COUNT = "os.maxFileDescriptorCount";
   355|     public static final String OS_FULL_METRIC_OPEN_FILE_DESCRIPTOR_COUNT = "os.openFileDescriptorCount";
   356|     public static final String OS_FULL_METRIC_PROCESS_CPU_LOAD = "os.processCpuLoad";
   357|     public static final String OS_FULL_METRIC_SYSTEM_CPU_LOAD = "os.systemCpuLoad";
   358|     public static final String OS_FULL_METRIC_SYSTEM_LOAD_AVERAGE = "os.systemLoadAverage";
   359|     public static final String PARTITIONS_PREFIX = "partitions";
   360|     public static final String PARTITIONS_METRIC_PARTITION_SERVICE_MAX_BACKUP_COUNT = "maxBackupCount";
   361|     public static final String PARTITIONS_METRIC_PARTITION_SERVICE_MIGRATION_QUEUE_SIZE = "migrationQueueSize";


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/internal/networking/InboundPipeline.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 23-89 ---
    23|  * instances and the pipeline can be dynamically be modified.
    24|  *
    25|  * <h1>Spurious wakeups</h1>
    26|  * InboundHandlers/OutboundHandlers need to be able to deal with
    27|  * spurious wakeups. E.g. it could be that a PacketDecoder is called without
    28|  * any Packets being available.
    29|  *
    30|  * <h1>Automatic reprocessing on change</h1>
    31|  * When a change in the pipeline is detected, the pipeline is automatically
    32|  * reprocessed. For example when the ProtocolDecoder replaced itself by a
    33|  * PacketDecoder, the whole pipeline (in this case the PacketDecoder) is
    34|  * automatically reprocessed.
    35|  */
    36| public interface InboundPipeline {
    37|     /**
    38|      * Adds the handlers at the end of the pipeline.
    39|      *
    40|      * No verification is done if the handler is already added and a handler
    41|      * should only be added once.
    42|      *
    43|      * This method should only be made on the thread 'owning' the handler.
    44|      *
    45|      * @param handlers the handlers to add
    46|      * @return this
    47|      */
    48|     InboundPipeline addLast(InboundHandler... handlers);
    49|     /**
    50|      * Replaces the old InboundHandler by the new ones. So if there
    51|      * is a sequence of handlers [H1,H2,H3] and H2 gets replaced by [H4,H5]
    52|      * the new pipeline will be [H1,H4,H5,H3].
    53|      *
    54|      * No verification is done if any of the handlers is already added and a
    55|      * handler should only be added once.
    56|      *
    57|      * This method should only be made on the thread 'owning' the handler.
    58|      *
    59|      * @param oldHandler  the handler to replace
    60|      * @param newHandlers the new handlers to insert
    61|      * @return this
    62|      * @throws IllegalArgumentException is the oldHandler isn't part of this
    63|      *                                  pipeline.
    64|      */
    65|     InboundPipeline replace(InboundHandler oldHandler, InboundHandler... newHandlers);
    66|     /**
    67|      * Removes the given handler from the pipeline.
    68|      *
    69|      * This method should only be made on the thread 'owning' the handler.
    70|      *
    71|      * @param handler the handler to remove
    72|      * @return this
    73|      * @throws IllegalArgumentException is the handler isn't part of this
    74|      *                                  pipeline.
    75|      */
    76|     InboundPipeline remove(InboundHandler handler);
    77|     /**
    78|      * Wakes up the inbound pipeline and lets it to start reading again from the
    79|      * network.
    80|      *
    81|      * Even if there is no data to be read, it will cause at least one processing
    82|      * of the InboundPipeline. This will force any buffered data to be pushed
    83|      * through the InboundPipeline.
    84|      *
    85|      * This method is threadsafe and can safely be called from any thread.
    86|      *
    87|      * Calling it while it is already waken up will not do any damage, it will
    88|      * just cause some temporary overhead.
    89|      *


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/internal/networking/OutboundPipeline.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 8-74 ---
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.internal.networking;
    17| /**
    18|  * The outbound pipeline of a {@link Channel}. So all data that gets
    19|  * written to the network, goes through the outbound pipeline.
    20|  */
    21| public interface OutboundPipeline {
    22|     /**
    23|      * Adds the handlers at the end of the pipeline
    24|      *
    25|      * No verification is done if the handler is already added and a handler
    26|      * should only be added once.
    27|      *
    28|      * This method should only be made on the thread 'owning' the handler.
    29|      *
    30|      * @param handlers the handlers to add.
    31|      * @return this
    32|      */
    33|     OutboundPipeline addLast(OutboundHandler... handlers);
    34|     /**
    35|      * Replaces the old OutboundHandler by the new ones. So if there
    36|      * is a sequence of handlers [H1,H2,H3] and H2 gets replaced by [H4,H5]
    37|      * the new pipeline will be [H1,H4,H5,H3].
    38|      *
    39|      * No verification is done if any of the handlers is already added and a
    40|      * handler should only be added once.
    41|      *
    42|      * This method should only be made on the thread 'owning' the handler.
    43|      *
    44|      * @param oldHandler  the handlers to replace
    45|      * @param newHandlers the new handlers to insert.
    46|      * @return this
    47|      * @throws IllegalArgumentException is the oldHandler isn't part of this
    48|      *                                  pipeline.
    49|      */
    50|     OutboundPipeline replace(OutboundHandler oldHandler, OutboundHandler... newHandlers);
    51|     /**
    52|      * Removes the given handler from the pipeline.
    53|      *
    54|      * This method should only be made on the thread 'owning' the handler.
    55|      *
    56|      * @param handler the handler to remove.
    57|      * @return this
    58|      * @throws IllegalArgumentException is the handler isn't part of this
    59|      *                                  pipeline.
    60|      */
    61|     OutboundPipeline remove(OutboundHandler handler);
    62|     /**
    63|      * Request to flush all data to flush from the handlers to
    64|      * the network.
    65|      *
    66|      * It will cause at least one processing of the OutboundPipeline.
    67|      *
    68|      * This method is threadsafe and can safely be called from any thread.
    69|      *
    70|      * Calling it while there is nothing in the pipeline will not do any damage,
    71|      * apart from consuming cpu cycles.
    72|      *
    73|      * This can be used for example, with protocol or handshaking. So imagine
    74|      * there is a handshake decoder (e.g. protocol or TLS), that as soon as it


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/internal/server/tcp/MemberChannelInitializer.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 15-41 ---
    15|  */
    16| package com.hazelcast.internal.server.tcp;
    17| import com.hazelcast.config.EndpointConfig;
    18| import com.hazelcast.instance.EndpointQualifier;
    19| import com.hazelcast.instance.ProtocolType;
    20| import com.hazelcast.internal.networking.Channel;
    21| import com.hazelcast.internal.networking.InboundHandler;
    22| import com.hazelcast.internal.networking.OutboundHandler;
    23| import com.hazelcast.internal.server.ServerContext;
    24| import com.hazelcast.internal.server.ServerConnection;
    25| public class MemberChannelInitializer
    26|         extends AbstractChannelInitializer {
    27|     MemberChannelInitializer(ServerContext serverContext, EndpointConfig config) {
    28|         super(serverContext, config);
    29|     }
    30|     @Override
    31|     public void initChannel(Channel channel) {
    32|         ServerConnection connection = (TcpServerConnection) channel.attributeMap().get(ServerConnection.class);
    33|         OutboundHandler[] outboundHandlers = serverContext.createOutboundHandlers(EndpointQualifier.MEMBER, connection);
    34|         InboundHandler[] inboundHandlers = serverContext.createInboundHandlers(EndpointQualifier.MEMBER, connection);
    35|         SingleProtocolEncoder protocolEncoder = new SingleProtocolEncoder(new MemberProtocolEncoder(outboundHandlers));
    36|         SingleProtocolDecoder protocolDecoder = new SingleProtocolDecoder(ProtocolType.MEMBER,
    37|                 inboundHandlers, protocolEncoder, true);
    38|         channel.outboundPipeline().addLast(protocolEncoder);
    39|         channel.inboundPipeline().addLast(protocolDecoder);
    40|     }
    41| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/internal/server/tcp/MemberProtocolEncoder.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 9-85 ---
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.internal.server.tcp;
    17| import com.hazelcast.internal.networking.HandlerStatus;
    18| import com.hazelcast.internal.networking.OutboundHandler;
    19| import com.hazelcast.internal.nio.ConnectionType;
    20| import com.hazelcast.internal.server.ServerConnection;
    21| import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;
    22| import java.nio.ByteBuffer;
    23| import static com.hazelcast.internal.networking.HandlerStatus.CLEAN;
    24| import static com.hazelcast.internal.networking.HandlerStatus.DIRTY;
    25| import static com.hazelcast.internal.nio.IOUtil.compactOrClear;
    26| import static com.hazelcast.internal.nio.Protocols.CLUSTER;
    27| import static com.hazelcast.internal.nio.Protocols.PROTOCOL_LENGTH;
    28| import static com.hazelcast.internal.util.StringUtil.stringToBytes;
    29| public class MemberProtocolEncoder extends OutboundHandler<Void, ByteBuffer> {
    30|     private final OutboundHandler[] outboundHandlers;
    31|     private volatile boolean encoderCanReplace;
    32|     private boolean clusterProtocolBuffered;
    33|     /**
    34|      * Decodes first 3 incoming bytes, validates against {@code supportedProtocol} and, when
    35|      * matching, replaces itself in the inbound pipeline with the {@code next InboundHandler}.
    36|      *
    37|      * @param next the {@link OutboundHandler} to replace this one in the outbound pipeline
    38|      *             upon match of protocol bytes
    39|      */
    40|     @SuppressFBWarnings("EI_EXPOSE_REP2")
    41|     public MemberProtocolEncoder(OutboundHandler[] next) {
    42|         this.outboundHandlers = next;
    43|     }
    44|     @Override
    45|     public void handlerAdded() {
    46|         initDstBuffer(PROTOCOL_LENGTH);
    47|     }
    48|     @Override
    49|     public HandlerStatus onWrite() {
    50|         compactOrClear(dst);
    51|         try {
    52|             if (!clusterProtocolBuffered) {
    53|                 clusterProtocolBuffered = true;
    54|                 dst.put(stringToBytes(CLUSTER));
    55|                 return DIRTY;
    56|             }
    57|             if (!isProtocolBufferDrained()) {
    58|                 return DIRTY;
    59|             }
    60|             if (encoderCanReplace) {
    61|                 ServerConnection connection = (TcpServerConnection) channel.attributeMap().get(ServerConnection.class);
    62|                 connection.setConnectionType(ConnectionType.MEMBER);
    63|                 channel.outboundPipeline().replace(this, outboundHandlers);
    64|             }
    65|             return CLEAN;
    66|         } finally {
    67|             dst.flip();
    68|         }
    69|     }
    70|     public void signalEncoderCanReplace() {
    71|         encoderCanReplace = true;
    72|         channel.outboundPipeline().wakeup();
    73|     }
    74|     /**
    75|      * Checks if the protocol bytes have been drained.
    76|      *
    77|      * The protocol buffer is in write mode, so if position is 0, the protocol
    78|      * buffer has been drained.
    79|      *
    80|      * @return true if the protocol buffer has been drained.
    81|      */
    82|     private boolean isProtocolBufferDrained() {
    83|         return dst.position() == 0;
    84|     }
    85| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/internal/server/tcp/SingleProtocolDecoder.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 27-128 ---
    27| import static com.hazelcast.internal.nio.Protocols.UNEXPECTED_PROTOCOL;
    28| import static com.hazelcast.internal.util.StringUtil.bytesToString;
    29| /**
    30|  * Checks if the correct protocol is received then swaps itself with the next
    31|  * handler in the pipeline.
    32|  * <p>
    33|  * See also {@link SingleProtocolEncoder}
    34|  * </p>
    35|  */
    36| public class SingleProtocolDecoder
    37|         extends InboundHandler<ByteBuffer, Void> {
    38|     protected final InboundHandler[] inboundHandlers;
    39|     protected final ProtocolType supportedProtocol;
    40|     /**
    41|      * This flag is used to ensure that {@link #verifyProtocol(String)} is called only once
    42|      * with initial bytes of connection. Formerly, this method would be called multiple times
    43|      * with new incoming data, although it failed after its first call.
    44|      */
    45|     protected volatile boolean verifyProtocolCalled;
    46|     final SingleProtocolEncoder encoder;
    47|     private final boolean shouldSignalMemberProtocolEncoder;
    48|     public SingleProtocolDecoder(ProtocolType supportedProtocol, InboundHandler next, SingleProtocolEncoder encoder) {
    49|         this(supportedProtocol, new InboundHandler[]{next}, encoder, false);
    50|     }
    51|     /**
    52|      * Decodes first 3 incoming bytes, validates against {@code
    53|      * supportedProtocol} and, when matching, replaces itself in the inbound
    54|      * pipeline with the {@code next InboundHandler}s.
    55|      *
    56|      * @param supportedProtocol                 the {@link ProtocolType}
    57|      *                                          supported by this {@code
    58|      *                                          ProtocolDecoder}
    59|      * @param next                              the {@link InboundHandler}s to
    60|      *                                          replace this one in the inbound
    61|      *                                          pipeline upon match of protocol
    62|      *                                          bytes
    63|      * @param encoder                           a {@link SingleProtocolEncoder}
    64|      *                                          that will be notified when
    65|      *                                          non-matching protocol bytes have
    66|      *                                          been received
    67|      * @param shouldSignalMemberProtocolEncoder a boolean used to notify the
    68|      *                                          next encoder in the pipeline
    69|      *                                          after the {@link SingleProtocolEncoder}
    70|      *                                          when matching protocol bytes
    71|      *                                          have been received
    72|      */
    73|     @SuppressFBWarnings("EI_EXPOSE_REP2")
    74|     public SingleProtocolDecoder(ProtocolType supportedProtocol, InboundHandler[] next,
    75|                                  SingleProtocolEncoder encoder, boolean shouldSignalMemberProtocolEncoder) {
    76|         this.supportedProtocol = supportedProtocol;
    77|         this.inboundHandlers = next;
    78|         this.encoder = encoder;
    79|         this.shouldSignalMemberProtocolEncoder = shouldSignalMemberProtocolEncoder;
    80|         this.verifyProtocolCalled = false;
    81|     }
    82|     @Override
    83|     public void handlerAdded() {
    84|         initSrcBuffer(PROTOCOL_LENGTH);
    85|     }
    86|     @Override
    87|     public HandlerStatus onRead() {
    88|         src.flip();
    89|         try {
    90|             if (src.remaining() < PROTOCOL_LENGTH) {
    91|                 return CLEAN;
    92|             }
    93|             boolean verifyProtocolPreviouslyCalled = verifyProtocolCalled;
    94|             if (verifyProtocolPreviouslyCalled || !verifyProtocol(loadProtocol())) {
    95|                 if (verifyProtocolPreviouslyCalled) {
    96|                     src.position(src.limit());
    97|                 }
    98|                 return CLEAN;
    99|             }
   100|             encoder.signalProtocolVerified();
   101|             initConnection();
   102|             setupNextDecoder();
   103|             if (!channel.isClientMode()) {
   104|                 encoder.setupNextEncoder();
   105|             }
   106|             if (shouldSignalMemberProtocolEncoder) {
   107|                 ((MemberProtocolEncoder) encoder.getFirstOutboundHandler()).signalEncoderCanReplace();
   108|             }
   109|             return CLEAN;
   110|         } finally {
   111|             compactOrClear(src);
   112|         }
   113|     }
   114|     protected void setupNextDecoder() {
   115|         channel.inboundPipeline().replace(this, inboundHandlers);
   116|     }
   117|     protected boolean verifyProtocol(String incomingProtocol) {
   118|         verifyProtocolCalled = true;
   119|         if (!incomingProtocol.equals(supportedProtocol.getDescriptor())) {
   120|             handleUnexpectedProtocol(incomingProtocol);
   121|             encoder.signalWrongProtocol("Unsupported protocol exchange detected, expected protocol: "
   122|                     + supportedProtocol.name() + ", actual protocol or first three bytes are: " + incomingProtocol);
   123|             return false;
   124|         }
   125|         return true;
   126|     }
   127|     protected void handleUnexpectedProtocol(String incomingProtocol) {
   128|         if (incomingProtocol.equals(UNEXPECTED_PROTOCOL)) {


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/internal/server/tcp/SingleProtocolEncoder.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-103 ---
     1| /*
     2|  * Copyright (c) 2008-2021, Hazelcast, Inc. All Rights Reserved.
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.internal.server.tcp;
    17| import com.hazelcast.internal.networking.HandlerStatus;
    18| import com.hazelcast.internal.networking.OutboundHandler;
    19| import com.hazelcast.internal.nio.Protocols;
    20| import java.nio.ByteBuffer;
    21| import static com.hazelcast.internal.networking.HandlerStatus.CLEAN;
    22| import static com.hazelcast.internal.networking.HandlerStatus.DIRTY;
    23| import static com.hazelcast.internal.nio.IOUtil.compactOrClear;
    24| import static com.hazelcast.internal.nio.Protocols.PROTOCOL_LENGTH;
    25| import static com.hazelcast.internal.nio.Protocols.UNEXPECTED_PROTOCOL;
    26| import static com.hazelcast.internal.util.StringUtil.stringToBytes;
    27| /**
    28|  * Together with {@link SingleProtocolDecoder}, this encoder decoder pair is
    29|  * used for checking correct protocol is used or not. {@link
    30|  * SingleProtocolDecoder} checks if the correct protocol is received. If the
    31|  * protocol is correct, both encoder and decoder swaps itself with the next
    32|  * handler in the pipeline. If it isn't {@link SingleProtocolEncoder} throws
    33|  * {@link ProtocolException} and {@link SingleProtocolDecoder} sends {@value
    34|  * Protocols#UNEXPECTED_PROTOCOL}. Note that in client mode {@link
    35|  * SingleProtocolEncoder} has no effect, and it swaps itself with the next
    36|  * handler.
    37|  */
    38| public class SingleProtocolEncoder extends OutboundHandler<Void, ByteBuffer> {
    39|     private final OutboundHandler[] outboundHandlers;
    40|     private boolean clusterProtocolBuffered;
    41|     private volatile boolean isDecoderVerifiedProtocol;
    42|     private volatile boolean isDecoderReceivedProtocol;
    43|     private volatile String exceptionMessage;
    44|     public SingleProtocolEncoder(OutboundHandler next) {
    45|         this(new OutboundHandler[]{next});
    46|     }
    47|     public SingleProtocolEncoder(OutboundHandler[] next) {
    48|         this.outboundHandlers = next;
    49|     }
    50|     @Override
    51|     public HandlerStatus onWrite() throws Exception {
    52|         compactOrClear(dst);
    53|         try {
    54|             if (!isDecoderReceivedProtocol && !channel.isClientMode()) {
    55|                 return CLEAN;
    56|             }
    57|             if (!isDecoderVerifiedProtocol && !channel.isClientMode()) {
    58|                 if (!sendProtocol()) {
    59|                     return DIRTY;
    60|                 }
    61|                 throw new ProtocolException(exceptionMessage);
    62|             }
    63|             if (channel.isClientMode()) {
    64|                 setupNextEncoder();
    65|             }
    66|             return CLEAN;
    67|         } finally {
    68|             dst.flip();
    69|         }
    70|     }
    71|     private boolean sendProtocol() {
    72|         if (!clusterProtocolBuffered) {
    73|             clusterProtocolBuffered = true;
    74|             dst.put(stringToBytes(UNEXPECTED_PROTOCOL));
    75|             return false;
    76|         }
    77|         return isProtocolBufferDrained();
    78|     }
    79|     protected void setupNextEncoder() {
    80|         channel.outboundPipeline().replace(this, outboundHandlers);
    81|     }
    82|     @Override
    83|     public void handlerAdded() {
    84|         initDstBuffer(PROTOCOL_LENGTH);
    85|     }
    86|     private boolean isProtocolBufferDrained() {
    87|         return dst.position() == 0;
    88|     }
    89|     public void signalProtocolVerified() {
    90|         isDecoderVerifiedProtocol = true;
    91|         isDecoderReceivedProtocol = true;
    92|         channel.outboundPipeline().wakeup();
    93|     }
    94|     public void signalWrongProtocol(String exceptionMessage) {
    95|         this.exceptionMessage = exceptionMessage;
    96|         isDecoderVerifiedProtocol = false;
    97|         isDecoderReceivedProtocol = true;
    98|         channel.outboundPipeline().wakeup();
    99|     }
   100|     public OutboundHandler getFirstOutboundHandler() {
   101|         return outboundHandlers[0];
   102|     }
   103| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/internal/util/phonehome/CloudInfoCollector.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 48-85 ---
    48|                        Path dockerFilepath) {
    49|         awsEndpoint = awsEndPoint;
    50|         azureEndpoint = azureEndPoint;
    51|         gcpEndpoint = gcpEndPoint;
    52|         kubernetesTokenPath = kubernetesTokenpath;
    53|         dockerFilePath = dockerFilepath;
    54|     }
    55|     @Override
    56|     public void forEachMetric(Node node, BiConsumer<PhoneHomeMetrics, String> metricsConsumer) {
    57|         if (environmentInfo != null) {
    58|             environmentInfo.forEach(metricsConsumer);
    59|             return;
    60|         }
    61|         Map<PhoneHomeMetrics, String> info = MapUtil.createHashMap(2);
    62|         if (MetricsCollector.fetchWebService(awsEndpoint)) {
    63|             info.put(PhoneHomeMetrics.CLOUD, "A");
    64|         } else if (MetricsCollector.fetchWebService(azureEndpoint)) {
    65|             info.put(PhoneHomeMetrics.CLOUD, "Z");
    66|         } else if (MetricsCollector.fetchWebService(gcpEndpoint)) {
    67|             info.put(PhoneHomeMetrics.CLOUD, "G");
    68|         } else {
    69|             info.put(PhoneHomeMetrics.CLOUD, "N");
    70|         }
    71|         try {
    72|             dockerFilePath.toRealPath();
    73|             try {
    74|                 kubernetesTokenPath.toRealPath();
    75|                 info.put(PhoneHomeMetrics.DOCKER, "K");
    76|             } catch (IOException e) {
    77|                 info.put(PhoneHomeMetrics.DOCKER, "D");
    78|             }
    79|         } catch (IOException e) {
    80|             info.put(PhoneHomeMetrics.DOCKER, "N");
    81|         }
    82|         environmentInfo = info;
    83|         environmentInfo.forEach(metricsConsumer);
    84|     }
    85| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/internal/util/phonehome/MetricsCollector.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 10-49 ---
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.internal.util.phonehome;
    17| import com.hazelcast.instance.impl.Node;
    18| import java.net.HttpURLConnection;
    19| import java.net.URL;
    20| import java.util.function.BiConsumer;
    21| import static com.hazelcast.internal.util.EmptyStatement.ignore;
    22| /**
    23|  * Class responsible for collecting phone home data (phone home metrics).
    24|  *
    25|  * @see PhoneHomeMetrics
    26|  */
    27| interface MetricsCollector {
    28|     int TIMEOUT = 2000;
    29|     int RESPONSE_OK = 200;
    30|     int A_INTERVAL = 5;
    31|     int B_INTERVAL = 10;
    32|     int C_INTERVAL = 20;
    33|     int D_INTERVAL = 40;
    34|     int E_INTERVAL = 60;
    35|     int F_INTERVAL = 100;
    36|     int G_INTERVAL = 150;
    37|     int H_INTERVAL = 300;
    38|     int J_INTERVAL = 600;
    39|     /**
    40|      * Calls the {@code metricsConsumer} for each metric collected by this collector.
    41|      *
    42|      * @param node            this node
    43|      * @param metricsConsumer the consumer to call with the metric type and value
    44|      */
    45|     void forEachMetric(Node node, BiConsumer<PhoneHomeMetrics, String> metricsConsumer);
    46|     static String convertToLetter(int size) {
    47|         String letter;
    48|         if (size < A_INTERVAL) {
    49|             letter = "A";

# --- HUNK 2: Lines 51-91 ---
    51|             letter = "B";
    52|         } else if (size < C_INTERVAL) {
    53|             letter = "C";
    54|         } else if (size < D_INTERVAL) {
    55|             letter = "D";
    56|         } else if (size < E_INTERVAL) {
    57|             letter = "E";
    58|         } else if (size < F_INTERVAL) {
    59|             letter = "F";
    60|         } else if (size < G_INTERVAL) {
    61|             letter = "G";
    62|         } else if (size < H_INTERVAL) {
    63|             letter = "H";
    64|         } else if (size < J_INTERVAL) {
    65|             letter = "J";
    66|         } else {
    67|             letter = "I";
    68|         }
    69|         return letter;
    70|     }
    71|     static boolean fetchWebService(String urlStr) {
    72|         HttpURLConnection conn = null;
    73|         boolean response;
    74|         try {
    75|             URL url = new URL(urlStr);
    76|             conn = (HttpURLConnection) url.openConnection();
    77|             conn.setConnectTimeout(TIMEOUT);
    78|             conn.setReadTimeout(TIMEOUT);
    79|             conn.connect();
    80|             response = conn.getResponseCode() == RESPONSE_OK;
    81|         } catch (Exception ignored) {
    82|             ignore(ignored);
    83|             return false;
    84|         } finally {
    85|             if (conn != null) {
    86|                 conn.disconnect();
    87|             }
    88|         }
    89|         return response;
    90|     }
    91| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/jet/impl/JetInstanceImpl.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 5-117 ---
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.jet.impl;
    17| import com.hazelcast.cluster.Address;
    18| import com.hazelcast.cluster.Member;
    19| import com.hazelcast.core.MemberLeftException;
    20| import com.hazelcast.instance.impl.HazelcastInstanceImpl;
    21| import com.hazelcast.internal.util.Preconditions;
    22| import com.hazelcast.jet.Job;
    23| import com.hazelcast.jet.config.JetConfig;
    24| import com.hazelcast.jet.config.JobConfig;
    25| import com.hazelcast.jet.impl.operation.GetJobIdsOperation;
    26| import com.hazelcast.jet.impl.operation.GetJobIdsOperation.GetJobIdsResult;
    27| import com.hazelcast.logging.ILogger;
    28| import com.hazelcast.map.impl.MapService;
    29| import com.hazelcast.spi.exception.TargetNotMemberException;
    30| import com.hazelcast.spi.impl.NodeEngineImpl;
    31| import com.hazelcast.spi.impl.operationservice.impl.InvocationFuture;
    32| import javax.annotation.Nonnull;
    33| import java.util.Collection;
    34| import java.util.HashMap;
    35| import java.util.Map;
    36| import java.util.Map.Entry;
    37| import java.util.concurrent.CompletableFuture;
    38| import java.util.concurrent.ExecutionException;
    39| import static com.hazelcast.cluster.memberselector.MemberSelectors.DATA_MEMBER_SELECTOR;
    40| import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;
    41| import static java.util.Collections.singleton;
    42| /**
    43|  * Member-side {@code JetInstance} implementation
    44|  */
    45| public class JetInstanceImpl extends AbstractJetInstance<Address> {
    46|     private final NodeEngineImpl nodeEngine;
    47|     private final JetConfig config;
    48|     JetInstanceImpl(HazelcastInstanceImpl hazelcastInstance, JetConfig config) {
    49|         super(hazelcastInstance);
    50|         this.nodeEngine = hazelcastInstance.node.getNodeEngine();
    51|         this.config = config;
    52|     }
    53|     @Nonnull @Override
    54|     public JetConfig getConfig() {
    55|         return config;
    56|     }
    57|     @Override
    58|     public Address getMasterId() {
    59|         return Preconditions.checkNotNull(nodeEngine.getMasterAddress(), "Cluster has not elected a master");
    60|     }
    61|     @Override
    62|     public Map<Address, GetJobIdsResult> getJobsInt(String onlyName, Long onlyJobId) {
    63|         Map<Address, CompletableFuture<GetJobIdsResult>> futures = new HashMap<>();
    64|         Address masterAddress = null;
    65|         Collection<Member> targetMembers = onlyName == null
    66|                 ? nodeEngine.getClusterService().getMembers(DATA_MEMBER_SELECTOR)
    67|                 : singleton(nodeEngine.getClusterService().getMembers().iterator().next());
    68|         for (Member member : targetMembers) {
    69|             if (masterAddress == null) {
    70|                 masterAddress = member.getAddress();
    71|             }
    72|             GetJobIdsOperation operation = new GetJobIdsOperation(onlyName, onlyJobId);
    73|             InvocationFuture<GetJobIdsResult> future = nodeEngine
    74|                     .getOperationService()
    75|                     .createInvocationBuilder(JetServiceBackend.SERVICE_NAME, operation, member.getAddress())
    76|                     .invoke();
    77|             futures.put(member.getAddress(), future);
    78|         }
    79|         Map<Address, GetJobIdsResult> res = new HashMap<>(futures.size());
    80|         for (Entry<Address, CompletableFuture<GetJobIdsResult>> en : futures.entrySet()) {
    81|             GetJobIdsResult result;
    82|             try {
    83|                 result = en.getValue().get();
    84|             } catch (InterruptedException e) {
    85|                 Thread.currentThread().interrupt();
    86|                 result = GetJobIdsResult.EMPTY;
    87|             } catch (ExecutionException e) {
    88|                 if (!en.getKey().equals(masterAddress)
    89|                         && (e.getCause() instanceof TargetNotMemberException || e.getCause() instanceof MemberLeftException)) {
    90|                     result = GetJobIdsResult.EMPTY;
    91|                 } else {
    92|                     throw new RuntimeException("Error when getting job IDs: " + e, e);
    93|                 }
    94|             }
    95|             res.put(en.getKey(), result);
    96|         }
    97|         return res;
    98|     }
    99|     @Override
   100|     public void shutdown() {
   101|         try {
   102|             JetServiceBackend jetServiceBackend = nodeEngine.getService(JetServiceBackend.SERVICE_NAME);
   103|             jetServiceBackend.shutDownJobs();
   104|             super.shutdown();
   105|         } catch (Throwable t) {
   106|             throw rethrow(t);
   107|         }
   108|     }
   109|     /**
   110|      * Tells whether this member knows of the given object name.
   111|      * <p>
   112|      * Notes:
   113|      * <ul><li>
   114|      *     this member might not know it exists if the proxy creation operation went wrong
   115|      * </li><li>
   116|      *     this member might not know it was destroyed if the destroy operation went wrong
   117|      * </li><li>


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/jet/impl/util/ExceptionUtil.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 175-195 ---
   175|      * another JetException explaining the possible reason.
   176|      * <p>
   177|      * This is a hack to improve readability of this common exception.
   178|      *
   179|      * @param e the exception to handle
   180|      * @return the given exception wrapped, if it is a case of CCE for SerializedLambda
   181|      *     or the given exception otherwise
   182|      */
   183|     public static RuntimeException handleSerializedLambdaCce(HazelcastSerializationException e) {
   184|         Throwable cause = e.getCause();
   185|         while (cause != null) {
   186|             if (cause instanceof ClassCastException
   187|                     && cause.getMessage().startsWith("cannot assign instance of java.lang.invoke.SerializedLambda")) {
   188|                 throw new JetException("Class containing the lambda probably missing from class path, did you add it " +
   189|                         "using JobConfig.addClass()?: " + e, e);
   190|             }
   191|             cause = cause.getCause();
   192|         }
   193|         throw e;
   194|     }
   195| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/map/impl/EntryViews.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 12-61 ---
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.map.impl;
    17| import com.hazelcast.core.EntryView;
    18| import com.hazelcast.internal.serialization.Data;
    19| import com.hazelcast.internal.serialization.SerializationService;
    20| import com.hazelcast.map.impl.record.Record;
    21| import com.hazelcast.map.impl.recordstore.expiry.ExpiryMetadata;
    22| import com.hazelcast.map.impl.wan.WanMapEntryView;
    23| /**
    24|  * A class providing static factory methods that create various entry view objects.
    25|  */
    26| public final class EntryViews {
    27|     private EntryViews() {
    28|     }
    29|     public static <K, V> EntryView<K, V> createSimpleEntryView() {
    30|         return new SimpleEntryView<>();
    31|     }
    32|     public static <K, V> EntryView<K, V> createSimpleEntryView(K key, V value, Record record,
    33|                                                                ExpiryMetadata expiryMetadata) {
    34|         return new SimpleEntryView<>(key, value)
    35|                 .withCost(record.getCost())
    36|                 .withVersion(record.getVersion())
    37|                 .withHits(record.getHits())
    38|                 .withLastAccessTime(record.getLastAccessTime())
    39|                 .withLastUpdateTime(record.getLastUpdateTime())
    40|                 .withCreationTime(record.getCreationTime())
    41|                 .withLastStoredTime(record.getLastStoredTime())
    42|                 .withTtl(expiryMetadata.getTtl())
    43|                 .withMaxIdle(expiryMetadata.getMaxIdle())
    44|                 .withExpirationTime(expiryMetadata.getExpirationTime());
    45|     }
    46|     public static <K, V> WanMapEntryView<K, V> createWanEntryView(Data key, Data value,
    47|                                                                   Record<V> record, ExpiryMetadata expiryMetadata,
    48|                                                                   SerializationService serializationService) {
    49|         return new WanMapEntryView<K, V>(key, value, serializationService)
    50|                 .withCost(record.getCost())
    51|                 .withVersion(record.getVersion())
    52|                 .withHits(record.getHits())
    53|                 .withLastAccessTime(record.getLastAccessTime())
    54|                 .withLastUpdateTime(record.getLastUpdateTime())
    55|                 .withCreationTime(record.getCreationTime())
    56|                 .withLastStoredTime(record.getLastStoredTime())
    57|                 .withTtl(expiryMetadata.getTtl())
    58|                 .withMaxIdle(expiryMetadata.getMaxIdle())
    59|                 .withExpirationTime(expiryMetadata.getExpirationTime());
    60|     }
    61| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/map/impl/MapPartitionAwareService.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-53 ---
     1| /*
     2|  * Copyright (c) 2008-2021, Hazelcast, Inc. All Rights Reserved.
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.map.impl;
    17| import com.hazelcast.core.DistributedObject;
    18| import com.hazelcast.map.impl.proxy.MapProxyImpl;
    19| import com.hazelcast.cluster.Address;
    20| import com.hazelcast.spi.impl.NodeEngine;
    21| import com.hazelcast.internal.partition.PartitionAwareService;
    22| import com.hazelcast.spi.impl.proxyservice.ProxyService;
    23| import com.hazelcast.internal.partition.IPartitionLostEvent;
    24| import java.util.Collection;
    25| /**
    26|  * Defines partition-aware operations' behavior of map service.
    27|  * Currently, it only defines the behavior for partition lost occurrences
    28|  *
    29|  * @see IPartitionLostEvent
    30|  */
    31| class MapPartitionAwareService implements PartitionAwareService {
    32|     private final MapServiceContext mapServiceContext;
    33|     private final NodeEngine nodeEngine;
    34|     private final ProxyService proxyService;
    35|     MapPartitionAwareService(MapServiceContext mapServiceContext) {
    36|         this.mapServiceContext = mapServiceContext;
    37|         this.nodeEngine = mapServiceContext.getNodeEngine();
    38|         this.proxyService = this.nodeEngine.getProxyService();
    39|     }
    40|     @Override
    41|     public void onPartitionLost(IPartitionLostEvent partitionLostEvent) {
    42|         final Address thisAddress = nodeEngine.getThisAddress();
    43|         final int partitionId = partitionLostEvent.getPartitionId();
    44|         Collection<DistributedObject> result = proxyService.getDistributedObjects(MapService.SERVICE_NAME);
    45|         for (DistributedObject object : result) {
    46|             final MapProxyImpl mapProxy = (MapProxyImpl) object;
    47|             final String mapName = mapProxy.getName();
    48|             if (mapProxy.getTotalBackupCount() <= partitionLostEvent.getLostReplicaIndex()) {
    49|                 mapServiceContext.getMapEventPublisher().publishMapPartitionLostEvent(thisAddress, mapName, partitionId);
    50|             }
    51|         }
    52|     }
    53| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/map/impl/MapService.java
# Total hunks: 3
# ====================================================================
# --- HUNK 1: Lines 6-45 ---
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.map.impl;
    17| import com.hazelcast.cluster.ClusterState;
    18| import com.hazelcast.config.WanAcknowledgeType;
    19| import com.hazelcast.core.DistributedObject;
    20| import com.hazelcast.internal.cluster.ClusterStateListener;
    21| import com.hazelcast.internal.metrics.DynamicMetricsProvider;
    22| import com.hazelcast.internal.metrics.MetricDescriptor;
    23| import com.hazelcast.internal.metrics.MetricsCollectionContext;
    24| import com.hazelcast.internal.partition.FragmentedMigrationAwareService;
    25| import com.hazelcast.internal.partition.IPartitionLostEvent;
    26| import com.hazelcast.internal.partition.OffloadedReplicationPreparation;
    27| import com.hazelcast.internal.partition.PartitionAwareService;
    28| import com.hazelcast.internal.partition.PartitionMigrationEvent;
    29| import com.hazelcast.internal.partition.PartitionReplicationEvent;
    30| import com.hazelcast.internal.serialization.Data;
    31| import com.hazelcast.internal.services.ClientAwareService;
    32| import com.hazelcast.internal.services.DistributedObjectNamespace;
    33| import com.hazelcast.internal.services.LockInterceptorService;
    34| import com.hazelcast.internal.services.ManagedService;
    35| import com.hazelcast.internal.services.NotifiableEventListener;
    36| import com.hazelcast.internal.services.ObjectNamespace;
    37| import com.hazelcast.internal.services.PostJoinAwareService;
    38| import com.hazelcast.internal.services.RemoteService;
    39| import com.hazelcast.internal.services.ServiceNamespace;
    40| import com.hazelcast.internal.services.SplitBrainHandlerService;
    41| import com.hazelcast.internal.services.SplitBrainProtectionAwareService;
    42| import com.hazelcast.internal.services.StatisticsAwareService;
    43| import com.hazelcast.internal.services.TenantContextAwareService;
    44| import com.hazelcast.internal.services.TransactionalService;
    45| import com.hazelcast.internal.services.WanSupportingService;

# --- HUNK 2: Lines 71-115 ---
    71| import static com.hazelcast.internal.metrics.MetricDescriptorConstants.MAP_PREFIX_NEARCACHE;
    72| import static com.hazelcast.internal.metrics.MetricDescriptorConstants.MAP_TAG_INDEX;
    73| /**
    74|  * Defines map service behavior.
    75|  *
    76|  * @see MapManagedService
    77|  * @see MapMigrationAwareService
    78|  * @see MapTransactionalService
    79|  * @see MapRemoteService
    80|  * @see MapEventPublishingService
    81|  * @see MapPostJoinAwareService
    82|  * @see MapSplitBrainHandlerService
    83|  * @see WanMapSupportingService
    84|  * @see MapPartitionAwareService
    85|  * @see MapSplitBrainProtectionAwareService
    86|  * @see MapClientAwareService
    87|  * @see MapServiceContext
    88|  */
    89| @SuppressWarnings({"checkstyle:ClassFanOutComplexity", "checkstyle:MethodCount"})
    90| public class MapService implements ManagedService, FragmentedMigrationAwareService, TransactionalService, RemoteService,
    91|                                    EventPublishingService<Object, ListenerAdapter>, PostJoinAwareService,
    92|                                    SplitBrainHandlerService, WanSupportingService, StatisticsAwareService<LocalMapStats>,
    93|                                    PartitionAwareService, ClientAwareService, SplitBrainProtectionAwareService,
    94|                                    NotifiableEventListener, ClusterStateListener, LockInterceptorService<Data>,
    95|                                    DynamicMetricsProvider, TenantContextAwareService, OffloadedReplicationPreparation {
    96|     public static final String SERVICE_NAME = "hz:impl:mapService";
    97|     protected ManagedService managedService;
    98|     protected CountingMigrationAwareService migrationAwareService;
    99|     protected TransactionalService transactionalService;
   100|     protected RemoteService remoteService;
   101|     protected EventPublishingService eventPublishingService;
   102|     protected PostJoinAwareService postJoinAwareService;
   103|     protected SplitBrainHandlerService splitBrainHandlerService;
   104|     protected WanSupportingService wanSupportingService;
   105|     protected StatisticsAwareService statisticsAwareService;
   106|     protected PartitionAwareService partitionAwareService;
   107|     protected ClientAwareService clientAwareService;
   108|     protected MapSplitBrainProtectionAwareService splitBrainProtectionAwareService;
   109|     protected MapServiceContext mapServiceContext;
   110|     public MapService() {
   111|     }
   112|     @Override
   113|     public void dispatchEvent(Object event, ListenerAdapter listener) {
   114|         eventPublishingService.dispatchEvent(event, listener);
   115|     }

# --- HUNK 3: Lines 219-261 ---
   219|     public void onDeregister(Object service, String serviceName, String topic, EventRegistration registration) {
   220|         EventFilter filter = registration.getFilter();
   221|         if (!(filter instanceof EventListenerFilter) || !filter.eval(INVALIDATION.getType())) {
   222|             return;
   223|         }
   224|         MapContainer mapContainer = mapServiceContext.getMapContainer(topic);
   225|         mapContainer.decreaseInvalidationListenerCount();
   226|     }
   227|     public int getMigrationStamp() {
   228|         return migrationAwareService.getMigrationStamp();
   229|     }
   230|     public boolean validateMigrationStamp(int stamp) {
   231|         return migrationAwareService.validateMigrationStamp(stamp);
   232|     }
   233|     @Override
   234|     public void onClusterStateChange(ClusterState newState) {
   235|         mapServiceContext.onClusterStateChange(newState);
   236|     }
   237|     @Override
   238|     public void onBeforeLock(String distributedObjectName, Data key) {
   239|         int partitionId = mapServiceContext.getNodeEngine().getPartitionService().getPartitionId(key);
   240|         RecordStore recordStore = mapServiceContext.getRecordStore(partitionId, distributedObjectName);
   241|         recordStore.getRecordOrNull(key);
   242|     }
   243|     public static ObjectNamespace getObjectNamespace(String mapName) {
   244|         return new DistributedObjectNamespace(SERVICE_NAME, mapName);
   245|     }
   246|     @Override
   247|     public void provideDynamicMetrics(MetricDescriptor descriptor, MetricsCollectionContext context) {
   248|         Map<String, LocalMapStats> stats = getStats();
   249|         if (stats == null) {
   250|             return;
   251|         }
   252|         for (Map.Entry<String, LocalMapStats> entry : stats.entrySet()) {
   253|             String mapName = entry.getKey();
   254|             LocalMapStats localInstanceStats = entry.getValue();
   255|             MetricDescriptor dsDescriptor = descriptor
   256|                     .copy()
   257|                     .withPrefix(MAP_PREFIX)
   258|                     .withDiscriminator(MAP_DISCRIMINATOR_NAME, mapName);
   259|             context.collect(dsDescriptor, localInstanceStats);
   260|             Map<String, LocalIndexStats> indexStats = localInstanceStats.getIndexStats();
   261|             for (Map.Entry<String, LocalIndexStats> indexEntry : indexStats.entrySet()) {


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/map/impl/operation/GetEntryViewOperation.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 16-56 ---
    16| package com.hazelcast.map.impl.operation;
    17| import com.hazelcast.core.EntryView;
    18| import com.hazelcast.core.OperationTimeoutException;
    19| import com.hazelcast.internal.locksupport.LockWaitNotifyKey;
    20| import com.hazelcast.internal.serialization.Data;
    21| import com.hazelcast.map.impl.EntryViews;
    22| import com.hazelcast.map.impl.MapDataSerializerHook;
    23| import com.hazelcast.map.impl.record.Record;
    24| import com.hazelcast.map.impl.recordstore.expiry.ExpiryMetadata;
    25| import com.hazelcast.spi.impl.operationservice.BlockingOperation;
    26| import com.hazelcast.spi.impl.operationservice.WaitNotifyKey;
    27| public class GetEntryViewOperation extends ReadonlyKeyBasedMapOperation implements BlockingOperation {
    28|     private EntryView<Data, Data> result;
    29|     public GetEntryViewOperation() {
    30|     }
    31|     public GetEntryViewOperation(String name, Data dataKey) {
    32|         super(name, dataKey);
    33|     }
    34|     @Override
    35|     protected void runInternal() {
    36|         Record record = recordStore.getRecordOrNull(dataKey);
    37|         if (record != null) {
    38|             Data value = mapServiceContext.toData(record.getValue());
    39|             ExpiryMetadata expiredMetadata = recordStore.getExpirySystem().getExpiredMetadata(dataKey);
    40|             result = EntryViews.createSimpleEntryView(dataKey, value, record, expiredMetadata);
    41|         }
    42|     }
    43|     @Override
    44|     public WaitNotifyKey getWaitKey() {
    45|         return new LockWaitNotifyKey(getServiceNamespace(), dataKey);
    46|     }
    47|     public boolean shouldWait() {
    48|         return recordStore.isTransactionallyLocked(dataKey)
    49|                 && !recordStore.canAcquireLock(dataKey, getCallerUuid(), getThreadId());
    50|     }
    51|     @Override
    52|     public void onWaitExpire() {
    53|         sendResponse(new OperationTimeoutException("Cannot read transactionally locked entry!"));
    54|     }
    55|     @Override
    56|     public Object getResponse() {


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/map/impl/operation/PartitionWideEntryOperation.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 119-158 ---
   119|         }, false);
   120|     }
   121|     private void runWithPartitionScanForNative() {
   122|         int totalEntryCount = recordStore.size();
   123|         responses = new MapEntries(totalEntryCount);
   124|         Queue<Object> outComes = new LinkedList<>();
   125|         operator = operator(this, entryProcessor, getPredicate());
   126|         recordStore.forEach((key, record) -> {
   127|             Data dataKey = toHeapData(key);
   128|             Data response = operator.operateOnKey(dataKey).getResult();
   129|             if (response != null) {
   130|                 responses.add(dataKey, response);
   131|             }
   132|             EntryEventType eventType = operator.getEventType();
   133|             if (eventType != null) {
   134|                 outComes.add(dataKey);
   135|                 outComes.add(operator.getOldValue());
   136|                 outComes.add(operator.getByPreferringDataNewValue());
   137|                 outComes.add(eventType);
   138|                 outComes.add(operator.getEntry().getNewTtl());
   139|             }
   140|         }, false);
   141|         while (!outComes.isEmpty()) {
   142|             Data dataKey = (Data) outComes.poll();
   143|             Object oldValue = outComes.poll();
   144|             Object newValue = outComes.poll();
   145|             EntryEventType eventType = (EntryEventType) outComes.poll();
   146|             long newTtl = (long) outComes.poll();
   147|             operator.init(dataKey, oldValue, newValue, null, eventType,
   148|                     null, newTtl).doPostOperateOps();
   149|         }
   150|     }
   151|     @Override
   152|     public Object getResponse() {
   153|         return responses;
   154|     }
   155|     @Override
   156|     public boolean shouldBackup() {
   157|         return mapContainer.getTotalBackupCount() > 0 && entryProcessor.getBackupProcessor() != null;
   158|     }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/map/impl/operation/PostJoinMapOperation.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 35-74 ---
    35| import com.hazelcast.spi.impl.operationservice.Operation;
    36| import com.hazelcast.spi.impl.operationservice.TargetAware;
    37| import java.io.IOException;
    38| import java.util.AbstractMap;
    39| import java.util.ArrayList;
    40| import java.util.Collections;
    41| import java.util.LinkedList;
    42| import java.util.List;
    43| import java.util.Map;
    44| import static com.hazelcast.internal.util.MapUtil.createHashMap;
    45| public class PostJoinMapOperation extends Operation implements IdentifiedDataSerializable, TargetAware {
    46|     private List<InterceptorInfo> interceptorInfoList = new LinkedList<>();
    47|     private List<AccumulatorInfo> infoList;
    48|     @Override
    49|     public String getServiceName() {
    50|         return MapService.SERVICE_NAME;
    51|     }
    52|     public void addMapInterceptors(MapContainer mapContainer) {
    53|         InterceptorRegistry interceptorRegistry = mapContainer.getInterceptorRegistry();
    54|         List<MapInterceptor> interceptorList = interceptorRegistry.getInterceptors();
    55|         Map<String, MapInterceptor> interceptorMap = interceptorRegistry.getId2InterceptorMap();
    56|         Map<MapInterceptor, String> revMap = createHashMap(interceptorMap.size());
    57|         for (Map.Entry<String, MapInterceptor> entry : interceptorMap.entrySet()) {
    58|             revMap.put(entry.getValue(), entry.getKey());
    59|         }
    60|         InterceptorInfo interceptorInfo = new InterceptorInfo(mapContainer.getName());
    61|         for (MapInterceptor interceptor : interceptorList) {
    62|             interceptorInfo.addInterceptor(revMap.get(interceptor), interceptor);
    63|         }
    64|         interceptorInfoList.add(interceptorInfo);
    65|     }
    66|     public static class InterceptorInfo implements IdentifiedDataSerializable {
    67|         private String mapName;
    68|         private final List<Map.Entry<String, MapInterceptor>> interceptors = new LinkedList<>();
    69|         InterceptorInfo(String mapName) {
    70|             this.mapName = mapName;
    71|         }
    72|         public InterceptorInfo() {
    73|         }
    74|         void addInterceptor(String id, MapInterceptor interceptor) {


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/map/impl/recordstore/DefaultRecordStore.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 159-199 ---
   159|     }
   160|     private void destroyMetadataStore() {
   161|         if (metadataStore != null) {
   162|             metadataStore.destroy();
   163|         }
   164|     }
   165|     @Override
   166|     public Record getRecord(Data key) {
   167|         return storage.get(key);
   168|     }
   169|     @Override
   170|     public Record putReplicatedRecord(Data dataKey, Record replicatedRecord,
   171|                                       ExpiryMetadata expiryMetadata,
   172|                                       boolean populateIndexes, long now) {
   173|         Record newRecord = createRecord(replicatedRecord, now);
   174|         storage.put(dataKey, newRecord);
   175|         expirySystem.add(dataKey, expiryMetadata.getTtl(),
   176|                 expiryMetadata.getMaxIdle(), expiryMetadata.getExpirationTime(),
   177|                 now, expiryMetadata.getLastUpdateTime());
   178|         mutationObserver.onReplicationPutRecord(dataKey, newRecord, populateIndexes);
   179|         updateStatsOnPut(replicatedRecord.getHits(), now);
   180|         return newRecord;
   181|     }
   182|     @Override
   183|     public void removeReplicatedRecord(Data dataKey, boolean backup) {
   184|         Record record = storage.get(dataKey);
   185|         if (record != null) {
   186|             mutationObserver.onRemoveRecord(dataKey, record, backup);
   187|             removeKeyFromExpirySystem(dataKey);
   188|             storage.removeRecord(dataKey, record);
   189|         }
   190|     }
   191|     @Override
   192|     public Record putBackup(Data dataKey, Record newRecord, ExpiryMetadata expiryMetadata,
   193|                             boolean putTransient, CallerProvenance provenance) {
   194|         return putBackupInternal(dataKey, newRecord.getValue(),
   195|                 expiryMetadata.getTtl(), expiryMetadata.getMaxIdle(), expiryMetadata.getExpirationTime(),
   196|                 putTransient, provenance, null);
   197|     }
   198|     @Override
   199|     public Record putBackup(Data dataKey, Record record, long ttl,

# --- HUNK 2: Lines 965-1007 ---
   965|                 false, null, false, true,
   966|                 null, callerAddress, true, false);
   967|     }
   968|     protected Object removeRecord(Data key, @Nonnull Record record,
   969|                                   long now, CallerProvenance provenance,
   970|                                   UUID transactionId) {
   971|         Object oldValue = record.getValue();
   972|         oldValue = mapServiceContext.interceptRemove(interceptorRegistry, oldValue);
   973|         if (oldValue != null) {
   974|             if (persistenceEnabledFor(provenance)) {
   975|                 mapDataStore.remove(key, now, transactionId);
   976|             }
   977|             onStore(record);
   978|         }
   979|         mutationObserver.onRemoveRecord(key, record, false);
   980|         removeKeyFromExpirySystem(key);
   981|         storage.removeRecord(key, record);
   982|         return oldValue;
   983|     }
   984|     @Override
   985|     public Record getRecordOrNull(Data key) {
   986|         long now = getNow();
   987|         return getRecordOrNull(key, now, false);
   988|     }
   989|     protected Record getRecordOrNull(Data key, long now, boolean backup) {
   990|         Record record = storage.get(key);
   991|         if (record != null) {
   992|             return evictIfExpired(key, now, backup) ? null : record;
   993|         }
   994|         return null;
   995|     }
   996|     protected void onStore(Record record) {
   997|         if (record == null || mapDataStore == EMPTY_MAP_DATA_STORE) {
   998|             return;
   999|         }
  1000|         record.onStore();
  1001|     }
  1002|     private void updateStoreStats() {
  1003|         if (!(mapDataStore instanceof WriteBehindStore)
  1004|                 || !mapContainer.getMapConfig().isPerEntryStatsEnabled()) {
  1005|             return;
  1006|         }
  1007|         long now = getNow();


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/map/impl/recordstore/RecordStore.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 381-425 ---
   381|     boolean isExpired(Data dataKey, long now, boolean backup);
   382|     /**
   383|      * Does post eviction operations like sending events
   384|      *
   385|      * @param dataValue    record to process
   386|      * @param expiryReason
   387|      */
   388|     void doPostEvictionOperations(@Nonnull Data dataKey, @Nonnull Object dataValue,
   389|                                   @Nonnull ExpiryReason expiryReason);
   390|     MapDataStore<Data, Object> getMapDataStore();
   391|     InvalidationQueue<ExpiredKey> getExpiredKeysQueue();
   392|     /**
   393|      * Returns the partition id this RecordStore belongs to.
   394|      *
   395|      * @return the partition id.
   396|      */
   397|     int getPartitionId();
   398|     /**
   399|      * Returns live record or null if record is already expired. Does not load missing keys from a map store.
   400|      *
   401|      * @param key key to be accessed
   402|      * @return live record or null
   403|      * @see #get
   404|      */
   405|     R getRecordOrNull(Data key);
   406|     /**
   407|      * Check if record is reachable according to TTL or idle times.
   408|      *
   409|      * @param now    current time in millis
   410|      * @param backup <code>true</code> if a backup
   411|      *               partition, otherwise <code>false</code>.
   412|      * @return {@code true} if record has been evicted
   413|      * due to the expiry, otherwise return {@code false}.
   414|      */
   415|     boolean evictIfExpired(Data key, long now, boolean backup);
   416|     void evictExpiredEntryAndPublishExpiryEvent(Data key, ExpiryReason expiryReason, boolean backup);
   417|     /**
   418|      * Evicts entries from this record-store.
   419|      *
   420|      * @param excludedKey this key has lowest priority to be selected for eviction
   421|      */
   422|     void evictEntries(Data excludedKey);
   423|     /**
   424|      * Returns <code>true</code> if eviction is allowed on this record-store, otherwise <code>false</code>
   425|      *


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/map/impl/tx/TxnLockAndGetOperation.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 35-75 ---
    35|     private boolean blockReads;
    36|     private UUID ownerUuid;
    37|     private VersionedValue response;
    38|     public TxnLockAndGetOperation() {
    39|     }
    40|     public TxnLockAndGetOperation(String name, Data dataKey, long timeout,
    41|                                   long ttl, UUID ownerUuid, boolean shouldLoad,
    42|                                   boolean blockReads) {
    43|         super(name, dataKey);
    44|         this.ownerUuid = ownerUuid;
    45|         this.shouldLoad = shouldLoad;
    46|         this.blockReads = blockReads;
    47|         this.ttl = ttl;
    48|         setWaitTimeout(timeout);
    49|     }
    50|     @Override
    51|     protected void runInternal() {
    52|         if (!recordStore.txnLock(getKey(), ownerUuid, getThreadId(), getCallId(), ttl, blockReads)) {
    53|             throw new TransactionException("Transaction couldn't obtain lock.");
    54|         }
    55|         Record record = recordStore.getRecordOrNull(dataKey);
    56|         if (record == null && shouldLoad) {
    57|             record = recordStore.loadRecordOrNull(dataKey, false, getCallerAddress());
    58|         }
    59|         Data value = record == null ? null : mapServiceContext.toData(record.getValue());
    60|         response = new VersionedValue(value, record == null ? 0 : record.getVersion());
    61|     }
    62|     public boolean shouldWait() {
    63|         return !recordStore.canAcquireLock(dataKey, ownerUuid, getThreadId());
    64|     }
    65|     @Override
    66|     public void onWaitExpire() {
    67|         sendResponse(null);
    68|     }
    69|     @Override
    70|     public Object getResponse() {
    71|         return response;
    72|     }
    73|     @Override
    74|     protected void writeInternal(ObjectDataOutput out) throws IOException {
    75|         super.writeInternal(out);


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/map/impl/tx/TxnSetOperation.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 48-88 ---
    48|                            Data value, long version, long ttl) {
    49|         super(name, dataKey, value);
    50|         this.version = version;
    51|         this.ttl = ttl;
    52|     }
    53|     @Override
    54|     public boolean shouldWait() {
    55|         return false;
    56|     }
    57|     @Override
    58|     public void innerBeforeRun() throws Exception {
    59|         super.innerBeforeRun();
    60|         if (!recordStore.canAcquireLock(dataKey, ownerUuid, threadId)) {
    61|             wbqCapacityCounter().decrement(transactionId);
    62|             throw new TransactionException("Cannot acquire lock UUID: " + ownerUuid + ", threadId: " + threadId);
    63|         }
    64|     }
    65|     @Override
    66|     protected void runInternal() {
    67|         recordStore.unlock(dataKey, ownerUuid, threadId, getCallId());
    68|         Record record = recordStore.getRecordOrNull(dataKey);
    69|         if (record == null || version == record.getVersion()) {
    70|             EventService eventService = getNodeEngine().getEventService();
    71|             if (eventService.hasEventRegistration(MapService.SERVICE_NAME, getName())) {
    72|                 oldValue = record == null ? null : mapServiceContext.toData(record.getValue());
    73|             }
    74|             eventType = record == null ? EntryEventType.ADDED : EntryEventType.UPDATED;
    75|             recordStore.setTxn(dataKey, dataValue, ttl, UNSET, transactionId);
    76|             shouldBackup = true;
    77|         }
    78|     }
    79|     @Override
    80|     public long getVersion() {
    81|         return version;
    82|     }
    83|     @Override
    84|     public void setVersion(long version) {
    85|         this.version = version;
    86|     }
    87|     @Override
    88|     public void setOwnerUuid(UUID ownerUuid) {


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/query/impl/getters/AbstractJsonGetter.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 177-220 ---
   177|      *
   178|      * @param parser
   179|      * @param pathCursor
   180|      * @return {@code true} if given attribute name exists in the current object
   181|      * @throws IOException
   182|      */
   183|     private boolean findAttribute(JsonParser parser, JsonPathCursor pathCursor,
   184|                                   boolean multiValue) throws IOException {
   185|         JsonToken token = parser.getCurrentToken();
   186|         if (token != START_OBJECT) {
   187|             return false;
   188|         }
   189|         while (true) {
   190|             token = parser.nextToken();
   191|             if (token == JsonToken.END_OBJECT) {
   192|                 return false;
   193|             }
   194|             if (pathCursor.getCurrent().equals(parser.getCurrentName())) {
   195|                 parser.nextToken();
   196|                 return true;
   197|             } else if (multiValue) {
   198|                 parser.nextToken();
   199|             } else {
   200|                 parser.nextToken();
   201|                 parser.skipChildren();
   202|             }
   203|         }
   204|     }
   205|     /**
   206|      * Traverses given array. If {@code pathCursor#getNext()} is
   207|      * {@code null}, this method adds all the scalar values in current
   208|      * array to the result. Otherwise, it traverses all objects in
   209|      * given array and adds their scalar values named
   210|      * {@code pathCursor#getNext()} to the result.
   211|      *
   212|      * Assumes the parser points to an array.
   213|      *
   214|      * @param parser
   215|      * @param pathCursor
   216|      * @return All matches in the current array that conform to
   217|      * [any].lastPath search
   218|      * @throws IOException
   219|      */
   220|     @SuppressWarnings("checkstyle:cyclomaticcomplexity")


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/security/permission/ActionConstants.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 18-57 ---
    18| import com.hazelcast.cardinality.impl.CardinalityEstimatorService;
    19| import com.hazelcast.collection.impl.list.ListService;
    20| import com.hazelcast.collection.impl.queue.QueueService;
    21| import com.hazelcast.collection.impl.set.SetService;
    22| import com.hazelcast.cp.internal.datastructures.atomiclong.AtomicLongService;
    23| import com.hazelcast.cp.internal.datastructures.atomicref.AtomicRefService;
    24| import com.hazelcast.cp.internal.datastructures.countdownlatch.CountDownLatchService;
    25| import com.hazelcast.cp.internal.datastructures.lock.LockService;
    26| import com.hazelcast.cp.internal.datastructures.semaphore.SemaphoreService;
    27| import com.hazelcast.durableexecutor.impl.DistributedDurableExecutorService;
    28| import com.hazelcast.executor.impl.DistributedExecutorService;
    29| import com.hazelcast.flakeidgen.impl.FlakeIdGeneratorService;
    30| import com.hazelcast.internal.crdt.pncounter.PNCounterService;
    31| import com.hazelcast.internal.locksupport.LockSupportService;
    32| import com.hazelcast.internal.usercodedeployment.UserCodeDeploymentService;
    33| import com.hazelcast.jet.impl.JetServiceBackend;
    34| import com.hazelcast.map.impl.MapService;
    35| import com.hazelcast.multimap.impl.MultiMapService;
    36| import com.hazelcast.replicatedmap.impl.ReplicatedMapService;
    37| import com.hazelcast.ringbuffer.impl.RingbufferService;
    38| import com.hazelcast.sql.impl.SqlInternalService;
    39| import com.hazelcast.topic.impl.TopicService;
    40| import com.hazelcast.topic.impl.reliable.ReliableTopicService;
    41| import java.security.Permission;
    42| import java.util.HashMap;
    43| import java.util.Map;
    44| @SuppressWarnings({"checkstyle:executablestatementcount"})
    45| public final class ActionConstants {
    46|     public static final String ACTION_ALL = "all";
    47|     public static final String ACTION_CREATE = "create";
    48|     public static final String ACTION_DESTROY = "destroy";
    49|     public static final String ACTION_MODIFY = "modify";
    50|     public static final String ACTION_READ = "read";
    51|     public static final String ACTION_REMOVE = "remove";
    52|     public static final String ACTION_LOCK = "lock";
    53|     public static final String ACTION_LISTEN = "listen";
    54|     public static final String ACTION_RELEASE = "release";
    55|     public static final String ACTION_ACQUIRE = "acquire";
    56|     public static final String ACTION_PUT = "put";
    57|     public static final String ACTION_ADD = "add";

# --- HUNK 2: Lines 80-119 ---
    80|         PERMISSION_FACTORY_MAP.put(AtomicLongService.SERVICE_NAME, AtomicLongPermission::new);
    81|         PERMISSION_FACTORY_MAP.put(CountDownLatchService.SERVICE_NAME, CountDownLatchPermission::new);
    82|         PERMISSION_FACTORY_MAP.put(SemaphoreService.SERVICE_NAME, SemaphorePermission::new);
    83|         PERMISSION_FACTORY_MAP.put(TopicService.SERVICE_NAME, TopicPermission::new);
    84|         PERMISSION_FACTORY_MAP.put(LockSupportService.SERVICE_NAME, LockPermission::new);
    85|         PERMISSION_FACTORY_MAP.put(LockService.SERVICE_NAME, LockPermission::new);
    86|         PERMISSION_FACTORY_MAP.put(DistributedExecutorService.SERVICE_NAME, ExecutorServicePermission::new);
    87|         PERMISSION_FACTORY_MAP.put(FlakeIdGeneratorService.SERVICE_NAME, FlakeIdGeneratorPermission::new);
    88|         PERMISSION_FACTORY_MAP.put(ReplicatedMapService.SERVICE_NAME, ReplicatedMapPermission::new);
    89|         PERMISSION_FACTORY_MAP.put(AtomicRefService.SERVICE_NAME, AtomicReferencePermission::new);
    90|         PERMISSION_FACTORY_MAP.put(CacheService.SERVICE_NAME, CachePermission::new);
    91|         PERMISSION_FACTORY_MAP.put(RingbufferService.SERVICE_NAME, RingBufferPermission::new);
    92|         PERMISSION_FACTORY_MAP.put(DistributedDurableExecutorService.SERVICE_NAME, DurableExecutorServicePermission::new);
    93|         PERMISSION_FACTORY_MAP.put(CardinalityEstimatorService.SERVICE_NAME, CardinalityEstimatorPermission::new);
    94|         PERMISSION_FACTORY_MAP.put(UserCodeDeploymentService.SERVICE_NAME,
    95|                 (name, actions) -> new UserCodeDeploymentPermission(actions));
    96|         PERMISSION_FACTORY_MAP.put(PNCounterService.SERVICE_NAME, PNCounterPermission::new);
    97|         PERMISSION_FACTORY_MAP.put(ReliableTopicService.SERVICE_NAME, ReliableTopicPermission::new);
    98|         PERMISSION_FACTORY_MAP.put(JetServiceBackend.SERVICE_NAME, (name, actions) -> new JobPermission(actions));
    99|         PERMISSION_FACTORY_MAP.put(SqlInternalService.SERVICE_NAME, SqlPermission::new);
   100|     }
   101|     private ActionConstants() {
   102|     }
   103|     private interface PermissionFactory {
   104|         Permission create(String name, String... actions);
   105|     }
   106|     /**
   107|      * Creates a permission
   108|      *
   109|      * @param name        the permission name
   110|      * @param serviceName the service name
   111|      * @param actions     the actions
   112|      * @return the created Permission
   113|      * @throws java.lang.IllegalArgumentException if there is no service found with the given serviceName.
   114|      */
   115|     public static Permission getPermission(String name, String serviceName, String... actions) {
   116|         PermissionFactory permissionFactory = PERMISSION_FACTORY_MAP.get(serviceName);
   117|         if (permissionFactory == null) {
   118|             throw new IllegalArgumentException("No permissions found for service: " + serviceName);
   119|         }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/security/permission/DurableExecutorServicePermission.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-37 ---
     1| /*
     2|  * Copyright (c) 2008-2021, Hazelcast, Inc. All Rights Reserved.
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.security.permission;
    17| public class DurableExecutorServicePermission extends InstancePermission {
    18|     private static final int ALL = CREATE | DESTROY;
    19|     public DurableExecutorServicePermission(String name, String... actions) {
    20|         super(name, actions);
    21|     }
    22|     @Override
    23|     protected int initMask(String[] actions) {
    24|         int mask = NONE;
    25|         for (String action : actions) {
    26|             if (ActionConstants.ACTION_ALL.equals(action)) {
    27|                 return ALL;
    28|             }
    29|             if (ActionConstants.ACTION_CREATE.equals(action)) {
    30|                 mask |= CREATE;
    31|             } else if (ActionConstants.ACTION_DESTROY.equals(action)) {
    32|                 mask |= DESTROY;
    33|             }
    34|         }
    35|         return mask;
    36|     }
    37| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/security/permission/ExecutorServicePermission.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-37 ---
     1| /*
     2|  * Copyright (c) 2008-2021, Hazelcast, Inc. All Rights Reserved.
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.security.permission;
    17| public class ExecutorServicePermission extends InstancePermission {
    18|     private static final int ALL = CREATE | DESTROY;
    19|     public ExecutorServicePermission(String name, String... actions) {
    20|         super(name, actions);
    21|     }
    22|     @Override
    23|     protected int initMask(String[] actions) {
    24|         int mask = NONE;
    25|         for (String action : actions) {
    26|             if (ActionConstants.ACTION_ALL.equals(action)) {
    27|                 return ALL;
    28|             }
    29|             if (ActionConstants.ACTION_CREATE.equals(action)) {
    30|                 mask |= CREATE;
    31|             } else if (ActionConstants.ACTION_DESTROY.equals(action)) {
    32|                 mask |= DESTROY;
    33|             }
    34|         }
    35|         return mask;
    36|     }
    37| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/spi/impl/AbstractInvocationFuture.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 707-746 ---
   707|             return (V) resolved;
   708|         }
   709|         Throwable cause = ((ExceptionalResult) resolved).cause;
   710|         if (cause instanceof CancellationException) {
   711|             throw (CancellationException) cause;
   712|         } else if (cause instanceof CompletionException) {
   713|             throw (CompletionException) cause;
   714|         }
   715|         throw new CompletionException(cause);
   716|     }
   717|     /**
   718|      * @param value the resolved state of this future
   719|      * @return an {@link ExceptionalResult} wrapping a {@link Throwable} in case value is resolved
   720|      * to an exception, or the normal completion value. Subclasses may choose to treat
   721|      * specific normal completion values in a special way (eg deserialize when the completion
   722|      * value is an instance of {@code Data}.
   723|      */
   724|     protected Object resolve(Object value) {
   725|         return value;
   726|     }
   727|     protected V resolveAndThrowWithJoinConvention(Object state) {
   728|         Object value = resolve(state);
   729|         return returnOrThrowWithJoinConventions(value);
   730|     }
   731|     protected <U> void unblockApply(@Nonnull final Function<? super V, ? extends U> function,
   732|                                     @Nonnull Executor executor,
   733|                                     @Nonnull InternalCompletableFuture<U> future) {
   734|         final Object value = resolve(state);
   735|         if (cascadeException(value, future)) {
   736|             return;
   737|         }
   738|         try {
   739|             executor.execute(() -> {
   740|                 try {
   741|                     U result = function.apply((V) value);
   742|                     future.complete(result);
   743|                 } catch (Throwable t) {
   744|                     future.completeExceptionally(t);
   745|                 }
   746|             });

# --- HUNK 2: Lines 1066-1107 ---
  1066|         return complete0(value);
  1067|     }
  1068|     public final boolean completeExceptionallyInternal(Object value) {
  1069|         return complete0(wrapThrowable(value));
  1070|     }
  1071|     private boolean complete0(Object value) {
  1072|         for (; ; ) {
  1073|             final Object oldState = state;
  1074|             if (isDone(oldState)) {
  1075|                 warnIfSuspiciousDoubleCompletion(oldState, value);
  1076|                 return false;
  1077|             }
  1078|             if (compareAndSetState(oldState, value)) {
  1079|                 onComplete();
  1080|                 unblockAll(oldState, defaultExecutor());
  1081|                 return true;
  1082|             }
  1083|         }
  1084|     }
  1085|     protected void onComplete() {
  1086|         if (state instanceof ExceptionalResult) {
  1087|             super.completeExceptionally(((ExceptionalResult) state).getCause());
  1088|         } else {
  1089|             super.complete((V) state);
  1090|         }
  1091|     }
  1092|     private void warnIfSuspiciousDoubleCompletion(Object s0, Object s1) {
  1093|         if (s0 != s1 && !(isStateCancelled(s0)) && !(isStateCancelled(s1))) {
  1094|             logger.warning(String.format("Future.complete(Object) on completed future. "
  1095|                             + "Request: %s, current value: %s, offered value: %s",
  1096|                     invocationToString(), s0, s1), new Exception());
  1097|         }
  1098|     }
  1099|     @Override
  1100|     public String toString() {
  1101|         Object state = getState();
  1102|         if (isDone(state)) {
  1103|             return "InvocationFuture{invocation=" + invocationToString() + ", value=" + state + '}';
  1104|         } else {
  1105|             return "InvocationFuture{invocation=" + invocationToString() + ", done=false}";
  1106|         }
  1107|     }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/spi/impl/NodeEngine.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 178-217 ---
   178|      * Deserializes an object.
   179|      * <p>
   180|      * This method can safely be called on an object that is already deserialized. In that case, that instance
   181|      * is returned.
   182|      * <p>
   183|      * If this method is called with {@code null}, {@code null} is returned.
   184|      *
   185|      * @param object the object to deserialize
   186|      * @param klazz  The class to instantiate when deserializing the object
   187|      * @return the deserialized object
   188|      * @throws com.hazelcast.nio.serialization.HazelcastSerializationException when deserialization fails
   189|      */
   190|     <T> T toObject(Object object, Class klazz);
   191|     /**
   192|      * Indicates that node is not shutting down or it has not already shut down
   193|      *
   194|      * @return {@code true} if node is not shutting down or it has not already shut down, {@code false} otherwise
   195|      */
   196|     boolean isRunning();
   197|     /**
   198|      * Returns the HazelcastInstance that this {@link NodeEngine} belongs to.
   199|      *
   200|      * @return the HazelcastInstance
   201|      */
   202|     HazelcastInstance getHazelcastInstance();
   203|     /**
   204|      * Gets the service with the given name.
   205|      *
   206|      * @param serviceName the name of the service
   207|      * @param <T>         the type of the service
   208|      * @return the found service, or HazelcastException in case of failure ({@code null} will never be returned)
   209|      */
   210|     <T> T getService(@Nonnull String serviceName);
   211|     /**
   212|      * Gets the service for the given serviceName if it exists or null otherwise.
   213|      *
   214|      * @param serviceName the name of the shared service to get
   215|      * @param <T>         the type of the service
   216|      * @return the found service, or null if the service was not found
   217|      * @throws NullPointerException if the serviceName is {@code null}


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/spi/impl/NodeEngineImpl.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 328-367 ---
   328|     public TransactionManagerService getTransactionManagerService() {
   329|         return transactionManagerService;
   330|     }
   331|     @Override
   332|     public Data toData(Object object) {
   333|         return serializationService.toData(object);
   334|     }
   335|     @Override
   336|     public <T> T toObject(Object object) {
   337|         return serializationService.toObject(object);
   338|     }
   339|     @Override
   340|     public <T> T toObject(Object object, Class klazz) {
   341|         return serializationService.toObject(object, klazz);
   342|     }
   343|     @Override
   344|     public boolean isRunning() {
   345|         return node.isRunning();
   346|     }
   347|     @Override
   348|     public HazelcastInstance getHazelcastInstance() {
   349|         return node.hazelcastInstance;
   350|     }
   351|     @Override
   352|     public ILogger getLogger(String name) {
   353|         return loggingService.getLogger(name);
   354|     }
   355|     @Override
   356|     public ILogger getLogger(Class clazz) {
   357|         return loggingService.getLogger(clazz);
   358|     }
   359|     @Override
   360|     public HazelcastProperties getProperties() {
   361|         return node.getProperties();
   362|     }
   363|     @Override
   364|     public <T> T getService(@Nonnull String serviceName) {
   365|         T service = serviceManager.getService(serviceName);
   366|         if (service == null) {
   367|             if (isRunning()) {


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/spi/impl/operationservice/Operation.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 1-48 ---
     1| /*
     2|  * Copyright (c) 2008-2021, Hazelcast, Inc. All Rights Reserved.
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.spi.impl.operationservice;
    17| import com.hazelcast.cluster.Address;
    18| import com.hazelcast.internal.cluster.ClusterClock;
    19| import com.hazelcast.internal.partition.InternalPartition;
    20| import com.hazelcast.internal.server.ServerConnection;
    21| import com.hazelcast.internal.util.UUIDSerializationUtil;
    22| import com.hazelcast.logging.ILogger;
    23| import com.hazelcast.logging.Logger;
    24| import com.hazelcast.nio.ObjectDataInput;
    25| import com.hazelcast.nio.ObjectDataOutput;
    26| import com.hazelcast.nio.serialization.DataSerializable;
    27| import com.hazelcast.spi.exception.RetryableException;
    28| import com.hazelcast.spi.exception.SilentException;
    29| import com.hazelcast.spi.impl.NodeEngine;
    30| import com.hazelcast.spi.properties.ClusterProperty;
    31| import com.hazelcast.spi.tenantcontrol.TenantControl;
    32| import com.hazelcast.spi.tenantcontrol.TenantControl.Closeable;
    33| import com.hazelcast.spi.tenantcontrol.Tenantable;
    34| import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;
    35| import java.io.IOException;
    36| import java.util.UUID;
    37| import java.util.concurrent.Callable;
    38| import java.util.concurrent.atomic.AtomicLongFieldUpdater;
    39| import java.util.logging.Level;
    40| import static com.hazelcast.internal.util.EmptyStatement.ignore;
    41| import static com.hazelcast.internal.util.StringUtil.timeToString;
    42| import static com.hazelcast.spi.impl.operationservice.CallStatus.RESPONSE;
    43| import static com.hazelcast.spi.impl.operationservice.CallStatus.VOID;
    44| import static com.hazelcast.spi.impl.operationservice.CallStatus.WAIT;
    45| import static com.hazelcast.spi.impl.operationservice.ExceptionAction.RETRY_INVOCATION;
    46| import static com.hazelcast.spi.impl.operationservice.ExceptionAction.THROW_EXCEPTION;
    47| /**
    48|  * An operation could be compared to a {@link Runnable}. It contains logic that

# --- HUNK 2: Lines 488-527 ---
   488|      * @see #getWaitTimeout() for more detail.
   489|      */
   490|     public final void setWaitTimeout(long timeout) {
   491|         this.waitTimeout = timeout;
   492|         setFlag(timeout != -1, BITMASK_WAIT_TIMEOUT_SET);
   493|     }
   494|     /**
   495|      * Called when an <code>Exception</code>/<code>Error</code> is thrown
   496|      * during an invocation. Invocation process will continue, it will retry
   497|      * or fail according to returned <code>ExceptionAction</code>.
   498|      * <p>
   499|      * This method is called on caller side of the invocation.
   500|      *
   501|      * @param throwable <code>Exception</code>/<code>Error</code> thrown during
   502|      *                  invocation
   503|      * @return <code>ExceptionAction</code>
   504|      */
   505|     public ExceptionAction onInvocationException(Throwable throwable) {
   506|         return throwable instanceof RetryableException ? RETRY_INVOCATION : THROW_EXCEPTION;
   507|     }
   508|     public UUID getCallerUuid() {
   509|         return callerUuid;
   510|     }
   511|     public Operation setCallerUuid(UUID callerUuid) {
   512|         this.callerUuid = callerUuid;
   513|         setFlag(callerUuid != null, BITMASK_CALLER_UUID_SET);
   514|         return this;
   515|     }
   516|     protected final ILogger getLogger() {
   517|         final NodeEngine ne = nodeEngine;
   518|         return ne != null ? ne.getLogger(getClass()) : Logger.getLogger(getClass());
   519|     }
   520|     void setFlag(boolean value, int bitmask) {
   521|         if (value) {
   522|             flags |= bitmask;
   523|         } else {
   524|             flags &= ~bitmask;
   525|         }
   526|     }
   527|     boolean isFlagSet(int bitmask) {


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/spi/impl/operationservice/OperationService.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 93-134 ---
    93|      * {@link com.hazelcast.spi.impl.operationexecutor.OperationExecutor#executeOnPartitions(PartitionTaskFactory, BitSet)}
    94|      *
    95|      * @param taskFactory the PartitionTaskFactory used to create
    96|      *                    operations.
    97|      * @param partitions  the partitions to execute an operation on.
    98|      * @throws NullPointerException if taskFactory or partitions is null.
    99|      */
   100|     void executeOnPartitions(PartitionTaskFactory taskFactory, BitSet partitions);
   101|     <E> InvocationFuture<E> invokeOnPartition(String serviceName, Operation op, int partitionId);
   102|     <E> InvocationFuture<E> invokeOnPartitionAsync(String serviceName, Operation op, int partitionId);
   103|     <E> InvocationFuture<E> invokeOnPartitionAsync(String serviceName, Operation op, int partitionId, int replicaIndex);
   104|     /**
   105|      * Executes an operation on a partition.
   106|      *
   107|      * @param op  the operation
   108|      * @param <E> the return type of the operation response
   109|      * @return the future.
   110|      */
   111|     <E> InvocationFuture<E> invokeOnPartition(Operation op);
   112|     <E> InvocationFuture<E> invokeOnTarget(String serviceName, Operation op, Address target);
   113|     InvocationBuilder createInvocationBuilder(String serviceName, Operation op, int partitionId);
   114|     InvocationBuilder createInvocationBuilder(String serviceName, Operation op, Address target);
   115|     /**
   116|      * Invokes a set of operations on each partition.
   117|      * <p>
   118|      * This method blocks until the operations complete.
   119|      * <p>
   120|      * If the operations have sync backups, this method will <b>not</b> wait for their completion.
   121|      * Instead, it will return once the operations are completed on primary replicas of the
   122|      * given {@code partitions}.
   123|      *
   124|      * @param serviceName      the name of the service.
   125|      * @param operationFactory the factory responsible for creating operations
   126|      * @return a Map with partitionId as a key and the outcome of the operation
   127|      * as a value.
   128|      * @throws Exception
   129|      */
   130|     Map<Integer, Object> invokeOnAllPartitions(String serviceName, OperationFactory operationFactory)
   131|             throws Exception;
   132|     /**
   133|      * Invokes a set of operations on selected set of all partitions in an async way.
   134|      * <p>


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/spi/impl/operationservice/impl/InvocationBuilderImpl.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-52 ---
     1| /*
     2|  * Copyright (c) 2008-2021, Hazelcast, Inc. All Rights Reserved.
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.spi.impl.operationservice.impl;
    17| import com.hazelcast.cluster.Address;
    18| import com.hazelcast.spi.impl.operationservice.InvocationBuilder;
    19| import com.hazelcast.spi.impl.operationservice.Operation;
    20| /**
    21|  * An {@link InvocationBuilder} that is tied to the {@link OperationServiceImpl}.
    22|  */
    23| class InvocationBuilderImpl extends InvocationBuilder {
    24|     private final Invocation.Context context;
    25|     InvocationBuilderImpl(Invocation.Context context, String serviceName, Operation op, int partitionId) {
    26|         this(context, serviceName, op, partitionId, null);
    27|     }
    28|     InvocationBuilderImpl(Invocation.Context context, String serviceName, Operation op, Address target) {
    29|         this(context, serviceName, op, Operation.GENERIC_PARTITION_ID, target);
    30|     }
    31|     private InvocationBuilderImpl(Invocation.Context context, String serviceName, Operation op,
    32|                                   int partitionId, Address target) {
    33|         super(serviceName, op, partitionId, target);
    34|         this.context = context;
    35|     }
    36|     @Override
    37|     public InvocationFuture invoke() {
    38|         op.setServiceName(serviceName);
    39|         Invocation invocation;
    40|         if (target == null) {
    41|             op.setPartitionId(partitionId).setReplicaIndex(replicaIndex);
    42|             invocation = new PartitionInvocation(
    43|                     context, op, doneCallback, tryCount, tryPauseMillis, callTimeout, resultDeserialized,
    44|                     failOnIndeterminateOperationState, connectionManager);
    45|         } else {
    46|             invocation = new TargetInvocation(
    47|                     context, op, target, doneCallback, tryCount, tryPauseMillis,
    48|                     callTimeout, resultDeserialized, connectionManager);
    49|         }
    50|         return invocation.invoke();
    51|     }
    52| }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/spi/impl/operationservice/impl/InvocationFuture.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 94-161 ---
    94|         if (response instanceof WrappableException) {
    95|             response = ((WrappableException) response).wrap();
    96|         } else if (response instanceof RuntimeException || response instanceof Error) {
    97|             response = cloneExceptionWithFixedAsyncStackTrace((Throwable) response);
    98|         }
    99|         if (response instanceof CancellationException) {
   100|             throw (CancellationException) response;
   101|         } else if (response instanceof ExecutionException) {
   102|             throw (ExecutionException) response;
   103|         } else if (response instanceof InterruptedException) {
   104|             throw (InterruptedException) response;
   105|         } else {
   106|             throw new ExecutionException((Throwable) response);
   107|         }
   108|     }
   109|     @SuppressWarnings({"checkstyle:npathcomplexity", "checkstyle:cyclomaticcomplexity"})
   110|     @Override
   111|     protected Object resolve(Object unresolved) {
   112|         if (unresolved == null) {
   113|             return null;
   114|         } else if (unresolved == INTERRUPTED) {
   115|             return new ExceptionalResult(
   116|                     new InterruptedException(invocation.op.getClass().getSimpleName() + " was interrupted. " + invocation));
   117|         } else if (unresolved == CALL_TIMEOUT) {
   118|             return new ExceptionalResult(newOperationTimeoutException(false));
   119|         } else if (unresolved == HEARTBEAT_TIMEOUT) {
   120|             return new ExceptionalResult(newOperationTimeoutException(true));
   121|         } else if (unresolved.getClass() == Packet.class) {
   122|             NormalResponse response = invocation.context.serializationService.toObject(unresolved);
   123|             unresolved = response.getValue();
   124|         }
   125|         Object value = unresolved;
   126|         if (deserialize && value instanceof Data) {
   127|             value = invocation.context.serializationService.toObject(value);
   128|             if (value == null) {
   129|                 return null;
   130|             }
   131|         }
   132|         Throwable cause = (value instanceof ExceptionalResult)
   133|                 ? ((ExceptionalResult) value).getCause()
   134|                 : null;
   135|         if (invocation.shouldFailOnIndeterminateOperationState()
   136|                 && (value instanceof IndeterminateOperationState
   137|                 || cause instanceof IndeterminateOperationState)) {
   138|             value = wrapThrowable(new IndeterminateOperationStateException("indeterminate operation state",
   139|                     cause == null ? (Throwable) value : cause));
   140|         }
   141|         return value;
   142|     }
   143|     private OperationTimeoutException newOperationTimeoutException(boolean heartbeatTimeout) {
   144|         StringBuilder sb = new StringBuilder();
   145|         if (heartbeatTimeout) {
   146|             sb.append(invocation.op.getClass().getSimpleName())
   147|                     .append(" invocation failed to complete due to operation-heartbeat-timeout. ");
   148|             sb.append("Current time: ").append(timeToString(currentTimeMillis())).append(". ");
   149|             sb.append("Start time: ").append(timeToString(invocation.firstInvocationTimeMillis)).append(". ");
   150|             sb.append("Total elapsed time: ")
   151|                     .append(currentTimeMillis() - invocation.firstInvocationTimeMillis).append(" ms. ");
   152|             long lastHeartbeatMillis = invocation.lastHeartbeatMillis;
   153|             sb.append("Last operation heartbeat: ");
   154|             appendHeartbeat(sb, lastHeartbeatMillis);
   155|             long lastHeartbeatFromMemberMillis = invocation.context.invocationMonitor
   156|                     .getLastMemberHeartbeatMillis(invocation.getTargetAddress());
   157|             sb.append("Last operation heartbeat from member: ");
   158|             appendHeartbeat(sb, lastHeartbeatFromMemberMillis);
   159|         } else {
   160|             sb.append(invocation.op.getClass().getSimpleName())
   161|                     .append(" got rejected before execution due to not starting within the operation-call-timeout of: ")


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/spi/impl/operationservice/impl/InvocationRegistry.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 19-59 ---
    19| import com.hazelcast.core.MemberLeftException;
    20| import com.hazelcast.internal.diagnostics.InvocationProfilerPlugin;
    21| import com.hazelcast.internal.metrics.MetricsRegistry;
    22| import com.hazelcast.internal.metrics.Probe;
    23| import com.hazelcast.internal.metrics.StaticMetricsProvider;
    24| import com.hazelcast.internal.util.LatencyDistribution;
    25| import com.hazelcast.internal.util.RuntimeAvailableProcessors;
    26| import com.hazelcast.logging.ILogger;
    27| import com.hazelcast.spi.impl.operationservice.Operation;
    28| import com.hazelcast.spi.impl.operationservice.impl.operations.PartitionIteratingOperation;
    29| import com.hazelcast.spi.impl.sequence.CallIdSequence;
    30| import com.hazelcast.spi.properties.HazelcastProperties;
    31| import java.util.Iterator;
    32| import java.util.Map;
    33| import java.util.Set;
    34| import java.util.concurrent.ConcurrentHashMap;
    35| import java.util.concurrent.ConcurrentMap;
    36| import static com.hazelcast.internal.metrics.MetricDescriptorConstants.OPERATION_METRIC_INVOCATION_REGISTRY_INVOCATIONS_LAST_CALL_ID;
    37| import static com.hazelcast.internal.metrics.MetricDescriptorConstants.OPERATION_METRIC_INVOCATION_REGISTRY_INVOCATIONS_PENDING;
    38| import static com.hazelcast.internal.metrics.MetricDescriptorConstants.OPERATION_METRIC_INVOCATION_REGISTRY_INVOCATIONS_USED_PERCENTAGE;
    39| import static com.hazelcast.internal.metrics.MetricDescriptorConstants.OPERATION_PREFIX;
    40| import static com.hazelcast.internal.metrics.ProbeLevel.MANDATORY;
    41| import static com.hazelcast.internal.metrics.ProbeUnit.PERCENT;
    42| import static com.hazelcast.spi.impl.operationservice.OperationAccessor.deactivate;
    43| import static com.hazelcast.spi.impl.operationservice.OperationAccessor.setCallId;
    44| /**
    45|  * Responsible for the registration of all pending invocations.
    46|  * <p>
    47|  * By using the InvocationRegistry, the Invocation and its response(s) can be linked to each other.
    48|  * <p>
    49|  * When an invocation is registered, a callId is determined. Based on this call ID, when a
    50|  * {@link com.hazelcast.spi.impl.operationservice.impl.responses.Response} comes in, the
    51|  * appropriate invocation can be looked up.
    52|  * <p>
    53|  * Some ideas:
    54|  * <ul>
    55|  * <li>Use a ringbuffer to store all invocations instead of a CHM. The call ID can be used as sequence ID for this
    56|  * ringbuffer. It can be that you run in slots that have not been released; if that happens, just keep increasing
    57|  * the sequence (although you now get sequence-gaps).</li>
    58|  * <li>Pre-allocate all invocations. Because the ringbuffer has a fixed capacity, pre-allocation should be easy. Also
    59|  * the PartitionInvocation and TargetInvocation can be folded into Invocation.</li>

# --- HUNK 2: Lines 67-107 ---
    67|     private static final float LOAD_FACTOR = 0.75f;
    68|     private static final double HUNDRED_PERCENT = 100d;
    69|     @Probe(name = OPERATION_METRIC_INVOCATION_REGISTRY_INVOCATIONS_PENDING, level = MANDATORY)
    70|     private final ConcurrentMap<Long, Invocation> invocations;
    71|     private final ILogger logger;
    72|     private final CallIdSequence callIdSequence;
    73|     private final boolean profilerEnabled;
    74|     private final ConcurrentMap<Class, LatencyDistribution> latencyDistributions = new ConcurrentHashMap<>();
    75|     private volatile boolean alive = true;
    76|     public InvocationRegistry(ILogger logger, CallIdSequence callIdSequence, HazelcastProperties properties) {
    77|         this.logger = logger;
    78|         this.callIdSequence = callIdSequence;
    79|         int coreSize = RuntimeAvailableProcessors.get();
    80|         boolean reallyMultiCore = coreSize >= CORE_SIZE_CHECK;
    81|         int concurrencyLevel = reallyMultiCore ? coreSize * CORE_SIZE_FACTOR : CONCURRENCY_LEVEL;
    82|         this.invocations = new ConcurrentHashMap<>(INITIAL_CAPACITY, LOAD_FACTOR, concurrencyLevel);
    83|         this.profilerEnabled = properties.getInteger(InvocationProfilerPlugin.PERIOD_SECONDS) > 0;
    84|     }
    85|     @Override
    86|     public void provideStaticMetrics(MetricsRegistry registry) {
    87|         registry.registerStaticMetrics(this, OPERATION_PREFIX);
    88|     }
    89|     @Probe(name = OPERATION_METRIC_INVOCATION_REGISTRY_INVOCATIONS_USED_PERCENTAGE, unit = PERCENT)
    90|     private double invocationsUsedPercentage() {
    91|         int maxConcurrentInvocations = callIdSequence.getMaxConcurrentInvocations();
    92|         if (maxConcurrentInvocations == Integer.MAX_VALUE) {
    93|             return 0;
    94|         }
    95|         return (HUNDRED_PERCENT * invocations.size()) / maxConcurrentInvocations;
    96|     }
    97|     @Probe(name = OPERATION_METRIC_INVOCATION_REGISTRY_INVOCATIONS_LAST_CALL_ID)
    98|     long getLastCallId() {
    99|         return callIdSequence.getLastCallId();
   100|     }
   101|     /**
   102|      * Registers an invocation.
   103|      *
   104|      * @param invocation The invocation to register.
   105|      * @return {@code false} when InvocationRegistry is not alive and registration is not successful, {@code true} otherwise
   106|      */
   107|     public boolean register(Invocation invocation) {


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/spi/impl/operationservice/impl/OperationServiceImpl.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 225-273 ---
   225|         return inboundResponseHandlerSupplier.responseQueueSize();
   226|     }
   227|     @Override
   228|     public void populate(LiveOperations liveOperations) {
   229|         operationExecutor.populate(liveOperations);
   230|         for (Operation op : asyncOperations) {
   231|             liveOperations.add(op.getCallerAddress(), op.getCallId());
   232|         }
   233|     }
   234|     @Override
   235|     public void execute(PartitionSpecificRunnable task) {
   236|         operationExecutor.execute(task);
   237|     }
   238|     @Override
   239|     public void executeOnPartitions(PartitionTaskFactory taskFactory, BitSet partitions) {
   240|         operationExecutor.executeOnPartitions(taskFactory, partitions);
   241|     }
   242|     @Override
   243|     public InvocationBuilder createInvocationBuilder(String serviceName, Operation op, int partitionId) {
   244|         checkNotNegative(partitionId, "Partition ID cannot be negative!");
   245|         return new InvocationBuilderImpl(invocationContext, serviceName, op, partitionId)
   246|                 .setTryCount(invocationMaxRetryCount)
   247|                 .setTryPauseMillis(invocationRetryPauseMillis)
   248|                 .setFailOnIndeterminateOperationState(failOnIndeterminateOperationState);
   249|     }
   250|     @Override
   251|     public InvocationBuilder createInvocationBuilder(String serviceName, Operation op, Address target) {
   252|         checkNotNull(target, "Target cannot be null!");
   253|         return new InvocationBuilderImpl(invocationContext, serviceName, op, target)
   254|                 .setTryCount(invocationMaxRetryCount)
   255|                 .setTryPauseMillis(invocationRetryPauseMillis);
   256|     }
   257|     @Override
   258|     public void run(Operation op) {
   259|         operationExecutor.run(op);
   260|     }
   261|     @Override
   262|     public void execute(Operation op) {
   263|         operationExecutor.execute(op);
   264|     }
   265|     @Override
   266|     public boolean isRunAllowed(Operation op) {
   267|         return operationExecutor.isRunAllowed(op);
   268|     }
   269|     @Override
   270|     @SuppressWarnings("unchecked")
   271|     public <E> InvocationFuture<E> invokeOnPartition(String serviceName, Operation op, int partitionId) {
   272|         op.setServiceName(serviceName)
   273|                 .setPartitionId(partitionId)

# --- HUNK 2: Lines 287-326 ---
   287|         op.setServiceName(serviceName)
   288|                 .setPartitionId(partitionId)
   289|                 .setReplicaIndex(replicaIndex);
   290|         return new PartitionInvocation(
   291|                 invocationContext, op, invocationMaxRetryCount, invocationRetryPauseMillis,
   292|                 DEFAULT_CALL_TIMEOUT, DEFAULT_DESERIALIZE_RESULT, failOnIndeterminateOperationState).invokeAsync();
   293|     }
   294|     @Override
   295|     @SuppressWarnings("unchecked")
   296|     public <E> InvocationFuture<E> invokeOnPartition(Operation op) {
   297|         return new PartitionInvocation(
   298|                 invocationContext, op, invocationMaxRetryCount, invocationRetryPauseMillis,
   299|                 DEFAULT_CALL_TIMEOUT, DEFAULT_DESERIALIZE_RESULT, failOnIndeterminateOperationState).invoke();
   300|     }
   301|     @Override
   302|     @SuppressWarnings("unchecked")
   303|     public <E> InvocationFuture<E> invokeOnTarget(String serviceName, Operation op, Address target) {
   304|         op.setServiceName(serviceName);
   305|         return new TargetInvocation(invocationContext, op, target, invocationMaxRetryCount, invocationRetryPauseMillis,
   306|                 DEFAULT_CALL_TIMEOUT, DEFAULT_DESERIALIZE_RESULT).invoke();
   307|     }
   308|     @Override
   309|     public void onStartAsyncOperation(Operation op) {
   310|         asyncOperations.add(op);
   311|     }
   312|     @Override
   313|     public void onCompletionAsyncOperation(Operation op) {
   314|         asyncOperations.remove(op);
   315|     }
   316|     @Override
   317|     public boolean isCallTimedOut(Operation op) {
   318|         if (isJoinOperation(op) || isWanReplicationOperation(op)) {
   319|             return false;
   320|         }
   321|         long callTimeout = op.getCallTimeout();
   322|         long invocationTime = op.getInvocationTime();
   323|         long expireTime = invocationTime + callTimeout;
   324|         if (expireTime <= 0 || expireTime == Long.MAX_VALUE) {
   325|             return false;
   326|         }


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/spi/impl/operationservice/impl/PartitionInvocation.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-51 ---
     1| /*
     2|  * Copyright (c) 2008-2021, Hazelcast, Inc. All Rights Reserved.
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.spi.impl.operationservice.impl;
    17| import com.hazelcast.cluster.ClusterState;
    18| import com.hazelcast.cluster.Member;
    19| import com.hazelcast.core.MemberLeftException;
    20| import com.hazelcast.internal.partition.InternalPartition;
    21| import com.hazelcast.internal.partition.PartitionReplica;
    22| import com.hazelcast.cluster.Address;
    23| import com.hazelcast.internal.server.ServerConnectionManager;
    24| import com.hazelcast.partition.NoDataMemberInClusterException;
    25| import com.hazelcast.spi.impl.operationservice.ExceptionAction;
    26| import com.hazelcast.spi.impl.operationservice.Operation;
    27| import com.hazelcast.spi.impl.operationservice.ReadonlyOperation;
    28| import static com.hazelcast.cluster.memberselector.MemberSelectors.DATA_MEMBER_SELECTOR;
    29| import static com.hazelcast.spi.impl.operationservice.ExceptionAction.THROW_EXCEPTION;
    30| /**
    31|  * A {@link Invocation} evaluates a Operation Invocation for a particular partition running on top of the
    32|  * {@link OperationServiceImpl}.
    33|  */
    34| final class PartitionInvocation extends Invocation<PartitionReplica> {
    35|     private final boolean failOnIndeterminateOperationState;
    36|     PartitionInvocation(Context context,
    37|                         Operation op,
    38|                         Runnable doneCallback,
    39|                         int tryCount,
    40|                         long tryPauseMillis,
    41|                         long callTimeoutMillis,
    42|                         boolean deserialize,
    43|                         boolean failOnIndeterminateOperationState,
    44|                         ServerConnectionManager connectionManager) {
    45|         super(context, op, doneCallback, tryCount, tryPauseMillis, callTimeoutMillis, deserialize, connectionManager);
    46|         this.failOnIndeterminateOperationState = failOnIndeterminateOperationState && !(op instanceof ReadonlyOperation);
    47|     }
    48|     PartitionInvocation(Context context,
    49|                         Operation op,
    50|                         int tryCount,
    51|                         long tryPauseMillis,


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/spi/impl/operationservice/impl/TargetInvocation.java
# Total hunks: 1
# ====================================================================
# --- HUNK 1: Lines 1-45 ---
     1| /*
     2|  * Copyright (c) 2008-2021, Hazelcast, Inc. All Rights Reserved.
     3|  *
     4|  * Licensed under the Apache License, Version 2.0 (the "License");
     5|  * you may not use this file except in compliance with the License.
     6|  * You may obtain a copy of the License at
     7|  *
     8|  * http://www.apache.org/licenses/LICENSE-2.0
     9|  *
    10|  * Unless required by applicable law or agreed to in writing, software
    11|  * distributed under the License is distributed on an "AS IS" BASIS,
    12|  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|  * See the License for the specific language governing permissions and
    14|  * limitations under the License.
    15|  */
    16| package com.hazelcast.spi.impl.operationservice.impl;
    17| import com.hazelcast.cluster.Member;
    18| import com.hazelcast.core.MemberLeftException;
    19| import com.hazelcast.cluster.Address;
    20| import com.hazelcast.internal.server.ServerConnectionManager;
    21| import com.hazelcast.spi.impl.operationservice.ExceptionAction;
    22| import com.hazelcast.spi.impl.operationservice.Operation;
    23| import static com.hazelcast.spi.impl.operationservice.ExceptionAction.THROW_EXCEPTION;
    24| /**
    25|  * A {@link Invocation} evaluates a Operation Invocation for a particular target running on top of the
    26|  * {@link OperationServiceImpl}.
    27|  */
    28| final class TargetInvocation extends Invocation<Address> {
    29|     private final Address target;
    30|     TargetInvocation(Context context,
    31|                      Operation op,
    32|                      Address target,
    33|                      Runnable doneCallback,
    34|                      int tryCount,
    35|                      long tryPauseMillis,
    36|                      long callTimeoutMillis,
    37|                      boolean deserialize,
    38|                      ServerConnectionManager connectionManager) {
    39|         super(context, op, doneCallback, tryCount, tryPauseMillis, callTimeoutMillis, deserialize, connectionManager);
    40|         this.target = target;
    41|     }
    42|     TargetInvocation(Context context,
    43|                      Operation op,
    44|                      Address target,
    45|                      int tryCount,


# ====================================================================
# FILE: hazelcast/src/main/java/com/hazelcast/spi/utils/RestClient.java
# Total hunks: 2
# ====================================================================
# --- HUNK 1: Lines 89-128 ---
    89|         this.retries = retries;
    90|         return this;
    91|     }
    92|     public RestClient withCaCertificates(String caCertificate) {
    93|         this.caCertificate = caCertificate;
    94|         return this;
    95|     }
    96|     public RestClient expectResponseCodes(Integer... codes) {
    97|         if (expectedResponseCodes == null) {
    98|             expectedResponseCodes = new HashSet<>();
    99|         }
   100|         expectedResponseCodes.addAll(Arrays.asList(codes));
   101|         return this;
   102|     }
   103|     public Response get() {
   104|         return callWithRetries("GET");
   105|     }
   106|     public Response post() {
   107|         return callWithRetries("POST");
   108|     }
   109|     private Response callWithRetries(String method) {
   110|         return RetryUtils.retry(() -> call(method), retries);
   111|     }
   112|     private Response call(String method) {
   113|         HttpURLConnection connection = null;
   114|         try {
   115|             URL urlToConnect = new URL(url);
   116|             connection = (HttpURLConnection) urlToConnect.openConnection();
   117|             if (connection instanceof HttpsURLConnection && caCertificate != null) {
   118|                 ((HttpsURLConnection) connection).setSSLSocketFactory(buildSslSocketFactory());
   119|             }
   120|             connection.setReadTimeout((int) TimeUnit.SECONDS.toMillis(readTimeoutSeconds));
   121|             connection.setConnectTimeout((int) TimeUnit.SECONDS.toMillis(connectTimeoutSeconds));
   122|             connection.setRequestMethod(method);
   123|             for (Parameter header : headers) {
   124|                 connection.setRequestProperty(header.getKey(), header.getValue());
   125|             }
   126|             if (body != null) {
   127|                 byte[] bodyData = body.getBytes(StandardCharsets.UTF_8);
   128|                 connection.setDoOutput(true);

# --- HUNK 2: Lines 160-200 ---
   160|     }
   161|     private boolean isExpectedResponseCode(int responseCode) {
   162|         return expectedResponseCodes == null
   163|                 ? responseCode == HTTP_OK
   164|                 : expectedResponseCodes.contains(responseCode);
   165|     }
   166|     /**
   167|      * Builds SSL Socket Factory with the public CA Certificate from Kubernetes Master.
   168|      */
   169|     private SSLSocketFactory buildSslSocketFactory() {
   170|         try {
   171|             KeyStore keyStore = KeyStore.getInstance(KeyStore.getDefaultType());
   172|             keyStore.load(null, null);
   173|             int i = 0;
   174|             for (Certificate certificate : generateCertificates()) {
   175|                 String alias = String.format("ca-%d", i++);
   176|                 keyStore.setCertificateEntry(alias, certificate);
   177|             }
   178|             TrustManagerFactory tmf = TrustManagerFactory.getInstance(TrustManagerFactory.getDefaultAlgorithm());
   179|             tmf.init(keyStore);
   180|             SSLContext context = SSLContext.getInstance("TLSv1.2");
   181|             context.init(null, tmf.getTrustManagers(), null);
   182|             return context.getSocketFactory();
   183|         } catch (Exception e) {
   184|             throw new RestClientException("Failure in generating SSLSocketFactory", e);
   185|         }
   186|     }
   187|     /**
   188|      * Generates CA Certificate from the default CA Cert file or from the externally provided "ca-certificate" property.
   189|      */
   190|     private Collection<? extends Certificate> generateCertificates()
   191|             throws CertificateException {
   192|         InputStream caInput = null;
   193|         try {
   194|             CertificateFactory cf = CertificateFactory.getInstance("X.509");
   195|             caInput = new ByteArrayInputStream(caCertificate.getBytes(StandardCharsets.UTF_8));
   196|             return cf.generateCertificates(caInput);
   197|         } finally {
   198|             IOUtil.closeResource(caInput);
   199|         }
   200|     }

