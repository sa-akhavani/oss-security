{
  "vuln_id": "GHSA-7gfq-f96f-g85j",
  "range_index": 0,
  "safe_id": "GHSA-7gfq-f96f-g85j",
  "package": "langchain",
  "platform": "PyPI",
  "actual_cwe": "CWE-94",
  "actual_cve": "CVE-2023-36281",
  "vulnerable_version": "v0.0.311 \u2192 v0.0.312",
  "patched_version": "v0.0.311 \u2192 v0.0.312",
  "target_cwes": [
    "CWE-79",
    "CWE-1333",
    "CWE-94",
    "CWE-22",
    "CWE-352"
  ],
  "diff_lines": 3591,
  "diff_analysis": {
    "vulnerable": true,
    "cwe_found": "CWE-94",
    "evidence": "The new LLMBashChain (libs/langchain/langchain/chains/llm_bash/base.py) and BashProcess utility (libs/langchain/langchain/utilities/bash.py) execute arbitrary shell commands that are generated from LLM output based on user-controlled prompts. The chain takes natural language questions, has the LLM produce bash code, parses it, and then passes the resulting commands directly to subprocess.run or a persistent bash session without any sanitization or restriction. This constitutes improper control of code generation and execution, matching CWE-94 (Code Injection), as an attacker can influence the generated commands to run arbitrary system-level code.",
    "analysis_time_seconds": 3.83,
    "token_usage": {
      "input_tokens": 34789,
      "output_tokens": 154,
      "total_tokens": 34943
    },
    "model": "gpt-5.1",
    "provider": "openai"
  },
  "dataset_version": "v3",
  "reverse_mode": false,
  "code_checked": "vulnerable (+)",
  "detected_vulnerable": true,
  "correct_detection": true,
  "analyzed_at": "2026-02-04T00:50:40.638191",
  "model": "gpt-5.1"
}