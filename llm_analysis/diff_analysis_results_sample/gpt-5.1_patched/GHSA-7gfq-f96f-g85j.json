{
  "vuln_id": "GHSA-7gfq-f96f-g85j",
  "range_index": 0,
  "safe_id": "GHSA-7gfq-f96f-g85j",
  "package": "langchain",
  "platform": "PyPI",
  "actual_cwe": "CWE-94",
  "actual_cve": "CVE-2023-36281",
  "vulnerable_version": "v0.0.311 \u2192 v0.0.312",
  "patched_version": "v0.0.311 \u2192 v0.0.312",
  "target_cwes": [
    "CWE-79",
    "CWE-1333",
    "CWE-94",
    "CWE-22",
    "CWE-352"
  ],
  "diff_lines": 3591,
  "diff_analysis": {
    "vulnerable": true,
    "cwe_found": "CWE-94",
    "evidence": "Old code allowed constructing PromptTemplate objects with template_format=\"jinja2\" and provided a jinja2_formatter that explicitly warned it could lead to arbitrary Python code execution when used with untrusted input. This is a classic code injection risk (CWE-94) because jinja2 templates are not sandboxed and can execute arbitrary code if user-controlled data is used in templates.",
    "analysis_time_seconds": 4.56,
    "token_usage": {
      "input_tokens": 34825,
      "output_tokens": 109,
      "total_tokens": 34934
    },
    "model": "gpt-5.1",
    "provider": "openai"
  },
  "dataset_version": "v3",
  "reverse_mode": true,
  "code_checked": "patched (-)",
  "detected_vulnerable": true,
  "correct_detection": false,
  "analyzed_at": "2026-02-04T01:06:17.262751",
  "model": "gpt-5.1"
}